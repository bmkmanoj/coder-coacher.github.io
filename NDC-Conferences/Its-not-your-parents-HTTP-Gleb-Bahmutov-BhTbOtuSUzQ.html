<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>It's not your parents' HTTP - Gleb Bahmutov | Coder Coacher - Coaching Coders</title><meta content="It's not your parents' HTTP - Gleb Bahmutov - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>It's not your parents' HTTP - Gleb Bahmutov</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BhTbOtuSUzQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well hello everyone and welcome to it's
not your parents HTTP session today you
look like a bunch of very smart and
handsome developers completely immune to
flattery and I'm really happy with NDC
invited me to talk about this topic
it's a beginner level topic so I'm not
going to go into details of HTTP frames
for example but we're going to overview
the history of HTTP what problem it was
trying to solve words now today and what
the future is for HTTP and alternatives
a couple words about myself first what
is mine so my name is Lee Bogg notif I
started as a computer vision researcher
and when I slowly switched into web
development I'm very active on Gitter
and github and Twitter and all the
slides will be on slice calm
I made a transition from being a C++ and
C sharp developer for a bunch of years
to CoffeeScript and then JavaScript ins
of front-end but my passion is actually
writing things down for myself all right
if you attended Troy Hans presentation
Haggar career it's the first point that
he made like he made a blog and he was
just trying to write things down for
himself so that he doesn't have to look
up things everywhere and the same is
true for me I forget things and then or
not forget I I blog and I recently took
a screenshot of word cloud of all those
things that I wrote about on the blog
and you know JavaScript functional
nodejs performance I don't have HTTP
here I do have browser as a tag but
nothing related to HTTP right hmm but I
think I'm know what I'm doing right like
I have my you know sleeves kind of
rolled up so but that means I know I
mean business my proudest achievement
was writing a little
a code snippet for playing game of life
on github contribution account so you
can go to any account and just click a
button and you can see if you can get a
repeating pattern
some people have beautiful you know
visualizations most most people's
account kind of die after a certain
number of iterations I was born in
Moldova but I don't have to tell you
guys where it is because we were in
Europe
you guys know where it is probably in in
America have to explain in other ways
right now I work and live in Boston
which is in Massachusetts I live in
Cambridge home of MIT Harvard
universities and I was looking at bunch
of jobs with a head before and those one
thing would kind of underlied the common
theme so to speak and it wasn't
programming language or a subject it
wasn't a particular technology except
for one thing and that thing was
internet right none of these companies
would be where we are today
except from probably math works but even
at math works I was actually porting
MATLAB to run inside your browser
without internet and we also say in a
World Wide Web
like whatever we see in a browser
internet when people say I saw it on
internet they mean a certain the browser
and if you say a certain the browser
that means HTTP so none of these jobs
are very different
would you possible without HTTP so well
today I'm I work at a company called
Cyprus and we just do end-to-end testing
tool looks like this where you load your
website and it runs right inside the
browser so you can see the execution
running it completely replaces selenium
and protractor and corner and phantom GS
and then you can just go for each step
and you can see exactly what browser
gate we're trying to solve a problem but
you know when we say Internet is broken
we mean websites are broken with so many
crappy websites where I cannot buy a
ticket when I want where I'm trying to
make reservation it doesn't work so
we're trying to sell it
okay so 2017 I called myself a software
engineer
all right that's kind of my day-to-day
state of mind like I can't look puzzled
and I can't sleep problems and I'm not
sure about you guys but I often ask
myself a question right if I wasn't born
in I take if I was born at a different
time what would I be what kind of job
would I find myself interested in so
let's say I was born 4,000 years ago I
probably would be a farmer just by
statistics probability most of the
people with just subsistence farmers
they grew their own food or they hunted
and I probably be a farmer I probably be
very happy farmer like this guy this is
a weird picture I don't know why he's so
happy
but if I were born along the Nile River
4000 years ago I would probably want to
be a civil engineer right because they
had a large project building a pyramid
so you know royal family would come to -
to me or my company my corporation and
say okay we need something what would
look good after the Pharaoh dies and it
would look good on a greeting card 4000
years later and I was like oh well I'll
take whatever technology is available
you know playing simple geometry stone
materials unlimited labor very cheap
labor and I could probably build you
something like what looks like a bunch
of bricks stuck together right and I'll
build the pyramids and I know that I
would like the job just because my son
and I we build fixing things from Lego
and the first thing was you know we do
it like how tall can we build a tower
from Lego block and you know but first
you build the tower one higher than me
and told me and then all the way to
sitting so I know I love building tall
structures from bricks I want to be an
engineer even if I were born
four thousand years ago so what what
engineer is actually pretty good board
um it's derived from Latin from towards
and one word is meaning means to device
or construct and another one means
cleverness so English means someone who
builds something in a very clever way
right but in our view point is that an
engineer is someone who has to construct
something but in a set of constraints
and constraints would be features time
cost user experience for example if
you're constructing a pyramid you
probably are not concerned about the
costs but you concern about the feature
which King has to look good because
otherwise you probably will die you can
also think about engineers as a link
between science and what is possible and
the general population so an engineer
can build an airplane all right
something that operates on scientific
principles for general population to
take flight if I were born in Roman
Empire I mean this is a golden age right
I would be building roads I could be
building aqueducts collisions palaces
temples engineers civil engineers at the
time were a sink in a very good position
but nothing like Industrial Age if I
were born 2200 years ago I probably
would work on you know hydropower plants
skin shapes railroads building bridges
but then if I were born as 60 years ago
I probably would want to be a scientist
right because at that point especially
because of space race being a scientist
was the pinnacle where different levels
of what says respect the society pays
different professions doctors are always
admired and respected in Soviet Union
for example where I was born being a
scientist was the top right good you
know you could be a celebrity it could
be a doctor but being a scientist was
the highest position with society at
mark because except science is actually
hard in science if you ever look at the
paper a published paper which is always
the last page and the last page with all
the references all the source material
but this current page uses to actually
propose something new and describe
something new and as Isaac Newton said
that it's not that he was taller and he
could see farther away but he was
standing on shoulders of giants so in a
sense we're still building a pyramid
except now it's not made out of big
stone blocks it's made out of other
inventions so every scientist takes
whatever other scientists created before
slides their work and then publishes new
paper and if you don't do this then your
career goes nowhere very very fast right
science is a constant grind of trying to
publish trying to find it
trying to get your paper in a top
journal or conference getting tenure
right
and this means but scientists constantly
have to look up source material right
and they have to make whatever they
produce it could be papers images
experiment results raw data as available
to others as possible so that other
people can cite and reference it and
that your science becomes more more
important
if more people link to you and can use
it then your career prospers but you
also have to do it constantly right
yourself you have to cite other people's
work ok so what does this have to do
with HTTP and the topic at hand ok
moving to Europe in 1989 at CERN a
couple of thousands of scientists are
working there and they have this problem
they have a bunch of papers they have
bunch of datasets right and every
scientist is trying to find information
or provide information to others right
so they have this giant number of
documents and they have no idea of how
to find them how to retrieve them how to
search how to store them ok
at the time they had heard a permanent
researcher of by name Kim and he was
there for I think eight years by then
and he had this problem and he says well
I'll try to come up with a solution okay
and he makes this proposal and it goes
to the management and it's titled
information management a proposal it has
abstract it kind of describes a graph of
documents and have it be connected to
each other and on the top it's kind of
hard to see but we respond from his boss
on the red is proposal which is vague
but exciting right so talk about setting
the bar very low kind of like only
invent the Internet
no but exciting so he goes off and
starts working at that time he already
wrote something called
enquire and inquire dealt with it's
almost like a wiki of cards right and
the cards were written in something
called hypertext basically it's normal
text but they had almost like markdown
as a link with like name of
card but you should look if you want
more information and it wasn't only
proposal right he also considered other
things for linking bunch of documents
for example if you've thought about
doing keyword search right every
document would provide lists of keywords
and menu every time you need a document
you search by keyword maybe you'll find
the document end related things he
thought about maybe creating almost a
universal Dewey Decimal System like a
libraries with why Bruce yesterday but
for the for the documents then he says
no no I'll just have this giant graph
any any document can link to another
document using some resource ID and the
document could be on a different server
by the time were related servers like
FTP but could actually serve a document
right but there's no concept of
connecting hypertext to those servers so
off he goes and two years later he comes
back and he describes what HTML is a
markup language and he builds HTTP
server and he also builds the first
browser and this is the screenshot of a
first browser called all wide web all
one word
we're a couple interesting things if you
look at the first browser first were a
bunch of spelling errors right it was
very quick right you had to write all
parts of the system so sometimes a link
takes a backseat second it kind of looks
like modern thing right um he he used
next system which kind of led to Apple
so what duck bar on a right looks the
same interesting enough if you think
about right imagine you're starting a
library and there are no books right the
first thing your library probably would
provide you is like a stack of paper you
want to have a book to read you have to
write one so this means that on the left
you
have mainmenu various edit button and
very fine button and the Edit is
actually above find this browser
function both as a browser and as editor
and the editor function was actually
first because most people had to
actually write something before you
could actually read something over time
we obviously switch to more passive I'm
just reading what everything document
I'm writing buddy I'm producing very
little content but the first browser had
added and create on the top and
obviously you edit the document that you
store locally right you can just access
the file system if you want to find
something you have to go to remote
server and then is read on we've also
had a very interesting model of from
interaction so usually we think about
user centric browsing right we go to a
page it has a link we click on the link
we go to another page when we click
previous a back button we go to the back
document that we actually saw so where
user controls both back and forward
means in this browser you had 2 Mol's
you had user centric which it has also
document-centric mode where imagine a
document has bunch of links and you go
to a first document click on the link
and then you click a back button
instead of you going back to last
previous page what you saw it actually
opens the previous link in original
document so previous and next were
actually defined by the order of links
in a document so it was document-centric
browsing not user center and this was
meant for quickly going for all the
links in a document because obviously
there was no spam or no as ads you could
just read one link after another so this
was 1991
on 94 a second version called Nexus was
written by him and this already looks
just like a modern browser it also has a
first domain info that's on that CH by
that time DNS system already was
available and were already domains but
they were only we're not not all by Web
there were FTP direct connections this
was first web site on the first modern
domain was no URL still right you did
not see the URL if you want to actually
see the URLs you had to open inspect
mode and actually see what you're
looking at the first web site actually
just described what the system was
what's hypertext hi HTML right how to
add it who are the people behind it and
then also switch the order of edit and
find to find and then edit more Intune
with just passive browsing so this was
the user facing but under the hood you
had to retrieve a remote documents it's
easy to retrieve local documents you
just open the file you read it in any
display but most of the links actually
point is somewhere else right that was
original goal of a system so here's a
way to actually transport with HTML
document bring it in order to short so
you need is a protocol so 991 in Burnley
described HTTP his part of document
retrieval and it's known as HTTP 0.9 and
as you can see it's not a very large
document it's signed by Kim Kim VL and
you know we I talked about being an
engineer right an engineer is someone
who considered of costs and trade-offs
and user experience and practical
application of a technology this guy's
engineers and
I mean his title right now is professor
of engineering in the School of
Engineering with during appointment
Department my lexicon during so his
title has three engineer words in it
like if you want to be an engineer
that's your role model but more
important thing is that the whole
proposal the whole standard at that
point the initial thing was only 650
words it fits on the page and a half
it's vast extent because when you're
trying to find the trade-off between
with features the cost the time he
needed something now he didn't have
bunch of peers he wanted to have a
system and the system of a browser HTML
but no way to actually retrieve and a
different HTML document was useless so
he needed something very very quickly
and so he concentrated on simplicity
there are only four sections in this
document you have to open a connection
you have to make a request for a
document you have to receive a response
and you have to close the connection
that's it the simplicity rules you know
people ask why the port 80 by default
well because he picks one and at that
time there was RFC of commonly used
ports and they covered bunch of ports
right and at that point there was a gap
between 79 81 so he just said okay I'll
take that one in three and there are
other gaps so we might as well we could
have had a port 53 or 41 or a bunch of
gaps but he picked 80 and it became by
default he specified that once the
document have been transferred with the
CP connection is closed right so that
kind of defines the current HTTP model
before we actually extend it but it was
a single-shot operation give me the
document and when you give me the
document I no longer need you
free to break a connection you can serve
somehow request the whole thing was just
get and the name of a document right
looks very very similar to what we have
right now except there is no host name
just get and rename your document okay
simplicity is the key at that time the
only thing with browser could show was
HTML the standard but he invented right
and it's a ascii-based standard and
that's it there is nothing else and as
soon as you send and receive this ASCII
text document you close a connection the
only kind of interesting thing is that
if you engineer right and you divide the
system you probably want to do some
guest safety standards or guards or
describe unhappy path one how to do
something when was a behavior when
something fails and in in the first
version of HTTP was none you receive a
document and the server could not tell
you even if the document was not found
the server could send HTML it was
include attacks not found but there is
no way for machine talks to communicate
for protocol but the document doesn't
exist you as a user and at first it was
all meant for humans right human would
read i'll i guess the link was wrong oh
I guess the server is not doing his job
or yes I am not allowed to do it no you
have to read the text there is no error
response : no response code at all not
even 200 and at the end well protocol
says the server will not store any
information right it was purely
read-only requests no cookies no
sessions that we make on top of cookies
no post requests
nothing it was purely read-only document
retrieval system and I always think
about this and we have a name for this
pattern right and if you're not going to
need it like why spend time thinking
coding debugging arguing about features
with you not going is I have an
immediate goal I want to retrieve all
the textual documents right and I'm just
going to implement it does HTTP solve
this problem what is this problem
well I'm reading this document it has
text and it has a link a hyper in a rest
Hof goes towards a different server has
the name and I want to read the link
that's a problem with HTTP is trying to
solve your always forget when we say
OACP is slow or ACP doesn't do that
doesn't allow to wait communications
well it wasn't meant to do that HTTP
stands for hypertext Transfer Protocol
it transfers UHE HTML document that's it
it's like arguing
why doesn't Honda Civic you know why can
it like transport 10,000 people well
it's not meant it's not built to do that
it may user asking for document and
receiving another HTML document when you
do that right when you have to try to
retrieve something from a document you
have to transfer data and at that point
you had a choice what actual transport
protocol am I going to base HTTP on and
the decision was made because you don't
want to lose part of the document you
want to retrieve a whole document and
you don't want to implement the logic
itself too big with TCP right try to
transfer control protocol and we kind of
think about us going through a browser
that it just does with your connection
but it is
true the actual HTTP request goes to TCP
but goes to IP but goes to a cloud and
then prove the same mirror stack on the
server gets to the HTTP server which
returns the document to us all details a
hidden but you know we different layers
actually ask different questions like IP
for Internet Protocol ask for question
where where should request be delivered
and TCP just says how you know I have to
transfer first part second and then
assemble the same the choice of TCP has
a huge implication right because the
performance of HTTP retrieval and the
future other stuff is directly tied to
performance of TCP and we will show we
will see this over and over again
TCP have two things going for it and
making it an ideal choice it is
guaranteed dated delivery right if you
are asking to get HT HTML documents you
will receive a full document will be no
parts missing and most importantly
nothing will be garbled it's not like
the first paragraph will arrive after
the second the first paragraph will
always be delivered before the second
one and assembled in the same order as
the original document any person is
celebrated I think the trade offs and
the original system is was a great
simple concept the whole IT boom of 2000
the internet boom and all and bus right
would not have happened if this
technology wasn't clever enough
ingenious enough to be extendable and
powerful interesting thing in a protocol
the first Center says future HTTP
protocols will be back compatible with
this protocol obviously this kind of got
dropped pretty quickly saying like now
we mean we have the support modern
what you give us so we're going to skip
that requirement and 9091
is a long ago it was only 26 years ago
now here's a question would you get an
airplane if 26 years ago airplanes look
like that
right obviously not like no way
airplanes could have evolved but quickly
in such a short amount of time but
internet did the growth of Internet was
incredible first just academic
institutions but quickly businesses big
started retrieving any text over the
internet system is actually very
interesting proposition and the number
of available websites not servers that
website will grow at extreme rate as
soon as many people start using the
system you get on the question of again
I want to see this JPEG how do I do that
and turns out a lot of things that we
thought were not needed were actually
needed so fast forward five years the
second standard HTTP 1.0 is already 60
pages and it kind of looks like what we
expect to see it has cookies it has
request headers response headers and so
on
but very useful
non non HTML data images more methods
for Alice is not just yet it's also
posting the data main change status
codes were added like right away and
user preferences like you want to
communicate what format of a document
and what are you human critics were
aculeatus later because of great
competition and because of a great
browser Wars there were a lot of other
changes to http one right 27 drafts
most of them concentrate on performance
and security as soon as many people got
on internet you had to take care of
but were not as simple let me see
I'm going to skip i.e Kiev but just go
to the next one we think with HTTP one
is kinda uniform and all the details are
taken care for us but in girls it's a
mess it's a mess of protocols
implementations extensions non-standard
parts and they all interact and I highly
recommend you pick up this book right
but shows the tangled web how different
things interact in security implications
of the interaction but we're still
asking for a page and web browser goes
and retrieves have a page and I'm
talking about the browser I know the
service of the community HTTP but most
of the things apply and in a browser
with choices are limited on a server you
could do TCP connection directly in a
browser you have to work with standard
the modern HTTP requests and responses
used to be so simple kind of blew up
right we have giant amounts of
information flowing with HTTP for each
request you know state even though
protocol was supposed to be stateless is
transmitted for cookies we have cached
and you have a lot of security headers
Kings will be missing as soon as we got
to the whole page retrieval we start
asking ok I don't need the whole page I
just need a part web page we also will
load so Internet Explorer introduced the
feature of including a frame in one
document that comes from an average DP
server so ready you have a website
that's a composition of a couple things
and then they quickly introduce
something that's scriptable xml
httprequest ajax is known and like you
went very quickly from being just
internet only to showing its full
potential when gmail get introduced to
RFC standards but
kind of looks nasty I don't like making
direct requests but there's a new
standard but tries to normalize how
browsers retrieve different this
information is called fetch it's quickly
being adapted I think all the modern
browsers except from I'm not sure what
Safari but profitable are supported to
but it's very clean syntax and it's
available already so today what do we
have we have a whole stack HTTP and then
on top we implement something else like
graph graph QL again trying to make it
more usable trying to build up values
the features but if we talk about HTTP
it has is transitioning to a CB 2 or
quick but very couples are alternatives
right but available today like web
sockets like WebRTC and unfortunately in
the alike web RTC technology I don't
think we have time to discuss it but
also of off I'll speak a couple words
about Service Worker okay so that's the
outline WebSockets making TCP
connections is incredibly expensive
you have to handshake that requires a
couple of round trips people try to
optimize it but still the round trip is
killing you every request because only
one thing can be done requires this the
congestion protocol tries to say ok you
don't know how much data you can send so
you can try to do a slow start and you
send more data and if it doesn't get
through when you go back to previous
level again it's very slow HTTP
connections are expensive and especially
if you can only do one that's very bad
as if you want to define how to upgrade
so you connect to HTTP 1 and you want to
say ok I want to switch to something
else and leave the server supports it
then you both can switch and it's
actually very nice right that's a good
feature to have WebSockets got
implemented pretty much immediately the
game
standard and now every browser supports
them so because if you want to avoid the
overhead and you want a single
bi-directional connection in the browser
web site is either way to go for Service
Worker all the major API is are now
required HTTP right because the API is
an amount of data that they can transmit
and amount of things they can do on your
behalf as a user and on behalf of web
sites is tremendous so you better be
pretty sure that you're actually talking
to a right website and no one actually
impersonating you so the best things are
FCPS now for example serviceworker is
trying to solve this problem right it's
not HTTP protocol but it works with
intercepting HTTP requests but coming
out of your browser and it's meant to
solve this problem of application cache
when things go offline when the server
doesn't respond what do you do we tried
kind of write down all the things with
browser's cache but it never worked so
we had to switch to using something else
and let the serviceworker
so browser has this new thing that kind
of sees in between the browser and can
intercept every request can transform it
send it to the server and can receive a
response transform it or not and give it
back to a browser and you can implement
all sorts of sorts of a smart caching
strategies offline support you name it
um in this slides were a bunch of
examples later but you can look and
videos where things look like they
shouldn't work but they still do just
because a serviceworker before I discuss
hep-2 I just want to address overflow
room right because that's the most
important part of a talk right and if
you guys are watching you probably
should switch like one one switch all
day just look at look at the slides okay
http/2 only purpose of HTTP is to make
things faster and things are slow right
now because if you look at how playing
on a long screen how even a simple
website is loading these resources right
so I'm reloading near times calm you can
see hundreds and hundreds of requests
going out all sorts of things page
scripts Styles funds and your ad
tracking technology everything 236 246
250 this looks nothing like you know
original page right completely
completely different problem HTTP
doesn't tell you how to do these things
quickly write 200 things to fetch how
their paradise how the way virtual right
thing so we click it and it would
quickly found out with the limitations
not the bandwidth as you scale up with
the available bandwidth for mobile
device or laptop or for wired connection
the page still loads in the same amount
of time with HTTP what really kills you
and what makes the biggest difference is
making a round-trip shorter it with
delays to make each connection and fetch
the data but really really affect the
loading performance so in 2009 Google
started speedy project and speedy was
trying to reinvent HTTP and it was a
binary multiplexed protocol in a measly
vessel a 50% improvement so they kept
working on this and six years later it
became an RFC and this would be known by
HTTP 2 and the changes were purely in a
way things were sent nothing in API
change except one thing so it's a level
but kinda sees between application in a
browser and
everything below and it converts what we
know as text requests in response to
bunch of frames so split them up sell
them individually make the frames binary
now you can do things like that you need
bunch of resources well split everything
into frames and use a single persistent
connection to send things and you can
multiplex and so multiple resources will
serve it and arrive at the same time and
then HTTP 2 will reassemble everything
and give you complete things correctly
you can even specify dependencies and
say hey give this resource a priority by
giving weights so for example in this
case I need two resources a and B and sa
well give a 12 slots and B for that
means but a will use three times as many
frames to be fetched and B so it should
arrive three times fast you can say
fetch D and then C and in the last
example you can fetch G then C then
fetch a and B but give a three times as
many free slots as resource B so that
makes things a lot more controllable a
lot faster and the things should arrive
in a better order the page to the right
first and then maybe some splash images
at the very end if you have to get up
for headers it will give you this and
the whole amount of security and content
security policy is just enormous
and that's why a single request but
cookies and header take up almost half
as well original protocol definition was
in 91 so the big part of HTTP 2 is to
compress the headers and we do it by two
things one they only send you with gifts
of headers so you have requests 1 and
then request - the only thing that
really changes
is the URL the path if it's on the same
domain and so the protocol will send a
header frame with all the headers but
for the secondary source it will only
change the change paths to the single
field also you can see what columns in
request because HTTP 1 used to justify
the full URL when it was making
connection so you never had actual
headers forget for method for host for
path now they have to be specified and
they're called Silda headers and now
they can be sent separately and also it
has a static table of all the common
address like method then refer right and
you can just encode this by numbers by
indices instead of sending like refer
text and everything else is encoded as
well pretty good
adoption all the evergreen browsers now
support it so in just a few years HTTP
reached a lot of traffic it's actually
hard to find up to days that and you'd
think that major CBN's of proxies or
website would make this data up-to-date
in life so the best I could find was
June but it's only that 14% of all web
sites were using HTTP to write and this
is growing this is doubled from previous
year almost for a lot of websites that
are kind of stuck in between on speedy
protocol and they haven't made a
transition but HTTP to really optimizes
the number of connections so a lot fewer
requests are now using just one
connection and then saying that's it I
don't need anymore
two great resources if you want to find
out more about HTTP and networking are
available online for free
yeah Gregorek v browser networking is
just unbelievable book
and Daniel Steinberg the guy who wrote
coral have a free online website that
actually explains in human language HTTP
to protocol and what different parts
mean if you go to Chrome net internals
you can actually inspect HTTP 2 and you
can see individual frames as they arrive
I'm going to skip it just because of
time constraints and I'm going to go to
something else so I said with HCB to was
one to one replacement of HTTP 1 not
nothing new right you just change the
framing before it goes to TCP but there
is one edition and what addition is
server push imagine your client browser
and that's the timeline and the server
has a document and if they give me the
index.html you receive in the Christian
mail you parse it and you find all
varies is getting an image so you make
request for an image the server gives
you the image and when you display
what kind of takes a long time right how
do you optimize this time between
receiving index.html and then showing it
not even when you make requests but but
actually belong the line who knows
nobody need the image and in the credit
email the server so with server port you
make requests and the services ok you
meet the individual node but you will
also need this image and I'll start
pushing it right away over the same
connection and so you receive it index
and image you parse the index.html and
you look how I need to get this photo
you make requests if you'll make a
request nothing change but then you
immediately hit the cache and says oh I
already have it so it should be in
principle in principle faster it's
extremely nice when you can do it with
CSS and JavaScript because the server
knows that you will ask for them anyway
really really well replaces all the
inlining of like initial HTML and
JavaScript really you know
straightforward to implement you do need
to have HTTPS even though the protocol
itself says well you know browser can
use non TLS connection but none of the
browser's actually implement that so you
do have to have a certificate the whole
thing is just when you have a response
stream you push the image where we've
had worse and if a browser makes a
request within like five minutes with
those headers it will match and it will
get it right away if you inspect the
initiator in the dev tools in chrome you
will see what some resources are now
have initiated push so other means not
human but push means the server actually
pushed it to you before you asked for it
I'll give a bad news doesn't work that
well because it doesn't actually play
nicely with your regular browser cache
ok
and the whole reason here is just let me
go for these things is that but service
has no way of knowing but you will have
this resources where is a suggestion or
open capital to send a digest of the
cache what you already have so that the
server will say oh I'm not gonna push it
to you because you already have it and
it's not when I'll start pushing so in
my opinion probably wait a little bit
until this feature gets added otherwise
which is going to kill the performance
by pushing things the browser we have
HCP to was all about performance and
it's changing some of the best practices
if you compare what HP 1hp to the best
practices for the main sharding
concatenated resources and inlining
change you still have to minimize amount
of work like reduce the nslookup so the
top part of performance advice is like
do less work that applies always you
know do good
on the client side but the rest for
example you know split your resources to
domains now doesn't apply right because
you're actually a more efficient having
one connection but can be quality
control and optimize rather than several
connections that all can beat all do TCP
congestion up separately concatenation
is now a problem because what means if
anything changes the whole thing has to
be in a recent with HTTP to use browser
cache and the same connection so the
four main features of HTTP how to know
is that it's multiplexed that means
multiple things go over a single
connection it uses compression
especially for headers that's a big win
you can specify which resources should
actually be sent faster by having
preferences and you have this new
feature resource pools or server port
that can preemptively send things to the
client I have to admit that except for
server push I think people found ways to
abuse all HTTP to features right and
kind of break it but the thing is more
question of the technology is pretty new
the browser and the server stacks and
code has not been hardened yet so did
not do enough validation but I want to
finish with something else and I want to
finish with a protocol called quick and
we need this protocol just because hep-2
has a very very sore point right the
original selection of TCP as underlying
protocol means that if you have a stream
multiple resources and if there is a
packet loss in one particular frame TCP
says no you all have to wait until I
actually send you this packet because
everything has to arise in order okay
so that means for practical purposes
Iver is a packet loss http/2 which is
perfect on paper for perfect conditions
as soon as you hit a couple percent of
packet loss rate actually become slower
because it doesn't open multiple
connection so it cannot actually be
transmitting other things it has to wait
with one frame and then it has to
continue so if the choice of TCP was a
problem because of order of packets well
you have an amateur's UDP and there is a
new protocol called quick and quick is
built on top of UDP and of course you
know or Google who is developing quick
had to build the own TLS equivalent so
quick is almost like speed of a binary
multiplex protocol that became HTTP -
but over UDP and the main thing it tries
to optimize this latency the number of
round trips to actually start sending
the data so quick overview of a timeline
of HTTP to nineteen 120 60 years ago
HTTP point 9 appeared a year later
English Premier League I don't know but
I think it's related HDPE one became
standard eight years later ten years
later speedy became a thing and now it's
duplicated in order to avoid kind of
having two protocols that do the same
thing and as different in features now
have HTTP - but the work on quick has
been going on for the last four years
right so you know the secret is that if
you actually use Google Chrome and you
visit Google properties probably you
know most of the things are transmitted
using quick already and you can kind of
see if you go to you know chrome net -
internals with the quick tab you can eat
if you have enabled I forgot if it's
enabled or not by default but I don't
see I think it's enable already you can
see all the sessions but actually
transmitted is not using HTTP 1 or GP 2
but quick and if you go then to let's
say YouTube you can see what v3 services
are transmitted using quick protocol if
you inspect a resource the response has
a header called out service which says
quick on port 443 well I'll service is
the interesting header it says ok
everything that you asking me it's also
available on this different port so you
kind of say for whole domain I can also
give you the same thing on this
different port so you're not saying only
this resource is available you're saying
the whole thing is available and that's
to make things more efficient so you can
ask them many things at once ok
commenting on time seven minutes
great ok we only looked at HTTP two and
quick but I have to say that one of the
most exciting things is web RTC data
channel so we think of web RTC a Google
hangout no video in a browser but where
is the data channel that you can
communicate and you can ask thing from
the server and the problem is trying to
solve it
let's say you have a server you have a
couple of users everything's going great
more users connect you know the server
slows down you know you put more money
you buy a bigger server but but at some
point it just crashes Rudin borings and
if you watch in a Silicon Valley it
looks like this right it literally
starts burning now I am NOT through what
they were doing and why they couldn't
handle like a million users if we're
just doing video compression I'll be
doing with the compression for every
user but whether it is C data channel
allows you to actually bypass the server
and connect peer-to-peer that means
browser to browser and it looks like
this first user ask for things from a
server but then more users can ask each
other and as more users connect you
actually have more days
available you know thing BitTorrent but
more people actually using the service
but better it is without increasing the
load on the server completely flips you
know financial or architectural
decisions and if the server goes down
not a problem
all the data is distributed and
duplicate and should be accessible we
always think that offline means the
service down no offline means I'm just
asking for data from somewhere else so
people who build whole bunch of
interesting projects using peer-to-peer
alternative to HTTP - ok so we covered
these interesting things and I just want
to quickly recap we're very several
versions of HTTP - protocol and every
version was trying to solve a problem
with real-world users of previous
version and country and most time you
know you didn't know what you would have
a problem when you actually start using
that so HTTP point 9 was just trying to
say I want to load remote HTML documents
people start using where to load the
HTML documents and then quickly found
out all we want to use it for everything
else is so good so HTTP 1 was trying to
solve hey we trying to connect the whole
world together
so let's design a better protocol for
that Ajax was trying to solve a problem
I don't want to load the whole page
every time I need like a kicker update
right can I load data load full page up
reload and then WebSockets came along
and says hey we want to communicate all
the time you want to chat we want
real-time data in a browser and whether
problem that became apparent when Ajax
one polling was not enough and they had
to invent something else serviceworker
today are trying to solve the problem of
caching and offline and saying we need
full control over resources and how
they're going to be cashed and how
they're going to be received by the
browser HTTP 2 is trying to solve a
performance but the world wide web was
not built for web apps right was not
built for a page with weights like three
megabytes and has hundreds of little
things that need to be sent HCP 2 is
trying to solve this problem but wasn't
apparently before
and finally the quic protocol is trying
to find an alternative to problems with
TCP introduced I'm sure with two more
and you someone will invent new protocol
saying hey whatever HCP 2 and quicks
have done here's a problem and I have an
alternative solution and let's make this
into a protocol let's make it into a
standard and I want to finish with this
the only things that don't go through
this process that don't suffer from
defects and the state constant and not
change at all from day one of a failed
things right things that no one else is
using in that case the thing is perfect
thank you so much guys for listening and
I want to thank NDC Oslo and my company
for sending me here and don't forget to
vote if you liked it if not just tell me
in person thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>