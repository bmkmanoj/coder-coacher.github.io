<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Using EEG and Azure Machine Learning to Perform Lie Detection - Jennifer Marsman | Coder Coacher - Coaching Coders</title><meta content="Using EEG and Azure Machine Learning to Perform Lie Detection - Jennifer Marsman - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Using EEG and Azure Machine Learning to Perform Lie Detection - Jennifer Marsman</b></h2><h5 class="post__date">2017-04-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-7WRQFclEA8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello my name is Jennifer Mars Minh and
the crazy contraption you see me wearing
on my head is a headset that reads EEG
and it's made not by Microsoft I work
for Microsoft this is made by a company
called Emotiv it is a female founded
startup woohoo and it's they have
offices in San Francisco and Hong Kong I
believe all right so I've this headset
and what it does is it reads EEG or your
brainwaves and so I took this headset
and I put on my husband and I asked him
a series of questions and first I had
him tell me the truth and then I asked
him to lie to me
and what that gave me is a label data
set of what his brainwaves look like
when he's telling the truth and what
they look like when he's lying and so I
was able to feed that data into machine
learning algorithm and build a
classifier to perform lie detection so
that's what we're going to talk about
today if you do have any questions or
things that don't get answered I am on
various social media I have a blog and
Twitter and a million other things so
I'm pretty pretty easy to find online so
feel free to follow up if there's
anything that doesn't get answered today
all right so let's kind of start with
the basics what is a e/g so essentially
AG is just a non-invasive way of there's
little felt pads that are resting
against my scalp right now and it's a
non-invasive way of measuring that those
electrochemical signals that are running
through your brain and for the official
definition we can turn to of course the
source of all knowledge which is
Wikipedia right so wikipedia has a
little blurb right there that I threw up
there about exactly how these these
signals work what what happens for those
of you who came early and saw me setting
up the way this works are actually um
sixteen different sensors that are
resting against my scalp here and it's a
wet sensor so I did it's a little felt
pad and I actually use saline solution
like same thing I use for my contact
lenses to wet each each of the little
pads individually and then you screw
them all on it's a little bit of a
process
especially when you have hair so it's
really funny every single demo that like
the emotive company has done publicly
they always use a bald guy like always
because bald guys is just easy you just
stick them on in and it works Imbrium
with me it's like this 20 minute long
process of like putting it on and
adjusting chunks of hair around and that
sort of thing to get a good signal
reading so a little bit a little bit
more complicated the last point I want
to make is that I think everyone in this
room probably knows us but just in case
I remember I submitted once to a
conference and I used to call this talk
fun with mind-reading and someone like
it was one of those conferences where
you could see the feedback if your talk
wasn't accepted and so someone wrote
something like this is not mind reading
and I was like yeah actually I know like
the abstract actually said it wasn't it
was it was just a fun title you know but
so let me be really really clear this is
not mind-reading if I were to put this
headset on your head I cannot tell what
you're thinking but what I can do is I
can create mappings between series of
brainwaves EEG and actions and those
could be actions in the physical world
so for example there's some cool stuff
you can do with like using your brain to
like make a drone fly and things like
that and then also their actions in the
in the virtual world so I'm going to
attempt to do that in just a second you
will see and then secondly I can see
patterns in the data or more accurately
I can train a model to see patterns in
the data and then use machine learning
to make predictions based on historical
data so if I have you know if I see a
series of brainwaves that means
indicates that someone has been lying in
the past and see that same pattern again
then that can indicate that oh okay
you're lying to me so those are the
things that that we're going to do here
today so let me just start by showing
you kind of what got me so excited about
this headset so I actually first learned
about this headset way back in ancient
times of 2010
I saw a TED talk by a woman by the name
of Stanley who is the founder of emotive
and if you guys get a chance it's only
like ten minutes long super quick and
it's just an amazing thing I'm going to
show you a tiny excerpt from it on today
but go back and watch the whole thinks
it's really cool but I saw this headset
and I saw some of the power of what it
could do in that TED talk and I was like
I want apps and so I had been just
craving it ever since and then finally
finally got a chance to get one and was
so excited and just a million fun
experiments planned to do with this so
let me but let me show you some of the
things that got me so excited so I'm
going to open on this is a piece of
software that came it's made by a motive
so it came with a headset and it's
called the the control panel so let me
do this so that way you're not seeing
all the background stuff okay so right
now when I first put it on for those of
you who came early and kudos by the way
since this is the first session of the
day the day after the attendee party so
that's always a rough session to get to
so but for those of you got early you
saw me going through the process of
putting the saline solution on the pads
and screwing each one in and getting
everything situated and what this gives
you this little diagram is a heads down
diagram of the of the actual of my head
and this is my nose and my ears and it's
showing that all the sensors are reading
green right now which means we're
getting good signal strength which is
good and so there's a couple of
different things so we're good on that
so let me jump over here and show you
something so this is showing that it's
not only using my my my brain waves but
facial expressions actually get picked
up in EEG so facial movements so if I
blink like this I blink the other eye if
I look one way look the other way is
picking it up I can't see because I'm
looking smiling which is almost thing
you can raise your eyebrows woo so it's
kind of cool that it actually can do
that as well so there is a developer SDK
so you can tap into these are
essentially events that are fired of
movements of the face and so you can
wire things to those events as well
based on expressions
but what I want to show you what I would
what this was the thing that really made
me think oh my gosh I have to have this
device with this particular demo right
here so what I am going to do right now
is I am going to move a cube with my
mind all right I'm going to go all Jean
Grae on you and so the way we do this
isn't even machine learning what this is
doing is just very simple pattern
matching alright so I am going to first
start by training a neutral state so I'm
going to kind of go to my happy place
for eight seconds it takes eight seconds
to train so I'm going to try to be
completely relaxed with a group of
people staring at me for a seconds and
then that will give it a sense for what
my brain looks like at rest because each
person's brain has kind of a unique like
fingerprints they all have their own
signature so like for example my brain
might spike it 24 and my husband's brain
might spike it like three so I'm you
might have to account for these things
when you're doing your various tests so
I'm going to start with that so I'm
going to there's going to be a really
awkward silence but we're all going to
be okay with it and I am going to close
my eyes for the eight seconds because
it's really weird having a much people
staring at you so when the eight seconds
is done will somebody just scream
something out loud that Hays you can
open your eyes now okay so eight seconds
uncomfortable silence here we go
now okay so it's training I'm actually
gonna do it one more time because a
little bit distracted let me show you
one more time
sorry
thank you all right
so yes I'm going to accept that when I
was a little more focus there or a
little bit more relaxed there okay so
now what I'm going to do there's
actually a different series of actions
you can do and I'm going to map this to
the the pull action because that's a
neat visual of the cube coming towards
you so now what I'm going to do is for
eight seconds I'm actually going to
think with my mind pull pull and I and
of course I don't actually have to be
thinking pull I could be thinking
hamster dance or whatever I want to as
long as I consistently think that
thought pattern whenever I want to pull
the cube towards me it should work
alright it's just this is just pattern
matching it's not even machine learning
here so that's what I'm going to do I'm
going to do pole I'm going to think pull
with my mind
for the eight second straight and then
and then we'll see if it works so here
we go training again eight seconds
envisioning pull here we go
okay all right now once I hit yes the
cube is going to be live and then I'm
going to try to essentially duplicate
that thought pattern and then pull the
cube towards me so here we go yes all
right now pull do it again
here we go right right Kyle come on yeah
yeah oh yeah oh yeah all right so pretty
pretty close up so you can see how I did
this I saw I first thought the talk when
they were demonstrating this and I was
like okay I need that because you
haven't really lived until you've moved
to cube with your mind so it's really
exciting so I had all these ideas and
then I am finally after like wanting
this thing for forever I finally got it
and I was just so excited to try these
things and of course get access to all
of this fun data to be able to do some
really fun stuff with machine learning
all right so before we jump into what I
did though let me just show you one more
thing which is this is just a quick
snippet of the TED talk it's a really
short version of it but I just want to
show you one part where they demonstrate
some of the applications and what some
people are actually doing with this
technology so I'd like to show you a few
examples because there are many possible
applications for this new interface in
games and virtual worlds for example
your facial expressions can naturally
and intuitively be used to control an
avatar or a virtual character obviously
you can experience the fantasy of magic
and control the world of your mind and
also colors lighting sound and effects
can dynamically respond to your
emotional state to heighten the
experience that you're having in real
time so moving on to some applications
developed by developers and researchers
around the world with robots and simple
machines for example in this case flying
a toy helicopter simply by thinking lift
your mind the technology can also be
applied to real-world applications in
this example a smart home you know from
the user interface of the control system
to opening curtains or closing curtains
I like how we always do the hand gesture
these are not the droids you're looking
for
you think you always with the hand with
it yes see turning them on you cracks me
up
we're all this one's my favorite and
finally to real life change in
applications such as being able to
control an electric wheelchair in this
example facial expressions are maps to
the movement commands now break right to
your Road
I'm going left turn back bus
of trial videos great
we are merry I'll cut it off there but
um so really cool stuff right like
there's obviously huge potential for
things like gaming just to create a
feedback loop where you could you could
actually have the game be based on the
person's emotional state so imagine like
being able to tell that someone's
starting to get a little bored and make
another zombie jump out you know just
using that kind of real-time feedback
loop based on our person's real emotions
and being able to cater the game to them
it's kind of a neat a neat idea and then
of course the smart home stuff is
interesting as well but the one that
really got me is the case at the end a
paraplegic or someone paralyzed from the
neck down being able to have that
freedom of mobility again by using
facial expressions and the the power of
their thoughts so really really cool you
know life-changing stuff that you know
is there's neat potential here alright
so there's all these amazing like
world-changing type things that we're
talking about then what does Jennifer
choose to use this technology for lie
detection
very very very way to change the world
Denver and so so here's how I got
started with all of this I started
thinking about polygraphs and so if you
if you've done any reading on the topic
there's a lot of critics of the typical
methods of doing polygraphs that a lot
of times that they say that they're
based on this how emotional someone is
rather than whether they're truly
innocent or or guilty or telling the
truth or lying and they do measure
things like you know your your heart
rate your galvanic skin response like
how sweaty you get your breathing like
all of those things and if you've seen
the same kind of cop shows that I have
you'll know that there are ways that you
can you know beat some of these things
because having a high stress rate or
high emotional rate can also be can be
simulated by pain so you can you know
this little trick of like putting a tack
in your shoe or something and you know
when you're telling the truth you step
on the tack so that your emotional stay
is like this and then
you're lying it'll stay high emotional
rate so it looks somewhat consistent on
whether you're telling the truth or
lying or just truly believe in getting
yourself into a mental state where you
really believe the lie and and things
like that so there's there's ways of
beating these and so I started thinking
about so I'm not a neuroscientist by any
I took like one class on like the brain
in college and at the time I things I
remember from that is that when you're
telling the truth that typically
activates the recall centers in your
brain and when you lie that typically
activates the creative centers in your
brain and I started thinking okay if
it's activating these different places
on my brain and I have this headset
that's reading from sixteen different
places then might I be able to tell and
I didn't know if this was going to work
or not I just kind of had an idea and
said okay let me just try this and see
what happens and that's kind of how this
all got started so that I kind of listed
out my goals and my tools in good little
former grad student fashion but so that
the end goal was to see okay can I use
this data to accurately predict if
someone is lying and that my tools all
all listed out there too all right so
here's the actual procedure my my poor
sainted husband Eric I had him sit in a
chair I did have him relax and close his
eyes and I that was for two reasons
number one I actually was sitting next
to him on the first round I think he was
across from me on the second round but I
think he was next to me on the first
round and because I was still keeping
the headset pretty close to the reader
this is actually using not bluetooth but
a similar kind of like proprietary
wireless technology to communicate from
here to here so you can't be too far
away from the machine and so I was just
you know playing it safe then I hadn't
learned all the limits yet and so I sat
and asked him these series of questions
and then I was you know sending markers
as he started talking and and that to
kind of annotate my data cuz I have all
this brainwave data but I wanted to
actually annotate okay here's where I
asked the question here's when he was
answering those sort of things and so
there's a way to annotate
and manually do things I'll actually
show you some of this too and I did ask
him to sit relaxed in the chair for two
different reasons number or have a
dipole force different reasons number
one was that so that he actually
wouldn't make like crazy facial
movements and I'll show you you remember
with the so this is this is the test
bench tool remember how when I was
telling you that it was picking up the
facial movement so I was looking one way
the other way and it was reflecting that
in the data so this is oh I'm sinking
look at my look at all that activity and
so here is where I would look that
correlates to where I say um and I'm
actively searching for a word in my mind
that's interesting
okay sorry um alright so here is a look
at look at all that thinking happening
right there alright so here's a here's
what I'm just laughing so when you here
let me just try to go self-written so if
I close my eyes and I just relax a
little bit you'll see that it goes a
little bit more on Sal or just flat line
yes yes okay boring waves and then
notice if I do this with my face or big
scratching lots of facial movement feel
the noise that puts in my data I'm
trying not to think anything so that way
you'll see just a facial movement hmm
there's so many stupid pictures of me on
Twitter okay so um if it's a facial
movement does actually affect this data
a lot and so first reason I Adam closed
his eyes and relaxed his face and all
that was because I didn't want any
facial movement to mess up my data I was
trying to keep it as clean as possible
for this communal controlled experiment
so I had him keep this you know no
scratching your face no cheating just
keep your eyes closed but face relaxed
and answer the questions was that was
the deal and then the second reason was
since he was sitting right next to me I
didn't want I didn't want him reading
the questions over my shoulder right
because if he was reading questions over
my shoulder then he might actually be
thinking about the answers at at
different times and when I was
annotating the data because I would read
him the question out loud and then hit a
marker in the data so that I could I'm
trying to pinpoint and all of this brain
data here's exactly when he was thinking
about it or at least a smaller region so
I could pull out a
smaller subsets rather than using all of
the data right and so if he was reading
over my shoulder then he would start
thinking early and I wouldn't get that
the right data pulled out so those were
the two reasons all right and this is
the tool I use this is the the test
bench suite that also came with the
Emotiv software so this is another piece
of software they made and it shows the
brain waves from all of these all of
these channels and you can see I can
actually turn channels off if I don't
want to look at all of them I can
deselect some but right now it's reading
from all of these different all the
different channels you can see this went
Orange which means it's not reading
quite as well right now so here's all my
data and so what I did was I was asking
those questions and then as I asked a
question there's this markers that you
can send manually and so I had some
markers here in documents and motive and
take the data to ones I think were a
little better alright so I had a couple
different things that I would ask and
then as I send a marker in here so as
this data is is rolling in from each of
the sensors I can send a like for
example I just asked a question I can
hit a one and send a one and it will it
actually shows you the one here along
the bottom as you're scrolling and it's
when the answered the question I can put
in a two and then grab everything
between one and two for example so it D
be a way of extracting some of the data
from all of that mess so it's a lot of
data all right so that allowed me to
narrow in on the times when his brain
was actually doing the processing all
right the other thing I should say is
that the the sampling rate here you see
is 128
that means it's taking 128 readings per
second which works out to roughly every
eight milliseconds it's taking a reading
so just in case you're wondering wow
look at all this that's kind of cool
alright so here I'm going to turn this
off because I get way too distracted
when looking at my brainwaves all right
so I asked him I was running that test
bench I was sending those markers like
you saw oh actually let me show you the
data that comes out of there too so this
data is actually the data that comes in
here is actually
so it's all stored in a proprietary
format and then that proprietary format
has a convert to CSV essentially so it
goes on disk in one format then you can
run this this command-line tool to
convert it into CSV and look at that so
actually I'll let me just show you yeah
I can go ahead and just show you this
but the arm so basically I asked them a
bunch of yes-or-no questions is the
thing and then here is an example of
some data let me zoom in so you guys can
see this okay all right so this is all
the data that that comes can you guys
read that ok so that uses visible light
great so here's all the data that comes
with test bench and then I added some of
my own columns on the end as well so
first of all there's a counter column
this just counts up to 128 and resets
for the the sampling rate so I ignore
this ignore this here are the actual
interesting columns so this is the data
and kind of note these headings they
have funny names like a f3 f7 f3 I'm
going to show you where those actually
correlate to the places on my brain in
just a second but there's here's all of
our different channels right here of
data so we have all these different
channels coming in and so you can see
the data is mainly in like the four
thousands roughly so we've all this data
coming in from different areas and then
we also have there's a gyroscope here so
there's X Y values I am not currently
using this data but it might be
interesting to play with I've thought
about adding it in just to see what it
would do with it there was any
correlations what I was thinking about
is like the World Series of Poker you
know how sometimes people have their
tells about you know if you you know
there's tilt their head a certain way or
behavior certainly when they're lying so
there may be there may be some
correlation in there but I haven't been
using it yet this is the marker column
this next one so when I do send in those
ones and those twos and such to to slice
out the relevant data
I am the markers will show up here so it
shows zero by default and then
the other numbers that I defined what
they are and then send those in to be
able to slice out relevant chunks of
data those would appear here so then I
would just grab everything between like
a1 and a2 for example and extract that
data out and then I could do some neat
stuff with it the other thing they
provide time values in as two separate
columns so there's a time value second
and a time value in milliseconds right
here and so I actually do some
processing on the back end to convert
that into a single value so it's easier
to do math with it so just take you know
the seconds times 1000 plus the
milliseconds to get the entire value as
one number and then for each of these
you'll see there's also another whole
set of additional data and it's the C Q
underscore those same names and what
that is is the contact quality so you
notice how there were you know the green
those green things I was saying oh great
everything is reading wonderfully
there's actually an enumeration for that
where it's its various colors it shows
up in the UI and then there's numbers
here in the actual data but it's a value
between 0 &amp;amp; 4 for how strong the signal
quality is and so in a read for each
individual one and so that's really nice
for doing your data cleaning when I see
these values coming in if I see you know
a bunch of zeros right here like I threw
all this data out actually when I was
doing my processing because this is when
you first put down the head it doesn't
start reading all of them
instantaneously and so you can see these
are zeros for a bit and then they all
turn to fours after a while okay and
then that's when I actually start my
reading so that's the contact quality
for each of the channels that are
touching my head and then here so that's
where the Emotiv are the stuff that the
Emotiv software the testbench software
provides ends so these three columns at
the end were things that I created first
I needed a label column so this is the
value that I wanted to predict and so in
this case this particular file was user
20s data and it was this was all them
answering truthfully so for the I
created an is truth column and set this
one to one this is my time data
where I just converted it into a single
value in milliseconds rather than having
the seconds in milliseconds as two
separate columns and then finally I have
a user ID so I started this work with my
husband and then I kind of expanded it
after that and started putting the the
hesita and lots of different people and
then trying to extrapolate to be able to
do you know general purpose lie
detection would be the next exciting
challenge all right so that's kind of
what the data looks like and and what
what we have access to now let me jump
back here so so I asked him a series of
questions these are the initial
questions I asked so it's not a I asked
them all multiple times and the reason
for that I actually read in some of the
literature and some of the stuff that
Emotiv said or sent out that it's
actually good to do and and some of the
research I was doing on EEG just reading
things randomly online that EEG is
inherently such noisy data because so
many of things you know from your facial
movement and you know there's a lot of
processing going on in your brain for
other things it's good to take multiple
readings and then take averages across
those just to kind of cleaning to some
of the outliers in the data so I did
that and then I asked a bunch of yes/no
questions again with with eyes closed
relaxed face and so they just answered
yes or no and so I had them tell the
truth and I did another run where they
lie and that sort of thing and so here
are some of the questions that I asked
in the initial set with my husband a Jew
named Erik Mars man were you born 1978
so some some of these are true and some
of these are false so some of them the
correct answer is yes and for some of
them the correct answer is no and I did
that on purpose intentionally in order
to create a nice confusion matrix of of
I wanted there to be you know true/false
yes/no things in each of those quadrants
essentially and so like for example no
we don't have a dog no he doesn't have
red hair
yes he has a PhD yes he's married no we
don't have five children or actually we
don't have five children he might have
five children but if he does then we
have another problem
just beside I kind of just did all these
things that had very very hopeful e very
clear yes or no question answers and
then was able to use that data alright
so that was kind of the the procedure
here is some documentation of that first
fateful run I wanted to have it well
documented so oh cool okay take a
picture so I can maybe put this on my
blog sometime and he's like fine so you
can tell he's really excited to help me
with this research no Jennifer I don't
have an Ashley Madison account leave me
alone I'll decide when we're done honey
all right then the next thing you see is
a sensor quality so I mentioned that
that was in enumeration and there is the
kind of enumeration what they map to and
I grabbed two different screenshots of
what this looks like and actually I was
running last night and I actually had to
use this headset in awhile so like the
sensor pads have gotten really really
dry so I had to dump like most of a
bottle of this on it to get them reading
nicely again but when they haven't when
they when they dry out they tend to go
there they're black essentially they
don't read well at all and then you have
to get them really wet to to work well
but that gives you sense o 0 or the
black is is like almost no signal at all
and then there's green is the strongest
level of signal and then there's kind of
progressive levels of degradation in the
quality of the signal that are available
and as you saw in that excel spreadsheet
all of that data comes through
individually for each one of the nodes
on my head alright now here is a mapping
of what those column names actually
mapped to so you guys saw some crazy
things like the you know a f3 which
actually is this guy right here yeah so
again this is a heads-up display so
you're looking down that thing on top is
my nose and these are my ears so
essentially you're looking at it like
this right is the view that you're
seeing and so the t8 and t7 are the ones
right above my ears these and ones in
the back of the head are the oh one and
O 2 so that's kind of where it where it
all
so it's kind of interesting if you want
to go back and see okay what what part
of your mind is actually lighting up and
there is things you can go back and do
that alright then the next thing is
around so I did do some research because
a lot of times when you have what you
think is a really good idea someone has
done it before right somebody's at least
thought about it and so I wanted to see
you know this doesn't seem like I mean I
thought it was a really cool idea but
it's probably probably not the first
person who thought of it right and so I
went on to do some research to see what
did other people done had anyone done
anything before with EEG and lie
detection and so I found something this
this some research here on something
called the P 300 ERP so ER P stands for
event related potential that's actually
a way of processing EEG in a way that
kind of does some of that like smoothing
out for you essentially but what it does
is it actually measures not so this
works well differently so the P 300 ERP
is a little dip it's actually this dip
that you see right here in this waveform
so this little runt
this deep dip right here is the P 300
ERP and they call it the P 300 because
it occurs roughly 300 milliseconds after
you see a visual stimuli and what the
simulator you see is essentially that
that feeling of recognition okay
so imagine you're walking through NDC
London and you know you're there's all
these faces coming by you and then all
of a sudden you go you have that oh I
know that person from somewhere and
maybe you've seen then matter user group
before or something like that but it's
not someone that you know very well but
you still kind of get that flash of oh
I've seen that face before right
everybody's experience the ceiling right
that's the P 300 ERP so it's it's a it's
a subconscious thing your brain just
does it it's your brain pattern matching
essentially so it gives you that loop
that little dip that you see and so the
way government agencies and such have
been using this data is they've been
experimenting with using that in
conjunction with detecting guilt so the
idea is instead of hooking someone to a
polygraph and asking them yes/no
questions you actually do more of a
visual examination
you can throw up images in front of them
and then see how they respond to the
image does that recognition flash so for
example put up a couple of neutral
images and then maybe you know a picture
of the crime scene you know or the
murder weapon or something like that
and if they have that that flash of
recognition that's something that's a
lot harder to to fool right then a then
a than a polygraph or you can kind of
control your breathing rate and things
like that but that that flash of
recognition is harder to suppress okay
does that kind of make sense all right
and then obviously this is a really
fancy way of saying if the person knows
something that they that only a guilty
person would know then they might be
guilty right they might have some
knowledge that they're not being
completely straightforward with all
right so that is the the p300 erp so
it's interesting interesting stuff all
right
so now let me transition now with some
of my research and the experiment
procedure and such so now let's talk
about you know how I process the data so
I was using Azure machine learning I
work for Microsoft and Azure ml is a
really nice tool for doing almost like
rapid rapid application development of
machine learning tools it's really neat
because there's these 25 different
machine learning algorithms that are
already baked in there and you can just
kind of drag and drop and wire up a
workflow like really really quickly and
you can swap in and out algorithms
really fast and so it's kind of a neat a
neat tool for for doing these things and
there's also if any of you guys are data
scientists there's ways to drag and drop
in modules with Python scripts in them
and are as well so you can take little
chunks of R and little chunks of Python
run them right from within Azure machine
learning you can also use sequel which
is handy I've used that to do like group
bys to compress my data or aggregate my
data so very very very cool stuff very
powerful stuff so it contains all these
modules for importing and doing various
kinds of data cleaning and such and then
you can create experiments train your
models test your models and then really
the the most exciting thing that I know
this is not like sexy at all but the
most exciting thing is
the deployment is just beautiful because
it's literally a button press and then
it exposes kind of your trained model on
a rest end point for you it sets up the
security it gives you an API key so only
people with the API key have you know
can call the model so like all of that
taken care of for you and then you can
just call this model with this API key
and then they give you sample code to do
it it's just really really really
beautiful and simple so very very nice a
very very nice deployment story is
fabulous all right so let me just talk
really briefly about okay so I have this
problem I want to solve how might I do
that and here's one way to do to solve a
supervised learning problem so
supervised learning you would use when
you have historical data and you want to
make predictions about future data and
so the first thing you need to do like
in Azure machine learning when you need
to wire up something that that could
look like this and so the first thing
that we have or is we need to get our
data set in there and there's several
different ways of getting data into
Azure machine learning you can import
data from or you can upload it locally
from if you have data on your machine
like I did you can just upload it as a
new data set or you can stream data from
elsewhere on the internet there's like
an O data feed provider as well as
accessing stuff from from Azure is C
really easy and a lot of other things so
we pull in all this data so in various
ways and then you can apply various data
cleaning modules so there's a whole
bunch of different data cleaning modules
to do things with like data with missing
values how do you want to handle those
doing still Turing and other various
cleanup doing things like getting rid of
the data with bad signal quality right
if you saw those zeros and some of the
contact quality throwing that data out
all those types of things
pulling out splicing out the um
everything between the one and two you
could use a little script to do that so
all kinds of stuff then after your data
was cleaning in a format that was easy
to use you'd want to split your data and
the reason we do this in supervised
machine learning problems is that when
you have this labeled data set you have
a whole bunch of data with like
essentially the right
SURS right like for example let me let
me take it away from EEG and something a
little bit more concrete but I'd like to
give the example of predicting that the
price of a home so you would have a
whole bunch of features of things that
would affect the price of a home and
then how much that house actually cost
right so your features are the things
that would would influence that
prediction could be things like you know
number of bedrooms number of bathrooms
size of the home square footage or
whatever the the number of years since
the Kitchell kitchens been remodeled the
size of the master bathroom because for
some reason people really care about
having a big master bath in the u.s. at
least so very you know various things
that people might care about size of the
yard whatever so a lot of different
features like that and then we have the
the price and so if I said you know for
a house that is you know 3,000 square
feet location might also be relevant to
so maybe in this neighborhood or
something like that the cost of the home
is you know $300,000 let's say if that
were the case and I fed it all that data
and then I wanted to test how well it
did and I said okay tell me how much a
3,000 square-foot home in this
particular area would be of course it's
going to give me the right answer right
because that's the data that I trained
it on so it already knows that right
answer so what we do when we have this
labeled data set is we actually hold
back some of the data so you only train
it with maybe you know 70 75 80 percent
of the data and then you hold back you
know 25 percent ish and then use that to
test the model so that way it's seeing
data that it's never seen before and
then you can compare the output that the
model created with what the actual known
right answer is and you can see how well
it actually did that make sense kind of
explaining that well enough okay so in
this case what we're doing here is we're
splitting the data and in my case for my
experiment I think I did a 70/30 split
so I trained with this EEG data I
trained it on 70 percent of the data so
that means 70% of the data went here is
training data and then with Azure
machine learning you just tell it which
algorithm you want to do and that
basically tells it which type of math do
I want to a
why to find the correlations between
those features and that you know label
that you want to predict okay
so there's different types of math and
they're all good at different things all
right so you tell it which algorithm and
then I then apply that math to figure
out that data and that that trains our
model and then it builds a model based
on that based on those patterns and then
what I do is I take that trained model
that gets set into the score model
module and then I also pass in that that
in my case 30% of data that I held back
and then what score model does is it
actually feeds in the feature so it
feeds in kind of those inputs if you
will and says okay you know for this
trained model what do you think and then
the model produces its answers and then
you compare it against the actual right
answer that you that you already knew
okay that makes sense so that happens
here and then that will give the model a
score for how well the model how
accurate and other various features the
model the model is and then those all
get passed to evaluate module and then
what you can do with evaluate module is
actually do a whole nother model over
here so maybe I build the same thing
over on this side only I use a different
algorithm so let me try this algorithm
versus that algorithm see which one
performs better or maybe on the other
side maybe I've settled on an algorithm
but I'm going to use different initial
parameters to my algorithm because you
actually need to do some some messing
with a lot of the initial parameters to
affect the accuracy of your your
algorithms as well okay so then I can
just keep trying this is a little bit of
the arts of data science it's not all
science because there's a little bit of
let's try this let's try this and so you
you do that and so I try a couple
different things and then you can use
that evaluate model and it'll compare to
against each other to see how they
perform against each other
alright so that's essentially what you
can do or one template to use for
supervised learning I mean as your ml so
the one remaining question so that that
might kind of make sense does that kind
of make sense to folks okay the one
thing that might not make sense is okay
Jane you said that there are these 25
different algorithms in Azure machine
learning if I don't have a machine
learning background how do I know which
algorithm to pick alright so how do I
know which algorithm to
stick right here enter the agile machine
learning
cheat cheat cheat cheat cheat cheat
cheat right okay so this is a wonderful
resource that this lovely data scientist
Brandon on the azure ml team put
together and it is a it's kind of based
on you you start with those large
friendly start node and then first you
kind of break down what problem are you
trying to solve with this and so there
is the problem of if you just have you
want to find structure in your data and
in groups similar things together you
might want to use a clustering algorithm
and so we have a k-means clustering
algorithm which is the most popular type
of clustering algorithm available and
then we also have if you wanted to make
predictions so that supervised learning
that we were talking about there's kind
of two different categories of
predictions you can predict categories
versus values so the difference between
those is if I wanted to predict the
price of a home like I was talking about
before that's a number right that's a
value want to continue them and so for
for numbers like that we are actually
that's what's called a regression
problem and that's handled a little bit
differently because it's they're
actually numbers so you can do things
like you know extrapolate between values
like I might have a in my training set I
may have a you know home that cost your
two hundred thousand dollars in a home
that cost three hundred thousand dollars
and it could extrapolate or figure out
from that that another home might cost
you know two hundred and fifty thousand
dollars even though that value wasn't in
my training set right it can figure out
those values on a continuum and then
there's also the idea of predicting
categories so categories is when the
things that you're trying to predict fit
into distinct buckets right different
buckets different categories so is this
is this person going to develop breast
cancer in the next you know three years
yes or no is who is going to win you
know Michigan or Michigan State who is a
you know am I going to go over or
my sales quota boom boom so and then
does have to be binary either it could
be multiple things which color is this
based on these series of pixels red
yellow or blue those types of things
alright so all of those that's what's
called a classification problem alright
so you can do do it like that and
finally we also something in here called
anomaly detection
so not only detection is really useful
when your data set is highly unbalanced
so think about the problem of like
credit card fraud detection right in in
that particular scenario you have if I'm
you know a large credit card company I
probably have a huge database of
transactions and the majority of them
are hopefully you know valid
transactions but then there is going to
be some small percentage of them that
are fraudulent
but then this probably an even smaller
percentage that is a known fraudulent
transaction so the known fraudulent
transactions versus the entirety of your
data set is going to be very you know
hopefully a very very small percentage
of the entire thing and so when you're
trying to train a data set to predict
between the two of those that's actually
really hard when you only have a you
know a couple examples a relatively
small number of examples of of one side
and then a whole bunch of examples of
the other side if I was trying to
predict valid or fraudulent right and so
an anomaly detection can handle things
like this so it can say okay this is
kind of within the basis of normal and
then this is outside of normal so when
you have a highly unbalanced data set
like that it's great so credit card
fraud detection anomalies in like
pipeline flow of you know here's oil
flowing through pipelines to be
delivered and and if things are off
there if people are siphoning off oil
and gas or things like that those could
detect it those kinds of things a
network hacking intrusion can use
anomaly detection so a lot of cool
things like that you'd use anomaly
detection alright so in my particular
case I was trying to use EEG a bunch of
brainwave data to predict whether or not
my husband knows lying so where would I
go here so I'm on the start thing do I
want to discover structure find unusual
data points predict values or predict
categories
anybody know I know it's really early in
the morning what's that categories ten
points to Gryffindor
yes we are trying to predict categories
and now if I put experience Oh am i
doing three or more am i doing two - yes
I was making a binary I did not ask any
questions like does this dress make me
look fat
where there might actually be an
in-between e type answer so yes there
were two everything was either true or
false so in this case that would take me
to this to class classification and then
it tells you then all of these things
that are kind of where each each
algorithm really shines like for example
support vector machines svms are really
good if you have a lot of features there
are some linear ones and they're great
because they're really fast but they
only work if your data is linear there's
some decision forests and various in
Sambas of decision trees and so here's
kind of where each one is good Booster
Juice trees are great but they have a
large memory footprint those kind of
things so there's a lot of great things
you can kind of look at that and be like
okay let me try a couple different
things I usually start with a linear and
a nonlinear one just to see what
accommodates my my data best so you can
you can mess around with these but then
again it's really easy to swap things in
and out as you try out and experiment
with these alright and if you do want to
download this yourself you can download
a nice copy and like print it out like
hanging in your office and look super
cool
it's akms wack azor azor machine
learning cheat sheet and then i also
have some resources up there i wrote a
blog post on kind of how to get started
with Azure machine learning I actually
wrote it for a student audience so
you'll have to forgive me because it is
like the title of the blog the article
is you know how to win a hack a band
with Azure machine learning because it
was for students but just skip like the
first paragraph and then the rest of it
is really like how to get started with
Azure machine learning and that aka - MS
will act hack them out and then I do
have a video end to end walkthrough of
building and training and deploying a
model in Azure ml and that is using the
Titanic data set so it's all this
demographic information about passengers
on the Titanic
on the ship and then you
that data to predict whether or not they
survived or tragically perish so that is
another kind of good example and it's
like two like 20 minute long video so
it's not that long so feel free to check
any of those out if you'd like more info
okay so let's see let me show you after
I put this in our machine learning I see
so I'm going to show you a very early
prototype that I put together and so
what I did was I followed basically that
that model that you saw before there's
other ways you can do this to UM rather
than the 30 3070 split there's um other
other methods but that's one way they
can work so what I did was follow
something similar to that and then I
here's my evaluate model and what's
really cool about this is gives you a
lot of data around how these two compare
so in this case I think I think I was
using the same data but I was using two
different algorithms I believe this one
was a linear model so I think this was
maybe a logistic regression is this one
and this one was a decision jungle
decision jungles are awesome alright so
if you look at this you can see that
there's a let me actually let me show
you how to read this chart to first so
first of all what this this chart is
measuring is your true positive rate
versus your false positive rate so what
that means is true positives are when we
think it's true and it actually is true
false positives are when we think it's
true and it actually is not true so
that's not good either so basically you
want zero false positives which would
mean I would want this to go all the way
I want this curve to go all the way up
to here and then you want a hundred
percent true positive so digit is so
perfect would be this curve or this line
going all the way up to here and then
hugging all the way across there right
so you want your curve to hug this as
much as possible and you can see this
one and this right here this kind of you
can never see it on a projector but
essentially imagine a gray line kind of
going across the diagonal of this square
that's essentially 5050 random chance
monkey flipping a coin right so if your
curve is not higher than the diagonal
then maybe start over maybe there's
something wrong so in this case if I
look at this this first one this one
seems like it's doing maybe you know 75
percent or something because it's kind
of right in the middle and if you look
at this to accuracy is about 71%
so in whatevs but if I look at this one
so this is my decision jungle right here
this one actually is hugging that curve
pretty well so I again this was early
stuff so this I don't think this was
actually doing what this was doing was
just tallying could I differentiate
between my lying data and my my truth
data and you can see right here that I
do have my my true positives are high we
do want those to be high and your true
negatives are high and you want those to
be high that's good and then false
positives and false negatives are both
low which is good you want those both to
be low and you can see I have an
accuracy of about 93% which is very good
and then the precision numbers and the
recall numbers are fairly high too and
then f1 is actually a combination of
precision and recall and then this a you
see that stands for area under the curve
which is kind of like what you saw there
is about 98% so that's very very high so
that was I was starting to think okay
maybe there's something to this like
maybe I could actually do this thing and
there's actually some great data down
here as well that's bidding of okay let
me let me sort these things into
different bins and they give you
information on that too so a lot of good
data that you can get from here so I saw
that there were some some ideas this was
looking kind of positive that oh my
goodness
93 percent accuracy that's fairly good
so let's so the next thing I did was it
was really funny cuz I just gotten some
of these early results and then
literally the week maybe two weeks two
or two or three weeks later but like
very close after this my team had an off
site so I work on the distributed team
we all live in different areas and so my
you know my my manager actually sits in
like Minneapolis and I sit in Michigan
and there's other people just all spread
out all over the US and so we all get
together once or twice a year for
like you know talk about priorities and
blah blah blah and that sort of thing
and so and then last year when we all
got together for this we actually had a
metric that year where we all had to
deliver like X number of channel nine
videos then watch Channel nine
Microsoft's online free videos cool you
should check them out if you don't watch
them so we had a metric where we all had
to produce you know X number of Channel
nine videos and stuff and so to help us
out like while we were all on site
together
our marketing team actually brought a
camera crew so there was this
professional quality like camera crew
sitting around and so I was like oh I
have an idea so I grabbed my manager and
I grabbed the cameraman and I'm like oh
would it be okay if I ask you some
questions and recorded it just to see
what would happen and he was like sure
like this is for my research that I'm
doing with that EEG thing and he's like
oh yeah what are you doing with that
okay sure let's check it out so this is
what happened first I wanted to get an
accurate sense for my managers data to
be able to calibrate it specifically for
my manager so I did the same thing that
I did to my husband where first I asked
him a series of questions to get a
baseline for what his brain I thought
was the truth so here you go
are you email no
are you a male yes
have you ever worked for labor song yes
okay you guys get the idea right all
right and then I asked him to lie to me
do you have a PhD yes you currently have
a pet yes
no UI yes no no no okay so that's a
bunch of like now what would you guys do
if you had access to your managers
brainwave hahaha here we go
do you believe Microsoft is the best
company in the world to work for yes am
I going to get a promotion to here
yeah so you guys all heard that totally
awkward little giggle right so of course
I was like what does that mean does that
mean that things are going well and he
has some good news that he can't tell me
yet or does that mean that like I
totally suck and he doesn't know like
how to tell me so so of course I did
what any girl would do and immediately
ran back to my hotel room and built a
classifier with his brainwaves so let's
take a look at what happened I also
built a really um ugly Windows 10 app
because I'm not a UI design person yeah
check that out
I stole a control from somewhere and
stuck it in there and yet so I will put
it on github one of these days and then
just like make a plea like somebody
could you redesign this for me and make
it actually look nice but UI has never
been my strong point okay so I'm here
just to refresh you the questions were
do you believe Microsoft is the best
company in the world to work for my
manager said yes and my algorithm that I
built so what I actually did was I went
into Azure machine learning used a
similar model basically took the one
that I dealt for my husband
then rejiggered it with to put just my
managers data in it so his training and
his desk data so that this would be a
model calibrated specific to his my
managers brain and then published it so
tested it trained it you know did a
couple different things to make it um
tuned it and then published it and then
this is so exposed on an end point and
then this Windows 10 app actually called
that endpoint and then gets data back
from it so do you believe Microsoft
that's coming to work for he said yes my
algorithm said is that oh no he has an
iPhone
and he's really into design I'm just
saying we might have a closeted Apple
fanboy okay so then on the next question
the really important one am I going to
get a promotion this year my algorithm
says yes and I am actually delighted to
announce that as of September I did get
the promotion yeah so it was in fact
accurate so very very good stuff I
really go so that's just one example of
calling and machine learning service I
know not you sorry about that
okay shift of five there we go
all right so I have done a bunch of
modification since then you're not going
to read all this so let me just call out
some of the the salient points I've done
the some of the changes I've done since
that first run with my husband and this
early stuff are first of all I put
multiple markers in the data so before I
think I was sending like I'm the very
first one I think I only put one marker
in the data which was after I stopped
asking the question and when he started
answering and then I was grabbing like a
time around that and so I actually
started doing sending one at the
beginning and one at the end to be able
to grab pull out all that data
accurately and then mess with it within
there I started taking neutral brain
state recordings I didn't have a neutral
state when I first ran the experiment
and I think that helps a lot because
remember when I was you know every brain
has their own digital or not digital but
everyone has their own electrochemical
signature and so when you think about
like when when we were training the cube
to move with my mind it actually used
that neutral state to calibrate it
across people so as I'm trying to build
something right now that will work
general-purpose
across all people having that neutral
brain state according will help with uh
with kind of data normalization
essentially I added more questions
because my very first question list was
a very short list so I expanded that out
this is kind of interesting so as I took
data from a bunch of people one of the
things that we thought about was that if
when I first put the headset on you and
you're like answering questions you like
yeah this is crazy lady askew
questions and I'm wearing a brainwave
thing and this is kind of cool but then
after you've been answering questions
for a while it starts to get boring okay
and so the problem was I didn't want if
I was asking everybody truth and then
lie and I didn't want like that
excitement and this is cool all ticket
kind of put into that truth data and
then everybody was starting to check out
by the time they got to lie because then
it might inaccurately start to pick up
on like that emotional state rather than
whether it was truth or lie right so
what I did to account for that was for
some people I asked them to lie first
and then I asked them to tell me the
truth and then for others I asked them
to tell me the truth and then live so
that should cancel out those thatthat
fatigue effect of getting sick of
answering the questions that make sense
yeah okay cool
I asked additional data about the test
subject as well so I was asking things
like someone suggested this and I just
collected the data because I always have
more data there's nothing wrong with too
much data so I was asking about whether
someone was right or left-handed because
you know how whether you're right or
left-handed is supposed to correlate to
the dominant side of your brain so I was
like okay let me just at least collect
that data and I can use it if I want to
so I started gathering a little bit of
additional data about the test subject
and then their age and a few other
things and then I also started mixing
truth and lie in a single session as
well to try to tease out any confounding
variables all right I added more
questions in here so there's a little
bit more questions in here this year
some of the additional data that I'm
collecting the gender the age right or
left-handed here's some of the different
ways that I was doing a feature
extraction so how to figure out what are
the relevant things in that EEG data one
way to do it is unrolling the waveform
where essentially with time series data
you take the first thing and then kind
of this so I have the first set of
measurements and then I took the second
ones and put it right next to it and
next to it and whatever and it works as
long as you can get a consistent like
start point every time but that was kind
of sketchy wavelets is another really
big thing so there was actually an EEG
competition on the Kaggle website which
is this data science competition website
and one of the most
eating variables that the winners found
was these low frequency time domain
signals was actually the most telling
variable and so I was trying some stuff
with that too I also found a PI EEG
library online thank you for is Chang
Bao who who wrote it so I he was
actually extracting interesting
information out of eg signals so I
leveraged that and started pulling some
of the stuff that he had out of there
the other thing I'm talking about is
like a hidden Markov model or looked a
little mini state machine so when you
think about it when when you're actually
going through the process of lying there
so there's a lot of stuff happening in
your brain right like first you're
listening to the question you're
thinking about the answer you're
thinking about whether you want to tell
the truth or lie then you come up with
your answer and then you have to do the
mental activity to actually vocalize
your answer and say it out loud so
there's a bunch of kind of things that
happen in a row it's almost like a
little state machine so if you can kind
of zero in on the most relevant parts of
the state machine that would make it
useful I already talked about comparing
to a neutral brain state using ERP
instead of raw EEG is another thing I've
been kind of playing around with in
samba 'ls is another thing so that's a
technique in machine learning where
essentially you can combine multiple
multiple classifiers together to get an
even more powerful results and then
finally I'm deep learning so I think
this is a problem that essentially
screams for deep learning and the reason
is it's very similar to the idea of
speech recognition right because we all
have our own unique voices our own
unique pitch and timbre and all the
other things that are related to to
voice their vocalization and if you guys
have ensure everybody has seen of you
know a speech you know waveform as
you're talking it's it's it looks like
that if you've done any kind of video
processing you can see that your your
voice signals sound very similar and so
being able to extract you know very
similar people saying the same thing
with different accents and different um
different voices but still see that
that's the same word it's essentially
the same thing as what I'm doing here is
trying to find out truth or lie with
different brain signatures and so I
think and essentially the speech
recognition problem has been solved with
deep learning so
I really I believe deep learning could
see you solve this as well the only
reason I haven't done it yet is I don't
have enough data you need a lot of data
to do deep learning accurately and I
just don't have been doing this was kind
of a side project so I just don't have
the quantity of data yet to make that
truly effective all right next steps
I've been gathering data from a lot of
people to try to do something
general-purpose experimenting like you
saw on the previous slide with a bunch
of different things and then the last
thing this I don't think is actually
that hard to do but I'm having a
real-time feedback loop so you can
actually put it on someone's head and
ask the questions in real time and then
get some responses so very very cool
stuff they're a bunch of thank yous to a
lot of people I kind of was showing this
early work to the Azure machine learning
team and they were all like really
excited about it and a bunch people
offered a bunch of really helpful
suggestions that have made the work even
better so I'm grateful to them and then
finally this headset is so cool like
it's awesome and it's not that expensive
and it's so much fun and I have all
these other ideas of how I want to use
EEG in conjunction with machine learning
to do other cool things Microsoft Azure
machine learning is really really a
powerful tool like you can you can get
started and get up and running and do
some some pretty powerful stuff and it's
just amazing it makes it very simple and
very easy and then finally husbands and
managers beware mind control is next
thank you guys so much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>