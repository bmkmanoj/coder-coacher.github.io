<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Deploying Windows Container based apps using Kubernetes - Ben Hall | Coder Coacher - Coaching Coders</title><meta content="Deploying Windows Container based apps using Kubernetes - Ben Hall - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Deploying Windows Container based apps using Kubernetes - Ben Hall</b></h2><h5 class="post__date">2018-02-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/c8ppFCPLgMU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you very much for attending as I'm
sure some of you are aware Cuban at that
moment is gaining love excitement a lot
of traction within the community and
people are very keen to explore how we
can change the way we're deploying
software and how we can improve and
introduce more resilience and
reliability into our deployments and
this is what I want to focus on today
but in particular how do you do that
when you're deploying existing Windows
applications and working within existing
Windows applications and how does that
look like when we want to use cool new
shiny technology like kubernetes but at
the same time we'll also cover if you're
building garnett core and window
dynacord linux how that works on our
capabilities and fundamentally how can
we get the most out there what will it
bring to our companies if we decide to
adopt him bring it into our stack so my
name is Ben Hall I am I am based here in
London and I'm the founder of a project
or company called cat coda cutter coda
is an interactive learning platform for
software developers so directly in your
browser you get given pre-configured
environments with kubernetes clusters or
openshift or in this case docker and
alongside that you get step-by-step
instructions about how you can solve
particular problems like how do you
deploy kubernetes or how do you deploy
in configure applications running on top
of it and it's all available for free so
after technology after you've heard all
about the awesome technologies I want to
explain you can go and try for free on
Captain coda without having to download
or install anything so are they
introduced I want to start with an
introduction and provide a fun event
fundamental foundations into how do you
build these new Windows containers what
makes them different to Linux
and why am I excited about the
possibilities will then take those
containers and will deploy them onto
kubernetes we'll look at what kubernetes
brings to the party and why everyone
again so excited about the possibilities
it's bringing and because we're dealing
with production and we're dealing with
infrastructure we'll look at actually
what does that look like in reality what
the day-to-day operations that you can
be concerned with and how do you many
things like monitoring and making sure
that your applications are working when
you're deploying into these cloud
based solutions so I'm sure that many of
us have explored and play with darker
and so far but for those who are coming
into the topic fresh containers allow us
to take complex software which can be
off-the-shelf and configured by vendors
or what we've built internally in our
own applications and packaged up and
launched a process docker fundamentally
is a process manager when you start that
container all if they're in if start in
the Linux process or the windows process
or Windows containers and making that
available exactly as if we installed the
package and ran it directly the main
benefit of that is how they keep it for
cure so they use certain features within
the Linux kernel to make sure that the
thumb boxed and separated out and
isolated from other things running on
our machine and that means if something
goes slightly corrupted or malicious or
they actually get accidentally get
hacked into they can't interfere with
the rest of the system they can't take
things down and they can't breach and
intact as a part we it also means is
because we've got these containers they
get packaged up at these docker images
and leave docker images contain
everything with that process or that
application needs in order to be able to
start so in the case of difficult server
we've got the new version a sequel
server where I have been recently ported
over to Linux and as part of that you
will have to seek with server packages
it will also have a base operating
system and all in the files it needs so
example debian or boo to or sent off if
you're interested in more of the Red Hat
side of the wheel community and it has a
configuration by default setting and
everything you need so now if you want
to launch vehicle server on Linux you
would do da cavern this will launch a
container you've had some nice
environment variables because it is
still sequel server after all so we
accept the end-user License Agreement
we've had nice secure passwords open up
the port so we can access it in this
case the default port for sequel server
is 1433 and then the name of the image
and if it's not on our machine already
or go off and download it and winter has
been downloaded it will launch process
and now we have a full version of sequel
server winning
and so this provides us a lot of benefit
and a lot of bandages but it's not just
web processes and databases that are
beneficial and helpful when we're
dealing with containers we can also
verse win day to day development tools
and we convened on for example the usual
command line we can launch that directly
from either container and as a
containerized process and so we don't
have to worry about how do you install
it what positions the Python do you need
and what's a different configuration and
what it interfere or greater are the
things running on my system instead
we've launched out the process we solve
the problem we need to solve we stop it
and it can get completely with me from
our machines without side effects or
without anything left behind and so this
helps have move and change and
experiment with different technologies
are a lot more effectively but for most
of time the real benefit is when we want
to deploy our own applications either
container and we want to deploy what
we're building in a more streamlined
more standardized packaged up way and so
instead of worrying about different
versions of.net being installed in
development teams laptop to stage in a
build agent to production by having
everything packaged up at if duct image
we can streamline that and we can be
confident that what we're building and
testing against it's actually the same
exact version as what would be winning
in production no matter where it's going
whether it be bare metal cloud or hybrid
type solutions and so in this case I'm
going to build a very simple hello world
application as an asp.net core it's
going to be targeting Linux initially
and then we'll look at Windows and put
the application quite simple it returns
the machine name and so in this case
when you launch a container the machine
name of which application thinks it's
going on it's the name of the container
itself and so that when you're raising
error messages if your application does
happen to have an unfortunate event by
tracking the name of the machine helps
you track down to the container which
was actually winning it and I thought
it's a helpful trick for debugging and
so in this case that's what I've been
focusing on the second important part of
a containerized application is the IP
address which and the application is
listening on so by default certain
applications will listen on 170 Ivy
Rhoda what
and so that will only live in free
quests coming in on the local loopback
network card and so this makes sure that
things from the outside can't accidently
access it which is very nice and very
secure very secure but when we're in a
container
obviously the network were not obviously
when we're in a container to the network
interface for the container is not the
local loopback of our host machine it's
a different network interface and so if
it's only accepting requests from the
local interface it's only accepting
requests from within the container
because that everything is Fanbox know
that everything is isolated and so what
we need to do is actually within our
configuration be very explicit and say
like actually please listen to all IP
addresses and requests from all
available network cards and network
interfaces and in this case started in
by binding to zero zero zero dot one and
it allows us to receive network traffic
from other containers and other parts of
the system a very common problem which I
spent many hours debugging about why my
application isn't responding to over
them and that's just because it wasn't
under my IP address so two key things to
be aware of when you're looking at
containerization for apps so now we want
to start taking this application and
turn it into a docker image once we have
this docker image which defines the
structure of the application we can
start it and turn it into a container
which is just a winning process based on
that image and so to do this we need a
docker file a docker file is a list of
instructions which define what our
application needs and how it's been
built so in this case we're defining our
base dependencies we're saying we want
dotnet we want 1.1.1 and we would like
the estate sdk to link and so based on
the naming convention that Mike's often
produce when they produce their base
docker image that is the name which we
need to find and so if they've got done
that I already installed everything
configured and so we can use that and
then be confident that we have all of
the talling we need in order to be able
to successfully build and publish our
binarism dotnet and so in this case our
net we have done that with store which
will pull over the package with him from
NuGet and put them into our container we
copy all of our sauce
load into the directory and then we can
win dotnet publish and build our nice
dealer to critical thing that the bottom
are from metadata about how the
application is functioning and how the
application is configured and so the
first thing we do is say what port the
application is listening on and so when
this image is being win in production
this metadata that exposed can be
interrogated and it can be used so that
people don't need to figure out how the
application is configured but it also
help things like kubernetes understand
the structure of your application it can
use them mint infer that and help it by
automatically configuring different
requirements and then finally at the
bottom we've got the default command I
how do you launch this application and
by having it baked into the image it
means that we can be image we can be
less dependent on the actual underlying
technologies and instead we can focus on
my image higher level abstraction I win
this container and then a container and
the image has all of the information it
needs to work out how to start the
process if we had to be document that on
every single time we launch the
container
we'd have to be very aware about okay
what's the name of the deal ow
what even technology is actually running
inside of that container is it node if
it done there if it golang by having
that all packaged in we just are
confirmed with the abstraction of like
here's my application hit my image
please launch that somewhere and so
these are the techniques when you're
building it and third when you have that
docker file defined they look and feel
consistent between different
applications you turn into an image by
doing docker build give it a nice
friendly name so you can refer back to
it later and docker will run through all
of the steps within your docker file
which was then eventually get you to
your nice built winning application
which is ideal and so now we have
something which we can learn and
something which we can deploy the one
issue is this at the moment is you may
remember my docker file I defined the
SDK as my base layer and so at the
moment when I go to win this in
production I'm actually also winning all
of the SDK tooling which went with it
and this has some potential security
implications ie if anyone broke into my
web app don't be able to compile
that on source code and then be add
compile down our own applications or
utilize additional tooling which may be
left behind like cokeman tour w get and
that's which i use though to exploit it
and we don't want to make it too simple
for attackers we wanted that at least
and make them work for their exploits
and so we can simplify and we can reduce
the size of our images and get them
ready for production and for Dockers
introduce a new concept called multi
stage builds and this is where we can
change and add a secondary stage to
build a more optimized version of that
docker image and so we have our first
stage which is what we had before which
with using the SDK tooling to build DLL
and then as a second stage what we can
do is define a different base image so
in this case the runtime so it doesn't
have all the compilers and didn't have
all of the additional to link we can
copy our DLL which we built youth in the
first stage the first set of images and
use an SDK and into our more optimized
version of the container image and by
doing this we reduce the size we take it
down for nine hundred Meg because
they've got all that compiler an
additional tooling in and we made from
thing much more secure and much more
optimized which is only 250 Meg and we
can continue optimizing and building
that and so it's a really nice way to
get our images ready for production and
ready to deploy on to something like
kubernetes so that's how it works in
Linux so what about Windows and how did
Windows changed matters so as part of
the Windows Server 2016 release there's
four key components which were
introduced we have Windows Server core
and Windows Nano these are operating
systems designed for winning inside of
the container and so we can use this
exactly what we did for linux where we
defined the SDK we can use these as our
base foundation and then build upon and
deploy our applications and we also then
have introduced two new container win x
windows containers and windows hyper-v
containers windows containers are those
similar to what we experienced on linux
today so today share the host kernel but
when you start that process it will
start the windows process and allowing
and it will still learn in a very
sandbox secure way very similar to how
it wins on Linux but like on Linux it
will utilize and share the kernel of the
host and so all of the machines all of
the containers on the machine will all
talk to the same kernel and so if you
did unfortunately have a kernel exploit
potentially it could interact and
interfere with all at the different
other containers this is where we know
the hyper-v containers adds an
additional isolation mold for our
applications and so when we launch in
this hyper-v isolation what happens if
that windows will boot up a very similar
small lightweight virtual machine and it
will win that container within the
virtual machine and so we don't have a
shared kernel issue it's an isolated
standalone kernel wrapped in a VM and so
if anyone did manage to break out did
only hit the VM and then it would have
to break out that but I've already been
locked down and super secure and so it's
an extra defense and an extra barrier
without any performance overhead and but
when we launch these containers and
windows they look and feel very similar
to Linux so we've got our server and
operating system we've got Windows we've
got darker and we can burn things like
sequel server or iOS from the windows
build from the windows packages directly
at a container when we look at hyper-v
other third the difference is that the
kernel is separate it's isolated based
on this super small windows utility VM
and we can see where this is beneficial
of things where you're potentially
running slightly more a third party or
potentially malicious cold so shared
hosting ie if you're sure you probably
don't want people to be using the same
kernel just in case people are out to
purposely target and the other things
and multi-tenancy so if you're willing
to government departments
you probably don't want them to
interfere and interactive to hear from
different governments just for that
added benefit and it's a particular
reasons but fundamentally windows
containers are still secure safe
reliable there are two new operating
systems hello we start with Windows
server core
when the server core is nearly window to
compatible and what I mean by that is
it's got all of the same API if you
would know and love from windows and so
the idea being that you can pick up your
application it doesn't need to be
changed it doesn't need to be real
rebuilt and it will almost run
without any modifications and when I say
almost is there's some API which they
couldn't quite port over there's some
things they haven't moved like the fax
server which to be honest is probably
acceptable but the idea is I albeit the
same experience and you can just
literally take your VM turn it into a
container image and then wind up and v
core Windows Nano is the really
stripped-down really lightweight version
and so this has got to feel a few
different iterations and a few different
processes Windows Nano originally was
meant to be a lightweight virtual
machine that you could boot up on
hyper-v and it would be have a low
footprint and so you could pack it more
effectively and get more value from your
resources but that's contains recently
people weren't utilizing and as we moved
into a containerized willed Windows Nano
is now designed just for thoroughly
winning inside of a container and it
means that they could remove all of the
logic about how do you actually boot the
VM in the first place and now we're not
nano is approximately 50 mega in size
it's a really nice base footprint for
packaging and I'm deploying our
applications onto and so when we look at
where diff means and what it means for
us server core is kind of like your
traditional operating system it's got
all of the API they've got all of the
legacy functionality there and the idea
is that you can lift and shift and
everything will just work as it was very
similar to if you start packaging up
applications as container done and
booting Windows Nano is more aligned
with something like alpine it focus on
being another container it focus on not
having complete 32-bit compatibility but
you know from 90% of the applications
that's probably fine and you can get a
much more effective much more
cut-down version of the win time to
build your applications on but you may
have to do some tweaks and some
modifications or rebuild it
to get the API of compatible we've done
and so now wouldn't we have this we have
the ability to package up and build our
traditional dotnet windows-based
applications as containers so what did
that look like in reality so let's take
a way back into the great early days of
dotnet where the asp.net team were
producing different examples and one of
the examples were the something called
nerd inner nerd dinner in this case if
hosted on complex until complex get
turned off and this particular build was
released in May 25th 2010 so it's like
one of the earliest dotnet examples I
could find and fortunately had been
built and it's been packaged up in a zip
file or the binaries are there but like
how can I now take that package up and
what other changes which would be
required so we need to be able to deploy
and build our windows containers so now
we've got Dakka Dakka works natively on
Windows using some awesome goal and
functionality but the window
functionality is piped into the core of
docker it's not a fork if they'll spin
off if not something driven by Microsoft
it is part of the main docker pipeline
it goes through all the time testing or
theme CI integration points the idea
then is that we have whipped two
binaries multiple binaries
windows arm and linux and so we've
installed it and you can VIN it and
you've got all your container images and
just like what we do with Linux and what
we had with the doughnut SDK those
various different bait images which have
been built which we can use as our
foundations so this is the base images
for Windows and you can see that all of
the tags on the far side are all it of a
Windows build version numbers because
when we have Windows we also have
Windows updates but we can't just have
things randomly updating itself within a
container could that breaks a hole
repeatability and knowing with actually
running inside of production so instead
we've tagged things with the windows
build and so you know exact
what version of Windows we are winning
and what version and security updates
have been applied and so when we do that
we've got images when we try and win
something like in this case windows of
Cour it will get downloaded and when
something gets changed and a need
security patches have been released we
only have to put download and pull the
changes which have been applied as an
additional layer and so we don't have to
keep download any huge images every
single time instead we can keep things a
lot more focused so just like we had
before and just like the food the same
example we now need to build a Windows
based image and so we have our docker
file and now we have our base image so
in this case window server core and on
top of that we can burn windows targeted
commands in this case install feature
web server so I install iis and we use
the same functionality the same fintax
the same approach but now we're building
something which is targeting windows and
using the windows functionality and a
windows kernel to bootstrap it
fortunately for most of us lots of paste
images some iOS is already available
lots of different versions available
something windows have core some for
Windows Nano and we can use and build
upon that in our application so now when
we're trying to build and deploy this
nerd in a simple application what we can
do is just use the official I is a made
form Microsoft we give it the windows
build which would interested in winning
and use that as our foundation so now we
can be confident that iOS has been set
up and configured as we need
same things we install the dependencies
so dotnet frameworks and we can
configure I US and within our container
and so we've removed a default website
we create a new one for our app we tell
it what port to listen on and at the
same time we give it that metadata and
finally copying our binaries and so
fortunately everything had been
pre-built by no dinner so all we need to
do is really configure the fintax and
configure to configure the iOS
infrastructure as part of our deployment
and that's what we're doing here and
then the application will hopefully just
launch so what has we did before we do a
docker build this will win through the
steps
will configure IRAs so when I post a
flan cheese it will launch iOS and
configured state what we desire and then
when we're in it our applications will
display and so by taking an application
which has existed without modifications
because we've got that Windows have
called base image and because I have
compatible to Windows we can just pick
things up and put them into production
and then win for at this point we can
look at optimizing and reducing the
footprint with Windows Nano etc and
kalenna into something much smaller but
at least if is our starting point to
have something winning whether it be
Linux or Windows based images so now we
are getting to the point of how do you
actually win needs and what's required
to win this in production if we're just
doing da cavern on a VM we'd have to
login we'd have to connect when Emily
ran commands on a command line and it
will eventually get to the point where
it becomes unmanageable a mistake will
start to be introduced so what we wanted
v ohms which are designed to manage
these containers for us and if things
happen or automatically adjust and
automatically react to the state of our
system and state of our infrastructure
and for their many different approaches
to orchestration and their swarm from
docker des openshift
there's mezzo stat d cos there's Cloud
Foundry been the most popular one or the
one which had gained traction from the
community is kubernetes so the official
definition of kubernetes and what it is
is an open-source system for automating
scaling the management of containerized
applications ie the things which we have
just built and we need to now push into
production and kubernetes was born from
inside of Google so Google learn all of
their systems as containers they have
done for the last ten years and they
have provided and pushed back a lot of
the core infrastructure and a lot of the
core technologies into the land of
kernel which keeps containers secure and
other things work document building on
in third place and so they have a huge
amount of experience and knowing how to
operate container a systems and so they
have Borg which is Aaron
version of how they do this they publish
a white paper and at the same time they
also started work on kubernetes which
takes their internal experience and
makes it available to the wider audience
and companies who aren't just Google so
this has been awesome and really
captured experience and knowledge and
transferred another effective way not
just through blog posts and technical
talks and the premieres of Cuba nettie
is to take all of our containers no
matter what types of containers they are
or purpose I serving and be able to
organize and manage those in a nice
simplistic consistent approach and to do
that we need those different
functionalities and we need service
different features which is provided by
the base by the base structure and City
though a few things that I've pulled out
which I think are critical when we think
about how do we learn and manage things
in production so we've got aspects like
role based access control so being able
to specify which teams and which people
and individuals can manage which
components of our applications so who
can deploy project a systems or who can
manage a view the state of that and
making sure that per team a can't
interfere and interact with team beat
workloads we also have things like
self-healing so if something happens at
3 a.m. in the morning
we don't want network operators and
infrastructures I have to go in and
manually update a money fix whatever
problem we want if it's better if our
systems can start self-healing and self
fixing and correcting the problems so if
we lose a server or we flew the
datacenter kubernetes will detect that
and it will automatically reprovision
whatever systems and whatever aspects of
our workload what was being deployed on
to other parts of the cluster and so we
don't lose capacity we don't lose
availability and kubernetes is always
making sure that we that the capacity
which we've defined is always available
and so we don't have to go in and
manually intervene we have other things
like being able to manage scaling and
rollout and rollbacks
managing secrets in a secure way
we're not randomly leaving passwords or
certificates just on a disco in an
environment variable somewhere instead
they can be backed by an actual secret
store and finally the one which I think
is often overlooked
if batch execution by default we think
of containers and we think of
deployments are these long lived long
venom processes like we want to deploy
database or a web server or methods
queue but actually there are lots of
different types of workloads which we
have we have one of cron jobs which need
to win at 3m every morning to recycle
something or win a type of report and we
also now assign and see more big data
workloads so being able to go like we
need to be able to process a thousand
different images
classify them and then we turn results
or blood results as part of a report
until kubernetes is designed for
managing scheduling and managing
scheduling an execution of workloads and
that happens whether it's long lived
winning processes which may go down and
have to be recycled or one of jobs which
win for 10 seconds and then disappear
and I never win again so as part of
kubernetes what have actually been
introduced and what been developed is a
really advanced object model which
represents all of the different moving
parts of an infrastructure and a
production based system and so at the
heart of kubernetes are concepts called
pods pods are fundamentally containers
which are winning our workloads and so
they can be docker container there are
different types but they are the
containers around these pods we have
different services so we have things
which are managing the schedules and how
these pods should be executed
so for example a daemon set will
automatically burn the part ie the
container on every single node within
our cluster and so we free a services
such as monitoring that must always were
non everything the hosts so we can
collect ammeter metrics you would deploy
at the daemon sir and then when
kubernetes identified and introduces and
detect a new node being added it will
automatically go ahead and deploy the
monitoring cold
and make sure that it's winning and so
we have deed guaranteed in place and so
that we don't have to go through a
playbook of what needs to happen when we
add a new node into a cluster we think
that things like stateful sets which are
designed for winning databases and
stateful applications and so as we scale
up our database certain things need to
happen
ie they need to point to different
directories because if they all pointed
to the same directory they'll conflict
and they'll fight and veil over wide
data and so when we scale up and we
think about multi-tenancy and multi node
systems we want to make sure that
they're scaling appropriately and then
at the bottom underneath we have
obviously our core foundation so we have
volumes so our container can store data
and it can store in different ways it
could just be a director and disk or it
could be 13 things like secrets or
configuration and kubernetes has objects
which make that easy and make them
manageable from our viewpoint so we can
focus and configure the right objects
based on what problem we're trying to
solve within our system and so when you
look at what gets learn we have these
nodes within our system and then
everything which we want to deploy like
all of our applications be that the nerd
dinner app which we just built will be
deployed as these pods no Laura Vela IP
addresses but within that pod we can add
configure it and we can tweak the actual
implementation details of that so if it
needs to be made up of multiple
different components and multiple
different containers we can package them
together as if they are all winning from
within the container thing interface and
same container itself so they all share
the same IP address they also have the
same volumes they all look and feel as
if they're together but from a
development experience we can break it
down into small isolated components when
we want to scale these pods get scaled
together and so when we want to bring up
a part of allocation application all of
the volumes and all of the containerized
apps within that will get scaled up and
added together
the second important part is not only to
kubernetes need to manage started
applications it needs to make them
available and so cumulative have got
different approaches based on how to
configure on how to manage networking
two three one three two most commonly
commonly used are node port cliff IPAs
and low balances so a mobile node port
is the ability to allocate a hard-coded
port across your entire cluster and for
no matter what machine you are accessing
or data get received on it will always
get routed to the correct pod which may
be on a different part of the system and
so you can always make systems available
as they get moved around cliff to IPS
are an aggregation IP address which
manages low balancing across different
components within our system and so this
gives us a single IP address which we
can send traffic to and an innard covers
that may get distributed to different
components and different systems and for
with i/o reliability and scale it even
out our workloads across different
machines and different nodes and then
finally load balancers which our
concepts which will automatically
configure a low balancer based on the
cloud provider which you are utilizing
so if you deploy a kubernetes into Azure
or ec2 and you requested load balancer
kubernetes will go off to a shore or EC
to get and configure the load balancer
and the alb for example get allocated a
public IP address and then made that
available within a system and so when
traffic at f-- into that public IP
address kubernetes will manage in how
that gets to the underlying pod the
underlying workload that were interested
in and we see from traffic and so I
powered some awesome slides from our
friends over weave works to kind of help
illustrate this in a little bit more of
a colourful way so traffic comes in a
node poor didn't matter which node
within our kubernetes cluster
traffic is received on it will come in
and we'll know which part it was
responsible so it will forward the
packets over the internal network to the
most available pod within our system
which is available
similar to Cliff IP addresses when we
are within our cluster and let's say our
web application odd nerd dinner sample
app needs to talk to sequel server it
will go off to the in the DNS server so
car-like where if equal server winning
and it will return back Wow he's got
three instances of sequel server winning
here is the one IP address let's
represent all of those and it will send
traffic to that and forward it on and
then the traffic will go to our our pod
and then finally the balancers which
other third it will automatically
configure the load balancer via based on
the cloud and when traffic comes in from
that external load balancer it will help
manage and introduce that into our
cluster and all of this is managed and
configured via cold and for this is
awesome beacon now we're no longer
defining bath scripts we're no longer
creating these complex confusing
playbooks
to get our system into a state where we
desire instead we're defining how we
want the objects to be configured and
then they understand what's required in
order to make and deploy our
applications based on what we've defined
so in this case we're configuring a
deployment object we've given it from
knife and a friendly name so that we can
understand it and we're setting a label
so that we know how the parts of the
system can connect and interact and
build upon what's been available and
then finally the spec I either workload
for this deployment object is containers
until we define which container we
actually want to be running within our
system and all parts of kubernetes is
configured via these llamo definitions
and so in this case we've got our
service ie how do we want to make our
friend and our nerd dinner application
available and so in this case we're
using nerd dinner and we're defining
what no no port should be and so
whenever traffic comes in on 30,000 80
it will always get routed to the void
available front end application and it
knows that it's interesting and directly
to front end because at the bottom we
defined our selector I
to find what labels should be used and
identified and send traffic to
automatically so this is for Windows
what about for so for Linux what about
for Windows so we have exactly the same
structure we have the exactly the same
configuration instead of defining our
Linux image which have been built we can
find a Windows based image they look and
feel identical and that is important the
only thing what we need to tell Kuban it
is if we need to give it a hint about
where we want this workload to be
winning and so in this case the workload
needs to win on Windows based systems
and so when we deploy this object and we
want Kuban it is to schedule this
workload what we do is to find a node
selector and we say please select nodes
which have to label operating system
windows and so kubernetes will take that
into consideration and it will only
schedule it on nodes with an a-lister
which have the label windows and i said
today have windows containers and they
can learn our workloads and so we can
have our iOS application working but
before we get to that point we actually
need a cuban it is cristo in the first
place so how do you go about doing that
so there two key components to setting
up and configuring kubernetes so this
one if you need a master and then you
need nodes the master if we spawn slave
for scheduling managing workloads making
sure that the state of our cluster and
state of what being deployed is actually
how we want it to be and so if things go
down it will be the master who will
detect that and I'm reschedule and we
allocate our resources and if we want to
deploy new components and new deployment
objects or update them we go to the
master and we tell it please schedule
this operation to happen and that will
manager all it I hope lifting all of the
workload is doing our notes and so these
nodes I have our container win time they
have all of our network and
configurations and they're actually
other things which do the heavy lifting
and so at the present we have these two
types
windows ok our master cannot only be
Linux so we need to be able to win Linux
systems which would configure them will
win the master but when it comes to
where the executions happening and where
all of our workloads are being done this
is now cross-platform and so we can win
it based on Linux we have Windows we
have arm and as more different
architectures get introduced more
different architectures can be added and
so this is how we can now have a single
kubernetes cluster which is capable of
winning different types of workloads
based on the underlying architecture
whether that be for Linux or whether
that be for Windows and so based on how
it's all being configured they can also
communicate transparently in this hybrid
approach and so we could have no dinner
running on windows containers utilizing
four core which had never been modified
talking to Windows Server Linux winning
unlimited containers on a Linux host all
over the network all on different
machines in our clutter and kubernetes
will manage that workloads and how that
happens but windows had a little extra
thing and it's leaves so windows they
recently introduced a concept of Linux
containers on Windows and so what
Microsoft and docker are building is the
possibility that not only can you win
Windows containers on Linux but you can
also natively burn Linux containers on
windows through the powers of hyper-v
and virtualization and other magic
awesome things that Microsoft are
currently building the experience which
I stole from a screenshot from dr. Khan
is you can win your containers have we
shown I just do doc of in nano server
and out over fire windows but you can
then take a Linux container ie Alpine
and win in exactly the same way and that
windows figure out what is that
responsible for and so now when we look
at how do we manage out with kubernetes
we know that you start to become a
really nice choice for winning all types
of our workloads no matter whether
that's Linux or Windows and so
kubernetes can net we'll be able to
schedule
containers of both types and both
architectures on all of our machines and
so we can start utilizing and
repurposing we know that a lot more of
an effect
of way so this makes a really good
platform and so in order to configure
and build our Cuban Etta's cluster we
need a way to do that and so one way
which I really like is coupe atom koopa
dormant in it will initialize a master
so on your Linux box you would
initialize the master that would go
ahead and it will configure all of the
components set of all of the
certificates that's required and give
you a working master and so then on each
node whether that be Windows or whether
that be Linux you go ahead and you join
the cluster you give it a token for that
only valid nodes can be added into the
Machine and then kubernetes will take
that and start scheduling workloads onto
the two of them and so when we say like
what nodes are in our cluster we see all
the different types of architectures and
all the different types available be
there windows or Linux and then
communities can manage both of those and
this is the dream right this gives us a
finger way of managing different types
of workouts the unfortunate bit is that
Windows is still quite difficult to
manage and still quite difficult to
configure fortunately all of the cloud
providers also realize this and so we
have managed way of deploying and
managing our kubernetes infrastructure
so this is managed kubernetes service
offered by jour through the usual
command line if they create me a cluster
and it will go ahead and initialize you
a cluster you will then go ahead and say
akf kubernetes service get me my
credentials so this will get the
certificates and get all of the
configuration acquired store it locally
and then you can start managing and
going like winning commands like get
nodes because if is your they are very
good at winning two hybrid workloads or
both Windows and Linux machines and so
this will support hybrid and cliffthea
shortly you can do things like what are
the available versions of kubernetes and
because it's a managed service it takes
care of all of the management of keeping
edges and so in this case well Clifford
initialized with one seven one eight is
released in the magic of the ten seconds
before you got initialize
and what you can do is keep Annette sure
we'll manage that upgrade process and so
you specify them we won the Calista to
be upgraded to one to 8 and then
kubernetes and as all worked clever and
collaborate and infrastructure and then
slowly roll out slowly update all of
your agents or without leaving town time
and all without losing availability and
capacity because what happens is it will
go to upgrade one of the agents it will
sir stop the workloads we allocate them
to other agents winning within the
cluster waiting for them to come back up
make sure that no is a workload if
winning on a machine or grade it make it
the version which we desire and then
pull it back into low balancer and then
move on to net agent so agile is a
really good solution for this but as
many of the managed kubernetes services
kubernetes the Google communities engine
to Google created kubernetes or and have
a big influence so it makes sense that
their cloud provider also has a service
and now Amazon have also joined the
party and realized the importance of how
do you earn a managed kubernetes service
all three trial providers are trying to
solve the same pain point which is
letting you focus on your workloads and
defining the workloads that need to
learn and not managing and understanding
the details of how does communities
operate at scale how do you make it
highly available how do you perform
upgrades etc taking all that pain away
so you can focus on what your
applications require and how it needs to
be done there are alternatives and so if
you want a more on-premise solution but
have it in a more managed south service
style of way their different
distributions which build on top of
kubernetes to help manage and make it
simpler the one popular one is open
shift from Red Hat and for this is an
opinionated way of how kubernetes should
work and so out the parks it's got
things like user authentication
configured it's got all of your build
pipelines and Jenkins integrated it's
got registries it's got all of the
moving components and it's also got a
very pretty beautiful dust ball
and with some nice animations so that
when you need to scale up you click the
hour up and they were automatically spin
up pods and they will get a nice
animation it's very important when
you're under intense low to have some
nice effects going on but the purpose is
like remove the actual day-to-day
operation pain of what it takes to win
communities and so again you can focus
on your applications and take some of
the opinions that's required away and so
when we have to manage it
everything gets managed in the same way
whether you're winning our managed cloud
service whether you win in the open
shift or use on bare metal and built it
from scratch and so if you want to do
things like make our donor app whether
it be on Windows or Linux do the matter
anymore it's always a consistent
experience and so if we want to make it
available to the outside world we can
request a load balancer Kuban entities
will figure out what cloud were in go
off to the service get our public IP
address and then the external IP address
will fit their polling and waiting until
it's being assigned and then once bits
been assigned we can get the IP address
from get service I lifted all the
services available and then traffic to
and that will be managed and sent the
appropriate request to the services
available in this case we only have one
replicas we only have one instance of
our workloads happenings and so
everything will time within and request
it will always go to that one available
pot but kubernetes manages all of our
instructors who no manager is how we can
scale up and how we can define an add
more replicas so we can use scale we can
find fie black whip occurs and tell it
what deployment we want to scale and so
although that configuration will be
brought up based on our definition and
so now we have our two additional pods
being configured and because of how
cumulative is configured it will also
automatically automatically
automatically automatically okay our
load balancer and so when we've now
attend requests it will send it and
round-robin it to all of our available
replicas are available pods within our
cluster if one of them happens to crash
unfortunately then kubernetes will
detect that automatically remove it from
the load balancer and so in everything's
bad traffic valid traffic to a down part
of the 50 and so we ensure much higher
reliability and with higher availability
because cumulative is automatically
configuring everything based on what our
cluster is trying to achieve and at the
fame of when we roll out updates to when
we want to deploy a new version
kubernetes is there to support how that
actually should operate so in this case
we fit in the image I the target what
we're deploying to a new version and
kubernetes will roll out progressively
and so instead of taking down all of the
available instances all at once and so
our application becomes unresponsive
instead it would do it one at a time and
so by default with the round-robin
approach doing requests will slowly
upgrade and they will start with one
move on update it and then move it onto
the next one because doing things like
Fett image field a little bit manual
again and that's probably not where we
want to be what we can also do is just
modify that object definition which we
created in Yammer and then we can do a
reapply kubernetes will look and
understand the differences between what
is the current state of our
configuration compared to the desired
state which we just said apply and all
change and update the differences on our
state to reflect that so in this case it
would update the image and then it
performed a rolling update our system
and by having it as if yeah more
definition another yam file we can start
building automation and so we can have
things like our just finishing the
object definitions stored in force
control and then when we do a purse then
that will kick off our build and then
that will roll out and that will trigger
filter so Alexis from weave is doing a
talk on this concept tomorrow called get
ops about how you can combine something
like kubernetes and get together to
create your automation foundation and
automating pipeline so what about
private web straight ie if we've got our
source code we don't want it to be
hosted publicly and
to everyone we want to make sure that
loud to private and kept in and this is
where kubernetes have got powerful
secrets management for storing things
like passwords and secure sensitive
information and so in this case we'll
just use an command line to define it
but of ways to do that with object
definitions but the idea being that our
infrastructure team and operations can
configure it out in advance when it
comes to the purposes of using those
secrets and using that information for
deployment purposes we just need to
define what key and what credentials to
use in order to be able to access that
image and so now we don't have to have
shared passwords or password management
solutions instead we just need to manage
what credentials were targeting and what
credentials we need to use in order to
have able to achieve it when it comes to
storage we want to be able to store say
stateful information until we can do
that by when we define in our claim with
like when we define in our llamo
definitions were and our deployment
approach we can define volumes and so in
this case we define an arm over thankful
set but the idea being that every
deployment within our solution has the
required volume attached to it and so in
this case every single time with scale
up and every single time we add a new
replica to an instance it will have a
unique volume attached to it if we
wanted these could be shared but in this
case and we have that control and our
flexibility or being defined based on
this object definition structure but
when we're running things like databases
and storage there's actually more
concerns and have more human
intervention required to perform fit in
operations
ie if we're learning elastic thirds and
one part of the cluster goes down we
can't just bring it back in and if my
sequel master goes down we've started it
necessary could have some adverse
effects and a certain human based
operations that need to happen to bring
our system back up into an operational
State and so this is where our concept
of kubernetes operators have been
introduced and the aim is how can we
take what normally would have been done
by system engineers and
suckster teams when certain things
happen like all grades need to be
performed or something's gone down and
create a codified automated way of
managing it so in this case we've got XE
d which is a distributed datastore and
in order for certain things to happen
there's I'm different states so as an
event loop the operator is looking at
the current state of the system and
deciding what actions need to be
performed so in this case it's observed
that there are too many nodes and
they're winning as different versions
which is unfortunate what we want and
what I decide configuration it is they
should all be willing one not 3.1 and
there should actually be three nodes
within our cluster to ensure that we are
as a call and so the operator knows how
to get to that desired state because it
knows how to configure and deploy our
system and so need know that it needs to
restart and recover one member it knows
how to do that recovery operation it
also knows how to do an upgrade but more
importantly it knows because this is
what human would do that actually to do
an upgrade we should also probably take
a backup beforehand just in case
anything does go wrong and it is
automating codified within our solution
and so these operators define this
knowledge and experience and so they get
deployed I have a llamo definition until
face it there what's in the state of our
closer as part of the cluster the most
important thing is that when it comes to
people within our teams who want to be
able to deploy my sequel or pull scares
or sequel server in a reliable
consistent fashion
they can use that object definition from
kubernetes they can take the extension
point created by the operator in this
case the xcd cluster and just have to
define the parameters which is unique
for that team so in this case how many
nodes do you need and what this is
version should be when it comes to
scaling up we would increase the thighs
weird reapply and redeploy the subject
definition to the kubernetes cluster and
then the operator would step in and
figure out how did it go farm where we
are today to where our desired state is
all through this really nice consistent
experience from a development point
so the final part which I want to cover
is like what should we monitor now so
we've got all of our star netcode
winning and kuba name T's is making that
consistent it doesn't matter whether
it's Linux or Windows
the only thing what we need to specify
if what no do we actually want that
workload winning on and we do that via
notes later kubernetes is managing how
do we make services available how do we
deploy and scale apart different
components no matter what type of
architecture but from a developer and
infrastructure team how do we now
monitor what the state of that is so we
can start raising alerts and so
kubernetes again have got some really
nice extension points to make that easy
and so when we're defining our services
ie how our applications are available to
other things within the system we can
define additional information additional
metadata that other services can use and
build upon so in this case annotations
and we can find an annotation that
Prometheus a monitoring solution should
go off to this service and collect all
of the metrics and so we added a tag
saying that when you'll do in your
scraping of course our cursor please
include this service in this application
and so within our dashboard it would
automatically detect that as we deploy
it and then it will automatically update
the configuration and the covers and
include it within its scraping and so
what Prometheus does is it goes off to
all of the different endpoints whether
they're part of your application which
you can customize and expose your own
metrics or after shelf exporters which
automatically publish data based on your
CPU usage or dispatch usage right your
underline node information or dari
targeted things like might equal
operations so what are the number of
deadlocks within your system or the
number of transactions which are active
which are very targeted to that
particular problem
Prometheus didn't care for me if you
just ease this key value
endpoint and it will go off it will
scrape them data and make it available
for querying and so we can then start
building up our nice pretty graphs so in
this case
CPU usage and CPU nodes but we can build
them - not prettier by interests rethink
levana
and so this will take the Prometheus
data source our than input and then you
can build dashboards and neither can
then be awesomely projected onto display
monitors and when things happen they'll
be alerted what we also have in Gravano
is the ability to wave alerts based on
the data collected and so if we things
going slowly in the in expected ways we
can get go finer to raise personal to
patient's or slack messages or emails or
page duties based on this data
because we've got kubernetes underlying
this when new things get deployed and
new things get added into our cluster
that will automatically start being
introduced into our monitoring solution
and so we don't have to manually
intervene and many go and reconfigure
something instead the state of the
cluster defining what that should be so
what should we be doing and so I wear
this or heading and what is the future
of infrastructure and containerization
technologies so we have Linux we have
Windows there now consistent it didn't
really matter where we're deploying our
infrastructure because kubernetes see
they're the same thing we also have alt
devices and arm and so there's a really
cool company called resin and Neve have
the capability of having the docker
approach to docker workflow but
targeting IOT devices so when we want to
package up and deploy our applications
onto it we can deploy it directly onto
our own device I'm sure you would have
kind of thought on the agenda
you've got Scott Hanselman and you had
Alex talk about winning kubernetes on
arm it's exactly the same thing we've
been talking about today for Windows and
Linux it's just another extension point
and you just another selector that you
make available and for those watching
online there's video of downside I'm
sure we have sequel server on containers
so now when we're thinking about how do
we deploy sequel server we don't have to
worry about going through the 20
different screens in order to bear to
get it to run that's all been doing and
a default configuration that we can
build upon and we can share that
configuration between all of our teams
and make it available but why can we do
that for development time experiences -
like we've already got the is your
command line running at the container
so we don't need to install there so how
long is it until we have seen flies
digital studio we're known as a
container I'll add develop machine
machine silhouette we don't need to
install it we won't have to download
five gig installation to spend two hours
installing it in a hope that it hasn't
corrupted anything else in our system
instead it can be packaged up and I'd
entered using container technologies
both on Linux now on Windows and we've
already started to see this trend the
next version of the clips it's going to
be web-based ie the future ID from the
team it's gonna be web-based and in
order to deploy overnight you were in it
out of containers container that
identified everything like it needs to
do and knows how to install it how to
get it configured and we can instantly
get something working and when we don't
want anymore we just stop the container
remove it from my system and it's gone
forget we know nothing left behind and
this third kalina's to point where
everything is been a container all of
our workloads both long running our big
data our development teams are all
packaged up of containers and because
we're building need consistent
experiences they can be deployed
anywhere and in with the case of Windows
they literally convert different types
of workload for different architectures
all on the same operating system which
is fantastic and something which we've
going to make lives a lot simpler terms
of managing infrastructure so to play
around with this we have cat coda so you
can explore different approaches to
building containers managing kubernetes
and all of the other underlying things
like how do you expose services in terms
of the talks I mentioned Alexis tomorrow
I'm just before lunch which I highly
recommend and I think it's gonna be
awesome
he's the founder of weave and also the
chairman for the Technical Committee of
the cloud native foundation I people who
look after the kubernetes vision so it
should be a really interesting
discussion and also we have pub comp for
those please go see Todd and track Jes
for more interest information it can be
an awesome party so finally what have we
discussed so we looked at how can we
build and manage them ruin containers
like what does it take to build a
Windows container and how is that
different from building a Linux based
system that we may
have experience of we then explore
kubernetes like what does kubernetes
bring to the party and how did it look
and what other benefits like why having
it Orchestrator managing our
infrastructure how did that look from
operation viewpoint and what benefit to
the bring by having that abstraction and
then finally a quick look towards the
future like can we have all of our
workloads seamlessly winning across
different systems all being managed by
the single view control a single view
point of our control plane and our
single source of truth which is keeping
edges so I hope you found something
valuable I hope you enjoyed it if you
want more information please feel free
to or a tweet or email me and with that
thank you very much I hope you enjoyed
the method of conference</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>