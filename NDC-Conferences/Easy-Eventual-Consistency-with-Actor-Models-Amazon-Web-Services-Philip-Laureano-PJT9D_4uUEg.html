<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Easy Eventual Consistency with Actor Models + Amazon Web Services - Philip Laureano | Coder Coacher - Coaching Coders</title><meta content="Easy Eventual Consistency with Actor Models + Amazon Web Services - Philip Laureano - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Easy Eventual Consistency with Actor Models + Amazon Web Services - Philip Laureano</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/PJT9D_4uUEg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right good afternoon everybody
welcome to the last session of the day
thanks to thanks for coming to my talk
so today I just before I get started I
just want to dispel any rumors that I'm
any kind of distributed systems expert
I'm not what I'm going to tell you today
is more of a story about how we did a
cadet net into production and how many
times we failed as well as how we failed
ourselves into actually making two or
three million more dollars than we did
when we didn't actually have a connect
so and all the stuff is in retrospect so
forgive me if there's a few little
detail that I might have missed so let's
start from the beginning so I am
actually from Australia forgive the
American accent and I work for a company
called domain and domain is responsible
for both commercial and residential
property on their website so that's
everything from renting from buying and
selling anything to do with real estate
so one of the problems that we had when
we first did this is that domain had a
massive problem with clickstream rental
in exit does anybody know it could
stream analytics is well yeah there's
like one person but if you don't know
what clickstream analytics is it's it's
like google analytics we want to know
what our users are actually doing on our
website so when you whenever you go on a
site like eBay or you click on something
or you send an inquiry that says hey I'm
interested in this product eBay actually
tracks what you do in the same way
Google does for us we had a system that
did this but it didn't really quite
scale to what we wanted it to do in fact
it was losing messages and it was making
us look very very bad because there's no
way we could track
or not it was doing what it was supposed
to do the setup was art I mean it was
modern for 2005 the problem was it was
getting along in the tooth because we
had a system that was basically running
on sequel server our scale was back in
2005 2007 if we didn't have that many
users though but when you fast forward
to today when we have several million
users hitting the site and with quick
streaming events one of the things that
we use it for is the ability to track
whether or not the features that we push
into production are effective or not our
product team also uses the metrics to
determine whether the things we feature
flag are things that we should keep so
for example we feature flag things of 20
30 40 % if we find that the metrics are
very low we wrap it down and if things
get better we wrap it up unfortunately
with this kind of system it wasn't
scaling because we had sequel server we
had reporting services it didn't really
do much at this point and it wasn't
reliable there's quite a few things that
we needed to solve so the first thing
that we needed to fix is that we have a
system that kept going down it there are
times where this is there's quite a few
outages at the same time in terms of
traceability if you did 100 clicks or we
had a thousand clicks on the website
there's no way to actually reverse
engineer or audit it and figure out
whether or not these numbers actually
add up to that at the same time speed
with a massive problem because we'd have
something that would take an entire day
to calculate especially when we had
hundreds of thousands of users per week
hitting our site at any given time the
last one is really around accuracy and
the problem there is that without that
kind of granularity that we would expect
by capturing all the events we basically
didn't have much to work with
obviously scaling was a big issue
because when we were using sequel server
we were relying on one server to do all
the aggregations and as I said it would
been flying like 10 years ago but when
our traffic doubles are even triples
being able to calculate this as fast as
it comes in is all but impossible
so that's for it a little bit too two or
three years ago when we moved into
Amazon Web Services we had all of a
sudden a brand new set of two we had a
whole bunch of toys to play with because
now we can have infrastructure on the
cheap it was easy for us to add new
servers but the problem was we didn't we
didn't know what to do with it at the
time so at the same time we started
playing around with actor systems like a
canet now for domain we are primarily a
node and a dotnet shop so we went with a
canet of course if you're you have
preferences for other systems we could
go with Orleans or the JVM akka but what
I'm going to talk about today is not
really specific to just a canet it's
going to cover a lot of the high-level
concepts and you should be able to apply
it to any actor system maybe except
Orleans because they don't have these
state machines unless you make it in now
the idea that we came up with is quite
simple so previously we had a job that
would take several hours to process an
entire days worth of quick stream events
but what if we had some way to cut the
jobs down into 86,400 jobs a day that
would take
one second or basically the equivalent
of one job per second for the entire day
and that's where Apple was born I mean
we thought Hayley we'd solved our
problem because now we've got all this
these actor systems that can do all
these parallel computations and and
everything would be okay but the truth
was we were wrong we were wrong because
we didn't actually consider how do you
deal with state how do you deal with
capture and how do you deal with
consistency how do you make sure that
you don't run into any inconsistencies
especially when we're in a business
where we need to be able to sell online
ad space by saying that we get this much
traffic so it was a challenge for us
because when we first presented this to
the management they said well we're
quite happy with just getting a reports
once per day but the way we sold it was
we have a competitive advantage over
everybody else because when we publish
articles on our website we can tell
immediately whether or not it has enough
effect on a particular property whereas
a batch system you'd have to wait until
the next day and all you have is
probably like one spike in a bar graph
we could break it down by hour and that
was a huge advantage for us because we
can do all these things in real time
that you can't do if you just went with
sequel server and super server reporting
services but before I get into the
details of how we actually did it I want
to talk a little bit about theory I'm
sure everybody is familiar with with
strong eventual consistency but just
from sake of completeness I'm going to
go over it so the idea behind strong
eventual consistency is that you have
more than one set of nodes they'll get
eventually get the same set of updates
so you can guarantee that they all get
them at the same time but with strong
eventual consistency
ideas is that it doesn't matter what
order you get them as long as we get all
the pieces then everything's going to be
okay and they'll both come to the same
conclusion now for eventual consistency
or what I like to call weak consistency
that's a bit more tricky because you
have to make sure that the pieces of the
puzzle all come in the same order
otherwise you might get some strange
side effects for example if you're
editing a document and you've got two
people editing the same doc if the order
of somebody typing something is
different from the other person then
you're going to have a lot of
inconsistencies fortunately for us we
didn't really run into this scenario and
I'll get to that in a second now I tried
to explain this to one of my junior devs
once and the best way I could just
describe it is the XP analogy so being
in Scandinavia I don't have to ask you
guys how many times you've been to Ikea
but the idea is that I should take two
people who don't know each other at all
probably won't even talk to each other
as long as they have all the pieces they
have they need to assemble the same
piece of furniture and the same
instructions to do it no matter most of
the time as long as they have all the
pieces in long they have the same set of
instructions they'll be able to come up
with the same conclusion independently
of each other and our system was built
on this simple principle when we have
that kind of scenario where we have a
consistent algorithm and we can
guarantee that all the pieces make it to
all the nodes then all of a sudden it
simplifies things the other thing I'll
get into later is that our system is
immutable so you don't have to worry
about syncing deletes and hindsight what
we didn't realize at the time is that we
were implementing something called
conflict-free replicated data types now
it's just a fancy way of saying if you
follow these sets of rules you will
always be consistent now there's some
talks out there that have said that see
our DTS are just
types but what we found in practice with
stuff in the cloud is that it doesn't
necessarily have to be like a code data
type it's more of a pattern that you can
implement now as far as cap goes in the
previous scenarios what we were doing
was we were running with a sequel server
where we had strong immediate
consistency the problem with that is
that we didn't need that we were willing
to trade that strong immediate
consistency for the ability to scale up
and have these computations done in
parallel unfortunately you can't really
do that with sequel server without
having them maintain the nasty store
proc which is what a lot of our des were
doing and that wasn't really helping us
as you can see here with the cap theorem
if you're not familiar with cap theorem
it basically says that you could choose
partitioning availability or consistency
but that dot right in the middle here is
impossible you can never have it all at
once so what was more important to us
than just consistency was this idea that
we can have partitions that would have
copies of the data and as long as you
had enough copies of the data in those
partitions we can guarantee that we
still are consistent provided that the
consistency lies in the algorithms that
we're actually pushing out now for CR
DTS they sidestep the cap theorem and it
sounds like magic but once we'll get
into this you'll see that there's
nothing magical about it so as I
mentioned before each CR DT has the same
merge operation and the difference
between your TR DT and stuff that you've
normally worked with in a relational
database is that duplication is a good
thing the reason why duplication is a
good thing is because there's certain
operations that you could pull off in a
CR DT that eliminate those duplicates
the other reason why it's sidesteps of
the caps
is that since you have copies of all the
data on every single one of the nodes
and you have duplication it basically
makes the data available everywhere or
pretty close to everywhere depending on
your level of duplication
now the Opera there's only three
operations for a CREP so first one is
querying it's getting the steak that's
pretty much you could make it an API if
you really wanted to or you could just
get a copy of it in our case the update
doesn't really apply to us because we
have n source everything and we make no
deletes so effectively here there's no
update so that cuts it down to two the
most important part that we have is the
merge operation and for Co DTS there's a
few set of rules that you have to follow
in order to have a effective merge
operation that you never have to worry
about conflicts with so the first thing
that it has to do is has to be
commutative so changing the order
doesn't really change the result you can
do it in any order you want associative
you could group the data in any order
everything will still remain the same
idempotent I can run it a thousand times
and I still get the same result now
here's something for the audience so
let's say I have node 1 and node 2 and
they've got two sets of data now
obviously in real world you probably
have something more complex than numbers
but for now let's just assume that you
needed to merge these two sets of data
which operator do you think would
satisfy all the stuff here
now it took us a while to figure this
out though but it was so simple that
when we figured it out it was yeah I I
don't understand why didn't we think of
it at the time it turns out that Union
is really all you need so when I have
two sets of data and I want to make sure
that I get consistency between two nodes
and I have no deletes and it's just
immutable all I need to do is do a union
and it eliminates all the duplicates it
also makes sure that all the unique
components are there and I could do what
I need to do with it so when we look at
Union if we go through the list I could
say that Union is commutative yes
changing the order doesn't do the result
change the result associative grouping
doesn't matter idempotent doesn't matter
either because you could run it a dozen
times
let's see sharp chord looks like this I
know this looks really really simple
obviously this is not production code
but conceptually this is it and I've got
one half set a one in the second one and
the complexity in merging these two is
just that one method call that's it the
other thing that I have to stress is
that everything is immutable at least
within what we did the reason why we
chose immutability in this case is that
in other CR DTS you have to keep track
of what you've deleted and try to sync
that up
they call it tombstoning we didn't want
to have to deal with that and at the
same time we wanted to do something a
bit more reasonable and collect all the
events within say 90 days and then once
it gets past that 90 day horizon we just
kill off all the events that we've
selected for that one day and for all
the listings that we listing events that
we collected on that one day
now one that I've gone over the theory
you're probably wondering how do we
actually store this stuff because if
we're not believing anything then that's
a lot of space that we're going to be
taking up so what we've just what we did
was we've we've used two different types
of backing stores so you notice that
I've actually copied and pasted these
slide from the previous one it looks
exactly the same the idea here is that
let's call node one elasticsearch no two
is s three the point here is that it
could be any data source and as long as
you follow these rules you get the same
level of consistency that you would
expect it's almost like magic but it's
not the next question you might ask is
what do you do in this case because this
is just numbers I mean you can't most of
our data is going to be plain old C
sharp or plain old Java objects so it
doesn't really make sense just to reduce
things down to a number or does it
because it turns out that there's a way
you could actually make sure that you've
got a unique hash set for every single
piece of data that you have now don't
mind the sha-1 because I do realize that
there was a security breach quite a few
months back but the important thing here
is that this is a sample extreme event
now what we've done is we take the sha-1
hash or any hash code with a sizable key
space so that we don't get collisions
and what we do is convert it into a
single hash string so that effectively
when we do that kind of merging it's
just like working with very very large
strings or int and it works out really
really well
the other thing that we're doing is that
this is a logical representation of our
click stream pipeline obviously it's not
the scale but what we do is that when we
have click stream events that come in
here it goes
straight to the web server the web
server posts the events to ahmed ahmed
ahmed ahmed processes it and send the
copy of the quick stream event to s3 as
well as elasticsearch you might also
notice that there's a reconciliation
process and that's part of the unioning
but this is at a much larger scale
what's important here is that in this
flow of events we have multiple actor
systems working inside of AWS to make
sure that everything is consistent and
they're always running almost in real
time so for us I know real-time is a
relative term but when it comes to
property agents they always think in
terms of days so when we tell them
something is less than 30 seconds they
think it's the most amazing thing ever
and to some extent it is now if you're
not familiar with actor systems app an
actor system is a collection of actors
and an an actor is essentially a
degenerate thread with oh no it's a
single threaded process inside of an
actor system that is guaranteed never to
have any kind of locks or conflicts with
global or mutable data at all and the
reason behind that is that the messages
that are sent to every single actor are
immutable you can't change it the built
in such a way that they context switch
between actors and you could treat every
single actor as a single threaded
process we don't have to worry about
anything
the interesting part about all this
stuff is all the systems that we were
able to put together as a result of
working and failing many many times over
I remember trying to do persistence and
Postgres and trying to get prosperous as
to do the calculations
it took us
a good one week because no matter how
many instances we would add to that
server what would happen is that the
computation or real-time computation was
the bottleneck so what we did was we
started Fanning this out to
elasticsearch because elasticsearch has
this unique ability to keep adding more
and more servers the harder we hit it at
the same time we came up with quite a
few patterns that make a lot of sense so
that we get the resiliency that we need
so you don't really see any outages the
other obvious use that we have is
aggregation so in our case it's just the
summer account but what we've learned
from that is that it's not as simple as
it sounds given the amount of traffic
that we get and if we've got a thousand
messages coming in per second how do you
guarantee that there's only a two lesson
10 second lag between the point somebody
does something and then the report and
the numbers are updated the most
interesting thing that we came up with
at least in terms of the circuit
breaking is is the ability for an actor
system to detect if certain things are
have gone offline so what we would do is
if we had two parallel server ATIS one
was a backup we would put an actor
system in front of it and if we detected
that if anything went down with any one
of those two api's it would smoothly cut
over and prevent any kind of outage so
one of the things that was as you can
see here typically we're working on the
scale of anywhere from 10 to 20 ec2
instances with multiple actor systems
per box the interesting part about this
is that when you when you go through the
aqua dotnet Docs they talk a lot about
clustered but we didn't actually use
cluster we didn't even use echo dot
remoting
the reason why is that we had a
continuous deployment infrastructure so
we were running octopus deploy and when
we deployed these actor systems to one
box they acted as a single actor in
isolation but they were all linked
together by SQS the interesting part
about connecting all these actors
through sqs that we never really
predicted was this idea that effectively
we were creating a distributed swarm now
the reason why it's a distributed swarm
is because sqs has this unique ability
to make messages invisible for a short
period of time when an actor pulls
something off the cure in this case you
make a standard HTTP call it makes it
invisible for say five minutes and then
if the message isn't deleted it shows up
on the queue again now that sounds
pretty simple but the interesting side
effect for us is that it turns sqs into
a blind dispatch effectively we are
running a grid with no master node the
cool thing about this is what do you
think happens if an actor pulls a
message off of sqs and for some reason
the actor fails what happens to the
message and let's say for the sake of it
I've got three actor systems running in
parallel on different machines the
interesting thing about this is if the
message is not deleted by the actor it
just gets picked up again by another
actor and if that actor is successful it
just deletes the message off the queue
and it keeps going so what we are
actually getting here is the ability to
have one actor pick up right after the
other
even if several actor systems fail
however as I said in the beginning we
failed quite a few times and
the ways we actually failed is that we
started getting throttled by sqs so as
you can see here the idea was that the
more infrastructure we threw at the
problem at least we thought it was like
that the more interpret structure we
threw at the problem the more we would
solve it but as somebody asked him in
one of the other talks he said well
that's great you've got a credit but
what do you how do you handle the cases
where you might hit the service too hard
you're always going to run into that
problem with well that's great I've got
a couple hundred thousand actors but if
AWS only takes a certain amount of
bandwidth and you're running on one of
the fastest servers then what do you do
so one of the things that we came up
with in this case was this idea of
throttling we and if you want to learn
how to actually do this kind of
throttling it's actually quite simple
because in a canet it has a timer this
timer allows it's actually called a
scheduler but this scheduler allows you
the same to send the same message over
and over and over again in our case what
we were doing was we were sending the
same message to monitor the amount of
memory that we are actually using or in
some phases we're checking the amount of
experience messages that we're pulling
and if it reached over a certain level
what we would do is throttle down the
actor system or at least one of them in
response to the memory being used so
this is an actual message from
production and as you might have noticed
this is a slack message so our actor
systems call home they actually say I
have used this much memory and here all
the thresholds what we did in this case
is if it reaches a critical threshold
it'll stop the polling - or reduce it to
the level where although it will
paralyze one actor system since we all
have them running as competing consumers
often sqs queue it effectively means
that we have this alas
to swarm but to keep going even if some
of the nodes are in a state where
they're critical so there's some really
really interesting stuff that we came up
with and it really helped us when we
rather these situations where we had a
catastrophic failure so what happened I
think there's almost last year there was
an eight OES outage in Sydney and what
happened was it took out an entire
region and it we almost lost a lot of
data and how we recovered from it was
essentially we had two copies of the
data in place we used this
reconciliation process that I talked
about before and on a much larger scale
all we did was take the list of hash
codes which is basically the list of
events on one side for s3 and the list
of hash codes for elasticsearch and we
found out where the holes were and we
patched them it took us quite a few days
but we were able to recover everything
the best part about this is that we run
this process every single day so if
there's any problems we can keep
patching it as time goes by because we
operated on the assumption that no
matter how good the system we built is
we're always going to have drop packets
you're always gonna have partitions and
you're always gonna have problems so we
always need to be in that state work who
are constantly reconciling the data the
last thing that we did to make sure that
we got past this whole thing around
eventual consistency is that since we
were running immutable we did one last
batch request for all the listings that
were affected so we send out the request
towards the end of the day and since we
knew that nothing will change at that
point we could send out one more request
and they would aggregate everything and
that would give us the final consistency
that we needed
again I have to stress this it was
there's nothing magical here you could
do this on your own backing store it
doesn't have to be s3 it doesn't have to
be elastic an important thing here is
that you don't necessarily have this -
same type of data sources so I don't
recommend doing two relational x' or two
elastic searches we chose s3 by the way
because we most of the time it's up and
elastic search was good because we could
search the aggregations once we've done
them and you can't necessarily do that
with s3 so in hindsight there's a lot of
things we could have done better but
we're pretty happy with the result I
mean at the end of the day this was this
project was about adding value to the
business and you can't necessarily do
that if we were just going to sit there
and thinker and and try to build that
stuff with it
what happened towards the end of the
project and it's still going that we're
nearing the end is that for the first
time we Adan started to trust us because
if we were on a phone with a real estate
agent and they say well how do I know
your numbers are correct and that's a
common thing with reporting they say
well how do I know you're not making
this stuff up and the story goes that
the customer service rep just told them
well why don't you just click a few
things five times and see if it goes up
and it did and it's these kinds of
situations
where real time really makes a
difference there's a few other things
that we've done as you can see here but
the lesson learned here is that if you
use CR DTS properly and you add
duplication you basically could do this
without much effort
because duplication at least within this
context
basically saved our ass the other thing
to remember is if with strong eventual
consistency you could achieve that with
just using these hash sets provided that
you have a good hashing algorithm
I recommend anything over 128 bits so
you not run into any Croatians if you
can afford the computation then I
recommend going up even higher than that
the other thing that we did use that
prevents any kind of outage is sqs so
what happened since we had so many feuds
all over the place if a service went
down nobody would notice in fact it
wasn't even a said 1 sub 2 it was a sub
3 we you could just hit a button
redeploy and nobody would notice a
difference and the reason why that was
happening was agents were still
expecting us to do these kinds of
reports or crunch these numbers within a
day so if we had a service go out for 10
or 20 minutes we just redeploy and
everything would be alright if you were
to go with an online service where you
would hit a server like sequel server
and ask for a computation you can be
sitting there for a long time and it
would look like the report never came
back and that's what happens with your
typical sequel server reporting service
you send a query out and then you cross
your fingers and hope that comes back
within a minute but it doesn't so what
we've learned is that it's a hot trick
but what we did was we did an offline
calculation and to the user since it was
constantly being updated the result was
it looks like it was done in real time
but by the time they're asking for it
the computation was already done so
without there's a lot of other stories
that come with us though but I'm pretty
much open to any questions because I
realize that there's quite a few other
talks that talk about how the intro to
active but we
covered a lot of cases of how do we
actually do this in production how do
you scale it up so that's it for me any
questions okay I'll take that as a
Norwegian yes very well thanks for
coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>