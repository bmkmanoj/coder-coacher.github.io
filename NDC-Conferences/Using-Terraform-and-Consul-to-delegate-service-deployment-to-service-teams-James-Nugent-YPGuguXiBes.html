<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Using Terraform and Consul to delegate service deployment to service teams - James Nugent | Coder Coacher - Coaching Coders</title><meta content="Using Terraform and Consul to delegate service deployment to service teams - James Nugent - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Using Terraform and Consul to delegate service deployment to service teams - James Nugent</b></h2><h5 class="post__date">2017-02-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/YPGuguXiBes" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so what are we talking today about
using two tools from article terraform
and console names James Newton at work a
hash cop
previously on terraform but I have coded
most of hash equals product somewhere
along the line and now work on ops for
sass so right now has anybody come
across I presumably if you came to talk
about it people know something about
hash record profits is that have anybody
never come across the company or any of
its tools okay cool
so just a quick recap we have currently
seven ocean source tools and then one
commercial product going through the
open source tools quickly we have
console which is tool for service
discovery in the top left
antara form which is a tool for
provisioning cloud resources across lots
of different clouds we have vault in the
top right which is a tool for secrets
management and the various different
types of security primitives then
finally we have moving on we have surf
which is kind of a library for
distributed mesh systems in the middle
vagrant which everybody is probably
familiar with as a tool for managing
developer environments and making them
easy to rebuild we have Packer which
we're going to briefly touch on today
but probably not for very long a tool
for building machine images so things
like virtual hard drives or Amazon
machine images or local virtual machines
and then finally we have Nomad which is
cluster scheduled associa Nettie's or
taka swarm it's in a similar vein to
that and then finally have a commercial
product terraform enterprise which is a
hosted fast version that combines most
of these tools and so the tools we're
going to talk about today primarily a
console and terraform
we're going to start off with terraform
so why were m4 is people tend to be
building micro service file
architectures today where their systems
are made up of lots of different
components which you
to act with each other whether it's over
our PC or through messaging however they
talk with each other and the trend
within the industry is for teams to own
their own operations so the teams that
write services quite often are the ones
that are deploying them we have this
problem where there's some shared
infrastructure which is owned by its
central operations team or maybe by one
of the service teams and smaller
companies there's a whole bunch of
shared infrastructure things like
networking and edge routing database
clusters that kind of thing which may be
owned centrally and we need to make
those resources available for individual
service teams to be able to deploy that
system so what we're after is a way of
writing code to make all this stuff
happen
so rather than clicking around the UI is
to deploy services we want to be able to
codify the whole thing have it under
source control and have everything be
repeatable so if you need to bring up
new developer environments or you need
to bring up a repertoire of production
debug something you should be able to do
that if you have a consistent codified
environment where the only changes are
made via code then that becomes possible
so we're going to start by looking at
terraform and how that works
it has anybody use terraform before ok
so there's quite a lot of people that
haven't so I'm going to give maybe a
five-minute quick intro to what
terraform does and then go and just some
more in-depth features that enable this
kind of pattern to work so terraform is
that infrastructure is code tool it's
open source works with a ton of
different clouds I'm going to use Amazon
because I like Amazon thanking you I'm
going make a directory for NDC London
and so terraform code lives in TF files
and you can either use this or you can
write JSON instead so tools can generate
the code for you so in this case you
live talk to AWS and we want to
provision a resource which is a virtual
private cloud so that's Alan's version
of Software Defined Networking in a
private address space so we want to sort
- AWS so the first thing we're going to
do is declare a provider so there are
lots of different providers was one for
Azure whereas it to Fraser actually four
depending on which API you want to talk
to as one for Google as well giant
there's one for Amazon because you know
about 50 of them including several SAS
products to talk to AWS we need to
specify region so we can use the region
parameter here so we'll say EU west -
this is the first time that's been in
London since they open the region here
and I'm hoping given tethered to a cell
phone the latency will be a bit better
than it was talking to us West - earlier
oh okay there we go so that would set up
a connection for us to talk to AWS so
now we can start to declare the
resources we want so in this case we
want to start by creating a V PC and
we'll call it you know main main is fine
we happen to know I we could read the
dots for this or we could go through
like the UI and work out what we need to
know I happened to know in this case the
main thing we need for the V PC is the
address space so we need to give it a
slider block of the address space in
which it allows might be addresses so in
this case we'll say we'll use a simple
one 1001 10100 slash 16 so that gives
you a lot of addresses and then maybe
we'll put some tags on it as well so we
could say for example name equals NBC
London 2017 maybe environment equals
production cool so what we've done here
is just described the desired state of
the cloud what we want is this thing to
exist and to have these properties and
then we want the other values to be set
apply the cloud provider as anybody use
count formation or something similar
like a zero resource manager templates
like I think cool so there's a different
workflow with terraform than all those
tools all of those tools in fact
a reason the terraform exists is because
I don't know anybody that's used
CloudFormation seriously that hasn't
lost critical infrastructure because of
cloud formation somewhere along the line
so terraform takes the stance that
anything it's going to do is going to
tell you about first and give you a
chance to say none so if I get some AWS
credentials cool then we can run this
command in the directory where a files
are terraform plan and what that will do
is go and talk to a WS using the
credentials that I have in my
environment and work out you know
whether whether the state of what's
there now in the London region matches
what was in my file and the answer is no
it doesn't because that V PC doesn't
exist and if we go to the console we can
verify you know your V pcs I'm in the
London region up here and there are no
there are no BBC's here and the default
so the one we want doesn't exist so we
can see terraform is going to add a WS v
pc name with site of what we specified
and the tags we specified and all the
other things are going to get there
default options so maybe we want to do
something that isn't default options so
maybe we want to actually do that a
second so if I terraform apply now that
would take the plan and actually go and
carry out the operations to make this
thing exist cell connection is kind of
spotty hopefully it shouldn't take too
long
okay
I guess its network traffic
to
good job um okay so when I wait for that
to catch signal and actually do
something useful
I guess the demos are going to be lifted
as always happening to that and you
actually start it again and see if we
can make it right can i in google
because it's a really boring talk if
they're an idealist cool Google's
looking sides are aggressively plan
probably okay so I look like it's
actually doing something now so maybe if
we apply and if Vodafone will cooperate
then we should actually go and create
this thing in the meantime here we go so
we're creating this resource that will
take a second there we go so we now have
one resource added zero change zero
destroyed and if we go and look in the
console we should see when we refresh
that what we have is a new V PC called
let me do it bigger than epic called NBC
London with the tanks that we asked for
and the size of address space that we
asked for now common problem with this
kind of thing when you have
infrastructure as code you may notice it
if you run things like puppet on servers
as well if the people go and screw with
this so people will go in and they'll
edit things so maybe for example they'll
go and change this to be staging and
eventually you have this nice
description of what your infrastructure
should look like and then what's
actually running and they never match up
so terraform will detect drift in
configuration so if we run a new plan
now having manually changed with
something in the console then terraform
will work out that you know the state of
the world that we declared no longer
matches the state of the actual world
and it will tell us what it needs to do
it will give you a plan to bring it back
in line with what the plan set
with what the configuration set so in
this case we went air this is the tag so
the plan to get it back to the desired
state is we need to change the AWS V PC
domain resource I will come to that name
in a second and we need to take the the
tag called environment and change this
value from staging to production so if
we're going to play that it will do
pretty much what you expect one of the
problems once you get beyond a single
resource which is kind of boring is you
need a way of linking things together
which don't necessarily exist yet there
we go if we go back to the console for a
second to refresh we should see there we
go we're back to production on our V PC
in the file so one of the one of the
problems once we've got a network we
could go in for the subnet in it so
we'll call this one public and this will
be a sudden net we're going to put
internet-facing instances into so we
give that a slider block and we'll say
10110 / 24 but the problem is we need a
way of referencing the V PC that we want
this thing to be in and this is quite
common pattern where you have a resource
that depends on another resource and
there's an order to the creation
unfortunately we can't use the ID which
is what you'd expect if you're gonna
create one using the CLI you use create
subnet and you give it the ID of the V
PC that you want to you want to put the
subnet unfortunately for us in this
model AWS identifies or assigned a
creation plan so we have no way of
knowing right now what the v pc ID is we
might be in a state where it doesn't
exist you three need some kind of
reference internally to be able to use
to say we want this subnet in that V PC
so some syntax for that in terraform
called interpolation so we can say V PC
ID equals and then open up an
interpolation context and say AWS V PC
so the resource types that we want to
find and then the name and then dot ID
so the name here main matches the name
that we gave to the V PC up there
and then just for good housekeeping
we're going to put some tags on it and
say public and just for good measure I'm
also going to put the second one in here
and call it privates that would make it
2-0 cry so what we have now is two new
resources and one that already exists so
if we go and make a plan in the other
window we expect terraform to find the
VP see which we already created and we
expect it to need to create two new
subnets and the second that will be
exactly what it does so here we go we
need to change nothing except and we
need to add these two resources so we
need to add this private subnet in this
public something net and we can see that
it's pipe through the VP CID the actual
value actually is known to us right now
because we already created the thing if
we did if the VP see didn't exist and
within this list of things to create
that would be much as computed because
the value isn't going to be rarefied
until such time as VP sees actually
created as we miss something here if we
go back here there's actually nothing
that makes this a public subnet so
there's a little tag for that map public
IP on launch equals true so that means
that instances in this subnet will get
you know an IP address that's public
facing instances and the other one will
not so if we go and apply this we'll get
exactly what we expect we'll get the two
subnets created and the reference back
so we within the same BBC and
everything's good so that's fine when
we've got three resources and we can
visualize what this thing looks like in
our head there's a command which can
help that's the apply is running in the
background just so these things are
created quite often what you want is to
be able to visualize what the
infrastructure looks like so there's
commands of actual terror form
grass oh yeah if you run that then it
will output grasses and unless you have
like some kind of graphical Espace it in
your mind then this means nothing to
anyone and if we pipe it through a tool
for this such as dart then what we get
is a graph which shows the order or the
dependencies between all the different
components of your infrastructures so in
this case an arrow indication in word
dependency so in this case we can see
the creating the VPC depends on having a
provider creating the two subnets
depends on having a V PC and then which
kind of an implementation detail we
don't have to care about deserve
debugging turned on what's important to
note here is that there's no arrow
between the private and public subnets
here because they actually share nothing
all the information known to them is all
the information was required to go and
create them is a known at the time the V
PC has been finished that's finish being
created so that means we can paralyze
these operations it's actually not a big
deal for subnets because they take about
a second to create if you're doing
something like an elastic search cluster
or and they'll actually MapReduce
cluster or something like that they can
take ten to fifteen minutes to come up
so being able to paralyze things that
don't depend on one another is actually
a really important optimization to be
able to make this thing fast and if we
go and look at the the way the
operations were dispatched when we
created this when we applied this plan
we can see it started creating both of
these things in parallel and neither of
them finish they were both running at
the same time so they weren't running
sequentially
there's a whole ton of resources that we
could go and do like this just for AWS
is you know probably 150 maybe 200
something like that if we go and look at
the docs for the provider here because
we can tell they're a we can tell any to
them redesign adults when you have to do
this and the the list carries on well
beyond the actual documentation so
basically any aspect of the AWS cloud
you can go and automate in this manner
and you can tie all of these things
together and furthermore all of these
clouds or all of these cloud services
can be managed in exactly the same way
with exactly the same syntax so we can
for the the most important ones probably
as your Google compute joins which is
under trained VMware if you have a local
VMware and you can orchestrate that in
the same manner digitalocean is anybody
using something that's not one of those
things what are you using software
actually SoftLayer is that yes okay
actually someone wrote that for us I
forget who it was one of software's
customers wrote that for us so what
becomes interesting is that you're not
limited to having a configuration that
references within one cloud so we could
for example and I'm not going to run
this to that I have any easier
credentials but we could do for example
what's called Azure virtual virtual
network test and have whatever and then
have route locks in here which map to
the AWS VPC we've created and it will
orchestrate across clouds using exactly
the same dependency graph models that
deal with in one so a really common use
case for this is to create a bunch of
resources in AWS and then don't set the
NS records and something like damn
simple or blind DNS or somewhere like
that
so that covers that kind of covers an
introduction to how the the resource
model of careful works together that
works and how resources into link with
each other I'm not going to go too much
more in depth with that too though I
talk about console instead so console is
a tool for service discovery and what
I'm going to do is connect to a VPN and
just show you console in action because
it's easier to visualize this thing than
it is to just look at just abstract
descriptions of it so I'm going to
connect to one of our new staging
environments which is running console
inside of AWS and it was created using
Sarah forms but the whole thing was
managed it was created with zero
operator input other than one one
command effectively if I go to the
console TFE staging local this this is
the UI the console present so
effectively console is different from
terraform in that it's not a build time
- it's a run time tool that runs in your
infrastructure constantly and it has a
server component so some of those active
servers and then there's an agent that
runs on every single node in your entire
infrastructure and that gives you a
common place to go and talk to console
so one of the questions that the answers
for example is if I'm the orders service
over here and I need to talk to the
payment service over here how do I find
one yeah I know that I need to talk to
payments but I don't really want to be
hugged coding the IP address of the mode
that happens to be running payments
right now because if we're in the cloud
we've got some kind of dynamic
infrastructure of play so the instance
that's there when your order service was
deployed might not be there tomorrow you
might be scaling according to demand or
you might be I know one might fail you
have to bring up a different one you
don't have to go and update things to
deal with that problem so what counsel
does is bringing the idea of services
and we can see a few different services
are registered with a console right now
including console itself so I have for
example this console snapshot service
and what that does is backs up console
it doesn't really matter what the
functional post services right now what
the point is it registers itself as a
and we have it running on three
different modes right now and we can see
the modes which are running on we prefix
at console servers with the name console
so we have this node name made up of the
IP address and then we have some some
service health checks so service health
checks help identify so this node is
running this software is the software
healthy or not can I route request to it
if it was a web app maybe it would look
to see can I connect to my database or
can I connect to this third-party
service that they need is this other
downstream thing available to me this is
a really important thing to know whether
I should be routing traffic to it or not
you need to know is it going to be able
to service my request because otherwise
just going to keep serving up errors so
in this case all of our nodes are
healthy we have one which is actually
operating right now this is a backup
program this is one of the things where
we run it three times but only one of
it's actually doing any work and if that
one fails a different one will take over
leadership and and take on the
responsibility of backing up our data
look at a different one here in this
case we have a service named OpenVPN
which is the way that i'm connecting
into this free pc even though
everything's private and that has a
health check which is is the box
available which is the serf health
status and then it has a secondary check
which is is the open VPN software
running correctly can I make a TCP
connection to port 1 1 9 which is what
I'm running on and establish that
connection these are actually Maggio's
compatible checks so if you're already
using something like Nagios or sensitive
to be able to to monitor systems like a
hourly or even 5-minute kind of check
thing you can just drop them straight it
so in this case we can see those nodes
alive and reachable and we can connect
to that port so we're going to assume
this is a healthy instance you could
write better checks that verify and
serving the correct protocol or that
kind of thing or the keys on our date
but these are fine for now
let's go look at an actual service that
you might connect to and see how you can
use this information to discover where
your things are so in this case we have
a vault not a vault server vault is
vault of a secret management service so
it's quite common for application those
who have to go and talk to vault because
they need a secret maybe they need an
API token for Trulia or maybe they need
to get database credentials or something
like that so they need to be able to
answer the question where is a lot
server I can talk to and furthermore
with vault it has a high availability
mode but because it's an authoritative
source of information only one is active
at a given time so there's a leader and
then was an active mode and Andres
standby nodes so what we really want to
know is who is the active node right now
so we can go and torture we can go ask
for the secrets that we need so how
would we get this information now we
have a couple of all servers running and
I'm inside the VPN so I can I can
resolve names within that private
network so one way to do it is DNS right
you could look up volt whatever and it
could go and tell you okay well the
vault servers over here the IP addresses
is like the original abstraction but IP
is the names well probably not the
original one but the most preeminent one
so the way we do that
for services that aren't going to
integrate with console and there are
some there are deeper integrations that
you can do but for the vast majority of
people DNS is fine what they want to be
able to do is say where's what
so we can use any DNS client and say
plus search for Mac OS reasons and we
can say vault service console and what
that will do is resolve console to a
console server and console as a cluster
communicates with every node about where
everything is so the local thing running
on your box can answer the question
about what's running like in a different
data center or anywhere in your
infrastructure now the default name is
console we actually use a different one
because we have a unique problem where
lots of customers also use the name
console and we don't want conflict
Oh
okay
fair enough clearly three does not
appreciate my DNS forwarding or vote up
I'm sorry you can use you can use DNS to
ping these things so any services
registered becomes a DNS name so in the
dot service namespace so if my
application my ordering service needs to
talk to volt to get a secret for the
payment processor or something it can it
can just make request as it was doing
before with a hostname of volt service
with Atlas and volt and the console will
take into account the help of all of the
instances when it returns your value and
furthermore it will show you something
more interesting about that if you're in
a data center over here and you have an
instance of volt right here which
happens what ISO volts about example
vectors you can only talk to one let's
say we're talking to our payments
processor and there are lots of those
running if I'm over here in my data
center so in Iraq one or something and I
have another instance in rack one I want
to talk to the one in rack one not the
one the other side of data center
several rows away so I am interested in
is not physical distance it's the
round-trip time between the services so
I'm interested in talking to the closest
server to me and because consoles
running on every node and it's the
gossiping among every node in the entire
infrastructure we actually can infer
information about which nodes are close
to each other in terms of time so here
we have this this visualization of this
which explains the round-trip time
between every nut so in this case if I
look at this the center of it is me and
then each line on this represents some
other computer in the infrastructure and
the round-trip time for this service so
we can do in text arts through
intelligent routing explaining
okay well I'm over here and I need to
talk to volt where do I go torture well
there are some other features that
console has as well for things like
configuration values so if you ever need
to role feature flags around to lots of
people it gives you a way to do that as
well but the primary for that primary
purpose of it is
service discovery so the first stage in
being able to automate all the
infrastructure or one of the first pages
is having everything taught through
flight service discovery so we want to
end the idea that if you're going to
deploy an application it needs to know
exact locations about all of its
dependencies so if I'm deploying my
order service then I don't want to be
saying the IP addresses payments gateway
is 1/9 2 1 6 a 5.6 I want to be saying
the way you find it is via this service
discovery registry there are lots of
these things around you can build them
on top of zookeeper or Etsy be a little
consul whichever one you whiche have a
particular one you like you can also do
it with DNS the only problem with most
DNS servers is they tend to be
configured in a manner that leads cached
values to be returned on a fairly
regular basis so that's the first kind
of step is you want services to register
themselves with console so that when an
instance comes into service say we have
an auto service comes up we want it to
register with console and say this
service is now available on this node
and it's in this state of health and
then under the third console we'll do I
sort of look up to see and it's close to
these other notes so we should be
returning it in preference to other
nodes when we're when we're determining
routing policy as soon as you've got
that then what you've done is decouple
the location of services from the people
that need to use them there's also a
great property of DNS so most of the
same arguments apply you're abstracting
out location and name resolution instead
of having these things hard-coded so
once you've done that you have a lot
more freedom about where you put things
because you don't have to go and update
configuration registries
one of the common ones that you have to
update is let's say you bring up a
website if you have a like a rails app
or a Java app or something that's
running your your public facing Internet
service one of the things that you need
to do is register it with a load
balancer so when you have when when
someone visits google.com or whatever
they're being taken to one of several
web servers behind the load balancing
system what we'd like is for the load
balancing system to integrate with this
or with some kind of service discovery
mechanism to know where can I route
traffic to who are my closest to right
now so you generally have several load
balancers and do some kind of layer
something that 2 or 3 routing first Who
am i close to who should I be talking to
how can i router needs a healthy
inferences all the same questions apply
all the way out to the edge and this is
what's commonly missed there's a service
there's a system that eBay built called
Fabio I'm not going to talk much about
beyond showing that it exists and what
Fabio is is a load balancer in the st.
in a similar vein to nginx or or H a
proxy that will integrate directly with
console so all you have to do is
register services with consul and it
will automatically do route forwarding
for you so if you say if the auto
services on slash orders then you can
specify that when you register the
service and it will automatically hook
in to any available order processing
interfaces and create an API gateway
that matches what you need we don't
really have time to talk too much about
that so let's go back to this idea of
let's go back to this idea of teams
deploying independently and how we can
make that work we've now decoupled the
runtime discovery of things so runtime
orders the order service doesn't need to
know about shipping service doesn't need
to know about the payment service other
than by the fact that it exists at some
name and it can go and use this to party
shared infrastructure to go into Scovel
where these things are
how do we do this in the first place how
we get these teams to be able to deploy
independently at different speeds one
thing we could do is one thing we could
do is share the values about things like
a well we're going to deploy inside this
V PC and we're going to deploy in these
subnets so we could disseminate the
information manually we could have some
kind of like shared repository of where
that lives and then every service team
could write their own configuration for
Terra formal transformation which make
use of those values there's one way to
do it but eventually a system for
composing these states built-in to
terraform so let me show us some some
code that we actually use in production
that that uses this model so we have a
central operations team that manages and
networking routing at work so network
networking and shared infrastructure so
that we might as council we manage
across the schedule we manage world and
then everybody deploys services on top
of those things but even within that
even within our infrastructure team we
have different people who've been
responsible for different aspects of it
we also stick everything in one big
repository and say this is our entire
infrastructure we have tried doing that
and there are ways to do that but it
turns out it'll scale that well so one
of the things we have for example is a a
terraform configuration that creates us
a a complete V PC that has all of the
resources we would need for the
networking it will configure it in a
best-practice manner across different
data centers with with all the various
different traffic abuse rates and mat
and Internet gateways and flow logging
and all the small of the normal stuff
these I'm not currently open source but
they probably will be by the end of
tomorrow but it's going to open source
all of this stuff we actually use for
infrastructure wrote this is like
everybody trying to bake their own
versions of it
so what we end up with with what we end
up without this I'm just going to show
this fat for a second is it that's where
it all runs
there's nothing here you can't do
without without the open-source software
so in this case we have these different
aspects of our infrastructure so in this
case we have a base V PC and maybe as I
spend this out we can see there are some
outputs from this and the outputs of
values which we've decided are probably
useful to other people
so things like what are the IDS of the
subnets that you're going to deploy your
services into what's the zone idea of a
DNS name what's the s3 bucket
sorry s3 endpoint names that we can
attach policies to it downstream so
these can pose together by allowing
different different parts of the
infrastructures then consume those
values in a dynamic manner so if we go
and look at something that uses this we
have no general environment staging main
what we have is effectively a module and
a module it brings together all of the
resources necessary to create some
things so in this case it's a cluster I
should probably revoke that so kind of
spoken now which this is the second
climbing to talks where I've displayed
something secret on me on the projector
last night was my github password yeah
it was excellent
so one of the things that tariffs unless
you do we didn't cover in the basic
intro is lookup data dynamically so for
example one of the things we might want
to know is which machine image are we
going to use so we might want to use the
latest Amazon provided upon - we might
be building custom images so we might be
in this case we're using Packer to build
an image of a console server which comes
up ready to work so we don't boot this
and from them run chef on it or
something
these things are pre baked and they're
pre baked to come up discover where they
are and then just make everything work
so in this case we don't know what the
image idea is going to be necessarily
because we could run it in a different
account we could run in a different
region so what we can do is query this
thing dynamically so in this case we
have a data source called an AWS am I in
this case is doc console so we're
looking for console servers and we match
by tags that are yeah we filtered by
tags and them by ownership and we just
want the most recent one so what this is
going to return is you know am i one two
three four or whatever which is the the
name of the server but we can extend
that concept once we have the ability to
dynamically lookup values of planned
time then we have the ability to compose
different pieces of infrastructure state
so if we have one that contains all the
information about how to network and it
has outputs defined on it which the
outputs we saw over here so things like
the subnet IDs we can query those a
planned time to be able to move values
in a read-only fashion from the central
authority that controls that thing out
to the people that need to use it at
least don't change that often so there's
no need for it to be a real-time process
generally they change generally you need
some more than one time when you when
you go create the infrastructure so the
way that works is a thing called remote
state so what we can say is we're
interested in the outputs of this part
of our infrastructure so in this case
TFE staging is that is that our counts
of terraform Enterprise staging and then
base VP C is the name of that component
of the infrastructure that I was just
talking about that has subnets that kind
of thing so we can look up all of those
outputs and make them available through
interpolation so if we look up here for
example we need to know which subnets
we're going to go we're going to deploy
into we just go and look that up from
the people who created them then we
don't have any values to copy and paste
we don't have any variables to set and
essentially get out of sync we don't
have any we don't have any tie to the
fact that we originally created in a V
PC over here we could go and deploy this
exact same script somewhere else and if
the values underneath it
the plan will be updated to reflect the
new reality of what it needs I really
need to remove that token now you can
apply this for applications as well it's
quite common to get individual
applications for example let's look at
let's look at revolt for example so volt
is a system that presents itself as
software it's just a binary download but
just downloading the binary is rarely
enough to actually run this with a
production quality system you need a
whole lot of other resources around it
you need things like security groups to
lock down the traffic that's going in
and out of the instances you need
policies so that it can pack itself up
into s3 so that you can give it you know
instance profile to those not familiar
with AWS that's a way that you can run
machines access to resources within AWS
that's a really neat system allows for a
lot but all of these things are part of
deploying role they don't live there not
someone else's problem there the problem
of the person who's setting up volt
right now so all of these things should
probably live together so one aspect of
it is installing software that's fairly
straightforward and I'll show you this
log we use
there are basically two parts to all of
this there's there's instances so in
this case our instances are a bit more
complicated for me the CPC things we
were looking at earlier but then making
use of data which is pulled in from
other places so we're taking things like
which subnets are we going into we take
them out from the from the V PC
configuration we take things like which
Amazon machine image am I going to run
based on the tags of the image so that
all this becomes dynamically
discoverable a planned time we also pass
in from secrets to it which as I've
demonstrated is clearly a bad idea
because they get public somehow
regardless of what you think they want
but the instance is anyone problem is we
also have security groups that live with
the instance declaration so these you
know this defines all the ports that
that particular software needs open we
also have a bunch of ion policies so ion
policies in this case define what things
are allowed to do so the in this case
this server is allowed to get it TLS
keys and decrypt them it's allowed to
describe its own environment so that
when it comes up it can configure itself
correctly and launch itself into service
if we imagine that I was a team you know
maybe I work in a bank rather than a
small company banks have whole teams
just dedicated to deploying this one
service and they almost certainly have
the same requirements right they want to
be able to maintain control over all of
the resources that they're responsible
for in a single place in a controlled
manner and be able to replicate this
thing across different base
infrastructures so you can make use of
these patterns effectively across not
only to scale between different teams
but also to scope responsibilities
within a small team which is what we do
so there's no reason in principle that
each component of your architecture for
example console and nomads and OpenVPN
and your actual applications there's no
reason in principle that you can't apply
exactly the same patents for
infrastructure as - sorry - applications
swim for structure you can take the
values you need from elsewhere you can
make them discover their environment you
can make them dynamically register
themselves so that you can scale these
things out and move them around in a
transparent manner and you can
effectively get to the point where you
end up with a system like this being
managed by either one team responsible
for different aspects of it or lots of
teams have them responsible for managing
individual aspects of their of their
software stack with that I'm going to
sort of stop talking and open up to
questions slightly the intent of videos
do a ton of demos the Internet's not
cooperating for that so I kind of have
the ad lib of it I need to be around for
a little bit if people want to ask
questions about you know either these
tools or any other tools that we have or
patents for using them or whatever at
lea biography so thanks for listening
but despite the internet problems and
really to go revoke that so colors total
now
how do you HTF state files so first what
is the TS speaks well for those unaware
when we ran terraform the way it knows
what's running in AWS is by maintaining
this this file of state so it maintains
actually most of it isn't needed the
only thing that's really needed in here
is the mapping of this identity to the
AWS identity so it matched the name
through to AWS this idea of what that
name means everything else can be
populated again there are a few
different ways to manage this file
actually managing it is a real problem
and it's kind of controversial as to
whether it should even exist but it does
so whatever there are a few different
options it will by default just create
it locally to wherever you run it that's
not ideal there's a system called remote
state so you can have it in an s3 bucket
for example and then people
collaborating and share the state file
really easily if you're going to apply
this kind of system where you you want
to BAM if you get values from other
people's states and you kind of Hashmi
using a remote storage solution s3 is a
good option or whatever the native
object storage for your cloud is there's
a whole load of different ones here if I
look at Terra for my own state remote
state this is a list of all the
different places that you can store the
thing s3 is a good one it's a good
default choice if you're on AWS or
whatever the major object storage for
your cloud is if your company that uses
artifactory then like companies that use
artifactory I found tend to stick
everything in artifactory whether or not
it belongs there that one might be a
good choice for you
we internally use our own stuff so we
run a sass will manage state for you so
we use that including to provision
itself with these for all kinds of
interesting chicken-and-egg situation
the trick there is to make it come up
enough that you can store state in it
this is mode like easy solution to that
luckily it's a problem that almost no
one else has so it's like I'm happy to
just punt on that problem with it so
like not to fix it properly but yeah
remote state is your friend as soon as
you've got remote state storage setup
you can use that terraform remote state
datasource to go and query values from
it from other configurations so how
you're going to get a module system out
of this thing you have remote States
shared around you can set different ACLs
on each of those depending on what the
requirements are that may be under your
operations seam can write to the state
for for networking and then he use
credentials with each of them which are
appropriately locked down so it can only
do the correct things each in each case
but yet we use outlets but you can use
whatever any of these they will work
equally well and tested fine other
questions
sure
haha actually so joining them is not the
biggest problem making them go away
again is a much bigger problem with
console this is actually a real problem
for most quorum systems it actually the
other way I found out about it was via
production outage which was fun because
I wrote a quorum system one time and it
does not have this problem so it's kind
of it is I don't want to say sloppy
because it's it's a great use case for
real hardware but for cloud its kind of
annoying so the problem is his problem
so you have an auto scaling group
running console clusters for example as
console service you can find you can
make them find out where the other
members are but let's say you have one
two and three running an auto scaling
group and then number one goes away
because it's terminated because you are
not greet it or because the instance was
faulty underneath and now number four
comes along so the quorum was previously
two and it's now machines one two and
three two of them have to be available
for it to do anything and now one is go
away but is still part of the quorum
because it still exists you know it's
still known as having been there before
and it might come back but also scaling
launches you instance for so now you
have instances two three and four and
now you have four instances but a
majority of for even those three only
exists and will ever exist again console
having their way of knowing that so it
has to treat them as you know all four
of these things still exist so now you
have a quorum three so the next time you
do that you have machines three four and
five now there but suddenly you have
five machines you have current three
you're still you might be okay there's a
point at which like there's a majority
of those machines are never going to
exist again and it depends on the size
you're also scaling group so it's really
important to manage the quorum size and
to force leave of members so the way we
deal with that is via
hay-bale and duct tape or bash so this
is the exact script we use for it
and it also does the discovery package
console bootstrap AWS so basically
console runs the system D service we
grew up in a configuration that says
before you run the console executable
run the script first and this will
generate out the conflict for okay thank
you shell checks seriously I don't want
the alerts go away okay so what this
this JavaScript does you know you could
rewrite this in Python or Ruby or
whatever your scripting language of
choice is I like bash it goes and works
out Who am I
so as a mode number of like this mode
running the software what's my IP
address you can find that fairly easily
what regional I am and then what auto
scaling group way in the way you can
find the auto scaling group is because
auto scaling tags every instance so you
can use described also scanner groups
and then you can find which which was a
scaling group here in for that and then
what we'll do is go and find all of the
other modes that within that also
scaling group because we can use the AWS
API from inside the machine and write
our config that says when you come up
you're going to go and join these are
just couple of servers and we do that
for all kinds of we do the same thing
for Volta no matter almost every service
running in AWS has this need to go and
self configure if you want it to be
flexible so this is health we do it I
will open source the script I just need
to take out a few bits because it's
uncommon for people to be using psycho
knows for example these are very heavily
weighted eyes these are a production
scripts so I think and make them a
little bit more generic before putting
them out because the chances are you're
not running to come a second
if you're in other clouds your mileage
may vary about how much of this you can
do you can normally find out who you are
the big problem is that you often can't
use the API without having some kind of
shared secret already AWS selfish by
allowing you to grant an instance so I
can show you what what we use for this
you can grant an instance permissions so
we have where are easy modules Council
this is the policy we use for it so
console servers are allowed to do these
things without credential they have
credentials but they're allowed to do
these things without without requiring
external credentials so allowed to
describe the auto-scaling groups
instances within them which availability
zones are in instance statuses rare
instances and tags basically with all of
those things you can discover enough
about your environment to come up if
you're not doing infrastructure
applications don't have to do this kind
of stuff in general you can use
something like console template instead
if you have all this service metadata
and you just need to know you need to go
and talk to somebody else you could do
this whole thing with console template
because this is tied to low in the
infrastructure to have that available
you're going to have to go the long way
about it and just deal with whatever
you've got does that kind of answer and
the other important side of that is
repackaging console bootstrap
is this other one which force leaves the
members of the quorum which no longer be
there and it basically does exactly the
same thing in in that it is particularly
annoying the way that them keeps popping
all this single it looks at the
instances that are currently running it
looks at the instances the council knows
about and then it dips it to so if
there's an instance the council thinks
it knows about the auto scaling group
doesn't we can use knowledge about also
scaling that thing is never coming back
so we can just force leave it and then
we manage the quraan choice so the
pattern is always introduce a new
instance
so the quorum will go up tick up by one
and then force leaves the one isn't
there anymore so that we get down by one
other questions cool
well thanks for listening and sorry that
demos weren't exactly functional time to
go revoking secrets again this is really
a month to talk but thanks listening</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>