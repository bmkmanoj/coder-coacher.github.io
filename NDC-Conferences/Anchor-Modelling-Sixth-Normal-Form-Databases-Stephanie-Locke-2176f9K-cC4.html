<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Anchor Modelling: Sixth Normal Form Databases! - Stephanie Locke | Coder Coacher - Coaching Coders</title><meta content="Anchor Modelling: Sixth Normal Form Databases! - Stephanie Locke - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Anchor Modelling: Sixth Normal Form Databases! - Stephanie Locke</b></h2><h5 class="post__date">2018-02-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2176f9K-cC4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay folks we will make a start thank
again thank you all for coming to one of
the Nisha's topic
and especially at a developer conference
it could be considered heresy to talk
about databases but who is a developer
okie-dokie so I don't need to talk about
how this works for data warehouses and
things okay so before I begin yes there
are more normal forms than three we will
be exploring them more going Pastore can
be useful
despite third normal form being your
goal and we will get into it but first
of all I wanted to introduce myself
hi I'm Steph you probably guess that
that's me
I run a data science consultancy and I
also focus on data ops so how can we
make analytics automated and take some
of the principles from DevOps and stick
it in analytics because data warehouses
reporting and stuff it's kind of stuck
in the stone age so I really love coming
to developer conferences so I can
shamelessly steal stuff and put it into
practice I'm a Microsoft MVP I write
books on are you can get them pretty
darn cheap because I self-published and
you can follow me on Twitter so that's
me now we can carry on so we're going to
cover today is what is furred normal
form how do you get there from some data
and why it sucks to have to use for a
normal form as a developer will then go
okay so step set up the problem what is
her proposed solution and the proposed
solution or one of the solutions is six
normal form databases so I'll take you
through how that works
anchor modeling and a lot of the
benefits
some clear use cases for when you should
consider using it so no DBA it depends
answer just a nice checklist so you can
say yes this situation is my situation I
should consider anchor modeling so
drilling into third normal form the
definition of third normal form no
repeating groups per room
no partially dependent attributes and no
dependencies except on the key of course
that requires a whole lot of background
so instead of doing more for like
complicated database modeling
terminology
I thought we'd work through an example
so we have some data this exists in your
database somebody has a customer table
it has information like names how many
people share the same name what my job
is and cuz I'm a data scientist who data
scientist hang out with which is ever
hipsters address details and some
purchases so a buy a lot of beer
I haven't yet got around to buying
anything else so this is your
unnormalized denormalized data right so
what's bad about that what are the
problems with this data like if this was
in your database and you're a developer
and you are having to code against this
what problems are you gonna encounter
redundant data yep anything else
gigantic table size we've got purchase
one and two do we really want to
restrict our customers to only
purchasing two things from us anything
else
yep there's a lot of ambiguity so if you
had a lookup for this kind of thing that
would work but otherwise you could end
up with some typos and things in there
okay so if I misspelled something in
that table it would be very hard for me
to specifically call out a customer with
the surname lock and fix it I might end
up fixing all the locks which would be a
problem there's a lot of repeating in
folk there's limits on how much people
can purchase there's things that are
dependent on other columns and the table
says customers but so much of that info
isn't about customers it is pretty weird
to have all of that together so we can
start tackling some of the issues so the
first normal form does not contain
repeating groups in a room what that
means is instead of purchase history
item 1 item 2 item 3 as columns instead
those should be a row for each purchase
so you don't have any repeating groups
going across in your columns now the
nice thing about this is our customers
can have unlimited purchases but there's
still a load of our problems so we got
through one of our problems which is the
purchase limit but we still have a whole
bunch of issues so maybe second normal
form will solve it for us second normal
form involves no partially dependent
information so
if first name and surname were your ways
of identifying a customer that would be
considered your natural key of course
first name and surname is a bad idea for
considering somebody a unique person
all those John Smith's are really going
to get in our way
but the number of people with the same
first name is partially dependent on
your key so part of your key first name
if you know that you know the answer to
this piece of information so we split
that out so now our data is in second
normal form still not particularly good
right so we solve a few things we're now
down to only three big issues and we
still got all the repeating info got all
the info about customers so third normal
form third normal form has no
conditional dependencies so the
population of a country was not
dependent on the key but it was
dependent on another part of the table
so we split that out into its own table
and now technically we have third normal
form but there's still things wrong with
that right
so what's still wrong with it
hmm yeah IDs we so can't do the update
based on a specific customer instance
but we still have purchase history in
our original table third normal form
says that's okay so you're probably
thinking wait have I been thinking about
third normal form wrong and you would be
right actually hopefully most of you
build your databases to what's called
Boyce Codd normal form voice Codd normal
form says only information about an
entity in the table so purchases is a an
interaction that we should split out
because it is about the customer entity
and your inventory entity and how they
relate so you would split out your
purchases and then use a customer ID to
relate to them so this is probably a lot
more like what you're already doing so
pretty nifty Lea you've just jumped to
normal forms because Boyce Codd normal
form is comes after fourth normal form
so when everybody else goes yeah you
need to get your database of food normal
form you go I get mine - Boyce Codd
normal form and sound instantly Thresher
so so are there any problems with this
schema now that one that you're probably
pretty happy roughly with this schema
you keep lookups and things in separate
tables you've got purchases in a nice
easy narrow table you'd probably be
quite happy with this in production
it looks good this is what we've been
told we should design to but as
developers when we're working with our
application and our data conceptual
module model we still have a whole bunch
of problems that don't necessarily
relate to the normal form but the way
that the tables end up structured so
you've got your database what are the
problems that you encounter and
frustrate you about your database when
you're bit when you're making a change
in your app what are the problems that
you encounter
yeah it takes a lot of work to if you
want to change data you have to maybe
set up a new table copy the data across
into it and then roll over which makes
your deployments really complicated any
of our issues who understands indexing I
don't indexing is hard if you have all
those columns going across and you've
got your however you write your queries
you can use indexes to improve it but
then you have to understand about
indexes and apply them in a way that
your DBA doesn't want to kill you
because there are raffle bunch DBAs so
whatever problems
paedon read performance yep
any others okay I I think I gave the
problems with the DBA with third normal
form for devs
but maybe I over fought so change gets
riskier over time you've got your
application with a and you've got eight
million customers you want to add a
field to your customer table because it
was put on a forum by a product owner it
gets kind of nail-biting going I need to
add a column to an eight million row
table that could take the database
offline or the performance is going to
be slow
what if I screw it up what if my
statement doesn't work the longer you
use your third normal form database the
scarier it gets to make changes again
your DBA will probably kick you for this
if you write select stir in your
database and then somebody else adds a
column then it can really break things
then how do you know that your dev
version is the same as your Pradhan how
are you managing schema change and
promoting that through your environments
it can be pretty difficult to do that
then as you make changes in an
established system it can take a long
time like what if you need to re index
or change a data type because you
thought yeah where are we going to get
32,000 different occupations and then
somebody comes along with the 32,000 for
one and you now need to sicker you need
to change the ID from medium into a big
int it's difficult then when it comes to
version control do you keep who here has
the database under version control
database schema yeah okay how do you do
how do you manage database change do you
keep a like do you use something like
sequel server Davout database tools
where you have your desired state for a
database or do you have the initial
version that somebody made and then a
series of scripts that have to be
executed in order to recreate your
database States who has a desired state
database who has a migration script
database yeah what happens if one of
those scripts gets executed out of order
like you move to sequel server on Linux
and the file system has a different
natural sort order on your numbers then
Windows does so then things get executed
out of order what happens if somebody
replays those scripts will it break
can you safely deploy your database
schema again and again all right and
then how do you know who changed what
and when it can be pretty difficult
right so food normal form databases
pretty troublesome so you end up with
availability issues indexing is hard DBA
shouted us customers shouted us it's
difficult to implement changes safely if
you've got lots of optional fields then
you're storing nulls everywhere right
and then you have to handle nulls in
your database in your front-end code and
it causes like storage bloat and again
the DBA shout at you it can be really
hard
looking through get logs to see what
changed and when and understanding how
the schema is has evolved is difficult
or which apps are working with which
version of the schema there are more
woes
changing data types oh that is efforts
or what if you need to correct some if
you need a new version of a calculation
change tracking is heard and then this
other one who has eaten their own dog
food and built reports off of the
database they've built for their
applications okay I highly recommend
that you do at least one report for a
business user off your database to prove
that your database is usable in other
contexts than your application because
it has to be and until you've written a
query to satisfy a business user you
can't no and you don't feel the pain
and a lot of people really want to be
certain that you can prove the values
you showed at a specific point in time
and doing change tracking in a third
normal form database context is usually
pretty difficult
how can you easily say user Bob last
Thursday got shown this screen if you're
in a regulated or a healthcare type of
environment you need to be able to say
that that's really hard in a fer normal
form schema and this is why no sequels
the answer right let's just do document
store and we can worry about the schema
later we can make changes as we need to
that is an acceptable solution in a
range of situations sick normal form is
another solution for another range of
situations so what is sick normal form
this is complete normalization so if you
imagine or think back to our first
denormalized data that is everything as
columns in one table sick normal form
basically does this every table
principally contains the entity key it
relates to so like the customer ID and
then has a column for a specific
attributes so every attribute in your
third normal form caller in your third
normal form table would now have its own
table so this is what it would end up
look looking like if you were hand
crafting your six normal form data
warehouse liner business system
that is some crazy stuff right imagine
writing all those joints you're not
gonna want to do it so we want that
flexibility because if we wanted to add
a new column to our data to our
conceptual model that our app is going
to use that's an extra table with a
foreign key constraints you don't have
to take your database offline you don't
impact anything else that is using all
the existing stuff you just have to add
a new table and start filling it in this
it it makes the changes additive only
but nobody ever should write six normal
form sequel queries it is how so we kind
of want that flexibility of being able
to add tables and stuff but give us the
third normal form that we can use in our
applications
so this is where anchor modeling comes
in for you guys anchor modeling has a
great website tons of video tutorials
for getting into the operational how do
you do things but you build a mock
conceptual model and the anchor model
system builds you an idempotent sequel
script so a script that you can run
again and again and will not make
changes to your database if those
changes have been previously applied and
does it from effectively a full
conceptual model so let me just see if
the Wi-Fi is fine
and show you
let me just extend and duplicate instead
they'll be easier okay so this system
has a nice online thing and it uses like
D free and forced Iraq did JavaScript
stuff pretty nifty and you can build
your model using this GUI you can also
build it through the underlying
representation but this system allows
you to build a model of how all the
entities interact inside your
application and you can build your model
for your app the other team can be
building their conceptual model you can
deploy them both to the same database
and then have connections between them
for where they hook together so you can
safely use this in a team environment
so you have the idempotent schema so
this is the current state and you can
run that script against any version of
your database so if you have an old
version setting around in the UAT
environment and you want to run the dead
version against it you just execute the
sequel script you can safely run that
sequel script again and again it has
some strong advantages for if you need
to do some interesting stuff so it has
multiple concepts of time not only do
you have the time something happened so
if a user directly edits a field you can
say the change happened at that time but
you might have processes that happen
after a change happens so a a person
walks into the doctor's office and gives
a change of address the event happened
when they handed the slip over you might
need to record that because that's when
the change should be valid from but the
receptionist won't load it into your
application for over six hours until
after the surgery closes the doctor
might have made decisions about where to
send prescriptions or letters in the
intervening six hours to the new address
but your system wouldn't know that six
hours later so you have the time and
event happens the time and event was
recorded and you can also then add a
further notion of time of when an event
was evaluated and when you evaluate an
event you can add a reliability measure
so these are optional attributes
optional capabilities of anchor model
that you can enable
but if somebody goes onto your app and
says their salary is now a million
pounds when all of your other customers
income is between 0 and 200 grand
you could add a low reliability marker
against that so downstream you could
kick off an asynchronous process to get
that data vetted and customer services
could go in update it with a real value
and assign a high reliability to that
new value or they could confirm it and
change the reliability to one that
you're certain that data is correct so
if you need to be worried about data
quality or to add multiple people's
opinions about how much something how
likely something is to happen you can
enable the reliability measuring and
have this baked into your model without
you having to write any specific code to
make that happen it does version control
it records every version of your data as
it changes if you want to so this makes
it fantastic for being able to rewind
your application and say this is what a
customer saw on a given point in time
because all the changes are additive you
do not need to take your database down
because you're not impacting existing
tables it is safe to add new tables that
is great that means no downtime
I love no downtime especially when I
don't have to do complicated things to
achieve it
so the model is pretty simple we'll look
at what makes up an anchor model it's
also really great for a data warehouse
for most of these reasons it worked
really well on a column store database
engine and it is cross-platform so you
can get it to generate sequel server
specific in a sequel server specific
database implementation or an Oracle or
Postgres or my sequel and because
everything in the database is basically
you can effectively think of it as two
columns the thing it relates to and the
thing you're talking about it is
wonderful in a massively parallel
scenario so from a scale out perspective
it becomes pretty nifty so what's in a
model in an anchor model when we say
anchor we're talking about entities so
your anchor will be a customer inventory
staff then you have attributes so these
are the things about entities not so you
look up tables so you probably already
have a bunch of knots and then a
constraint that says the values in my
database for this field must be in this
existing set and then ties how your
entities interact so you have some new
words but you probably already think of
this stuff when you're building UML or
use case diagrams right you have your
actors how they interact things that you
need to track about them and constraints
about what they can say so those are the
main components and then you can set up
some different concepts of time so you
can make some
thing static to just have a single value
so you're not gonna worry about change
tracking you can then make something
historize
to track the changes so whenever a new
value is whenever you update a value the
old value will be stored with a
beginning and an end date and you can
then use a point in time view to say
what was the value at a given time or
what changes did this value undergo
between these two dates and then
concurrent Reliant's temporal which is
definitely a mouthful that is where you
have the reliability indicators so you
not only have the concept of when things
happened when they were recorded but
also when they were evaluated for
reliability so you probably not gonna
turn this one on without a lot of
thinking but you can use these two in
the same model right down to the same
anchor so you can say well people don't
really change the date of birth so I'm
going to keep that as static but where
people live they change that fairly
often so I'm gonna make a histories view
of all the fields in address so that I
get the change tracking it doesn't the
really nifty thing is about this that it
doesn't have to be an all-or-nothing
scenario you can do a little bit in this
you can turn you can make a new version
that its history store static and revert
back you keep all your old data and you
just add this new section so how we do
the work you can use the GUI and I will
admit to having a lot of fun dragging
things around and seeing all the layout
sort itself out it has an XML schema so
yes it's XML I know that's kind of out
of vogue but because anchor modeling is
open-source you can make a version of
the translation engine engine in to use
JavaScript entirely you can take your
third normal form schema that you have
already apply some sequel scripts and it
will generate an anchor of model
representation so these are mentioned on
one of the posts on the home page so you
could go and experiments without even
having to go through a modeling exercise
you can take your existing database give
it a go see what it feels like
and you can bring your own it's an
entirely open system github repos you
can make changes recommendations
implementations so one thing your data
you start with a blank canvas here is an
anchor and I'm doing this because I
couldn't guarantee internet so here's
the example model which we can build so
squares are your anchors diamonds are
your relationships and circles are your
attributes and everything has metadata
so you have your descriptor which is
your nice pretty name for a field you
give it a shorthand TL a for attributes
you can say what schema it belongs to
and you can give it a longhand
description so you can be putting
information about how you expect your
model to be used or concepts that are
important or like
JimBob JimBob required this attribute
you can put that information in there
and then you can say whether it has a
lookup or whatever you want to do change
tracking and you can do it from inside
this GUI so you build your model like
this and then the next step is to get
ready to do a deployment so you can use
the GUI or there is a JavaScript utility
file called sis you late which will take
an XML file representation and convert
that into another form of output so yes
it does but when you create it we I'll
show you how to do that at the end just
so I maintain my timings okay so you get
the things once you have the file once
you have a sequel file you can run that
against your database and because it is
just a JavaScript thing that you can do
in a command-line you can then put it in
your continuous integration and
deployment pipeline your schema your
database gets generated from a state so
you can do a clean state build or you
can do a regression test or integration
test where you apply it to an existing
database and run a check to make sure
that it is okay
so it's quite nice and easy
you hit sequel code it does the
situation which is also just a great
word it had various options like do you
want to build partitioning in it has
some extra nifty bit you can get
adjacent representation of your model
the really nifty thing is it
automatically documents your database if
you've got your descriptions and stuff
in it's great and you can click through
to say what does this relate to put all
your data types I love it when I don't
have to document something but something
is documented for me
so once you have your database deployed
you then have to start using it in your
application so it provides a whole bunch
of third normal form interfaces and has
nice business names as well that you can
use so common application actions create
read update delete crud so when somebody
says you have a cruddy app it's not
necessarily a slight create is an insert
read is a select update is an update and
because this is all about keeping data
as much as possible it is relatively
difficult to delete data you can but the
easiest way for most situations is to
just put a toggle an attribute which has
a 1 or a 0 for whether a customer should
be deleted
so you could do the soft delete toggle
and then if we're thinking GDP our right
to be forgotten you can then do a more
intensive process to cascade through
your model which because it's very clean
and simple it's really easy to say these
are the things impacted by this customer
to do a full delete so you might have a
select you don't necessarily have to
select all of these things but they have
these metadata columns these metadata
columns tell you what version of the
schema the data was inserted or updated
under so if you do a schema change to
work with your app sort of like a forked
version then you can say this is the
data that might approve or if you have a
legacy app that is still running on an
old version when it's making changes you
can tell that you also get to see when
data changed so you understand its
freshness so a select statement just
kind of works as usual insert when you
insert you should make sure you have
your metadata ID and you can let me just
I've hard coded this but whenever you
make a new schema or make a new evolved
version of your model
it goes into a schema table and gets a
number so you can link that to your
commit through your and put it in as a
config value or something
or you can hard code it to give yourself
a fixed point in time that is a that
depends on how you want to work and then
we can insert values so even though it's
six normal form and even though we're
inserting an actor the actor name is
actually a different table to the actor
ID we're still getting our interface and
then when it comes time to do our
updates let me just make sure it worked
we can change it by referencing the
original anchor ID and get changes and
even though there are all these other
attributes we're only writing data into
the one table
this means we're only storing as much
data as actually exists it reconstructs
everything to say I don't have
information but you're not ever having
to store an absence of data this makes
your system much much smaller relative
to a fer normal form database e
no it has this sheer volume of tables
right and it has various bits of
metadata like when things changed so
that we know about those what was I
gonna say but the advantage of only
having data that is filled in not only
do you have a storage benefit but it
makes it much easier for your database
to compute statistics about the
distribution of data in those columns
which means your queries become more
efficient without you having to do much
what about you having to do anything ok
so when it comes time to change a schema
you can make a change in the GUI any
prior model is a valid state all the
prior versions so let's say you need to
go from a 32 into a 64 in version of
something because we have lots of growth
the 32 int version for all the old data
can still live in your database but your
quick your new version of the app can
point to the new 64 bit version which
you populated as part of with the old
values so you can correct your data use
the new point in time version in your
app but old versions or fixed things
that you can change can still be using
the original table so if you have
different versions of your app
in the wild they can all still use
different database states but still be
working from the same database so you
can do a change in a GUI or a system I
used to have this for a data warehouse
so I was able to make I was able to add
new value to a to a table in my metadata
database and then every hour when my ETL
would run it would bill it would detect
changes and regenerate the sequel script
and deploy new data deploy my schema
change so you can have this inside a
continuous delivery operation whether
you generate the XML and check it in or
whether you have something that
generates the XML and the downstream
sequel for you and then it I would
recommend you increment your metadata
tag so you know which version of the
schema your app is running against so we
have our existing model to make changes
to it we can use the GUI so I'm going to
add two attributes I don't like having
first name and surname in one system so
I can now fill in the information to
make my two new attributes this is where
you put in the date ring the data range
I made the video without putting like
brackets 255 you should put that in
otherwise it'll default to virtual one
and we can historize them so that we
have a change track version
and you know you have to be able to type
correctly what they've done to improve
search speed and value comparison is
they've implemented a checksum value
comparison which makes it much more
efficient if you're change if you're
storing big values of text or gooood so
various things to be able to effectively
compare that does mean that you need CL
are enabled in your database so right
now you can't use as your sequel as a
platform for a sixth normal form
database that does the checksum
comparisons and right now with the I
think the current advice with specter
and meltdown it's like turn off CLR the
mightier the our into our and -
integration and just like go back to
straight sequel so that is a
consideration for implementing this that
you will need to think about are we
allowed to effectively run c-sharp in
our database
idempotent script so that deploys and
then our new version of our app app ID
too can do an insert it can reference
only the columns it expects and that
version of the system works so we now
get a second record without actor name
but that has the first name and the last
name so you can keep changes relatively
in track with your app you can do
updates you can be nice and be backwards
compatible and that's still fine here is
just changing values
and you can just be mean to your legacy
apps and just update your new values so
if you're dropping columns because
they're no longer relevant or because a
version of the app is no longer
supported you can just insert the data
you care about so you're able to account
for effectively doing feature flagging
so when to use it they did a really nice
paper where they simulated different
conditions different types of scenarios
to come up with some nice easy
conclusions if you're going to track
version history anchor models really
good for that it will be much faster
than a big database with version history
done in a sort of hand-rolled kind of
way if you have lots of optional values
this is brilliant because it's only
storing the data that exists if you have
a big model so this maybe doesn't apply
for when you're building rep like a
relatively simple mobile app but if
you're taking a big legacy app that
covers a whole sort of mortgage loan
process then you might have a lot of
data a lot of entities and interactions
and this can be really useful if your
models changing a lot definitely
consider Ankur modeling because the
changes are additive and you don't have
to write the ad you don't have to write
the deployment scripts so there's no
mistakes I love but there's no mistakes
if you need audit trails it's really
good because it takes care of that for
you
and especially if you need reliability
measures then trying to model three
concepts of time is really hard and you
will spend a lot of time doing it
whereas you could just turn it on so it
isn't an all-or-nothing because it's an
idempotent script that doesn't drop your
database doesn't drop tables doesn't
impact anything that already exists you
can use this for a small section of your
app and keep the rest inferred normal
and when you should go back or stick
with the normal form if your schema is
never gonna change so discontinue its
outer support thing that's just gonna
take over with those few users then
maybe collapsing it back to third normal
form to simplify things if you have lots
of search conditions so the way that the
select with ways works is it will use a
bunch of the database wizardry behind it
to not have to join everything but if
you have lots of search conditions then
it has to join all of those tables so if
you had ten conditions that will
probably be a slower query in section
normal form than it would be inferred
normal form if you have low data volumes
then the overhead of multiple of lots of
tables will probably mean that your
database is a bit slower if you have
lots of lookups so the knotted
attributes that can be a little bit
difficult
and even though the database can do
clever things around performance with
this it may still be a little bit slower
than a third normal form version in a
number of these scenarios so what you
were if you need that extra millisecond
and it isn't that you can turn on the
partitioning or turn on like use a
column store database then you might
want to revert to third normal form but
these are the criteria where I would
suggest you give anchor modeling ago
okay I go through this nice and quickly
so we'll be able to have plenty of time
for questions and playing with a model
so for normal form actually most of you
have probably been doing boyce-codd
normal form whoo-hoo you got an extra
two it really sucks as an application
dev to have to try and work with a third
normal form database there are things
that you can do to make it better but
this really is one of the big driving
forces for the swing back to document
databases because managing databases
proof schema change to match your
application is fundamentally difficult
because of the way that databases work
anchor modeling by splitting out every
attribute into its own table means that
those changes to your model to your
application become additive you don't
have to run big updates you don't have
to run alter tables you don't have to
have an indexing strategy
you just add an extra node to an XML
diagram to an XML file or have a
business analyst use a GUI or you use a
Giri because you like chucking things
around it because of the JavaScript file
it sits inside your CI CD pipeline to
help you move faster and again because
it's additive it means that you don't
have to request offline database time it
puts things back in your control to save
you having to do synchronized processes
with your database ting you still use
third normal form views and functions
that enable you to get the latest view
the view in a point of time and a list
of changes that have happened you're
able to query the schema to say what did
the schema look like at a given point in
time and you're able to tie your
application to a specific or tie your
database to a specific version of your
application so you're able to trace the
impact of a version if something goes
wrong and you need to just like do a big
undo for a given state of your
application you can actually say delete
anything with a metadata ID of 99 the
release we will never speak of again and
it'll wipe all the changes so you can do
that you should consider this for when
your database is undergoing a lot
of change when you have lots of optional
values when you need to do version
control or tract changes these are
really good cases for doing this and
when you need to be able to add in
multiple concepts of time so if you have
processes that might happen offline by
being able to record when an event
happened but when you loaded it that can
be very useful so thank you for coming
thank you to the organizers and sponsors
and stuff what I'd like to do now is go
over to QA you can drive me using anchor
modeling if you go to its alikom forward
slash talks the first entry is for this
talk you can get the slide deck you can
also get a github repo which has example
code for a bunch of these things it has
some glossary and some more detail and
we can drill into those but it means
that you can take this away and look at
it more intensively than a Friday
afternoon after three days of solid
learning so that's why I wanted to keep
this keep the main theory bit kind of
short and sweet so that we can have a
play and answer questions and things
that you fought off through this so
questions yep
so the question is with a given version
wait did I Oh for some reason I thought
I only talked for like half an hour okay
you can all leave whenever you want to
I'm not gonna keep you here so let me
just duplicate this so my database here
the attributes for a given thing so if
I'm adding a new field about actors in
this case it's going to be a new table
and it will drop the old version of the
view which says actor has these 10
columns and there'll be a new version of
the view which says actor has these 14
columns the old tables the old columns
don't go away the old application would
continue using its select statement that
it always had and it wouldn't see any
change your new version of the
application would use a new select
statements that refers to the new
columns so it would see its put there
bits that are relevant to your new
version your old version would see the
old columns
so in the event that you have to
synchronize data between two of the
tables the inserts work through triggers
on the views and processes so you can
set up a your own independent
synchronization script you can
potentially modify the trigger that does
the insert so you can change your anchor
model but I would recommend an
independent script that does that data
synchronization especially because that
by thinking of it as application
compatibility between versions you
probably are already thinking about the
lifecycle of your versions how long you
are going to support them and what
changes you need to make to keep them in
support so that application support
usually kind of has its own folder of
stuff you're doing so you might have
like a new like a halfway house CSS
sheet to make the old app kind of look
like the new app without rebuilding all
the frames so that kind of process would
sit in there in your migration lifecycle
planning
any more questions okay so you have the
files got the presentation make sure you
grab stickers and cards and stuff if you
follow my company Twitter I give away a
book a month usually kind of data
science focus but very beginner stuff if
you have any questions on this you want
to play
I do office hours so you can just go on
its alikom go to schedule a call and
book in half an hour
all my availabilities plugged in so if
you want to followup with me on this you
can email me or you can schedule a call
and we can have Twitter conversations
now that there's 280 characters I can
talk normally thank you all for coming
today to such a niche topic and
hopefully I've inspired you to give it a
go on at least a toy example for your
environments thank you all very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>