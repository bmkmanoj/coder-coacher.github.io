<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Fast and Small - What are the Costs of Language Features - Andreas Fertig | Coder Coacher - Coaching Coders</title><meta content="Fast and Small - What are the Costs of Language Features - Andreas Fertig - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Fast and Small - What are the Costs of Language Features - Andreas Fertig</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Bt7KzFxcbgc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I recently learned I'm the first time
here it's my first time in Norway it's
my first time in Oslo and it's my first
time in Norway I knew that first but I
learned that there is probably a larger
audience tuning in in a separate room
where they have the possibility to
choose between different talks so hi
there to you too today I'm going to talk
to you about fast and small what are the
costs of a language feature what's the
idea behind that pay only for what you
use the model I associated most and
strongly with C++ and in thing it was
around 2005 the technical report about
C++ performance got out and it's a
document I like still today because it
tells us a little bit what's going on
behind the scenes and which code do we
actually produce the good thing is that
compilers and optimizers now are they
are really really smart and help us to
optimize our code a bit more and get rid
of unnecessary unwanted stuff so there
are many features in the language and
it's up to us to decide which one we
like to use that's the cool thing about
C++ the important thing for many
solutions is that nevertheless we are
still closed to hardware that's also
very good however what C++ is not is
what you see is what you get language
for example they are constructors and
destructors which are involved silently
sometimes they can call functions
greater objects or allocate memory it
still means that we pay only for what
you use but it also raises the question
what are the cost of the things we use
really even with a good reason to use a
feature or a library it matters what's
behind it so what I will show you in
this talk are various hand-picked
selected language features and I like to
give you few behind the scenes so how do
you do they work internally so this
should help you to decide which one to
use or in which area you will like to
use it let's start with an easy one Auto
the interesting thing about Auto first
is it's not really new before C++ 11 it
was used to tell the compiler that a
variable should be placed on the stack a
great thing isn't that always the case
yes since C++ 90 it is always the case
this makes all the most useless key
words of all times probably well not so
anymore with C++ 11 Auto got reinvented
there the meaningless reserved keyword
got a new meaning now it does what we
know from other languages for c-sharp
for example is bar it helps the compiler
to fill in the correct type of a
variable depending on its initialization
this is deduced by the argument on the
right hand side this whole process
itself is also old we know that from
template type deduction for years
what other can do is it can spare us a
lot of typing that's one thing because
we do not have to write all if template
parameters you can just say order on the
left hand side but more important is it
can save us from silly mistakes which
can hurt sometimes so for example
forgetting or adding Const or getting
template parameters slightly wrong in
another way
result in unwanted and maybe unseen
conversions behind the scenes the
resulting output may look like the same
but there may be a conversion involved
with other this is no longer possible we
get the same type on both sides the
deduction rules for auto are mainly to
remove all top-level qualifiers so we do
not get the full-blown type with all
qualifiers constant volatile for example
are removed it aims only for the
underlying type if this type is a
pointer to constant memory the
countenance of this memory section red
points to remains of course comes
reference on the other hand is
completely removed so roughly the rules
are here becomes t ref it becomes
constant if you have a Const P star
comes it becomes a comes peaced are the
good and important use for this talk is
this all happens at compile time it's
not that the initialization can change
with each for loop and you get a
different variable type no it's done
like templates at compile time so no
additional runtime costs or increased
RAM or ROM usage so much about auto
let's move on to a combination of auto
and deco type deco type auto the usage
of deco type is a little bit different
to auto it's like auto to query the type
but this time including all the
top-level qualifiers to tell you upfront
duty is its nature it's also compiled
time only without any overhead as long
as we stick to the rules
everything works expected let's have a
look at this example here
we have the ordinary program the
variable foo builds the base for it from
that we did use with also on deco type
for new variables a b c and d in the
last step
foo is incremented by 1 so it's not the
most sophisticated example here but it
will illustrate my point and my question
to you is what is the output of the
program what does it print out for a one
grade I take that what does it print out
for B
would you agree with one c1 again right
and deep reasonable idea about teeth
what's teeth
I have one one here who wants to go with
one okay I initially did two wrong it's
two and if you pay close attention the
only line that differs from our usual
expectation is the one with deco type
auto and the braces I put in there so
days seem to influence our time our
deduce type somehow we put braces around
math expressions for example and to
group things and putting braces around
variables changes the expression type a
bit it's not an ordinary variable
anymore in this very moment
it's an l-value and in the context of
deco type auto I will show you later
an l-value is supposed to lead to a
reference so now you can say all right
nice that we have learned that but
really who puts braces around available
like I did here I mean come on it's
typing two additional characters and
nobody wants to do that we got Auto to
type less so I agree nobody does that
some do by intent and there's a
potential that you do this by mistake
and that if you use one feature with
which i think is the one they would load
out of c++ if they had a chance to and
that's macros we put braces around
parameters of macro functions to get rid
of nasty
side effects for years these braces
remain in the coat the brief recess it
does only do a text replacement so the
outmost braces will stick around and
popular example is such a max function
is shown here and I agree we are in
modern or postmodern C++ so there should
be probably a template but it doesn't
have to so you can get in the situation
you may have legacy code where you only
switched the one side you like to have
deco type in order for some reason but
you didn't change the other side then
you can end up with stand that's not all
this is a slightly modified version of
this know pray our program we simply do
an X plus plus so we increment and
variable which is passed to the macro
function and my question is once again
what's the output now for a is trivial
come on one good piece one travel as
well see
we have to sink a little bit to one I
take the one to post-increment and B so
I get a two because of the reference ah
that man is good so it's - its - again
but there's a but even that the result
looks the same what happens in the
background is different because of the
nature of the post-increment we first
take the variable and increment it
afterwards we need to get a temporary
object and in the context of the
standards that's an x value an x value
is an l-value work you can steal its
contents from so what we get in this
case is the output is - but instead of
binding to foods and reference we now
bound to an temporary object that's most
likely not what we want so there's
another thing you can say okay program
is not so sophisticated and writing x +
+ is not the best thing to do we learn
on other places that it's much better to
say plus plus X so let's pretend the
program doesn't do anything at all so it
doesn't matter we can change it we fix
that we say plus + X we change from the
post to the pre-increment
that's nice what again a cells would now
a we didn't change anything there so on
B didn't change it 1 to C is a little
bit tricky but still rather simple we
changed to the pre instead of the post
increment so I think everybody
that's two this time and ta what's D
this time
you already saw that it's the first case
again this time it's for but just
because we switched to the pre increment
we do to change to the pre increment the
variables incremented first and X remain
so we have an variable with braces
around and we are back to an l-value why
does deco type in combination with Auto
behave the way does it's perfectly
defined in the standard these are the
words from the standard so we looked at
case C and now sorry at case D and E
here the first time and the second at
the third time it was e no sorry
the first in a second example we got an
l-value
and that's why we gained reference to
fluent in the second example we ended up
this is temporary which can be reused so
the results turned out to be different
deckle type in although that wasn't in
combination with Auto that was might
hague can lead to unexpected results
it's still questionable to write such
code with macros but it can happen and
in that circumstances it appears a bit
difficult to get the correct result
you like irrespective of that Decco type
is a compiler only feature which has no
influence on the resulting code or the
performance if applied correctly well if
it matches what you want I will show you
an example later when and where it makes
sense to put braces around and variable
let's move to the next item
do you know this type of code it's
always the same pattern annoying to type
again and again plus even that it is so
simple and we are so used to it there's
room for errors and I'm not talking
about what happens in the body one
potential error I often see is the post
increment instead of the pre increment
this slide illustrates it correctly in
some cases it's my own code I was taught
in my early programming years to write
it that way X plus plus and
unfortunately it just sticks still today
it's well meaningless let's
say that way if you deal with an integer
result but it matters if it comes down
to object nonetheless writing X plus
plus leads to an temporary object as
we've seen in deco type and this in each
loop iteration that means we construct a
temporary and destructed right after
that just ridiculous the waste of
resources with a bit of luck the
compiler optimize this away now there's
a second potential error source one
which is not that obvious often and
that's the loop condition itself to be
precisely called to end this function is
invoked at each loop iteration in most
cases and does not change anything
because it's supposed to give you just
the end element so this means that of a
multiple calls and the result of and
remains constant this is a great
opportunity for the optimizer in a very
large number of cases it sees this
constant us and simply cashes the value
of n for us so it does not get called
with any loop iteration anyhow for some
reason and does look too complex to the
optimizer it leaves it as it is and as a
result we end up with end getting called
with each loop iteration loop cycle now
we are luckily in modern Sybil of bluff
array of the modern version using a
range base for loop the first thing I
like is it's much easier for the eye so
let's type in two so all the things the
programmers love
to be so are we supposed to react on
that sound it's a test okay my nice okay
for most this variant reduces the typing
to the necessary parts the one which
changing all the time
that's nice the other thing which is
nice is they're the two problematic
parts are gone if you look closely we no
longer need to write the iterator
increment hence we cannot do it in a
less efficient way in addition the
comparison to the current iterator
element and end is also no longer our
part so let's hope whatever happens in
the background is now as as efficient as
we could do it we will look to that in a
minute kind of disturbing please note
one thing that's the colorized ampersand
with range based forbs in combination
with Auto especially this one is often
forgotten that's a little bit due to the
nature of how we've written it before
that omitting it means that we end up
with a copy in each loop iteration
instead of what we more likely want a
reference to the current iterated
element so we supposedly dropped to
possible performance penalty mistakes
and we got another one so we are down by
one that's good so how does this work
internally this the definition of a
range base for is it can be found in the
standard and it turns out that it's just
syntactic sugar the compiler does the
transformation for us from a range base
for to a traditional for loop that's
nice
the important thing is there's the
compiler aims for maximum efficiency it
always uses the pre increment so it does
a good job there and it does a second
thing if you'll take a close look at the
loop declaration it ensures caching
the value of end by storing it in a
variable so it ensures caching
regardless of the quality of your
optimizer it's guaranteed to be cached
that's a brilliant way of doing that
it's nothing we couldn't have done our
selves but it's nice that the compiler
does this for us in the background now
if you for some reason that society node
have an application which relies on the
fact that end must be called with each
loop iteration range based for loops are
nothing for you because they are
definitely to be cashed in the other way
if n changes anything this will stop the
optimizer from cashing it here it is
guaranteed to be optimized always all
the time the whole thing is braised a
little bit on the curly braces you can
see on the outside they open an
additional scope for the for loop or
around it and with that the compiler
ensures that all temporary variables
which it declares inside of that curly
braces in this scope are destroyed at
the end of the loop applies to our
example the code internally generated
for a numbers example looks like this
numbers of our range initialization
vector kindly provides us with two
members for beginning and end the next
step of the compiler would be to lick
look for a begin and end in the global
scope
the auto Rev iterator becomes the full
range declaration and we are basically
done by the way this version omits the
same code as the one the compiler
generates so I'm pretty sure it's the
same regardless of that these two
versions seem to be a little bit less
efficient than the standard for loop
that might come from the fact that we
have an additional variable here to
cache end but I don't know one or two
instructions more so was good
one thing which bothered me for some
time was effect that I must have an
iterator
which is never really iterated and
that's due to the declaration nature of
begin and end they both must be of the
same type and to be durable for the
iterator it must be type of iterator and
this implies that end must be of type
iterator as well even as is never
iterated we just need devalue luckily
this has changed with C++ 14 that's the
version from the standard of C++ 14 and
17 the difference between the two
versions is the way begin and end are
declared in CB of plus 14 this was part
of the for loop declaration so we had a
one-liner
this implies explained that begin and
end must be of the same type this
limitation was lifted with C++ 14 here
begin and end I'll be cleared outside of
the for loop but still within the curly
brace scope so they can be of different
types and that's not a potential that
end can be just an ordinary value with
no relations to the type iterator
all we need to get the still working is
in comparison operator to not equal
either in local or global scope when I
think about C++ 11 and its successors is
the ability to write such a small and
totally worthless but still well it
program here we have the lambda which
captures nothing takes no parameters has
an empty function body and it's executed
directly so a lot of nothing
nonetheless lambdas are an interesting
feature and I think it will take us a
couple of years to see all the
application areas where we apply them
best they are very powerful we can delay
their execution we can use them together
with templates to pass lambda objects to
other functions and we can execute them
there it's really powerful so to me they
nonetheless look tiny that example here
will probably be optimized the way
tomorrow will be happy but what do they
really cost we we write them in line
it's not so much we have to do for them
so to show you that here's a slightly
more useful lambda it showed us help to
see what's going on behind the scenes
let's see what it does it captures all
variables in scope as reference this
enables us in the next step to increment
X by one and the lambdas body in the
following line the lambda is executed
and that's it so it's not a most
sophisticated code but it illustrates
the lambda on the right side this is how
a lambda most likely looks from the
internal view of a compiler to be able
another this class
as a compiler defined name so we do not
need to care what's the type of the
lambda so it's unknown to us the
essential part is the function called
operator within the lambda our compiler
is so decent to created for us with
complete prototype and if necessary it
also declares all required variables we
like to keep trying away reference or
copy within the function called
operators body we find our actual code
we've written for the lambdas body but
default the function call operator is
marked as constant in case we like to be
able to change code inside lambda from a
captured variable we must make it
mutable they attributed it like that
this two versions generates the 99%
equal clang intermediate language output
there's the one thing I cannot give my
lambda the same name as the compiler
internally dust because it starts it's
variable sometimes within dollar sign or
just with numbers and there's a second
thing but that does not show up into
this to keep it simple to give it small
end to keep it as the original version I
made the member variable X public per
standard the compiler is required to
make all captured variables private it
would for me require constructor to do
that and it just blows up the code in
assembler output it boils down to a
pointer so it doesn't matter if you use
the reference here or a pointer in the
illustration example the compiler
internally treats a reference
Poynter this opens our view of it
because we now know it's a class and the
class is the constructor and a
destructor it's an object and the way we
capture values do also matter if we
capture by reference we increase the
size of the lambda by the natural size
of a reference an oil platform if you
capture by copying we increase the size
of our lambda by the type like a full
size of the type and maybe they are
memory allocations happening in the
background so it's probably not that
small as it looks in the first look
there are more lambdas on this slide
they are still simple in case a 2d the
variables are copy constructed only in E
and F we capture them by reference and
now if you take a close look and it's in
main
it's the first look the second look is
if you take a close look at all the
lambdas there none of them is invoked
none of them so I find it notable that
only be e and F generate an unused
variable warning induced will most
likely get optimized away all RS stay
around in your code they cause a
construction construction and
destruction every time you pass them
what happens there on a second sort of
logic the compile and optimizer cannot
see through what we are doing here for
bars it's a well it's used
when we capture something which alters
the outside world because we capture by
copy that changes something there's a
copy constructor involved or things like
that so they leave them in place so the
question is what's different with B why
the speed trigger an unused variable
warning to answer that let me first
raise another question what happens if
we capture all in scope that was the
first first thing which got me curious
when assembled over lambdas we capture
everything in scope that means also
global variables so doing that would
make a hell of lambda in a larger
codebase so we are lucky the compilers
are friends even if you say we capture
everything in scope the compilers are
decent for us to look in the body of the
lambda and capture only those variables
which we really use so this reduces the
size of lambda to the necessary parts
and that's the reason why B triggers an
unused variable warning because the body
of the lambda is empty and we say simply
that we like to capture everything in
scope by copy but the compiler finds out
that we do not use any variable in the
body of the lambda so it doesn't capture
anything that's why B triggers the
unused warning it's different for
example in the case of the lambda D for
D we explicitly name the variable we
like to capture by copy and that one
sticks if we name it the compiler takes
it in in the moment we name the
variables
it doesn't look in the body and optimize
it away so I consider that worth knowing
when dealing with lambdas because if
they stick around for debug purposes
they can hurt
next item structural bindings structure
bindings are a new feature coming will
C++ 17 or already there I'm not really
aware of C++ 17 is finally out the
drawer currently they are called
decomposition declarations in the
standard but there's already a proposal
which intends to change the name back to
the more widely used structured bindings
structure bindings enable us to access
multiple variables just with one single
statement they use the power of auto to
do that in this example we initialize
the variables X and epsilon which hold
the end variables from our point struct
X and epsilon the array notation gives
us a clue that we get more than one
values array syntax currently is
impossible and that's by design
to skip well use in-between like it's
possible this two-tire it uses two thick
nor for that it was decided for the
first draft of the for the first release
of structural bindings that shouldn't be
possible so how do they work internally
um everybody who was here for equalised
talked earlier this day got a claims on
that it's roughly the code generated by
the compiler first the temporary hidden
variable is created and this gets a lot
of PT or point aside afterwards the
compiler creates two variables X and
epsilon for us just as we asked the our
field of course was the value follow
points tracked the interesting part is
they are more like a reference
to the inside of our point of our
temporary and the whole magic of getting
the variable happens with yet yet looks
like a template which takes in
parameters and index ranging from 0 to n
n minus 1 we can also make the CAPTCHA
under variables the reference then we
add on the left side TM % what's
changing in the background is on the
right side that the temporary variable
which is created it's a reference then
to our point and there was a little bit
surprised when I first realized that
because I didn't think that there was
another variable constructed that means
that we have a copy construction
happening there in the background I was
under the impression that I get a copy
of X and epsilon and not that there is
another object resulting first so how
does the compiler do that to find the
decomposition the compiler takes three
steps first it checks if the object in
question is an array just a simple form
for it all elements are accessible by
default in the compiler knows their size
and all the other things very well in
the case it's no array the compiler
looks in step two for the simple tuple
size in the name space stood and in the
last and in the final step the compiler
checks is the object in question is a
class with only public members if none
of that is
true we cannot use structured bindings
this raised to concern to me that the
whole feature works only well with
public classes and from my point of view
that's not what the class for class is
to encapsulate stuff and not to give
world access so I asked myself how does
this work with classes with private
members and I came up with a solution
it's simple we just have to make the
compiler happy so for ads let's use an
example point class here nothing new I
just changed from in to double to
confuse you a little and because I think
it's the example of Scott Myers point
class and is most recent book effective
more in C++ so that's the base and how
do we make this class decomposable we
need to make the compiler happy and the
compiler is happy when it finds the
symbol called tuple five in the names
they stood for our class so let's give
it to him there are two ways
that's the naive one in this tuple sighs
the compiler looks for member value for
variable value the version one down is
the probably much better one because it
uses the standard library stood integral
constant and this brings all the
elements necessary with it so now we
have the symbol which tells the compiler
how many variables are in our class to
be decomposed and we need two more
template functions and the compiler uses
them to get the type of each variable it
tries to get out of our class in our
simple example
that's double for both cases so apply to
our example if you put it together now
it looks like that to create part is
from point from before and the colorized
palette is what you've seen on the slide
before so there's one thing missing and
that's to get itself
there's no get here so we need that
that's the version
we'll get get is a template function and
as we like to have access to our private
members it's within our class other
possibility would to provide it in
global namespace here is in our class
and it uses another very cool feature of
C++ 17d context per if this whole get is
completely constant expert it completely
happens at compile time we know the
index of the elements we like to access
and with the counts expert if we can
reduce the size of the function get to
only the necessary part in case of index
0 it's only return M epsilon in case of
index 1 its remember function call to
get X so that's that's cool that's nice
let's
crazy form moment let's say okay and now
we've did all that work but we like to
give out a reference to other internal
variable let's same epsilon that defeats
the purpose a little but let's do that
how do we do it
we have tackle type Auto putting prices
around the variable in combination with
deco type Auto gives us a reference so
that way we have also a function which
returns two different types first time a
double second time a reference to double
that's powerful let's come to a more
well-known feature what do we know about
static you have there for a long time
but what do we know about it there are
simple things they are roughly excuse me
there are roughly four application areas
a global variable can be marked as
static is that the lifetime of the
variable is extended to the end of the
program its goal is also reduced to the
current compile unit we can put static
on functions can mark them aesthetic
then their visibility is reduced to the
current compile unit
this gives the compiler by the way
potential for several optimizations
about a function the static can also
apply it to a member function in this
case the function exists without objects
the class itself it's one case we use
often and last but not least static can
be applied to function local variables
so you can have static local variables
within functions and there are a bit
special
they also have an extra paragraph and
standards
that's how are they are described their
local variables that's what a standard
defines I initialized the first time
control panel system and that's
especially the feature we liked about
them and I think why we use them so
let's focus on that
how does this work the words in the
standard are pretty simple especially
for us developers I like them it's the
job of the compile I do not need to know
but I like to know so how does it do
that even a compiler needs to keep track
of which variable was initialized which
not so if this information needs to be
stored somewhere cannot come from
nothing to keep track the compiler in
this conceptual code only the compiler
introduces a new additional and for us
hidden variable let's call it compiler
computed given the compilers generous
with our with us it uses a rule for its
type which is set to false by default
next the compiler
dissects our static variable a bit
instead of writing it as we would do it
reserves part of memory with the size of
our object we like in addition it
introduces in you if this one uses the
variable generated by the compiler to
detect whether the variable was
initialized or our static was
initialized or not and in case we passed
that if the first time the compiler
that's the conceptual part I'm not sure
but calls the placement you to invoke
the constructor of the class and we are
fine afterwards the compiler that's its
own variable to true the order here is
important because the standard also
requires that we get a do-over
in case the initialization of our static
sales the constructor throat's you
should be able to pass that function
again and again and hope that it will
work after some time or the second time
maybe so to maintain the exception
safety the order is important the
variable is set to true after we
successfully constructed our object so
this static cost headaches for many
developers over the year against the
years as you can see there's absolutely
no thread safety available and that's
the best version of the static you can
get the ones where you handle pointers
and you knew yourself
there are worse so that's the best one
since years we are looking for methods
to guard the section against concurrent
access and the really good news is since
C++ 11 we no longer need to take pain
pills
this single sentence is a game changer
as part of C++ 11 it changed our world
for static if control enters the
declaration concurrently while the
variable is being initialized the
concurrent execution shall wait for
completion of the initialization
beautiful now this nasty locking part is
child of the compiler let it deal with
it go home wonderful huh thread safe
that's not sound easy task for us all
the time though how does the compiler do
it
based on the example from before our
bull increases slightly to an integer
the low abide of the enterprise still
used as a bull to keep track of the
initialization state the remaining parts
are used as mutex or atomic lock that
depends on implementation so we also got
in not a new if this uses a function
called seeks our god choir and we have
the six our god release afterwards and
they both take this compiler computed
variable behind mainly the SIG's Angad
acquire function happens love magic it
depends on the configuration for example
of your Jesus EEG plus plus or clang
what they believe or what you have
configured them what is your threading
environment they either use and meet X
or the last resort fallback they use
Atomics to guard the section and there
are also kinds of us because the
operation with some costs may be slow it
may be delayed to get deadlock so this
is only done in the case the variable is
really not initialized in all other
circumstances we are fast so that's
wonderful
we've got that out of our back we can be
happy we have thread side statics now
I'm in the embedded field I know a
couple of operating systems which are
rather small which are not Linux based
there are four tiny processors there are
environments where you have your own
locks you know exactly what you're doing
your static is already guarded because
you need to guard a much larger section
there are also environments where your
single threaded just one thread doesn't
require a lock so but now the compiler
throws in this lock that's good for all
the people working in an illustrated
environment but for the ones in a single
threaded environment or for dudes who
are controlling their environment
precisely I don't know the interesting
thing is Jesus he generates code like
this since 2005 it was just not usable
that much for us because it was only TCC
and it was a gvc specific enhancement so
it was not cross platform across
compiler compatible and when they
introduced this feature there is a kind
to add an option F no thread safe
statics to make it go away
so that's the solution I hope or a
compiler rentals provide as well there's
a dirty heck you can do at least for
clang and GCC the symbol seeks our guard
acquire and seeks our God release are
intended to be overwritten by your
standard library so the compiler
provides them only if there is no
existing symbol for that so really dirty
trick is just widen yourself and
implement them empty
and they will go away but it's just if
you're controlling your environment and
you know in what you're doing this also
applies only if we are dealing this
object and to be specific objects with a
non-trivial constructor of a destructor
let's switch here we have this singleton
still we have the static in there and a
bit more complex I take an instance of
that singleton it has a set and a get
now and in the set I pass arc C and
that's just to get the optimizer off my
back I don't like this path to getting
optimized away and then I return the get
but it's all and that's a good one
because that's a class with trivial
destructor and drivel constructor we
will have no lock there from the
compiler because it doesn't matter for
us we cannot see if this code is
initialized the first time we pass it in
a function or at the start of the
program doesn't matter what's missing
here is we've written so much code to
have this singleton and where's the
constructor the constructors the default
constructor and that's public so we have
the potential to have several singleton
which defeats the purpose of the name
singleton we can fix that and then
attempt to fix that is to make the
constructor private so we're defining it
ourselves this gives us also the
potential to initialize X to well-known
value and at the point where we end up
with the locks again because now we've
provided our own constructor the class
is no longer travels from the
perspective of the compiler it will
start generating the locks
we provided the code so it's on us to
know what we are doing we cannot work
around that with the equals default we
can say yes please we like to have our
constructor in the private section but
compiler please do provide
implementation discounts a struggle for
the compiler so we will have no logs
they are introduced by the compiler of
course the same thing is possible for
the destructor we can do it in the less
efficient way by providing the empty
curly braces then it's a constructor
provided by us with code by us even if
we have not really written code there we
can fix that with the equals default
that works too it stops working if for
some reason we declare the destructor
workship if we have some application
where our singleton needs to be a base
class for something even the equal
default does not help us in this case if
we have a virtual destructor
even if defaulted it is a non-trivial
object for the compiler and with it and
it will generate the logs for us so
that's all for my site my name is Andrea
Ferris being a pleasure giving a talk to
you today I'll be around for questions
either I think we have about three
minutes for questions here or at the
conference I'm here till Friday have a
nice lunch in case you have no questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>