<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building for Alexa with Web API - Heather Downing | Coder Coacher - Coaching Coders</title><meta content="Building for Alexa with Web API - Heather Downing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building for Alexa with Web API - Heather Downing</b></h2><h5 class="post__date">2017-09-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NaByhM0KjAI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks for coming all the way over here
to listen to an American talk about
something that you don't have yet I
appreciate it it's it is coming you can
play with it but I've been fortunate
enough to play around with Alexa for
just the past eight months in addition
to other voice assistant work I do with
Google and Cortana and this is such a
lot of fun
it is very developer friendly and since
I'm a dotnet dev I thought we can can we
interface with this and extend the kind
of stuff that we normally have so that's
kind of why I decided to play around
with it and now I've done over fourteen
different prototypes from very very
large companies in the world to kind of
show them what they can do with it and
I'm having a great time so I thought why
not share it with all of you right if
you haven't met me before my name is
Heather downing I do a little bit of
everything there's what we say I'm a
technologist so in this instance I do a
whole bunch of work around mobile I do
quite a bit of API work and of course
any sort of device driven development I
also do hobbies on the side I'm a
horseback archery competitor as well as
semi-professional photographer so if any
of y'all would like a picture afterwards
let me know and I promise to you I will
give you the best try all right so the
reason that we wanted to drive this home
to developers is because of this right
here everybody familiar with what
Gartner is yes excellent they predicted
by 2018 thirty percent of our
interactions with technology will be
through conversations with smart
machines that's pretty specific that's
just a right around the corner a few
months from now and that's the whole
world and not just the US and there are
over 12,000 skills available currently
in the Amazon alexis store that's huge
that's enormous
unfortunately 69% of them have won or no
reviews one-star low reviews terrible
experiences I'm sure you've probably
gone through that before but
in case you haven't there's actually a
very famous skit from Saturday Night
Live that kind of goes into how funny it
can be to interact with a voice
assistant and have it not really
understand what it is you want or what
is you're trying to accomplish and so
just to kind of put things into a user
perspective for all of you here's an
example of one of those reviews this
poor guy just wanted to lock his doors
and check to see if they weren't locked
and he was smart enough to know now not
most users are not this aware he was
smart enough to know that the company
that made his car didn't have enough
foresight to think maybe we just want to
check to see if your doors locked to not
lock it again and again and again and
again and again what this is is a
fantastic tool with lazy development
that is really what it is because at the
end of the day we have all the power if
somebody who is non-technical whether
your boss your client or what have you
ask you is this possible and your answer
is no they will believe you because they
are not the technical person so if you
say no happy path that's it done then
this is what happens right so I'm here
to kind of persuade you into pieces I'm
gonna go over what it means to develop
for the voice world so it's a little bit
of design a little bit of intuition
there and then we're actually going to
go and code one at the very end here
sound good good deal
so why should you even build for voice
if you're at a larger company that maybe
it's a bank or insurance company that
maybe doesn't do a fun startup why would
you even care about this you should
absolutely care about this because the
longer lasting products have tapped in
to the basic utility that when applied
with this new kind of technology made
life better in some way and a good
example of this is maybe frequently
asked questions we all hate that static
page we hate that thing and it guess who
else hates it our users users don't like
it especially if it's buried under menus
and menus and collapse and sub menus and
by the time you finally find what the
answer is to your tax question you're
exhausted just trying to get to that
answer this is where voice can really
shine because then you somebody could
just ask the darn question and get the
darn answer that is where it shines
through it makes it better it's
certainly not something I would choose
to do for a long form kind of
interaction because nobody wants to
rattle off every single piece of their
personal details for 20 minutes with a
voice assistant that's not very fun
and it would be better if maybe I use
something tactile for that but when it
comes to accessibility it's a really big
to understand that there are plenty of
people in the world without sight okay
so this works really well for them in
addition to people who just are not tech
savvy so my mom really dislikes mobile
apps and I'm a mobile developer so this
is the one place that we met in the
middle is that she didn't have to be
trained how to talk she knew how to just
start having a conversation and she
didn't know where to find this in the
uber app like that was hard for her but
she could just ask a question and my
Google assistant took care of it for her
and she liked that interface and so this
is going to become more and more a part
of our lives as developers and it's
important that we understand why so we
don't grumble too much about it and
instead embrace it and put it as another
tool in our tool Bo so let's talk about
the approach Paul Grice is considered
the grandfather of NLP a voice design
and when it comes to communication okay
he said there's only four things that
matter when you're communicating the
quality of what you're saying how brief
you are the relevance of what it is and
how clear you are even if you're talking
to somebody in another culture in
another country that maybe doesn't have
the same life experiences as you as long
as you stick to these four you're
probably communicating well now we are a
tremendous group of talented people that
are not very good at communicating so
that's why I decided to put a couple of
things in here
because it matters because at the end of
the day we're the ones developing the
conversation that brings me to the
co-operative principle has anybody heard
of this before no great fresh ears
alright this is an example maybe of what
the happy path versus a cooperative path
might look like we are used to something
on the left the user here asked to set
an alarm the UI says it's normal
response that your user gives every
single piece of detail that you need in
order to carry out your function and
then you get a response to the user but
in reality that doesn't often happen
especially when people are talking to
these devices when they are distracted
like when they're trying to cook dinner
or they're trying to wrangle their
children or they're trying to run around
the house they're going to forget to
give you pieces of data so and the happy
path you basically would tell them that
they are an exception like in a bad way
you are an exception I can't handle a
huge error no the problem is there's not
really errors in conversation in reality
there's misunderstandings and when
there's misunderstandings
it isn't unnecessarily a
misunderstanding of the entire statement
maybe only a piece of it that's reality
right you might get this this and this
of what I just said but maybe not that
part right
so if we retain context as we go of the
things we did understand that's
cooperative that's a cooperative
conversation and so that's why this
exchange is better your user sets says
they want to set an alarm
you give your normal response and they
only give a piece of information in this
case it would be one of the parameters
that you need to carry out your function
and instead of putting up a I didn't
understand what you said you retain that
and acknowledge that the user gave you
some data and just ask for the next
piece instead of making them repeat it
all over again because it's very clunky
to do that this is how we should be
coding it's very important that we
embrace this concept so that way it
feels like a natural conversation that
brings me to one of my favorite parts of
this whole thing which is conversational
implicature
isn't that fun kind of go something like
this
Jacob says I really need a drink and
Todd says have you been to the Scotsman
that's the end of the conversation right
there's a lot implied there what's being
implied is that this particular
establishment serves drinks they happen
to be alcoholic because of the tone of
whist
so prefer businesses nearby and it's a
place where I might like because I was
also standing in the room when Jacob
said that and so I was included in the
answer by a human being because they
could see that I was there so there's so
much that happens here this is aware
voice breaks down for us because we're
like we don't have eyes we don't know
that there's another person in the room
there's no way that we can apply all
these things oh but you can absolutely
you can this is important especially as
we start to anticipate things for users
so instead of asking them the same
questions over and over like where are
you maybe you retain that information
maybe you start to build a profile
outside of this skill about your user so
you don't have to ask a whole bunch of
additional questions because how this
might go would be okay look so tell me
where to get a drink
okay where do you want to get a drink
Sydney okay do you want a juice bar do
you why in a bar do you want what kind
of what do you want then it goes on and
on and on and it's very cumbersome but
if I only really ask that question on
Fridays and Saturdays after 8 p.m.
there might be something implied there
it's possible now it is culturally based
so please understand what somebody does
in India is not what somebody does in
the US it was somebody doesn't Australia
is apparently not what some people do in
New Zealand and so you know there's a
lot that you have to consider so voice
is also culturally based and you will do
a skill / culture if you're interested
in the documentation of what we're going
over today you can head on over to
developer amazon.com / Alexa and it's
all there ready for you to go this is a
wonderful thing that changes
approximately every three to four weeks
so make sure that you visit often so
let's say I
convinced you and we want to build the
skill there's actually several more that
have come out in the past few months are
the ones that I want to differentiate
are these three flash briefing is
something that's like an RSS feed that's
spoken by Alexa along with every other
RSS feed in on a daily basis okay so
this works really well on something like
a twee angry tweet of the day you know
reading that out maybe that would be a
great skill for you to build just to
play with it and it's just something
that comes to the user it's just part of
the batch of their morning routine then
there's a smart home skill now it's
called smart home but what this really
means is that you will use Alexa to
interface with something and she doesn't
need to speak back to you
you just need to control the actual
device and it could be anything it could
be something that's already predisposed
to this like maybe a blue cheese light
bulb or one of several different garage
and window openers or it could be a
Raspberry Pi that's hooked up to
something else
so this is a smart home skill works
really well for that and there's more
and more devices that are growing every
day but you can always build your own
but when we're gonna focus on is a
custom skill a custom skill is takes up
the majority of the skills that you see
inside of the Alexa store and it kind of
goes like this you know these are asks a
question and then Alexis Alexis
processes look at it so Alexa is powered
by Lex isn't that fun Lex is the NLP
processor that Amazon owns it's very
very good
it makes conversation a lot easier and
there are many other competitors but
this part they do extremely well and so
yes we can absolutely do NLP on our own
but that would take way more than the
time that I have to show you today so
let's like suffice it to say somebody
has solved NLP for us and gave an given
us an endpoint in which to interact with
right so now the interesting stuff
begins now we can apply our business
logic to it and go from there and that's
what we do in that third box over there
is that
you get to have a service that or a
function that handles whatever the
request is and sends it back in a
specific JSON format over to Alexa and
then Alexa will then speak it to the
user
additionally underneath it as an option
there is an app that goes along with
with Alexa that allows you to do
summaries or screens you can have videos
in there you can have it's completely
tailored in HTML and CSS and look really
nice it can be back and forth per
request or just for the whole session so
there are additional things you can also
push out to the app this is a great that
right here actually allowed me to
discover that my 11 year old
across-the-street neighbor I say across
the street I live in an apartment
building walls are thin and it's not a
very big hallway that would come up
apparently to my front door which is
where my echo is sitting and shout
through the door I had my device and get
what the weather was today and I and
eventually it understood what she was
saying and she has a very heavy accent
being from Afghanistan okay it's very
very heavy but it only took a couple of
times for our sub profile to be created
for her and so it got to be faster and
faster to respond to her and every time
she would do it I mean it doesn't like
Bing me or anything but I would just
kind of looks the app going Oh Mari as I
use my echo today you know you can sell
and so that's really what that's for is
like an additional recall it's great for
recipes if you if you don't want the
users have to remember everything and
you want to have it be written down this
is given to you for free and all of the
echoed device owners have it so let's
talk about the components - what a skill
is the first one is intense this is an
intense subject and basically it's just
events and this is true across any sort
of voice assistant work that you do this
is the intention that you're trying to
fulfill okay kind of looks like this
coming over from Alexa when they sends
it over and hits your endpoint this is
the data that you will see for that
it'll have a name of the intent which is
basically
the event that you're trying to tie to a
function okay it doesn't have a whole
lot here notice that there could be more
than one slot of data that means that
something that you need from the user
like remember how we went over the happy
path which is the co-operative path
maybe this is the time of day maybe it's
their name maybe its location what have
you this is an array that can hold all
of that for you
then there's sample utterances now
utterances in general are used across
the board for some reason it was I
wanted to call it sample utterances
because really what it's doing is some
fuzzy logic if you don't say exactly
what one of the sentences are but it's
close it will basically try to figure it
out for you it might be wrong and send
it to the wrong intent but he will try
so it's important that we train just
like machine learning train a model for
what it is we want to do and did you
know how many different ways there are
to say hello it depends on where you're
from how fast you say it and what have
you so there can be many many many
versions of an utterance to invoke one
intent which is of course a function
example just asking the time it could be
any one of these things and it and the
more that you add the better it becomes
the better it is across the board for
more than one person now the reality is
if this is in a home it's probably
you're probably only gonna say it one
way because you get used to it but it's
great for parties when you have all your
friends over and she doesn't respond to
anybody but the user who that has it in
their home because they're used to just
saying one thing so if you want to be
able to make this fun for like a game
you may be some sort of trivia game that
you play with multiple people it's
important that you have different ways
to say what it is you want to do then
there's the invocation name so this is
the important part that people always
ask me do we have to have this part it's
so cumbersome but yes how many different
websites do you think there is for
whether I mean so if you ask her what is
the whether she has a default on there
that Amazon gives you for free that's
defaulted to Noah okay
that's the weather that
pulls it from but if I was to build a
weather skill based around what the
weather is like for the Eclipse that's
coming up in a couple of days who which
skills are we talking to you
there is only 55 Alexa skills based on
the Eclipse so which one and this is
where the invocation name comes in this
is your domain name this is your DNS
okay right here is that this is what is
used to identify your skill and in the
future it'll become more commonplace it
isn't an option right now but eventually
you will be able to start to default to
certain skills that you want but it
isn't possible right now but probably
will be by next year and of course your
cloud service so when I say service what
I'm really talking about is all the
business logic it's where it lives it
doesn't have to be a formal web service
it could be you know BW s lambda
function they would love for you to do
that and so you certainly can as long it
could be firebase you could decide what
you want to do one of the most fun
projects I had seen is somebody who
controlled their slides during the
presentation through who LexA it was
fantastic and they did that directly
through firebase so there's lots of ways
you can connect it and that's what I
mean when I talk about cloud services
but for our purposes we mean a sure
something on Azure called Web API and
then of course portal configuration
you'll spend more time here than you
thought possible and that's because this
is where it all comes together where the
rubber meets the road that means this is
the place where you will put your schema
of intense that means these are the
intended behaviors I have and then they
will be mapped to all those utterances
and the more the merrier
the average skill has over 300
utterances that maps to maybe seven to
eight intents okay because they're
trying to cover their bases when people
are saying things partially or
what-have-you
this also controls the publishing of
your skill and allows you to put
information in like your Terms of
Service in your contract then though
these visual components that I talked
about earlier this is kind of what it
would look like this is the default UI
if you don't really want to mess too
much with the visual end of it because
I'm a back-end developer and I can't CSS
this is kind of what you get by default
it's pretty nice pretty clean and you
can just send it directly in this is
kind of what it looks like or maybe you
get fancy okay maybe you want to not
only have her speak and return but have
a tethered screen so this example here
on the slide is goodness' which is
Nestle the company Nestle and they
wanted to do some sort of healthy eating
website and they wanted to predict
whether or not you are at home cooking
with it just looking at it on the go or
you weren't anywhere near a computer but
you wanted to use the echo so the way
that they did this is with WebSockets so
they did for this so they use signal R
and pushed it out anytime somebody asked
you know give me a recipe about blank
then this would not only answer the
question but show the options on the
screen at the same time it's very very
cool it's a great thing to do we did
this in Kansas City the Kansas City
developer conference and it was a huge
hit because instead of waiting for the
scrolling out there to see when a
specific speaker or session was going to
go you could just ask the question and
it pulled it up for you no touching of
the screen required it's pretty fun to
do there's a lot that you can do here
with kids especially when it comes to
building a story time thing or build
your choose-your-own-adventure kind of a
concept I'm sorry what yeah yeah so the
echo show I will talk to you about at
the very end but this has to do with
just a screen somewhere else that is
listening for you to push data through a
WebSocket okay right and of course
here's our cloud-based service and these
are the requirements as they stand today
it will probably change tomorrow but
this is the thing all right now you're
welcome to look at this I'll put my
slide up later for you guys but
basically what it means is this yet you
can't have a skill that doesn't make
sense to a user and they have an entire
team that will try to break it for you
it's kind of nice
is that way I don't have to hire people
to do this for me no I'm kidding you
should test your stuff before you send
it into Amazon it's actually more
difficult to get a skill through Amazon
that it is through the apples store so
just keep that in mind and this is why
to a user this is Alexa it's not you
it's not your skill it's this so they
don't want you tomorrow the experience
of their user if it's bad if it's a bad
experience and so they try to break it
so that's basically what that means you
have to make sure you can hit the
Internet at all times so make sure that
your service is always on you need to
make sure that it's secure and we'll go
into that a little bit you know and also
make sure you validate that all the
requests coming in are from Alexa and
not somebody else that brings me to
custom slots and built-in intents so
this is kind of what that structure
looks like is you're trying to go
through and decide what it is you're
going to say the name of your intent and
maybe your utterance and then there's
what we call slots and that's just it
could be a predefined list of things
they could say like in this case it
would be Virgo or Leo or Sagittarius and
not necessarily surfing okay you can do
that or you can make it kind of an
open-ended slot and that means you have
to train it a little more but that means
you can take in just a little part of a
sentence all the way up to about eight
or nine words so let's take a look at
what this portal thing looks like shall
we all right so whenever you go to
developer amazon.com and click on alexa
you will go into the alexa skills kit
and these are examples of some of the
skills that I've played with of course
one that I'm really fond of is my L cars
skill does anybody know what L car
stands for nope does anybody know what L
cars is yes
yes it is the Star Trek ship computer
name and there's an entire suite of
images and sounds that you can get from
the internet completely free and I'm a
huge Star Trek geek and so I decided
that I wanted to talk to her just like
Captain Picard could talk to the
computer onboard the ship and so that's
what I built here and this is kind of
pre-populated to make it easier for you
and so this is just the name this would
be the invocation name right here on the
front notice how even though it's an
abbreviation I thought it would be
easier to kind of spell it out
phonetically you don't always have to do
that and in in the case of what we're
gonna build you would maybe use just
period after it to indicate that that's
what it is it just seems to work better
when I make it sound like something
Spanish alright so down here at the
bottom you see there's audio player
video app and rendering template earlier
I had a question about the echo show it
uses a rendering template for that and
that's an additional device that it came
out this year but for our purposes for
this custom skill we don't need to do
any of these but just know that they are
there as options okay all right that
leads us to our interaction model page
you will spend the most time here you
can also play around with their skill
builder it's in beta right now but if
you're just like me and you just kind of
want to take the file that's important
to just paste it where it needs to go
this is your friend so right here is
your intent schema notice how is a list
of intent some of them have slots and
some of them do not this is where you
indicate what that is and this is what
Alexa uses while parsing NLP in order to
route the request to the correct intent
okay over here is custom slot types
here's the example of just your own data
type okay in this case all of these are
a list that you're allowed to choose
from you're not allowed to choose from
anything else but this list if you want
it to edit it you just hit edit and then
you can put in whatever you'd like here
okay
and here our sample utterances notice
how many different ways to say hello I
put in there here on the left is that is
the name of your intent and then after
that is that one-to-many relationship so
this is how it parses through all the
intents and sees if they can match up at
all okay all right so now that we've
looked at this let's look at the
configuration page itself in this case
on the endpoint notice that that you can
put recommended for you to use aw is
lambda but I found in a speed test that
I sure was faster so you know that may
change you'd never know but I found it
was faster and so I decided to just host
it on my own service on a sure and this
just said to pick the geographic region
that's closest to your target customers
now right now we have North America and
Europe but we all know that most of us
three came over to Australia and they're
going to be adding more and more Germany
was also added as an additional language
so she can speak in German as well and
of course if I choose UK then she has a
lovely British accent but because I'm
American I'm gonna leave it with an
American accent and here is a count
linking this is the important part where
you're able to link your own separate
federated profiles with whatever a
profile is on this device by this user
and we don't have to do that for this
skill but just know that this is where
you would enable that and that requires
the user to consent whenever they enable
a skill okay
and of course additional permissions so
as of right now if the user registered
their device with an address instead of
you asking them all the time where are
you maybe you can get that directly and
just handle it from there a lot of users
don't register it but it's nice if it's
there maybe you can check for it and
this is also their list for a reads and
lists for write this is a list where you
just say Alexa add this to my shopping
list or add this to this list or
whatever it is this gives you access to
that core list feature if you need it
maybe you just need to read from it
maybe you need to give it maybe you want
to do some sort
hey what is my wife over her birthday
and I know that she keeps us list with
LexA maybe I'll just you know have
suggestions maybe that's a good
suggestion skill somebody should build
that and then once you've checked all
the boxes we go down to security now
because we've chosen assure our
development endpoint is a subdomain of a
domain that it has a wealth card
certificate from a verified certificate
authority so we don't have to worry
about rolling our own you certainly can
but it's nice to not have to and then
once you've checked all those boxes off
your skill is now enabled to test yay
right there are two things you can look
at here if you don't own one of these
devices this is a great place to know
how it sounds to do anything so maybe
you could just say hello and then listen
to it and then you can hear what her
voice would sound like okay but what we
find is the most interesting is this
part say in an utterance and seeing if
you get anything in responses if I say
hi I now can see the JSON that's sent
and also that's in reply okay really
important you can go directly to JSON
and do that on this tab as well but I
just found that this is easier and then
down here at the bottom yes she'll
actually respond right you can listen to
the whole point and right down here is
kind of a little bit of a example of
what it would look like in the card
because and that's all I sent is
whatever the text was I just sent that
to the card and that's a good way to do
it so this is pretty much what it takes
for you to just get rolling and play
with it immediately the great thing is
is if you do have one of these devices
and you log in with that same account to
the developer portal you're
automatically enabled to use the skill
it's yours to test immediately and you
don't actually ever have to publish it
if you don't want to you can just use it
at your house I do that all the time
I hear I love to create skills with kids
and so this is what we do is they eat
their own and they can use it the whole
day it always works on this device
because this device is signed
to my developer count all right so
that's just something to keep in mind if
you decide you don't want to open your
school up to the rest of the world this
is a great that they already have that
enabled but should you be interested in
publishing then you'd have to register
it with a whole bunch of information
like the description
what kind of interaction it is that even
give you sample phrases they're pretty
helpful in this regard it also shows
that you have to update any of the icons
that will be shown a near lexa app and
also in the Alexus store the user may
never see the icon once they interact
with it but it's required nonetheless
and of course privacy and compliance we
tend to forget this part if you are
working on a skill with a team this is
great for the project manager to go do
with the client saying hey while I build
this why don't you put together a
privacy policy in a Terms of Service and
I can link that I can link it to that's
great for them to do all right so now
that we have done all of this I think
I've done the portal tour let's look at
a code example shall we alright
yes I'm running a VM on aback all right
please be my friend no
yes okay exciting all right so now what
we had just done we could have done just
in my good old friend here right we
could have just tested that whole thing
now that looks very large we could have
just tested this whole thing museum like
fiddler or something else like that but
it's just kind of nice and convenient
that it's built into the portal for us
especially since we have all the other
tools and how she sounds kind of at our
fingertips here all right so it's
important to note has anybody in here
not familiar with what it's like to
publish on Azure awesome don't have to
go over that great so basically when I
set up this new scale oh my goodness
it's just a little large hair mm-hmm
okay well mm-hmm okay that's crazy yeah
yeah maybe not you go to 720 thank you
nope sorry this guy's I'm like what is
happening this was that where we were
before right we're just gonna go through
this it's gonna be fun all right
any other guesses this one I don't know
this still looks rather big all right
why not let's just try the bigger
biggest wanna see what happens okay
that's better you can all see that then
clearly good deal all right
so basically all I did was do a file new
project right which we can do here so
I'm gonna go ahead and close that
solution and do that here so if I'm just
starting out a new project you can
decide whatever it is this looks so
strange all right hopefully you can
still follow along since you're all
smart and you involved on the sanaa sure
before we can call this whatever we'd
like so how about just NDC Sydney all
right and I decided that I want to go
ahead and do Web API project I initially
check hosts in the cloud so I can just
set all that up right now and I don't
have to worry about this at all and in
this case this is a very very ugly URL
don't like it gonna change it all right
so for my purposes I actually set this
up in the West US but it actually works
just fine here and I have a plan in
Australia East here see whoo all right
okay and so I think Oh somebody somebody
else took that oh that's terrible
let's try that yes no one has it all
right so now while it's setting that up
I can go ahead and just grab into Web
API there's three things that we need
just to get this to run and that is your
intent schema remember sample utterances
and you need to put just a basic let's
see if we can hit the endpoint and get
her to say something okay I will do this
in a couple of in a couple of ways all
right
so here yeah we have a new intended
application we're excited and while that
it's loading there we go right so here's
our intent schema okay this is all you
need right here there's an important
part here is to know that we have to
overload some of the help the stop and
the cancel intense they expect you to
customize this to whatever it is you
want to do with it but it's important
that you implement it so this is how we
would implement something that's already
defaulted by using the Amazon namespace
and referring to the intent and this is
our neat HelloWorld intent hooray right
so then you would copy this and you
would go back out to our portal here
there we go
our NDC Sydney portal here and then you
would go to the interaction model right
and just paste it right in here okay the
next thing that we need to do is get all
the sample utterances that I've got
right there okay and that's all you need
there next you'd go to the configuration
and whenever they decide to give you
that lovely URL you'd put it right here
and in this case I went ahead and
already pre-built this demo to hit with
SML okay ice SML is sweet since this is
a markup language it's fun it's been out
for about ten years and I've got a slide
deck to help you out with that in just a
little bit so all we need to do is set
that up there and then we are good to
test so if you want to you could again
do this in Fiddler or whatever you'd
like or you can just use the page so in
this case I just want to know that I can
hit it
right let me just hit this it could be I
don't know right I just want to know
that I can hit it so this would be where
you would do that alright so now that
we're all built up here I swear this
looked great right before you walked in
what we need to do here is add an Alexa
controller okay so we're going to add
that and it's just an empty control it's
all we need
that's like sound crazy alright and then
I've got that set up here already okay
there's a couple of things going on here
that I wanted to point out to you all
I'm doing here is a hello world I just
want to know that I can hit it and she
can say something clearly this is not
best practices if you're going to be
building a skill it's just hard good
everything in here with the dynamic
object but I still want to show you the
minimum amount that Alexa needs in order
to do her job okay so we have to put a
version in there of your skill at the
time you have to even if it's just empty
you have to send it whether or not you
have want any session attributes that
are set session attributes are the one
little gift that Amazon gives us so
right now this is a stateless kind of an
interaction okay so this is the one
little piece of state that they give you
you're allowed to put anything you want
in here and it's only alive during this
session okay so you can decide it's just
a key value pairs dictionary shove
things in there and then reference them
later okay I actually that's a great way
to determine whether or not somebody has
is on step one over there recipe or Step
five and then of course Alexa goes to
sleep because it takes you 10 minutes to
make cookie dough all right so when you
just say I like to what what is the next
step in my recipe you don't have to like
look it up you can just be like oh
here's your next step that's a great
place to put it as an accession
attribute to go this is the last step
that was done okay in this case the
response object is what is needed you
need to at least outline a basic card
and the type and the text for what you
want her to say okay so there's a couple
of different types you can do the one
prebuilt for this was an SS ml type but
in this case this is just plain text
this is an easiest way to get started
it's just plain text literally read the
string please this is interesting
because if you decide that you want to
use some sort of data from somewhere
else like Twitter emoticons are not
spoken so you have to scrub that data
before you give it to her this is a
literal say this exact phrase okay so
you have to be careful there's a whole
bunch of extra codes everywhere she will
just stick nortz or she will crush okay
depends on on what it is okay and then
this down here is important should end
session that means that her little ring
will immediately stop after she's
delivered the result okay this is what
they look for when they whether or not
they approve a skill or not in the store
so they said once you've given somebody
value you remember those four Maxim's
once you've given somebody value be done
right but maybe you're not maybe it's a
three-step process maybe you ask a
question you get a little more
information then you need to keep that
session alive so that means that that
might be a false but for our purposes
it's not so this is basically all you
need to slap into our controller okay
- this is all you need for that and as
long as I save it and then I right click
publish you know - to Azure as long as
I've got that endpoint then we can give
it a go right so you can either test it
here and see that she actually did give
something back and you can have her
speak it here or if it's connected you
can say Alexa asked NDC Sydney to say
hello hello Aussies great so we
basically just built that in ten minutes
sends my weird resolution right that was
that quick to do now you could certainly
go far out from here and do way more and
for our purposes I want to go back to my
slide deck here and kind of talk about
debugging okay yeah a debugging so this
looked great we basically deployed it to
production and made it work right what
about debugging can we do it locally no
cannot do it locally this is a service
driven device and there is no way for me
to plug directly into it and mess with
it it has to be somewhere it has to
reach out to the Internet in order to
get this information okay which is
really fun to do whenever she says
there's a problem with the requested
skills response you hear that often
which means you've got an exception okay
and so when that occurs this is where
Asha really shines because we've got
remote debugging right who here has
never heard of remote debugging great
see you guys are so far ahead of the
curve so I can tell you that this is
where I would just set a breakpoint
start talking to her or go ahead and use
my simulator and immediately catch what
the heck is going on so that's what you
can do here and it that's what kind of
makes it a little bit better from doing
this on AWS in case you didn't know this
is kind of how you do it you publish and
then BAM you can hit it yeah
so this is all it really exciting right
but what about expression cuz right now
she sounds pretty cool but how do you
get more expressive right there are some
amazing things that can be done with
speech synthesis markup okay so who here
has heard of speech synthesis market
before yeah okay so a couple of you so
that means some people have messed
around with skills I like it it's really
fun this is an example of one think
about it as HTML CSS for the voice
that's the best way I can describe it it
allows you to tell her how to interpret
things and right now you can even make
her whisper you can make her yell you
can slow the pitch down to where she
sounds Mayo you can do all these things
it's kind of amazing you can spend a lot
of time here this is a great place for a
front-end developer to also spend their
time when there's no visual UI is to do
see how much they can massage or maybe
it's you massage how she sounds can you
make her sound sarcastic can you make
her sound happy can you make her sound
angry all these things you can also have
her spell things out whenever they come
in so it makes it really fun to play
with if you're interested in the spec
for that it's out on w3.org and again I
will go ahead and throw that deck up at
the very end of the session so an
example of expressive code might be here
so notice here where it says the type is
SS ml right down here okay right here it
just plays an additional audio file as
an owl makes it possible for Alexa to do
that to interpret it that way or we can
go ahead and mess with maybe my elk ours
example right so out on github I
actually have the entire skill available
for you to to fork and do what you like
with this is a complete skill so that
means it would pass the
Publishing tests and in here it kind of
tells you what it is that it covers and
a sample conversation okay
so in this case no I could say Alexa
start L cars hello this is starship USS
Enterprise how are you feeling
well well booyah so that's an example
have you seen a speech Conn it's like an
emoticon please say options if you need
a list of commands cancel acknowledged
good and you can play with us all day it
is great to go back and forth with it
and this is of course just kind of tells
you what you should expect in the sample
conversation it's lots of fun if you're
interested go to github.com slash
coralline and it is one of the very
first ones on the list here okay got it
alright so now you kind of seen that
example let's kind of wrap things up
with some additional references okay
intent sequencing this is really
important remember how we talked about
this is stateless which is how you
should write your api's right sorry if
you guys should be stateless depends on
the situation but Alexa definitely is
she remembers nothing so it's important
that we take care of that if you're
interested in how to sequence it well
this is a great blog post if free/busy
came out with and if you want to even
play even more with the audio around SSM
l also another great one and again just
pointed out my old cars example skill
out on github and the last one is really
interesting so we know that google
assistant is one of the major
competitors for alexa right now please
understand I love all NLP I love all
voice there's a lot of great things that
Google does a lot of great things Amazon
dust and Cortana as well but when it
comes to voice design James G Angola
just blew us away at Google i/o talking
about what that means and he goes into
the kinds of conversations remember we
talked about conversational implicature
right all those different things it is
excellent it's well worth watching it's
only an hour and
the time the person who inspired me to
even start was Walter Quezada who is a
great plural sight author and he did
this exact kind of implementation of
what it meant to develop an Alexa skill
in the.net space right and so that was
done last year and I've since just built
on it from there but he is a great one
to follow there if you're interested in
the slides there's the bitly of my
slides so you can go ahead and grab that
but I think one of the most important
things I kind of take away from this is
that you need to keep your skills short
and to the point okay this is a huge
deal remember
the reviews we need this to be really
good we knew this is just do exactly
what we need to do and be done right so
for example if I were to make a skill
for a company like a pizza company I
wouldn't want the skill to build a pizza
oh my gosh that is chatter back and
forth and back and forth no I love Swiss
olives so don't want this I do want this
we usually don't change our taste
preferences for pizza very often so it
makes sense to utilize a profile that
you've already built for your user on a
website and just say when would you like
your pizza because I already know what
you want and you say how about now
everybody's gonna say now or maybe in an
hour and they say got it it's on its way
so not only have you taken care of the
user in two steps or less you've also
charged their card you already sent
everything to the closest location of
them it's that auto magic to the user
this is why we will all have jobs in the
next several years around voices because
we're the ones who can implement that
cool smooth experience but I have to
convince you to spend the time on that
and not say it has to be back and forth
conversation because that's not really
what it's about it needs to be short it
needs to be to the point so this is a
big one make sure that your code
executes a response in less than four
and a half seconds if it does not then
Alexa will tell the user I'm sorry the
skill is not responsive
and that's it it just dies so that means
no monoliths no huge api's which is
difficult because all of my clients have
huge monolithic av hi this is a great
time to be like let's just do a vertical
slice here and see if I can just get my
data maybe cached on the server
somewhere so that it's faster for us to
retrieve or maybe just this kind of
information this is great to do a micro
service so just or extend your existing
API and say I just want to add a
controller right like what we did just
added one for her but the whole rest
still exists I could have referenced all
of my other business logic and not had
to rebuild it from scratch all I really
had to do was change how it sounds right
how its presented so that's just the
presentation layer is really what you're
doing there
make sure you adhere to have voiced
design principles I cannot stress this
enough as we're going and things we're
getting better and better and better in
the world of voice it's going to be
important that we keep up as developers
because there's no visual UI in voice we
are the designers and so it's important
that we lay everything out in ways that
make sense there's no errors in voice
remember no errors in voice if you if
felt these people they will not use your
skill okay so it's important that you
handle them better that means this is
our opportunity to kind of re-evaluate
the way that we write our code and how
we structure it right so that we don't
lose one of our users in the fray and
have fun with this this is such a fun
thing to do you can do it in an hour
clearly we did it super fast here you
can break everything out use whatever
design pattern you want and really
extend this and make this beautiful
right do you see how fast it created
that that's why I chose dotnet that's
why I chose Web API because I could set
that up in an API endpoint faster than
almost any other platform and I could
just focus on what was the conversation
right so don't come up with a voice idea
instead come up with an idea rooted in a
problem that is best solved through
voice if you guys think about an idea I
want you to tweet me there's
there's a my twitter handle up there in
the right-hand corner and talk to me
about ideas that you have that would be
best solved through that I'm starting to
compile a list of things that make sense
because when companies want to justify
putting money towards the development of
voice this should be something that we
can readily show them this is why you
should do this these are the kinds of
examples that we have thank you so much
for the session and stay curious right
so somebody had a question yes
yes actually so that is a good question
so when it comes to slot types remember
that data type that you were talking
about the question was is there an open
way that should just say anything goes
here instead of saying here's a
pre-populated list of acceptable options
right there is you have to train it but
that option absolutely exists so it's
one of those things that that means that
you have to train a response to a one
word to two words to three words to four
words I need to train those responses
there and then it will accept anything a
good example of this would be when I
wrote a skill for our local transit so
here you guys have a great train system
awesome I like it maybe you want to know
when the next one's going and so in
order for that to work there are so many
possible locations you could be going to
and at least where I live and we had a
bus system so I can't pre-populate a
list of every single destination that's
just crazy talk so in this case I used
one of their generic data types that
allows you to train it and I could say
any address I wanted I could say any
address I wanted I could say that just
the name of a business I could say a
geographic location and we just hooked
it up to the Google Maps API and it
handled the string so that's what we did
there and that's exactly how we handled
that now it's better to know a little
bit about your user so maybe you can
handle that some of that stuff in the
background and not force them to leave
it open but it's good to be able to I
agree we see there especially in that
choose-your-own-adventure kind of
situation where you need to repeat
things back for example Alexa opinel
cars hello this is starship USS
Enterprise all right set course for
Starbase STS yes commander set course
for Starbase sts-112 warp 7 course laid
in for sts-112 ready at your command
engage
now I trained this part right here
because it could have been any Starbase
and please say options if you need a
list of commands cancel acknowledged
right so in that case I went ahead
interested a generic slot there okay and
there's a lot more information about
that on the data types section of Alexis
documentation but it's a great question
anybody else yes oh yeah I could I could
use the question was can I combine Alexa
with any other kinds of like Louis right
for Microsoft you can do whatever you
want now remember because of that
generic slot type that we talked about
absolutely you do not get the audio
right now because there are legal
ramifications for Amazon to release the
audio piece to you and so because you
don't have the audio you can do text
analysis on it if we use that generic
slot type and send it over yeah so I did
stuff with Microsoft cognitive services
for example I wanted to be able to
predict how angry somebody was when they
were interacting with my skill hey you
know based on the things they said did
they use profanity if there's nothing
else to take away from this is this you
have to allow it because what will make
somebody matter saying I'm sorry and
understand what you said when they say
your sample utterance plus some sort of
exploitive or if you just handle and
give them the data that they requested
and maybe with an additional sorry about
that right there's a lot of power in
this we can totally do all of this and
make this not suck so I highly suggest
that you guys make voiced assign amazing
so thank you again and I'll take
questions up
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>