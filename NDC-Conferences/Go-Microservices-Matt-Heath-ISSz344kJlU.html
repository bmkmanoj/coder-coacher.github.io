<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Go &amp; Microservices - Matt Heath | Coder Coacher - Coaching Coders</title><meta content="Go &amp; Microservices - Matt Heath - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Go &amp; Microservices - Matt Heath</b></h2><h5 class="post__date">2018-02-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ISSz344kJlU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi so I'm Matt's
I'm gonna talk to you a little bit
about go and microservices and i guess
other
it's yeah I'm so a little quick intro
well one thank you very much coming I
guess you're missing choice forks so
yeah that means a lot I I'm Matt I'm on
Twitter here so if you have any
questions I'll be around all day
otherwise give me a shower on Twitter
and I work for a company called munzo so
has anyone heard in munzo yes okay so I
actually did a talk NDC two years ago on
handling failure in micro service
architectures which was perhaps a little
premature as we hadn't really launched a
product at that point thankfully now we
have launched two products and a few
more people ahead of us so maybe this
would be slightly more relevant now so
to give you a little bit of intro if you
haven't heard in one zone we give out
these kind of luminous debit cards
however that's like kind of side part of
of what we do we our mission really is
to change the way that people interact
with finance and for me that's kind of a
personal thing I've I found it's very
difficult to kind of easily get spending
data about like what your expenditures
are easily keep track of your money
that's not something that banks have
traditionally made particularly easy
although that is hopefully changing very
soon with open banking but that's kind
of always been something that I
personally have really had an interest
in like having better control of my
finances and having ideally someone who
can tell me to like spend less on one
thing or put my money over here and that
can kind of help me kind of live a
better life really and the flip side of
that is the banks to me are a bit like
this so banks are quite dated you often
have to go into a branch to do something
sometimes you have to go into a branch
and the person in the branch can't help
you and they direct you to a phone in
the branch where you didn't phone
someone and none of this is a
particularly good user experience if we
if we were focusing on UX for a second
banking is not that area like banking is
generally terrible there are a very
small notable couple of exceptions
however as an industry thank you
probably has some of the worst user
experience of all areas and that's a
problem because you really can't follow
you really can't function in a modern in
the modern world without a bank account
it's quite difficult especially if you
move countries and then you can't get a
bank account and that's really difficult
if you like actually you need to pay
your rent or even get a hammer cause you
have no way of proving to most these
kind of companies that you're a real
person so banking is kind of core to
every everyone's life and it's something
that has terrible user experience and
that's something that I'm on so we want
to change so we started quite a while
ago back in February 2015
turns out building a bank takes a really
long time I don't know if anyone would
have guess that I took a lot longer than
we thought and to help us speed our way
along this kind of journey we realized
we wouldn't be able to give people what
you would consider a traditional current
account for quite a while
we need a full banking license to hold
funds and that's not something you can
easily get for a lot of very good
reasons so in our case we launched a
prepaid debit card and this is this neon
card a lot of people have seen and then
slowly over time we've built up the kind
of banking expertise and the technology
behind that so that we can add the
features you expect of a normal bank
account and then kind of from that point
start iterating and that's kind of the
point we've got to you now or actually
little belf the point of this picture we
have run through kind of alpha stage a
beta stage we gave on a few hundred
thousand cards we've now started
upgrading people to full current items
which gives you all the extra kind of
features and that's kind of where we are
now which is really kind of fun for me
because it's taken pretty much three
years to get to that point and now we
can do all the really cool things that
we thought we'd be able to do a long
time ago
so it's giving a little bit of context
we give people
of an app you can all your interaction
with us is through the app we have 24/7
chats that means we have teams around
the world
as they don't have to stay up all nights
and we give people a debit cards they
can control the money and in the app you
can do really basic things like see
where you spent you actually see like a
description of that shop which makes a
bit easier to control your money we
categorize those automatically you can
do things like searching which response
you can't do you can actually search for
emoji which is obviously a really
important feature so if you do ever want
to search for the coffee cup that does
actually work and it will pull out all
of the coffee related shops you can also
store things like your receipts and
stuff so if you have expenses expenses
you can actually pull those not really
easily and build like an expense report
I store pictures of my brunch just as a
kind of memory survive being another
really basic thing is like you can
freeze your card if you lose it
and crucially if you find it two minutes
later you can unfreeze it and I think
this is like this is a feature we kind
of mentioned quite a lot but I think
specifically a developer conferences
this is a really interesting one why did
why doesn't everyone do this it's
literally a bull flag in our database of
whether your card is enabled or not I
mean seriously it's actually an enum
there's like four different states but
like this is the first feature we ever
added like okay we have cards we put a
card in the machine that means we get an
API call in real time every time you you
charge a card we've still we've since
built our own master card processor but
as approach time we used a third party
card processing system um so yeah we
look at your code up in the database
it's not enabled to climb literally that
simple and it turns out if you relatable
it we can undo that so this is one of
the like really small UX things that is
trivial and and all large companies like
all large banks have loads of people who
are really intelligent
you have really simple ideas like this
but my actually building them is a
slightly different
problem yeah this took like 10 minutes
or so to go all the way back if you were
considering building a bank at some
point you're going to be staring at this
screen which is problematic kind of like
intense terror because I how do you
really start any large any large
software project like where do you start
right the beginning you can spend ages
designing how everything will work
ultimately you probably don't really
know how we're working end at this point
I basically do nothing about banking so
now I know slightly more about banking
and that means really that all
assumptions are going to make at the
beginning of a project are probably
wrong so there were a few decisions we
need to make right upfront and one of
those was like how we could just get
going really quickly and build something
so in our case we chose to use go as a
main language not our only language but
as our main language that we would knock
out a prototype in and then kind of
iterate on from that point so that he
wouldn't use to go or seen the go-go fo
kill few people so I guess the real
question is why would we use a
relatively obscure language to build
something that potentially might store
huge amounts of people's money and we
might need to bring lots of people on it
if our team grew and there's a few
reasons for that we could have used any
language really like you can build
anything in any language and I wouldn't
say that any eaters and you better than
any of us so this is not one of those
talks this is not a talk to say you
should all ditch everything you're doing
and use go that's not the case go is
good at certain things but not
everything and in this kind of talk I'll
mention what those kind of pros and cons
are so in our case I'd say the real kind
of sum up is that this very simple it's
an effective language to build things
and and it is very scalable and I mean
scalable in a number of different ways
so to go through those the language
itself is extremely simple
I've been programming probably full-time
and go for about five years now which is
which I found a great experience and
before then I programmed in a lot a
number of other images and usually in
those other languages you can do really
really clever things so you can write an
extremely small amount of code that's
kind of magical and it's like feels
really good and the problem is if you
have a need to debug that you it takes a
really long time
you have to like start stepping through
into frameworks you maybe haven't
written you don't understand and that
takes a really long time and that is not
the kind of go way of doing things there
are lots of tools and packages that you
can use however go you write extremely
simple quite boring code it's quite
boring like just write lots of code it's
very straightforward and that's a really
good thing because it means if you
haven't written that code you can go
read someone else's code and you can
understand it and that's a massive
benefit the language itself is very
simple they're a relatively small number
of constructs the types in the type
system is quite simple so statically
typed and it's not as expressive there's
a number of other languages as an
example you don't have generics which is
a kind of point that people keep on
bringing up in indigo community and
there are definite disadvantages to not
having constructs like generics in your
programming language you have to write
the same thing several times however
sometimes you can solve it without being
really generic and you can have a really
simple solution and sometimes you need
to write a bit more code but it is still
really simple so for us as we've grown
our code base
I found this so much a benefit I can go
to any area that I didn't write and
obviously there are slightly different
code styles go has a tool that you run
called go formats which will format all
of your code into the specified kind of
language format so as an example there
are no tabs vs space as arguments here
that is
that's that's not an option it has a way
and lots of other things like that you
run at all every time and it means your
code is consistent across your entire
code base so there are some style
variations but the the main code is is
extremely readable the other advantages
are kind of which I guess is the main
outed advantage in library are things
like lightweight currency so I've got a
few examples of this but although you
can write extremely simple code go makes
it very easy to run that code
concurrently and that means you can
write really like quite complex
applications that are highly concurrent
which is particularly good for web
services which I'll come onto in a bit
and because of that like having
concurrency is like a first-class
citizen off the language it makes it
really awesome stick so in a lot of
languages if you want concurrency you
how to spin up threads and go we use
things called their routines which
essentially lightweight Co routines that
can be moved between threads and in a
traditional application you would have
tens hundreds hundreds of thousands
potentially millions of go routines and
that's actually normal
they're extremely lightweight so if you
want to fire up and you go routine you
pretty much I think it like hates a K on
the stack and that's it
and to use line in your code base you
would literally have some function that
you would execute and it'll block and if
you want to make that execute
concurrently you would literally write
the he would go in a space before it and
now it'll execute concurrently as it
come currently with this parent now
that's great
concurrence making concurrency this easy
is an incredible kind of positive
experience for the language however
anyone who's debugged concurrent
applications probably immediately
realizes how easy it is to really shoot
yourself in the foot here you can make
things extremely complicated you can
have loads of things that are running in
and concurrently and might be changing
State everywhere
that might be a really bad thing so
although it is easy to do there has to
be like some element of responsibility
here but it means you can design
programs in a slightly different way so
to use our example we have Ingo yours
have a main package that's like the root
of your program you have a function main
which is again the root function of your
whole program and then somewhere inside
this function we're going to call handle
requests and we're going to run that in
a go routine so let's queue concurrently
what that means is the program flow will
run through here and then we'll get to
this point and we will fire a separate
go routine handle request which will now
execute concurrently with the main the
routine and to be clear the main program
is itself running in erga regime so you
can do any number of these crucially
when main gets the end here it will
actually exit so if your handle request
hasn't finished by that point it would
exit so in a lot of programs you might
fire lots of things and then you'll use
some synchronization mechanism to wait
for those to exit and then you'll clean
up and exit program so as I mentioned go
routines themselves are extremely
lightweight you can fire them very very
quickly yeah when you are literally
firing on Leon you're allocating a que
memory on the stack that has slowly
increased as the co scheduler is
improved and that means that yeah
they're they're like pretty much instant
so when you're doing this you now have
the opportunity to modify huge numbers
of variables across your application
concurrently at the same time which is
probably about things so one of the kind
of main points I'd say there's loads of
documentation on the go website one of
the really good articles is called
effective go and that is like the step
on from a style guide it's like the
ethos behind how you should programming
go and not some examples of specific
syntax and kind of constructs and one of
them is this so you shouldn't
communicate by showing them
instead you should share memory by
communicating and this is a very kind of
course concept in goers language you can
have many variables in memory and if you
have a reference to them you can modify
them from any number of go routines
that's obviously bad because you may
have things which are modified in and
out of order and the go scheduler main
reorder your the execution of your go
routines so you have concurrent access
um things like maps and arrays and
various other things
um mutating those concurrently is
generally a bad thing go will usually
panic if you modify these things
concurrently so what this sentence is
trying to tell you is instead of like
having references to specific variables
and mutating them we should instead pass
those things around between go routines
and go has again a primary kind of
top-level construct called a channel
which allows us to do this so these two
concepts the go routines and channels
are the way that we build all programs
really can go and these are just a way
to send a message from one go routine to
another go routine and that is straight
through you could send pointers probably
don't do that unless you know what
you're doing so this allows us to move
have many concurrent running sections of
our code and then we can move our
different messages between them and
communicate in that way so that means we
can construct things like point lines we
can have one go routine that's doing one
particular operation it passes a result
to another one that's the result another
one
we can also do things like running in
and out so if we have many if we have
many go routines that are generating
particular results we can then pass
those into one thing which can
congregate them and this gives us
ordering so we have one synchronous
operation which were reading in from
many results from a channel so we get
synchronization across our program the
other one is if we have a large pool of
things we need to process we can process
we can spare many go routines that
listen on one channel and that means we
can effectively load button
work across a large number of discreet
go regimes within our application so
those kind of things allow us to do
quite interesting things within our
application and then by using those we
can construct like the the applications
all so taking a little bit defense that
go to use themselves I mentioned to
really lightweight and you can spin up
loads of them really quickly because
they don't do any sorry they don't learn
as oh s level threads so the go
scheduler has changed quite a lot over
the last couple years and is now
incredibly efficient so usually most
languages your kind of performance
bottlenecks will come from spending up
new threads for concurrency and that
means you have context switching you're
moving memory in and out of cache lines
and CPUs so in go the go scheduler will
the runtime will spin up one thread per
call and then it will multiplex all of
your go routines across those without
you really know anything anything about
him and that means that you don't have
any content level context switching at
that point as soon as one of those
threads blocks for my IO or Treat disk
or memory it will park that spin up a
new one on the core and then move other
go routines which need to be scheduled
onto that so we'll do that incredibly
efficiently and that's why you can run
like potentially millions of go routines
in one process also goes a managed
memory managed language so a long time
ago it had kind of a stop the world
garbage collection frankly that has gone
away now and it has a really efficient
concurrent garbage collection so you can
generate huge amounts of garbage and the
runtime will just deal with that for you
so that means like if you have come from
say another language like Ruby or Python
or heaven forbid PHP which I used to do
you don't have to deal with those kind
of things and moving to make a compiled
language or or something like Java is
quite difficult you have to change your
mindset quite a lot because you need to
keep track for all of these things and
gos gonna do that for you that's really
straightforward it's extremely efficient
and the other thing if you're using this
as a large company is the language
stability
Sogo is about to upgrade to a version
one point 10 all versions all sub
versions of the go one language have had
a compatibility guarantee so basically
if you wrote a go one point one program
and now on one point ten it should still
compile there's been lots of performance
changes under the hood as I mentioned
the memory of memory management and
specifically the garbage collection has
pretty much increased several orders of
magnitude over that time however you can
just me compile your program and it's
basically fine that's kind of a
guarantee that the girth is provided and
that means if you're using this in a
much larger company you can upgrade
versions and get performance increases
for free without having to schedule like
loads of development time to read the
words and we update to a new language
version which is pretty awesome so
popping all of that together at mon-sol
we've been able to switch using go we
started using it pretty much from
beginning we've got a really simple
language which means that it's easy for
people to join our company and start
using we can pretty much rely on the
runtime to deal with all of these things
for us and we can rather than focusing
on the language level problems we can
focus on building our actual product
which is the interesting part however
what we don't want to do is build one
dirham application if we're building a
bank so I guess I have to mention the
term micro services which in our case
like it's extremely high P and I'm
that's something that a lot of people
talk about very specific things about
micro services what we mean when we say
micro services is just really small
applications they're really simple
they're just HTTP servers that's all
we're doing there's no like special
inferred meaning from this term and the
reason we use go for this is because
it has extremely low overheads so the
the average memory usage of one of our
binaries will be like 40 megabytes and
if we compare that to like one of our
services that's running the JVM that's
hundreds of megabytes it means we can
deploy a lot of these and they're really
efficient deployment is really simple as
well Sogo is statically linked and that
means you can compile your entire code
base into a single binary you have one
file that is executable you put that on
a linux server and you execute it and
that's it that's your deployment you can
do really complicated things if you want
but the binary itself contains the
runtime it contains all the dependencies
and it's literally executable so if you
want to do anything with deployment you
don't have to deal with like
environments and working out which
version the runtime you have built into
your docker container for example you
don't have to make sure you've got all
of the files with it you literally
compile it and then you run it and
that's like amazing for a development
team so if you wanted to get started
with those there's a few options so if
anyone's seen go kits this is a kind of
standard library for micro services and
this will do things like let you create
a server it'll handle all the requests
flow for you and then you can just
pretty much build really simple
functions which it will run go Kate is
quite like paired back it lets you
specify kind of all the extra things
yourselves whereas if you want something
that's kind of more fully fully featured
then something like micro which is kind
of a fully comprehensive toolkit really
this is probably the one you want so
with micro you can literally define a
function you can run that compile that
as a binary you'll now have a HTTP
server it supports a number of other
transports as well and then you can
deploy them and it comes with my lots of
kind of stuff down things for
observability so discovering everything
like I'm all talking about we have our
own - maybe don't use that but if you
want to have a look on like how we build
really
simple applications this is like really
straightforward and in our example
literally when we build a service it's a
function that takes a request and
returns a response it's really that
simple
we then usually put some of the related
ones together so you can share some of
that domain logic in which case we will
register a number of them with paths and
then register specific handlers this is
just like any normal web application
you're registering a specific routing
path and then you're executing a
function which is literally going to
take a request to and return a response
and it's really that simple
as of two days ago Amazon now support go
on lambda this is a good example again
of how the overheads are so low you can
actually run them as lambda functions
and buildings really easy
you couldn't test them locally because
you can compile them against the toolkit
and it just runs it locally so there's a
post on the Amazon blog check that out
if you want to just kind of play with go
in in lambda and again this is really
simple so if you wanted to do this you
are going to define again a function and
this is like a bit there's a big going
on here so you're gonna take a function
and this first parameter is going to
bring in an API gateway props a request
there's anyone used API gateway or
native us before okay couple of people
so API gateway allows you to define like
a route to execute a function and this
is just going to take that request
you're going to do something with it and
then you need to return a response and
an error and in go you can return
multiple parameters from from your
functions it's allows multiple return
parameters and the kind of common
convention is if you have an error the
last parameter is the error so this is
just that kind of like standard way of
doing things and go the actual function
main here is literally lambda start
my function so that's it so if you want
to have a play with that there's loads
of details on the Amazon blog it's
really really straightforward you pretty
much write some code compile it and push
a zip to Amazon and it will execute it
which is kind of awesome
so that's what winning good at munzo
we started deciding we would use go for
all of those kind of reasons and that
brings us like all the way back to the
beginning how how do you build a bank if
you are starting from scratch
and you know that it's going to be
really hard I think that's the one thing
we did know right the beginning building
like a large complex application is
generally quite hard building one that
stores people's money and has to be
really responsible is quite terrifying
its broadest so at the beginning we were
pretty much like this we're going to
have a mobile app that's that's a solid
decision you can get behind that and
then that is going to do something and
then yeah that'll store your money great
so obviously we're gonna have some form
of server-side application and write the
beginning we knew that that was going to
get complicated we'd have probably a
database behind that maybe multiple
databases the application is going to
get a lot of time we'll need to add all
sorts of things in like emoji based
search and like probably caching and
like lots of other crazy features that
we require and this is this is a really
common thing that everyone finds
themself in it's a really common story
you hear from lots of large companies
you build a really big application and
unsurprisingly it's really hard to
develop on deploying spider you have one
code base everyone's contributing in etc
etc and these are the reasons that
people have talked so much about micro
services over the last four or five
years and why people have started
breaking their applications into much
smaller chunks and that's exactly what
we did right from the beginning so we
started off with a large number of
discrete applications the Auld in one
thing one thing well ever very bounded
context and that means that you can
focus on how one of these works without
needing to really know about the horse
kind of the whole application all of
these are maintaining their own api's so
you effectively have api contracts
between each service and in our case we
communicate are a number of ways either
synchronous kind of our pc-based calls
which we require for later see sensitive
requests response and we also use a lot
of hues and do a lot of like event
sourcing kind of things which allows us
to push those into queues and if we have
problems we can kind of slow down our
processing and deal with that I'm doing
things back up in our case we started
off in I mentioned February 2015 and we
slowly added more and more services and
I think the thing to bear in mind is if
you start that way especially if you're
starting a startup or you don't have an
established product you probably don't
know how your product will work and that
means that it's very difficult to know
what this does you'll make some guesses
and you'll build napier and a good
example of this is how we built our
transaction API originally we thought we
might read some stuff like this is how
transactions in the real world work and
I mean like kind of monetary
transactions rather than transactions in
a specific database terminology and
inevitably those assumptions were wrong
and that meant that we had to rebuild
lots of these things and change the
api's between them which is quite
painful so if you're starting off right
at the beginning this is this is a
problem and this is why most people
build an application the prototype
quickly and then at some point in the
future you pull out specific sections
which are performance sensitive so in
our case we started right at the
beginning and we've slowly added more
and more services and deleted a few in
the middle and we're now running about
415 services and these are discreet
services each one of those were running
many copies off based on performance
requirements so ultimately we have
sacrificed the individual simplicity of
these four like overall complexity of
our system but those are things we can
manage so to go all the way back we
started off with an app that is going to
connect to some form of API and we need
to deploy that on a server somewhere we
could use kind of lambda or some other
like service products
I'm not sure those were like
particularly well used when we started
but in our case we have a server that we
need to run something on and inevitably
over time we're going to add more of
those and we end up in another problem
where as a small development team we've
now turned ourselves entirely into an
ops team where we just have to manage
servers all the time which is again
problematic so to solve this problem we
switch to using communities and
kubernetes if anyone's used allows you
to kind of run a platform across all of
your services essentially stick that as
like one lakh of compute power one set
of resources that you can scale
independently and then on top of that
you can run all of your applications so
we can run a cubelet on each one of
these servers and that will decide that
the scheduler will decide in the
kubernetes master which applications are
going to run on which servers and then
the qubit will execute those and most of
the time we're running these in docker
containers so the cubelet will
essentially pull the docker container
and execute it behind this and you have
EDD so this is our consistent data
storage and this is what Cuban Isis uses
to store all of its data and so one
thing very important now if you weren't
going to use communities it is extremely
important that this is stable and
reliable if your sed cluster breaks and
everything will break completely nothing
more on and that's really bad as you
might imagine um
I think we yeah we published a blog post
about how we do this a couple months ago
so on Amazon sed requires quorum based
decisions to make its route so I retain
its consistency which means you were so
she need an odd number of nodes we don't
really want to have three so we run
across to the availability zones three
isn't very many that doesn't give us
much margin for error specifically we
wanted the ability to lose an
availability zone and also have one
server down for maintenance potentially
at the same time and the minimum number
you can do to do that is nine at CD
servers so you have three in each
availability zone thankfully that is
just about within the recommended
number that's like the maximum
recommended number of servers and we've
run these as individual auto-scaling
groups on Amazon so we essentially have
nine auto-scaling groups of one and that
means that they won't individually
numbered and we have an application that
runs on that when it comes up that we
attached is the correct EBS volume so
that means we can actually terminate all
nine of our SCD clusters on all nodes
completely and within two minutes we
have a whole new cluster which has
retained all of the data if we lose
under the quorum for them then we have
no downtime whatsoever and crucially
while that is down the only real
limitation is communities can make
scheduling decisions so if your
applications crashed at that point or
specifically if the nodes crashed and
went away your work clothes wouldn't be
redistributed that's like an aside on
how we run that however the nice thing
if you're building applications is all
of that is squished down into one lovely
abstraction layer where we just run on
our applications on communities and most
people in the company don't really need
to know how all the underlying stuff
works in order to do they do their job
and you also get nice things like
dashboards so you can go and see what
your applications run so in our case we
are taking go and docker and kubernetes
and that gives us like a really really
nice way to run our applications
I mentioned dr. is I'm saying go is
going to statically link all of our
libraries into the actual binary and
that means we don't need a runtime we
can run our go binaries in a scratch
container with no shell which makes it a
more secure and then we can run those
really easily on kubernetes and kid
matey's will deal with resource
constraints and node failure at the
moving around so we can pretty much just
ship lots of services on top of
communities I've bandied this word
around quite a lot though which is a
service and in our case we're talking
about an individual go binary there's
essentially HTTP server and it might
have a number of handlers so number of
different paths but ultimately it's
listening on a port receiving HTTP
requests and responding with those these
gonna communicate in some
so usually over some form of transport
and originally we used a very long time
ago we use rabbit and Q to build a
really quick prototype however that
doesn't give us all the kind of things
that we wanted so ultimately we need
many copies of each service to provide
reliability and scalability and we need
some way of communicating between these
and crucially if you're communicating
between lots of services there are a
number of things you need to look for so
lots of stuff I wish I worked me through
but ultimately you need to know where
they are you need to be able to tolerate
failure and because we're in a we've
built a cloud native application these
services are coming and going so we need
some way of routing requests reliably
through a series of services that may or
may not be there when we try and make
the request and our services I mentioned
are small go binaries we could build
lots of our own code to do this if
you're using Java Scala you could use
vinegar for example which does most of
most of our list however we want to
create on we want to keep our services
as small as possible and as simple as
possible so we just want to use HTTP at
this point and that means we need some
way of routing these requests and cuban
entities gives us a concept called a
service which allows you to route
requests to multiple copies of a
receiving service however of this list
that only gives you the top two so that
leaves us in a bit of a quandary so in
our case we've chosen to use link ID
which is one of these kind of service
mesh products which I guess is the
marketing term for them these days so if
you have seen link be great if not
there's m'boy sto and a couple of other
products which going to do these kind of
things and all this is gonna do is take
a request and then decide where to route
it to so in our case we just send we
proxy to log over to the local link D
and our service here is completely
unaware of how it is routed to its
destination we then are using Cuban
Italy service discovery to get that
information
so we can locate where all the copies
are linked adi has a neighbor that will
connect to this and do that for you and
then as a result it will route the
request to the instance it most likely
thinks is going to serve that correctly
so do things like retry as if icon
connects or if it's not impotent request
it load balances across all of these and
if there is a failing one it will take
that out of service and then work out
when it's back in service and then start
routing traffic back over to so to go
again back at the top in our structure
we have any Oba the top load balancer
onanism our traffic then goes into an
edge proxy which is something that we've
written which again is really simple go
HTTP server this will then route to
another service so we we call this tail
like our API services and these are
going to do things like unmarshal JSON
and decide what to do with that request
and the cool thing is that as an example
we have we have a public API that you
can use if you're a customer and we
route this particular slash web focus on
top level API to this particular service
and what that means is we don't need to
be deploying our hedge proxy every time
we increase or change our API if we want
to add a new endpoint we just deploy a
new one of these API which makes it
almost riskless we're running our
services in cuban at ease their resource
constrained so they can't consume all
the CPU memory on the machines if you
deploy new one no requests are going to
it so we can deploy new features on our
API with literally nearly zero risk
which if you're building something is
towards difference money is pretty
important and beyond that we then route
to a number of other of course a number
other services so this case we're
actually deciding what you're doing with
your web hook we'll throw you and then
we will probably put it into the
database to register a new web hook
Handler and that mean that means when
you're going to use your card in a shop
will actually ping your web hook in
time quite often you'll get that before
the receipt prints but I don't know like
guaranteed oh yeah so this is like a
really basic flow through that each one
of these arrows is obviously a massive
obstruction because we're actually
putting this thing into linka D it's
deciding which service to route it to is
their routing into that and liquid
itself is communicating over an overlay
network which you are required to use if
you're using communities so there are
many many many layers of abstraction
here but ultimately if you're building
like business domain level logic it's
not right so it's really nice and simple
and then behind this we have some
databases and maybe other providers so
we use Cassandra for almost all of our
data for reasons I have done chat about
and then other things like Africa for
replicated logs and asynchronous
communication so that kind of gives you
an overview of how we've gone taking
really basic go services so encourage
the P servers we're deploying those
inter communities would you point quite
a lot of them but they're all relatively
simple and as a result we can put
together all of the features that you
kind of would expect of Frank we can
store we have a ledger which can store
all of the transactions on your accounts
we have integrations with MasterCard
Faster Payments direct debits chaps all
of those things are literally clusters
of small go servers that are running
within this because we haven't built our
load balancing into those servers we can
actually and we pulled that out we can
deploy service in any language
we just need kind of a common contract
so if you're deploying a container that
listens on the HTTP interface and can
serve requests in a specific formats
then we can deploy those into our
infrastructure so a number of our data
science applications are in Python
because
much better much better libraries 4,000
go we have to integrate with IBM MQ for
a number of things so we don't want to
use the go bindings for that because
we'd have to shell out it well we'd have
to use the C bindings which is really
horrible and complex so instead we can
just write a scholar service that does
this for us and we can use the Java
bindings same with the low loader soap
servers if you're building financial
products you've probably had to
integrate with lots of financial
companies that soap is the pinnacle of
technical achievement nothing will
surpass soap and gos X and our support
isn't that great so we we use Java
services now but ultimately these just
kind of end up in communities and kind
of business as usual so there's a number
of things that we've kind of learned off
the back of that one of them is that we
need to constrain our complexity so we
build lots of small services and we've
pulled that complexity outside so if we
have problems we can go and look at the
code base of that particular service and
its really short that's nice and easy
the other reasons that we've done this
kind of taking this kind of approach in
security so if you were deploying one
service of 400 you don't have to give
everybody access to deploy that service
you can deploy them within communities
using our isolation and all based access
control so the specific people can only
see specific secrets they can only
deploy specific applications and those
applications can only even establish TCP
connections to other specific services
so those that isolation is something
communities gives us which is a massive
elephant force the other one strangely
is like operational ease so while we do
have an incredibly complex system if
you're building a day-to-day product you
can quickly create a new service you can
commit that we go through our change
control process which is primarily get
home and then you can build and deploy
that in Turkey
and the kind of feedback cycle on that
is potentially minutes we have a number
of staging environments you can deploy
things really quickly into those when
you are deploying them into production
there's loads of readiness checks that
will ensure your service is correct
before it's the traffic's all over so
those things are like of kind of crucial
importance so those the reasons kind of
wine we've done that I guess there are
also a load of things we've learned over
the last year or two so one of them
which I guess is a little bit I've kind
of touched on it is that we want to make
our services as small as possible so we
have quite a lot of services that are
quite tiny compared to a lot of like big
companies so using Netflix is approach
for example most of those will run like
an application on a server and over in
many of them because they're massive and
in our case we don't have that kind of
scale so we're running lots and frantic
Asian's on the same server but they are
constrained um however if we're doing
lots of things in the same binary then
it's sometimes hard to like establish
what the performance of that thing is
it's harder to look if you're looking at
graphs of like overall performance of a
service and this particular thing is
slow if that service is doing many
things and that's difficult if you're
reading many things off a queue for
example and it's doing different logic
within that same service even though
it's very similar logic potentially
you'll be stalling the queue if one of
those executes incorrectly and we've had
lots of examples of that keeping them
really small also means that we have
them thankfully we can do that because
go has really low overheads so I
mentioned our default provision for a
services I think 30 mega memory limited
to 100 mega memory which is insanely
small we can use communities Palo Alto
scaling to scale that outside way
horizontally but and then we'll tweak
those based on the performance
characteristics of the service but
ultimately keeping them really small
means it's very flexible one thing which
I wasn't really sure
of right beginning was now we prefer
services over shared code and libraries
so if you're building something that
would be a library you could compile
that into many services the problem is
if for example you have built something
that is in 200 of those services and you
now need to fix a bug you now have to
deploy 200 services which is really bad
so in most cases we pull that kind of
library code into a service itself and
we'll just make calls to that and that
means we only have one place where we
have to fix that if we have to change
the interface yes we still have the same
problem but again it allows us to
constrain that kind of complexity into a
small place also I guess this applies to
like all large code bases sometimes
there is a way to do things that is
already there and there is a better way
to do things
and if you're in a really large code
base with a large like with a
development team that is scaling often
it is better to do it more consistently
than have many different ways that are
slowly progressively better if you're
doing the same thing in many different
places and this is something that yeah
we've kind of had to learn I guess over
time sometimes if you have so many
services you will be unaware that there
is a service that already does the job
you were building a service for so we've
had to make sure that we share these
things around and get better at
communication in that regard when we're
doing designs we share internal RFC's of
like what we're going to do to like
solicit feedback across the company and
that again allows people to point out
that yeah hang on we've solved this
problem it's over there so you there's
kind of a problem with all large code
bases in this case they're discrete
applications so sometimes the visibility
in that is lower also quite often you'll
be using shared infrastructure so I
mentioned that we use cassandra store on
Tatom if you're using one Cassandra
cluster with many many key spaces and
you have one service that thrushes
Cassandra
then you're going to create a knock-on
effect for a number of their services so
there are a few options for that if you
have large enough scale you can
segregate those
too many clusters if you don't then that
is quite expensive some products you can
run much smaller volumes without
dedicated service so for example we run
Kafka as a number of staple sets within
communities rather than running like a
number of massive dedicated care
instances and that means that we've
isolated performance problems to those
clusters individually and that allows us
to have better performance overall and
higher our time also I mentioned
complexity is huge so onboarding people
is hard but again that's something that
I think the mic I said well building
your application as a series of micro
services and using a language such as go
has made that problem a lot easier for
us so people can join our company they
have a really simple language to learn
but like the framework is almost
non-existent we don't have loads of code
you need to learn so you can pretty much
start working on a specific service the
deployment is super straightforward so
you can get up to speed really quickly
and then slowly learn all the other
things around the company so that's
something that we focused on quite a lot
the last year or so but ultimately we
still need to reduce our complexity
hugely and we do that by isolating those
things I mentioned we use Ivy mmq for a
couple of things we have to because we
integrate with other third parties but
we don't want all of our other services
to be aware of them so we can
encapsulate that complexity behind a
service and then have kind of more
normal interface into our infrastructure
and finally I guess we need to monitor
everything so if you have hundreds of
discrete services monitoring and health
checks and being aware of performance is
probably the most important thing so
yeah I think if we're going to ask what
we do differently a long time ago we
would have probably done things hugely
differently we have learned there are
obstructions across services were often
incorrect and we've had to change those
quite a lot so knowing more about your
domain is kind of
quite important and then breaking those
things down into smaller and smaller
chunks has worked very well for us and
yeah that's it thank you so much does
anyone have any questions yeah so I mean
we're we're super transparent as a
company some of the services are big but
by big I mean like thousands of lines of
code not tens of thousands of lines of
code they will have potentially 12 plus
handlers they're all doing different
things but loosely related and for us
that is quite complex so some of them
will be really small like a hundred
lines of code a couple hundred ones one
or two handlers like anything
as a very good question how hard is
debugging really hard um so I guess
there's a couple of different areas
where debugging is quite hard debug and
go itself is relatively straightforward
there's loads of really awesome tools if
you're debugging an individual binary so
this is really very much a question of
how hard is it to debug our applications
versus hard how hard is it to debug
distributed applications and the answer
is go really easy those are really cool
tools you can use it has run time
tracing there's a thing called people
off which you can use to literally trace
execution so you can see where the
bottlenecks are and you can trace the
government teams as well so you can take
like a sample of execution from the run
time and you can actually pull that into
some tools and see like you can trace
where the execution 1 so that's amazing
debugging distributed applications is
really really hard
and we use a number of tools for that
and we have a number of our own internal
tools ultimately we are usually when
debugging those problems in production
because there are things that have
happened and we're trying to work out
why they've happened or at least what
triggered them so we can then reproduce
them locally and fix them using things
like run tracing like Zipkin and so I'd
say probably distributed tracing is one
of the most important tools form
structures like this we tag every
request
that's our API war various edge points
with unique request ID which is then
passed through between every service so
like when a service makes makes an
ongoing HTTP call it will has a context
because go doesn't have thread-local
variables we have to pass a context
object through every method call
whereas in cons of that bit tiresome but
ultimately we have this request ID that
we can then take out of this context
serialize as a header send that to the
next service which then DC realizes it
and put it into the context and passing
on the contact also allows us to pass
things like deadlines
and allows us to cancel context so if
something is average much further up we
can actually cancel child requests
through the infrastructure which is
quite cool but yeah that's hard and I'd
say like instrumenting applications
using distributed tracing and we also
log every log line with that request ID
so we can pull the log lines for a
specific request even though my have
touched like 40 services across 40
different servers we can pull that
together and see see the loss for that
request
that's quite a that's a good question we
don't have a special special place we
actually is a mono repo so it's like one
gigantic repository that you clone down
which has every service literally as a
folder within within that but yes that
is difficult if you are new to the code
base because memorizing quickly what all
400 of them do it's impossible whereas
if you've been around for a bit longer
you kind of have that's like innate
knowledge that you've soaked up over
time so no we don't have an explicit
tool that does that it'd be really cool
if we did and yeah we we have a list of
these and they all have a readme that
kind of I guess hopefully is up-to-date
but probably not but that defines at
least what the service is intended to do
so you have someone author and then yeah
it's really just communication between
teams to make help onboard people and
get them on speed
yeah so we we have a number of longer
running orchestration things so some of
them strangely are actually integrating
with other payment networks as an
example where you send some of these
networks and not request like request
response and you will get the response
out some arbitrary amount of time and
that means that we had to architect that
in such a way that we send the thing and
it's kind of complete but we need to
check it later to confirm that it didn't
fail or needs to be recent and then at
some point we will receive a response
and I is essentially a new request which
processes it and then when we come back
around to checking if it's already
complete we can just drop out and like
meet on the floor longer-term ones some
of the more interesting ones are things
like when you sign up in our amp there
are many stages and ultimately someone
may just put their phone down
partway through that so those are kind
of models as state machines and we have
specific services that orchestrate those
state change like state transitions so
they will use lots of other services to
do specific chunks of those work that
work but there will be one service that
kind of controls the overall state
transition so we have a few like that
some of the other ones sometimes they
just they have a really long request and
it would be nice if we didn't do that or
will trigger it and then we'll have
something that's on a queue that will
poll periodically to check when it's
been completed what time it out if is
taken to normal series caf-co to defer
all of those things yeah so combinations
will be but I guess
yeah so we have a really basic tool that
will spin all of them up and actually
for local development most of us use a
Mac and we can compile the binaries
locally so we run all of the shared
infrastructure using docker compose so
we can run docker containers for all of
our databases cue use etc and then we'll
spin up a subset of like the services
the all running on that's like really no
ideal we have not cracked how to do that
well ultimately if you're not running
one of the services you'll get a timeout
at some point which will tell you that
it timed our hitting that service you
like okay I need to go and store that
one and we have a few scripts that can
identify those code paths so yeah if I
was developing locally for example on a
specific area I would fire up a subset
of the services and try and run alone
I'm running 400 binaries on even a
reasonably powered computer is
moderately difficult and doesn't work
particularly well and that's something
that we still need to solve so whether
we solve that by running machines in
Amazon we might use mini cube for it so
you've run kubinashi's locally but I
don't think that yeah they just added an
omni so that that gives you tools to
easily spin things up but again running
that a number of things when your
computer is quite difficult so yeah
that's something we still need to solve
um one option is we push those into like
custom staging environments and allow
you to easily like modify a service
locally and route traffic down in and
our fans and effectively
yeah um so that's a good question
yes it does inevitably however that is a
kind of surmountable problem and I'd say
that the advantages of the speed that
you couldn't develop things and deploy
things is really what we're aiming for
not necessarily the overall speed of the
API so card networks are a good example
of this card networks are really slow
because they've been around from the 70s
and there's no real incentive to make
them faster if you tap the card and five
seconds later it works that's okay so
what I means in practice is we will get
an API receiver message will move the
money in your accounts and we'll send
you a push notification and often that
will beat the current network to your
phone that doesn't know all the time or
if we have some kind of problem which
means that our we put all those things
through several queues which means the
we've isolated your card definitely
working from getting a push notification
thrashing we had some problems with the
last couple of days if anyone was
watching our Status page but what that
means is we've isolated the extremely
reliable components from things that
don't have to be as reliable and yes
making lots and lots of network calls
definitely does increase latency but
it's something that you can reduce quite
significantly by well one link it is
maintaining connections to everything so
you don't have the cost of opening a new
connection and sending a request you've
already gone open TCP connection you can
make your services moderately
quicksand-like that latency should be
like 100 milliseconds between services
however that is one specific problem
that we had with go and communities if
anyone's used or is aware of like how
the Linux scheduler works it does time
slicing on CPU and Kuban at ease if well
if you're using cgroups to throttle CPU
on a particular process
and you use all of the available CPU in
your tone slice you can't execute you
just paused until that time slows ends
and the default on Linux is a hundred
milliseconds and the default in Cuba
Nettie's which is not modifiable is 100
milliseconds so we've had to modify
we've we have a fourth given at ease
that we've modified that in which allows
us to configure the time slice window
and changing that to like 5 milliseconds
or 2 and 1/2 milliseconds increased our
agency by like an order of magnitude
sorry decrease the latency by about an
order of magnitude so those are yeah it
does increase latency and it's something
you need to like instrument and be very
aware of but yeah you you can make
really fast tables the graph is like
near the exponential unfortunately which
is probably I mean which is similar to
the the rate that we're hiring new
people as well so yes it's something
that we have to be quite a werewolf but
we've deliberately put the
infrastructure in place that would
support so it's really a question of can
we as a company maintain that level of
like knowledge but I mean it's just the
same as having one really big
application that had loads of like
classes it's just that those classes are
different processes running on different
machines so trail</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>