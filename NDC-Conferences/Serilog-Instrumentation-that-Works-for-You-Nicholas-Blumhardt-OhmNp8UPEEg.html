<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Serilog: Instrumentation that Works for You - Nicholas Blumhardt | Coder Coacher - Coaching Coders</title><meta content="Serilog: Instrumentation that Works for You - Nicholas Blumhardt - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Serilog: Instrumentation that Works for You - Nicholas Blumhardt</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/OhmNp8UPEEg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right oh and II see just couple more
people coming in yeah isn't it awesome
that the lighting matches the slide
because it would have been really really
unfortunate if the lighting was all
green and we're starting with that one
you having an awesome day yep um I'm
Nick I'm sure I met some of you through
my earlier work on auto-attack maybe all
through the summer BCL currently I work
on a product called seek but this
session is about an open source project
that I started and now run called Sarah
log as a 16 minute session so we should
have heaps of time at the end for some
questions if some if you've got any and
if not we run over I'll stick around and
make sure that I have a chance to talk
to you so don't don't worry too much if
you think you miss any of those so
anyway I come all out from from Brisbane
on the east coast of Australia so it's a
little city like Oslo probably like I
was below we've got rather big software
seen especially dotnet seen for our size
unlike Oslo we have beautiful sunny
weather
it's about year-round it's great that
the wildlife loves it that dad's is so
this story starts some years ago when I
just come back from overseas and I was
working on a system for a financial
institution and I think it was really
the kind of system that financial
institutions the world over right
someone was taking taking payments from
customers through a portal on the
Internet
I just finished a really long arduous
unpleasant session of debugging trawling
through log files and that wasn't the
kickoff for this but I realized while I
was while I was doing this just how much
interesting data we keep in application
logs I was a consultant and so I saw the
opportunity to really pull some of that
out and with upper whip up a report for
my client I thought I'd impress them so
they're doing a bit of insight into
their system I spent five minutes
thinking about how I might do it kind of
put the pieces together in my head of
how advice and regex and all the rest
this kind of ugly gunk and I had to
shelve it because I realized there's
just no way I could justify taking that
amount of time out of the project they
were working on to them to do anything
with this data that we were collecting
and that was really disappointing and so
it sort of stuck with me that there was
this missed opportunity and so now we
are down the track the the product of
that sort of process was Sarah log which
is an open source projects I mentioned
it's a few years old now that's gone
beyond being a kind of a pet project the
core contribution sort of team is quite
dedicated we've got 80 contributors
listed on our main repo but if you look
at all of the 209 repositories in this
area of organization I think we've got
oh sorry all the 59 repositories in the
cellular organization we've got about
209 contributors now in the new get
scheme of things I don't know if it's
huge but we have about two and a half
million package downloads it's kind of
interesting just from the perspective of
it being a new logging library that's
come into an already pretty established
space like other ways you log4net for
application diagnostics and there lots
of people have n log as well those
really established libraries and so it's
quite hard to believe that I know there
could be interest in activity around
building a whole new logging framework
now that Nets out more than 10 years old
but we do have there is a lot going on
with Sarah log I really want to try to
get to the core of that today in this
talk so I'm not going to spend a whole
lot of time going over other details of
how the cellular KPI works one of the
design goals when Sarah log was
originally built was to be completely
unsurprising if you can take in what's
on this slide like Sarah log was
developed fairly recently so it's all
quite a modern API I was coded as
configuration you know it's a sinker
where it was born into the kind of world
of tasks and all the rest of that you
can you can write log files you can
write the console I think you saw in
last slide that they're about
different sinks so destinations that you
can send log data to now none of that
particularly distinguishes sera log
something different see it's leveled
logging library so you can write debug
statements or information statements or
log your errors and control at runtime
which ones of those are actually going
to be written through to storage yeah if
you take that in you've pretty much got
most of the details now sarah log so so
in this session what I really want to
spend some time on is that the core that
makes of the ideas that make Sarah log
different and I think interesting at
this point in time so those are
capturing events with message templates
so this is house every log takes
information from your program and
records it so that later on you can do
Diagnostics in a low-friction kind of
way and the second piece that we look at
is related to it
which is which is doing correlation
through an event enrichment so this is I
guess how you use Sarah log to find that
needle in the haystack when you're when
you're actually doing some diagnostics
for an application all right
so in part one we look at the we look at
the message templates part
heard of message templates previously
till able to using sera log Oh lots of
hands cool aha and one never heard of
Sarah log apart from I guessing the
title of this session yeah yeah okay so
it turns out that there's kind of a long
history in application logging certainly
a lot of people have have thought about
how to improve this situation that we
have the classic kind of most
established form of text of logging that
we have is text logging which you'll
have seen with log to net where logging
is done by creating a kind of a
narrative of what's going on inside the
applications usually with it's sometimes
called printf debugging because of the
formatting functions in C very old
approach you can see the example on the
Left where we take am an elapsed time
span formatted into a string and we
write that out to the console so some
real strengths that are in text logging
in that it's very easy to write a quick
logging statement as you work through
writing a piece of code program code and
you don't really have to take your mind
off of the job you can just kind of
write out your thoughts and what this is
what I'm intending this piece of code to
do and in goes some data and it comes
out in there and a kind of a nicely
human readable form so when you scan
through a text log as a human I mean all
of those um all that perceptual system
that's trained for for reading text can
really quickly make a narrative out of
what's going on in a text log the
problem with text logs and why we're
here I guess is that humans and
computers differ a lot around this point
like processing this text to to say find
all of the events where the commits took
longer than 500 milliseconds is trivial
for to express in English but quite a
painful process to go through if you
want to use some kind of automated tool
to pull that out of a log especially
when there's a lot of data and all kinds
of different information formatted into
it so on the other side we have a school
of thought that's called structured
logging
and this is how it is this is how it has
origins way back and the approach that
structured logging takes is to conceive
to REE this idea of writing logs not as
producing messages but about but as
producing events which in this case you
can see my fake structured logging API
we're just using an object initializer
to create an anonymous app that has
exactly the same data we've got the type
of events that occur this type of the
event that's occurring and then the
elapsed time and you can imagine that
when we produce something like a stream
of JSON out of this style of logging
it's trivially easily easy to use the
kinds of tools that we have to go and
find events that are commits or defined
events that where the commit time took
between 500 and 600 milliseconds that's
much easier to mechanically work with
this sort of information unfortunately
though we've now song the other way and
we can't use that human text recognition
kind of system to make sense of these
these logs really quickly so during
development not only do you have to kind
of switch modes and think about how to
structure up some kind of object to
represent your event when you're writing
code which introduces friction it's also
very difficult to scan a stream of JSON
there's more than five lines long and
make any sense whatsoever of what's
going on in there so structured logging
is has been the underdog for a really
long time it's it's fantastic in dealing
with large volumes of data from very
busy systems but the ergonomics has been
very poor and so it hasn't really
achieved the traction that that text
logging still has I think with
developers but
does I guess the question then that we
have to ask is now we're stuck at a
local maximum here where we've got good
ergonomics at development time
we're obviously resources are pretty
scarce and then when we're desperate to
get information out of run time there
are there are techniques that suffice
but if we take a closer look at what
we're doing with text logging you know
is there a way to to remove all of this
manual effort and still keep the things
that we like about about logging with
text so when we write a text logging
statement and application we do actually
have separate schema which describes
what the event is and data that
parameterize it so when when you're
writing a program and your program is
running we've got that format stream
commit took curly brackets 0
milliseconds and we've got elapsed as a
separate property where we format that
series of text we just lose that
information that we had and we sort of
throwing it away as a lossy transform
and there's not really any easy
mechanical way to go back from that log
line to the to the original kind of
separate schema and data which is really
where the problem comes in it comes into
it but if we were able to to preserve
those two pieces of information through
our logging system could we have our
cake and eat it too and that is I guess
the one of the core premises of Sarah
log so here we've got an example written
with Sarah log notice the logger isn't
initialized in the using statement
cellular is built with no static state
in the login pipeline at all so you can
create yourself 100 loggers call them
from any thread you like whatever you
like or as a convenience if you don't
want to inject loggers or pass loggers
through your code camp you can use the
static log class which is sort of used
in this example so here we have on every
any great idea in programming really has
to be expressible in a console app or
it's just too much for me to take in
right so we've got a console app it says
hello if we run it too
information there we run it with control
f5 there's two pieces of information
there I hope that the text isn't too
small for you
we've got the counter it's going through
the stream of messages and we've got a
name and you can already tell that Sarah
log is a little different from what
you're used to in in text logging and
that is maybe a throwback to visual
studio 6.0 I think that magenta is for
numbers and green two strings something
way back in the past anyway but you can
see that when Sarah logs printed that
message out to the console it has more
awareness than what you typically expect
in a logging library or in string
formatting so it has enough information
there to know that the number is is
actually in numeric and it's separate
from the message and the string is also
a separate piece of data there and if
you if you can kind of wrap your head
around what's going on there you've got
the the fundamentals of house every log
combines text down structured logging to
see that more clearly though we'll
switch over and instead of viewing that
as as text we'll take the same code and
we'll write it out as a JSON stream
unfortunately the readability just goes
downhill however you notice that the
template that hello number and then the
format placeholders is is in that JSON
document as well as the individual
values that we wrote a zero for the UM
the counter value and we've got one for
the name I mean I can't I can't remember
that um zero as the counter and when was
the name and I've got one login
statement so that's obviously not going
to scale to a big complicated
application so several log introduces an
extension to dotnet format strings that
we call message templates what page down
and the arrow key next to each other
okay
we'll just make a slight change and you
see instead of instead of using numeric
placeholders in that format string there
are now two placeholders to the name we
have the counter and we have the name
and both of those are essentially going
to become properties on the log event
that we're going to collect to do
analysis on later group functions next
control so the template is carried
through again but you'll notice on the
right-hand side the two properties that
are included in every log event names
now counter and name which means that
even though we can take the same the
same piece of logging code and produce a
stream of like machine to a level Jason
we can just as easily continue to to
produce the human readable text at the
same time it wouldn't really be super
interesting though if all we were doing
was producing a stream of Jason
obviously there's you know I don't want
to go and pause and read jason log files
sarah log came along I guess at the
point that most large dotnet systems
were not monolithic anymore and so it's
kind of post log file if you can imagine
that and Sarah log is built so that the
target for log log events is generally
expected to be something that's jason
aware or something that can represent
structured data if we take the same
example now and then we pop this into
Postgres which I just noticed there's a
post grad session going on in the UM in
the room next door the post graders is
quite an interesting database for
storing event data because it has a very
rich system for including jason inside
the table schema so you can have a jason
column and that it provides indexing
over the jason partial indexes and a few
other concepts make our post code is
really interesting to store event soon
if we take the same code and we run that
you see we get the output on the console
but as well we're in the same event
information to a log
that's not good thank you haha so now
you can tell that it didn't just
pre-baked the content of the logs table
it really is empty yeah yeah all right
so if we look at our loads table you see
that we've got a properties column over
there and right that has much the same
as what our what our JSON documents at
the console showed and then that little
stream of messages we've got the name
we've got the counter and they're both
preserved so if you think about the
example we were talking about with the
elapsed time events from an application
now where the counter is say greater
than 7 we can look yeah now we can use
Postgres as JSON query syntax and go
through there actually the properties
and then a very complex looking right
arrow that's accessing a JSON object
member and then Postgres needs to quote
adjacent values and strengths but that's
actually doing a numeric comparison and
if you run the same query now we've
zoomed in to just the events where the
counter was was greater than 7 now it
seems simple but of course we've just
taken a log stream from an application
with no other no extra work at the time
that we wrote the logs we have an ax
format where we can pretty much perform
any arbitrary query on on the events
that come out of that application so
when time comes to actually do some
debugging and diagnostics or even just
to try to get some insights about the
system the amount of effort that's
actually required to go and extract that
information is hugely reduced so
previously we had sort of text logging
was easy during development time and
structured logging was better for
analysis and now it's very low we've got
the case where hopefully we can still
enjoy a really simple text-based kind of
logging for development but then by sort
of flicking a switch and sending the
logs to somewhere that's more suited for
production diagnostics we can actually
get the full structured data experience
out of that as well so
there are a number of places that you
can send logs from stereo log actually
we've had the number already it's about
100 which is pretty amazing I think
because I wouldn't have ever imagined
that people would have such a huge
variety of logging targets obviously the
space has become really hot in recent
years and so we've got application
insights from Microsoft we've got Splunk
and elastic search and got Postgres
coming along quietly in the background
adding all sorts of awesome
Jason querying facilities I'll show you
another example using a log specific
data store core seek which is like
welcome day today and it's good for
these kinds of vicam it's good it's good
for demos because I can run it locally
and I don't have to worry about the
network causing some causing some pain
so if we jump in there now did I just do
that startup product project thing again
no I didn't there we go someone's some
serious volunteer going on out there so
most of the time with Sarah log you went
generally save it yeah you want
generally save events locally because
you're running right-size services or
some kind of cloud-based service that
needs to that needs to draw events from
a whole host of machines and so there at
most of those hundred targets I think to
Sarah Logan network base this one was
just sent lobes fire HDB to a server
running running locally and again sorry
looks like and again a proven that there
wasn't really any pre-loaded data again
and see that the counter and the name
popped through and we've got a query
interface where you can do things like
very counter is greater than 7 and get a
result back from our logo vents and we
still get the text view to read
but the promise of Sarah log is also
that Sarah log would provide fully
structured events so coming up against
something that's built to say just
recording pure JSON objects there's a
lot more opportunity to record
interesting data in JSON so Jason has a
basic type system but it covers arrays
and and fully structured and nested
objects so Sarah log needs to provide
that kind of experience to to really
excuse me I'll just wait for the car to
finish shooting its horn again sorry
alright so for Sarah log to record
structured data there's a little
extension
our alarm system test thank you yep okay
great so here we have got a more
interesting user object ID equals three
and to record that with several log
there's an extension of message
templates that said we could pass the
user through and you get an idea of how
Sara logged got it's got its name it's a
it's a serializing logger and so it's
not limited to just having simple values
recorded like strings and numbers to
send data through stereo log that has
structure you can include it in your log
event and pop a little prefix in there
the add symbol and then if we run that
again hopefully startup project is set
this time and zip over and have a look
at the resulting data you see that
instead of the user coming through with
two string we got the user through as a
as a JSON object with the properties so
we can look for user dot ID equals three
and obviously you've got one user here
and that's that's really really useful
and powerful when you're doing things
like recording say headers from an HTTP
request or D tos and system you also do
need to be very careful though because I
think the first thing that people tend
to do when they start logging this area
log is serialized all the things and
initially we had some really interesting
bug reports where someone would have
serialized an object it wasn't built for
serialization and it had a system locked
tight in there and so you walk from type
to assembly and then you walk from
assembly to all the types in the
assembly and then all their dependencies
and all the other assemblies and end up
with gigabytes stashed into just one the
log message so hence serial
serialization with Sarah log is an
opt-in with the with that little
residual character there and um and you
do need to still kind of keep in mind
that that log events should probably be
pretty compact but especially if you're
trying to debug a problem of the system
that is networked and you have a have
say request object coming and be able to
lower all of that data and then query it
for say I want checkout requests where
the cart has more than five items
makes every log really different logging
experience to what you can achieve this
text so that's that's the essence of
message template and it is a very simple
idea but it's the possibilities are
really quite deep when I first realized
how how much more valuable you could
make your log data with so little extra
effort I sort of went along to a user
group talking jumped up and said this is
going to be the next big thing and that
was probably three years ago and I don't
think I was too wrong because in the
recent versions of asp.net core message
templates have been adopted into the
logging infrastructure there and for
instance if you look at the logging
output produced by asp.net core MVC
you'll see that it's using message
templates to record web requests and
searching for controllers and all those
things as well so this is from message
templates org because the slide that
we're looking at because we realized I
think when that process began that there
are actually quite a few libraries now
adopting message templates and donate in
addition to Sarah logs so even if you
don't go and adopt Sarah lo hopefully
this is something that you can apply
either now or in the future with one of
the other libraries that you might be
using so a message templates separate
out the capturing of a log event from
the rendering it's a really simple idea
I didn't realize myself when I started
working with them but there's one other
little side benefit that's quite
surprising that you don't initially see
but becomes obvious marts pointed out
all the events produced from a single
message template are effectively the
same event and they're at their type
isn't is really the template every event
that's produced by the same log line
will have the same template associated
with it and if you imagine that for
instance you're looking for Shekhar
checkout events and you're logging all
of those with the same template like
that being able to go and actually zoom
in on all of the checkouts just by
searching for events from the template
is really
for it if you have to collect the
template as well as the rendered message
though you've essentially doubled the
volume of the log data that you have to
collect and so it's more common when
using Siri log 2 instead record the
message template by hashing it in this
example the the message template gets
hashed and produces that first value
that's highlighted and you see that all
instances of the same event they're just
the same computational hash from the
message template and then the different
event gets a different hash so that's um
that's something that I didn't expect
was going to come out of message
templates when I first when I first
started working with them however it's
become a kind of a very natural way to
go and search for the log data now and
then so you can see in this case even
though all of the events look different
and have different data embedded in them
and they can be very complex it's
trivial to go and zoom in and cut and
capture just the ones that were produced
in the same log line but that is not I
think the the thing that makes me really
excited about event types like most
diagnostic sessions do do start with
looking for an Olin thing I've got an
exception it was raised in a web request
I see the order ID in that web request
and then I want to zoom in and find all
the events with that order ID and I'll
see something went wrong like that's
pretty common diagnostic scenario but
went the ones that really make me sweat
the unknown unknowns when something went
wrong between 2 o'clock and 3 o'clock
yesterday afternoon and our numbers are
out and no one has any idea why and I
have a million log events to get through
to figure it out but the curious thing
is that is that just like I guess
instances in a in c-sharp itself you
generally have a lot more instances than
you do types and so if we start
excluding the the events by their
template to be 0 these are the ones that
are Omega we exclude the debug events so
that saves us a bit of
zooming but so okay it's got nothing to
do with claim status so we're excluding
that so nothing to do with this
eligibility thing exclude that you know
not interested in this one either
and while we might have million events
to scan through after we start to
exclude them type type by type the
things that we couldn't we would never
have actually found yeah things that we
would never have found scanning a log
file by eye because we don't know what
we're looking for
suddenly can can be revealed and that's
that's probably to me the the number one
reason that I really enjoy using Siri
log for this sort of work okay so Sarah
log out of the box doesn't actually
provide event types by the way you need
to plug that in we'll see actually how
that's plugged in a little bit later I
found that a 32-bit hash seems to work
I've never had anybody report collisions
but you know it you can also actually
take that hash and just format it into a
log file and get some of these benefits
to like you might still have a text log
you might not have any central way to
collect it and such as a structured data
but that doesn't mean that you can't
find some kind of way to encode that
event type down into the log file and
make just text-based log debugging a lot
more a lot more fun as well so it's not
only it's not only for kind of
structured log data collection so that's
event IDs so that's pretty much message
templates in a nutshell and why I would
why I would do Sarah log but the other
interesting thing that that Sarah log
brings to the table while it's otherwise
unsurprising and looks just like logs
and that is that you know love is it
really it really does have a very very
strong focus on treating log events as
events and I say correlation but I had
to pop this up because if you were
around through this time of doing SOA
with WCF and those sorts of tools the
notion of correlation was generally
you've got some kind of scheme for
passing correlation IDs through a chain
of service calls
that's one kind of correlation but the
kind of correlation that Sarah logo is
built for is the kind of chaotic
correlation that you need to do when
you're dealing with large systems that
interact with each other in kind of
arbitrary ways like it's not there might
be feasible in a v1 to kind of roll out
some kind of sophisticated pre-baked
correlation scheme but really when it
comes to doing off to doing diagnostics
and analysis the number of scenarios for
having to for tracking down events are
really kind of boundless and so the kind
of correlation Sarah logo is built for
it's be able to go and say without
having a thought about the scenario in
advance necessarily go and find all of
the events from the same customer or the
same order or the same you know
subscription ID and that this process of
like natural correlation is really
moving like navigating through a stream
of logs jumping from one sort of
correlation axis to another you might
have a request ID that tags everything
that's generated by the same HTTP
request and in the back end where you're
processing orders perhaps in the system
you might have a message ID that that is
associated with all of the events that
come out of processing some kind of
message bus message and then given the
requests that or given them the message
handlers that failed you know can you
work back to the web request that
triggered it off and that's usually a
process of navigating backups through
say some kind of natural correlation
identifier in the one kind of timeline
of the code sitting across and then
finding the other correlation identifier
and working through all the events there
and so Sarah log brings is really a
toolkit I guess for adding this kind of
data to events and it's not it's not a
completely foreign concept in dotnet
logging like there's generally some
context there's some kind of diagnostic
context that you can jam data into in
just every logging library but Sarah
lobster treats is the first-class
citizen you're not just kind of
formatting a thread ID into the message
log events in Sarah log like an event
object and
there are a number of API is that allow
you to actually attach properties to
that event and you can then go in and
collect them up and use them for for
debug and later on so that process we
call enrichment I've got a little demo
I'll make sure I actually set it this
time okay and so yeah this one's writing
to two destinations you see if you if
you like auto fax kind of fluent builder
syntax you'll be really at home with
them with Sarah log but you can chain
that cut that together so you've got the
console output and seek output or their
file or database or anything else so in
this case we've got a little simple
little program it calculates an answer
the answer is square of whatever numbers
that we've gone through and what the
zero to ninety nine and initially all of
those events are just going to get rid
of that sorry actually wrong on all of
those events are just going to have the
data that's provided in the message
template the first way though that we
might want to drill down to a particular
set of related events especially if
you're collecting a lot of events from
some kind of service-oriented
architecture or all of different
applications it's just to attach some
data at the you know at the logo level
so every event that goes through this
area load pipeline we might enrich it
with property called environment and
this one is going to be production
should be demo I guess and so that's the
simplest form of enrichment in Sarah log
you can create a yeah we run that again
and if we look at the events they will
all have that environment attached there
we can go we can go in search or exclude
you know in whatever data store that
we're using to collect the events there
um the second kind of enrichment is
probably the more familiar one if you're
working with
other logging libraries and that is
there's some ambient data that we can
collect and attach to log event so it's
not always the same but for example we
might have a thread ID and we want to go
to tell what events were kind of raised
in the same logical context so we do
risk oh I have a bad feeling to have
them you get package installed
really come on resharper okay
actually we have to skip that one
because you know terribly it's not
already in my cache and then having that
on we'll come back to that though so in
reaching the events with a thread ID
we'll we'll go and take the current
thread ID that's like thread dot current
thread manage thread ID and stick that
onto each each event object so that you
can go and find events based on the same
kind of causal chain so those are kind
of the simple global enrichment
scenarios but that obviously in a single
application you might have hundreds of
different ways that you might want to go
and track down events and Sarah log
provides a much more fine-grained way of
doing that based on the log context and
so the log context is sarah logs kind of
scoping mechanism and in every instance
where we go through this loop and we
calculate the answer based on whatever
the current loop counter is now we might
want to attach that to all of the events
to the race in the loop so log context
push property in this case we're going
to say we'll call it counter because we
haven't used that one in this example
and the counter is I and here's where
one of the Sarah lobes design points
becomes a little bit of an anti feature
in some way if you look at the events
now that come out here you'll find that
they don't carry out counter
unfortunately we also don't see the
debug level events I should turn those
on so the reason that we don't see the
the counter is that zero log really does
stick to that no static state rule like
I do I do really like the convenience of
like being able to put something in the
ambient context and then have it just
attach to stuff now track wherever the
wherever the call chain leads but
obviously there's a lot of scenarios for
doing logging and so having having a
logging pipeline that goes in grabs data
from somewhere by default just doesn't
it just has a bit of a smell to me and
so now we need to actually opt in and
say enriched from from logged context we
run that again and we now see that each
time through the loop all of the three
refresh all of the the three events that
are raised in the same loop iteration
will have the same counter value so if
we found that we'll see that we can now
see that when the counter was 95 we
produced the answer 90 25 and so this is
the the enrichment technique that you
generally use where you've got a message
hand lock and the message came in that's
got an order ID attached so you push
that onto the log context and then make
a bunch of vlogging calls that record
what how the order was processed and
then later on if you've got a problem
with it you can go and follow along that
chain and see everything that
contributed to the the same order being
processed all right okay we're looking
at the enrichment toolkit do we have
that group sorry
I flipped the wrong way actually I
skipped one as well a half so there is
there is one other technique it's
actually only only include it because if
you've used log4net
you're generally all logging is kind of
like source oriented so before I can
before I can log anything I need to
actually say which class is going to do
the logging and Sarah log doesn't throw
that concept away at all for Sarah log
we can actually create loggers
individual loggers that have enrichment
applied to them so we can say barda's
program
logger equals log or context and then
program which I hope is not static
because I see shell dislikes that good
in this case we can say program logger
debug calculating whatever that is and
in this case only the events raised by
that one specific logger instance called
program logger will carry that
information so this is the UM this is
the inverse of kind of the I want
everything Nicolle chain to carry the
same correlation ids in this case it's
like i only want the messages raised by
particular logger instance to carry this
information so you can see we got the
source context attached but to that
calculating event but we don't really
have it on and as the others in there so
cellulose got a fairly counted some
complex set of enrichment api's but
under the hood these are all represented
by the same concept and just where if
you've used middleware and say a spit on
that core or Owen that that idea that
you have a component you can plug into
the pipeline and can inspect all of the
events that flows through the pipeline
and interact with them is kind of a
pretty good analogy for how in Rich's
work and Sarah log so with just with
just this one implementation you can you
can implement a log event of richer and
richer and the parameters to that the
log event itself and you can inspect the
log event and look at all of its
properties and then you can not only add
properties to the event but you can
remove properties as well and this is
where things get interesting because
there are a few different schemes where
for instance you might want to log a
user object but not the password that
we're storing the text field attached to
a property or maybe we want to make sure
that there are no credit card numbers
ever logged through Laurine pipeline and
can just inspect individual and
individual properties and wipe them out
if they're armed if they look like there
might be a credit card number so in
Rich's are really a really powerful
concept and we use them for all kinds of
things
it probably looks a little bit more
complex than it needs to be you see that
we're passing a scalar value through
here as as the parameter instead of just
an integer thread ID and I think at
least some of you will at this point be
saying well how can this be a good idea
I've got all these complex objects in my
program and I'm passing them into a
logging library that's going to go and
muck around with some background threads
and all the rest house there ever going
to be thread safe Sarah log has a really
limited set of types that it will treat
as thread safe kind of scalar data like
it or to treat the built in numeric
types and strings and a couple of others
that are known to be immutable and then
the the other data that gets passed
through whether it's serialized or not
it gets pulled apart through a capturing
process and put into an object model
much like JSON nets so if you've ever
used J object and J array and those
types and Jason's on that sarah log has
structure values scalar value and some
equivalent types that that I used to
represent the actual log data so then
Richard here actually has to use a to
use the scalar value to represent the
thread ID just to say that's how these
things represented otherwise it will end
up getting converted using to string
because that's the way that's very low
determines that something ensures that
something is going to be safe to go on
them pass through an asynchronous
logging pipeline so more than meets the
eye so Sarah logs based on a pipeline as
well you can see on the left there
enrichers can go right in the middle and
then using that same pipeline we can
plug in filters and lots of other kind
of event oriented concepts and the
pipeline kind of looks like it's a fixed
topology but you can chain pipelines
together do all kinds of them event
processing type things like you can send
the output of a logging pipeline to our
X and then do some kind of analysis say
windowing or otherwise like rate
limiting and then pass the events into
another logging pipeline that might
dispatch the sinks so it's not really
enrichment that's the I guess the
fundamental idea here but the notion
that logging is an event pipeline rather
than being a kind of a big text
formatting engine so that's really Sarah
log
in a nutshell there's a lot more to it
obviously if you want to get in there
and learn learn about how its API is
work but if you if you focus on how
message templates make it possible to do
human friendly as well as machine
friendly logging without extra overhead
and enriches make it possible to handle
the kind of micro service architecture
that you wrote last summer and now your
lump is supporting and those two things
I think of the reasons that you use
Sarah lobe so you can find Sarah log at
0 log net that's me up the top there and
there's the message templates that are
also mentioned Ron github seek that I
showed is them up there as well I think
we've got some time left for for a few
questions as well
ah and because I will forget I have
Sarah log stickers I have many Sarah log
stickers so please come and come and see
me if you would like to grab one of
those as well so I can take any
questions yeah over there yeah okay yes
the question was with whether there's a
way to do the opposite of enrichment
which is kind of remove sensitive
information so the same interface is
used for that process so if we get back
to the example in richer you see it has
the ad property of absent method used to
modify the log event we jumped through a
few hoops because we want to minimize
the number of dictionaries we allocate
when you use thread safe data structures
so ad property absent seems pretty
worthy but that just adds a property
there's another one called remove
property if present that can do that
kind of work and I didn't show it in any
of the demos but the capturing process
to Sarah log is also pluggable so by
default you can use the little app
symbol to serialize a.net object just by
walking its properties you can plug in
what we call these structuring policies
there's a long long story about how that
name came to be and and they will
actually also let you customize how
objects are pulled apart and so we have
a destructuring policy that handles
f-sharp types we have policies
that handle things like Jason net
dynamic objects and we can serialize
those into Sarah log data and that's
also where we have a library that allows
you to mark sensitive properties with an
attribute so that say if you've got an
SSN property on on a DTO you can put a
put an attribute not logged on there and
the policy will make sure that's
excluded at the time that the that the
object is captured sorry yeah the sync
the the sync infrastructure that
actually sends messages out to different
destinations is really free of any kind
of like overarching policy like you just
plug it in into the interface and you
give an event to the thing and it can do
whatever it likes there's a pre-built
sync abstract based class called
periodic batching sync which will go and
batch up messages and then allow the
derives think to go and send them say to
some network destination and the
building one has a policy that does an
exponential back-off where if the M if
the attempt to log fails it'll wait for
twice the timeout and then four times
the timeout and get up to about ten
minutes and then start dropping events
on the floor so Sarah log I really
didn't want to deviate far from what I
knew and loved in log4net because only
it's a it's been a successful strategy
for me I log from that has that kind of
fail stop policy where nothing in the
login pipeline will bring your
application down and Sarah log not only
we don't we don't propagate errors back
out from Network calls we also try to
make sure that we don't keep too much
data in memory either so there's a
little bit of stuff in there you can you
can customize it by plugging in wrappers
as well that might wrap up a sink and a
different air handling policy sky a few
options that just answer your question
yeah great thanks yeah you couldn't it
wouldn't go anywhere yeah so if the
events already been sent
even's already happens let's say we have
a couple of logs that fly to a certain
board what happens then the over gets
again we know the order I guess the
question was if say something like an
order ID was only revealed after a few a
few related events had already being
processed could that be retrospectively
applied to the earlier events it may be
possible if you if you did something
custom in the sink infrastructure
there's an idea that has been floated a
few times called kind of transactional
logging where we buffer log events as we
go at the debug level say and we just
throw them away
unless an error happens in which case we
flush the hole up through Sarah log
doesn't implement that the trick to
implement what you're suggesting right
now would just be to come up with say
some kind of good operation ID and then
you would log that on all of the related
events and use the order ID to surf
backwards towards the the the built in
the operation ID perhaps okay yeah cool
right so yeah yeah this this is exactly
yeah this is this is one of the core
things that I think drove me to start
working on Sarah log and it's gotten
stronger over the course of we went
through the dotnet core shift that
everybody else I think has gone through
in the dotnet library space and we also
we really pared down the core of Sarah
log in that process the Coursera log DLL
has only got a few types for handling
they're kind of restructuring and
capturing kind of enrichment things and
we've tried to keep things like the file
based sinks which tend to grow until
they become less complex as databases in
separate packages and there I think
in all these cases we've tried to keep
options open so that rather than try and
make one set of sinks do everything we
try and keep them simple enough that if
someone wants the file logger to do
something we don't do they could if
they're prepared to spend the effort
just going to fork it and create an
alternative
and there's only a small amount of codes
have to modify but yeah I've seen that
phenomenon too it's a pretty strong
guiding principle for how we organize
the project because I see that the the
trajectory of vlogging libraries does
tend to really slow as they start to get
more complex yeah but thanks for
question I was a that's an interesting
observation too yeah and oh yeah
class name and line number are um very
hard to it is plot there is a way to do
it in fact if I have a chance to tattoo
after this I can sketch some code it
requires you to do a little bit extra
work each time you write a log statement
though but but yeah there is a trick for
doing it unfortunately with c-sharp you
can choose either to have a variable
number of arguments or you can choose to
get the class name and line number pass
through to a method and so several log
like many others chooses the variable
number of arguments but it's um it's
been that has been raised a few times
and there is there is a hack for making
it work so we happy to help with that
one any other questions we have some
time yeah at least at least is good yeah
I mean Sarah log has been built with it
puts the quality of the log data first
and then when it comes to performance
then the biggest focus we have on
performance is performance when the
logger has turned off because that's
probably the most critical performance
where you have see a debug statement in
a tight loop and you turn that off at
runtime and we try very hard not only to
make sure that that's as close to zero
allocations as possible and generally we
do have zero locations on that case but
we also do things like we don't use
volatile Zoar memory barriers by default
so logging statements where the logger
is off don't have any impact on a CPU
cache that kind of thing so logging with
Sarah log off is about as fast as it
gets we allocate a bit more as far as
the event objects that go through the
pipeline then I think than other
libraries but once you start to really
use any existing logging library to try
to include correlation information that
Richmond scenario you end up having to
allocate things like a dictionary to
hold them we've got some more room to
optimize in the future and some ideas
though so we're at least as good as
anything in the space at the moment and
I think we've got room to go better
definitely the intention yeah Josh oh
yeah
I just format it and start all over
again so yeah this errorlog project yeah
under the sarah log project i think
there are about 50 somewhere close to
about 50 and the rest it's hard to track
them all down but yeah there are a lot
produced by people outside the project I
think we have time for one more
potentially well good okay thanks you
guys been an awesome audience thanks for
coming along really appreciate you
taking the time and come say hi and</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>