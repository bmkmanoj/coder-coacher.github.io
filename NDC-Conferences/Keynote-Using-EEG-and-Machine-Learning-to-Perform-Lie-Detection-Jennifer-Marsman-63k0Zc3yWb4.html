<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Keynote: Using EEG and Machine Learning to Perform Lie Detection - Jennifer Marsman | Coder Coacher - Coaching Coders</title><meta content="Keynote: Using EEG and Machine Learning to Perform Lie Detection - Jennifer Marsman - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Keynote: Using EEG and Machine Learning to Perform Lie Detection - Jennifer Marsman</b></h2><h5 class="post__date">2017-09-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/63k0Zc3yWb4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone my name is Jennifer Mars
Minh and this crazy contraption you see
me wearing on my head is a headset that
can read EEG or your brainwaves and I
took this headset and I put it on my
husband and I asked him a series of
questions and first I had him tell me
the truth and then I made him lie to me
and what that gave me is a labelled data
set of what his brainwaves look like
when he's telling the truth and what
they look like when he's lying and so if
you know anything about machine learning
you know you can take that data feed it
into a machine learning algorithm and
then build a classifier to perform a lie
detection so that's what we're going to
talk about today I do work for Microsoft
if you do have questions that don't get
answered today during the session feel
free to reach out to me on Twitter on my
blog and then Tim Huckabee and myself
are also going to be doing it ask me
anything
immediately following this session on
the fourth floor so I'm happy to take
questions there as well all right so
let's talk about this taking a step back
what is e e G and of course for the
official definition we can turn to the
source of all knowledge which is of
course Wikipedia right so you can you
can read the official definition there
essentially what what it is is the
electrochemical signals that are going
through your brain that can be measured
in a very non-invasive way for those of
you who are in the room early and saw me
messing around getting this thing on my
head
you saw that there's this the headset
has actually little felt pads and so I
took saline solution the same thing I
use on my contact lenses and put that on
the felt pads and then that helps it
read the signal so it can kind of read
those those signals that are going on in
your brain and I don't think I need to
say this to anyone in the room but just
just in case I can't actually do mine
reading with this all right you put this
on someone's head you don't know what
they're thinking or anything like that
but what I can do is I can create
mappings between patterns of EEG and
actions either in the physical world so
for instance like making a drone fly
with the power
of your thoughts by thinking up-up-up or
in the digital world and I'm gonna show
you I'm gonna attempt to show you that
in a minute by trying to move a cube
with the power of my mind and then
secondly I can see patterns in this data
or more accurately I can train a machine
to see patterns in this data and to
learn based on historical data what
those what those patterns actually mean
so using in supervised machine learning
you can use historical data from the
past to make future predictions so we're
gonna see how to do that as well in the
field of lie detection all right so let
me just start with a quick demo so this
headset is actually made this isn't a
Microsoft thing I do work for Microsoft
but this is not a Microsoft thing this
is actually made by a company called
Emotiv
which has offices in San Francisco as
well as Taiwan it's a female founded
company woman and so yeah yeah so it's a
great but it's a really neat headset um
that I that I have been just Westing
after forever I'm the founder of the
company Tenley did a demo with it as a
TED talk way back in 2010 and ever since
then I wanted headsets so badly so I
want to show you a little kind of
snippet of what some of the people are
doing with today and some of the things
that got me super excited about it so
I'm gonna start by showing this is a
piece of software that actually is made
by a motive that came with a motives
with their actual software so this isn't
software I wrote this is software that
comes with the headset and it shows you
a couple things so you can kind of see
that everything is reading green right
now which is good that means it's got
strong signal from all of the 14 nodes
resting against my scalp so that's great
if I switch over to here you can see
everybody look this way is it looking
that way one way the other way yeah okay
cool when I'm looking I can't actually
see what's happening in front of me so
hopefully that's working blinking blink
blink blink some blinks and then raise
your eyebrows smiling coils so I didn't
actually train it for this one but you
can see it's picking up some of those
things now wire this is important and
where this is going to come into play
later is that space
movements also feed into EEG de that's
what you should be taking away from this
so just moving your face is enough for
it to pick up with EEG so some of this
is actually affecting the data so just
bear that in mind and then this is the
demo that really got me excited with
about this headset when it was first
shown and as a TED talk all those years
ago and so what I'm going to attempt to
do right now is move that cube with the
power of my mind okay so everybody's
brain has a unique signature much like
fingerprints where we all have you know
slightly different fingerprints your
brain has a unique signature as well and
so you know you everyone I'll show you
actually in just a second I can show you
like the wave patterns and such so like
my waves might spike it like 24 and my
husband's might spike it like 3 so you
need to take him to count things like
that so what I'm gonna do is start by
just training what my brain looks like
at a neutral state alright so this is
just gonna be me I'm gonna train it for
neutral so what's gonna happen is it's
gonna take 8 seconds and I'm just gonna
try to close my eyes and go to my happy
place in front of a crowd of you know
650 people staring at me I'm gonna try
to relax and just like try to think AB
cut all just kind of go to a neutral
relaxed state okay so we're gonna do
that for eight seconds there's gonna be
an awkward little silence and we're all
gonna be okay with it all right and then
when I am gonna close my eyes so when it
says done well somebody just yell out
loud zone you open your eyes okay we
good with that okay thank you all right
so we're gonna train now
eight seconds happy place here we go
training now
thank you you guys were awesome with
that okay so I'm gonna go ahead and
accept that training I think I was
sufficiently relaxed and now what I'm
gonna do is there's a series of actions
that they've already programmed it to do
right and so I'm gonna do pull I'm gonna
Majan pulling the cube towards myself
okay and so what I'm gonna do now is I'm
gonna think pull with my mind okay so
this is just pattern matching right
we're just doing really basic this isn't
even machine learning here I'm just
thinking pull and what it's gonna do is
take the pattern that my brain waves are
using and I don't necessarily even have
to think pool I could be thinking
hamster dance but whatever I think as
long as I'm thinking that thing
consistently whenever I want it to pull
it should work right that make sense
all right cool so now we're gonna map
that pool and my brain activity to to
that motion so now I'm gonna train it
again by thinking pull for eight seconds
it'll be another eight seconds here all
right so now we're gonna go ahead and
pull Oh what was that that's not good
there we go whoa okay yikes alright so
it lost signal right in the middle of
training so that's not good but let's
see if we can get this up alright so
let's try one more time hopefully that
didn't affect anything too bad and here
we go one two three
okay I'm gonna say no I'm actually gonna
train it one more time because I was not
totally focused there because the thingy
the blip threw me for a second so if you
do it one more time a little more
focused all right one more two three
here we gonna go train here we go
okay so now when I hit yes the cube is
gonna be live so now what we're gonna do
is see if I can kind of repeat that
pattern of motion I'm gonna try to think
pull the same way I was thinking before
and see if we can actually make this
cube move okay all right let's do it all
right now pull oh come on yeah you have
not lived until you've moved to keep
with your mind I'm just I'm not gonna
lie
I feel like Jean Grey every time I do
that it is so cool all right that's the
whole reason I bought the headset really
was was to do that okay so you can see
how I got pretty excited about the
potential applications here so let me
just show you a quick two-minute snippet
of what people are doing with this
device today and some of these these
possible potential applications so this
is a really like just a short part of
Tammy's TED talk from back in 2010 and
then if you would like to you can go
back and watch the whole thing it's only
like 1012 minutes long it's pretty short
so go watch the whole thing later but
let me just show you what people are
doing today and I have to hit the play
button there we go
that you can control the world in your
mind and also colors lighting sound and
effects can dynamically respond to your
emotional state to heighten the
experience that you're having in real
time the moving on to some applications
developed by developers and researchers
around the world with robots and simple
machines for example in this case flying
a toy helicopter simply by thinking lift
with your mind the technology can also
be applied to real-world applications in
this example a smart home you know from
the user interface of the control system
I love this dude because notice how he
always uses his hands and does the like
these are not the droids you're looking
for saying like watch him he's up he's
got to do his hand he said not the
droids you're looking for
he's my favorite he's awesome yeah now
this is actually my favorite application
of the technology though right here
finally to real life-changing
applications such as being able to
control an electric wheelchair in this
example facial expressions are matched
to the movement
straight
all right we'll cut it off there we'll
cut it up there but so you can see
there's a lot of really cool things that
people are doing with this already
there's a lot of academics and
researchers and and a lot of people
exploring and it could be anything from
game development so imagine like having
a real-time feedback loop where you
could tie into people's emotions right
so let's say you can actually sense one
of the things I didn't show you is um
there's kind of a sense of like
excitement level that's mapped so
imagine that you're playing a game and
the you can actually sense that the
users getting a little bored so like
make another zombie jump out right so
you could actually base a real-time on
the actual users feelings and
expressions and how they're interacting
with the game and be able to add
additional stuff based on that and then
of course the thing that really gets me
there's kind of the smart home
applications and other applications as
well but my favorite is the one at the
end when you consider someone like the
the case of a paraplegic or someone
paralyzed from the neck down being able
to use facial expressions and the power
of their thoughts to move an automated
wheelchair like those kind of things are
are really exciting to me when we have
the power to you know use technology to
make the world a better place like that
so all these life-changing examples all
these cool things that we can do to
benefit humanity and what does Jennifer
choose to do with it lie detection on
our husband yeah way to help humanity
Jen so um let me tell you where I kind
of got this idea you guys probably watch
all the same you know criminal drama
shows that I do so you probably heard
the the fact that some people question
how effective polygraphs are and so the
typical polygraph where you're you're
measuring things like galvanic skin
response like have sweaty your palms get
and you're you're blinking raid and your
heart rate and things like that and the
the critics of this method say that
those things actually measure your
emotional response so if you're really
nervous sometimes you get the same
effects as if you were really you know
guilty versus lying or telling the truth
versus lying and so I started thinking
so again let me let me say really
clearly I do not claim to be a
neuroscientist
I have very little there's actually very
little known about the brain it's
amazing how much we still don't know
about the brain but I did get my
master's degree in artificial
intelligence and machine learning and
one I did take a look one brain science
class while I was there and one of the
things I remember is that when you're
telling the truth that tends to activate
the recall centers in your brain and
when you're lying that tends to activate
the creative centers in your brain so I
started thinking if I have this headset
that's reading from these 14 different
points on my head could I do that like
would that maybe be possible so it was
one of those things where I just started
this as a fun side project let's see if
this would actually work and tried it
out and so in good little former
graduate student you know thing I listed
out my goals and my tools and blah blah
blah
okay so here's the fun part my actual
experiment procedure so I my first my
first victim here was my husband was my
actual husband and I sat him down in the
chair and I did make him close his eyes
and the reason for that was actually two
reasons number one I was actually
sitting next to him because I had the
headset has to stay pretty close to here
so that it picks up over it uses a
proprietary technology kind of like
bluetooth to talk back and forth and so
I didn't want him out of range so he was
sitting pretty close to me and I didn't
want him reading the questions over my
shoulder because I was actually putting
a mark in the data when I started asking
the question and like when he finished
answering so that way with all this
brain data I could slice out just the
part where he was thinking about the
answer right and so if he was reading it
over my shoulder that I wouldn't be
getting an accurate slice of when he was
actually processing the information so
that make sense all right so that was
one reason and the second reason was
because you guys saw earlier how when
you actually I'll let me run the other
thing as well I'll run test bunch and
show you this for a second too when you
do have a whole bunch of I'll come back
to this verse again when you do have
facial movement that gets picked up in
the data because remember how we were
able to pick up like the blanks and the
smiling and the raising eyebrows and
stuff in that data so EEG these things
are actually affected by facial
movements too right so I didn't want him
to be like scratching his face or
blinking or anything like that so I just
said just to get the data as clean as
possible
like in the test runs I said can you
just you know close your eyes and just
you know ant listen an answer like that
so that was the second reason and then I
ran this tool called the mode of test
bench and I'm launching that right now
for you and we can see that in a second
but I asked him a series of questions
and those are some of the questions
right there at the beginning and I asked
him truth and then lie and
differentiated the data and I did do a
nice confusion matrix where some of the
correct answers to these are yes and
some of the correct answers to these are
no because I wanted there to be a nice
confusion matrix of like true/false
yes/no I wanted things on every single
quadrant right and so like do you we
don't have a dog then no we don't have a
dog yes he does have a PhD no he doesn't
have red hair
yes he's married no he does not have
five children well at least he does not
have five children with me he may have
five children but if so then we have
another problem so all of those things I
asked and let me show it to you real
quick tour so you can see like the
actual process so I was using this tool
this is test bench which also came with
emotive and you can see oh no I went
orange on one of them that's okay so
what this actually does is it's here's
all fourteen of the different signals
right here and so you can see if I kind
of go calm for a second pretty
flatlining there and then yeah that
makes it crazy so you can see that so
you can see kind of different brain
activity and how it actually shows up
like in the in the thing so it's pretty
cool so that's what this does so this is
the actual EEG reads and you can turn
off certain things so the different
sensors if you want to focus just on
certain sensors like I can turn off some
of these readings and just look at some
of them and focus in on certain ones too
that I find to be more useful and then
when I was actually collecting this data
I used this little marker tool where I
was sending manual markers so if I open
where did I put those documents emotive
so here's one of them actually let me do
the data too when I think that one like
a little better so I have a couple
markers here and so for example this
question asked things so I could if I
when I was asking Eric the questions I
could say you know ask the question or I
think I said question asked said the
question got his answer and then sent a
question answered and you can actually
see see the little one and the two and
the data here so that allows me to
extract out I just went through and
wrote a little python script
afterwards to be able to extract out
just those signals and then move them
over so I make sense
good you guys see that that's pretty
straightforward okay cool the sampling
rate is a hundred and twenty eight
readings per second if you do the math
on that that works out to approximately
every eight milliseconds it's taking a
reading so so pretty good there all
right so that's all I can think of to
say about that so let's go back here
then for a second and then oh and here's
here's the documentation of the actual
process that first run I wanted to
document it like for my blog and stuff
later and you can tell my husband is
really happy about helping me with this
research no Jennifer don't have an
Ashley Madison account can I please go
watch TV no no honey I'll decide when
we're done hahaha okay and then here's
the sensor quality so for those of you
who again were in the room a little
early you might have seen when I was
putting it on my head before it went all
green and beautiful like that there was
actually a lot of yellow and red and
black and Jennifer shifting around
chunks of hair so that I can have yet
more pictures of me on Twitter with
crazy hair so it's actually really funny
if you look at when a motive actually
presents this stuff every single time
without fail they use a bald guy because
they're so easy like my husband is also
follicly challenged and like when I put
the headset on him it's just like you
put it on and bam it works and it's
fabulous with me it's like a 20 minute
long process of okay getting it on and
then shifting chunks of hair around to
make sure it's getting a good reading
everywhere and it's a complete pain but
anyway so you can see though once it's
reading there's a basically an
enumeration of different levels of
signal quality so you can
get you know it's really good to use for
data cleaning later to make sure you're
getting the highest quality data signals
and so Green is represented by four so
that means that's the strongest signal
quality and then there's progressive
levels of signal degradation so yellow
knacks then orange and red and then
black means it's not reading any signal
at all all right and then all of that is
collected in the data to actually I
didn't show you the data you guys wanna
see the data let me jump over to the
data so when I record that in test bench
like I was showing you here as that data
is being recorded then they actually
store it in a proprietary format but
then they give you a nice little convert
to CSV thing with it and so you run that
convert to CSV and then once it's a CSV
it looks a little something like this
can you guys read that okay I do I'm
gonna make a little bigger bigger okay
so here is what the data actually looks
like so first of all there's a counter
the counter actually just counts up to
128 and resets and because that's the
128 readings per second so that kind of
gives you the sampling right there and I
did not use that data at all I just see
that out I threw this out as well here
are the actual relevant values so these
are the 14 different places and I'll
show you how those map to areas on the
scalp in just a second but we have
something a f3 f7 f3 kind of all these
fun names oh want to know too etc etc so
those are our 14 different things right
here and then we actually have there's a
gyroscope in there as well
so measuring kind of the angle of your
head and I did not actually use this in
my first runs but that's kind of on my
to-do list that it might be fun to play
with someday because these think about
if any of you guys watched like the
World Series of Poker and you know how
sometimes like more inexperienced poker
players have little towels well maybe
there tilt their head a certain way when
they're lying or something like that so
there might actually be something to
that data so that's like on my list to
play with someday but I haven't done
anything with it so far but that's the
the gyroscope stuff here is the marker
column so the marker column remember
when I was sending markers I sent the
one when the question was started and
then a - when I finished he finished
answering so I could extract out that
stuff this will read all zeroes except
for when I sent the one in the two
and then I can just parse this file and
then pull out everything between a1 and
a2 and use that as a single question
answer session here's the sink this
doesn't matter um here's the timestamp
the way they do timestamp is a little
bit a little bit crazy because they they
have it as two separate things so here's
the seconds value and then here's the
milliseconds value in two different
columns so I actually do something at
the end to make those a single time
value as opposed to two just to make the
math easier but here's the value in
seconds the value in milliseconds and
then this is the this CQ represents
contact quality so that's those levels
from from four to zero from green to
black that I was showing you before so
you can see kind of when you first get
started and it first goes on your head
it might read zero for a second and then
this one was reading green after that so
that's good and so what I do but I was
collecting data is I would throw out all
this zero stuff at the beginning to get
a good accurate a good good accurate
data all right so here's contact quality
and I have that for each one of the
fourteen different sensors so our
contact quality for each one of these
and you can see where they map to the
places on the brain based on the diagram
I'm going to show you in a second and
then here's where their data ends right
here and then after that I added three
columns myself um the first column is my
label right because in machine learning
we need we need a nice labeled data set
if you're gonna do supervised machine
learning so for this particular session
I was at this person was telling the
truth so I put is truth is one so now I
have that this is truth data marked in
there and so then when I make
predictions when I want to predict if
something is truth or not it will give
me zero if it's lying and one if it's
the truth and then here's the time value
and this is just using those two values
that you had before taking you know the
seconds times a thousand plus the
milliseconds to get the time all in one
value like so so I did that right here
and then after I did the initial
experiment on my husband and such I
wanted to see if I could do it
general-purpose so I started collecting
data from lots of different people and
just for privacy reasons I wanted to not
associate their names with it so I put
this is user 18 in my data right here
and so here's user eight
Keane's data alright so that's just a
quick look at the data that I was
getting so now if we jump back here you
can see we already saw this the signal
quality and that was represented in the
Excel spreadsheet by that C Q underscore
each one of those unnamed and then
here's the actual mapping of where those
different things you saw those columns
in the Excel spreadsheet here's where
they actually map to the positions on
the brain and this is a heads up thing
so you're looking from the top downward
where that little bump on the top is the
nose and those are the ears t7 and t8 oh
right here so you're kind of seeing this
view right here eek right like that
a f3 and a f4 right here here's the t78
the the ones that like hurt your ears in
the back or o 1 and O 2 right here so
all of those are the are the various
sensors that we have here and where they
map to places on the brain ok so now one
of the things that I did do was usually
when you have an idea that you think is
super cool someone has already thought
of it right so I did go out on the
internet and did some research and
thought hey has anyone thought about
doing lie detection in conjunction with
EEG before and and what has been their
results and such and I was doing some
some research on this and I did read
about something called the p300 ERP and
so some you know government agencies and
researchers are looking at this this and
what this actually does is the piece 300
ERP response actually measures that
flash of recognition so let's say you're
walking through NDC NDC Sydney here and
you're walking through the crowd and you
see someone and you get that oh I know
that face from somewhere you know that
feeling you get that's the P 300 ERP
response so it's that oh I know that
from somewhere maybe you don't remember
the context of you know they could have
done a kindergarten with me maybe I
worked with them maybe I saw them at a
user group before whatever but that
little flash of recognition is called
the P 300 ERP and if you look at it Anna
if you look at it plotted this is what
it actually looks like it's this little
dip there's this kind of big relative
dip that you see right here and it's
active the reason they call it P 300 is
because it's activated roughly 300
milliseconds after the visual stimulus
that you got and so you can see right
here the dip 300 or 500 is probably more
accurate but it's a it's a bigger it's a
little dip that you see right right
afterwards and so government agencies
have actually used this response in EEG
in conjunction with lie detection so the
idea is instead of like a polygraph
where you're asking people yes or no
questions and measuring those responses
you have a headset like this they're
probably a better quality one or up the
maybe a hospital grade one I don't know
but you use some kind of a EG detector
and you can then say things like I
shouldn't say that this is no this is
actually a really really good headset in
terms of like the value there was
actually a study done I was reading
studies about the various EEG readers
and this one is one of the highest in
terms of like the amount you pay versus
how high-quality the the signal is it's
very very good so I am actually a huge
fan of this this one side so what they
actually found is so if we're trying to
use this in conjunction with detecting
guilt right and and lie detection what
they did is they sat a person down and
had a headset on their head and then
asked showed them images right so they
put pictures in front of it some of them
were like just neutral images whatever
but then say you put a picture of the
crime scene or the murder weapon or
something like that and if you put
things like that in front of them and
they get that flash of recognition the
knack and show that okay maybe they know
more than they think they do or they
have seen this before or there's some
kind of you know some kind of
recognition happening and so they
actually some people are experimenting
with using this to help with lie
detection and a little chart that you
see right here is actually probably the
the silliest way of saying this but
essentially what that means is it's the
information that of what the suspect
recognizes correlates to something that
someone with no intimate knowledge of
the crime should know then you know
maybe they're guilty right and if they
if they know something that they
shouldn't know then maybe they're guilty
and if they know they
know something that someone who didn't
know anything about the crime doesn't
know then it's probably okay so very
very straightforward thing right here if
the this is the information the suspect
is expected to know information that
should not be known to the suspect and
that information that the crime that
only a perpetrator would know and so if
they know stuff that is correlated to
information that only the perpetrator
would know then maybe they're guilty
right like kind of like da right it's a
lot of pretty charts to say it something
pretty simple but kind of cool all right
so what I took away from this kind of
this was really really interesting stuff
it's a little different than the way I
was approaching it but what I one thing
that I took away from this that was
really really useful is I was actually
wondering I had no idea in what
timeframe these responses were happening
like in terms of number of milliseconds
after the stimulus and so knowing that
something like that recognition flash
actually happened you know 200 to 500
milliseconds after the tip stimuli I was
like okay my sampling rate of 128
readings per second which is roughly
every eight milliseconds it's probably
good then if I'm getting that every
eight minutes so that was a big takeaway
from me that okay because I was that's
one of my concerns was is the sampling
right high enough you know am I getting
information fast enough to be able to
know if this is working well and from
this I was like okay I think I'm
probably good with every eight
milliseconds time okay so now let's
transition for a second to Azure machine
learning so I used a drum machine
learning to implement this I work at
Microsoft and so I like to play with all
of our new technologies for machine
learning and there's a lot of cool stuff
we have machine learning there's some
new stuff that's going to be come out in
the Ignite timeframe which I'm really
excited about there's the C NT K which
is our deep learning open source
framework so we have all kinds of cool
tools cognitive services which are some
pre-built models that you just call with
the REST API so we have all kinds of
cool stuff and so for this I just wanted
I was just playing around and wanted to
kind of rapidly iterate and stuff so I
chose as your machine learning and XML
is pretty cool there's 25 pre-built
algorithms that are already included in
there that you can call and utilize and
there's a whole bunch of modules for
importing the data and cleaning the data
and then you can train models and test
models and then the deployment story
is beautiful it's literally like a
button press and it takes your model
stands it up as a rest endpoint
generates a token so that only people
with that security code can can call the
web service and it's just it's so easy
like the deployment it's just awesome so
that's one of the things I love the most
about it because usually deployment is
the worst so uh that's that's really
cool so that's kind of some of the power
of Azure machine learning so I use that
and here is one template that you can
use if you were looking at Azure machine
learning and trying to figure out you
know it's web-based tools so you don't
need to download a lot of stuff so you
go there and you kind of have to drag
and drop or I'm sorry you drag and drop
little modules and string them together
to create a data flow and so in this
case you could take a data set like this
and then do some kind of data cleaning
and I use various modules for that and
then machine learning we split our data
and the reason for that is if I have
this nice labeled data set of you know
here's all this you know great EEG data
and then here's whether he's telling the
truth or lying if I fed it all of that
data and then I went back and I wanted
to see if it worked and I you know took
some of that data and said okay for this
EEG pattern is he telling the truth or
lying it's hard to know the answer right
or something pretty close to the answer
cuz I trained on that data right so it's
not gonna do as you know that I can't
really trust the answers of that it's
performing that well so typically in
machine learning what we do is when we
have a nice label data set like that you
hold back a certain amount of the data
so you can assuming the law there's lots
of different ways to do this there's
cross-validation and some other
techniques as well but one technique you
can use assuming you have a sufficiently
large data set is to use just a simple
3070 split so I take 70% of my data
train it with that data and then hold
back 30% and then once I built that
train model I apply you send in like
just the features or just the EEG data
of the of the 30% you've held back see
what the model generates and then I can
compare that to those known right
answers that I've held back does that
make sense okay so that's why that's why
we do that in machine learning so I took
seventy percent of the data trained a
model with that and then this
puts a trained model essentially and
then I take that 30% of the data I held
back for my test data I apply it and
what that does is the score uses only
the features puts it into the model gets
back to the results and then compares it
to the the known right answers that we
have in the test data and then that
gives it a score of accuracy numbers
precision recall things like that and
then you can evaluate that side-by-side
with another model so I do that exact
same thing over here but maybe over here
I use a different algorithm and then I
compare the two and see how well they do
or once I've settled on an algorithm I
start tweaking the initial parameters
because that can affect accuracy and
things like that so this is kind of the
the art part of data science where you
iterate and iterate based on your data
and see how you can get the the best
results there all right so is that all
kind of makes sense all right the one
big thing that's probably still missing
here is okay Jen if you just said that
there's these 25 different algorithms if
I don't have a machine learning
background how do I know which algorithm
to feed into the model so enter the
Asura machine learning cheat cheat cheat
cheat cheat cheat cheat cheat so this is
an amazing thing with a large friendly
do not panic button right in the middle
and so what this does is actually give
you a lot of different ways to use talk
about data so you can do things like so
regression and classification so those
are both forms of supervised machine
learning I'm a supervised machine
learning we're again taking that
historical data from the past a label
data set of historical data and then
using that to make future predictions
and the difference between our
regression and classification is that
regression predicts a number right so
like the cost of a home how much your
energy bill is gonna be things like that
you would use regression for and then
classification is when you're predicting
between distinct categories so who's
gonna win the World Cup this team or
Brazil who is going to it are my sales
numbers gonna be over or under um it
doesn't have to be binary either it
could be you know what what color does
this series of pixels most closely map
to you know red orange yellow green blue
etc alright so that's classification is
when you're dealing you're trying to
predict between discrete buckets
discrete categories and then regress
is when you're predicting a number right
and then anomaly detection is really
interesting anomaly detection is when
you're trying to do this with a highly
unbalanced data set okay so imagine the
problem of credit card fraud detection
all right when you have your whole
database of all these you know all this
credit card data you may have a whole
bunch of you know valid transactions and
then out of your whole data set probably
the number of fraudulent transactions is
gonna be a really small subset and then
the number of known fraudulent
transactions is probably gonna be even
smaller still right so you have a very
small number of known fraudulent
transactions and then you have all of
these valid transactions and so when
it's a very unbalanced data set like
that it's hard to build a conventional
classifier using some of the other
methodologies and so anomaly detection
is something that can specifically
account for that so basically you can
train it with with what normal looks
like and then when you get something
that's kind of outside the bounds of
normal you can utilize that so credit
card fraud detection uses anomaly
detection I've used it for oil and gas
pipelines to detect you know problems
with pipeline flow Network intrusion
detection it's really good we use it on
our networks that Microsoft fun fact
people try to hack the Xbox Live Network
like all the freaking time like
everybody wants more gamer points right
so like that network is like constantly
being things so we have like network
intrusion detection algorithms running
on on that all the time so all kinds of
cool stuff with anomaly detection and
then clustering clustering is actually
um unsupervised machine learning so
we've been talking about supervised
machine learning using a labelled data
set to make future predictions that's
supervised unsupervised machine learning
you don't need a label with your data
set you can just have a whole bunch of
data and then clustering algorithms just
group like things together so that's
really good for things like building a
recommendation engine um you might want
to group like movies together or like
restaurants together so that people who
like one might like others and that sort
of thing okay
all right so quick test if I have a
bunch of EEG data and I'm trying to
predict if my husband is telling the
truth or lying should I use
classification clustering anomaly
detection or regression
classification 10 points to Gryffindor
yes that is a classification problem so
we would go here predict categories am i
predicting three or more or two
categories two right I was just
predicting between truth or a lie I did
not ask any questions like does this
dress make me look fat where the answer
may be somewhere in the middle okay so
that is exactly right so then you can go
and use these these algorithms are the
best ones to kind of get started with
and then if you look at the cheat sheet
it actually gives you a whole bunch of
really great information about where
each algorithm shines for example SVM's
that stands for support vector machines
those are really good when you have lots
and lots of features like over 100
features I'm feeding into your algorithm
the things that predict your label are
your features so if you have a whole
bunch of things that might affect it
SVM's work really well
there's linear models right here as well
as I'm nonlinear things like decision
tree and SAAM bowls here and you can see
like the boosted decision trees are
really really accurate but they also
take up a large memory footprint so it
kind of tells you some of these kind of
pros and cons of each of them so you can
kind of look at those and decide okay
which one might work best and try a
couple of those I usually start with one
linear and one decision tree to start
and see how it's performing better and
then iterate from there based on that
because if a linear model works great
because they're super fast but they
don't always work because real life is
messy alright so if you would like to
download that cheat sheet and print it
out and hang it in your office like all
the cool kids do you are totally welcome
to you can download it at AKA ems Azure
machine learning cheat sheet and then I
also have a blog post that I did on
getting started with our machine
learning if you'd like to play around it
with it more yourself and that's a AKMs
wack hack ml that's got a whole bunch of
interesting things so one of the things
I put is um if you want to just get
better at machine learning and practice
it you need two things like number one
you need cool datasets to play with and
then you need cool problems to solve and
so I give you here's a whole bunch of
places that have really cool datasets so
like I have sources of where you can
find cool data to play with I have a
tutorial like an end and walkthrough is
linked from there a link to where you
can provide feedback which is actually
if you guys don't know about that you
know the Microsoft like user voice thing
where you can go and submit
that is really good to snoop on if you
guys don't do that right now like if you
want to see what's coming because they
actually mark some of them as this is in
development or this is we're still
talking about it this is in
consideration in development whatever so
you can kind of see what features are
coming sometimes if you snoop around in
there so just you didn't hear from me so
really really cool stuff but there's a
whole bunch of great resources linked
from there I did write it for a student
audience so the the actual title of the
blog post is how to win a hackathon with
Azure machine learning yeah but just
ignore the spin in the first paragraph
and the rest of it is just like getting
started with Azure machine learning all
right and then um if you'd like to see
an end end demo for like how do I get
data into Azure ml how do I do data
cleaning with it because that part is
really really important how you get the
data in a format that a machine learning
algorithm can use it effectively and
then how to train a model test a model
deploy a model you know call the model
all that stuff I have a whole end-to-end
demo predicting whether or not someone
would survive the Titanic based on
demographic information about them like
their age their gender how much they
paid for their ticket stuff like that
so you can go and check that out there's
a video of that online there okay
so now I ran this on my husband I
collected the data I've explained the
experiment procedure I put it into Azure
machine learning so let's go look at it
here is my model that I built and I am
going to right click on the evaluate at
the very end and hit visualize and there
is a chart here I'll show you how to
read it so this is this is a chart that
plots the true positive rate versus the
false positive rate so false positives
are when you say something is true and
it is not in fact true and true
positives are when you say something is
true and it is true all right
so false positives are bad and true
positives are good so perfection would
be if we had false positive rate of zero
so to plot it on the chart zero would be
like that all the way up and then true
positive rate we would want that to be
one which is 100% and go go all the way
up here to Shoop all right so the sense
the tighter it hugs this curve the
better your machine learning algorithm
is is performing okay so you want it to
be as close you know
hug this as tight as possible and then
this is usually really hard to see on
projectors but there is like a thin gray
line that goes up the middle right here
so this is essentially 50-50 random
chance a monkey
flipping a coin all right so you want
your algorithm to be performing better
than that if your algorithm is not
performing better than that start over
there was a problem there go back go
back to the drawing board all right
so I you can see this one is doing kind
of man this was the linear algorithm but
this one this was the decision jungle is
actually doing pretty well so if we go
down and look at the the data here
you can see the true positives and the
true negatives are high which is good we
want those to be high and then the false
negatives and false positives are low
which is good and then we have an
accuracy of around 93% and high
precision and recall and and stuff as
well so I started to think oh my gosh
there might be something to this maybe
there may be you know the this this is
preliminary stuff but it looked kind of
like there may be something to this and
so literally you guys literally like I
like I think it was like a week or two
right after I had gotten done this
initial work with my husband my team had
an off site all right so I work on a
distributed team my husband my my
manager sits in Minneapolis I sit in
Detroit we're like spread out all over
the US and so you know once or twice a
year the whole dysfunctional family gets
together and you have an off site and we
talk about our stuff and all that kind
of thing and so and this was the year
when we had to do be out a commitment we
had a one of our my Jobs was to do a
whole bunch of channel 9 videos you guys
know channel 9 Microsoft's YouTube
channel 9 dot I miss Dan comm good stuff
ok go watch him all right so that year
we had a goal where we had to deliver
like we had to create like X number of
channel nine videos that got you know
why number of views each so they had to
be not only Channel 9 videos but popular
Channel 9 videos like those kind of
things so that was one of our views so
our marketing department had actually
hired a camera crew and brought them to
our off-site just in case you guys feel
like making some videos right now just
go ahead you know so so
but that gave me an idea right this had
kind of worked on my husband so I
grabbed my manager and I was like hey
remember that headset that you let me
buy I've been doing some initial machine
learning work with it and would you mind
if I just put it on you and asked you a
few questions and he was like yeah sure
whatever and he didn't really know what
I was doing yet so I got my manager and
then I grabbed the camera crew and I was
like let's have some fun all right so
first I had to build a class part and I
wanted to build it specifically for my
managers brainwaves okay because I
haven't done the work to generalize
across all people yet so first I asked
him a bunch of questions and made him
tell me the truth
are you a male yes
and you ever worked for me or song yes
okay so you guys get the idea right and
then I made him lie to me do you want a
PhD yes he does not you currently have a
pet yes yep do you have yes
okay so you guys get it right now what
would you do if you had access to your
managers brainwave ah
do you believe Microsoft is the best
company in the world to work for yes
am I going to get a promotion this year
okay so you guys all heard that totally
awkward little giggle right so what did
it mean didn't mean he had some good
news and he couldn't share it or did it
mean I totally thought like I had to
know so I did what any girl would do and
I ran back to my hotel room that night
and build the classifier with his
brainwaves so what I did was I did the
same process that I had done with my
husband
I took the truth data uploaded it to as
machine learning took the lie data
trained a model that was specific to my
manager deployed it so it stood up as a
rest endpoint and then I wrote a really
ugly Windows 10 app because as anyone
who has ever seen a Jennifer Marvin demo
knows I am not that good at UI design
I'm really good at algorithms
yeah but design has never been my strong
point so I made this really really ugly
Windows 10 app and what all it does
basically is it calls the the web
service button and so I I trained with
just the truth and lie data and then I
was going to ask it this is this program
will basically ask it the the two
questions that I asked at the end that
data all right and we'll call those and
then I also tried to do something cool
and I made a little thing that gave you
the confidence levels as well so it'll
show like how true or how how much of a
lie we think it is all right so here we
go
do you believe Microsoft is the best
company in the world to work for my
manager said yes my algorithm says he
has an iPhone
and he's really into design I'm just
saying we might have like a closet like
Mac fanboy on our hands all right and
then the real important question
am I getting commercial this year my
manager said yes and my algorithm said
and I am delighted to announce that I
did get the promotion so you can see
there's a lot of things you can do
this is just a I've had so much fun
working on this project and I have like
all these other ideas for how you can
use machine learning in conjunction with
the eg like I I can't even there's so
many here's a couple of things that I'm
looking at doing next
okay so after kind of the initial data
runs I did with my manager and my
husband and such I did kind of some
second data runs I don't expect you to
read all this so let me just call out a
few major points so the first the first
couple of runs I did I took I just did
one marker per question and then I took
like a time interval around it and so
then after that on the second run I
started doing like a marker before I
asked the question I asked the question
all of that and then a marker after they
answer so I get all the data more
accurately I started taking neutral
brain state recordings so one of the
things I need to do still is like
normalize it across all people so that I
could just plop it on anyone's head
where I don't have training data for
them and see if I can do it so I'm to be
able to do that I started you know even
saw how when I was doing the thing at
the beginning where I was pulling the
the cube towards me I needed a neutral
brain state to be able to normalize my
brainwaves versus kind of like the
collective holes so I started taking
neutral brain state recordings for
people as well so that way I could use
that for a data normalization
I'm started asking more questions
because you know the more data the
better and it's a pain to get it on
someone's head so once it's on I want a
lot of good data per person oh this is
kind of interesting
so I started switching order to reduce
fatigue effect so the idea behind that
is fatigue effect is at the very
beginning like if I take your data at
the beginning it's kind of fun right
because this crazy lady puts
this headset on your head and then she's
asking you all these questions and
you're like oh this is kind of fun and
you can see your brainwaves or whatever
it's kind of cool but it gets boring
really fast okay and so what was
happening is if I ask all the questions
where I asked people to tell the truth
first and then lie like that excitement
emotion might kind of get all correlated
with the truth data and then kind of the
boredom at the end associated with the
lie so what I did was I for some people
I asked them to tell the truth first and
then lie and then for other people I
asked them to lie first and then tell
the truth so that way that you know kind
of the the emotional response we'll get
will get distributed throughout the data
that make sense okay
so that's a fatigue effect all right and
then I started asking additional data
about the test subject as well so how
many of you guys seen that show brain
games do they have it in Australia I'm
not sure okay yes I'm seeing some nods
okay well there's this show called brain
games and they they do all kinds of
tests with the brain like they had some
driving challenges where they took like
older more experienced drivers who had
more driving experience and then had
them like do an obstacle course where
they like throw stuff in front of you
while you're driving and you have to
swerve and stuff and then they had
younger drivers who were you know less
experienced driving but you know their
brains were maybe a little bit sharper
because they were younger and they
compared the two of them against each
other to see who would do a better job
and that sort of thing and so I started
collecting and actually the younger
people won which was kind of interesting
they beat the the older drivers were
able to avoid the obstacles better so
for the small sample size they did have
it wasn't a huge huge study but anyway
so I started collecting a couple extra
things like age for one just in case
there is you know degradation in the
brain over time I collected age I
collected gender I collected whether
you're right or left-handed because have
you guys heard the the thing that maybe
your your that correlates to the
dominant side of your brain I don't
actually know if that's true or not but
more data is good and I don't have to
use it so I started collecting that as
well so all kinds of extra data to that
I can use and then finally I'm mixing
truth and lie in a single session so I
asked them to tell the truth and then
lie like back to back to kind of try to
tease out some of those confounding
variables to make sure it's not stuff
that's specific to a session that
gets in there rather than the actual
truth or line all right so here's some
of the questions I added there's a
couple of them in there they're all were
meant to be yes or no questions although
there's some other stuff in there too
then it's like we won't get into it
right now but there's other stuff that
some situations when you wouldn't not
necessarily use those and then extra
date I already talked about this use
your IDs the gender whether they're
right or left-handed here's the fun part
okay so here's different ways I started
doing feature extraction on this data
because I have all this interesting data
so this is time series data right so
it's it's these waves like that and so
there's different ways you can do this
so one thing is unrolling the waveform
and what that means is essentially I
have over time so for each one of these
fourteen sensors I have you know data
over over some time interval which is a
specific of how long that
question-answer lasted and so you can
basically take like all fourteen of them
and like unroll them in the same order
and then use that as kind of your whole
feature vector so that's one way to do
it
another way is something called wavelets
so what that is is um dividing a time
signal into frequency bands and there
was actually a really good
EEG thing on Kaggle if any of you guys
are familiar with Kaggle it's a date a
science competition site and they did a
competition about being able to
differentiate if someone was trying to
grasp with their hand versus lift and so
you can think of the application for a
pair of pulley or for someone who had
their their arm removed or an amputee if
you were able to give them a prosthetic
and then in their brainwaves map what it
looks like when they're trying to graft
versus lift you could actually kind of
build some of that into the prosthetic
potentially and so there's um there's
just some interesting applications there
and then the person who actually won
this actually did it using some of the
low-frequency time domain stuff so there
may be something to that to you so I was
playing with that there's a wonderful PI
EEG library by Forrest Chang Bao I have
never met him but I am eternally
grateful because he open sourced it and
so I used that and pulled in some of the
feature extraction that he was using
another thing is state machines okay
so this is actually kind of interesting
because when you think about all the
stuff that is actually happening in the
brain when when I ask these questions
like from from the user perspective
first they have to listen so they
actually have to decode those signals
and figure out what it is that I'm
asking so they have to do the auditory
work to figure that out then they have
to kind of process the question see what
I'm asking then they have to decide
whether they're going to tell the truth
or lie then they have to come up with an
answer and then they have to do the work
to you know the auditory work to
actually say it out loud right the to
vocalize the response okay
so there's kind of like a mini little
state machine happening in there and if
I can zoom in on that and then zoom down
even further into just like the truth
lie part of that that will help be more
effective so I was hidden Markov models
kind of work well with state machine
type things so that's another thing I
was kind of playing with comparing to
the neutral brain state I already kind
of talked about that so to be able to
normalize across all people you want to
do that comparison of kind of everyone's
brain waves against the average to be
able to make better predictions ERP so I
talked a little bit about that and so I
never defined it when we're talking
about the P 300 ERP but that stands for
event related potential and so it's
actually a different way of processing
EEG where you're taking some essentially
averages over time so it kind of helps
weed out some of the noises or some of
the noise
so using ERP instead of the raw EEG is
another thing that I've kind of played
with and then in solemn bowls are a
technique in machine learning where
essentially you use multiple classifiers
together and then some of the some of
them can kind of help account for the
error of previous ones so you can in
Samba lab unch of things together and if
you look at who is winning these Kaggle
challenges almost everyone is using an
assault in sambal to do that so it's
basically kind of matching up a lot of
things together
I'm sorry using a lot of classifiers in
conjunction to come up with the best
results and then finally um deep
learning I think of honestly the key to
solving this right because if you think
about what I'm really trying to do it's
really really similar to the problem of
speech recognition right you guys have
all seen audio files you know that when
you
talk.you makes these audio waveforms
which are very similar to the brave with
the brain waveforms that I just showed
you right and everybody has slightly
different voices different timbres and
pitches and all those other things I
don't really understand because I never
really paid attention a music class but
you know what I'm saying that those
things are all in each of us speaks a
little bit differently but it can still
recognize hopefully the words that we're
saying when we're saying the same words
and that's what that's what speech
speech has done and so really it's a
very similar thing where it's again time
series waveform data that I'm processing
and I'm sure and everybody has a brain
signal that's a little bit different
much like our voices are all different
so it's really really really kind of
similar problems and speech recognition
has been solved with deep learning like
it's a solved problem at this point and
so I think deep learning could actually
solve this too the only reason I haven't
done it yet is because I don't have
enough data with deep learning you
actually need to use lots and lots of
data to do it effectively and I've been
kind of collecting headset data from
people in my spare time hahaha with my
high-stress job at Microsoft and my
three children and all that so it hasn't
caught on as quickly as I would like but
when I do deep learning is a great thing
and there are great tools like the C NT
K as well as things from other companies
that can process those okay so that's
some of the techniques so the next steps
I'm collecting data from lots of people
now to be able to do a general-purpose
one as well I'm experimenting with
different features to improve the
accuracy like you saw on the previous
slide those are some of the things I'm
experimenting with and then implementing
a real-time feedback loop there's
something the only thing the thing
that's holding me back there otherwise
this would have been done a long time
ago the other thing that's holding me
back there is that I need that thing to
convert this from from the the
proprietary format into CSV
automatically and they actually have
that embedded inside of their tool and
it's not like a command-line thing that
I can call and so I've been going back
and forth with a mode of support trying
to get them to just give it to me as a
console app and then once I have that
that should be like not hard to code so
and then what I could do there some
really awesome demos where I can stick
it on someone live and ask questions so
I wanted I want to do it to Satya
Microsoft's CEO I dream big right reach
for the stars all right and I do want to
say thank you to all the people so when
I had an early version of this and I
demoed it to the Azure machine learning
team and they all started drooling and
we're like can we help you this is so
cool
so I do want to say thank you to all the
people who have helped me and made
suggestions on the experiment procedure
and Python scripts and all kinds of
other stuff the whole team started
helping me with this and it the ending
result is so much better now
based on everyone who is able to
contribute some stuff all right
so in summary this headset is awesome
and so cool I've sold all these other
ideas and I do feel like Jean Grey every
time I move something with my mind which
is fun as machine learning is an amazing
tool and made it really really fast and
easy to get up and running with this
technology and to iterate quickly and
try different things and I I really
really love it and husbands and managers
beware mind control is next thank you
guys so much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>