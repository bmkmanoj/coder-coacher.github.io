<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sqoop Installation | Hadoop Sqoop Installation | Sqoop Installation on Ubuntu/CentOS | Edureka | Coder Coacher - Coaching Coders</title><meta content="Sqoop Installation | Hadoop Sqoop Installation | Sqoop Installation on Ubuntu/CentOS | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Sqoop Installation | Hadoop Sqoop Installation | Sqoop Installation on Ubuntu/CentOS | Edureka</b></h2><h5 class="post__date">2016-11-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LJgAU3d3n6U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi folks this is Vern from Erica today
you will learn to install scoop in your
Hadoop cluster in case you haven't set
up Hadoop already please watch the
previous video in this playlist so let's
get started by downloading the scoop
package from the internet since it's
free you can just download from a
patches website let me show you how it's
done I'm going to Google scoop download
and from here we can just download it
from a nearby mirror so I have already
downloaded this 1.4.6 version of scoop
and I would request you to download this
alpha package of scoop okay it is about
16 MB and let me show you where I have
downloaded that so this is the tar
package which I downloaded what we need
to do is we need to extract the contents
from here we can do it from the terminal
by running a command and the command is
tar - xvf package name there you go
scoop has been extracted successfully
now let me clear the screen and show you
then you follow that's created so the
folder you see here right this is the
new folder now that we've extracted
scoop what we need to do is we need to
set the environment variables with
scoops path so let me copy this path and
update the environment variables to
update the UNAM and variables we need to
open our bash RC file okay so this is
the command to open the bash RC file you
can see scoops path is not set here so
I'm going to paste the path of my scoop
and the path of my bin folder in my
scope folder that's a bin folder here
right this is
have abated here so let me save it and
exit remember to always source your
Bashar C file after you updated with the
new path now that this is done we can
just straight away run a command called
scoop help to find out if scoop is
working on a system scoop help okay
so what do you see here these are the
available commands this means that scoop
is successfully set up in your Hadoop
cluster now you can import your data
from your AR DBMS or your my sequel so
that's it guys thank you for watching
the video feel free to comment your
doubts and queries do subscribe to our
channel to learn more happy learning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>