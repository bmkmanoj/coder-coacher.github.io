<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Understanding Lucene Scoring | Apache  Lucene - Scoring | Edureka | Coder Coacher - Coaching Coders</title><meta content="Understanding Lucene Scoring | Apache  Lucene - Scoring | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Understanding Lucene Scoring | Apache  Lucene - Scoring | Edureka</b></h2><h5 class="post__date">2015-02-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Do9oM81-b80" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so let's start with understanding the
boosting and scoring aspect of it okay
so we have seen the yeah so the range is
also applicable to dates okay
so it can be dates as well so the dates
are also applicable so there is a format
on which you have to specify the dates
it understands the dates as well
yeah the query syntax understands the
dates as long as you specified in the
default format you should be able to
query the dates as well so without any
issues okay so so far we have seen
searching all the documents by various
ways right so we have seen list of
documents okay
matching and coming in so so in this
case we said we wanted to search all the
records and we got some files in in a in
order so any guesses what what order
this could be and how do I control this
order the way how loosing figures out is
by using some default techniques okay
so the default technique is called as
scoring okay loosing uses some default
scoring techniques like the test phase
model and boolean space model with
tf-idf weightages I'll explain all of
these things in detail so the reason why
you need scoring is to sort the records
which one has to come first and which
one has to follow next okay that is what
we call
as scoring so newsom provides some
vegetable thing to each document and
then sorts all that documents in that
order
that is what is called as scoring in
very simple terms so there are different
techniques and different ways of scoring
documents so leucine by internally uses
tf-idf as a default scoring mechanism
with vector space and boolean space
models okay so I will explain what are
these things is it clear what is scoring
in first place so that we can get into
the next topics okay right so using a
space model with some weightages it
gives you the scoring so a space model
is nothing but resin representing your
query as well as the document in a
vector format okay
is called has a simple terms is called
as a vector space model nothing more
than that okay once you represent the
document and the query in a
multi-dimensional vector space then
assign the weightages to each term or
the document the conjunction of the
vector space model and the weights will
give you a scoring it is the algorithm
okay we are not getting into the details
of each and every step how a score is as
I into a document for ordering this is a
very high-level overview of how a score
is derived is it clear how a scoring
algorithm is derived for documents this
is the high level approach make sense
guys I'll explain what is this tf-idf
invictus biggest models very soon okay
this is a high level approach to derive
and score for a document using this
score loosing when retrieves the
document
sorts it based on this score and this
entire approach is called as scoring
okay so very high-level overview of the
vector space models so I'm not or
complicate or confuse it is just a
collection of documents represented in a
vector space as simple as that and also
as I mentioned a query also represented
in a vector both a document collection
of documents and query talking just to
visualize it and make it a little bit
more simpler okay a vector space model
is nothing but let's say this is a
vector okay a 2-dimensional vector let's
say I have documents okay
I have term let's say a do Rekha okay
these are all the terms okay courses
these are all the possible terms okay
I'm just using two terms for now this is
the vector space model okay this is the
document ID doc one okay whether I found
it in this document or not courses I
found it or not doc - I found only
courses doc three I found in one okay
doc four okay I found it I didn't find
anything of this so this is how you can
visualize a simple vector space model
make sense guys similarly you can think
of a query also represented in a similar
fashion what is that you are looking for
let's say you are looking for contents
right and you are looking for a term
called ed Eureka okay so this is a
straightforward single dimension if you
are looking for multiple fields like
sorry there
another field contents okay
and you are looking for sick courses as
well so this is another dimensional
query dimensional vector which is both
represented in vector space model for
querying the documents okay so this is a
very high-level approach when we
determine the document collection and
the highest vector space goes for that
query it gives you some weight age
factor along with that weight is further
using the tf-idf the score is derived
okay so there are lot of scoring
techniques by default it is figured out
by his similarity metric what is the
similarity metric say for example you
have multiple documents okay so now
let's say I have multiple documents okay
so first of all we represented it in a
vector space model and then I have to
find similarities between these two okay
so maybe this is a very hard example
let's take something interesting let's
say milk eggs and bread and butter okay
so I have documents okay which says okay
consumer one which is much more
meaningful example consumer to consumer
three these are all the documents
consumer four so I somehow got these
documents I'm saying who and all is
shopping for this product okay a
consumer one bought milk
and bread-and-butter okay let me add few
more examples guys is this interesting
shall I continue or you guys wanted to
move further okay let's add few more I'm
saying why this key
okay or let me say vodka okay and say
what is that you guys usually prefer
with drinks tell me something snack what
is your favorite snack with some drinks
like vodka or wine okay chicken that's
great
perfect what else any one more choice
choice of yours okay
chips fine so this is the shopping app
okay where I have aggregated who is
buying what so consumer - he has bought
while he has bought chicken and chips
okay consumer three he bought milk bread
butter consumer for he bought vodka
he got chicken
chips okay this is this is very simple
thing so let me just actually show you
how a file might have contained and how
it got transformed to a vector space
model let's say can this is consumer one
file this is the actual file which had
contents let's say he I'm just adding
water nan he bought milk eggs bread
butter that's it
as simple as this right so this is what
the consumer has bought after indexing
okay
it goes into consumer one file and when
I am scoring this is how a vector space
module would have been represented okay
now how do I correlate between documents
and derive a score that is done by
something called similarity techniques
okay the default similarity technique is
called tf-idf okay so the tf-idf is
stands for term frequency and inverse
document frequency yeah term frequency
and inverse document frequency so I'll
explain all these things would you make
any analogy between say for example a
consumer five comes in okay he is buying
well what is the probability that he
will buy anything similar his only he
started buying chips or chicken right
great let's say chips and chicken he
bought okay so can you guys tell me is
there any correlation between consumer
five four and two is there any
correlation between consumer four five
and two yes no exactly say for example
if I am searching for a term called
while what should be ideally what should
be the next document will you written
the consumer who has written purchase
milks milk eggs bread right exactly so
you will return consumers who have
purchased vodka wine chicken chips okay
that is the idea behind finding
similarities how to find similarities is
again a different technique which I can
explain it okay is it clear guys so far
yes it is exactly similar technique is
adapted to find the scoring as well okay
recommendations is big different this is
to only derive the similarity and the
scoring based on those similarities okay
it only applies to the indexed fields
okay it does not apply to the stored
fields all the analysis so far we have
discussed is only for the index fields
okay so predictive analysis also comes
in scoring okay how does that be okay
let me first explain what is DF IDF term
frequency in word document free document
frequency so term frequency is nothing
but okay let's say I have this it's a
very simple calculation how many times a
term has occurred in a document okay say
if I'm looking say what is the term
count of milk for this document one
perfect eggs one bread one butter one so
that is what we call it as term
frequency as simple as that
okay so okay I'll give you one more
example of consumer to the consumer - it
has got milk eggs so here what is the
term frequency one one okay so Prakash
says how many dogs does this word
contain exactly so document frequency is
nothing but how many times this has
repeated in the documents okay so any
guesses what is the document frequency
of milk - absolutely
so inverted document frequency is
nothing with inverse you just divided it
by one whatever the document frequency
you get terms like inverted document
frequency as simple as that so when you
multiply term frequency and inverted
document frequency you get tf-idf
as simple as that that
is what we call it as weight or score so
very simple mathematical function which
is used to derive the in term frequency
and tf-idf uncie you derive the tf-idf
you assign it to the scoring that's as
simple as that okay so it's a very
simply have to normalize the idea we use
a logger to normalize the data points so
that it is you know why we use logs
right guys should I explain it or not
required just to reduce the magnitude of
the data points
say for example milk if you have 10
million consumers okay and every out of
10 million consumers 5 million consumers
are purchased built so your number will
be something very big like this right
and also eggs okay
for practical calculation purposes if
you use bigger number for any
multiplication if it will be
exponentially growing and at some point
it will break this is a higher magnitude
data point right this is a very higher
magnitude data point just to normalize
it it into a smaller magnitude we use
loggers to normalize the data to a
smaller magnitude so that we deal it in
say one point three eight something like
this and we know exactly it's very
simple instead of you making this as a
number big number you can just also say
very simple technique like this right so
you know that you are dealing with one
point less than say ten point scale
magnitude and you can multiply or as
I've scores better make sense guys yeah
so that is how you have this scoring
hand a TI tiny F calculated once you
have the scoring you can assign it to
the order by default loosing provides
scoring algorithm using tf-idf if you
want you can change or customize your
own scoring algorithms as well so which
is a very very advanced topic I wouldn't
recommend for basic means that you
should go ahead and try all those things
okay now let's next thing let's do a
score boosting so boosting is say for
example you wanted to alter the order
the way how losing is returning okay say
for example you wanted to boost some
records based on some value condition if
it satisfies two top order you can boost
those records so boosting is done by two
ways either you can boost the records
while indexing and store it permanently
inside the index for you can also query
them at the front type okay you can add
boost at the front time as well
is it clear okay
so boosting at in next time has to be
done at the free level so if you are
trying to boost a particular field you
can select that field and say set boost
and you can add numeric value it has to
be a relative value so you can decide
what should be the alteration factor
based on the tf-idf okay we'll see
example which you can be very clear
after that how the weights are allocated
and how much you have to boost maids
based on the weights okay this is how
you can do index time boosting and
similarly at the query time boosting you
don't have to do anything just say query
dot set boost and select the field it
will boost that particular term
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>