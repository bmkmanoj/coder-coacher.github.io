<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>OpenStack Tutorial For Beginners | OpenStack Tutorial | OpenStack Training | Edureka | Coder Coacher - Coaching Coders</title><meta content="OpenStack Tutorial For Beginners | OpenStack Tutorial | OpenStack Training | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>OpenStack Tutorial For Beginners | OpenStack Tutorial | OpenStack Training | Edureka</b></h2><h5 class="post__date">2017-04-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eSRKnNgWrM0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey everyone this is Rachel from Ed
Eureka and in today's tutorial we'll be
learning about open sac so let us get
started by looking at the agenda but
before that am i audible to everyone
drop me a confirmation on the chat
window please okay so Anna says yes so
Hugh says he can hear me
you thank you Paul Yasmin all right
let's begin guys so this is what we'll
be covering today in today's tutorial
so first we'll take a look at what is
virtualization just the basic concepts
of virtualization then we'll jump on to
what is OpenStack and why should we
actually use OpenStack I'll tell you
about the OpenStack components and the
OpenStack architecture
we'll take a look at the different
OpenStack services and we'll take a look
at a case study and finally we'll see
the OpenStack success stories so is the
agenda clear to everyone okay so I've
got a few confirmations so let's begin
so let us start with what is
virtualization so on the left hand side
you'll see this is the basic
architecture that is without
virtualization so you have like your
proper Hardware your CPU your memory
storage disk your ni C for networking
purpose disk for storage and on top of
that you lay out the x86 architecture
which is basically your computer
architecture you light your 64-bit or
32-bit architecture that you have in
your computer about how each of the
process takes place the process queues
and everything that kind of architecture
and on top of that there is the
operating system or the user interface
with which the user can actually
interact with the hardware for different
purposes and inside that there is your
application so this is what you run
inside your operating system now
virtualization basically means actually
logically partitioning everything or
let's say it is going to duplicate your
hardware and divide it into different
components if you see you can use
different software's for virtualization
it can be vmware or it can be k vm Xen
or any kind of hypervisors that you can
use for virtualization we widely use
Oracle VirtualBox manager also to launch
to actually use VM we widely use Oracle
VirtualBox managers for virtualization
for actually working on VMs creating VMs
and working on them right so this is the
virtualization architecture so you have
your basic hardware that is always
needed obviously and on top of that
there is your machine architecture and
inside that you use software for
virtualization and what this software
exactly does is that it replicates your
hardware but in an abstract manner so
this is not a real hardware so when you
virtual eyes it does not actually divide
your hardware components it actually
creates an abstract form or a
virtualized form of your hardware and it
can be either you can actually logically
partition it it's either two parts or
more as many parts as you need it and on
each platform you can run different
operating systems and on different
operating systems you can launch
different applications so this is what a
virtualization actually is so this is
just a logical partitioning in abstract
manner so is that clear to everyone any
questions about virtualization so this
is just a brief overview of what we're
actually going to deal with because
OpenStack actually deals with a lot of
virtualization so any questions
okay so Kunal says no questions okay but
if you have any doubts later on you
might ask me at any time during this
tutorial ok so now let us see what is
OpenStack like OpenStack itself says
that OpenStack is a collection of open
source technologies delivering a
massively scalable cloud operating
system so it is basically a set of
software's that enables you to build
your own cloud infrastructure you can
think of it as a software suite that
comes with a different services that
allow you to perform different
activities and actually launch up your
own cloud infrastructure on which you
can actually run your applications
starting from development to testing and
deploying it and the best part about is
that it is open source and it is said
that open source cloud platform
forms are actually going to be the
future of cloud computing so OpenStack
has got a lot of scope in it and there
are a number of companies that have been
contributing to OpenStack and by
contributing I mean they are
contributing code and you can see that
each year OpenStack is releasing almost
two versions and you can see that
OpenStack is almost releasing two
versions every year and these are some
of the companies that have been
contributing the code starting from
Rackspace and actually Rackspace was the
one who actually created OpenStack in
2010 with NASA and there are other
companies like Cisco IBM Red Hat VMware
Dell HP and these are just a few of the
companies that are in the OpenStack
community that have been contributing to
OpenStack so this is what OpenStack
basically is so after that why should we
actually use OpenStack let us understand
why in fact was created on the first
place what was the need of creating
OpenStack so we'll see that so here we
have the consumer and the consumer
basically here could be application
developers or they might be application
owners so they want to build an
application and they want to have an
infrastructure and most people actually
support or they want to go for a cloud
infrastructure so what they do is that
they send requirements they just write
down what they need to set up their
infrastructure and descend it to an
infrastructure team maybe they could be
the infrastructure team of a cloud
vendor so they send all the requirements
to them they see the infrastructure team
over here they actually take a look at
their requirements whatever they need
and we create the infrastructure
accordingly after that what happens is
that the application developers or the
consumers they have got their own set of
tools now obviously in order to develop
an application there are numerous amount
of tools that you can use and technology
has evolved in such a way that these
kind of tools have evolved and they
enable you to develop your application
faster among those tools they might use
Jenkins for continuous integration and
continuous deployment they might use
ansible or chef for configuration
management and automation purposes let's
say git for version
until so they can use a different tool
for that and after they have got their
infrastructure and they have tools they
need to configure their environments and
the environments can be development
testing and production so they have to
integrate all these tools together so
this might be a little bit of problem if
the configurations that the
infrastructure team has actually
embedded in the infrastructure they
created for the consumer might not be
compatible with the tools the
infrastructure might not have an
integration with the tools that they
want to use so this is what the consumer
needs to do additionally in after even
they have got their entire
infrastructure defined so it is better
if they could actually create their own
infrastructure themselves so that they
can actually configure it themselves and
they would integrate with the tools they
want to use it will be more easier for
them and OpenStack enables you to do
that so you can create your own cloud
infrastructure on permissions you can
set it up as a private cloud you can set
it up as a public cloud you can contact
some OpenStack vendor that gives you
OpenStack services so if loi your cloud
infrastructure in a lot of ways with
OpenStack and mostly large enterprises
would use OpenStack to set up their own
private cloud because they might have
sensitive data that they want to keep in
their own data centers or let's say
information so that's why people are
actually going for OpenStack so now let
us compare OpenStack with public cloud
and when you talk about public cloud the
one name that comes to your mind is
always AWS the Amazon Web Services so
Amazon Web Services gives you a lot of
things it has pros and definitely it
might have some cons also so I've listed
them out so let us take a look at them
one by one so the first point that
Amazon Web Services gives you is that it
has very well-documented api's so ap is
are something that actually enables you
to communicate between different
services and the API is that AWS gives
you are very well-documented and that's
why you can just use them right away and
the processing is fast there is full
autonomy for developers they can run
any kind of applications on the servers
that AWS provides and AD Bluest actually
has a natural integration with the tools
that I just mentioned like Jenkins and
ansible chef puppet gets they have
Amazon Web Services actually has got a
natural integration with those tools and
those tools are fully compatible with it
and it also has a very well-defined
ecosystem and if we take a look at the
corns you would know that the API is are
proprietary and there might be data
sovereignty issues because when you're
putting in data it's fine but if you
want to take out your data from their
server to your servers you might face
some data sovereignty issues so this
might be a problem that you can
encounter there can be environment
differences let's say that if you are
running development and testing on your
public cloud or on your aw servers but
you are actually deploying it or the
production servers is in your company
premises and also it may be while you're
transferring data you might be facing
some security issues on making a VPN
tunnel or something so that's why some
people do not prefer AWS and if let's
say n sensitive data let's say that if
your company actually has data that is
sensitive and you don't want to rely on
someone else's security even though AWS
has a very well security defined for
your cloud but still you might be a
little bit dubious about relying on
other people's security protocols and
you might not actually trust them and so
most companies prefer to keep their data
on-premises in their data centers which
is actually maintained by their own
security protocols so that is why some
people do not go with AWS and the
benefits that you get with OpenStack
could be it is vendor neutral and by
vendor neutral I mean that it is a
business and design approach to ensure
that there is a broad compatibility of
technologies and it encompasses
standardization and non proprietary
business principles and unbiased
business practices and of course you can
have your cloud infrastructure
on-premises so you can define your
on-premises or on-prem infrastructure
and obviously you can have when you have
everything on premises so you can have
that broad and test all the environments
integrated in a single infrastructure so
this is the benefit that you get with
OpenStack so Kunal has a question he is
asking can you explain vendor-neutral
yes of vendor-neutral basically means
that there is compatibility it means
that it has no three configurations
defined so anyone can use it
and nothing is actually proprietary
everything is non proprietary and all
the business principles are unbiased so
it is free for everyone so most of the
open source technologies are vendor
neutral and so is OpenStack so Kunal did
you get your answer okay he says yes
very well thank you can all for the
question
so moving on let us take a look at the
different OpenStack components so these
are the OpenStack components that make
up OpenStack and these are actually a
bunch of services altogether so horizon
is the dashboard so this is a web
interface or a graphical user interface
that enables user to actually see a
brief overview of your entire
infrastructure at once
and they can also provision themselves
with horizon you can log in as different
users the key stone is the identity
service or this is a service that
actually maintains who is using what
kind of a thing the Nova is used for
computing the glances for image storage
swift is for object storage and in
today's world since you know that
everything is actually stored as an
object and Swift is one of the services
that OpenStack provides and there is
Neutron for network as a service cinder
as a block storage component heat is
used for orchestration and ceilometer is
used for billing or metering kind of a
service so we're actually going to look
deep into each of the services so if you
still have questions on this you can ask
me but I'll just tell you that I'm going
to explain each of these components one
by one in a brief manner so any
questions okay
very well so first up is Keystone so
Keystone is basically the authentication
and authorization service
so by authentication it means that it
identifies if you can actually log into
or if you can actually have access to
the entire OpenStack infrastructure so
when you're using a dashboard it will
ask you for your username and password
so this is the part of the
authentication system and by
authorization it means that is it
identify if you have rights to do or use
a particular service so that is what
Keystone manages and two functions that
are just old which is user management it
means that it keeps the track of users
and what they are permitted to do so
this is the authorization and
authentication thing mostly and provide
Service Catalog it means that it
provides the catalog of what services
are available and where their API
endpoints are located and let me tell
you that all of the services actually
communicate with each other with API and
each of the services have n points
defined and by end point end points are
nothing but they are a network
accessible address and it is usually
described by an URL from where you can
actually access an openstack service ok
so let us take a look at a Keystone so
the Keystone provides you with a token
service so the token service what the
token service does is that it validates
and manages tokens that is used for
authenticating requests once a users
credential have already been verified so
if you are able to login into the
dashboard or log into your OpenStack
infrastructure so if you want to use any
kind of service it sends different
tokens to each of the service through
API and the catalog service what it does
is that it provides an endpoint registry
and it is used for endpoint discovery
because you communicate with endpoints
right and the policy service it provides
you with let's say a rule based
authorization engine and the Associated
rule-based
user interface or the rule management
interface you can say an identity is the
same thing that gives the track of
all the users that identifies different
users through their credentials so any
doubt on Keystone and let me tell you
that every time you actually want to
access a service it has to get validated
by Keystone so if you request for let's
say compute service you request for
storage Keystone needs to verify it and
after that only you get that service so
Keystone is actually associated with
every service so no doubt great so the
next step is glance so glance is the
service where you store all your images
ok and the images are nothing but they
are the virtual disk images so you can
think of glance as a repository for your
virtual disk images and it provides
service where users can upload and
discover data assets which are meant to
be used with other services so let's say
that if you want to actually launch an
instance if you want let's say an Ubuntu
instance you must launch it from an
image so the image from where you
launched that instance that has to be in
glance so this is where you store your
images ok
and it uses a restful api and restful if
they're you know what they are
they send HTTP requests and they connect
with each other using by passing on HTTP
requests of glance users and restful api
and this is the API server and this
allows squaring of different VM image
metadata as well as retrieval of your
actual image so your images can be
stored in s3 in Swift storage or in file
systems or anywhere so this is the image
service and so whenever you ask for an
instance you should know that Glantz is
the service that is actually going to
provide you with the instance because
your instance has to get launched first
from an image so you can see that this
includes images and metadata definitions
of your images so the disk format that
Glantz uses is mostly qco w2 and this is
the dis format that is supported by the
emulator and it can expand dynamically
and it support
copy and write so any questions on
glance no questions so we'll move on to
the next service which is Nova now Nova
is the compute sown so this is where
your instance get launched in and this
is where all the computing and
processing takes place and in Nova all
the components that are in Nova they all
communicate through message queues and
mostly they use rabid mq for message
queuing system so each of this component
starting from the scheduler conductor
the database and the different
hypervisor is network this is VM over
here so all the components communicate
using the rabid MQ message queuing
system so you can see then OpenStack
Nova is a component with the OpenStack
open source cloud computing platform
developed to provide on-demand access to
compute resources the provisioning and
managing large networks of virtual
machines so this is where you can
actually configure the network for your
VM so you can store data inside your VM
and later on they will be either stored
in Swift or cinder so I'll be explaining
how each of the components work and Nova
later in the architecture part so if you
have any doubts still here you can ask
me do you have any doubts
ok so Anna is asking that is Nova
similar to easy to compute in AWS of
course ec2 is also the compute service
or the computing service in AWS and open
sides and think of it as Nova so they
are actually quite similar so if you
have any more questions you can ask me
so moving on to the next service so then
we have got Neutron Neutron is a service
and OpenStack that provides you with n
AAS mass which is known as network of
service and Neutron is responsible for
actually connecting all the different
services of OpenStack together so this
is how the Neutron service is laid out
so it also uses an API and it has got a
neutron scheduler different plugin
agents
and there are different plugin agents
for cisco virtual and physical switches
NEC OpenFlow products open V switch
Linux bridging and the most common
agents are l3 DHCP and some specific
plug-in agents so in the Neutron what
the neutron server does is that it
accepts API requests and it routes them
to appropriate plugins for action so
I'll be explaining how Neutron also
works in the architecture part so yahan
is asking that what do you mean by ships
with plugins it means that when you are
installing Neutron service of OpenStack
in your system you would already get
different plugins that are compatible
with different kind of agents and
examples that gave you are the different
plugins so sometimes if because if
you're actually downloading just a
neutron service you might want to use
different plugins to connect to other
services and when I mean that it shifts
to different plugins that means that the
version already has got all those
plugins and the plugins will also get
installed when you're installing Neutron
so yassmin did you get your answer ok so
she says yes very well so next up we
have got Swift and Swift is the object
storage service for OpenStack so in
today's world you are actually storing
huge amounts of data and the data
storage system has changed nowadays
everything is stored as an object and
Swift is the service that allows you to
do that in OpenStack so in Swift proxy
so whenever any request comes for
storage the Swift proxy gets that and
after that it redirects it to the proper
containers or to the proper database
where it should get actually stored so
you can see that this is proxy handles
every request it can store data
according to some account it will go to
let's say a defined user database or you
can tour all your data in different
containers and you should know that if
you
want to define containers now containers
are nothing but different folders you
can think of containers as folders in
your system that you are using and you
can store different objects inside the
containers the only difference between a
folder and a container is that
containers cannot be nested it means
that there cannot be containers inside a
container
whereas in folders you can have
different folders in a folder right so
this is the difference between a folder
in a container and you can also directly
store it in an object store without
defining a container so this is how
Swift works for any question on Swift ok
no questions so let's move on to the
other storage service which is Cinda now
v was an object storage service and this
is a block storage service the
difference is that this can be thought
of as an external hard drive or a
pluggable storage device so you can
think of it as your external hard drive
that you plug into your computer for
storing your different files or folders
and in cinder everything is defined in
blocks so each of the block has got a
predefined size and the data is stored
in each block so these are the different
components and cinder you've got the
cinder API and cinder volume cinder
database and cinder scheduler we'll
learn how each of these components work
in the architecture part so this is just
to have an introduction to cinder ok so
the here is asking can cinder also store
images like Swift you can store any kind
of data you want to store in cinder you
can store images the only thing is that
your glance stores all the images in the
Glantz database but you can also store
it externally in a pluggable storage
device like cinder also and it will go
through glance it will get and after
that we get launched in Nova so that is
how it takes place storage you can
actually you can even store images or
any kind of data in center so does that
answer you so he okay so he's asking why
not only cinder because the services are
divine cinder
is solely responsible for storage only
it does not directly communicate with
Nova so it has to go through glance if
you want to launch instances with the
images and cinder it has to go through
glance so this is how it is actually all
the services are defined so if you're
using cinder for both images to launch
images or store images that is going to
be used by Nova and also as a pluggable
storage device that is too much work
load for cinder isn't it so it'll be
more advisable if you use cinder and
cinder is actually only created for a
pluggable booting device so does that
answer you so I hope it answered your
question
so shall we move on to the next service
ok so he says yes and so let's move on
to the next service which is horizon
okay so horizon is the dashboard so this
is usually a web based interface through
which you can actually take a look at
your entire cloud infrastructure you can
manage your infrastructure with this
dashboard all the different application
developers or tenants so the application
developers are generally referred as
tenants so they can get provisioned with
VMs that they need from the horizon
itself so you don't have to actually go
to the CLI to start and write commands
to launch of instance and provision them
to a particular user so you can use
horizon for that that is much easier and
horizon is based on a Django module and
it is called the Django OpenStack so the
end user and the admins they directly
communicate with all the services to the
dashboard horizon and they can access
all the services from the dashboard so
this is very important and I'm also
going to show you how to use horizon in
today's tutorials and it's very easy to
manage your OpenStack out infrastructure
with horizon it is very very easy
okay so Kunal is asking we can use CLI
also right yes of course you can use CLI
instead of horizon if you don't want to
use a web interface our GUI and if
you're a person who likes to use the
command line
to phase 4 and right commands and do
stuff so you can use CLI also into the
horizon this is optional but I would
recommend you to use horizon because it
will help you to manage your
infrastructure in a more easier way so
next up we have got Co meter so
ceilometer is a part of the telemetry
project by OpenStack so what it does is
it offers metering and it helps you for
billing purposes so what it does is that
it lets you know what kind of services
you used what actions each user
performed and how they have actually
used all the OpenStack services so the
co meter is a service that is
responsible for monitoring all of the
actions that you did or any of the users
of your OpenStack cloud infrastructure
did and later on 0 meter is used for
producing the bill of how many services
or for how much time we have consumed
each service yeah so Canal is asking why
is this billing because sometimes you
let's say that you have set up your own
OpenStack cloud infrastructure and you
are letting other people use it so this
is also how different people are using
OpenStack the cloud vendors are setting
up an OpenStack infrastructure and they
are giving out OpenStack services
they're letting other people use
OpenStack services so with OpenStack you
can also define public cloud so there
are many enterprises that they do not
want to take the hassle or they don't
want to take the burden of actually
installing OpenStack and setting up
their own cloud infrastructure when they
just want to use a few services they can
buy it from an OpenStack vendor so for
those vendors should use IDO meter so
that they can produce a bill for the
consumer that have consumed these
services so did you get your answer ok
very well so let us move on to the last
service that we're going to see which is
heat now the heat provides you with a
REST API to orchestrate different
services
now orchestration is very much required
when you are using automation and today
every
automation so heat is responsible for
orchestrating different services and
orchestrating means defining how each
service would get consumed and how each
of the service will get triggered let's
say that it will maintain that it has to
go to Keystone whenever you request
something
the Keystone should get triggered it
will get a token to Keystone so the keys
from you get trigger it will
authenticate the token send back the
token to the service that generated that
token and verify it so and then maybe it
will trigger some other service
according to the request of service that
you have made so this is the whole
purpose of heat so maybe you have got
different nodes together okay so you
have got in region one you have got a
compute node and networking node a
storage and you've got region 2 ne1
these two regions to actually
communicate with each other so the heat
service will help you orchestrate help
you integrate all of these two regions
together so this is how heat works so
any questions so now questions very well
so now let us move on to the OpenStack
architecture so here I will tell you how
your request gets processed how each of
the service gets triggered and what each
service actually do and also what each
of the components of each of the
services do so we'll take a look at it
so mostly let's say that you're a user
and you're accessing OpenStack through
the dashboard horizon so the first thing
that you need to do is log into horizon
and let's say that you want to access a
VM you want to launch a VM and you want
to work on a VM in your OpenStack
infrastructure so the first thing that
you have to do is log into horizon and
or what a horizon does is that it
provides a baseline user interface for
managing all OpenStack services and it
is also stateless it doesn't require a
database and the horizon gets updated
via API pooling okay so after you have
entered your credentials what it does is
it sends a request to the Keystone API
and the Keystone actually you know that
it manages a different user credentials
tokens that is associated with each user
and tokens are nothing but they are an
arbitrary bit of text that is used to
access resources so what happens after
that is the user gets a token from
Keystone and the token includes the list
of user projects and rolls in them and
after that the user calls the service
specifying the token and the service
interprets the rolls okay and then
Keystone validates the authentication
data so and these are all actually done
by API s and this API is a REST API that
a sends HTTP request to each other so
horizon sends an HTTP request to
Keystone and Keystone sends back an HTTP
request to horizon after it has verified
the credentials of the user and since
you requested for a VM the VN can be
launched in the Nova compute zone so
what horizon does is that it sends an
API request to the Nova API and it
actually sends in the form of post
request Nova API and it is signed with
the given token by Keystone and Nova API
also uses restful api service which is
used to interact with Nova and this is
the only allowed way to interact with
Nova and it is also stateless it means
that it requires no database so after
that the next step is to validate the
API tokens so it sends back a request
and it processes the API request so what
the Nova API does is that it parses
request to a Python of object model and
it validates by fetching the data from
the Nova database and if the request is
valid it will save the initial database
entry about the requested VM into the
database and these are all the Nova sub
components there is the scheduler there
is the conductor and this is the message
to in system and this is a unified way
for collaboration between all the sub
components or
Bonin's of nova so how the messaging
process actually happens let me tell you
that the first thing that happens is
that it creates update in the Nova
database so let's say the first
component the scheduler will send a JSON
messages with a receiver ID so this
might be the receiver and an entry ID to
the RabbitMQ so this is the message
string system that nobody uses and then
the other component which is a receiver
this will fetch the message unpack the
entry ID and process it in the database
and the Nova database gets entry by the
entry ID and it takes it up for further
processing and it actually uses two
modes and it uses RPC calls which is
known as the request procedure call
where you can actually make requests to
one program which is actually in a
different computer or in a complete
different Network and the thing the
baseline or the rule they follow is that
they do not know that they are in a
different computer irrespective of the
network in differences or the
environment or the computer in
differences they can communicate with
each other through RPC calls so they use
either RPC cast or RPC casting means it
does not wait for results it means just
fire-and-forget
and RPC call is where you actually wait
for result when you are actually
expecting something to get returned okay
so this is what happens and after that
you have to publish the provisioning
request so it will then again send an
authentication request to the Keystone
API so the Keystone will then validate
it the Nova database will get an entry
ID for the requested VN and the Nova API
actually makes the RPC call to the
scheduler and it actually publishes a
short message to the scheduler queue
with the VM info that was requested so
this is how it is done to message queue
the API passes they RPC so the API makes
this RPC call to the scheduler through
the message queue
the first from API it goes to the queue
and from there it goes to the scheduler
so the novus
is actually a demon which actually
determines on which computer holds the
requests that you made children and then
in turn it actually schedules the
provisioning so what happens next is
that the scheduler fetches information
about the whole cluster from the
database about different filters and it
selects the compute nodes and it updates
the database with the ID and after that
what happens is that the Nova compute
this actually asks the Nova conductor
for vm info from the database so it as a
nova conductor the conductor retreats
the data from the database and for doing
that the Nova computer actually makes an
RPC call to the Nova conductor for the
VM details to get it from the database
and what it will do is that it will
query the neutron to locate all the
networking information for the VM that
you requested so what the neutron does
is that it provides you with a very
flexible API for different service
providers or their tenants to manage all
the OpenStack Network topologies so it
can create networks to associate with
VMs it can set routers for your VM and
after that what happens is that it uses
different plugin agents to configure
your network for the VM so this is the
plug-in agents actually define the
network for your VM in your compute node
okay so the Nova makes a call to the
Neutron API to provision network for the
instance and the neutron actually
configures the IP your gateway your DNS
name your l2 connectivity etc after that
it is time to define the storage ok so
there can be two kind of storage since I
told you the first one is Swift which is
the object storage and the second one is
sender which is the pluggable or block
storage system okay so in block storage
system the data will persist until it is
specifically or explicitly deleted by
any user and it is accessible within the
VM as a block storage device and cinder
is basically used to add additional
storage to VM
and all of these components are
maintained or managed by the cinder
service and in Swift also none of the
objects or any of the files that you're
storing in Swift will not get deleted
unless you explicitly delete them and it
is accessible from anywhere in the VM
and it is basically used to add or store
files including different VM images and
all of this just proxy and object store
I already showed you the architecture of
Swift proxy how it actually redirects it
to different containers or how to store
it this proxy determines it so all these
components are managed by the SIP
service and you can say that cinder is
actually used as a backup service to
archive your data while it's Swift you
can actually directly integrate with the
compute node you can directly use it for
direct storage of your files as an
objects from your VM so after that the
next thing that you should do is you
would ask for volume now it is actually
assumed that a volume is already created
what is the Nova compute does is that it
contacts the cinder to get the volume
data and you can also do that attaching
volumes after your VM is created and
volume means the storage area of your VM
okay so the Nova sets up the host mount
if it is needed and it instructs the
hypervisor to use volume as a new block
device and after that we come to glands
so the glance provides you with services
for discovering registering and
retrieving virtual machine images right
and it provides you with images service
so it can use multiple backends for
image storage it can also store the same
image in multiple locations and it
supports multiple image formats so it
can retrieve it from Swift after that
will happen is that the compute nodes
will actually request for VM image from
glance it will request the VM image via
our image ID so it will ask you so every
image that is contained in glance has
unique ID let's say you requested for
Ubuntu 64-bit image so that will have
image ID and
we'll actually get past in your request
to glance so then when the glance API
receives that request it will have an
image ID present in it so when you ask
for an image with an image ID how it can
be found is that it can return an URI or
HTTP GET URI okay and after that the VM
will start rendering via the hypervisor
and the Nova will create a command to
the hypervisor and it will delegate the
VM rendering to the hypervisor and after
that your VM will be up and running so
it will again send a message to Nova
conductor to update the database with VM
state and then you'll finally get your
VM launched and it is ready to use so
that is how all the processing takes
place that is how each of the components
actually communicate with each other if
I have to summarize this whole entire
thing I will tell you that at first you
log in to Horizon the Keystone will
validate your credentials then you ask
for VM so it'll contact the Nova the
Nova will again send to the Keystone to
validate the authorization rights of the
user it will send back a token after
verifying it then Nova will actually
retrieve the image from glance which can
be either in Swift or it can be either
in cinder so you get retrieved from that
Neutron will be responsible to provide
with all the networking configurations
for the VM so this is the summary of how
the OpenStack architecture and how each
of the service actually interact with
each other so any questions over here
okay no questions okay so now we'll take
an account a case study and will
understand how CERN has been using
OpenStack so you all know what CERN is
it is the European Organization for
Nuclear Research and they carry out lots
of experiments mostly about particle
physics and there are a number of
scientists from different parts of the
world in tributing onto those
experiments the headquarter of CERN is
located in Geneva in Switzerland
so they're conducting a lot of
experiments and there are a lot of
scientists actually working on a lot of
different projects so there is a lot of
data and to manage those data they have
got two data centers one is in Geneva
and the other one is at Budapest so let
us now understand why they actually
thought of using OpenStack I'm very sure
that you must have heard about the Large
Hadron Collider so this is a very huge
huge machine it is so huge that it
actually stretches between two countries
yeah I'm not joking
so what is it it is basically our
particle accelerator so they pass like
two beams which travels with the speed
of light and they collide together and
there are like some kind of detectors to
actually study about that collision
so there are detectors inside those
tubes those large tubes and they detect
the impact of those collisions when
those two beams actually collide with
very high speed so this is basically the
experiment and it's mostly particle
physics stuff so I don't know much about
particle physics but it definitely
interests me a lot so when you have a
huge huge machine you have even more
huge huge data to manage so obviously
CERN could not rely on typical hardware
servers to manage and store all their
data I mean they have even two data
centers to manage the data so obviously
they cannot rely on this typical
hardware because maybe the fundamental
laws of physics have not changed but the
technology has definitely changed so
that's why they wanted a private cloud
infrastructure and private in the sense
because these are experiments and these
are not released to the public directly
so they have to conduct experiments
verify it and then actually release the
results so that's why they cannot rely
on a public cloud maybe for security
issues or maybe because of the amount of
data they are handling so that's why
they needed to set up a private cloud
infrastructure they also needed it for
backup because let's say because of a
natural calamity one of their
headquarters actually god forbid
something happens there and they lose
all their data
that's why they want to back up also and
the best thing to have a backup is
always a cloud infrastructure for cloud
data storage so that's why that's the
reason that they chose OpenStack to set
up their private cloud infrastructure so
let us see how they have done that so if
you see their infrastructure by numbers
right now they are using OpenStack and
they have been actually using OpenStack
since OpenStack released their first
release starting from SX and now they
are into okata as well so they have got
5000 compute nodes out of which 4,800
are cavium and 200 are hyper-v nodes and
they have almost 16,000 virtual machines
running on those nodes they have 2400
images
1800 volunteers and there are more than
2,000 users and 2300 projects going on
in the OpenStack cloud so they are using
Nova to its fullest to actually process
all those data so this is there a
typical structure the typical
architecture of the Nova service that
they are using in OpenStack if you see
here is a there is a top cell controller
and they have actually got solely
independent API nodes also that actually
connects different components together
so everything passes through the API
node and then the top cell controller
the cells are actually the computers
different computers that run so there is
a controller cell and the other child
cells are all controlled by the cell
controllers so each of the child cells
are responsible for a specific task
maybe for a specific project or maybe
there are a component of a specific
project
so if you see the architecture over here
this is the simple Nova compute or the
Nova service architecture so there are
api's this is the Nova scheduler the
Nova conductor the Nova Network and they
use the rabbit MQ for a message queueing
for passing messages on to the different
Nova components so this is a typical
Nova deployment by CERN I'm not going to
explain much about the Nova architecture
how Nova was this is just the layout of
the Nova deployment at CERN so I hope
you've all understood that any questions
ok no questions very well ok so we'll
move on so now let us take a look at the
OpenStack success stories how people
have used OpenStack and how they have
benefited from OpenStack so you have got
like 4 companies so you know that jfe
Steel is one of the largest steam
companies in the world and jfe Steel
with OpenStack has actually reduced 28%
on overall IT cost and Comcast it uses
OpenStack and their OpenStack cloud
spans 84 data centers and supports
different platforms residential email
product development and Hadoop Big Data
as well when you see Walmart which is
one of the largest companies in the
world
it relies on OpenStack to manage
ecommerce and in adnd it connects more
than 14 million wireless customers via
virtualized networks and has deployed
over 70 OpenStack clouds globally so
these companies have actually earned
huge success with OpenStack so now let
me show you how you can actually use the
dashboard horizon so this is the web
browser in my VMware I have already a
OpenStack setup defined so I'm going to
go to my dashboard so I already have
that link so this is in the IP 10.0 2.15
this is going to click here
so yeah this is the dashboard so this is
the first thing that you'll see when you
open your dashboard it will ask for your
login username and password so I'm going
to log in as admin
and after you have done providing the
password just click on this button over
here so there you have so this is what
you get after you login into your
dashboard so we are in the projects tab
over here so if you can see different
users
so these are the different users which
are basically just services over here
and every one of them has got a unique
user ID
so now let us go to this admin tab over
here you can see an overview
so you can actually see the usage
summary by also providing with a
specific period of time so this can be
actually your ceilometer service we
think of this you can say that active
instances it will count the V CPU hours
and in terms of how much memory it has
consumed how much RAM it has consumed so
this data can be actually used for
billing purposes so this is what
actually ceilometer monitors so she
let's say that I wanted from this state
to this to submit so yeah there it is
so the project name is actually the
username that I have logged into so I've
been using two V CPUs for discs I've
been using two gigs for ram one gig the
VC two hours is this much and there are
all of the details so let's say that I
want to launch an instance so let me go
to images because I have to launch an
instance from a particular image right
so this you can actually consider as the
glance service so this is where your
images are and you are going to launch
an instance in the Nova and if I want to
launch a serious instance our launches
from the image and I will click on this
button over here launch so you have to
fill up all these details ok so first
thing you need to provide with an
instance name I will call it OpenStack
VM
zero
so you also have to tell how many
instances that you want of this kind so
the stars that are mentioned to these it
means that this is mandatory you should
provide these details before you want to
launch an instance so let me go to
flavor
so flavors are actually the size of your
instance so there are different flavors
like em one tiny tiny or small so you
can actually create your own flavors so
this one was actually created by me you
can actually define what is the size of
the instance that you want you can
define the amount of BCP use the ramage
should use the total this size and
everything so let's say that I'm going
to launch a very tiny image let me
select the m1 tiny
so you can also configure the network so
I've already got a network defined which
is the public network the name of the
network is public and the subnets
associated it goes by the name public
subnet the state is up and active so
I'll just go ahead and click this button
over here just launched instance
so it showed a message that one instance
is launched so let me go in this
instance tab over here so this can be
considered as the Nova service
so this is your instance that you've
created so let us go ahead and power up
this instance over here so let me click
here so this is my OpenStack VM zeros so
this has the instance ID is this the
status is active it is launched in the
Novo compute zone so this is when it
created it has been four minutes and
that is created so this is the
specifications the flavor is m1 tiny the
flavor ID is 1 so the RAM that I've
assigned is 512 MB it uses 1 V CPU and
this size is 1 GB and this is the public
IP address so you can find all the
details of your VM over here so if you
want to access this go to the console
so there you go this is the control of
your instance
so you can login onto this instance of
the default username is eros and the
password is also given to you so you can
use this instance for whatever purpose
that you need you want to run
applications you want to use it for
testing purpose if you want to test your
applications on it you can do that so
this is how your VM gets provisioned so
now if you go to the network tab over
here so here you have these are your
networks that are defined the public and
private network this is for the demo
user or the demo project so now you can
now if you go to project if you want to
see the network topology of your VM or
instances or the infrastructure you have
how your network is connected to the VMS
and everything you can just go and click
over here
so there you have this is your public
network and you've got three instances
connected to it
she want to see the graph this is it so
this is a better way of seeing it this
one looks better doesn't it if you want
to see the labels so this is the public
network this is the VM we just created
and these were the two VMs the
pre-existing bins that we already had in
our OpenStack infrastructure so this is
how you can use OpenStack and this is
how you can actually manage everything
using the dashboard open Sakurai's and
you can access everything this is the
object store you can go ahead and
explore everything over here so this is
how to do with any kind of questions
till here does anybody have any
questions ok so no questions so to
summarize what we have learned today we
have learned the different
virtualization concepts we have learned
what is OpenStack and why do we actually
need to use OpenStack the OpenStack
architecture the different components
and we have taken a look at the
different success stories by various
companies who have used OpenStack so any
doubt still here you can still ask me if
you have any doubts in any of these
sections no doubt great
ok thank you everyone for joining
today's session if you want to learn
more about OpenStack you can actually
visit at a rakish web site and you can
explore what more you can learn about
OpenStack in Eddy rigorous course
curriculum so you can go over there
check it out and if you have any doubts
any queries or if you want to give any
feedback to me kindly post it in the
comment section below thank you everyone
for watching this and I'll see you next
time till then happy learning I hope you
enjoyed the thing with this video please
be kind enough to like it and you can
comment any of your doubts and queries
and we will reply to them at the
earliest to look out for more videos in
our playlist and subscribe to our Reddy
Rica channel to learn more happy
learning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>