<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Decoding the Science of Decision Tress with R | Webinar - 1 | Edureka | Coder Coacher - Coaching Coders</title><meta content="Decoding the Science of Decision Tress with R | Webinar - 1 | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Decoding the Science of Decision Tress with R | Webinar - 1 | Edureka</b></h2><h5 class="post__date">2015-08-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ytA8WdRur3A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello and welcome to the session in this
session we would be discussing about
data mining technique which is part of
supervised learning and that is decision
tree so we'll be learning about decision
tree which is part of your machine
learning right it supervises basically
let us move on and discuss more about
this so in today's session which is
scheduled for one hour we would be
discussing about the classic banking
challenge you guys may have already
guessed that if you have not done that
we'll try to do it right fraud basically
right fraud detection within bank if I
give you a loan what is the chance that
you might default on the loan kind of
right what are the solutions are
available do we need to use decision
tree only or can we use any other
solution if I'm given such a problem
such a challenge of detecting the fraud
within the banking sector right giving a
credit card lending alone might be a
tricky situation right what if the
person whom i am going to give loan or
credit card what if he is going to
default yeah bank is going to incur huge
losses so that's the typical challenge
that we have what are the way via
solutions that we have in order to
address this so a problem and why do we
need to use decision tree why not some
other technique right and we are going
to evaluate decision tree against few
other techniques which can most probably
use in this kind of a situation and then
we are going to discuss briefly about
the decision tree methodology we look
into the theory of decision tree
methodology and then we are going to run
the same thing on our our is a two
which is you know doing a lot of buzz
and lot of rounds in the statistical or
analytical world so we'll execute the
same case study theoretically on our and
see how we have to basically build a
modeler on that so that's the classical
situation credit card debit card opening
balance loan account someone might open
an account in my bank what if he is a
terrorist what if he is trying to save
or a safe black money in my bank right I
need to be aware of all those things
nowadays regulatory norms are so strict
that if you say that hey I didn't you
that this person was a terrorist doesn't
save you from taking a dent on your
brand image right so a bank wants to
classify its future customers into two
categories is a particular customer
risky customer for me and do I need to
reject loan for him or is this customer
a good customer and it's based on few
customers available attributes let's say
you have a customer aquatics YZ he has a
following attributes he's an undergrad
he's married he has a taxable income of
so much dollars the city population is
so much he has a work experience of 14
years is not from an urban area he's
probably from a rural region there how
do you categorize them as a risky
customer are as a good customer we need
to identify this so what are we try
do here we are trying to categorize the
person right we have two categories so
we are trying to categorize even before
we proceed with this case study let me
ask you this if I get an email to my
gmail or yahoo or whatever mailbox
uh-huh how does your email classify
itself into a spam email or not spam
spam means it should go and sit in the
spam folder if it's not spam probably
will reside in my inbox how does that
happen right think about that think
about the situation there is a new yeah
absolutely money it's based on machine
learning write an email for you might go
to spam the same email might come to my
inbox not just that you are seen not
this number of users the mail was sent
to it depends on wages are the
parameters for example if you're a
frequent traveler probably for you if
there is an email related to travel
promotion it makes sense but for me
probably I am NOT interested in any of
the travels so I'll select that email
and click on spam now when machine all
our goleta algorithm is going to learn
and it's going to decide whenever a new
email triggers on whether it has to
classify that in ela spam or not
learning my algorithm learns each time I
take an email select an email and click
on spam it's going to learn that from
next time this kind of email put it in
Spanky no right so
here are a few more case studies even
before we proceed with the banking case
stuttering a manager has to decide
whether you should hire more human
resources are not should I hire or
should I not have you that's a problem
we need to crack that you cannot go
where that feelin say hey let me hire
let me try if that works otherwise I'm
going to fire them labor laws are not so
easy right if you're hiring and firing
someone no one is going to sit idle
right will be a lot of cases filed
against you how do you avoid the labor
union strikes and things like that if
you're going to hire it's going to be
very costly affair what if you are
planning to hire five data scientists
for example it's gone going to cause you
a lot of them all right so you'll have
to be very data oriented in order to
take such a decision an individual has
to make a decision such as whether or
not to undertake a capital project or
must choose between two competing
wenches that's another example so one of
the solutions are available this is
basically a classification problem I'm
trying to classify that is I'm going to
segregate say I'm putting all these
things in a small basket and giving to
you what would you do you're going to
differentiate everything you're going to
classify everything these are my fruits
these are my wedgie table these are my
meat whatever we cream what techniques
are you going to use here we can either
use decision trees knife bayes
classifier k-means cane and basically
sorry not Kimmy's k-means is part of
your clustering technique part of
unsupervised London right here we have
Kanan k-nearest neighbors support vector
machine svm can also be used so and many
other things are there but primarily let
us look into these four and try to see
which one is going to best suit us
here we are so DD stands for decision
queen i beez k-nearest neighbors and svm
do we have a question now we are mine la
desegregation also can be used here
follow the folks don't worry about
logistic regression that's a kind of
prediction building technique basic
model building so look at this we have
yes against each and every statement
which is made here those are the
advantages of decision Queen I would
order the models the other models will
they not suit here they've might suit
but they are just explaining or that one
tease each model or each technique has
its own advantages and disadvantages in
real time probably you will end up using
two or three techniques together to get
a valid output there but for a webinar
discussion for the signalers restrict
ourselves to decision tree and its
advantages the visualization of decision
tree is going to be extremely simple
which you are going to learn even when
we execute our code our command it's
extremely easy to interpret and easy to
explain to the executives even if you
have non-programmers Freud who do not
understand the programming concept or
logic behind that you can easily
interpret things dt which is decision
tree illustrates a variety of decisions
and also the impact of each decision of
different decisions where do we take it
so you have two or three or five
decisions to be taken right which
decision is going to impact your final
outcome to what extent that can be
easily illustrated using decision tree
it's going to allow you to predict
or classify or explain or describe
whatever outcome you're trying to
achieve if it's a numerical variable you
try to predict ifs categorical probably
will try to classify right it's not just
going to give you only one scenario
wherein it says hey this is the final
classification good with that no it's
going to give you or it will also help
you determine what is the worst case
what is the best case and what are the
expected values for different such
scenarios and the good part about this
is it can handle both numerical and also
categorical data if you have categorical
data it's called as classification
problem if you have numerical data
numbers salaries and things like that
it's called as prediction problem risky
even in data mining you call numerical
things as prediction and you use
regression all right you have these four
techniques now decision trees are white
boxes that means the acquired knowledge
can be expressed in readable form if you
run this model right decision tree
everything is clearly visible we will
just hold on right we are going to do a
practical experience or we are going to
execute our code and we'll see
practically how does it look like right
while the other models are black boxes
that means you'll not be able to read
what's happening internally right with
the knowledge that you have acquired in
order to comprehend it's gonna be
difficult for example right in decision
tree you left these kind of classifiers
these kind of rules such as if weather
is nice and if when is normal and the
days sunny then go play it's in the
readable format right very easy to read
that's a good part about decision tree
now look at
this it illustrates a rare idea of
decisions basically and also the impact
of each decision that is what we have
discussed there is a manager either he
can hire a permanent employee or he can
outsource a piece of work again it's
classifying right to decisions either
you go for a permanent employee or and
out of the piece of work what if I hire
a new employee and what is the success
associated with that there's fifty
percent chance that you're going to save
hundred dollars is there also risk a
negative risk associated with that yes
with fifty percent there's a fifty
percent probability that you might also
feel and what happens if you fail you're
going to lose 40 thousand dollars right
look at this another thing here if you
out shows a piece of work there is a
success and a failure associated with
that right either you can succeed or
fail any decision that you take either
you succeed or fail basically right
there's a fifty percent chance that you
can you might succeed and you might save
ninety dollars and there is a 50 /
chance that you might also fail if you
fail you're going to lose twenty dollars
so here I'm looking into probability x
impact probability 50 person x in x the
impact is going to give me the value for
success probability x impact 50-person
failure x the impact is going to give me
another value if i subtract these two
I'll get the final outcome this call is
expected monetary value 1 and so let me
that's okay fine alright so with each
decision you might have the succeed or
fail so the values associated with the
success and failure are listed down you
multiply probability by impact for
success probability by impact for
failure you multiply right and then you
subtract these two to get the final
outcome expected monetary value you
multiply the probability by impact here
also you multiply probability x pipe you
subtract these two to get the final
value right right which is thirty
dollars and thirty-five dollars zero
which one is giving you more profits
here thirty-five dollars from so you'll
go and also the piece of food so your
decision tree not just tells you or not
just classifies but also it's going to
provide you with the details on what is
the success and impact associated with
each decision that you're taking now let
us understand this more so decision tree
is a supervised rule based
classification okay Manisha
this question these dollar figures how
they have been yeah it's notional money
cheats notion if you have the subject
matter expertise you can decide right if
I put hire a person how much salary do i
need to pay him if the project is a
success what is the benefit that I'm
going to get you do all those things
based on that you are Abbott a number
impact there's a lot of groundwork that
goes into that all right this decision
creates a supervised rule-based
reasoning basically so you will have a
flow chart in this way and the top one
snowed here will be called as a root
node
and the moment i classify it here like
sunny rainy or cos I'm classifying great
basically it's based on classification
rule and these notes are called as
basically internal nodes and you have
the branches these are all the branches
and then finally you have the leaf node
leaf node is also called as terminate
node that's the last no red you cannot
further classify map now the path that
you take front right from the root node
to the leaf node is called as a
classification rule so one
classification rule could be if it is
sunny and the humidity is high don't
play if it is stunning and if the
humidity is normal go play if it's
raining probably go playing I don't know
what this outlook is if it's overcast
and windy probably not Lee if it's
overcast and it's not when you probably
won't want to play now this attribute
selection measures right what attributes
you should I measure how to a split all
this is based on some greedy approach
and entropy which is out of scope for
our discussion ring if you get into this
program full-time probably you learn
about not probably you will learn about
the finer nuances of that so here we go
when this technique decision-making is
coupled with machine learning right
decision tree can be used for prediction
purpose if you're going to couple that
with your machine learning cons because
decision tree on its own is a different
concept stand alone
entry is a different concept can be
using a project management as a simple
technique right to help you decide on
which decision is better for you right
so look at this now we have come back to
our previous algorithm so this is the
historical data that I have if a person
is undergraduate married taxable income
city population he has so much of work
experience and if it's not an urban
probably the risky customer from and if
is going to fall into this category
probably is a good person so I look into
the historical information I see who are
those people who actually defaulted to
other people who were paying the e/m ice
or who have repaid the loan without any
challenges without any default things in
a statement right so I have all those
details here so induction that means i'm
using this data to actually build a
model i use some learning algorithm i
learn the model once the model is built
i can apply that model to new situations
new scenarios now a new customer comes
to me and applies for loan i'm going to
capture all these details from that
particular customer i'm simply going to
put in this already built a decision
tree and get a solution on whether this
person can be categorized as a rescuer
good the new person and let's get into
God extremely finally once where that is
let us know our model works right so now
don't ask me a question on you know why
do you select undergraduate as your root
node why can't i select Martell status
why can't I select this icon and select
city population why can't i select work
experience or any other category there
or any other variable there as my root
node just because this is the first
column doesn't mean you'll use that all
right so
that is when this is where you know an
algorithm called as greedy approach and
entropy values and information gain
comes into picture manage if you do not
have historical data then there's no
chance of classifying anything right
then probably you'll do some experiment
some say way to get the data are you can
probably go with unsupervised learning
in look into some kind of clustering
right but in order to do this you need
to have some data if you do not have go
get it do some surgery do some
experiment quickly and you know you're
good to go all right so I'm first class
if I'm using undergrad if I look into
only undergrad right I'll see for good
and three risky they're basically seven
entries here I have two and here I've
fine so is a person undergraduate yes or
no that's the first classification
problem that I know so all entries
related to know are listed on you is a
person undergraduate all the entries
related to yes is listed on here so if I
go to this model right I have two years
yes n yes so the Rose associated to yes
would come in here and the Rose
associated to know would go there now
I've classified I'm going to stop the
classification if I see that the
category is the same my intention is to
categorize in two similar groups so here
I have risky and risky so I'm going to
stop there if two categories on same
here i'm good and also have risky so
i'll try to further classify this
particular branch how do i do that right
this is also called as pure subset
because there is no other way of
classifying this my final outcome is
category
to classify a person is riskier good so
here I've risky and good combination so
I'm going to further spin the second
split here is taking marital status why
marital status why not taxable income
something you look at the information
gained and things which spit is going to
give me more information basically all
right you're classifying a single and
the worst are you have three entries for
single and you have two entries for
devos so you write down the
corresponding columns the rules there
and here are you going to further split
this guy's are you going to further
split this divorced blades on taxable
income or city population do we need to
further split that no absolutely no
because that's a pure data set but nity
nity nity says that the pure subset can
also be decided on the basis of marital
status rather than category absolutely
yeah you can do that may be or may
understand your question properly nitish
okay no no no Nitish no now I got it so
Nitti see is that marital status is
married and married so you need not
further split that no that's not the
logic the logic is looking into the
outcome which are interested now come
with your interested in the category
right now they so you'll have to look
into only category section yeah Shashank
session log right janish versus urban
what do you mean when they're so yeah
this single should be further classified
using urban there this need not be
classified because you already have good
and good there if you have the same
category you're not going to further
classify me here you have good and risky
two different categories so you into
further split time now you have further
split that based on your taxable income
in you get two more pure data sets pure
subset drink that so this is a simple
classification now if I were to tell you
on the classification rule right i would
say undergraduate no mantle cities
dewulf drop down that's one room
undergraduate Muriel's module see the
single and less than 32,000 that's
another room undergraduate no metal
state a single taxable income greater
than or equal to 33 King you had third
rule so in this way these are all your
classification rules ah my anchor so
that's out of the scope of this webinar
because time would not be sufficient
Michigan we are already half an hour and
I have not even completed fifty percent
there we'll see at the end if I find but
that's not a concept which can be
explained probably in 15-20 minutes it
would take some sufficient I'm sorry
about that so
use a model now now here is a new data
point which you got right a new person
came to you and he has fill in the
application with all these details now
you are left with a challenge on whether
you have to give him the loan or not
approve his loan arma for that you need
to first categorize this particular
person so look at this this is a test
data so first taking first one easy and
undergraduate know she'll take that
route marital status is what you are
going to work into easy married or D was
divorced so these two it's a good right
classification if I go back
undergraduate mantle street is good so
that's a rule that you have established
long bar so based on that classifying
the customer is good and probably a wing
to lend him the loan or what it would be
right so now comes the hand sound
session here even before that do you
have any doubts on just basics of that
who sets the rules you have got the
rules right from the decision tree
that's an algorithm this is an algorithm
machine learns on its own Manish so
first time probably if you have limited
data say you have only data point for
ten customers you are going to build
this model and start using maybe the
accuracy level is only fifty percent may
be right but as I know you keep using
that right as and now you keep
predicting with the new customers as an
have your data set improves increases
then you are going to further tweak your
model right now see now i'm going to
explain you on our yes actually
deeper engine R is a new tool or new
language on its own which is specialized
in your statistics data analytics yeah
it's similar to see sleeplessness or
whatever technologies you can think
about but this process is to categorize
data how do you know data in Category
feels risky good without the model you
first build the model based on your data
you first build the model right because
based on your historical data you might
have already captured Santana sorry
Shantha you might have already got your
historical data you might have lent
alone to 100 customers or of them 70
have paid on time 30 of defaulter so
you're going to class you're going to
record all the data of historical uses
thereby you come to know what category
people are going to classify be
classified as you know defaulters on
what category falls under you know good
customers Guinness how is it different
than SAS or Hadoop SAS is another
statistical tool which competes with our
but our has forty six percent market
share as compared to SAS which has only
eleven point three percent market share
now as of today two years back situation
was different size for the market leader
in statistics and analytics but as of
now it's our Hadoop is different Hadoop
is all about dealing with a big data no
absolutely no shank I do not agree with
you are is free SAS programming is even
more difficult in comparison to our
a space is more difficult to learn
because it has its own structure and
things like that our programming is
pretty easy if you would have used that
where do you have gui-based you're
speaking about e-minor you're speaking
about e G and E minor Shashank right
what is the cost of that license single
user single the shop license cost you
four tunes I think the entire
implementation would cost you five or
six screws for a company why would a
company spend five or six screws to get
SAS Iman which cannot do everything
which are does SAS has how many products
close to 12 13 products so that's the
charm r is open source or a whole money
has a question I think so then do we
deploy decision crease in production
with less data as it is expected to
learn over time meaning we are okay with
errors inch absolutely that's a call
that you take oh absolutely do you want
to go by a gut feel Manish and then give
a loan or do you want to rely on some
data that you have what called you take
are you going to rely on some data that
you have to take a decision or are you
going to go your bug go by your gut feel
take a call you're going to take a
bigger dent on your brand image if
you're going to go where got three so
that is what you are telling me don't
use any model because you do not have
anything
our can work with her tube absolutely
you can integrate with our what if our
analysis goes from my Quran we are not
God to be a hundred percent correct but
we want to make an effort to take the
route of data-based decisions jatin what
was that / mg that you have typed in
some junk I believe all right and r is
for structured data no assure our deals
heavily our deals heavily with
unstructured data issuer says do we have
site for no we do not have that in this
session how is Big Data different than
data signs big data is all about data
coming in from your videos youtube from
your mobile phone conversations audio
files from the images that you post on
your wats app or something right and
it's based on the data coming in from
your Wi-Fi logs from your GPS systems
and all that along with your social
media textual information right that's
big data big data is data which your
traditional systems cannot handle they
is all about building these kind of
prediction models our work can our work
on very large data sets is a question
raised by my unk our is
memory the system memory that you have
say you're using 4gb RAM it's limited to
4gb ram but nowadays GPUs are coming in
and not spend a lot of laminate GPUs
which will help your are handle larger
datasets audiences effort is wasted but
if you're not building model what are
you losing their I mean it's
cost-benefit analysis basically right
GPU is like CPU basically right GPUs are
like CPU session and it's much faster
smaller chip smaller size things like
that ah one second there we have
let me see whether I can answer that
fishing Oh graphics processing units yep
let me go back to our are also here is
our am I in the wrong webinar I'm a web
developer has our programming room
absolutely Ravi just do a Google search
on what kind of opportunities are
awaiting a data scientist what are the
salaries that they're drawing and things
like that you'll take back your word and
say that hate is a good wave now that
I'm Martin yeah you are have any glue no
r is open source it does not have any
global certification all right I think
you guys have exhausted of your
questions right let us actually run this
and try to simulate the same learning
that we have done on our this is your
are our studio basically right is there
a question from how to get recognized in
the market from our piece if you
probably undergo these k of
certification programs Yasin that in
itself is going to induce some
confidence in interviews point number
one point number two choose a course
which is very robust in nature do not
choose a training program from summer
institute which covers only the basics
without the case studies we saw the
project and all that right if you look
into it you're a kite smell structure
you have the theory you have the case
studies you have the assignments you
have everything in monasteries
no single Institute right there is no
single insecure are there is no one
global certification for redesigns each
university has its own right each
training institute has its own so the
one thing that's going to differentiate
you from joining something would be
probably the course curriculum just go
to the course curriculum and see whether
that's in line with job descriptions
which are posted on various websites job
portals right that's going to give you
some sense ah what are the good books to
learn our garnish where r is an ocean in
there is no single book you can do data
mining with our foot decision tree right
data mine data mining with our that's
the book that i will recommend furrows
his job they demand for certification
most important and so on absolutely but
if you have a certification and if you
could not answer anything are they going
to take you yeah see that's the point
that you have to ask and second thing is
a Eureka also provide you with a
certification right why not good take
that wrong what is programming language
used for our our Ravi our has its own
programming language i'm going to show
you now yeah yeah yeah nice for data
mining using our okay here we go we are
going to read this data set i'm not
going to explain you the code which is
used in our rather I would spend more
time in clarifying your doubts so let us
run this first line right what this
first line is doing is its reading this
file for our check dot CSV now I have
this fraud check dot CSV data set where
is it here it is so someone was asking
me on what how does your initial data
look like right before you build the
bottle before even you build the model
you'll have few details available my
excel is crazy because it has a bunch of
different plugins installed I have not
Excel of X or mine or a crystal ball and
all that so just bear with me while it
opens
comma-separated value that's an extra
thing yasin dot CSV stands for what
exactly is our job as a data scientist
Justine so you will end up building
these kind of prediction models jutting
basically you'll be predicting the
future sales you'll be predicting the
future rainfall probably if you're in
weather department right you'll be
predicting on which product will get
sold to a great extent for retail
customer if you go to amazon and search
for a product it's going to recommend
another product for you so how does that
prediction happen how does amazon
recommend you a particular product all
these are a business analyst i would say
shashank at least two months of practice
two months of undisturbed you know
attention towards these programs is is
going to put you in a pretty good
position to crack an interview
difference between data scientists and
business analyst is a question yasin is
asking data scientists is a person who
is going to play with the numbers
crunched the numbers build the
prediction models may company more
profitable less risky and things like
that business analyst is a person who is
going to gather the requirements I'm not
speaking about business analytics spin
your business analyst woodmere des cours
help des means mohnish data science
alright yeah it's going to help you what
more is needed on top of this you need
to learn statistics you need to learn
forecasting you need to learn data
visualization and you need to learn data
mining techniques if that is why Manish
you'll have to be cautious on selecting
a course look into the course curriculum
looking to the job descriptions of the
radius web portals that's going to give
you a ballpark figure or some kind of a
sense on what courses you are you have
to learn what are the tools and language
is to be learned to become a data
scientist is what Justin says jutting so
statistical analysis forecasting data
mining and data visualization these are
the four things that I would recommend
from mine how do you differentiate
between data science and predictive
analytics predictive analytics is a part
of data science issuer business
analytics and ears are similar yes yes
in they both are similar once you do
something
with the data you will have to come up
with a business inference out of that
any data analysis that you're going to
perform should help your business
basically that is your business analysis
there are some free courses offered in
Coursera will help and it's going to
help you chesham it's going to help you
alright so here is the data set which we
have undergraduate details marital
status taxable income city population
work experience and then urban yes or no
right now this is the data set that I've
which I've uploaded to our I'm attaching
the data set for my use i'm reading the
header when I say header right it's
going to give me the full six cells of
this particular excel sheet right which
are 600 rose and six variable six
columns 600 out of six right so out of
these 600 observations are rose the
first six are displayed here then you
can do a quick summary and check this
call is descriptive statistics read you
first describe the data set try to see
how the data set is going to look like
and things like that so in undergraduate
I vsf know 288 places I have no 13 12
places I've years marital status have
for this factor i have three levels
divorced married and single i have the
count against each of those these two
are your categorical data this is your
continuous data income hence you have
minimum value maximum value you have
taken the mean median first quartile and
third one first quarter's right a bottom
25% third quartile is from minimum value
to the third water you will have 75
percent of the data
issuer yeah in memory basically it
stores there locally for some time guys
hope you are able to hear me all right
yeah now let us do this I'm going to
classify the people who have taxable
income less than or equal 30,000 and
risky and the people who have greater
than 30,000 has good just for our
understanding just for this case study
purpose in reality within the data set
itself you are going to have whether a
person is risky or good customer right
now what am I going to do I'm going to
merge this new column which I've created
with the existing data set front so you
have six variables now here if a run
that command have seven observation sir
that means the new column which I've
created which is called as here which is
called as
got created and I've basically merged
with the existing table there now if you
look into the table right you'll see
that a for category what is this doing
customer dollar category from the
customer data set I'm selecting category
which is available now let me run this
command so what did I just do or let me
look into names and then it'll become
easier for you so okay ok now what I've
done is I've deleted the third column so
look into this you have undergraduate
first column second column is marital
status third column is taxable income
that got deleted and that girl anyways
you have category right income less than
30,000 you are going to term him as
risky greater than 30,000 as good to
that category is anyways there now all
right now c is equal to two mins i'm
going to restrict my sample i'm going to
say that
hey generate the same sample each time
kind of do not worry about that if you
do not understand right now whenever I'm
going to build a model I need to look
into two things one is I need a training
dataset based on which I'm going to
build a model right say out of 600 I'm
going to say hey let me classify or
segregate or divide this data set into
two halves fifty percent each so the
first fifty percent of the data I'm
going to use on training or building the
model basically right look at the length
of crane it's 300 because I'm doing
number of rows of customer / 2 and
assign it to the training data set so
the length of training is giving you
three hundred I'm assigning minus strain
the test that means whatever data set or
whatever rules have assigned to the
training data set apart from that water
is left out whatever 300 is left or am i
sending it to the testing Edison i'm
looking i'm going to look into the
length of that which is 300 so 300 for
testing and 300 for train why am I doing
this because once they build the model
I'm going to test whether that model is
actually giving me good results or not
what is accuracy of that model right I'm
going to test using this test data so
the training
is it we have the testing data set look
at the names I have all these things for
testing Gators head I'm going to
classify something called as testing
underscore hi I'm going to create a
check the length which is 300 once again
i'm looking at the dimensions of
training dataset and testing data set
right now if you have noticed here
you're testing underscore high has taken
the category it has taken all the
categories from your test dataset
basically right so what does my test
dataset contain fifty percent of the
data from this whole data set out of
that I'm just taking the category you
know what is category here and just
taking my good and risky details only
this one column there and I'm assigning
it to testing underscore hi just for now
remember that so I'm going to look into
the summary of the training is it I come
to know about the summary here briefly
you need to look into how the data is
distributed and things like that in
order to run this decision tree you need
to install a package called as free now
what is three trees a package or
collection of code which people have
already written in the past and that has
been approved saying that hey you can
reuse this code that's a beauty of our
they'll be there are two million users
working on our two million uses say I'm
a user I'm doing some work and I come up
with an interesting code to accomplish a
piece of work I can send that go to our
coal community who are going to package
that code and give it a name and release
it in the market for free do you need to
like the code each time not require you
can just use that right so look at this
package free was built under our version
this so here if this package is built
you need not install it once again so it
comes by default in your arm now I'm
this is the command to run decision tree
tree I'm running this decision tree on
training data and I want category I want
to predict the category whether the user
is or whether the customer is a risky or
a good customer this still is going to
tell why regressing on dot dot means and
all the remaining variables there so
classify and tell me the category based
on undergraduate metal status city
population work experience and I'm and
that is what your dog means there and
I'm doing that on my training data set
let me run that done so let me plot that
free look at that nothing is visible
you're right on this plot this is a
decision tree that's created but I want
to know the attributes associated with
that here we go so this is how it as
classified is sick in first city
population it's segregated that based on
work experience once again based on work
experience and city population and
things like that and then you have
various rules created what is the rule
city population less than 58 to double
three yes it goes to work experience is
work experience less than 20 years is it
less than eleven point five years then I
in city population and again in that way
right it's going to create your decision
tree now I'm predicting now I've just
built the model will the decision tree
now I'm predicting it using that predict
function right
so I'm trying to predict based on this
model tree model that I've built and now
I want to do that prediction on the
testing data and I want the
classification to type this class don't
worry about the code my dear friends
it's not easy to learn in one hour right
so here we have the dimensions of
training dataset now once i have done
that i want to look into what is the
Miss classification error so we're on
when i run this model it's 0.2 333
something this says that right your
error is more so for example in reality
a person should have been a risky
customer but he has been classified as
good in reality a person should have
been good but he is classified as a
risky the higher this number more is the
classification error right so that means
your model that you have just built is
not helping you achieve good results
what do i do if that is the case you're
going to prune the tree pruning means
limiting right say you have these many
levels of split probably you willing to
reduce these number of splits or
probably you will consider only once one
part of this that's called as pruning
where is this so again you're going
fix the sample size and then you're
going to this command seaweed or trees
for cross validation and what are the
names in that size the method basically
it's going to use that that is worth
speaking about so when I cross validate
right when I do this it's going to give
me these dots now don't worry about this
i'm going to explain only about the
interpretation I be means both both your
dots and also your lines let me run that
now look at this from here until here
it's good then there is a certain change
there's a steep band there Steve been
right at second position there is a
steep and basically so i'm going to use
best equal to two because of the second
position i have seen that that is so i'm
going to prune the set now do not worry
about pruning in all that i'm doing that
so once I prune I come up with a plot
now if you see for a fact it has been
condensed remember the earlier one it
had a lot of branches and things like
that now you have reduced the branches
right why did you do so because my graph
here the plot cross-validation was
telling me that hey take only two and
I've put 2 there are now if you predict
and now if you look into your miss
classification error you're getting 0.22
so you are able to reduce it from 0.23
33 t something to 0.2 you can further do
that or very advanced techniques
available in decision tree which is
going to help you achieve your outcome
right so I
few more examples porch which I'm going
to take your questions so you can use
your decision tree to find out tumor
cells right cancer cells and all that
you'll be able to classify the credit
card transaction as fraudulent
transaction or not if you're going to
swipe a credit card somewhere sometimes
you tend to get a call from the call
center cygnett serve have you really
made the payment or have you really
initiated the transaction based on what
are they going to decide it obviously
cannot call each and every customer and
check whether the transactions
fraudulent or not because millions of
transactions are going to happen at any
single point of time right categorizing
the news articles as finance related
articles weather related articles if
people are posting on social media left
right and center how do you you know
scrape through the entire data and
classify as finance weather sports and
things like that right so you can do all
that now I'm open for questions post the
questions I will request you to look
into this all right whenever you are
making a future complex decision you can
use a decision tree when you're just
experimenting with the decisions right
and if you want to evaluate the decision
visually and look into its impact you
end up using decision tree when you want
to present your decision and its
comparison with other decisions then
also you tend to use that do not forget
friends at the end once you close you'll
be shown the feedback survey feedback
URL please spare just few minutes right
it will hardly take 15-20 seconds so
just fill in the webinar or so we write
thank you so much for attending even
before that let me take your questions
now
party package sneha DJ use party package
somewhere very rare user short party
package right it's tree package which we
have install our is your question
something else to say here is a question
what is a package but Vicki I am not
sure you will have to check with it
Eureka as a trainer here so you'll have
to check with that Eureka maybe yes
maybe no I don't know so shantha as a
question 15 years experience a senior
project manager what roles really up for
indeed a science field I've learned
Hadoop are an antic smooth Cassandra and
machine learning from a Eureka how great
that sound great so Santa I will request
you to look into the domain expertise
that you have rights fifteenth
experience is not a small experience and
I'm sure you might have gained a lot of
expertise in your over the 15 years in
particular industry or sector or domain
right you will have to look into that
specific industry or domain and apply
for a position wherein you lead a team
of data scientists and guide them miss
clear it that is a kind of position that
I would rather look into if I were you
what is it
should probability using this tree code
the prior probabilities for target was
its non-target is not one is to one
hundred fifty percent each I quite I
didn't get you are the clear on that
question what is the threshold
probability what do you mean by that
between r and python watts
fashion on demand r and python are
equally good now i would say our
ah no Aditya default is not 50 person I
have divided the data set into fifty
percent training and fifty percent
testing I've just segregated in that way
default is not point for anything what
are the on-site opportunities for data
scientists there are plethora of
opportunities just do a search making
see data scientist job shortage right
you'll see that and whatever country you
are trying to up right just go to the ER
job portals looking to this keyword data
scientist data analyst data engineer
business analytics and things like that
come to known your what's your career
prospects for business and analytics and
data science which has better future
career both are the same it's yesterday
I can call you moma door I can call you
your scene right either way it's a scene
it just seemed him for two different
things mmm default this point right to
make decisions and answer that I mean
what are the type of questions ours in
data ah Shashank that funky I mean
depends on company which company is
interviewing you which domain they're
planning to take you if Amazon
interviews you they ask a lot of
questions related to retail how do you
build a recommendation engine mushy and
Association rules and things in that if
a banking customer or client or some
company in space of FSI is going to
interview probably the last few
questions are on how to build a fraud
detection model and things like that so
it's all specific to any mr. Dale can
you show the max of predicted
probability across each class of the
targeted variable I didn't quite get you
audit Leon that you can drop me an email
or to support a tad arica that go
probably i'll be able to help you with
that but just a little elaborate on what
your question is there when doing a data
scientist program in u.s. be helpful
absolutely but doing a data scientist
program jet in there is going to cost
you fortune if you're going to get the
same program for a lower cost here why
not optus rather than op that I a scene
which sector case studies do we deal
with while learning I think there are
plethora of case studies across the
industry so that everyone benefits from
the program alright friends I think we
have done a good job in able to complete
the session within one hour and also
address few of the questions thank you
so much for attaining a session have a
great day</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>