<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>ETL With Big Data | Talend For Big Data | Talend Tutorial for Beginners | Edureka | Coder Coacher - Coaching Coders</title><meta content="ETL With Big Data | Talend For Big Data | Talend Tutorial for Beginners | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>ETL With Big Data | Talend For Big Data | Talend Tutorial for Beginners | Edureka</b></h2><h5 class="post__date">2015-03-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/b8NwZYEOZuE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is most of the agenda that we are
going to cover today now what is what
exactly is ETL with big data or Talent
with big data it's a graphical
abstraction layer which is sandwiched on
top of the hadoop application yeah
now the surprising births going on in
the market these days that introduction
of huddle big data is the tomb for the
ETL which is not true this is really a
myth
all right now the surprising stuff about
this current way of buzzers up this is
really not practical and these are all
outlined as comments made by some named
statements yeah now the typical
assertion as I said how do eliminates
the need of ETL seriously that's not
really true now what no one seems to
question in response of these sort of
comments is the name assumption these
statements are based on is it realistic
for a moment let's think is it realistic
for the organization to you know
transform their whole enterprise data
from from the a legacy platform to the
hadoop system there are a lot of
challenges so it's really not the
evolution of ETL but we will see soon
that how ETL and big data they come all
right in between guys adjust for your
understanding
how we have planned a webinar we are
going to finish up the session in in
half an hour's time then we have
reserved the question answer you know
questions around for all the
participants or at least for 15 minutes
to 30 minutes all right
so by the end of this webinar we are
going to take up you can write down your
question on the question board and by
the end of this webinar me Mike your
your webinar presenter your future or
the course is going to take all the
question one by one you can trust me on
that
right now moving you know moving forward
now this modern data integration tool in
platform they ensure the timely trusted
relevant and secure now more an
integration technology use optimizes to
process the information in both scale up
and scale down architecture
now push processing into database man
system and not just the data into the
Hadoop sorry
they also integrate from end to end
now they broker and publish the data
layer that abstracts processing such
that multiple application can consume
and benefit from the secure and curated
data set
ETL no doubt means to continue of course
to evolve another for developer
preference at performance but it also
takes care of the left hands in need of
the modern application see honestly
speaking hundred we'll just another
engine upon which he L and its
associated technology like data quality
data profiling can run well renaming
what is commonly referred to as ETL or
was ignorant dismissing the data
challenges and enterprise wide data
needs is just irresponsible well this is
one of my favorite slide which explains
a lot of myths in yes or no is writing
ETL scripts in MapReduce code is still
retail that's right yes it is still it
here now is equal running faster in few
cases and slower and others on Hadoop is
eliminated yeah no absolutely not in
introduction of hadoo changing when
where and how
idiot happens yes now the most important
part with ETL big data is the question
is not really what are we eliminating
that are we eliminating ETA or not but
where does ETL take place and how are we
changing the definition and how does it
really complement the big data alright
they go hand in hand all right now what
is this ATM all right now ETL
represents the ability to consistently
and reliably extract data with the high
performance and minimal impact to the
throw system represents the ability to
transfer one or more data set in the bad
or real time into the consumable format
now obviously the load stands for
loading the data into the persistent or
the virtual stone now this is more or
less anyone who is not from the
background of EPM can understand this is
more or less what the ETL does moving
forward the most important slide in the
webinar why do you need to use why do we
need to combine the ETL with Hadoop and
most importantly why do we need to
combine talent with detail talent with
Hadoop sorry now now how learning this
ETL along with the big data is in the
major business challenge now right major
business problem it is addressing now if
you see this entire products route
offered by talent we have big data we
have data integration we have data
quality with a master data management we
have recently introduced Enterprise
Service bus
we have Business Process Management
anything that you talk about data is
part of Ln products food and when you
combine it with Hadoop which we are
going to sleep let them under till in
minutes that writing how Talon for big
data is abolishing or almost making the
MapReduce programming so much easy for
any developer whether you are starting
fresh whether you are program manager
whether you are an ETL he or whether
you're technically whether you senior
staff it really doesn't matter
learning talent for big data is just so
easy now why this is this is one-stop
solution now talent is of course above
ecosystem which complement most of the
environment whether you talk about the
Hadoop ecosystem in terms of P in terms
of hive in terms of scoop in terms
of HBase each petal on Cassandra open
the no sequel database like MongoDB you
name it talent has a platform to
establish the connection and make the
job up and running in that environment
all right as you see most of the top
class brand the market leaders in the
Big Data industry whose map are cloud
era they all have done the partnership
with talent
knowing the capabilities that it has to
offer
through its graphical user interface and
it gives you so much of time rather than
doing the MapReduce and coding which
gives you obviously a upper edge now to
improve the efficiency of the Big Data
job design with graphic interface
abstract and generates the code run
transform inside Hadoop native support
for HDFS scoop HBase mahute big high
MapReduce as I said Apache Allah is true
embedded in hot rocks data platform now
they are obviously as I said certified
with the three market leaders Wow there
are power bottom box all right now we
are closing on to the action white alum
this is what the talent corporation has
to say because the more connected the
data the world becomes the more quickly
a business must adapt very underlined
statement yeah because the more
connected the world becomes the more
quickly a business was again imagine if
I'm only working on big data environment
as as a big data user or I'm a MapReduce
programmer or I just know hi or I just
know think but I really do not
understand my business data it really
doesn't make sense now why does learning
talent helps here because Stalin
learning with the big data gives you two
operands one it makes you winner of
and the leader of how to integrate your
data to understand starting from the
source where the data is coming from
plus it also gives you a control on the
big date idea all right
now that makes you the winner of both
the world obviously talent is only the
graphical the only graphical user
interface tool which is capable enough
to translate an ETL job to the method
will show the Nietzschean job gets
executed as a MapReduce job on Hadoop
and get the big data running up and
running in minutes and make you a big
data developer in minutes this is a key
innovation which helps to reduce the
entry barriers in Big Data technology
and allows ETL job developers to carry
out the data warehouse offloading to
greater extent now it's strong applet
eclipse-based
craft little workspace talent open
studio for big data enables the
developer and data scientist to leverage
editing and processing technology like
SD a passage base high pig without
having to write Hadoop application code
a dupe application seamlessly integrate
within minutes using the talent now
before we go to the next slide let me
just have a quick look on the question
board all right
hi I'm new NIT
I have different background deviously I
took - all right all right
we will what kind of processing moves to
the data in Hadoop goes to the
computation all right gasps and now Z
just within minutes we are going to
finish up the slide then it's all demo
and it's all questioner all right now as
you see on this forehead white talent
which still we still justifying white
tile and anyone who comes on you who the
pressure who comes from a different
background because there are a lot of
news floating on the market should I go
to the MapReduce programming where
should I learn it through tool plus
because
and for big data is an awesome tool when
we are going to see the demo in minutes
you will be just mesmerized that what it
is capable of doing in minutes now by
simply selecting the graphical component
from the pallet and arranging them and
if you know the right set of
configuration you can create a Hadoop
travel minutes at a low 29 into his DFS
which is Hadoop distributed file system
it will use the Hadoop thing to
transform the data and the load data
into the Hadoop highways data warehouse
it can perform aterial or e e leverage
the scoop scoop is nothing but it will
take out the data from traditional atopy
on the state of a system and pushes it
into vintage a moment Wow
Tallinn open studio Tallinn open
solution plus the power of a to make
Stalin open studio for big data right
for Hadoop application to be truly
accessible to your organization they
need to be smooth integrated into your
overall data flow now talent opens for
big data is the real tool for
integrating the head of application into
your broader data picture now one of the
primary reason why talent is so powerful
it has more built in connected component
than any other data integration solution
available visited in the market with
their 800 close connector that make it
easy to read from or write to any major
file for my data base package Enterprise
Edition you name it most of the area and
it covers anything they don't cover they
keep on upgrading in their newer
versions so for example Talent open
studio for big data you can use drag and
drop configurable components to create
data integration flow that move the data
from delimited log files into Hadoop
hive or form the operation I extract the
data from hi min remaining sequel
database there is n number of
possibilities guys see of course more
and more enterprise wanted to scale up
in Hadoop Big Data technology with the
use of existing pool of talent
this is where our IT industry and most
of the area they are struggling that but
going on that you need to have Java
background and only your Kalani and how
about my existing pool of resource how
am I going to train them on a big data
project now these are the kind of
critical question that the business need
to address and one of the solution is
talent public data now high-rise job
trend in the data scientist data
analysis talent also comes with basic di
transformation which complements this
area and reduces your dependency on the
simple Excel index for PA to Gartner is
telling is the best technology in the
market for data integration in big data
now these three major players in the Big
Data industry Hortonworks cloud around
mapper have already tied up with talent
for Big Data solution and now mostly any
level of person in the industry can
quickly get started on this without much
political T's as I was saying the mid
I don't know Java programming how this
goes help me learn and Excel in Big Data
the biggest advantage that you get with
talent OB is there is no prerequisite
ease trust me to learn this concern
whether you know whether you come with
prior knowledge of Hadoop or not it
really doesn't matter you can be a big
data experts and up and running with the
data integration environment in minutes
guys
this course has some or other thing best
things to offer each and every one well
that's it big data in ten minutes that
what a big that for the talent claims go
from zero to pro in Big Data just under
10 minutes you can be on hand coding the
talent for Big Data sandbox is ready to
run the virtual environment which we
will see in minutes that includes the
talent platform for Big Data this is at
the popular distribution as you see on
the crown top of the crown they have
cloud era hot invokes they have map are
they also have a part say hadoo
as I said anyone who can use talent for
Big Data starting from the fresher the
fresh graduates in IT industry
consulting starting from professional
starting from developers that the
managers anyone can get started on this
obviously I am having experience on 10
years I'm a manager I how do I start
with Big Data
it really doesn't allow me to
flexibility of now start lining the
programming of the MapReduce programming
now so what should I do
cope Italian for Big Data
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>