<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Talend Interview Questions and Answers | Talend Online Training | Talend Tutorial | Edureka | Coder Coacher - Coaching Coders</title><meta content="Talend Interview Questions and Answers | Talend Online Training | Talend Tutorial | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Talend Interview Questions and Answers | Talend Online Training | Talend Tutorial | Edureka</b></h2><h5 class="post__date">2018-04-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/whM2Ffs2I50" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone welcome you today's class
that is talent interview questions so
what are you trying to do in this class
is to give you an insight on harvest
talent doing in market and we will get
you through some general questions like
we have got a lot of feedback from most
of our followers to provide you a video
tutorial for interview questions so in
that way or in the second part of this
video we'll be dealing with the general
questions and then slowly I'll take you
to data integration simple questions and
then complex questions and once you are
comfortable in that we try to understand
I'll also give you the understanding a
backgrounder of that question so that we
can you know it resides in your mind for
a longer time so you have the answer
with reason and then we want to be data
questions and our interesting part here
is I'm just trying to get somebody like
one of the attendees so I'll involve
them surprisingly and let's see how they
react like how you people will go
without any preparation to interview how
will be your thought process how can you
manage that situation even that we are
trying to do am walk in this video hope
it will be your interesting let's get
into that so let us first understand how
is talent doing in market so most of you
before you're changing your domain or
your no line of learning in career you
would like to understand how it is doing
in market right now and how far it can
travel that will be your first question
in the mind so we thought we will give
you an answer for that here so talent is
a software integration vendor and has a
market share about 19.3% right so the
company provides a soft way and it
provides services for I know whatever
you name like the data cloud storage
Tirra integration MDM there is a term
management master data management data
quality and they'll come up with very
new innovation like you know trying to
avoid or winners coming from the source
itself or the harbor tool called data
preparation and they have and praise
application to
so a number of short phase has been
provided by Tallinn window so she can
observe in the slide so talent data
integration has a greater share and no
talent you know ninety one to six
percent over there an overall data
integrator that is Oracle di so that is
having around a nine point eight four
percent and Golden Gate again from
Oracle it's holding around or 8.5 an
percent and IBM InfoSphere and data
stage that is you know reader stage
software is holding a seven point nine
month and most of the projects you know
if you are in already in the ETL feel
you would have observed a great number
of increase in detail projects its
migration projects so just want
informatica to talent in uh stage to
talent like that would have observed are
many projects coming in so that's how it
is growing in market so overall from
this slide what we can understand is
talent is growing and it is holding the
market position in very good position
and then it is improving right so hope
this clears your doubt about how is it
doing in market and then the next
question will be like how many companies
are using this and how is the strain in
which all domains they are using so of
course it's an ETL tool that's why the
major share is on computer software
companies that is you know close two
thousand three hundred odd companies are
already using it in computer software
section and the information technology
you know close to 1000 that is nine
fifty eight in the staffing and
equipment close to 300 likewise for all
other domains it's it's doing good and
it is growing so wherever you are in
whichever domain your talent is entering
over there and it is gonna grow right so
this is current talent in market with
respect to the distribution of companies
okay so once you know it has entered all
the domains and your talent can do
better in data management in all the
domains so what is the talent job trend
so these are all you know you can see
the source is from you know IT jobs
watch dot Co so from 2009 Dill's
it's growing and you can see some you
know ups and downs here also but it's
always been early growth and they are
good you know whichever quarter you go
on you will always be having a vacancy
for talent and salary has been you know
or whenever there is a good tool coming
up a new tool coming up we'll find some
ups and downs over here but then overall
as a talent Salatin it is growing and it
is a very good rate okay so this is
about your job vacancy and you know the
salary trend so having this background
like over are looking to change your
domain or you know line of learning to
talent and most of you are trying to
find job and then learn over it by
having a training right so most of you
already seen the previous videos I have
received comments like when they have
joined the you know training when Iced
see the comments like seeing the videos
or they have joined the training we just
finished one of the training branch and
they were all of them were able to
answer close to 80% to 90% of all these
questions so it is also you know getting
to the talent interview question that is
multiple choice questions I will tell
you what are the different kinds of
questions we are dealing with today
so first we'll go with multiple choice
questions which is very important for
getting talent certification and then
what are the general interview questions
which or topics they'll be asking you
more questions on which are the hot
components they'll be looking for deep
understanding all this stuff and then
mass filter data integration where our
questions will come up and then specific
to Big Data where all questions can come
up right so let us first start with
multiple choice questions so before I go
on shooting the questions let me try to
get in one of the attendee so who can I
interact with asking questions and I'll
just tell her to join let's see how does
she react or let us ask fuse equations
for us let us settle down and let's see
how her thought process will be okay so
let me add her okay I'm adding oh hi
swathi
hi Jessie B yeah hi sweetie how are you
doing yeah I'm fine thank you
so I just still wanted you to I know he
added you to this webinar for a small
help would you be able to do me that
favor yeah sure yeah right well I know
it's just a matter of two or three weeks
maybe we are not prepared but I just
wanted to answer few of the questions
which I have made for evaluate you or
all the people who are there in the
training okay so will that be fine
will you try to answer try my level best
to answer these questions yeah that's
the spirit I thought you'll be scare or
something like that but then good okay
so maybe able to see my screen I have
just shared with you as well yeah okay
so here you go so first question pretty
simple so that you can calm down and you
think that the open mind or calm mind
right so in Tallinn stood you where you
find the components needed to create a
job so the options for you are whether
it's in repository or whether you can
find your components in run view or in
designer workspace or in palette I think
the answer is pretty much simple I'll go
with the palette because once we
activate our job we can find all our
components in the palette okay so is
there any other ways you can get the
components into workspace either we can
just type in our workspace the name of
the component or either we can
drag-and-drop from the palette yeah then
don't you think even designer workspaces
answer yeah that's also correct but
generally all the components are listed
down in the ballot so I think yeah
that's very good of coming to you know
you got to a conclusion because your
question is where do you find the
components so this specific place where
do you find that is palette that's what
you are trying to tell right yeah okay
let's even it's right or wrong yes it is
palette so good Swati okay so good that
was pretty simple as I said so let's
move on let's increase the complexity in
the component view way can you change
the name of the component though the
question you know it sounds simple
sometimes we don't remember exactly
which tab or which option does we have
to use for that
so what do you know this so where do you
change the name of the component whether
it's in basic setting Advanced Settings
documentation tab or View tab I think
it's the View tab when we go and when we
click on the component and go to the
View tab and there we can find the
option to change the name I remember
this telling you in the class oh and
that's great
so you have remove that because usually
I make it a point because usually we go
double click on the name and we change
it in the designer itself will never
come to the component and go to the
exact place where it we have to change
that so most of us will not remember
this but then you have paid attention in
the class and you remember it so let us
see whether your answer is right or
wrong so this is right so it's the
buta where we have to go and chain the
component name right
so this also was quite simple but then
only if you had paid attention it's good
swati so let's move on to the next
question so this is something to have
three FS okay so has TFS components can
only be used with big data batch or big
data streaming jobs whether it's true or
false can read it once more their safest
components okay whether they can be only
used with big data batch or data
streaming I think that's true okay so of
course for Big Data components we have
downloaded the different software and
only there that is the data version and
then only there we can find these
components right yeah so in that way is
that your thought process or why did you
come to a conclusion whether it is true
I think HDFS is a technology which may
use for Big Data so I think it's true
okay so with that present let us see
what is the answer
oops you lost this time so I'll tell you
why is it false okay see whenever you
develop ETL job it's just that we're
using that components ok so even my
intention is not for big data batch or
streaming jobs if I'm not giving those
configurations or it is not intended for
that use even then the components are
available even then I can read or write
from HDFS components right
so you're getting the point over there
so you take the big data input component
you read the data and you just print it
okay that job may not be the data batch
or may not be the streaming job but
still it works right yeah that's why
this was so we can use it for all
purposes not only for the batch or
streaming purpose okay so remember this
one so now view when you answer
something wrong and you call that answer
the reason for the answer you remember
it for more time right yeah okay that's
more let's me little bit faster now or
not so the next question is in which
respective of talents to do so most of
us will not know where the respective
option is available in talent and
analysis on high table contact can be
executed so there are different drop
respective right yeah you got it yeah I
think this is profiling because like
within that perspective we can easily
analyze the high tables exactly yeah I
remember
so in the class we were you know try to
show that right for the component design
we have a different perspective for you
know for profiling we have different
prospective and where we create the jobs
or integration perspective which is the
second option so where we create the
jobs is in the integration perspective
but then the question was on the
analysis of it which you troll profiling
let's say whether it is right or wrong
so at least right good tought processing
the right answer so let's go on so what
doesn't a stick mark next to the job
name signify in the design workspace so
you'll have that star symbol right
whenever you're working on it so for
what reason it does pop up so whether
it's an active job whether job contains
unsaved changes or the job is currently
running or the job contains errors this
is option B the job contains unseen
changes when we whenever which make the
changes in our job at that time that a
strike appears if in case we don't save
it before execution yeah that's the
right answer in the reason also is the
right so let's see for just for
confirmation purpose yes it is the right
answer so obviously an active job
doesn't have any a stick mark and
whenever it is running the job window
shows the logs and it does not
reflect anything in the repository
window and any errors would show up in
the designer or in the log window so the
right answer will be the unsaved changes
good
that's one so a little bit of complexity
increase now suppose you have designed a
big data batch using MapReduce framework
so we have done this right the last part
of our training so now we want to
execute it on the cluster using
MapReduce
so which configurations are mandatory in
the Hadoop configuration tab of the run
view so maybe you would have you're
visualizing it right whenever you are
designing what all options will you give
so in Big Data section so what are the
options are mandatory is what I'm asking
so your options are name node data node
resource manager and your taco I think
among all these name node is the like
mandatory one I'm a little bit confused
about job tracker but I think I will go
with the name node okay so yeah fine so
you are giving me the final answer so
let us see whether it is right or wrong
and then I will give you an explanation
of it okay so name node and job tracker
so I understand maybe we were in the you
know understanding that you have to give
me only violence or out of this for
maybe we would have asked me but then
it's quite tricky one this is how you
know even in your certification
examination there'll be few questions
like this where the answer will be more
than one so if you remember our name
node is the mandatory one of course we
have repeated many times the class but
then in the HDFS batch thing whenever we
are you know if you're having different
nose and all the stuff obviously one
more mandatory option or attribute we
used to fill in is the job tracker right
so these two other mandatory things yeah
okay maybe we are you go back and check
right yeah I mean okay so now you know
the name Lord and your record both are
mandatory right okay that's more so how
to find configuration error message for
a component so whether you right click
on some component and tell show problems
you just hover over
the error symbol in the design of you or
you open the error view or you open the
job CEO I think this one is also like we
can just go and hover over that
exclamation mark and it will show us in
the design view itself so I think B is
the correct option
yeah so of course you have eliminated
all other options and you know that
whenever you however that symbol you are
able to see that error message so let us
see this is the right answer good one so
let's move on what is the process of
joining two input columns okay pay
attention like two input columns inside
the team app I am talking about so in
the team of configuration window once
you double click and go inside right and
there you want to join two input columns
in that case what is your actions or
steps whether will you drag a column
from the main input table to a column in
another input table or you right-click
on one column in the input table and
select join or you select two columns in
the two distinct input tables right
click and then select join or selecting
two columns in two distinct input tables
dragging them to the output table I
think option a option evil with our
correct answer like once we are inside
the configuration window then from the
input tables we have to drag the columns
and then drop it in the output table so
I think is the correct answer
okay that's good let's check whether it
is right or wrong and you are right as
usual yeah every time we drag the column
to the other output section so that's
the right answer so let's move on for
the next question so to import a file
from FTP which of the following are
mandatory components whether it is the
FTP connection and TFTP put the FTP
connection the FTP file list and then
they FTP get T FTP connection and TFTP
get T FTP connection TFTP exists and TF
difficut may be here also you might have
any bit of confusion so go through each
of the options and which is the nearest
match for the question you can tell me
okay
first component we need is DFT
the connection okay that is a mandatory
thing apart from that we can't like say
establish the connection yeah I mean
once we have established the connection
we need to fetch a file so for pitching
the file we need it so first is anyways
it's not the option second okay I mean
if we are talking about mandatory things
then I don't think the file list is
necessary right and T file exists is
used to check like whether a file is
exists or not so I think the FTP
connection and TFTP get will be the
mandatory one again we know the name of
the file that's great so that's that's
obviously it will be the right answer
but then I'll ask you another question
so if you go by suppose if I say using
these components if you develop a job
and you never want that job to fail if
that is your question will you change
your options now
like this yeah suppose you have the
connection you have to get it will be
executed properly I agree so if that
file which you're looking for it's not
available so then it would fail right
for the one with your children so if you
want to develop a job which will never
fail for all any condition out of this
options which one would you choose
I think then we can go with the fourth
option like first we will check whether
that file exists or not and if it exists
then we will go and fetch it so what
that scenario I think option B will be
correct
that's of it so let's come back to go a
question which we were having previously
and you have answer it as option three
and that is perfectly right and for the
second question also whatever your
answer is right that's really good so
let's move on to the tenth question
so suppose you have three jobs okay
now again your complicity is increasing
so till now we have done really good so
if you are having three jobs one and two
the first and second jobs are perrolli
executed and then the job three should
execute once job one and two has
finished their execution okay which of
the following components are used to set
up this flow right quite simple one and
two
I want it in parallel once they have
completed I want to start job number
three so whose t unite T post job t run
job or T parallel ok so for the first
part of the quotient is like to execute
the jobs finally I think T paralyzed
component will be used and then after
that once we finish our execution of
first and second after that I think
either P run job or people shop I am
confused between these two options so I
think I will go with T run job be
paralyzed and Piron job should be the
answers okay according to your thought
process yes you are I've got two options
now right T paralyzed and tieran job
right yeah okay let's see so the answer
is T paralyzed and tipos job but then
whatever answer you gave is also not
wrong but then there will be some
questions like this in even in your
certification program but then I know
one or two combinations also is correct
but then why we have to choose this T
paralyzed and deep was job for this
question is so if you observe the
question
I'm not telling that you have to you
know go to another job and execute it
right when two jobs are executed
parallel even with on sub job okay for
this third job will give me the solution
for the question but then if I use T
paralyzed for the first two job and by
using just T post job without any
connection but if you use T run job you
need a connection for that right to
control the flow otherwise all three
will run in parallel you getting the
point
yeah yes Wow without having that
connection if you want to control the
flow deeper liz is anyhow you know or it
is taking care of Java and job too and
post job will wait till the paralyzation
two jobs is executed so in that way we
can give the solution for this using T
post job right
it was quite tricky yeah yeah just have
to give a different thought process to
understand this
yeah and again we have put a known over
there that T paralyzed component is only
available in der Enterprise version so
these things yeah we always discuss in
our
class like what is available in open
sores and how we can achieve burst all
the stuff hope you remember all those
things right okay we'll move on so the
eleventh question for a T file input D
limited component what is the default
will separator so whether it is
semicolon pipe comma or a colon I think
this is comma whenever we used to forget
specifying the separator in the output
where it will generally give me the
comma so gamma is the right answer is
option C okay so it is the right answer
on again it was quite straightforward so
that's the more - next question
so while saving the changes to T map
configurations so this one in many of
the examples we have seen so whenever we
change okay anything sometimes Thailand
ask you for confirmation to propagate
the changes in T map right so every time
you change the structure of a source
which is connected or in the target if
you are adding a new column or something
like that
it will ask you for this you remember
right do you want to real you know
propagate the changes so why does it
happen what is the exact reason because
it will not pop up that for everything
every any changes we do it into a map so
what is it specific chain which will pop
up this message so the first option is
because your changes affect the output
schema and the source component should
have matching schema so second one is
because your changes affect the output
schema and the target component should
have the matching schema third one is
because your changes affect an input
schema and the related source component
should have matching scheme and the last
one is because your changes have not had
been saved okay fourth option is not
valid then now coming to false because
changes affect the output scheme and
doesn't okay no not this not I think B
we yeah because whenever we change the
masking offer input data reflected in
our output then only we propagate the
thing this exactly C team up itself like
we joined two sources which are
different you know structure and we take
up
few columns from a source one few
columns from force so as to and we
create a different schema so source will
never affect that process only the
output schema in the T map and the
target schema only those matters and
that is what you have answered as well
so that's the right answer
so because your changes affect the
output schema and the target component
should be in the matching schema right
cantatas so the next question is in
talent how do you add a shape into a
business model so we have covered most
of the cases in repository pallet and
designer and now we are coming to
business model so do you remember those
so how do you do that so click and place
it from the palette drag it from the
repository click and quick access
toolbar drag and drop it from the pallet
I think this is option for drag and drop
it from the pallet we are similar to the
components how we used to do with the
company exactly so that's why you know
talent is very user friendly whatever
you take away their business model
repository or the way of executing it
will be similar or very easy so that's
the option drag and drop it from the
pallet so let's move on to next question
how do you create a role link between
two components so most of us would you
know let's go into the options then
you'll understand there are you know our
misconceptions so first one is drag and
drag the target component onto the
source component right click the source
component and then click on the target
component drag and drag the source
component on to the target component and
then right-click the source component
click the row followed by the row type
and then the target component yeah so
drag the first option is not correct
second one is also not correct third one
is also I think both one go right when
we right click we get the options row
trigger and on component ok and all and
then after that we go for the mean and I
we take it to the target component yeah
so the fourth option will be the correct
one perfect because your question was
very clear that roll link so I was
stressing on the different row types and
trigger types right so the question was
only related to the road
that's where the last option where they
have described more about the steps in
the row is the right one that is what
you're thinking and that is the right
answer
good one that's so talent openstudio
generates the job documentation this is
one of the unique feature in talent so
job documentation we had discussed this
I hope you give the right answer which
format does it generate the job
documentation whether it is HTML whether
it's text whether it is CSV or XML I
know this answer this is HTML yes yeah
I'm pretty much sure because inaudible
there is an option to like regenerate
the HTML documentation option it still
says generate the HTML document that is
that's why we remember and most of us
get confused like all the underlaying
storage of the talent is in XML format
but then this is a specific option of
documentation which generates in HTML so
your answer is right it is HTML so what
the next question is can we directly
change the generated code in talent true
or false I think we can change the code
because you have written some routines
and all right in the classes we were
returning the values and used to go
change the code or add something in that
code right yeah but then can you read
the question again and think whether
your whatever your thought process is
right or wrong so the question is can
you directly change the generated code
in the talent okay okay then it's false
maybe yeah because the customized code
big that we changed related code that
talent generates by default it can't
change that yeah yeah the first thing
which comes to our mind when this
question is asked in interviews yes I do
write code and I embedded that code in
the talent and I have changed it many
times so will be in that thought process
but then the question is the are in the
designer window when we have the
designer window in the code window
whenever we get the error we go into
code window and we see that right where
exactly there that is so can be edit
that code is the question so obviously
you have you know yes initially you
thought in a different way but then
later you realized it so you are giving
the answer as false and that
right so whatever talent generates after
our you know creation of the designing
of ETL that we cannot edit good question
so this is also quite confusing and also
simple for few of you who know it so
what is the default date pattern in
talent open study okay Thailand Open
Studios generally follows the most
regular format that is VB mm bye-bye so
I will go with this because we have
solved many questions based on yeah
exactly
so the option to DD mm why why is the
right answer
good ones will more so MD M stands for
what metadata management mobile device
management master data management or
mock data management its master data
management obviously so another product
of Thailand which we'll discuss in the
very first class Sam diem starts for
master data management it's the right
hand so good one so in order to
encapsulate and pass the collected log
data to talk button so this was one
where we discussed a lot in error
handling classes so I hope you remember
this so tell me which are the components
that must be used along with tilaka sure
whether it is t1 whether it is T die T
start capture or T assert catch off okay
to encapsulate and pass the collective
log I think p1 is necessary thought I
think but when we use T die I think he
doesn't like make the job exit so I
think only t1 is required and P that
katsudon is it capture is no these are
you knows what different purposes I
think p1 t1 is necessary so t1 I think
option a is the correct answer
okay let's see that so the answer is t1
and also T die but whatever you said is
absolutely right T die will make your
job exit or it will abort your job but
then the steps how to die works is
whenever you have a or component error
and you connect it to T die there also
you are giving some message right like
invalidate I
encounter or something like that or file
not exist whichever you require so even
after receiving that feed I will make
sure whether the Tila culture has
captured the message thrown by T die
once it is sure that T log catcher has
caught the message then only it will
abort the job so a both t1 and T die
will make sure that the logs has been
captured by Telecaster and then they
will do their action so both of them are
doing that encapsulation passing the
collected log data to the question which
is asked both of them satisfies the I no
need for this okay so this is how the
dye works so whatever you said is
correct but then you should understand
the detail how it will work so first
step it will give the locks make sure it
is caught and then it will abort it okay
so which component used to read data
line by line from an input flow and
store the data entries into the
iterative global variables I think this
one is quite simple for you whether it
is T I trade to flow T file list T flow
to a trait T low it's a little bit
confusing between P I trade to flow and
P flow to hydrate but I think I will go
with option C T flow to I tree yes
question if you can see the read data
line by line is there so your input
should be line by line right so yeah we
trained exactly so let's see whether it
is right or wrong
yes it is the right option good run so
this is how we you know a think and
eliminate the other options or to get
them know whether did would that work or
in the question itself will have cement
for the answer right so let's move so T
memorize rules belong to which component
family in talent so this is one of the
you know most difficult questions in
certification we won't actually remember
where exactly they belong to so let's
see whether you remember so T memorize
rows belongs to miscellaneous
orchestration and tune it or file
I'm confused between option en option B
so file it is not related to price it's
not related to Internet obviously it
should be the first and second one yeah
but again when we tried to eliminate
orchestration is something which we use
for the processing of data reputation
and all those work so I think
miscellaneous will be the right option
okay let us think I'll go with option
mean it is a right answer it comes and
Amazon isn't very good way of
eliminating the other options good one
so let's move on so - is a powerful
input component which holds the ability
to replace a number of other components
of the file family it's only related to
the file family right the first one
first option is the T file input n di F
T file input regular expression T file
input Excel T file input J saw okay
so X 0 is used for CSV annex in sheets
this one is used for the JSON file in DI
F and read six regular expressions and
really I think LD is will be the answer
okay so let's see what is the answer so
it is T file input regular expression
I'll tell you why and your thought
process of NDF maybe would have thought
okay L di F will help me in replacing
the other components in the file family
but then in T file input regular
expression we can read this stream we
can only extract
I know match your string in the regular
expression so it does multiple options
and multiple features are available in
that so that's how it will you know it
is able to replace a number of other
components in the file family so the
close match was you can input regular
expression right so let's go to the next
question which component do you need in
order to prevent an unwanted commit in
my SQL database so this is quite simple
I believe so
the options are MySQL rollback MySQL
commit MySQL lookup input by a skilled
row yeah actually answer is pretty much
simple so option a will be the answer so
in order to like undo some we use my
sequel rollback component so option is
the correct answer
exactly so that's the right answer it's
my skin roll back so another question
related to database a database
connection defined in repository okay
the metadata which can be reused in any
job within the project true or false
yeah it's true like whatever we have
stored in a repository we can use it
throughout our project any job or any
sub job anything can use that particular
whatever it is stored in the repository
that's right so it's a right answer
that's why we call it metadata right
across project we can use that
connection so let's do something with
bacon so the question is using which
component you can integrate personalized
code like routines so personalized code
written in pig in the talent program
whether you can use it you know by using
TP cross keeping map T Pig distant TP
code from the quotient itself yeah so
because all other options are I know
itself is telling what is the
functionality of it so DP code is the
right answer so that's how the
components are named in talent it is
psychologically designed so whatever
function you want you can just type in
that function in balint you get a
component for that so that is one other
another a user-friendly a feature of
talent so next question is on Kafka so T
calf:cow put component receives message
serialized into which data type we have
done this right so we make sure before
going into the output we do some step
right so whether it is a byte or byte
array string array or integer it's
option B byte array so that's the
speciality of Kafka perfect so we know a
particularly take a Java component and
whatever we want to put it into Kafka we
build an array of it byte array of it
right so we'll step everybody remembers
that so that's right forward answer and
it is right so the next question is
which of the two component families do
HDFS properties component belong to so
now this is a tricky question so they
fall into more than
bucket so which are those 40 hash tables
properties whether it is Big Data
and miscellaneous orchestration and big
data file and big data big data internet
okay for HDFS of big data is mandatory
so big it is there and also options yeah
so miscellaneous no miscellaneous one
with option because we are talking about
properties maybe and again it's very in
the question if you expand HDFS you will
get the answer distributed file system
file system yeah correct so that's why I
will go with option C file and big data
love it so that's why you know they are
very slight probably given it has the
HDFS properties so sometimes we will not
think in that verge of answering the
question that HDFS is nothing but Hadoop
distribution file systems obviously
should fall under final category as I
yeah so it is file and big data so we'll
have to be calm read the question and
get understanding of it yeah that's
what's right answer questions like which
component families they belong to oh
that's right so that's one so -
component that's which component is used
to read data from cache a memory for
high speed data access we have used a
number of jobs so I should be able to
answer this P has input T file input LD
I of T has staff as input T file input
examine okay I know the answer this is
the hash input because we have already
performed this in our class so I
remember doing these exactly so hash
input is they read the data and they
keep it in ROM memory and where we have
defined in that it will create a hash
map file binary file and it will refer
from that so that will be very fast and
that's the answer you are given and
which is right so good once a less small
which using which component you can
calculate the processing time okay how
much time it took so processing time of
one or more sub shops so please
understand so using which component you
can calculate the processing
time of one or more sub shops not jobs
inside a main job so which one will be
able to do that so whether it is t
flowmeter t chronometer start t flow
meter catcher T starts culture ok flow
meter and flow meter captures are not
options and I'm like pretty much sure
about that but I'm confused about the
chronometer start and P star catcher
generally we use these Starcatcher only
okay I will go with option B or B star
catcher okay yeah let me check whether
it's right or wrong it is not it is T
chronometer stat and you were answer was
absolutely right if I had asked you what
is the time taken by the full job that
is main job that's why the question it
is very clear that it is one or more
subjects inside the main job right so if
I have three separate jobs in my I mean
not separate jobs are such tearin' job
but then three different on sub job okay
on sub job okay and I have that three
flows then each flow how many how much
time did it took so in that way actually
we cannot only say by using t
chronometer stat actually on each sub
job start and yin we should also have T
chronometer stopped also right that's
why they are confusing you since there
was no chronometer stopped in the option
you might have thought that there is
only start there is no stop then how
will you calculate the time taken by the
sub job so your answer was logically
correct but then with the available
options for one or more subs or D
chronometer start is the nearest match
right yeah okay so that's more the unite
component belongs to which of the two
families again you got the family
question so whether it is file and
processing miscellaneous and messaging
orchestration and messaging
orchestration and processing okay P
unite processing yeah it belongs to
processing I'm very much sure about this
and another one should be right I think
option
maybe because hi-yah I think or case
it's not it doesn't belongs to messaging
so second and third are like pretty much
out and it doesn't belong to fight yeah
it doesn't belongs to fight so I think
option B D is the correct orchestration
and processing process and it's the
right answer get so that's more so using
T Java flex how many parts of Java code
can be added in the job so one two three
or four I think three
yeah exactly it's doing when we compare
teach our teach our vantage our flex in
the Flex we have three different parts
of the Java start mean and final these
three are the one which we have to give
it in D Java flex so obviously that's
the right answer
so that's more yes that was really great
us what the interacting with you for a
surprising walk interview and according
to me are you almost answered 85% of the
questions so obviously even now if we
give the certification exam I think you
will score more than required a passing
percentage as well and you will really
come out with flying colors thank you
increase and I am planning to prepare
more and appear for the examination yes
surely and that's why we provide you the
you know a lifetime access for all the
videos so go through whenever you are
feeling you're out of touch and whenever
you go through that you will again
pressure all the things all the
complexes which you have done and these
confusions what was created in few of
the questions you can get clarity of
that in our class videos as well so I
can go through that and you prepare for
the certification exam I surely do that
okay thanks a lot for joining for
multiple-choice questions
Oh mock for us in this video thanks a
lot thank you for giving me this
abortion be and clearing many of my
doubts thank you that's okay thanks a
lot
Wow goodbye so now let's start with
general interview questions which will
be you know frequently asked in
interviews we have try to collect most
of the important questions and we have
put down
you so let's go on with general
interview questions and try to answer
them so the question is what are the
various software and services provided
by talent so here basically what they
want to understand us what other are
different products are search which are
coming out from you know talent as a
vendor so what are those a different
sort ways which are available which are
the areas like whether it can be big
data or data integration data management
cloud storage they have an MDM master
data management they also deal with data
quality and recently they have come up
with data preparations to avoid you know
are there as coming up in the source
itself and then all enterprise
applications they are available in both
open source and Enterprise version so
whenever they ask you or they usually
expect whether you are only
concentrating on data integration from
Tallinn or you also spread your
knowledge across so all the products
which are provided by Thailand so how
they are used they are also quite common
and user-friendly in usage wise only
you'll have to learn the different
components available in their different
products and you can explore them so
basically with this question an
interviewer will expect you to list down
or tell them which these are all
available and at least a big picture of
it what that product does or what is the
unique feature about it or how does it
help to solve the problems in today's
data integration world so answer would
be the company provides various
integration software and services for
all these you know services like Big
Data cloud storage as I mentioned data
integration data management MDM and data
quality and also enterprise data
preparation right so go through in
Thailand comm will have you know
products page we can go through and read
about all the products download them try
to do a you know hello world program or
something as a simple program and then
you will be very confident to answer
like how does it look or white issues
and what are the component names you'll
be able to answer it right so this is
all about your various software which
are
provided by talent let's move on to next
question so why Thailand Open Studios
like different talent opens Tilia for
data integration talent open studio for
big data
why are those open studios that is
freeware why is it so popular
what is the reason so you can just think
of like if you are already using you
know a few of the features which are you
know very what is a very popular and
which has made their products a big hit
one is it is very user friendly that is
everyone knows about it and then the
features about it like you know it is
upon Java integratable like if you are
not able to do anything very you know
are not available in ETL say for example
binary conversion or mainframe data
frames you know mainframes data type
conversions this need Java code to be
integrated so it is upon Eclipse so that
is one of the major feature of talent
where you can integrate your I know
routines external routines and you can
plug and play with talent components
that is one thing and then so what does
it does like it will generate the core
and transform it to Java jar right and
also it is you know platform independent
so one download and you get all the
binaries whether you can execute it in
Windows Linux or Mac OS doesn't matter
so again when it is Java it is platform
independent and of course it is very
user friendly and the design is and no
installation configurations heavy steps
are not available they are very simple
just go download and set your Java paths
and get started with your ETL work so
such simple things so you can put on all
these whatever you feel it is you know
very useful or which is the good feature
learning curve is very you know very
easy already so there goes an open
source project that is based on Eclipse
CP suppose detail-oriented
implementations acts as a code generator
you know and the underlying programs are
in Java and it is user friendly GA so
these are the major thing not only this
but then there are many other you know
features which has made it so popular
but that is too technical but then
whenever there is an you know big
picture questions like this you can
tell Watauga sir I know stand out of the
crowd features like so these are the
very unique features in talent so that's
all about your why it is so popular the
reasons for it you can quote these
reasons so moving on to next question
why should one use talent instead of any
other tool available in market so this
kind of you know they are just
indirectly asking you or you tell me
which other tools which are doing good
in market and compare them with talent
and tell me what is that good in talent
and which is not available in other
tools different categories which all
categories what are all the good
features for example as we saw in the
previous slide it is user friendly so
you know development and deployment
everything is very easy in Talon so the
anybody can learn and do it very quickly
and one more thing is its uniform
platform like I told you routines can be
you know integrated and you can call an
SQL dot in easily design is very simple
and then less expense majorly like
whenever you are raw most of the
company's whenever you want to do a POC
or something like that you can use the
open source and then compared to other
big leasing market talent Enterprise
version cost is really less so you can
just code that also though it is not a
technical point this very important
point for us to understand you know what
is the cost and what is the users how
many users per one license all those
stuff right and it is future-proof like
it is Java based and you are all
metadata's are stored in XML formats in
your whatever changes you want to do is
very easy and also it is which are proof
and you know a huge community exists for
talent maybe you would have already
experienced it so any question you want
to get to know do we are wanting
enterprise version or you are just using
the open source the community helps you
the response time is very quick so all
these things matters for you know
suggesting it will for client so here
comes the answer like faster development
and deployment you're going to find a
platform as I said and Lex expense
because the license cost is less
maintainability is less future proof and
huge community right so you can quote
all this
for why we have to use talent instead of
any other tool in the market and now
comes you know or two level questions so
they won't understand the dough you have
worked a lot in talent we will not focus
much on what is the window name or what
option does it provide what is the
hierarchy which is the highest hierarchy
all the stuff we will give very less
importance but then in certification
exams or in project sometimes they would
ask these questions to understand how
deep knowledge you have in talent so
what this project according to a talent
basically it is the highest hierarchy in
the talent like you should first create
a project and enter into or talent down
any of the talent product right so
project is the entry point so it is the
highest hierarchy and then in project we
can have you know business models jobs
metadata context variables you know
routines all those stuffs are I know
stored under this bundle so project has
all the jobs and all the metadata is
related to job so it is the highest
hierarchy so that would be the best and
try for answer for this so project is
the highest physical structure that that
can be more technical and then bundles
up and stores all types of you know
business model jobs metadata retains
context variables and all other features
which are available so most of us will
not be able to answer this rightly so
make sure all the windows all the
features and hierarchies are known to
you okay so let's move on so what do you
understand by job design in talent so
you have a designer window like these
are the few questions in certification
exam which will be you'll feel like
though you are working on talent for
years together you will not be able to
decide among two options which are very
close you know very similar or something
like that so basically job is a
executable unit right which is anything
built using the components all those
stuff so it is technically what to say
like it is single a java file which will
be you know compiled and given to you as
a java file so it implements the
dataflow like business into code
routines program all those stuff so
designer window is where you can drag
and drop the components give solution to
your requirements and once you have
dragon
dropping the component back-end Java
code will be generated and ultimately
when you are done with your job when you
compile it generates a executable code
so all these things happens in the
designer window so that is where they
ask you know a different way like what
do you mean by job design all this stuff
so basically job is you know executable
unit and you are technically it's a
single Java class like it compiles and
it gives you an executable jar when you
build a job right so that one and it
implements a data flow by translating
the business needs into code routines
and programs so need not me you know
it's not like you have to exactly quote
this answers the basic understanding of
it and how the question can be asked and
what the question actually points to
when they say job design we should speak
about all these things so that's what we
wanted to let you know so let's move on
so what is a component again we all know
you know one component you know performs
a piece of function or something like
that
and where we can find the components all
the components will be listed in palette
and whenever we drag-and-drop the
component it is nothing but a piece of
code which is related to that component
it gets added to my design so that is
the one thing basically it does one
simple job say for example if you take T
file input delimited as a component when
you drag and drop all the code which is
you know needed to read the file you
know what is the delimiter what is the
you know separator what is the file name
what is the stream all those stuffs will
be a parameter kind of things so it will
replace those parameters and it will
execute the Java code which is written
for you know reading your file so
basically some functional piece which is
used for you know performing single
operation in Tallin so it is available
in palette and you can simply drag and
drop them at the back end it is a part
of the core and Java cores are
automatically compiled by a talent when
job is saved so basically first thing
you have to do is it's a particular
function code which we have using as a
GUI so we just give the parameters and
we execute the job so that is component
in talent so let's small so explain
various types of connections in talent
so we'll have I know whenever we
right-click on
any of the component will have row and
trigger in the you know first options
and then will have different types like
iterate link all the stuff right so
basically in row we have main lookup
filter result output you know unique
whenever we take unique components will
have unique r1 to placate row and when
it comes to trigger will have on sub job
okie on sub job error and run if on
component okay on component error
although so when it comes to e LT
components will have a link will not
have the rows will have the link and I
trait Dwight right on the data set so
all these things are the connections is
not like we'll have to answer about
database connections or file connections
nothing like that
it is connection which is associated
with the talent options so corrections
and talent define whether the data has
to be processed at output or logical
sequence of a job the where we control
the data flow right so as I mentioned
row I trade trigger and link and options
related to that like main look of filter
error rejects output unique duplicates
and on sub job okay on sub job error on
component okay on component edit so all
these things you can mention it as types
of connections and very it you know
which components like if you take define
list only I trait will be available if
it a file input delimited all three will
be available like main iterate and
reject so you can code these examples
like which component will have which
connections in specific they will get to
know you have more knowledge on
components right so they'll understand
okay has worked with all the components
he knows for which component what all
row types will come or you know how it
is working that will be understood right
so let's move to next question so quite
common question differentiate between on
component okay and on sub job okay so
basically you all know like after
completing
you know or one specific we gotta know
what is component so component does one
piece of work or one functionality if
that functionality is successful then it
gives you the flow which is connected to
the okay and if you are connecting
multiple components are non component
okay and the parent component will have
on sub job okay and on sub job error so
if all the components are executed
successfully which are connected with on
component okay then it's like an
condition for all the three components
so let's see what are the technical
difference so belongs to component
triggers and belongs a sub G optical so
you know it's basically the technical
differentiations the linkage sub job
starts executing only when the previous
component successfully finishes and the
linkage sub job starts executing only
when the previous sub job is completed
successfully so on sub jobs okay I would
have I know from the parent sub job I
would have having I know three to four
components all those four components
should complete the execution then only
the next sub job will start so we all
know like that link can be used with any
component link can be only be used with
the first component of sub jobs so this
is what you have to you know the Third
Point is a differentiator of
understanding so we'll have to explain
like only the first component which has
been connected to the on component okay
of the three component only that will be
you know having this sub job okay and
sub job Rodriguez so this is all about
your own component okay non sub job okay
so why is talent called a code generator
so as you all know like in the first
layer also I told it is upon you know
built up one Eclipse and then whenever
you drag and drop the component it is I
know nothing but replacing the code in
the backend so that's how why it is
called talent core generator you can
quote the same reasons so talent
provides a user-friendly GA where you
can simply drag and drop and at the back
end it generates the code and that's the
main reason I know each component
present in the job is divided into three
parts you know begin main and then
whenever you drag-and-drop a component
when you go back to Code section you can
see that for each component they will
have the three sections so that's why
you know talent is called a code
generator so next question is what are
the various types of schemas are putted
in talent like it's not like a database
level Laskey mass it is like in talent
we have repository schema we have
generic schema and we have fixed schemas
the deep understanding of these topics
like the talent training provided by D
rekha will be dealing with all these
topics in detail but then since this you
know video is all about the interview
questions we'll only dealing with the
you know meaning of those schemas so
repository schema is nothing but which
you can use across the jobs in a project
so project is the highest hierarchy
right so in a project which our job you
want to refer you can refer it from the
repository schema and general schema is
not you know tied to any particular
source as it is used as a shared
resource across the multiple types and
multiple sources like same schema can be
used for a file and same can be used for
a database and fix-it schema is are they
are only read-only schemas which will be
predefined in some components like T
context load a key and value will be
always be defined you cannot change that
also and if you t log cache or T starts
capture all those will be fixed at
schema so you cannot change them right
so these are the different three schemas
and the question would be quite
confusing you will always point to the
schema software database or something
like that
it is talent specific right so exclusion
is explained routines so already we know
what is routines and why it is needed
and how it is integrated in talent so
there are nothing but reusable code like
suppose we want to you know extract you
know symbol of the currency while we
pass the three-letter code of the
currency so it can be reused anywhere in
the project or any job so we can write
that code outer and you can call that
code anytime you want so basically you
know there'll be two types of routines
one is already predefined system
routines and one is as I told you as an
example that is user-defined you will
have to write that protein so both
routines are available in talent so
routines are the reusable piece of java
code and also it can be an excuse to
pair all those stuff even those are
supported so using routines you can
write the custom code so talent support
system routines and user rotates both of
them are supported that's more so can
you define a schema at runtime in talent
so this is something something that you
know a schema you cannot define any
schema at runtime until unless it is a
dynamic schema in Enterprise version
option but then whenever these kind of
questions comes in you will have to
smartly answer like saying or speaking
about you know dynamic scheme mind
device version or you want to
answer me in a way that how can it be
achieved in open studio so that should
be your approach and schemas you know it
cannot be defined during runtime you
know the moment the data you are
defining in the job either metadata or
the manually are giving the structure
for it then will have to define it
before the tyrant job is being compiled
or run right so schema can't be defined
during runtime the schemas define the
moment of data it must be defined while
configuring the conference right whether
but dynamic schema option is available
in the Enterprise version so this is how
we can answer so most of the interview
will have this mandatory question what
is built in and what is repository so
that's more I mean you all know that
whenever I am taking it from the
metadata which is reusable
I know properties and schema so
repository are built in will have two
things basically that is one is property
type like file name rows operator and
field separator is a property of that
component whereas schema is also be
their schema can be reused with many
other components as well but file
properties cannot be reused right so it
should make these differentiations
whenever these questions are asked what
is that which is different in built-in
repository what are the properties
involved in those then you will be you
know they'll know that you know the deep
understanding of it
so stored locally inside the job is
built in and stored centrally inside the
repository is repository can be used
only by the local job can be used
globally within any job in the project
can be updated easily within the job
data is read only within a job whenever
you change it in any of the repository
thing either it will convert it into
building or it will tell change in
repository option where you will have to
change it and it will be propagated to
many other jobs based on your acceptance
so this is a difference between your
built-in and repository right so that's
more what are context variables and why
they are used in talent so as you all
know or context variables are you know
one of the feature in talent wherein you
store the temporary variables or you
store the variables in the parent job
pass it to the child job basically there
are different types of context variables
as well like most of those will not be
considered on it will have
project-level context variables which is
applicable for all the jobs that is
embedded context variables and the
second one is repository context
variables which we use inside the
repository window we create the context
variables and we use it across jobs and
we also have external context variables
where we lower from a file using t
context load right so all these things
you will have to mention most of us will
not be knowing they're embedded context
variable so user defined parameters
basically context variables you can use
these technical words so may change
their values as the job promotes from
developmental test and production if we
have such a requirement will go for
context so we can first tell what is a
need for contacts and how it can be
handled in talent just by one-click of
context group will be able to you know
deploy the job in different environments
so we have embedded context variables
repository context variables and
external context where it's so need what
is it in your meaning of it and what are
the types will be the best answer for
context variable questions so the next
question is can you define a variable
that can be accessed from multiple jobs
yes of course what are they pointing to
so these are like twist questions so
actually we can create it that is like
in a routine whenever you create a
static variable right it is not like
straightforward question in talent
feature but then it is something related
to Java so lets you know static is the
answer but then what technically we can
answer will see it so yes you can do it
by declaring a static variable within
the routine so in routine if you declare
any static variable it can be accessed
by multiple jobs so then you need to add
the setter and getter methods like that
whatever variable you are trying to
access you will have to first you know
if you want to change the value of it
you have to use the set method and if
you want to read the value of what you
have already you know updated or the
previously updated value will have to
use the getter method
so once done the variable will be
accessible from multiple jobs so it is
something into Java so this can be you
know one level up questions to
understand how you know you know how to
embed Java into talent so the execution
is what is sub job and how can you
data from parent to child abilities one
of the mandatory question in all the
interviews so usually what happens is
there are multiple ways you can pass
value from one job to another job so sub
job is nothing but as you know series of
components which is doing some
particular function like say read the
file filter out data and then filter
data put it to one of the database and
off rows which are rejected by filter
put it in excel file so if this is the
one sub job which you know does a
meaningful work or a functionality is
called a sub job which are connected by
our Roth triggers and rows so that is
called as a sub job but the second part
of the question is about how do you pass
data from parent job to trial job right
so that can be done either from the
context variable or you can write the
data to a file and using a t file output
delimited and in the second job you can
read from that file so let's see the
technicality of this okay it can be a
single component or a number of
components for which no data flow is
joined a job can have at least one sub
job to pass value from parent to child
you need to make use of context
variables so or you can store it in a
file and read it in the next job right
so let's move on to next question so
define the use of outline view window
most of us will again I know would not
have observed much about you know
outline view
so outline view is nothing but it will
show you the code whatever you are using
one component you click on that
component so what is the code related to
that particular component will be able
to see so outline view in the terrain
opus road is used to keep track of
written values available in the
component like the standard variables
which are available for that component
say for example we have our of the
database component then how much lines
inserted how much lines updated how much
lines deleted those values will be
available for you in the standard
variables so this will also include the
user different values configured in T
set global component totes so the next
question is explain T map component so
most of the interview questions will
start with actually T map sometimes
they'll first try to understand whether
you know team app functionality is all
the wrong hat is properly so named few
functions that you can perform on it so
this is kind of a I know general
questions like what we have to answer
for which are the talent features which
are very important in team up right so
team app component it belongs to
processing family so family
categorization is one more point where
you can tell you know more about our
talent so you can just tell team app is
in processing formally and then it is
used for you know a multiple source it
can be accepted and it can give output
to multiple targets and inside we can
have stage variables we have multiple
joints and error capturing mechanisms
and you have you know different lookup
models joint models and that we have
temp storage options all those stuffs
which are involved in team up you can
put it down so as I said it belongs to
processing family and you can add and
remove column apply transformation
filter result expression usage and each
column level field level you can put the
business rules all those stuffs you can
tell about the team up so this is basic
question and most of us we know all the
features of this team up so this is also
one more standard question what is
difference between team happened t-joint
most of us will start with you know a
number of inputs and not availability of
the stage variables or all those stuff
so let's see the technicality of it so
it is a powerful component which is
handled to complicated cases can only
handle the basic joints rejoin and in
team up we can accept multiple inputs
whereas in t1 we have only our two
inputs are can be accepted and it can
have multiple outputs it can have only
two outputs main and reject energy on
reject and then supports multiple types
of joints you know different types of
joint supports only unique joint so
supports inner join and left outer join
supports only natural so can filter the
data using filter expressions and can't
do so so in t join we don't have any
expression editor or filtering condition
it's only related to the joints and also
they would continuously after this
question they would tell how will I join
three sources if I have
use t-joint then you will have to answer
like first I will join the two sources
get the output of the T joint and to
that output and one input I will use an
other design so by using T - t joint
components we'll be able to achieve that
requirement like if you want to join
three sources using T join will have to
answer like this right so what is the
scheduler so all of us know like after
usually when we do Talent
jobs the next step is to schedule them
so obviously we will use either third
party shader our window Chandelure to
shuttle the job it's basically to run a
job in particular interval right so
shade alert is in software which selects
process from the queue and loads them
into the memory for execution talent
does not provide a built-in scheduler
but then it is for open source we have a
shady emotions in talent admin center
that is tagged in that is only available
in the enterprise version right so you
can you should answer in the both ways
like it is available in Enterprise
Edition by attack but in open source we
don't have that option so we will have
to either go for window shredder or you
have to go for some third-party
scheduler or conta something like that
right so this is all about your general
interview questions so most of the
generally asked questions which they'll
judge you like at least you walked on
the tool you know all the options so
these questions would make you surely
confident to get through the general
questions right so now we are in the
third part of our agenda that is
Thailand integration interview questions
which are very specific to only talent
di so let's see what are the main
questions in data integration interview
questions right so the first thing in
the data integration is to describe what
is ETL most of us are into ETL field if
we are at least trying to get to know
what is IDL and what is talent all the
stuff so usually we will first tell the
observation of it I mean we would expand
this abbreviation saying that it is it
stands for I know extract transform and
load so basically don't start with that
that does not you know sound amateur so
we just directly start with explanation
of what is the process all about so we
have
in today's world we have data coming
from different sources different
heterogeneous sources one client may
give the data in excel another one can
give it in database and other one will
tell you take it from my API why am i
you know database something like that so
we have difference in schemas we have
different in formats of the file so we
need to extract the data from
heterogeneous sources so that's why you
know a needle stat for that extraction
of the data from heterogeneous sources
and then we will have the you know
business rules to apply on it and we'll
have to transform the data which we have
right and then ultimately when it is fit
for purpose
we'll have to load it into the target
database in the way it is expected so
this would you know make them understand
that you know the situation and why the
need of ETL was needed and then the
definition so it will refers to extract
transform and load and you know what
those terms mean right so next question
immediately after that usually most of
our interviewer will ask is
differentiate between the ETA line ELT
so basically we know that again we will
tell it is extract transform and load
and this is extract wouldn't transform
but then you will have to make sure yeah
we will differentiate them see where do
we use ETA list when we use the use case
of what we are executing can be best
delivered or Optimizely done by using
the capability of ETL engine then we
would go for ETL but the things or the
use case which are we are trying to
deliver using ELT is by using the
capability of the database will first
load the data and using the capability
of the database engine we will make it
faster or optimized in such cases we go
for ELT so make sure you put down the
first important point and then answer
this like data is extracted first and
then transform before it is loaded so
that is what it means and then in ELT it
is data is extracted then it is loaded
to the target system and then it is
further transformed so in ETL it is
increase in size of data processing
slowest enter
ETL process need to wait till
transformation is over but in ELT trap
final processing is not dependent on the
size of the data it is loaded but then
only it is transformed using the
capability of the database engine and
ETL is very easy to implement and ELT is
needs deep knowledge of the tools that's
why I said like use case dependent you
should first know what you are doing or
what kind of data are handling and what
kind of transformations you are doing
and whether it is costly in ETL engine
or it is costly in database engine and
then you will have to take the decision
on it so da ETL does not provide the
data like support an ELT provides the
data like support and ETL suppose the
relation data and ELT supports
unstructured data as well right so we
can put down all these major points and
that would really do good for that
question
so the X question is can we use ASCII or
binary transform mode in SFTP connection
like most of us will first we have to
put down what is FTP and what is SFTP
and what is S stands for I mean you know
why security is needed all the stuff and
then technically we can tell see know
the transfer modes cannot be used in
SFTP connection so SLT does not support
any kind of transfer modes as it is an
extension to SSH and assumes an
underlying secure Channel
so that is why I know the transfer mode
so I know cannot be kept as acceptable
connections so this is one you know out
of box question like we thought most of
the interviewers are asking this so we
have included this so the next question
is how do you schedule a job in talent
so again as I said if it is in the
Enterprise version it is already there
otherwise you'll have to go for window
scheduler or crontab in linux know or
you can go for a third party to like you
know auto sis or you see four so in
order to shuttle the job in talent first
you need to export the job as a
standalone program like build the job
and get the executables and that
executable is what you are going to
schedule right so Windows - little Linux
or cron can do this job for you so this
can be also scheduling always one
question you can surely expect so
there's also like da component related
question like explain the purpose of T
denormalized sorted row so most of us
we know what is denomination sorted the
name itself suggests what is the
component you know help us to do so it
creates it D normalizes the data and
sorta starts the data and provided me as
an output so TD normally I sorted or
belongs to processing family again
naming the family is one plus point and
it helps in synthesizing the sorted
input flow in order to save memory it
combines all the sorted rows in the
group where the distinct values are
joined with items of critters so you
just go to Tannen come get to know about
this I know very rare components which
are you know very I know capable so that
kind of components will be usually asked
in you know interviews so that I can
answer those rare components as well
because most of us will not be using
these components regularly so next
question is differentiate between insert
or update or update or insert so in any
of the you know database component like
say for example MySQL you will have the
action one data option where you will
have all this option insert or update
update or insert so basically how do you
choose this is what first they want you
wanna understand you know like I can
tell it will first insert and then
update and it will first update and then
insert so that will not be the answer
which you know into where we'll be
expecting you'll have to answer in a way
like see these options are provided for
some reason some optimization reason
suppose if I know the data coming in
which I am going to put it in the
database has most you know most of the
new rows than the existing rows then
number of inserts will be more and
update will be less so in that case I
will go for insert or update in the
other case I'll go for update or insert
so that I save time it is optimized so
that is the way you should be able to
answer this question so talent first
tries to insert a record but the record
is matching then it will update it so
the same way for the other so this is
one of the important question which will
be asked to try to get more information
on this component and also other options
available in action on data so explain
the use of tea context load as we this
is somewhere related to the one question
which were asked what are the different
types of context variables wherein we
have external context right so now how
do we load the XL context into talent
so we'll have to use the tea context
note and also tea context load component
has fix-it schema where we had one more
question previously what are the
different kind of schema repository
metadata and pixel schema again tea
context load comes under fix-it schema
so Deacon does not belong to
miscellaneous family helps in modifying
the values of active context on the fly
and it sends warning messages if you are
not loading which is existing and not in
the file and existing in file and not
you know declared in the job so you can
easily identify them and you can also
categorize them to be error or warning
or something like that so basically it
is used to lower the values for the
context defined in the job from an
external file so discuss the difference
between XM x and x ms parameters so most
of us whenever the job is failing or
heap space Emmer is coming will first go
into the Advanced Settings of the run
window and we will see what is the
parameters you are giving so usually it
will be default 256mb which is allocated
for your program
so basically x MX and they are the you
know minimum and maximum space which
your job can occupy so when you are
dealing with hi I know a huge data then
you will have to increase your raw x ms
values so basically it's a heap size so
x ms is the parameter used to specify
the initial heap space and x ms is the
maximum miss please
so what is the use of expression editor
in Tallin so quite side forward
questions so we can tell whatever
expression you want to either you want
to put it as a filter condition you want
to calculate something everything you
can do it in your expression editor so
basically you know where our output
constraint statements can be you know
easily viewed and edited and it comes
with a dedicated view for writing any
function whenever you open an extern you
know your expression window it opens up
a separate window with all the you know
variables listed down all the functions
listed out where you can choose from
them so necessary expressions are needed
to a data transmission can be directly
written you can choose it from the
existing one or you can write your
protein and call the retaining side your
expression builder as well so we can put
all possible reasons or the functions
which you can do it in your expression
editor so explain
error handling in error handling
you know exception handling these are
the common questions in any affair
interview
so basically you can either tell about
the components or you can explain about
the you know categories okay what are
the different ways you can do it so one
is like exception throwing process in
open studio or you can do it by triggers
by on job okay on header you can put
down some you know you can handle some
letters and by defining the error
handling sub jobs you can define one a
reusable job where you can capture all
the logs are you steed i t1 and capture
all the logs and put it into your
generic login table or a file so three
ways that is exception throwing process
in Thailand open studio and you can use
you know components which can capture
your exceptions so for a second one is
on sub job ok and error component on a
component error and ok so you can use
the t1 t die and your T log catches you
can use and you can merge the outputs of
all of them and have a dedicated log or
error handling recordings okay so one
more famous question is they will first
ask you what is T Java and then they'll
ask you what is T Java row and
ultimately they'll tell you compare all
these things so we can tell like T
device you know independent component
does not need any input but is our Rose
needs an input and even teach our Flex
needs an input and T Java flex has three
different you know begin main and
initialization and finally blocks so all
these basic things you can do and hope
you cannot put down this tabular column
and tell in the interview but then which
are the things you will have to mention
so it can be used to integrate custom
Java code all of three components will
help you doing that to integrate the
channel code so will be executed only
once at the beginning of the sub job so
T Java and teach everyone flux can be
used multiple times you know needs input
flow at each other doesn't need G Java
ro needs it and teach our Flex is not
needed so needs
output flow T Java does not need teach
our row and flix
should definitely need it and can be
used as a first component of the job yes
40 Java again no 40 Java row and flex
because it needs an input
right can be used as a different sub job
yes of what a Java and no for tea
tomorrow but s4d flex so allows main
flow or I traitor flow Java RT Java will
accept both a row will exit only main
flex will accept both of it and three
parts as I mentioned only flex has it
another two doesn't have and can auto
broke brigate the data and no for arti
Java and T's owaru
but flex will Auto propagate the data
right so these are the points which you
can mention but go on with the major
ones first so the next question is how
can you execute it talent job remotely
again it relates to one more question
like when we talked about rescheduling
we told first we have to export the job
and get the executables and then it can
be executed anywhere so we can execute
the darn job remotely from a command
line you need to do is to export the job
and get the dependencies and get that
you know dot bad file or dot jar file or
dot s H file to execute that talent job
right so the next question is can you
exclude headers and footers from input
files before loading the data so
obviously you can do it in different
ways and what is your way of doing it
the address and footers can be extruded
easily before loading the data from
input first you can give the different
number for our header and footer value
and you can do that or it can now filter
out based on some you know a delimiter
or which is present in headers and not
in the data anything can be possible so
explain the process of resolving heap
space issue already we saw X M s and X M
s which is initial heap space and
maximum base please
so even providing after that we will not
know how to manage it or how to resolve
it so few things which we would like to
you know put down for heap space issue
are like this so he fails issue occurs
when JVM tries to add more data into his
space than the space available to
resolve this issue you need to modify
the memory allocated to your talent
studio and make sure when you are doing
it in server one job is running and
taking some memory and you try to
trigger one more job it takes a memory
and the first job will not get the
memory which is required it slows down
and next it will fail so then you have
to modify the relevant ini configuration
file further you know XML send XMS
values so with all these and even are
using the DC overhead
variables to automatically you know set
the maximum wave space you can use that
variable as well so the next question is
what is the purpose of T xmlmap
component as you know we have already
explained about T map
so take similar map is it is explicitly
designed for XML input and we can you
know change the format of it now this
component transforms and routes the data
from single or multiple sources to
single or multiple destinations just
like team up it is an advanced component
which is sculptured for transforming and
routing XML data flow especially needed
to process numerous XML data sources so
we can code on these reasons for the XML
map component so these are the few basic
questions or most commonly asked
questions for data integration now let
us also quickly see what are the basic
questions in big data so the first
question in big data is differentiate
between POS for di and TOS for big data
most of us will know like why do we have
different downloadables for that what is
that not present in tos and which is
there in you know are we dead are not
there in integration first thing is all
the big data components as you are aware
of that will not contain any of your big
data components and then big data will
have all these you know what an works
related thing all big data whatever
related thing is there those jars all
those stuff will also be downloaded when
you download this T whales so let's see
technically tarrant open studio for big
data is a superset so when you download
big data this is as good as downloading
da plus big data so it contains all the
function is plotted by TOS for di along
with some additional functions like
support for Big Data technologies so
that is the major difference so T wise
for di generates only Java codes whereas
TOS for big data are generous MapReduce
code along with the Java course as well
right that is a major difference one is
all the components of big data is
available here and that is a superset so
these two will surely that is a major
difference between TOS n dy so big data
so what are the various Big Data
technologies supported by talent so most
of the big data's leaders I know like
Cassandra HBase mom buddy we
it's DFS Hadoop hi big couch where's dB
everything GU GLE storage you name it
and talent haha you know connector for
it so as I said yeah
Cassandra Apache has space big couch DB
Hadoop HDFS MongoDB
I know SQL donated Google storage hi and
poof all this Big Data technologies are
supported by talent so how can you run
multiple jobs in parallel within talent
again when it comes to parallel things
you will have to first ask them whether
you're you know talking about open
source or raw you are talking about
enterprise version so as talent is a
code generator various jobs and sub jobs
in multiple threads can be executed to
reduce the runtime basically we have
multi-threading which is available in
open source and T panelist component is
only available in Enterprise version an
automatic parallelization that is also
available only in your Enterprise
version but you can you know export your
jobs in open source and run them in
multiple instances if they do not have
any dependencies whenever they are run
in parallel even that way parallelism
can be achieved so one of the major
thing which is asking booted eyes your
parallel execution right so what are the
mandatory configurations needed in order
to connect to history office so all of
you know that we have Orton works up
what we've also have the manual set up a
festival support also in talent so
basically the name load related you know
resource related are very mandatory for
has staff is connection so distribution
what is the distribution whether it is a
custom distribution or any Haughton
works name load URI and the user name
all these things are mandatory for raw
HDFS connections so this is one thing
where they will try to understand
whether you know the I know which
component will work with minimal
configurations
what is that you have to manually give
all the stuff so which service is needed
for coordinating transactions between
talent studio and HBase so whenever
you're using has place
the transactions coordinating is usually
done by Apache zookeeper so technically
let's see this Apache zookeeper is an
open source software project of the
Apache Software Foundation it provides
centralized
lecture and services that enable
synchronization across the Hadoop
cluster so whatever raw now which is
related in the how to clustered
everything coordination of transaction
is done by zookeeper so the next
question is what is the name of the
language used for big scripting so all
of us know that it is not in scripts big
Latin script is what we call them so
Latin big is a high level platform which
is used for creating programs that run
on Apache Hadoop it is simple SQL like
scripting that is complete so you can do
all required data manipulation in but
you had with peak right so when do you
use T Kafka create topic again talent
also supports Kafka so first you need to
you know whenever you want to create
topics we have to use a topic component
and then the component creates Kafka
topic so all other Kafka related
components can use that so until unless
you know what is Kafka what is Kafka
topics you not understand these
questions as such so even Kafka is
included in the talent training which is
provided by Eddie raker so complete one
use case is taken on Kafka and we have
executed that so let's see the
technicality of it so used to create a
new Kafka topic this component creates a
cough out of it which is other Kafka
components can also use it allows you to
visually generate the command to create
a topic which various properties at
topic level so once you understand what
is topic only you'll understand the
answer for this question so try to go
through this we already release few of
the topic course contents of the new
syllabus for talent training so go
through it if you are wrong you know you
want to understand all these topics
surely you can take the training under
it reca
so the next question is explain the
purpose of TP Claude component obviously
as the name itself suggests so this
component helps in loading the data into
the you know fixing the single
transaction usually if you know Thailand
are row by row transaction will happen
like the row type main it right and all
we saw that right so but big load is
like whatever amount of rows are get it
will be done in one transaction so this
component helps in loading the origin
input data to an output stream in just
once single transaction it sets up the
connection to the data source for the
current transaction so TP glowed is
basically to the load data in a single
transaction so which component do you
need in order to automatically close a
hive connection as soon as the main job
finishes so obviously we know like we
have companies like tea pre job and T
post job once all the component has been
finished the execution the next
component which is triggered is a post
job so we can attach close connection
for hive to post job and within come up
with a solution for this question
so you ste post job and hive close
connection which will automatically
close your connection once your job is
completed right so these are few
questions which we thought which will
really help you to at an interview or
boost your confidence all these
questions and I know the use cases
technicalities involved our detailee
dealt in the training in aerica the
talent Big Data training which even
involves you know Hadoop hi Pig Kafka so
all this stuff along with the detailed
explanation of for all the dia features
of talent so all the first 20 hours
close to 20 hours of classes will be
based on talent da and the 10 hours are
dedicated to Big Data are covering all
the major big data connections and use
cases so that would be really helpful
for you to take over your career in
talent so go through the course contents
and schedules and
demo videos and get to know about it and
if you like it surely and role to the
classes and I'll be teaching you all of
these topics related to talent in detail
thank you for watching this video keep
following us I hope you have enjoyed
listening to this video please be kind
enough to like it and you can comment
any of your doubts and queries and we
will reply them at the earliest do look
out for more videos in our playlist and
subscribe to any Rekha channel to learn
more happy learning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>