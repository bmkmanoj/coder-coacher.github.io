<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Convolutional Neural Network (CNN) | Convolutional Neural Networks With TensorFlow | Edureka | Coder Coacher - Coaching Coders</title><meta content="Convolutional Neural Network (CNN) | Convolutional Neural Networks With TensorFlow | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Convolutional Neural Network (CNN) | Convolutional Neural Networks With TensorFlow | Edureka</b></h2><h5 class="post__date">2017-09-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/umGJ30-15_A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone this is sorted from Adi
Rekha and today we'll be discussing
about convolutional neural networks so
without any further ado let us move
forward and have a look at the agenda
for today so we'll begin by
understanding how a computer reads an
image then we'll see why can't we use
fully connected networks for image
recognition after that we'll understand
what exactly is convolutional neural
network and how it works and finally
we'll be looking at a useless so let's
begin guys will understand how exactly a
computer reads an image so this is an
image of New York skyline I personally
love this picture so when I even will
see this image
he'll first notice there are a lot of
buildings and different colors and stuff
like that but how a computer will read
this image so basically there will be
three channels one will be red another
will be green and finally we have blue
Chara which is popularly known as RGB so
each of these channels will they have
their own respective pixel values as you
can see it over here so when I say that
image size is B cross a cross 3 it means
that there are B rows a columns and
three channels alright so so if somebody
tells you that the size of an image is
28 cross 28 cross three pixels it means
that it has 28 rows 28 columns and three
channels so this is how a computer sees
an image and this is for colored images
for black and white images we have only
two chunks so let's move forward and
we'll see why can't we use fully
connected networks for image
classification so consider an image
which has 28 cross 28 cross three pixels
so when I feed in this image to a fully
connected network like this then the
total number of ways required in the
first hidden layer will be 2,352 you can
just go ahead and multiply it yourself
all right but in real life the images
are not that small all right so whatever
images that we have they are definitely
above 200 cross 200 cross three pixels
so if I take an image which has 200
cross 200 cross three pixels and I feed
it to a fully connected Network so at
that time the number of bits required
the first hidden layer itself will be
120 thousand guys so we need to deal
with such huge amount of parameters and
obviously we require more number of
neurons so that can eventually lead to
overfitting so that's why we cannot use
fully connected Network for image
classification
now let's see why we need convolutional
neural networks so basically in
convolutional neural network a neuron in
the lair will only be connected to a
small region of the layer before it so
if you consider this particular neuron
which I'm highlighting right now is only
connected to three other neurons unlike
the fully connected
network where this particular neuron
will be connected to all these five
neurons because of this we need to
handle less amount of weights and in
turn we need less number of neurons as
well so let us understand what exactly
is convolutional neural network so
convolutional neural networks are
special type of feed-forward artificial
neural networks which is inspired from
visual cortex so visual cortex is
nothing but a small region in our brain
brain which is present somewhere here
where you can see the bulb and basically
what happened there was an experiment
conducted and people want to know that
visual cortex is small regions of cells
that are sensitive to specific regions
of visual field so what I mean by that
is for example some neurons in the
visual cortex fires when exposed to
vertical edges some will fire when
exposed to horizontal later some will
fire and exposed to diagonal edges and
that is nothing but the motivation
behind convolutional neural network so
now let us understand how exactly a
convolutional neural network works so
generally a convolutional neural network
has three layers convolution layer a
layer pooling layer and fully connected
layer will understand each of these
layers one by one will take an example
of a classifier with that can classify
an image of an X as well as an O so with
this example we'll be understanding all
these four layers so let's begin guys
now there are certain trickier cases so
what I mean by that is X can be
represented in these four forms as well
right so these are nothing but the
deformed images effects similarly for OS
well so these are deformed images so
even I want to classify these images
either X or hope all right because even
this is X this is X this is X this is X
but all these are deformed images but
they are in turn X right so I want my
classifier to classify them as X so
basically that's what I want so if you
can notice here this is a proper image
of an X and which is actually equal to
this particular X which is the deformed
image same goes for this always well so
now what we are going to do is we know
that a computer understands an image
using numbers at each pixels so what
we'll do whatever the white pixels that
we have we are going to assign a value
minus 1 to it and whatever black pixels
we have we are going to assign a value 1
to it when we use normal techniques to
compare these two images one is a proper
image of X and another is a deformed
image of X we got to know that a
computer is not able to classify the
deformed image of X correctly why
because it is comparing it with the
proper image of X right so when you go
ahead and add the pixel values of both
of these images you get something like
this so basically a computer is not able
to recognize
whether it is an X or not now what we do
with the help of CNN we take small
patches of our image so these patches or
these pieces are known as nothing but
features or filters so what we do by
finding a rough feature matches in
roughly the same positions in two images
CNN gets a lot better at seeing the
similarity between the whole image
matching schemes what I mean by that is
we have these filters right we have
these filters that you can see so
consider this first filter this is
exactly equal to the feature of the part
of the image in the deformed image as
well so this is a proper image and this
is our deform limit alright so this
particular feature or this particular
part of the image is actually equal to
this particular part of the image same
goes for this particular feature of
filter as well and similarly we have
this filter as well which is actually
equal to this particular part of the our
deform limits alright so let's move
forward and see what all features that
we'll be taking in our example so we'll
be considering these three features or
filters this is a diagnosed illness this
is again a diagonal filter and this is
nothing but a smaller so we'll be these
three filters and we'll move forward so
what we are going to do is we are going
to compare these features the small
pieces of the bigger image we are going
to put it on the input image and if it
matches then the image will be
classified correctly now we'll begin
guys the first layer is convolution
layer so these are the beginning two
steps of this particular layer first we
need to line up the feature and the
image and then multiply image by the
corresponding feature pixel now let me
explain you with an example so this is
our first diagonal feature that will
take we are going to put this particular
feature on our image of X all right and
we are going to multiply the
corresponding pixel values so one will
be multiplied with one will get one and
we'll put it in another matrix similarly
we are going to move forward and we're
going to multiply minus one with minus
one we are going to multiply minus one
with minus one as you can see similarly
with multiply this rizal minus 1 into
minus one then again minus 1 into minus
one so we are going to complete this
whole process when we are going to
finish up this matrix all right and once
we are done finishing up the
multiplication of all the corresponding
pixels in the feature as well as in the
image we need to follow two more steps
we need to add them up and divide by the
total number of the pixels in the
feature so what I mean by that is after
the multiplication of the corresponding
pixel values what we do we add all these
values we divide by the total number of
pixels and we get some value right and
then now our next step is to create a
map and put
the value of the filter at that
particular place we saw that after
multiplying the pixel value of a feature
with the corresponding pixel value of a
bit out of our image we get the output
which is one so we placed one here
similarly we are going to move this
filter throughout the image next up we
are going to move this filter here after
that we are going to move it here here
here everywhere on the image we are
going to move it and you're going to
follow the same process alright so yeah
this is one more example where I've
moved my filter in between and after
doing that I've got the output something
like this one one minus one and all so
over here if you notice I've got couple
of times minus one as well due to which
my output that comes it's 0.55 right so
I'm gonna place point five five here
similarly after moving the pixel after
moving the filter throughout the image I
got this particular matrix alright and
this is for one particular feature after
performing the same process for the
other two filters as well I've got these
two values so we have these three values
after passing through the convolution
layer let me give you a quick recap of
what happens in convolution layer so
basically we have taken three features
all right and one by one we'll take one
feature move it through the entire image
and when we are moving it at that time
we are multiplying the pixel value of
the image with that of the corresponding
pixel value of the filter adding them up
dividing by the total number of pixels
to get the output so when we do that for
all the filters we get we got these
three outputs all right so let's move
forward and we'll see what happens in
ray luleÃ¥ so this is Rayleigh layer
guys and people who have gone through
the previous tutorial actually know what
it is so let me just give you a quick
introduction of Prelude layer so reimu
is nothing but a activation function all
right so what I mean by that is it will
only activate a node if the input is
above a certain quantity while the input
is below zero the output is also zero
all right and when the input rises above
the certain threshold it has a linear
relationship with the dependent variable
now I'll explain you with an example if
we have a graph of a low function here
so my function says that when f of X is
equal to zero if X is less than 0 and it
is equal to X when X is greater than
zero all right so whatever values that I
have which are below zero will actually
in turn become zero and whatever values
that are above zero our function value
will also be equal to that particular
value so f of X will be equal to X if it
is greater than or equal to zero and it
will be 0 if it is less than 0
so if I have X value as minus three so
definitely it is less than 0 so f of X
becomes u similarly if I have minus 5x
value then the again it is less than
zero so my f of X value becomes zero but
when I consider 3 as my x value then my
f of X becomes equal to X which is
nothing but 3 so over here I'll add 3
again if I take my x value as 5 that
obviously it is greater than or equal to
zero then my f of X becomes equal to X
so my f of X value becomes 5
so this is our rayleigh function works
so why are we using rayleigh function
here is we want to remove all the
negative values from our output that we
go through the convolution layer so
we'll only take the first output that we
got by moving one feature throughout the
image so this is the output that we have
got for only one filter alright so over
here I'm going to remove all negative
values over here you can see that it
will was minus point one one before and
I've converted that to zero similarly
I'm going to repeat the whole process
for the entire matrix and once I'm done
with that I get this particular value
now remember this is only for the output
that we got through one feature all
right so when we were doing convolution
at that time we were using three
features right so this is output only
for one filter after doing it for the
output of the other two filters as well
we have got these two values more so
totally we have these three values after
passing through trello activation
function next up we'll see what exactly
is pooling layer so in pooling layer
what we do we take a window size of 2
and we move it across the entire matrix
that we have got after passing through
ray Lulla and we take only the maximum
value from there so that we can shrink
the image so what we are actually doing
is we are reducing the size of our image
so let me explain you with an example so
this is basically one output that we
have got off passing through ray Loewy
layer and over here we have taken a
window size of 2 cross 2 so when we keep
this window at this particular position
we see that 1 is the highest value so we
are going to keep one here and we are
going to repeat the same process for
this particular window as well so in
here the maximum value is point three
this is 0.33 welcome so if you notice
here earlier we had 7 cross 7 matrix and
now we have reduced that to 4 cross 4
matrix so after doing that for the
entire image we have got this as our
output this output we have got after
moving our window throughout the image
that we have caught after passing
through ray Lulla right and when
repeat this process for all the three
outputs that we have got after the rail
Euler then we get this particular output
after pulling here right so basically we
have shrink that image to a 4 cross 4
matrix now comes the tricky part so
where we are going to do now is stack up
all these layers so we have discussed
convolution layer rail you layer and
pooling here so I'll just give you a
brief recap of what all things we have
discussed in convolution layer what we
did we took three features and then
after that one by one we moved each
filter throughout the image and then we
were moving it we are continuously
multiplying the image pixel value with
that of the corresponding filter pixel
value and then we were dividing it by
the total number of pixels alright with
that we got three output after passing
through the convolution layer then those
three output we passed through a rail
layer where we have removed the negative
value all right and after removing a
negative value again we have got the
three outputs then those three outputs
we pass through pooling layer so
basically we are trying to shrink our
image and what we did we took a window
size of 2 cross 2 moved it through all
the three outputs that we have got
through later a new layer and after
doing that we were only taking the
maximum value pixel value in that
particular window and then we are
putting it in a different matrix so that
we get a shrink image and after passing
it through pooling here we have got a 4
cross 4 matrix and since we took 3
features in the beginning so therefore
we have got the 3 outputs after passing
through pooling yeah all right next up
we are going to stack up all the layers
all right so let's do that so after
passing through convolution radio and
pooling we have got this 4 cross 4
matrix this was our input image now when
we add one more layer of convolution
reloj and pooling we have shrink their
image from 4 cross 4 to 2 cross 2 as you
can notice it now we are going to use
fully connected layer now what happens
in fully connected layer the actual
classification happens here guys ok so
what we are doing here is we are going
to take the shrink images and put it
into a single list so basically this is
what we have got after passing through
two layers of convolution reloj and
pooling and this is what we have got so
basically we are converting into a
single list or a vector how we do that
we take the first value 1 then we take
point 5 5 then we take point 5 5 then we
take 1 again
then we take 1 then we take point five
five point five five point five five
then we again take point 5 5 1 1 and
point five 5 so this is nothing but a
vector or you can say a list if you
notice here that they
certain values in my list which was high
for eggs and similarly if I repeat the
entire process that we have discussed
for who they'll be certain different
values which will be higher so for an X
we have first fourth fifth tenth and
eleventh element of vector values are
higher for oh we have second third ninth
and twelfth element vector which are
higher so basically we know now if if we
have an input image which has a first
fourth fifth tenth and eleventh element
vector values high we know that we can
classify it as X similarly if our input
image has a list which has the 2nd 3rd
9th and 12th element vector values
higher then we can classify at a zero
now let me explain with an example so
after three training is done after the
after doing the entire process for both
X and O you know the our model is
sprained now okay so we have given one a
new input image and that input image
passes through all the layers and once
it has passed through all the layers we
have got this 12 element vector now it
has point nine point six five all these
values right now how do we classify it
whether it is an X or oh so what we do
will compare this with the list of X and
O right so we have got the list in the
previous slide if you notice we have got
two different lists for X and O we are
going to compare this new input image
list that we have got with that of X and
O right so first let us compare that
with X now as I've told you earlier as
well for X there are certain values
which will be higher which is nothing
but first fourth fifth 10th and 11th
value right so I'm going to sum first
fourth fifth tenth and 11th value and
I've got 5 1 plus 1 plus 1 plus 1 and
plus 1 so 5 times 1 I've got 5 and now
I'm going to sum the corresponding
values of my input image vector as well
so the first value is 0.9 then the
fourth value is 0.87 fifth value is 0.96
10th value is 0.8 9 and the 11th value
is 0.94
so after this doing the sum of these
values have got four point five six and
I divide this by 5 I got 0.9 right now
this is for X now when I do the same
process for oh so you know if you notice
I have 2nd 3rd 9th and 12th
element vector values as high so when I
sum these values I get 4 and when I do
the sum of the corresponding values in
my input image I've got 2.07 when I
divide that by 4 I got put 4.5 huh
so now we notice that point 9 1 is a
higher value compared to 0.5 1 so we
have when we have compared our input
image with the values of X we got a
higher value then the value that we have
got after comparing the input image with
the values of 4 so the input image is
classified as X all right so now let us
move towards our use case so this is our
use case guys over here what we are
going to do is we are going to train our
model on different types of dogs and cat
images and once the training is done we
are going to provide it an input and it
will classify whether the input is of a
dog or a cat now let me tell you the
steps involved in it so what we are
going to do in the beginning is
obviously first we need to download the
data set after that we are going to
write a function to encode the labels
labels are nothing but the dependent
variable that we are trying to predict
so in our training data and testing data
obviously we know the labels right so on
that basis only we can train our mode so
we are going to encode those live after
that we'll resize the image to 50 across
50 pixel and we are going to read it as
a grayscale image then we are going to
split the data 24,000 images for
training and 50 for testing once this is
done we are going to reshape the data
appropriately for tensorflow not
tensorflow I think everyone knows about
times the flow times flow is nothing but
a Python library for implementing deep
learning models then we are going to
build the model calculate the loss it is
nothing but categorical cross entropy
then we are going to reduce the loss by
using atom optimizer with a learning
rate set aside to point double zero 1
then we are going to trave the Train the
deep util network for tena Potts and
finally we are going to make predictions
all right so I'll just quickly open my
Python and I'll show you the code how it
looks like so this is the code that I
have written in order to implement the
use case in the beginning I need to
import the libraries that I require and
once it is done what I am doing I am
defining my training data and the
testing data so train and test 1
contains both my training data as well
as testing data respectively
then I have taken my image size as 50
and learning rate I have defined her and
I've given a name to my model you can
give whatever name you want or it's the
first thing that we saw we need to
encode the dependent variable that's
what we are doing here we are encoding
our dependent variable
so whenever the label is cat then it
will be converted to an array
one comma zero and when it is dog will
be converted to an area of zero comma
one so by a vibrator actually encoding
the label because our code cannot
understand the categorical variable so
we need to encode it right next what I'm
doing is I'm resizing my image to fifty
cross 50 and I am converting into a
grayscale image right and once this is
done I'm going to split my dataset into
training and testing paths so yeah we're
basically splitting the data set into
two parts for training and testing and
here we are defining a model so you can
just I can just go ahead and throw in a
comment here
building the model yeah so this is where
we are building the model so basically
what we have done here is we have
resized our image to 50 cross 50 cross 1
matrix and that is the size of the input
that we are using right this input that
I am talking about then what we have
done a convolution layer we have defined
with 32 filters and a stride of 5 with
an activation function or raloo and
after that we have added up pooling your
mats pool layer ok again what we have
done we have repeated the same process
but over here we are taking 64 filters
and 5-straight passing it through a
railer activation function and after
that we have a pooling let Matt's pool
layer then we have repeated the same
process for 128 filters after that we
have repeated for 64 filters then for 32
filters and after that we are using a
fully connected layer with 1 0 to 4
neurons and finally we are using the
drop out here with key probability of
point eight to finish our mods this is
where our model is actually finished and
then what we are doing is we are using
the atom optimizer to optimize our model
so basically whatever the laws that we
have you are trying to reduce it and
that this is basically for your 10
support so we are creating some log
files and then with that log fight ends
about will create a pretty fancy graphs
for us but that helps us to visualize
the entire model and then what we are
doing is we are trying to fit the model
and we have defined a pox as 10 that is
the number of iterations that will
happen will be 10 and yeah so this is
pretty much it modern name we have given
then input is X underscore test to check
the accuracy
similarly the target will be y
underscore test the labels associated
with that case theta will be a y
underscore test and which we have in
code basically so this is how we are
going to actually calculate the accuracy
and we will try to reduce the loss as
much as possible
antenna fox so till now our model is
complete we are done with it
next what I am doing is I am feeding in
some random input from the test data and
I'm validating whether my model is
predicting it correct or not all right
so I've already trained the model
because it takes a lot of time and yeah
I cannot do it here so I have already
trained the model and you can see that
the loss that came after the 10th epoch
is 0.2 973 and the accuracy is somewhere
around 88 for
which is pretty good guys and yeah and
I've done the prediction on the test
data as well so let me just show it to
you that so this is the prediction that
it has done on few of the images in the
test data so yeah it is a CAD predicted
as Cal Cal predict as a cat cat cat cat
and dogs as well as there are certain
dogs as well so this is it for today's
session guys and if you want the code in
the data set go ahead and comment your
email id and we'll mail it to you as
soon as possible so let me just give you
a quick recap of things that we have
discussed till now so this is what we
have discussed in today's session we
started by understanding how a computer
reads an image then we saw why can't we
use fully connected network for a few
for image recognition then we saw why we
need convolutional neural networks and
what is convolution neural network after
that we understood how a convolutional
neural network works we discussed all
the layers that are involved in it like
convolution reloj pooling fully
connected layer all those layers we have
discussed in detail and then finally we
implemented a use case it's in classify
the images of dogs and cats alright so
this is it for today's session guys if
you have any questions any doubts just
to go ahead and type it at the comment
section below you'll get the answer as
soon as possible thank you and have a
great day I hope you enjoyed listening
to this video please be kind enough to
like it and you can comment any of your
doubts and queries and we will reply to
them at the earliest do look out for
more videos in our playlist and
subscribe to our Ericka channel to learn
more happy learning
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>