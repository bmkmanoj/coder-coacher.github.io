<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Splunk Architecture | Splunk Tutorial For Beginners | Splunk Training | Splunk Components | Edureka | Coder Coacher - Coaching Coders</title><meta content="Splunk Architecture | Splunk Tutorial For Beginners | Splunk Training | Splunk Components | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Splunk Architecture | Splunk Tutorial For Beginners | Splunk Training | Splunk Components | Edureka</b></h2><h5 class="post__date">2017-12-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/VQZ80hSyQEE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone and welcome back to our
Eureka's youtube channel this adult from
ed Eureka and today we have come with an
exciting episode once plants
architecture as you all know whenever
there is a need of analyzing watering or
visualizing the log the most common tool
which comes on everyone's mind is done
but what happens inside stuff let's see
in this video me lets us say how popular
and powerful the tool is let's still
down to today's agenda for better
understanding before I proceed with
spurns architecture let me give you a
brief idea for each component this would
make things easier for you to understand
so without delaying any further let's
discuss today's agenda we'll start our
session with distributed slugs component
where I teach you about forwarder and
Excel and searcher don't worry I won't
mess my part on the advanced component
and then include the paths for deployer
de Provence server licensed master and
cluster master once we are done with
this part it will be easier for you to
understand and grasp things about stunts
architecture it would be easier for me
as well to discuss about slugs
architecture such that each one of you
get a fair understanding about it and
you actually gain something out of this
short video
let's start our session with stumps
component and let me give you a brief
idea for each component and how they
work together as a cluster inside this
block
you might be wondering why do we need us
dumb cluster when all the components can
be installed on one single machine well
if you are working in a bigger
environment and dealing with huge amount
of data coming from multiple sources
then in that case running just one
single instance of Splunk
won't work for you you have to get
multiple instances in order to work
smoothly let's assume a scenario suppose
you are working with around 100 jeebies
of data per day then in that case I'd
recommend you to have at least three
running instances to work smoothly as
you can distribute your data and get
faster search result from it I hope you
got a fair idea of water Splunk clusters
before we proceed any further and teach
you how a slum cluster actually work let
me help you in understanding different
components available in a distributed
Stuntz cluster as you can see here on
the screen we have a total of six
important components or Splunk out of it
search an indexer and forwarder b3 are
the basic components and the rest
deployers licensed master de provence
server and cluster master are relatively
advanced component of the cluster let me
give you a one-liner for each of them
this should make things easier for you
to understand let's start with searcher
search it is a part when the end user
writes the query to perform the search
on the data so you would be wondering
where does this data comes from so this
data comes from the indexer the indexer
is a place where the data resides it is
used to process the Machine data and
stores the result and indexes as events
this allows us to perform search in a
faster way and analyze it in a better
way I guess your next question would be
how this data comes to our index oh
don't worry I have a solution to that we
have a forward out as the name suggests
it is used to forward something well it
forwards the data coming to it it
collects the data coming from multiple
resources and it sends it to the indexer
so these were the basic components now
let's discuss about the more advanced
component of the cluster what we have
here we have a cluster master deployment
server deployers and a license master
starting with cluster master so what is
a cluster master cluster master is the
one which coordinates all the activities
and updates of an index of within a
cluster this thing is also
as a master node it is coordinating
every updates and whatever things is
happening insider indexer is being
controlled by a cluster master the next
deployment server ordered deployers well
there is a very slight hairline
difference between an employer and a
deployment server the difference is that
the deployment server sends
configuration and app updates to all the
component including forward our indexer
and searcher
while this deployer it sends
configuration and app updates only to
researcher next what do we have here we
have a license pasture which prevents
you from exceeding your purchase limit
suppose you have registered slung for
five minutes GBS of data body and you
are about to exceed that limit as soon
as you exceed that limit you will get
notified by the license master that you
cannot ingest any more data for the day
so this was the use of a license master
I hope you've got the individual uses of
each of them now let's see how each
component worked together in the next
slide by now I assume that you're a fair
understanding of different components or
Splunk let's move on and see what
happens inside Splunk and how each
component work together we have a
forward which is collecting the data
coming from multiple ends the forwarder
then sends the collected data to be
stored at index oh the indexer then
processes the machine data and stores
the result in indexes as events indexing
the data allows faster search and
analysis let me explain you with an
example how the data is actually indexed
within an index so let's assume there
are three indexes and the data is shared
and spread across all of them which
means that we'll have one third data on
one index so now when a user comes and
write its query on the search head to
search the data then the search head
will send its query on each index er
that is same query will reside on index
of one two and so on
now each index L will run the query on
its data you can say that searching is
performed on one third of the data
now once the searching is done it's time
to collect the result so in total we'll
be getting three results from three
different indexes now it's the job of
the search head too much all these
result
displayed to the end-user one of the
member of search at cluster has a role
of a captain which got its job among all
remember over the time the role of
captain can shift from one cluster
member to other apart from these we have
other advanced components which are
deployed cluster master and deploy and
so these I already told you in the last
slide I hope you remembered that
just for recap let me tell you again
deployment server gives configuration
and app updates to forward our index and
search head while this deployer it sends
configuration and app updates only to
the searcher now that cluster master the
cluster master is responsible for all
the configuration and app updates inside
an indexer as you can see here on the
slide the forward and the indexer are
designed to be used by the technical
guides it can be used by your system
engineer or a system admin while the
search head part it is designed to be
used by both the technical as well as
the non-technical guys it can be used by
an analyst to create visualization and
reports out of it whereas it can also be
used by system admin and the system
engineers till now we have covered the
first half of our agenda and discuss
about stance component I hope you got a
fair understanding of different
components and how they work together
now I guess you are ready to understand
the architecture Splunk
and learn how things work inside us once
engine just for a better understanding
of strengths architecture let's take a
scenario we have a Sam who's a system
engineer there an experience of 5 to 6
years
Sam interacts with this plan CLI and his
job is to make sure that all the data
coming from multiple resources are
already available in the right place
we have another guy named Billy he's an
analyst with an experience of around
nine to ten years bill he accesses lunk
web interface to search analyze and
create reports for the collected data
meanwhile Billy is busy analyzing and
creating reports out of his data let's
see what Sam is up to meanwhile Sam is
busy collecting inputs from multiple end
he's getting logs from different network
port or by running strip he is even
keeping a track for any changes made in
the file let me explain you this with an
example you'll understand in a better
way consider all your logs in a raw
format and they are not ingesting to
Splunk yet maybe all the logs are
residing in log file or is getting
pushed to a network port which we
commonly referred to as syslog now this
plan has the ability to Moy to the file
that is they track and detect the
changes made to any file and this plunk
it includes only those new changes into
it for example consider a scenario where
you having the application which writes
all its performance data to a log let's
assume on the previous day we had around
10,000 of frozen our file and by today
it had added more amount of logs to it
they were increasing the count to 11,000
so now we have thousand new rows added
to the file so when he used the mortify
the Splunk will detect the change and it
will index only those new thousand row
it won't add the complete log file are
you getting it as it doesn't index any
duplicate events remember that none
never index any duplicate events and
simple works slum keeps a track of the
data index into it just FYI the Splunk
uses md5 hash in order to detect those
changes and the same is the case with
network port these are all the various
ways in which stump can collect the data
now all the information the file changes
the network port the running off strip
are all managed by forwarder
they are basically two types of or
Werdum Universal and heavy forward of
Universal forwarder is a lightweight
stripped down version of Splunk does not
have any functionality other than
pulling or pushing data indexer it does
not have any ability to filter the data
whereas our Haley forward it can parse
an incoming data and it can
filter it both Universal and heavy
forward are capable of sending data to
indexer
once the data is in Sam can create
indexes for it for indexing the data he
uses data routing protocol and load
balancer to distribute the big amount of
data among all the pixels let me explain
you this with an example suppose you
have five servers which are clustered
together as indexer and your data it is
spread across all the indexes as
discussed Universal forwarder have the
capability to route this data they won't
be sending data to just one server they
are highly intelligent enough to
distribute this data to all those five
servers equally so they do all the data
routing and load balancing while pushing
the data to an indexer cluster some can
also give or restrict access to various
trunk application for different user now
if you are wondering what is plan campus
then in simple terms lungcap is a
pre-built collection of dashboards
panels and UI element it makes plunk
useful and deliver for different roles
now Sam also keeps the instances updated
with deployment server the deployment
server is used to manage the components
by company I mean the search head
indexer and the forwarder just for
example you'll be having more than 100
of universal forward up now if you want
to push your configuration to each
forwarder then practically you cannot do
manual change on each of them so in
order to manage those forwarder in a
centralized manner you will use a
deployment server so the primary user
deployment server is to push the
configuration updates to all the
component oops we almost forgot about
Billy let's see what he is doing
oh it seems that Billy is working very
hard to gain operational intelligence by
searching and analyzing the data
collected by Sam let me give you a clear
picture of this considered in this way
now our data is in the index the user
will have the ability to search the data
but these user will not be given the
access to these indexer by index I mean
the physical system or the GUI these
indexes are not available for the normal
user to log in the normal user will be
given access to only the search head
part now this search it is a place where
they will come and write their queries
and search it it will distribute the
search among all that searched clusters
now what if in future more members are
added to Billy's team what should he do
then then he has a solution he can
distribute the search on various
instances by distributed search now that
the user has access to searcher he can
search through the index data the end
user have the ability to create
knowledge objects by knowledge object I
mean tags even types of field aliases
they can also create reports and
schedule alerts usually stock is used
for monitoring it could be monitoring of
network or of network enterprise as a
part of it will be creating the all
these alerts all these monitoring
searcher or reporting will happen on top
of this searcher so this was the
complete architecture Splunk
or how each component of Splunk swore
now let me give you a short recap of the
architectures plan well initially you
will be having a raw data which would be
collected by heavy or light forwarder
now these forwarder would push the
collected data to index a cluster and
while pushing this data they would make
sure that data routing and load
balancing happens on all the data now
since all the data is in the user can
search across using search end to create
knowledge objects reports and allowance
so I guess we have reached the end of
the session I hope you guys got what he
came for
let me conclude this session with a
short recap of what we learned in this
session we discuss about different
components in a splint cluster where we
learned about forward our index our
search at deploy or deployment server
and cluster master and how all these
components work together we also discuss
the architectures plan where we learned
how things work inside us plans engine
thank you folks this was all for this
session don't forget to hit the bell
icon to subscribe for more exciting
video straw at Eureka and keep yourself
updated with hot and trending technical
content in the market thank you
I hope you enjoyed listening to this
video please be kind enough to like it
and you can comment any of your doubts
and queries and we will reply to them at
the earliest do look out for more videos
now playlists and subscribe to our Erica
channel to learn more happy learning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>