<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Elasticsearch Tutorial | Getting Started with Elasticsearch | ELK Stack Training | Edureka | Coder Coacher - Coaching Coders</title><meta content="Elasticsearch Tutorial | Getting Started with Elasticsearch | ELK Stack Training | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Elasticsearch Tutorial | Getting Started with Elasticsearch | ELK Stack Training | Edureka</b></h2><h5 class="post__date">2017-11-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1EnvkPf7t6Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello thank you very much for joining
today's webinar session my name is hit
Asian I'll be your instructor for
today's we have been a session for
elasticsearch so let's get started
so today in this session we will be
covering little bit about elasticsearch
what elasticsearch is and how do we run
different queries in the elastic search
so elastic search let me give you a
little bit idea about what elastic
search is it is basically a search
engine which is based on apache Lucine
so it helps in performing various kind
of searching it dews the full text
search a various kind of search
mechanism it supports so for now this is
the brief introduction about what
elastic search is let's quickly dive
into these slides and I'll be going
through the more detailed depth of what
elastic searches so this will be the
agenda for today's slide so agenda
include what is elastic search why we
need elastic search what are the
advantages of adopting elastic search
installation of elastic search various
APA convention which are used various
api's query DSL mapping analysis and
modules so these will be the agenda for
today so let's understand what is
elastic search so elastic search is
nothing but it's a real-time distributed
and analytic engine the best part about
this product is it is an open source I
mean it is being backed by an open
source community so anyone can download
without paying any licensing cost so it
comes under the open source license and
it is developed in the Java platform and
it is based on the leucine engine on top
of which we have restful interfaces so
whatever the search base engine work
behind the scenes on top of which we
have the restful api s-- so the LD is
helps in fulfilling the request and
responding to the request so it supports
full text search completely document
based instead of tables and ski masks so
there are some more
face engines which are available in the
market but those are based on tables and
schema-based the best part about this
product is this is all based on
documents instead of schemas and tables
as soon as we'll be moving on in the
depth we'll be able to understand what
is the benefit of having the document
based approach rather than a schema
based approach and it is used for single
page application projects so let's
understand why elasticsearch so first of
all the benefit of having elasticsearch
is in terms of query well in terms of
query it lets you perform and combine
many different type of searches like
structured as well as the unstructured
searches it also helps in working upon
the data which is based on geography and
which is also based on metrics so
irrespective of what type of data you
have whether it is structured
unstructured geo based or it's a metric
base elastic search all supports that
and the best part about this is you can
retrieve the result from the data which
you import in any way you like so it is
all based on some structured query sets
so we write queries and we retrieve the
results based on queries so we can ask a
query based on what you want from it you
can ask the query any ways you want
second benefit of having elastic
searching places it's let you understand
billions of log lines easily because of
the reason that it supports big volume
of data you can import your logs and
this search mechanism can help you to
drill down the issue across millions of
line of logs in a small period of time
it provides aggregation which helps you
to zoom out to explore the trends and
patterns in your data so like suppose if
I have a cloud environment of 500 nodes
and I want to analyze the entire
infrastructure in a short period of time
the best way to do it with the help of
elastic search where I will be importing
the logs into the elastic search and
based on whatever response I am getting
in the elastic search
I can very well get to the root cause of
the issue in the shorter period of time
so that is one of the benefit with the
help of elasticsearch we get in analysis
so query as well as analysis both are
taken care by elastic search a one best
example of elastic search is here this
person wants to search a file all those
files in which the place is mentioned as
Dubai so as you can see on the screen
there are multiple files but it will
search across all those files where the
place is written as Dubai it is also
possible to aggregate the data by the
number of days like suppose if in case I
want to track down the files with the
place Dubai created based on number of
days I can very well do that with the
help of elastic search also since it
supports the geography so we can very
well track the files or I can very well
track the files based on the geography
and I can present it in the form of
dashboard that supports the geo tagging
so let us understand what are the
advantages of elastic search first of
all it is scalable by the term scalable
means it can be scalable across multiple
nodes so eventually you can start with a
single node or two or three nodes and if
in case your workload grows then in that
case you can scale across multiple nodes
so it is very easily scalable in terms
of scalability and in terms of the
performance it is really fast as
compared to other search engines which
are available another advantage I should
say of elastic search is it is
multilingual
another advantage of having elastic
search in place is whatever index which
are created or whatever you can say
schema schemas are not generally used in
the elastic search instead all the data
is stored in the form of documents so
whatever documents which are created
whatever information it's a document
oriented approach and the data is
presented in the form of a JSON format
so the benefit of having JSON format in
places it is a widely
did web format and we can integrate
several solution because it is able to
provide you the output in terms of the
Chasen format so you can use that output
to present it or to integrate it with
some other application in your
environment another advantage is it
supports auto completion and instant
search so there whenever you start
typing queries you will see that it do
supports the auto completion and last
but not least it is schema free because
it follows the document oriented
approach where instead of schemas and
tables we have documents where the data
is stored let's quickly go through the
installation so we will be going through
the installation of elasticsearch on a
Windows platform where you need to have
the java installed first of all so once
you install java the best place to check
if everything is running fine or not is
you have to execute a command in the
command prompt java - version it will
give you an output like this this means
that the Java is installed properly and
the environment variables are properly
set one thing we have to keep in mind is
Java version must be seven or more it
should not be less than seven so this is
something which you have to keep in mind
next thing is install the elasticsearch
zip file from the website so once you
will download the zip file from the
website you need to unzip the file and
you just have to go to the bin folder so
there will be a folder called bin where
you have to go and then you have to run
the elastic search dot bat file so this
is nothing but a standard Windows batch
file which contain the series of steps
which it will be performing behind the
scene so it is just like a window script
which is when you double click it it
gets executed and it will be executing
the tasks behind the scenes and
eventually help in bringing up the
elasticsearch daemon on your machine so
you will be getting such kind of an
output on your screen and we have to
wait for the elasticsearch to start so
now the question which will be coming on
to your mind is how do I get to know
whether the elasticsearch is
started or it is running or not so the
best place to check is open the browser
on the same machine you can type as
localhost colon 9 to double 0 so if it
will give you an output like this saying
the tagline that you know for search
this means that elasticsearch is
installed and it is running properly so
this is how you can check whether
elasticsearch daemon is running or not
next well for people who are installing
the elasticsearch on a Windows platform
that do locally we can make use of the
sense plug-in which can help us to write
queries and import the queries there are
two options to do that so this is an
approach which you have to follow when
you're elasticsearch is local install on
the machine but if in case the
elasticsearch is remote well what I will
be doing in my case is I have an
elasticsearch set up on my AWS cloud
environment and I will be accessing that
elastic search through the Cabana
dashboard and I will be accessing the
same sense tool through the Cabana
because Cabana latest version nowadays
support the sense as well so either way
you can do let's go to the basic
concepts so before we dive into elastic
search we need to have a few more core
concept we need to discuss a little bit
more concept about the elastic search so
basic concepts near-real-time this means
that the elastic search is so quick that
as soon as you put the data into the
elastic search it is all available to
work upon so elastic search is near
real-time search platform that there is
a slightly change in terms of time when
you index a document until the time it
becomes searchable so as soon as you
create an index or you upload a document
it becomes searchable as I said elastic
search is a distributed system is a
distributed environment I should say so
with distributed environment you can
create these applications across
multiple nodes in the form of a cluster
so cluster is nothing but it's a
collection of one or more nodes that
together holds the entire data it
provides the federated indexing
and search capabilities across all nodes
and is identified by a unique name so by
default it will take the unique name as
elasticsearch but if in case you want to
rename the cluster name you can do it by
making certain changes in the
configuration file node is nothing but
it's a single server which is
participating in the cluster so it's a
part of a cluster it stores data and
participates in the cluster indexing and
search capabilities now let's understand
what index is index is basically a
collection of documents with a similar
characteristic and it is identified by a
name so whenever we want to work upon a
collection of documents it is we define
the index on which we have to work so
you can consider it as an identification
of certain type of documents so we
categorize certain type of documents
into a category into a major category we
call it as index so you can have
multiple index across elasticsearch so
suppose I have certain data related to
movies so I will create an index of
movies and I will upload the data in the
movies index and whatever documents
which will be created will be the part
of that particular index so this is how
it goes
so an index is a collection of documents
with similar characteristic and it is
identified by name name is used to refer
to index when performing indexing search
update delete so whatever operation you
want to perform you have to define on
which index you want to perform the
operation let's understand what type is
type is nothing but it's a local
category partition of index whose
semantics is complete it is defined for
documents that have set of common fields
so type is nothing but it's a category
inside the index for partitioning of the
index so this is something which we will
see we can define one or more index type
in one or more type in your index
documents documents are nothing these
are the basic units of information and
it is expressed in the form of adjacent
format as I said and since this is a
JSON format it is an internet friendly
format
so you can very well fetch that
information and you can use it in your
tools or display it somewhere or the
other let's talk about what shards are
so suppose if in case shards are nothing
but elasticsearch it provides you the
ability to subdivide an index into
multiple pieces like suppose if I have
created an index of a larger size as
compared to my capacity which is there
on that particular elasticsearch node
what will actually happen
the elasticsearch will subdivide that
complete index into smaller parts which
are called as shards and these shards in
itself they are fully functional and
independent indexes that can be hosted
on any node within the cluster so
generally these nodes are distributed
across and we also configure the
replicas of these shots so if in case
someday our node fails you will always
have a persistent copy of data available
in your environment so elasticsearch
allow you to make one or more copies of
the index shards which are called
replica shards or replicas so let's now
find out the API convention in
elasticsearch so these are the API
convention the elasticsearch rest api
they accessed using the JSON over HTTP
so it's a restful api and it supports
HTTP and these are some of the
conventions which are used throughout
the rest api so we will be covering each
one of these one by one
for now let's name them as multiple
indices date math support in index name
common option or URL based access
control so let's talk about multiple
indices most
API support execution across multiple
indices so different notations can be
used to perform the operation on
multiple indices so suppose if in case
you want to perform an operation across
multiple indexes then in that case what
you can do is you can make use of
certain expressions or certain you know
what we can say operators like comma
wildcard notations or some kind of
string parameters so these are the thing
three things which which is mentioned
here like comma separated notation
so if in case you want to separate the
indices based on commas you can very
well do that if in case you want to have
a search make the search or you want to
perform an operation using the wild-card
notation so we can very well do that or
if in case you want to specify certain
string parameter like ignore allow new
indexes expand wildcards these are some
of the string parameters which we can
use in our queries so next is elastic
search like to use search indexes
according to date and time you need to
specify the date and time in the
specific format so it's all the date and
time so whenever you want to search an
index according to date and time you
have to specify in in this format these
are some set of common operations for
all the rest based api's so some of the
operations which we will be using it
like pretty results human readable so
pretty results means it will give you an
output in the form of a beautiful not
beautiful but it will give you a more
presentable output human readable output
is another form of presentable output
date mat respond filters flat settings
parameters no values so these are some
of the options which we can use with the
rest api s-- URL based access control so
user can also use a proxy with the URL
based access control to secure the
access of elastic search indexes so we
can also make use of the proxies so user
has an option of specifying an index in
the URL and on each individual request
within the request body for some
requests like multi search multi get or
bulk so this is done for secure access
where we are keeping a proxy we are
using a proxy which is further having a
URL based access and we can make use of
that proxy to query the elastic search
so let's talk about the elastic search
api's these are the types of api's which
we have in elastic search the document
api the
search API the aggregation API the
cluster API and last but not least the
index API so let's quickly see what
these are so if you would ask me what
these api's are I would like to give you
a little bit of information about what
these are let me go back to the slide so
if you would ask me what document API is
our document API is these are those aps
that perform the operation on the
document level so if in case you want to
perform some operation the document
level you have to make use of the
document appears you can very well do
that with the help of document api's
likewise the Search API it is used for
search across indexes and all types
likewise aggregation is used for
aggregation if I talk about what index
API do it perform operation at the index
level so and cluster API so with the
help of cluster API you can perform the
operation at the cluster level so let's
see what document api's are they are
further categorized into two types
single API document and multiple API
document so these are the categories so
if I say here
index API gate API update and delete
these are the four api's which come as a
single document API so if in case you
want to perform an operation on a single
document you make use of these API is
for query for if in case you want to
make use of querying across multiple
documents we make use of the multiple
document API like multi gate API bulk
API if in case you want to bulk delete
if in case you want to do bulk update if
in case you want to to reindex in these
are some of the queries which are
implemented across bulk so we will be
doing this index api for creating a
document so if you would see here this
query
put-put means see these are some of the
keywords which we use get put post
delete in making the rest api calls so
likewise here put is the method which is
used so slash palest is the name of the
index and the song is the name of the
document and likewise 6 is the ID
so if in case let me show you these in
my lab environment so first of all let
me give you an idea about what this
particular query is doing this
particular query is so what we are doing
is we are putting we are importing this
document into the index so the document
will contain information like title
artist album and year so I have this
Cabana dashboard open
so this is the Indy dashboard this is
the dev tool which you can make use of
for making the queries so the same thing
is what I have mentioned here so what
this command is doing this is creating
so first of all I may have this my
playlist index already so let me show
you get
so I have already created this index so
if in case I want to import the data
into this index like suppose I'm using
seven and title let's keep the song as
what's wrong
my holiday I'm not sure if this this is
a song or not but - because right now
it's nothing is coming into my mind
artist let it be me
let it be Linkin Park
here let it be 2012 or let's keep it as
2011 so if you get this output as
created true this means that this
particular document is created so I'll
go back to my slide now so the same
thing is done here so with the help of
port I am creating the document so if in
case I want to read a document I'll make
use of the get method so I'll show you
this
so if you would get this output this
means that this is used for reading the
document which I created so with the
document IDs 6 this is the document
which is created if in case I want to
read the document 7 so this is the ID 7
make sense so this is used for reading
the document
likewise if in case you want to update a
document so for updating a document the
same thing you use the put and you
should be sure about the index name as
well as the document ID so based on that
you can add the parameters so if in case
I will add another parameter here
location
Deli
pose
so it gives me the successful one this
means that the location is added so if
in case I want to get
so location is added here in the
document so this is how we perform these
operations
likewise if in case you want do you have
a delete API if in case you want to
delete a document you can do it
similar way so for deleting a document
all you need to do is to document ID and
you can very well delete it from here
so let me show you that as well
delete le te let's keep as document ID
number seven so if in case I want to
delete it
successful one means this has been
deleted so these were the operations now
let's go to the Search API so Search API
using a search appear you can extend a
search query and get back the search
hits that matches the query so search as
for the name says it is used for getting
the results from a set of data so it can
be a multi index it can be multi type or
it can be based on here I search so
let's talk about what multi index is you
can search a document presented in all
the indexes or some specific index okay
so if in case you want to search across
all the index all the documents which
are place you want to search for a
particular document across all the
indexes you can do that with the help of
this you can search all the documents in
the index across all type or some
specific type so this is what multi type
do and there are some set of parameters
which you can pass in your search
operation in the URI so like these are
some of the parameters which you can
pass like Q lenient field sort timeout
terminate after from size etc so here is
the example so here what we are doing is
we are fetching the information we are
reading a document in fact we are
searching a document which contain year
as 2011 so if you see the output here it
will show you here as 2011 so this is
what Search API is to
right so let's move on to aggregations
so what are aggressions these are
nothing but if in case you want to
collect the data and you want to work
upon multiple datasets we make use of
the aggregation so aggregation it
collect all the data which is selected
by a search query so this framework
consists of many building blocks so
these building blocks are known as
aggregators which help in building the
complex summaries of data so if you
would see below this is the syntax of
the aggregation so these are the
aggregator types bucket metric matrix
and last but not least the pipeline so
we'll see so these are the different
types of aggregation I have some
information regarding aggregation let me
see if I can show you some a creation
stuff so here let me give you a
background we will be working on a
different data set for aggregation I
will be working on this bank data set so
it contains lot of documents which I
will be working on so this is something
which I have already uploaded so let me
show you some queries so I have written
some queries and I will
do quick in order to complete it in less
time so if you see this query I will be
running this query across multiple
documents across multiple indexes in
fact and whatever document matches the
first name Rubina it will give me the
output so if you would see here there is
an index called bank with the ID as 145
and it has first name as Rubina so if
you see hits here so total number of
hits is 1 so it is able to provide you
only one results so if you would see
here the match is the query which we are
using here query first name as Romina
likewise I have one more example which I
can show you so this is same working on
the bank data so I'll just quickly add
it here so now what this query is doing
this query is actually a range query
which is getting me the documents for
the range of balance between forty four
thousand nine hundred and ninety nine
and somewhere around 90 lakhs
so GTE means greater than equal to Lt
means less than equal to so let's see
here I'm getting 94 search results out
of which they are giving me the balance
as this alright
so likewise there are several queries
which you can execute let's jump to the
slide again what I index AP is index a
PS we are responsible for managing all
the expect of indexes like settings
aliases mapping index templates and all
those stuff so these are some of the
keywords which we use in the API we can
create the index so these operations
which we can do we can delete the index
we can get the index we can open or
close the index we can get the list of
the index templates or aliases or
different stuff let's talk about the
cluster API cluster API it is used for
getting the information over the cluster
and its node and making changes in them
so as I said this is a distributed
environment where we have lot of nodes
and this elastic search environment can
be a multi node deployment as well so in
this case the cluster API give us the
information with respect to the cluster
so if in case I can show you in my
deployment
cluster
help
why is it not taking anyways
so if you would see here I've ran this
cluster send the communication to the
cluster API and I got this response with
respect to my cluster where I have a
cluster named as elasticsearch so I
didn't made any changes in the cluster
name and the number of nodes I am using
here is 1 so I have a cluster of only
one node so by default elasticsearch
will be installed in the cluster mode
only so irrespective of whether you are
using a standalone installation or a
distributed installation there will
always be a one cluster and that will be
created by default and your nodes will
be a part of that cluster so it will
give you some more information like
shards active shards number of data
nodes and all those stuff so not even
cluster health you have cluster state
cluster stats
pending cluster tasks cluster reroute
node stats node hot threads these are
some of the commands which you can
execute to get more information so let's
find out how query DSL is used to define
queries so query DSL is nothing but it's
a kind of domain-specific language which
we generally use in our environment to
perform operations so whatever query is
we write it in this DSL
so DSL is nothing but it's a
domain-specific language so elastic
sides provide a full query DSL based on
Jason to define queries query DSL is an
AST of queries consisting of two type of
clauses so there are two type of clauses
majorly the leaf query clause and the
compound query clause so if I talk about
the leaf query clause it looked for a
particular value in a particular field
so for example so whatever with the help
of this if in case we are finding a
particular value like suppose I give you
an example like match term range or
queries so that is what leaf query do if
I talk about the compound query compound
query clause it combines the leaf query
clause and other query Clause to form a
compound queries so it is more or less
like a leaf or a branch structure
Leif will only be working on a
particular value whereas branch will be
a combination of leaf structure as well
as the multiple leaf structure should
say so let's find out how documents are
mapped in the elastic search so mapping
is basically a process of defining how a
document and the field that it contains
are stored and index so there are
different mapping types as well as
different field types like meta field as
well as the field or property types so
if in case if I talk about the field
type so there can be multiple field type
like geo data or specific data type or
if it is a complex query so you'll have
complex data type or even a core data
type so these are just the categories of
different field data types so these are
some of the mapping parameters which we
have like which we can use in our
queries like boost analyzer copy to geo
hash if in case you want you're working
on geo hash for formatting so if in case
you want to make the output presentable
likewise there are some more like
include in all index options fields
norms null values etc so let's find out
how the data is configured so the
analysis plays a very important role
with respect to how the data is actually
stored so during the search operation
when a query is processed the content in
the index is analyzed by a analysis
module so analysis module contains
analyzer tokenizer token filter and
character field so the process of
converting a text into a token and terms
which are added to an inverted index for
search is called analysis and it is done
by the help of an analyzer so analyzer
can be inbuilt or it can be like custom
analyzer so analyzer converts D
a filled-in to tokens and with the help
of token filters we can further perform
the operations so I'll give you an
example of this so there can be
different analyzer on based of which we
can perform the operation where is it ok
so what I'll do
I'll write the simple query
analyze and ily said II I don't know why
it is not taking the completion maybe
some browser issue so
so I'll type the analyzer as whitespace
so I'll use the whitespace analyzer
de SP AC e right this should be the
correct spelling and I'll add a text to
be work upon which will be like suppose
elastic search is the heart of elastic
stack
actually my browser is misbehaving so
let me reload the stuff
so what do this analyzer will do this
will take out the whitespace from this
particular sentence so wherever there
will be a white space it will divide
this particular sentence into 1 2 3 4 5
6 7 7 different tokens so this is what
the analyzer do so the content in any
index so I mean there can be different
kind of analyzers there can be stopped
analyzer here so what do stop analyzer
to stop analyzer is basically used for
stopping the particular so if in case
you have certain keywords which are
being used again and again like the a
are so these are some of the keywords
which are used again and again so what
do stop analyzer do it will remove all
those keywords and it will present the
rest of the tokens rest of the terms in
the form of tokens so this is what the
analyzer do so let's find out modules
and the different type of modules in
elasticsearch so different type of
modules
there are basically two kind of modules
one is the static as well as the dynamic
so elasticsearch is composed of number
of modules which are mainly responsible
for its functionality to different type
of settings which we have like static as
well as the dynamic so with respect to
the static settings they need to be
configured in the yml file the
configuration file before starting the
elasticsearch so certain modules which
are there by default those are basically
dynamic modules but if in case certain
modules which you have to mention in the
configuration file that means the
elasticsearch toward yml file those are
categorized as static modules so these
are the module types which we have we
have made a pyramid so you can quickly
have a look so that's all for today for
this webinar session please do not
forget to share or like the youtube
channel
this particular video and thank you very
much for today's webinar session for
joining in bye-bye I hope you enjoyed
listening to this video please be kind
enough to like it and you can comment
any of your doubts and queries and we
will reply to them at the earliest do
look out for more videos in our playlist
and subscribe to our at Eureka channel
to learn more happy learning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>