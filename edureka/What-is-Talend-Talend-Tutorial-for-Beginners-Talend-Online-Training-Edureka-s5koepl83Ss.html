<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What is Talend | Talend Tutorial for Beginners | Talend Online Training | Edureka | Coder Coacher - Coaching Coders</title><meta content="What is Talend | Talend Tutorial for Beginners | Talend Online Training | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>What is Talend | Talend Tutorial for Beginners | Talend Online Training | Edureka</b></h2><h5 class="post__date">2018-03-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/s5koepl83Ss" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone this is Chester on behalf
of Eddie Rica so today we are here to
talk about what is talent as I've
already seen series of information by
our YouTube videos on talent there is
one more video for you to get deep
understanding on what is talent so let's
get in so that's enough for this webinar
is what is talent understand why talent
is needed how it came into picture and
then what was the evolution of talent
when it was started but which product
they started and till now which all
products are available everything will
be told in no third part of this video
and we have lot of use cases which helps
you to understand where all talent is a
right fit and for your use cases where
talent can help and how optimised it is
and how robust it is you understand
those things and then at the end of this
webinar we are going to give you a demo
which will introduce you to the
capabilities of talent and you can
understand the powerfulness of the
talent right so let's get in and
understand what is talent so talent as
you all know it is also a company and
the product name is also a talent so
talent is nothing but an open source
software for all your ETL needs so it is
also a vendor as I said it is
headquartered at Redwood City California
so software and services provided by
talent are categorized into all these
areas right you have a talent data
integration software we have enterprise
application integration soft face we
have a data management office and we
have big data management sock this all
of these software's are provided by
talent for you for all these needs right
so to summarize talent is also a vendor
and it also provides software for all
your data ETL needs okay so talent
impose the organization's to immediately
turn data into business insights so
today data management is our problem
everywhere a huge data and then times
the constraint all those things you
be saying in your day-to-day life I
believe right and what does talent
offers for your problems see at least
seven times faster so take a baseline of
any of the it will do it in the market
and it is Java based tool and you can
literally come to a conclusion that it
is so so fast than anyone else in the
market and then coming to cost so you
provide the solutions using talent and
you will have to buy the product and
whether it is a word for all your use
cases or whether it is giving solution
for all your problems even then it is
economic so it uses one-fifth of the
expense you are spending on it right and
it is future proof the one of the key
selling points of talent till late and
again
our java based tool and a drag-and-drop
user interface and the design what you
making ETL as you know design change is
very costly meteor so all your designs
are future proof in talent that provides
you all that what is going to be
existing till the end right
and then unified platform so you have as
I said in the previous slide it is all
integrated so you name Big Data IO name
you know enterprise solutions everything
is available under one unified platform
that is Stalag for you so let's
understand the evolution of talent so
what was first and how it evolved what
was the need everything so evolution of
talent he was something like this in
2006 the data integration the first
version of data integration was launched
and then you know people started buying
it using it and since it was open-source
many of them give a try and then with
that success in 2008 they launched data
quality and today data quality is very
much used we have all day to day data
quality problems so what we praise you
know data profiling was required to go
ahead with any of your retail projects
to understand how much of your data is
good so for such needs they launched
data quality and then again they started
growing and in 2010 they launched ma
to data management so as you all know
after ETL they got success in ETL the
next step is obviously master data
management and they made it really
really easy and really really
user-friendly so that was data
management and 2010 and in 2011 the
launched application integration and in
12 bit data so big data is very closely
coupled with talent software and we have
all the connectors whichever big data
are you naming and talent can connect to
it and also write MapReduce for you so
we'll be understanding about it in our
another video of talent Big Data you can
also watch that and in 2013 Hadoop 2.0
whatever you know evolution happened in
Big Data is immediately has come back to
talent and they provide all the new
options provided there in your talent as
well and in 2015 we got into spark and
cloud integration so even this is a very
key selling point you know spark jobs in
Thailand are very user friendly and very
easy to generate and main thing is
performance when it comes to performance
spark and cloud integration jobs are
very good very optimized and very
powerful in 2016 with all these
learnings you know data preparation see
you I would call it you know stop the
problems being enter your system at the
source something like that so the people
or the customer or the data producers
for them it makes a lot of meaning
wherein you can award free of the data
issues to get into your system itself
from data preparations so it helps you
do I know reiterate your data sets and
validate them and then pass it on to
your ideal systems so rate of
preparation is also one of the good
selling products of talent and
ultimately very recently there was
introduction of data fabric which is
kind of a superset wherein most of the
qualities or the features which we saw
before 2017
they have been combined in data fabric
with all these options and that's a one
tool so why we have a subset or a
superset is it's all license dependent
so if you're not doing anything with
spark and cloud or something like that
you can only buy the data integration
software and you
you're working with only big data
related thing then you would only go and
buy Talent big data something like that
so the recent release is your data
fabric and talent so till now these are
the products which has been delivered by
talent and they are doing very good
really good in the market and you can
yourself understand within this small
period of time how many products have
come up and in the Gartner chart
they are talent standing it's in the
challengers quadrant in the leaders
quadrant it has morote or very quickly
from 2006 to 2007 team right so this is
how talent has a world so as I said now
and also we saw the evolution with all
the products so we'll have segregation
of them in this light that is talent
product so talent products for example
the platforms wherein they support its
in the first section wherein they say
big data there are management master
data management and price integration
I did a services hybrid cloud so though
few of them are not mentioned in the
evolution in evolution only the major
products and the timeline have mentioned
and there are many other products which
talent has come up with so all these
products comes under the talent
platforms and in the enterprise versions
there is a licensed versions we have Big
Data talent integration and Talent ESP
and for the open source we have MDM that
is done in Opel studio for MDM data
integration big data data quality ESB
and BPM so you can just go to Tallinn
website download the open studio freeway
and try it out well do a POC on whatever
problem you're facing when a talent can
provide the solution for you just have a
try and then if you're happy you can
propose to your client and get the
Enterprise version of talent for all
your needs right so these are the wide
range of talent products which has
talent provided and is in market right
now so what are the features of talent
product so why is talent you know very
fast growing and very user friendly
right so what has made or which are the
futures which is very unique
or which has made it to grow this much
big so one is native code as you know
talent isn't very user-friendly GA it
has and you just drag and drop the
components you require and you configure
them but then whatever you do in the
front end we have that cool generated in
the backend the Java code in the native
code which is generated and that code
will be compiled and that will be
executed as your job right so your
native code is always available there
and that's how it's very easy for you to
understand it so better collaboration so
and when we say better collaboration as
I said any big data
you name it as already we have the
components we are they're tightly
coupled with talent software so that
collaboration is really good whatever
you name whichever ERP you name we have
the components you want to connect to a
city systems you order an FTP or whatnot
so all collaboration is done and with
all customizations so you name our
components for Oracle DB and what all
options are available
you know sequencing or you know indexing
all those options which are differing in
each of the databases all the custom
options are also available in those
components so we have a Buttle
collaboration for each and everything
even a small detail has been given
importance faster design so for any
detail project you choose talent as a
solution you can really design them fast
and as I said it is future-proof so your
designs and this concept of dynamic
schemas in enterprise version of talent
so you do not have to worry about that
section as well so you can read your
files with dynamic schema all the stuff
and design as such an overall ETL design
you can really do it very fast up and
very optimized design can be delivered
with talent and what is this early
cleansing so as I said there is also
software for you know data quality and
you can profile your data before you get
into ETL and when you are getting into
ETL you can get to know what all the
profiling you know options were
available like there were so many nerves
or there were so many - which was not
required so you get all these readings
from your profiling thing and then you
can get a sign-off from your data owner
and you can early cleanse them
for even you're going to apply the
business rules on them and that can be
very optimized just imagine a lot of
data we're in data where you are using
for joining or for some condition you
are putting that for filtering or
something like that and that has some
hyphens and spaces or something like
that imagine what would be the cost to
correct them at the point where you are
really dealing with very large data so
Holly cleansing is really helpful and it
is a width tool which you can make use
of to avoid the costly things at the end
right so efficient management you have
very efficient management in talent like
you can get your workflows monitor
ations all those stuffs like what
happened starting from the point where
the job has failed the logs is very
customizable however you want to do all
those things so when job fails or your
workflow path or whatever monitoring you
have to do everything everything which
comes under management of a job or
management of the design is very easy
and efficient in talent right and
scalability obviously it is very easy
scaleable so you can go in and scale up
your jobs which are already developed it
can replicate in your jobs run it on a
different servers build a job and you
scale them up you get most of us have
them into it and you increase the
optimizations or bring down the job
running time all those things are very
easy very user friendly and that's how
it is very scalable and real-time
statistics yeah in our demo also we
would like to show you whenever you are
joining the ETL jobs so we have the
real-time statistics going on being
displayed on the job and if the job is
running in Enterprise version we have
something called admin center where then
you can monitor all the logs you can see
the statistics what is happening how
many rows have been passed fail in the
very first step of the job itself will
come to know the expected numbers in
that step that particular step whether
it is right or wrong whether it was
expected or not so that real-time
statistics also is available so all
these features put together makes Talent
a very good ETL tool for anyone who is
in need of any ETL solutions right
so these are the features of Dalit now
coming to talent in modern data
architecture so this is how they are
trying to put so if you can observe here
in dev and data tools they have
mentioned about their own dual talent
okay this is one of the information
which we can find it in Talent website
as well so we have today different
source systems the heterogeneous saw
systems where in one of your client will
give you an excel another one will give
you an XML whatever the existing so
systems may be okay and emerging will be
sort of like unstructured data your
other related data which are not so
structured or your data which is not in
proper format to go ahead for migration
or something like that so all your
existing so systems and where you want
to put them like Taylor systems your has
say P or your Hardin works whatever it
is and then which applications uses it
you know your reporting
layer something like that so baw and all
those reporting I would say all the
applications what they have mentioned so
all these are data wherein over there so
you use the infrastructure and you get
in the data over there so we have
operation tools you know there are data
or system center or OpenStack so which
works on operational you know needs of
it and then with talent or whatever the
tool present over here which is studio
or dotnet or Java you can get the data
and that's where they are linking to
both to your data system and
applications so how talent makes your
life easy so it can read from your own
heterogeneous so systems it has close
connections with all your Hadoop and
whorin works so all the sandbox
providers are tightly coupled with
talent and also if you want the manual
setup of Hadoop even that is supported
and then the structure which is needed
for your reporting can be easily assured
with talent ok so whatever they are
looking at the aggregations or the
incremental thing which they want to
show it in your you know reporting layer
all those stuff and every layer talent
has a picture to play and that's how
they are telling in the modern data
architecture where all talent can help
you and this can be your existing so
system where you can just put in your
current design and check
whether we're talent can help you so
this is Stalin in modern data
architecture so having the knowledge of
what is Stalin what are the different
products talent has delivered and for
what use case which one you have to
choose so that is the point where we
will have to see what are the real-life
use cases and how talent has helped in
that use case so let's get in and get to
know what other real-life use cases what
director
whenever talent came into picture so in
2006 or in that timeline we're in Virgin
Mobile was one of the vendor who came
into telecommunications
so for that offering a simple innovative
and complete solution light Virgin
Mobile France which is a fast-growing
mobile virtual network operator that one
of time so 94% of their customers report
that they were happy or very happy with
the customer service launched in United
Kingdom by Sir Richard Branson ok Virgin
Mobile also has offices in Australia
Canada France and India and United
States or hundred million consumers in
the world benefits from its services
right so for this client they was in
Mobile so what is that use case which
had what was a problem statement how and
how it was solved let us see that so
use Kies was operational reporting
customer service so there is a use case
category and what was the challenge
there is creating new mobile packages
with better fitting customer needs and
dealing with profitability so as we know
today there's a lot of scope for
telecommunication wherein there is lot
of vendors and hell lot of competitions
are available in between them right so
what is the data we have to analyze so
we have so much of millions and millions
of users you will have to understand
what is their priorities where are their
expectations and coming to the prices so
how we can give them better packages in
the network so that they stay with you
and they continue to stay with you with
you know referring others as well so
that was a challenge richer Virgin
Mobile faced so for analyzing this data
and which category how much customers
are coming what is their expectations
all those stuff so this was a very
complex thing which has to be handled
with a large data set right so what were
the results
so five million innovative tickets were
they process through Talent integrated
systems so every time we are receiving
that the case we are going to read
through it understand what is the
customers feedback or what is the
expectation whether a different package
has been provided for him whether he
would continue with the Virgin Mobile or
what is it an expectation from Virgin
Mobile all those stuff right access to
source code enables internal control
over information system so talent can
get to know what is the history of the
customer so how much he is spending on
data how much is spending calls on local
calls
how much is spending on international
calls something like that so with
integration with MySQL fits into
existing infrastructure and it is highly
customizable so having this solution
promoted term so we took the data into
MySQL thing and we have used talent
capabilities to aggregate it or get the
results on what is the expectations of
this customer and they have provided the
results for them right so similarly with
that use case we have with another
retail and e-commerce that is Group one
so launched in November 2008 in Chicago
Groupon has since grown to over thousand
regional offices but more than ten
thousand employees in 48 countries and
features thousands of deals every day so
most of us will be aware of this will be
getting promotion emails from them will
be seeing some ads related to Groupon
right the key to group one success
lysine unbeatable prices with top-rated
local business partners so this is about
the vendor or the client so let's see
what was the problem
then what is the use case so use kisses
customer experience so aligning
marketing activities more closely with
customer preferences which is a sheer
volume data okay so you know Groupon
like how many promotional emails comes
in and they have a large customer base
the challenge itself is that aligning
marketing activities more
closely with customer preferences okay
so that was the problem
so 1tb of raw data processed in real
time and stored every day so it's not
only 1tb its 1tb per day so imagine that
volume when you go with monthly and
yearly reports right so thousand data
integration jobs were run every day
using talent detail process so every
five minutes talent objects the data
warehouse with OLTP system data so you
can just imagine the time every five
minutes means in the next five minutes
we have to load the next set of data so
imagine the powerfulness of talent where
it can handle all those stuffs within
five minutes right so 1 TB of data and a
business rules upon it and aggregations
and then loading all those stuff for
this use case they have achieved of
course with different hardware
capabilities which after mention so this
is how talent has provided solution for
Groupon use case and another use case in
you know industry of media and
entertainment is for orange
so since June 2006 orange has been the
leading group brand in internet
television and mobile services most of
its markets right it also provides
telecommunication services to business
worldwide under the orange business
services brand right so what was the use
case and challenge so use cases sales
commissions and what is challenge
improving revenue sharing with vendor
partners by analyzing the sales data so
you get the sales data every time you'll
have to analyze that and improve is
revenue sharing okay so to doesn't
report from talent Fred data warehouse
so all the data related to reports has
been fed from talent enable companies to
analyze its business in detail so one
training session is all developers
needed to learn talent so that is what
they have mentioned and the success
story the learning curve for talent is
very less so anyone who is fresh or from
an ETL background both of them it needs
very less time to understand this tool
and work on it
you know productive from day one it's
very less time so existing process
remain in place adopting talent did not
require altering the process so this is
one more key point where in existing
process were there only the data fit to
the
arrows which needed by the report was
done from talent so all this way of
providing the data made them improve the
revenue sharing with vendor partners by
analyzing all the sales data which was
provided by talent so this made a
difference for them for improving the
revenue sharing right
so all these use cases you'd have
understood ok talent data integration
will help in some use case when there is
a large data Talent big data will help
in so if you want to maintain the
customer base we will have to go for MDM
wherein you know customer relation
management we have to put it on master
data so we have different tools you know
in talent to support different use cases
we will have a short demo on talent open
studio and we will showcase one simple
use case and with that use case you will
understand how easy is to develop a
talent jobs and to maintain it and how
optimize the solutions are in talent
right so let's see a demo on talent so
before we get into the demo let me show
you how to download talent and after
download how it will be available for
installation so once you go to talent
calm and then you download the required
product Slee for example we are using
talent open studio for data integration
so it's quite simple you'll have to just
log into talent code and this will be
your welcome page and you will have a
direct link for downloads of all the
products so you'll have to just go to
download section and then find the right
product which you want to download in
our case it is data integration so we
can choose that brought it and it's just
one click for the download and even for
installation it is very easy I'll show
you that steps as well so you just have
to come to data integration which we are
going to try now and just click on this
download free tool right so once you do
that a zip file will be downloaded ok so
it would look something like this so
talent Big Data is one more product as
we already know we have seen in the
slides so it will also contain
everything which is there in data
integration plus Big Data component so
you can
as well download this tool which is a
superset which contains big data plus
data integration right so that is what I
have done so I have downloaded TOS big
data so it will be in a zip format you
will have to just unzip it and just
launch the binaries which you need like
if it's you are using Linux system it is
dot as such file and if you are using a
Windows it is dot exe file so all of
them will be available in single
download you'll have to just launch the
one which is required for you so in my
case I'm using Linus operating system
which is 64-bit so I would choose this
binaries I'll execute it the only
requirement which Stalin needs as a
prerequisite is a Java installation
that's it
and your Java path has to be set and
this download and launching this exe is
that's all you need for your ETL needs
right quite simple so when I launch this
talent tool it will show up a screen
like the opening screen so we'll have to
create a project before you enter to the
talent tool right so let's create a new
project so I'll click on create new
project and I'll tell Y talent demo so
this is what is my project name and I
just say create it will create a project
for me and I say finish it will open up
the tool for me for this project I can
have multiple projects inside one
workspace so workspace is nothing but a
complete talent dependent all the files
will be loaded into that workflow which
is required for your project right so
that workspace is related to your talent
work whatever it is generated at back in
whatever files we do everything will go
into our workspace so one installation
like one Talent workspace can be
maintained and you can also maintain
multiple workspace but at a time you can
only use one workspace in Tallaght so
now it is first time my project is
loading so it is loading all the
required plugins jaws libraries set
emitters whatever is required for talent
is being loaded at the packet in between
my project is getting loaded let me also
give you an insight of what use case are
we taking - just to give you a glimpse
of talent and its capability
so what are we using what is a use case
you are trying to build here I will give
you a walkthrough for that so now my
talent for my project has been loaded I
will get a welcome page like this I can
close this and I'll get all related
talent windows for my project right so
this is my talent ETL tool and this
section is called repository where in
all my er diagrams I can have it over
here I can create here diagrams over you
I can create my job so I can have my
variables loaded I can maintain my
metadata I can maintain my external core
over here anything in Java I have to
write an integrator I can do it here so
all these things comes under the
positive for me and then this section is
called outline and code where a
particular part of code can be visible
and this section is the work design
section wherein I can drag and drop the
components and I can make my ETL jobs
over here and this section is called job
section where all job related
information will pop up once I create
the job all these windows will be
activated so let me first create the job
so that it will be more meaningful to
explain those windows so let me name it
as J under school first job Y talent
demo and you can give purpose in this
use case we are taking one football
players related information which is a
very large data and we are trying to do
some analysis of which club has more
members or who has the top players
something like that so I'll explain you
that you squeeze so I can just say
demonstrate
talent capability something like that so
same thing I'll put it to our
description and now I have all my
mandatory fields filled
I say finish now a new job will be
created for me and all other windows
which were blank previously will get
populated with the related values now
you can observe so I have my jobs and a
job design and there is all related
thing whatever I gave here purpose and
when it was created what is a version in
job window and we have all the
components listed in palette we have
wide range of components in Tallin each
of them are organized under each
headings like big data if you going will
have all the big data things when that
related components will be available
over here right so that is palette check
and drag and drop components from you
design your retail jobs and have
solution for your requirement right so
now let me go and explain the use case
which you're trying to do so we have one
input file v4 player details dot CSV
okay let me open this so there's nothing
but a complete details about all the
football players or FIFA players and
what all information we have it in this
file let us have a look so it's a really
big file so it's just still loading we
have large data answer this
so you can see over here we have the ID
we have the name of the player full name
which club they are playing to what is
the club logo and no haha what is the
height weight all those stuff and what
are their ratings what is their plus
point all those stuff like skill moves
weak foot no ratings average all those
stuff we have all these details for all
the football players so now with this
detail somebody if our association would
like to know which club has good players
or which club has more number of players
which would help them in analyzing whom
they have to approach for what and which
leaks are having the best players and
who is the best player and under this
age how many players are there so all
this information would be needed for few
decisions to be taken at the FIFA
associations so for this we'll try to
give some solution let us consider
somebody's looking at which club has how
many players and they want it in
descending order or ascending order and
then somebody would like to only have
all the players list who are belonging
to say for example French League or the
Spanish premium division or something
like that
premier Edition or something like that
whatever be the league name so they want
all the players under Dutch league so
let us choose this to use case one is
which League has or which club has how
many players that would be the one case
the second case would be for certain
leaks say for example Spanish Rimmer our
division and our French Ligue 1 we would
like to filter out all the players who
belong to that Lea and put it in a
separate file and that file would be
delivered to some requirement ok so
let's take these two use cases and try
to provide solution in talent for this
ok so first up in my talent would be how
will I read this file and this file is
quite huge file and it has lot of
columns to be right so manually doing is
a very impossible job right it's also
not optimal
what would talent offer me for this so
talent has a section core metadata where
I can provide this file and talent
itself reached the file and it decides
the datatype based on the data over
there and it will provide for review for
you we can have a review if you want to
change the data type length or anything
else you can do that and import the
metadata so I'll show you how so I am
using a delimited file that's why I come
in to file delimited under metadata and
then I right click on this file
delimited and I say create file
delimited and this is all metadata so I
would name it as metadata for FIFA
something like this well I say next I'll
have to just provide this file so FIFA
Player details and then what is the
delimiter so next step would be that so
the delimiter is comma here and I have a
header in the first line so I can say
set header row as column names and then
I would like to refresh the preview so
with this different fields operator and
header row settings so how does my data
look like so it will show me a preview
first and then I can proceed to create
the metadata so it has created this you
can see the first row has been kept as
the header and then now let me go to
next so it has listed on all the field
names along with the data types so right
now it has predicted all the data types
properly so integers for ID name string
and all the other stuff so I say finish
by doing this simple three to four steps
I am able to get the structure of that
file without any problem so I can get in
this metadata into my job as a component
and I can use it so everything will be
predefined so I can see now I am trying
to read it delimited file so in Tallin
the components will be named something
like this it starts with T and what am I
reading I am reading file what kind of
file is it it is input file so what is
the format delimited so why do you file
input D limb something like that if I
type in I'll get all the components
related to that so I have a component D
file input delimited reach the file row
by row so this is all I need so I just
drag-and-drop this tea
in put delimited component right and if
I double-click on this under the
component window I get all the
attributes which I have to fill in so
that I can tell this component which
file to read what is the row separator
what is a field separator like that okay
but now since I already you know created
a metadata over there I can just tell
the property type here as repository and
I can choose whatever metadata have
created else it would be manual as you
are seeing already it should be in
built-in and I should manually give the
file name I should manually key what is
the row separator field separator I
should manually come and tell here
header is one so rather than that since
I have already created it I'll go to
repository and I'll just choose this
file delimited so by selecting
repository all the values are
pre-populated here so I don't need to
again go and fill in and also if it was
manual I should have given the schema
manually but now since it is a
repository even schema would be
populated along with it so now I have
schema I have the file name I have all
the related fields to be calculated over
here so I can certainly read this file
without any problem right so my first
step of my use case is to read this file
so that I have completed but I had two
cases one cases to get to know how many
players are there in each of the club or
a league and the second use case was for
particular two leaks will separate out
all the players so I need the same data
at two places okay
so rather than reading the file two
times I can replicate the data coming
out of one component so talent provides
a component called T replicate I can
just even type inside the work area to
get the components as well right so I
can take T replication component and I
can give output from my T file input D
limited to T replicate so there are two
sections in each of the components which
reads or writes so every time when I say
row I will have some one two depending
on the nature of the component will have
the row types these are called row types
so main usually carries the data reject
carries the data which will not satisfy
the few of the conditions which we give
that is a little advanced topic and I
treat goes in row by row for each row if
you have to do a set of operations then
we will go with I trade operation for
our use case I just have to read the
file and get the data so I will go with
main and I will connect it to T
replicate so it will read the file and
it gives all the rows of that file to
this component and as I said the nature
of T replicate is two as you see the
design of this component one input and
many outputs that's how it looks like
right one arrow and three arrows coming
out of it so it can take one input and
give same outputs many times so I can
give it to another component from T
replicate which will just propagate the
same data to another one so our first
use case was to get to know how many
players are there in each of the leaks
right so what I'll do I'll take an
aggregation component I will have to
group them right so talent provides an T
aggregate row component so I'll take
this component and from T replicate I
will give the main row for this okay and
in T aggregation all the schema whatever
you hear in the left hand side that is
in the file which I'm reading I don't
need that I just need you know what is
the league name which I am trying to
group them up so I'll just choose that
I'll take the leak and then I'll create
one more column here to hold my
aggregation value I'll say number of
players and I'll make this type as
integer so these are the only two
columns which I need for my aggregation
what is the league name in that league
how many players are there that is what
the output I am looking for right so
this output will be given by my
aggregator row but I should tell what
column I am grouping by I am grouping by
with the league and then for number of
players what is the output column and
what should be the operation so in
number of players I am having so many
our aggregation functions available here
for me it is count where I have to count
the number of players so I can just tell
any of this name of the player or
whatever it is so I can just count
number of players in this league so this
will provide me the output of how many
players are there in the lead but then
after this they need the data in
ascending or descending format like
which has the highest players has to
come up the first the league which has
highest clear should be in the first row
and the league which has the lowest
player should be in the last row right
so I just need to sort them so I have a
component in Thailand further so T sort
so it is all psychologically whatever
you want to search just type in that
functionality or type in that need you
will get a component for that if it is
available so I have T sort row so
whatever output comes from again row and
mean I am giving it to T sort row and I
am telling on which column do you want
to sort it right I need to sort on
number of players which is a number and
I wanted a descending order so this is
what my output will be provided by T
sort ways my final output for case one
right so let me hold that value in
either I can print it on the console or
I can write it to a file right so let me
write it to a file so let me again take
T file in this case I am using output
not input previously we saw component
which for reading the I delimited file
which was T file input delimiter
now I am writing it so I am using
file output delimited so I'll just take
this or put delimited and whatever is
data coming out of T sort row I am
giving it to T file output delimited and
let me create that file in a director
folder in the bout put folder so the
name will be something like leak
please something like that count or
something like that
and Ross operator feel separated later
with that and by default schema would be
copied league and number of players my
final output will be available in oh my
dear acre demo put on league players
count so this is for the first use case
and if I want to build the second use
case wherein I wanted to filter out few
of the all the players which who fall
under a particular leak so in that case
I'll take filter component so my need is
filter so I'll take T filter row and
input I have taken it from the T
replicate K will give me multiple output
so I will take the same output to T
filter no it is nothing but the same
input which we are reading that will
flow into multiple outputs from T
replicate so quite simple so I will come
in and say schema will be already copied
so I will just say what is the filter
condition so if I see same filter all
the columns are copied so I will just
create one filter condition and I'll say
is league is what I am looking for and
that leak should be equal to some
particular value like how previously we
decided so suppose I want to get the
value for this leak I'll just give it
inside quotes so it will filter out that
data alone and this output again I can
give it to a different T file output
delimited which will only contain the
players who has falling under that lis
French Li so I can just rename this
components also like players for French
League something like that so here also
we can create it in the hit record demo
put but file name will be
players for French Ligue 1 or something
like that
and similarly I can take one more filter
row I can even copy paste the components
I take another input from T replicate
and I can even copy paste this T file
output also since they are same
structure and I can give this filter to
another one but I'll go in and change
the condition so the other one which you
are looking for is punished so I'll copy
this value or I'll take English Premier
League which has more number of people
or let me take that I'll just replace
this French league with English Premier
League so this second flow which we
created will have players for English
Premier League
and this filename as well I'll change it
for English Premier League so similarly
you can do it for many other clubs we
can have it in sequence so now let's run
this job and check if there are any
problems there any runtime errors or
compile time errors we'll get to know
that so to run this job we'll have to
just come to run window and then just
click on run
so now we can see even statistics will
be displayed on the rows like so many
$17,000 require has been read and same
has been passed from T replicate and
when we grouped up it was totally into
42 groups and even after the sort and
then they were around 598 players for
French league and 654 players for
English Premier League so let us see
these output spice has been created or
not so let's go into the demo output
folder and I see the league players
count CSV which was for first use keys
so let me open this so now you can see
in the order which we wanted we have the
league name and number of players
available here also we had filtered
players for EPL so we have all APL
players listed over you so all of them
and the IPL players and also we have one
more filter condition for French Ligue 1
and even that output has been generated
who all belongs to French Li so by
reading our file which was given for us
as source we have created the metadata
by adding simple aggregations and suite
of components we were able to give the
solution for which League has how much
players in sorted order and we could
filter out the players for that League
and provide it to their readers or
something like that who asked that
requirement so we all did this
everything from design to the output for
the solution for to use cases in such a
small pan of time so this is all about
your talent introduction demo it has
more capabilities keep following us for
more updates thank you one and all for
attending this webinar I hope you have
enjoyed listening to this video please
be kind enough to like it and you can
comment any of your doubts and queries
and we will reply them at the earliest
do look out for more videos in our
playlist and subscribe to any Rekha
channel to learn more happy learning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>