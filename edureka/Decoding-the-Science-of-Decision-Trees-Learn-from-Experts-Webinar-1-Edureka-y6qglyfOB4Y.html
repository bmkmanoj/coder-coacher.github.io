<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Decoding the Science of Decision Trees! Learn from Experts | Webinar -1 | Edureka | Coder Coacher - Coaching Coders</title><meta content="Decoding the Science of Decision Trees! Learn from Experts | Webinar -1 | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Decoding the Science of Decision Trees! Learn from Experts | Webinar -1 | Edureka</b></h2><h5 class="post__date">2015-09-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/y6qglyfOB4Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello once again and welcome to the
session on decoding the science of
decision tree we are going to discuss
about technique called decision tree
which is part of data mining supervised
learning right all right okay seems like
that was an accident accident the other
might have raised his hand so here we go
so this is adding a for today's session
or one-hour webinar we are going to
discuss about classic business problem
which is related to banking industry
what do you think guys what do you think
if you have already guessed on what is
the problem that we are going to discuss
today anyone what is a classic banking
challenge
related to loan if I give a loan to
someone what is a classic problem which
bank fees provide alone or not
absolutely our own so that's a classic
problem that we actually yeah they don't
pay fraudulent right they default the
loan things like that recovery yes
absolutely all are on the same page
right to look into the bunch of
credibility of the customer proin apps
you
to the available options for solutions
what are the way Leah solutions are
available if I have this kind of a
banking challenge problem why do we need
to use decision tree why can't we use
some other technique right so we'll
compare decision tree against few other
techniques and we are also going to
discuss about decision tree methodology
whether it's going to work or not how
it's going to work okay so let me move
on to the subsequent slide so these are
the radius classic situation problems
and banking or financial services sector
right whether a person is going to
default on the credit card should I even
give him a debit card or not is he going
to default on the loan or not he or she
became a fraud transaction of fraud
customer yes or no things like that here
is a typical problem a bank wants to
classify its future customers into two
segments or two categories basically
risky or good engaged on radius
attribute such as whether a person has
an undergraduate degree or not based on
the marital status whether a person is
married or not taxable income city
population work experience with
represent stays in urban area or not is
an all these attributes we want to
classify a customer as risky customer
are a good customer
how will the bank know whether a person
is risky or good that's the problem that
we're trying to solve you so if a person
applies for a loan right click approve a
person's loan based on whether a person
is good or not right or if it's a risky
i'm going to retake the loan this this
decision tree can also be used in
multiple other situations a scenario
such as should i hire a person or not
should i invest money in hire a person
or should i not hire of us should I go
with say venture capitalist a funding or
should I go with B should i purchase
iphone or should i purchase samson will
a person actually leave my company yes
or no
right will a political a customer move
from eight till two waterphone move from
one telecom operated to another yes or
no all these are the typical
classification problems which can be
solved using decision tree however are
the other solutions available here
apart from your decision tree that's the
question oh yes we don't just have
decision tree we have a bunch of other
techniques also
and those techniques are nine Bates
Kanan support vector machine and the
list would only go on and on so we have
a lot of techniques available for
classification let us compare these
foreign check on why decision tree is
superior in comparison to the other
techniques here we go one of the ways
advantages of decision tree methodology
he means decision tree and we means nine
fades Canaan and support vector
marketing simple visual representation
of a decision situation so you can
actually view on what's going on while
you actually run this model when you
actually execute this in our or any
other tool for that case you'll actually
be able to see the outcome you'll be
able to see what's happening there
that's decision tree your Canaan in my
ways svm these are kind of black box
models waiting you'll not come to know
exactly and what what's happening in the
back so no visual representation for
these however decision tree has a visual
representation at the end of this
presentation we will actually run the
our code and see how it works it's easy
to interpret and explain to executives
if you have non-programmers people who
do not understand the programming aspect
decision tree would be the best bet that
comes it to be extremely simple to
explain interpret and explain to your
non-programmers people who don't
understand your non programming people
do not understand your program it
illustrates a variety of decisions and
also the impact of each decision if
different decisions would be taken I'm
going to explain about this third point
in the next slide or so and allows us to
predict explain describe or classify an
optimal together that's only done using
your decision tree
it will help you demonstrate radius in
our use such as what is the best case
worse case and what would happen if I
consider a few of the attributes
basically and the good part is that this
can be used to handle both your
numerical as well as categorical data
right so your decision tree is white box
meaning you can clearly look into your
outcome in a visual way and see what's
happening in the backing however that
the models are called as black box is
you cannot really read what's happening
in the background let us consider this
small example you understand what if
scenarios which can be done using your
decision tree you have a manager you
want to hire right either you want to
hire a permanent position or you want to
out choose a piece of work
if you go for a permanent position the
person whom you have hired can either
stay for six months company are you
might leave right it might leave before
six months if a person stays for six
months right then there is a fifty
percent chance of factors in yogi
gaining one hundred dollars so this is
well as probability fifty percent
success here this is your probability
and this hundred dollars here is your
impact right so you multiply probably be
by in fact get a value there for the
success and if you go for a permanent
position your project might also fail
what is the probability of failure say
the probability of failure here for
instances 50-person once again and what
would happen what about the impact be if
your project feels
alright impact is that you would lose
forty four forty dollars sweetie so if
you subtract these two you'll get thirty
dollars right this is one scenario let
us look into another scenario if I out
lose a piece of work i project my either
succeed or fail
what is the probability that your
project might succeed you have 50
and what is associated in back here $90
if you out choose a piece of work your
project might also fail
there's a probability of 50 person that
your project might free and you might
boost pointy dollars so in all these
scenarios once i can let me erase
everything so if you're looking at these
two scenarios wearing you want to hire a
permanent position or you want to
probably out to the piece of work right
and if you outsource a piece of work
right or if you have to see a project
$35 is what you might get
alright if you go for a permanent
position you'll get only thirty dollars
so based on these two outcomes final
outcomes after looking into the
probability and impact of success and
probability an impact of failure you
would obviously go with the second
decision about tossing the work this
decision tree simple decision tree and
then we use for your data mining aspect
also your decision tree is a supervised
rule is classification you'll set some
rules and then classify people right so
the topmost node is called the root node
and based on that based on the decision
that you take for example your outlook
is whether you want to play particular
sport is that nope whether you are going
to play a sport or not is going to
depend on whether the climate is sunny
or whether it's rainy or overcast
sunny then you're looking into get
another rule another split
what is called as your intermediate node
or your split node if it's sunny or
you're also checking for humidity if
it's very humid probably you do not want
to play do not want to play or you want
to play is a final decision and end it's
called as a leaf node are terminate node
you
and whether you want to play or not
that's the route know you're checking
whether the climate is rainy or not if
it is rainy you'll stop there you're not
going to plea sorry you're going to
click yes that there's no further split
associated with this however if it is
overcast you are checking for another
rule on whether it is windy or not if it
is Wendy you're not going to play if you
if it's windy probably yeah if it's not
windy going to play if it's windy I'm
not going to play that that's right so
the final loads are fall as your leaf
node to terminate not swearing you have
taken a decision the intermediate nodes
are the nodes based on which are going
to further split your decisions right
and this is paul is a typical
classification rule for example should i
plead right and what is the first
classification rule it's sunny and humid
humidity is high right then you are not
going to click if it is sunny and if the
humidity is normal
you'll be if it's raining this is the
third classification rule rainy locally
the fourth classification rule is that
if it is our task and if it is not windy
then you'll be that's the fourth
classification rule and the fifth
classification rule is that if it is
overcast and if it is windy are not
going to
in this way you create a lot of
classification rules using your decision
tree and as in how you move down the
station we going to split further based
on the multiple attributes that you have
take the example of this
um decision are the proper waiting we
want to classify a customer as risky oh
good so here is a historical data which
we have we have the details on better
person is an undergraduate yes or no
whether a person is married single or
divorced taxable income right city
population work experience urban yes or
no whether a person is from an open area
or not and Asian all these things is a
historical data which you already have
with you it's a bank has already
collected right so based on that you
will have the story talita and the
category right whether a person is
riskier good in the past say you have a
loaded loan purpose you have even loan
to a person and he was an undergraduate
married with this taxable income the
city population for years which means
and not from ana beninia this customer
say he has defaulted you alone for the
risky customer you have already thought
this information from historical data if
there is a person who is not an
undergraduate single this is the taxable
income and the city population is given
work experience and he is from open area
so given all these attribute values this
person has paid you the loan on time he
has not default who is a good customer
and in this way you have a lot of
historical data available you are going
to build your decision tree model based
on this historical information
and once you build a model whenever you
have a future situation right there is a
person who walks into your bank he
applied for a loan he has an
undergraduate degree he is divorced and
has taxable income so much city
population he also has 14 years of
experience and is not from the urban
area how would you classify this new
clip customer would you classify this
new person as risky are
as good customer that's a problem that
yeah right so we have a historical data
we have built model is using decision
tree algorithm and then whenever there
is a new situation or scenario which
arises based on that I can categorize
the person as risky oh good
right at this point let me see what are
the questions
erin has this question our decision tree
9p skin and SPM algorithm absolutely
aren't all these are the wages
algorithms within your data mining super
wives
we can me even SVM and KN in a graphical
form is what kumaraswamy sees aha
interesting so does your models show
that outcome in a graphical format as
what your decision tree shows
kumaraswamy
you
I'm not speaking about the explanation
i'm speaking about your RR any other two
or does it give you with the final
outcome so let me show you that let me
show you that much for me and then you
can count to me if you have any
questions using which tool are we going
to see decision tree are our own we are
going to look at this using our
using our so let us proceed further so
how it works right let's build a
decision tree till going first choose
this root node and we have further
understanding chosen this route north
undergraduate now my question is why did
we select undergraduate as our first
root node because here we have a lot of
other attributes like undergrad such as
undergraduate marital status taxable
income city population work experience
animal if I have six attributes why am I
selecting undergraduate is it because
this is my first variable or first
column there
is that the reason
can someone just common based on your
understanding okay I'm not seeing an
answer so yeah there we go
it may be the least age
rajat says maybe it has two
possibilities yes sir no
provinces it may be the least age it
says yes or no is watch it sees
that is sensible for the situation is
what one pharmacist education directly
proportional to income okay is what I
run says it has the least radiance is
what me Elsie is easy to classify to
deserve one right that's a minimum
quality up one also see is that it's yes
or no has 21 but the right answer to
this is there is something called as
entropy and information gained
you
you
you
and information
right so these two are statistically
calculated I'm not going to get into
that detail in case one hour might not
be sufficient otherwise so using these
two how much information are you gaining
if you split or if you consider
undergraduate as your first node how
much information do you get if you
choose Monica Cedars I'm information do
you gain if you choose taxable income as
your root node and how much information
do you gain you choose either city
population are working or right as your
root node this is mathematically
calculated in the back in right you can
also manually do that calculation it
might be a little tedious but yeah you
could mark a manually also do this
calculation
and the attribute of the variable which
use is the maximum gain that is an
attribute which is selected as your root
node and in this case it happens to be
undergraduate this and in undergraduate
here for good and three risky people so
let us see here we have seven rows and
if I select yes as undergraduate 12 and
for both of these two I see too risky
and also if you look into undergraduate
ripe and the corresponding categories
you have three risky and for good Joe I
move on we have for good and free
whiskey and undergraduate as you all
have rightly seen you can i delete it as
yes or no if I speak it as yes so why
use corresponding allroad the entire row
corresponding to undergraduate yes is
listed down to it the right side against
yes and wherever you have undergraduate
value as know you have all these
corresponding groups so I have to yes
and the entire row corresponding
peoria's and corresponding here no is
taken here and wherever you have yes
this is information pertaining to that
and where we have undergraduate no these
are the rules pudding you know
underground right now what do we do
we classified the customer as risky are
good right here if I have both of these
things booth right as risky I'm going to
stop I'm not going to further split this
I am going to split only if I have
different categories different outcome
categories busy here I've glenda risky
so I need to further split this so what
does further split this am I going to
use marital status or taxable income our
city population or work experience or
urban what am I going to choose here
right once again information gain or
begin value which we have calculated
earlier right we should have ideal
calculated earlier that come to the
picture after undergraduate attribute
which variable or attribute gives us the
maximum information e that is chosen for
the next week not marital status just
because this is the first variable now
now it looked into my idle status active
link MCD population work experience
urban all of these and then it going to
further split the node right this is
tall as a pure subset because both of
these are risky here you have four put
and one risky so you can split further
right I'm putting further be further
east on morality and in my dell stator's
I have single and divorced all the
values related to single all the rows
corresponding to Americans did a single
is list it down here all the rules
corresponding to the host is listed down
here
right and I'm not going to further split
this mat the street is the worst table
why is that so because both of these
rows have good as category and it's a
pure subject however if you look in the
single here you have good and risky so I
need for this witness once again the
information gain comes in picture out of
these four out of these four variables
which is taxable income population book
exchange and Evan which variable or
attribute gives me the maximum
information being that is selected to
split this further so here we go since
this is pure is that subject we are not
going to add further since here we have
good and risk you a link here once again
the thirst plate is based on taxable
income yes because taxable income
variable give me the microphone
information gained after your Model T
 half-wit since I have only one
category here I do not have any further
split
I'll stop here since here I have same
category I am going to stop you from
splitting further and these two are also
follows cure subset
now here is a model that we have
undergraduate is no single keyword and
we got this classification model right
how did you select this first node as
root node based on information gained
why did we split on market status next
because this is the next variable which
is given as a maximum information in in
taxable income the third
your model your are or any other model a
tool that you use is going to throw you
this kind of a representative
to mark game on each other's question is
there ain't a thumb off rule on how to
arrive a decision tree i'm in st. 627
and n steps our money is the same
explanation hope
answer right six to seven steps take
your historical data split it based on
your variable which gives the maximum
information you split it till you are
ever to pure subset in a kumaraswamy has
this question how to make machine
learning from decision tree this convict
what exactly the meaning of machine
learning as is just based on offense
conditions so Kumar's forming machine
learning means you have only seven data
points when you build this model as and
how you get more and more customers you
keep adding that data
to the already existing data that you
have when you further refine your model
once again you do decision tree once
again you do decision tree so as in how
you get more and more data your
classification would become so much more
accurate
aaron says is there a formula for
information absolute here is a formula
for information gained and you know
there is something called as entropy
that you calculate something called the
information gain you subtract those two
to get the cake so it's slightly say
very complex slightly complex how do we
fix the income as 30 Tiki based on your
domain knowledge domain experience son
Santa Santa maybe for that particular
bank based on your domain experience you
feel that
median is 33,000 right or my measure or
mean is 33,000 if you do not have any
lives based on some descriptive
analytics elementary and Alex you arrive
at that but it has to be back into
domain knowledge any useful links video
links for the sea
or you can just google that decision
tree entropy information gain formula
you'll get that it's just simple
straightforward calculation money says
know what I mean it is it possible that
i take four step then some someone take
56 to arrive at decision tree
yeah it can be possible here based on
what tool you are using and all that it
can and each time you run the model
decision tree each time you execute the
command you might get a different
representation that's actually one but
your model will get enhanced over Peter
it is generation of classification too
much for me
however it's not that straightforward on
you just create classification rules
right in the back in there is there are
some calculations which go on with
something called as entropy something
called as information gain and you
subtract those two to arrive at another
value clearly algorithm is what we call
that so it's not as straightforward as
you see here but in the back end then
there are a lot of calculations which
going angela has this question in case
the information gain of two or more
attributes are same and we then randomly
pick any output here hundred that is
what exactly happens happy abhilash has
this question there can be many decision
tree forcing the problem absolutely a
peep at lunch there can be many decision
trees but which position tree is the
most optimum for you that is what your
of any tool that you use statistical
tool is going to pen
how do you determine which is the best
free from among radius crease valley on
has a scratch
hey Raj it says so he's not able to hear
me are you guys able to get me please
confirm yeah all right all right argit
so thank you Italian has this question
how do we determine whether which is the
best tree from among radius trees so you
know as I've been telling you how do you
select the root node based on the
information gained right there's
something called as information in which
kids can't read so this root node would
be I mean you willing to select only one
attribute as a root node there won't be
multiple such notes right you cannot
select marital status instead of
undergraduate you cannot select taxable
income there is only one so ultimately
when you execute this particular
algorithm in any of your statistical to
you'll get only one outcome only one
decision tree
you
you
all right Italian has gone offline to
let us move on further let's use our
model so now here is a new situation
which I have new entry new data as a
person who walked into my mind he sees
he's a not an undergraduate so no means
I take this route des Vosges so my dell
stator's i see whether signal that he
was i see that he does he devos i know
for a fact that i need to categorize
this person as good is then what is on
my model my model is build on what my
model is built on the historical data
the true facts which have happened in
the past it's not based on some
assumption values it's based on the data
we have seen in the past so if a person
has an undergraduate degree and the
mantle virus is your shield heroes and
the category would be good
so I'm going to categorize this position
is first of all and graduate now add
potatoes d would put this out good so
you are going to classify this person
into a good group and he can be
considered for all policies for a good
customer such as letting him loan
lending him blown at the lower interest
rate giving him credit card increasing
his critical limit Sean and to all this
position can be
money says is is there a guideline that
there needs to be X number of Records
for model to be reasonably dopest
there is no exact humble as such managed
mode the data points later it is for you
but I would say we're with 30 data
points 30 data points initial based on
that select your sample size based on
the formula which says n is greater than
10 times of your kurtosis square or n
greater than 10 times of your sorry
skewness square or mod of coitus so
there's a lot of thing around your
sampling and population right a wat
sample makes a good assumption for me to
proceed with filling this model the
general term rule is go with 30 data
points and then start using that 30
sample
calculate the skewness and kurtosis for
those 30 data points based on that
come up with revised the sample site
which will actually help you come up
with a better model
so that's my answer to manage then how
do we arrived at the confidence level of
critical regions so I think you are
looking into this as a regression right
this is not regression waiting you have
one number Manish this is classification
problem in data mining wearing you just
say yes or no there are no numbers
associated with that whatever value
outcome that comes is yes or no good or
bad good or risky weather person is
going to be defaulting on the loan yes
or no attributed absolutely epic a blush
Xiao any of this question these are
which factors we will decide whether it
is on the good category or Christie
category is on the same thing right is
on various attributes you have already
built a decision tree so this is your
decision tree which your model has built
which we have built right and based on
this whenever you get a new value you
you you check that or validate against
this and then you go ahead without a
blush as this quickly if there are many
attributes for
torical data they don't have to
calculate the IJ and protein for each
are absolutely a flash we have
ah goer has this question if you have
historical data particular bank for last
ten years is it going to increase the
validity of model or make it more coffee
so door this is what happens you know
you do not go back and collect so much
of data it's good if you have so much of
data but the banking policy stay near
the back might have been different the
living conditions of people in a
particular geography might have been
different if you go back by ten years
right probably now things are different
so segments of people who used to
default in years back probably now they
are change their life and things like
that so it's good to use the latest data
all right and that is the reason it's
called as machine learning 10 years from
now the trend might change people who
used to be falling the past might be a
different set of people all together now
right so since I keep uploading the data
as and how I get new customers add that
those customers to my existing model I'm
going to once again run the model to get
the latest information Avila says a
final model is built and if any new
attribute is on is over time then
then we are going to classify that
person as good or risky based on the
historical data and as then how you
progress right you will get to know
whether a particular person or the
person whom you have given loan did he
pay on time or day DD form if he falls
again that's a new data point for you so
that is a reason why this is called as
much in learning it so you keep
enhancing your model you not stop
anywhere based on your changing living
lifestyle whatever we get you keep
proceeding further
so let's use our model and predict we
have done that so let us do a hands-on
mount since we have less time I've been
taking to query string so here are a few
real life applications post which I am
going to show you on our how do we run
this particular model decision tree take
so finding out whether a person has low
grade cancer cells or I agree so you can
check that whether i put with rope
whether the cells within human body or
normal or are they showing tendencies of
cancer based on historically that you
can do to credit card transactions if
you do a credit card transaction should
a customer care person call you and
check before approving the transaction
right that's another thing if you have a
newspaper if i'm going to scan that or
if you have online
provision for that particular news
letter we can read entire thing and
classify the news as finance news or
weather news sports news so on and so
good that is also a typical class
classification problem obviously there
have been a lot of questions which have
been acting awfully but let us quickly
run this in our and see how it works so
have a particular dataset called fraud
did after our check I'm going to load
this fraud check in to our-- and this is
a very command which we use to read
projects is a csv file I'm going to load
this into are using this command read
Ozzie's and I want header information
meaning the first row quick as the
heading information I want that and I'm
going to read this and I'm going to load
this file which I am going to read into
this fryer on this paycheck so
around I see that there are 600
observations of six way vehicles if I
click on those it going to show me the
project area there we go we have 600
observations meaning we have 600 roads
here and we have 60 variables that mean
undergraduate is one variable Martin
Satan's taxable income city populations
on six variables also
once I read that I'm going to attach
this no I cannot um go line by line
explain each thing so few things i'm
going to skip in the interest of time
head of project so this data set is
uploaded here or we have read this data
set into our and I say head of fraud
check it's going to display the full of
six rows of this particular dataset file
fraud check and there we go we have the
information for that now that you have a
lot of values x-linked Emmure 688 double
3 double 3 736 925
5190 so on and so forth right so I'm
taking 33,000 s
our here 30,000 as a number where I want
to benchmark if the person has a taxable
income of less than or equal to 30,000
Isis a risky otherwise bird it's just
for a classification hope is that
nothing just to demonstrate for you all
so now i have assigned these risky in
good values for each and every 600 of
the wazians there and now i'm going to
build something called as a data frame
so when I build this data frame now what
I've actually done us today existing
fraud chick I've added another column it
is risky or good all right is done
taxable income taxable income is liz n
see 30,000 listen or 30,000 empty that
person is risky the taxable income is
treated than that it's good ain't afraid
so just for your understanding in real
well right you get the stump Lee data
set along with the category of good or
bad good a risky you'll get a bad it is
it since this this particular problem
wasn't there I just manually created
just for your understanding only full of
caution right take it what so now I'm
just taking a table there so here when I
look into the table categories right I
see that 476 entries out of 600 are
classified as good and 124 a classified
as risky now that we have the
information on whether a person is good
or risky based on the income right it
makes sense for me to remove this income
so I'll remove the thinkin column there
minus three mins i'm going to remove
that particular column it so now let me
see whether income is there no now if i
see me in the customer I draughty in the
income there and so it's remote now set
t equal to 2 i'll not spend a lot of
time on this said dot c is only used to
limit your
our each time you generate a sample each
time you take a sample it's going to
take the same sample if it's like to see
that so you can do any number you want
for that two three four it doesn't
matter and what number you having this
is our command friend now i'm going to
divide the entire dataset 600 dataset
600 observations into three hundred each
and the 300 which I'm going to do while
I'm going to assign or I'm going to tell
them that as a training it is it is on
which I'm going to build model the rest
of the 300 i am going to use to test my
model whether the model is accurate or
not so and let me check the lent the
screen you'll see that there are 300 why
because I've divided the number of rules
of customers into two
12 n rows I am taking a sample right i
am dividing that into to basically that
is one up
and- strain means all the data points
which are not from their training data
say as I need to test either and I'm
going to look into the length of history
I get 301 now training data I'm going to
assign this customer training whatever
data I've assigned as training dataset i
am going to assign it training on this
pretty down now whatever data I was
signed to this way able called test here
I'm going to assign it to testing
so now we have the testing data and the
training data you can also look into the
needs which are available that links
means nothing but your column names are
variable names
okay I have this and not worry about
these things a lot just understand the
logic of your d IM means i mention of
train need said length means it's going
to give me the length of your testing ms
bhai which is nothing but your testing
data set once an e now i want to want to
look into summary of its actually
recommended that you do this descriptive
statistics even before you proceed
further so I know for a fact that I have
undergraduate 161 undergraduate 139 were
not undergraduate and I have the
microspheres of people one out 5 of
saying a single one out for Marty and
9114 if you have the continuous data you
will have me one maximum first quartile
third quartile median and meanwhile in
that now in order to run this position
for you need to first install and load
this particular package called Creek in
the physical map
and now that's impactful running this
decision tree it's free training data
set category is my Y right it's always
white till X
you are trying to identify why category
as good a risky he's done all the values
that is what your dot means you you r
dot you that we
I want to categorize a person as good or
risky he's done all those input values
from this training dataset
remember I am building a model based on
the training leadership I've divided the
entire dataset into training it is it
and taking it easy now once we are done
we can plot this not this is where i was
seeing that we can graphically view so
if you want to view the corresponding
values associated with that and run the
command let me zoom this this is so
graphical city population that was the
first route no that was considered next
work experience isn't that also it has
taken few splits and then city
population was a third swift once again
good or crispy then work experience also
undergraduate yes or no that was a large
value if you Scott isn't how much
information each value is giving you in
that way it has generated a decision if
you see city population obvious here
also that means based on work experience
once again you're looking to which value
or way able is giving your minds
momentum Eugenie it's not as simple as
we have this good using our presentation
right there's a lot of there are a lot
of public zinc-rich going
once I built the model we need to
predict using a test either
criando score at 300 per model is actual
model which we have built now I want to
predict the future is on the testing
data and what are we doing we're doing
the classification and the typist plans
now if I look into mean of the Miss
classification error right how many
times will be misclassified here
the higher the mean bad is your model so
you can further bring it down right it's
0.23 three and you can further okay
what's the question art large as this
question or data analytics and
predictive analytics can be done by
building decision tree
yeah that is exactly what we had yeah we
cannot touch
you
decision tree is one such technically a
reality might be a different situation
but this is one technique which can
so now i'm setting a different see that
means i want a different sample simple
now I'm cross valley eating the free you
can see we don't cream now if i do that
names off i'm looking into sighs right
so let me plot this and show you what
exactly is being done here so I have
plotted this graph using only your
circles are small dots there if I want
both those points and line I go with the
time from there now if you see here at
second place you see deep in right you
see a steep in there
at the second point that means if you
fill your decision tree it's better if
you prune the tree 22 that's the
indication so I prune it by two and a
try to plot
now if you see earlier the graph had a
lot of clip your decision tree and a lot
of glitter now the number of words have
reduced and it got reduced to second
split peas let me also add texture on
that now this is how you classic the
simple
so you can increase the accuracy of your
model now I am predicting using the
testing data and now if you're looking
to the mean value it 0.22 it has come
down from 0.23
right even small decrease in this mean
value means a lot so this is all about
your decision tree now after you off to
your questions
so Chris has this question
how is a job market what kind of jobs
would you apply for with this knowledge
yeah Krish so you become a data
scientist basically dealing with a lot
of theta
yeah Chris I'm not so you cannot play
for
a job you know along with this data
mining you also need to learn
statistical analysis and forecasting and
then you can claim yourself as a data
scientist and start applying for those
kind of positions and only based on data
mining also you have a lot of jumps goer
has this question like most of
statistical models we have certain level
of confidence so do we have similar
confidence level in this model as then
what is the percentage of confidence
with which I can see optimal policy so
you know each model has a different way
of evaluating accuracy gar if you use
your regression models probably a I see
values are you're a square value if it's
your linear equation things like that
can be used however in your decision
train you use this mean I've done that
mean right you can use that one you to
actually give the strength of your model
what about freshers will they ask for
experienced a data scientist as a job
itself is pretty new right it's very
the way nascent stage so I do not I
don't think people are going to ask for
a lot of experience as such there is a
lot of crunch in the market there are a
lot of requirements demand supply issue
has screwed up still a lot of demand but
the supply is limited money has this
question from the example it appears
that we are looking at constructing
decision tree with leaves node not being
too d like here we see leave Nora to ah
that's a decision that you take right if
that's a cost-benefit analysis decision
that you take with the management if you
feel that they're far too many rules and
if you feel that you know the number of
Miss classification have to be brought
down our accuracy of the model to be
further increased than you do so or if
you are happy with the 0.23 three this
this many are not matching then that
took you that means what does that mean
on an average these many are not being
classified properly correctly if we want
to reduce it for the you can use or if
your management is H naught 0.22 I 10.1
then probably you will go with a
different technique all together so it
all depends on no money there is no
recommended range for the mean as such a
door has this question can we have the
ppt of this webinar and data finds
stepwise our instructions you need to
check with that Eureka theme at the end
right yofi once you close the session
you'll be given you will be thrown about
to take this L request and in that you
can mention that you require the
community and our instruction probably
they'll accommodate but the recording I
think should be made available
is testing underscore high the threshold
value is what object so that's not the
threshold value as such
I'm just comparing it that too
let me show you what we have done it
that's being on the score
one second I blush when you well I think
your quest Neela's question is it a good
idea to switch from my reporting your
profile like a micro-sized oh yeah that
would be the most logical chip for uni
hello here in MicroStrategy or data
visualization due to this tableau right
it could be the most logical way to more
is IG calculation our own our own has
this question is the information gain
calculation present in your code or is
it part of library it is part of library
tree our own they will create this
question can you show if new data enters
how will it be done
it's very excited too they will be on
this is a demand that you can use right
predict is a command and then here
instead of testing data right i use it
new data
I say the new data say CSV file I'm
going to load that if the new new header
that I am loading is called as new data
you give the new data and there's a
command credit
and it's going to pretty top are there
any other curing parameters other than
pruning a lot of other parameters
cycling which can be what pruning is one
such day
man over has this question
may I know what's a prerequisite to
learn this course there's no
prerequisite at such even precious are
free to join this pool you will be
taught right from the basics are saying
that you do not know anything
but there are a lot of job opportunities
are fresher circle you can just do a
search on your job photos right that
will give you a clear indication on how
much is a requirement there's a lot of
requirement
so before I forget one last question
from balázs
so category of test your test nita right
from that it has just taken your
category so what is a category here this
is a category good or bad
so we'll link for this course would be
shared with you Chris will be shared
with you
and guys do not okay Neela's with while
building the data tree is it possible to
plug in a custom logic like if the band
gives loan has a preference for married
people love them you can tweak that any
other but ideally what would you be
doing you'll be tweaking the logic of
the decision creates a decision tree as
the technique has emerged based on a lot
of scientists mathematicians who have
spent a lot of time on that right so
you'll be basically defined that logic
if you're trying to chain you can do so
if your understanding is far better than
the model induce
alright friends thank you for attending
this webinar and this recording will be
shared with you the moment you close the
window or you log off you'll be given a
survey you'll be thrown with the Sun so
a window just fill all those details and
whatever question you have please
mentioning that so that you will get
appropriate responses to them thank you
door thank you everyone
have a great day thank you are on</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>