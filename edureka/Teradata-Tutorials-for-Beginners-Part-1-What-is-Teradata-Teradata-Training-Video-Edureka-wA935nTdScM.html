<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Teradata Tutorials for Beginners Part 1 | What is Teradata? | Teradata Training Video | Edureka | Coder Coacher - Coaching Coders</title><meta content="Teradata Tutorials for Beginners Part 1 | What is Teradata? | Teradata Training Video | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Teradata Tutorials for Beginners Part 1 | What is Teradata? | Teradata Training Video | Edureka</b></h2><h5 class="post__date">2016-05-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wA935nTdScM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to the demo session so before we
begin let me start with my introduction
so I am Rahul I have close to nine and a
half years of experience in terror data
and terror native integration with other
databases third as integration with big
data and analytics so I have built data
warehouses data platforms and has been I
have been part of numerous performance
tuning projects as well so in my current
role I manage a team and I am also the
chief architect for the data analytics
platform for a retail major all right
so that's the background and for the
course we've we will soon see all the
topics that are there that we will cover
all right so let's get started ok so
before I begin let me first quickly give
you a quick walkthrough of how the
website looks like right so this is your
course overview ok so each module so
we'll have eight modules and within each
module you will have a class recording
so this is available post the class ok
so today's introductory audio plus a su
today's introductory recording the demo
class will be available to you ok yes
just give me a second guys I am
comfortable ok with in UNIX and Linux
COBOL developer got it
got it so there is a question that is
the teradata
tool better than ETL informatica ok so
let me be let me be unbiased and talk
about it ok so informatica is a ETL tool
but then Teradata is a is something is
is actually our DBMS okay so I am sure
all of you have our DBMS knowledge right
so Terada is basically a database plus
the ETL features are also enabled on top
of it so when you go and and say create
jobs in informatica what happens is you
still need a underlying database
generated Tara data on the other hand
has utilities like fast load M load TPT
so these are all scripting languages
built on top of Tara which can be used
to load and unload data into or out of
the array data database so I would say
the Toyota is more complete when it
comes to handling end-to-end data
warehouses but at the same time it needs
some amount of unix and scripting
knowledge because each I mean
informatica is drag-and-drop so it's
easier for new users but as you spend
time in in different systems right you
would see that the more granular you go
the faster your systems are right so
when it comes to the the divider scripts
the way it helps is is what happens is
when you do a connector from informatica
internal it calls a TPT connection a
protocol right so rather than that dead
in terror later you will directly write
that write that script okay right so I
think from that is my perspective that
iodized a more complete tool does that
answer your question
all right okay all right so let let us
continue with looking at this website
now so for each module you will have the
class recording you have the
presentation then at the end of the
class you will have a quiz you will have
class file which is basically the notes
that I write throughout the class I
upload it here right and then you have
an assignment right
and then there is a pre work for the
next module okay so once you log into
your portal once your ID gets created
you will have access to all of this
right and this is lifetime I mean you
will have access to it even after the
class and I mean for this is a lifelong
availability okay next for the
curriculum so these are the topics that
we will be covering so initially in
module 1 we will be doing the overview
right and the topics would be basic
relational concepts what is there then
how data is stored and retrieved
connectivity with mainframes and other
network applications and then what is
UDA
after that from module 2 onwards it is
more so first module is basically a
little bit of theory but then from
module 2 onwards it's hands-on right so
it's all about primary index creating
them about primary key their differences
what are the types of indexes that you
can create in Terra later right so other
indexes are join indexes PPI is
partition primary index and secondary
index so we will see when to use them
how to use them right if you have a job
that is they're not performing well how
do you leverage your indexes right and
so more from what you'll do onwards you
will start getting a good understanding
in-depth understanding of how data works
module 3 is about add a sequel the basic
sequel of create alter drop the DML
statements of insert delete and update
then you have DCL which is grant and
revoke data control language right so
how do you do grant and revoke on
different objects and control the axis
of your data will also do order by group
by and all of this this will be hands-on
right so we will write queries and see
how to manipulate the data that is
stored inside of Torretta right next
would be data production so terror Ida
is a MPP system I will start with module
ones slide today in this class itself so
you would
know how that works and then what are
the measures that makes it
fault-tolerant okay it's a MPP system
which stands for massively parallel
processing system okay which is a
combination of a different SMPS
symmetric multiprocessing systems a
combination that makes up a MPP so we
will see what each of these are right
and then how do you use transaction
locks what our fallback tables and then
how do you use all of these things to
make sure that you never lose data okay
and your system is always available even
if your say our data center goes down
some harder harder hardware fails there
is a network snag you want to ensure
that your your business critical
application still run so we will see how
to do that in data protection which is
module 4 module 5 is for the business
analysts or for the data analysts it is
about advanced sequel how do you use
them to look up data use sub queries to
fetch data or generate reports right so
people who are using on using B Business
Objects tableau all the reporting layers
right so how do you write your queries
to get data out ok and these are your
complex queries once you have covered
module 5 you will have a good
understanding of what there are offers
and then in module 6 we will start with
the different database objects and then
how do you do performance tuning of
using these objects right and then
module 7 and module 8 is about the ETL
part of it where they where we will
touch upon the utilities we will write
sample scripts and then we will load
data onto a table transform it and then
take the data out using these utilities
ok so that is a brief overview of what
is there in each module right and once
we dive into these modules and right
start writing our queries and start
writing our scripts
this will all become clear okay so that
is the overview of the course
now let us directly jump into the
presentation so getting started right so
this is what is the objective so I think
everybody knows what is data for those
who don't know it's a massively parallel
processing system currently the market
leader in the data warehousing space
right and the best part is that it has a
very robust optimizer so internally the
systems that you will be using the
optimizer the compiler they are all very
mature there has I mean there has been a
lot of R&amp;amp;D that has research and
development that has gone into it and
they are considered to be one of the
best in the industry right so a lot of
the job like entire I really don't
require hints if I have to compare it
with Oracle you really don't require
much of hints right so if you create
your tables properly you distribute them
properly in a parallel system right the
optimizer in Terada is smart enough to
run your queries with the best in the
best way possible okay so that gives
Tara some competitive advantage over
other our DBMS right and then we will
also look at the architecture will start
with it but it's huge so we will need a
few more classes to complete that but
then we will start with the architecture
today and then how data is stored and
retrieve in Toyota ok all right so as
you can see here it's the best
analytical database ok which is scalable
and it follows all the a CID properties
so terror it as atomic it's consistent
it allows you to do isolation and the
data that is stored is durable ok so it
follows all the a CID properties of the
our DBMS
apart from that the advantages it
advantages of trade are it's linearly
scalable okay so if you add more
hardware your your query and the
capacity to store more data linearly
increases similarly if you reduce the
number of users your performance again
improves okay so it's linearly scalable
as you add a new node when I say a node
it's similar to a laptop so the moment I
add it to the network I improve upon the
queries run time because I have added
some additional CPU and then I also
improve the queries the storage capacity
because I have also added some hard disk
right so and that is measurable and that
is linear in performance okay it's
parallely efficient because what happens
is you have multiple CPUs working in
parallel so if you consider say today's
CPUs which are say a quad core or
octa-core processor what happens is each
of these processors work independently
on a chunk of data okay so if I have a
big hard disk of say one terabyte and I
have a quad-core processor and I can
somehow tell my processor that you have
four cores and one core is responsible
for one to 250 GB the next core is
responsible for the data from 250 to 500
GB the third core is responsible for 500
to 750 GB and the last one is for the
last block if I can do something like
that and then start doing operations
pushing data and reading out right it
will be super fast I'm using all my
course so Tara has successfully done
that okay so that's why all your course
I mean they are called MPs in Toyota the
work in parallel and work only on the
data they are responsible for okay it is
called as ah so this is because of
something called as the
heard nothing architecture okay so
neither the data nor the computation is
shared across nodes okay
shared nothing next the execution of
complex queries with a maximum of 256
joins okay so you can join multiple
tables to get the result out of your
system right now a brief history
it started in 1976 at Caltech 1984 it
was the first enterprise wide market
launch and then 92 it became the first
data warehousing system that was
launched at Walmart and it has grown so
far okay since then okay and the number
of customers has only increased over
time all right so this is what we were
talking about it has large capacity so
if you have billions of rows in your
table you can still scale their data
performance it gives you it gives you
like linearly performance system by even
if your data increases you add a node
your performance again increases okay so
it is leniently scalable in terms of
performance and capacity single version
of truth because it supports multiple
sessions multiple there is no data
replication so you keep data at one
place and then you allow multiple
sessions to read from the same data
source therefore what happens is
remember a CID right so it is always
consistent right manageable growth this
is what I was talking about additional
nodes can be added without affecting
performance and it is fault-tolerant
module module for data protection we
will see there are numerous ways in
which data has been made fault tolerant
both at the software level by doing by
doing something called as replication
all backs and then also at the physical
a physical layer using like hardware
stand by nodes and all of that okay okay
so before before I move move ahead are
there any questions over what we have
covered so far right I will get to a MPs
MPs are called access module processes
okay so I will get to it in a few slides
the competitive advantage of generator
linear scalability right so adding nodes
will increase the capacity and
performance of the system
unlimited value lism because it's
designed to be parallel and shared
nothing
so MPP systems thus that is what they do
right so let me draw a small diagram I
think which will make things much easier
so say I have a disc here and I have
another disc here right and then I have
two processors here so what happens is
if processor two reads data only from
the disk two so this is called as a
virtual disk or a V disk okay and this
is also a Vedas and a and the processor
which is also called as a a MP because
it's the full name is access module
processor okay so these are your a MP so
a MP one reading data from V disk one
now what happens is here as you can see
nothing is shared
neither the data nor the computation of
the processors and finally what you do
is you merge them using something called
as an enterprise system bus inter that
is called as the by net and then you
send back this to the user okay now does
this diagram make sense so do you guys
agree that if I had one big chunk of
memory and then all the processors they
were not they were not segregated from
each other and they were all reading
trying to read data so say processor one
instead of doing it parallel II was
trying to read all of the data in
employee table and then processor two
picked up another task and was trying to
read all of the data from say what
should I say say another BigTable called
as transaction right so what would have
happened is because both of these tables
are large tables what would have finally
happened is your RAM which is basically
shared memory would be consumed right
what would happen basically what would
have happened is your employees select
would be slow and your transaction
select will also be slow because there
is only one processor involved the
waiter editor handles this is by
allocating to a MPs which are two
processors to do this select and del
transaction that hit just wait for a
minute now come back to you okay in the
production environment anyways that
doesn't happen because you do not have
two processors but you have multiple
processors so there is a empty processor
which will anyways take this up right so
there is one more module we will look at
it which is called session management so
the session management is something that
will take care of our problem of whether
somebody gets allocated to take up the
second query or not okay session manager
okay
so that is something that that we will
see in the next slide but is this clear
so if you have two processors doing
retrieving data for employee and then
you have another two processors
retrieving data from transaction the
selects for on both these tables are
much faster do we all agree to it guys
you will have to confirm at times I
asked these questions because I want to
know that whether everyone is following
this or not okay all right
all right Uganda is there a question
clear with everyone
nice okay let me remove this drawing
then all right
so apart from that it has a very mature
optimizer right which has been
fine-tuned throughout this history and
it can handle up to 64 joints in a query
it has very low CTO because all you have
to do is to buy a tear the server call
up the helpline number field engineer
comes installs it and you're ready to go
so when you get the get the server right
you get it with a user which is called
DBC and then you also get it with a
password sorry with a with the database
with a default database called SDBC like
in like in my sequel you have the test
and the default right similarly you mean
their editor comes with the DBC as its
default database okay and the default
user so then what you do is you inherit
everything from these users and from
this database so DBC is basically the
entire size of your server okay so we
will get in depth of all of this slowly
okay as module 1 covers all of this
we'll get into all of that slowly and
then you also have load and unload
utilities ok which are basically fast
load so here you have some traditional
load or utilities called as fast load
right multi load em load okay then you
have BTech you have TPT you have BTech
you have terrorize a parallel
transporter which is TPT you have T pump
which is to stream data ok and you also
have something called as fast export if
ehv ok
so there are a lot of utilities we'll be
using all of them right and we will also
see when do use which one okay all right
so the components and the architecture
let us get into it so before I go here
let me get into this diagram and explain
it from here so what happens is that
when you make a sequel request right so
what I do here is say I run a sequel
request so I do a select ID from say
employee okay that's a table all right
so what happens is the moment I fire
this query so why do I fire this query I
have something called a stored write
similar to a toad I have something
called a sequel assistant enter narrator
okay this is a client end tool so like
in a client-server right you have a
server running and then you have client
applications that can basically push
requests to your server right so sequel
assistant is one such client application
okay so you run your selects select
stars from here and then this gets
submitted so when this gets submitted
what do you think logically should be
the first step the first step should be
to parse and check whether it is
syntactically correct or not
right so the first step here in the
parser should be a syntax check okay
which is exactly what happens here
syntax check write what is the next
thing that happens
you will have to check whether the
columns and the objects that you have
mentioned do they exist or not right
so you will also have to check objects
right what is the third thing that you
need to check third thing is the user
who has requested for this data is the
user authorized to look at that data or
not so you will also have to do a
privilege check right privilege check so
these are the things that happen at this
level at the parser level right and then
if there are some system tables you will
have to replace data from the system
tables and create a sequel token once
you have created the sequel token what
happens is it goes to the optimizer now
what is the work of the optimizer the
optimizer based on so what is the input
to the optimizer one is the sequel token
from the parser and another is metadata
information from the system
okay metadata info from the system
okay now based on these two these inputs
the optimizer will come up with
different plans okay different glance of
how it is going to access the data there
Aetas optimizer is known as okay and
this is highly important there does
optimizer is a cost-based optimizer okay
it's a cost-based optimizer so what
happens here is that whichever plan so I
come up with plan one I come up with
safe this is plan number okay and this
is the call
corresponding cost for it okay so what
happens is say plan number one is going
to tell me that okay I'm going to do a
full table scan and to do the full table
scan so what is cost cost is basically
time and CPU right and the resources and
internal resources so you add all of
these up that is your cost so I am going
to take say three seconds to scan all
the all all the partitions right and I
am going to use some CPU cycles which is
safe for and then the total cost for
this step is twelve plus there is one
more where it has to if there is a where
clause I have to do a filter as well
which is it which will take two seconds
it will need one CPU clock so it is two
so the total cost for plan one becomes
14 okay similarly there is another plan
that comes up the other plan says that
I'm going to fetch data based on the
index so that's why I'm going to take
only two seconds to fetch the data and
only one CPU cycle which is great so
first step is to next step is to do the
where clause that is anyways on the
entire data so it is again 2 n 1 so it
becomes 2 so the plan cost so the cost
of the second plan is just 4 units so
tear it up having a cost-based optimizer
will pick a plan too and also it is it
has something called as the visual
explain okay so the user will be able to
see what plan has been finalized by the
that is optimizer okay and that is the
plan it will use to get the data out now
so we we can use okay there is a
question that can be used toward with
aid but the best way of using jeredy is
to use the
native application called a sequel
assistant or Terra Studio Express all
right this is the name sequel assistant
or Teradata
studio TD studio software because what
happens is data connects to its system
not using NC but using BT et which is
terror it as way of connecting ok it is
called iterator mode and it connects
using that and then the connectors are
also - there is a normal JDBC connector
and then there is a dotnet connector so
all of these are built-in within these
tools ok both studio and sequel
assistant so that's why I generally
suggest that use sequel assistant to run
all your queries ok all right ok so if
it was clear so far then let us push the
data onto the by net so this layer
called the message passing layer is
called as the by knit ok it was with the
US military
ok it came as a research project and
then it was given out to the to the open
source world so that's why the name is
Bennion network the full form for mine
it is actually been your network ok
because that's how they named it so
Bennion network network ok now what is
this so what happens is now your final
sequel with the optimized plan so this
is basically sequel which has been
enriched with metadata so this is with
your metadata this gets pushed onto your
by net so this sequel token now has
information about where should I go in
which disk so these are disks one disc
two
disc three and disc four so in the in
these discs the sequel with its metadata
knows where the data lies so it via this
ESB the enterprise serial bus
implementation which is called as a by
net it goes and hits the virtual
processor which is nothing but your EMP
okay access module processor now at this
level what do you do you do a select
from the data it is responsible for so
if I have 10 comma 20 in disk 1 the
processor which is V proc 1 MP 1 will
only operate on 10 comma 20 if I have 30
40 and 50 in the other disks aim a MP 1
which is basically your processor is not
at all bothered to handle this data okay
so 30 MPA 2 will be responsible for 30
ok nobody else is responsible for mp3
the only data it is responsible for is
row number 40 and mp4 the only Rose that
is responsible for is row number 50 okay
ID equal to 50 ok so what has happened
here one select task has been broken
down into four parts
with each processor handling its own
data now what if you were running a sum
function so a MP 1 will run a sum
function on 10 and 20 and give the value
similarly a MP 2 will then add 32 the
sum that a MP one has sent mp3 will have
a local sum which it will add to this
sum and then mp4 will finally had its
own contribution so here as you can see
you have a local sum and then you have a
global sum that
once when all the data has been
retrieved from all the amps okay so this
step is ended is called a merge okay
we'll see all of that when I run into
the visual explain of it okay so now is
this clear what I am P is and how it is
fetching data and and how the
parallelism is basically happening here
in the system are there any questions
around this right so there is a question
that what happens if a mp1 fails to the
local sum so what happens is if you have
fallback enabled okay
so then so we will come to it
this is beyond the scope of this module
but for now just know that if the data
is copied somewhere else the other MP
basically takes over and gives out the
result so your table will still be
available okay there is one more
question that the steroid I need special
hardware or can it run on any hardware
so it can run on any hardware okay so
what happens is when you install it it
creates something called as I mean it
creates his own file system right so
like like for anything right if you have
Hadoop running you will create a HDFS if
you have a line ax running it will
create its own file system similarly
when their idea runs it creates its own
FS right on top of which it starts
operating okay all right any more
questions any follow-up questions okay
good to move ahead then can we move
ahead to the next slide all right
okay all right let me remove these
drawings because alright so now let us
look at what is the now that we have
seen the diagram right let us come back
to the slide and see what a node is so I
am saying that the node is a basic unit
in the system and it consists of all of
these software's right so all of these
modules so it has a gateway what is the
Gateway the Gateway is one that allowed
me to run the Select right in the
diagram next it went to a parsing engine
when I did a syntax check I prepared the
query prepared the execution plan and
then give it to the MPs the MPs are my
processors which are responsible for
data management and conversion and it
also does the i/o processing and the
locking okay so all of that has to be
done by the processor right and once
that is done it then gives out the
results back alright so this diagram is
clear now alright so in the parsing
engine let us see what are the
components I have something called as a
session manager so the session manager
is used to enable the user to do login
so someone has to be a software module
has to be there to basically validate
the user write the user logs in with his
password I need a software module to
handle that that module is called a
session manager has something called as
the parcel what is the parser the parser
is going to check for syntax errors it
will check for the privileges and verify
whether the column and the table exists
or not I have the optimizer which
optimizes the query and tells you that
what is the best plan to run the query
and then the dispatcher which basically
pushes the sequel token enriched with
metadata over the by net to the MPs okay
all right so what is the buy net okay
the buy net is actually a software and a
hardware component okay so when I say
hardware it has physical es B's okay so
it has something like a physical ESB
okay a pipe a connector that connects
two components so if I have say a disc
here right and I have a processor here
okay so esv can connect these two using
Hardware actual hardware okay and also
it is intelligent enough so it also has
a software module built on top of it the
top of it okay so it has both of these
components and this provides networking
capability to the data database okay now
because it has a software component it
can support point-to-point multicast and
broadcast communication so based on the
type of request that you are sending
through the buy net the buy net software
decides whether to invoke a
point-to-point communication so if it
knows that okay so think of this as a
mailing system right so if I know that I
have to send it to a particular address
I can directly send it to that address
but if then it is a promotional email
that has been that has to be or it's a
lots or it's any other information which
has to be sent to three or four houses
then I'll possibly give it to two
postman right who will go on deliver it
to the and to these different houses so
then it becomes a multicast right I have
multiple messages to be delivered and in
a broadcast I will simply deliver it to
everyone because everyone needs to know
it okay so that's a broadcast so a
software module of the buy net decides
which protocol to involve for a
particular data packet
okay now point-to-point that's why as I
have written here is to a single lamp
multicast is to multiple lamps and
broadcast is to all the MPS
alright clear so far can we move on to
the next slide okay so these are a MP's
access module processor so MPs are the
database execution engine virtual
processors within the system what are
the responsible for okay so they are
responsible for managing a portion of
the database managing a portion of each
table it does all the work associated
with generating result set such as
sorting sorting as in if I do a order by
column then it is sorting I can also do
aggregation like average max min sum so
it does aggregation I can do join and I
can do conversion as well all of this is
related to the data so the access module
processor which is responsible for the
data stored in its corresponding V disk
virtual disk so that's why EMP is
responsible for all these operations
okay apart from that because I have to
make it compliant and consistent the
data so the data during changes right so
during an update or during an insert I
have to acquire locks on top of the on
top of the memory block or the table
that is holding the data so that's why
MP was also responsible for Lock
management so when I am trying to update
I should not have other records that
will start reading from that same memory
location so I need to do a lock
management as well so MPs do that and
then I have space manage
so how much space to allocate right so
all that is also there with the EMP okay
so now let us look at how a data is
pushed on to the V disk so if I have a
stream of if I have a stream of data
that is coming to me okay say the IDS
which starts from 1 and ends at 11 right
what happens is if I run something like
say I insert into okay so what I am
doing here is if this is the employee
table and these are my IDs ID equals all
of this right so if I keep doing inserts
so I do insert into EMP write values
right values and then I do one next time
I will do value equal to 2 right so if I
keep doing that what would happen is
that all of these go through a specific
algorithm called as the hash algorithm
okay so we will cover hashing in depth
but there is an algorithm called as hash
algorithm where you pass this ID onto
that algorithm okay and this algorithm
tells you the memory location so this
tells you the memory location where this
record is supposed to land where this
record is supposed to be stored okay so
what happens is the moment I pass one
and I pass that one through this
algorithm it tells that hey V disk one
is supposed to store it so my one lands
up here when I pass - it says MP two
should be responsible for this and the V
disk corresponding to MP 2 is V disk
- so go and store it in Venus - then you
have three stored for stored five six
seven eight and nine
okay so the hashing algorithm decides
where each of these records should lie
okay so that's the storage part of it
now what happens when I want to insert
sorry when I want to select this data
okay so when I'm running a select on top
of it so let's see what happens so when
I okay so this is data storage which we
have already covered this is the
retrieval part of it so once your data
is lying in the am piece if I run a
select star on the table star from EMP
right for on I'm not using the notepad
today but from the next class let's
let's start using that because I am also
drawing all of this to explain the
diagram so that's why I'm writing it
here
okay but but we will use the notepad
from the X class just pardon my bad
handwriting okay all right so what
happens here is that look at this there
is no where cross so I need to get all
the data out so what is the kind of
protocol that gets invoked here from the
by net the protocol is a broadcast
protocol right it's a broadcast protocol
correct so I go out to all the MPs and
say hey give me back the data that you
are responsible for so this one gives me
one and five this one gives me all these
three all these three and all these
three so these are finally over the by
net they are merged and I send that out
to the user over here okay
so that's how your
select is working okay before I go to
the next slide was this clear insertion
I am sure you would have understood now
you also understood this once the data
is inserted and staying in a distributed
distributed fashion across all the disks
you also understand how the Select is
going to work right your select will
also be distributed because my data is
in four different disks which are
attached to four different processors
and then these processors will are
operating on the data they are
responsible for right so finally they
are merged together send it out to the
user is this clear
okay all right now because what happens
is if you don't tell me I will not know
if you have any questions and then okay
all right okay so now let us look at the
next slide okay so all of these disks
which are called as V disks right what
happens is that they store all of the
tables uniformly okay so if I have 10
tables in a database each table will
have a footprint on each of the V disk
okay what when I say each table will
have a footprint on the V disk is say if
we have only one record here think of it
from that that you have to go to that
depth and thing right if I have just one
record then I cannot have that in all
the four disks right what will happen is
the records say for customer Row one
customer record one gets stored in this
am P all of these will have a header
saying that customer record customer
table is present but then so there is an
instance of this but there is no data
inside it okay so there is a so tables
you can think of tables as container
of data so you have you can have an
empty container with no data in it or
you can have a container with data in it
but that container will be there on all
your am piece and sorry not on all your
am piece that will be there in all your
V disks embiez are responsible for the
various so at times I mean as we move
forward people will say aim piece okay
at the moment they say am piece you will
have to think in your mind okay that's a
processor that has a V disk attached to
it and that's an EMP okay you'll have to
think like that okay
so what happens is these containers are
all instance here instantiated across
all the MPs but not all of them have
data if you have number of rows is less
than the number of MPs you cannot have
the same row in all the MPs right you
just have one place single version of
truth correct clear with this similarly
for the product table also you have
instances of product table and all the
aim piece clear with this okay question
what is the use of empty container let
me tell you that it is just for your
understanding
okay I do not say empty container what
happens is the moment you write say a
employee table okay you do a create
table employee ID integer and create it
executed what happens is your EMP table
also gets a instance here so EMP EMP B
but if I run a query to see if there is
any data in the EMP I have not stored in
a data right so even though this EMP
table has been instantiated which means
that it has been created and the
metadata tables the system tables they
know that there is a table called as EMP
otherwise if you run a select on IMT
table in Devon you would have given you
an error right if
a table is not created right so you can
have empty tables there is no constraint
on that right but once you start pushing
data right that's when these containers
get filled up okay that is all I wanted
to wanted to mention it is like making a
reservation in a good restaurant right
but then to enjoy the food you have to
turn up hit something like that okay so
it's a container saying that hey I am
coming but then I have not I have not
arrived yet right the data is not there
yet right or in a meeting I have
accepted the invite saying that a I am
there okay but then have I attended the
meeting or not right so it is something
like that
it's a token that says that there is a
table called as EMP and the moment data
starts coming in it is going to stay
here mark - this this this container
okay so this is - just to make you
understand the parallelism of of the
entire system so even when you create
the table you have these instances on
each a MP okay now was that clear all
right so okay
so hands-on we will we will do it from
the next class okay because we will have
to set up the system and then we will do
the hands-on right but from the course
point of view are there any questions
with the architecture that we have
covered so far
any questions here over the slides
we have covered today are there any
questions
okay so let me do one thing let me
unmute you one by one and take up the
questions okay
so Raj you're first just give me a
moment
hey Rajendra yeah how yes my question is
the ampÃ¨re venue creating the am is it
something that like we created virtual
vcp using the vmware how is the
partitioning how it is done actually is
it a sum does the binding basically
process a similar es es es yes yeah one
is that question another thing question
is not if you have a multi node so the
top layer what you are said where the
passing and this thing done is it
something they request for the client
outcomes or some low balance or
something or how it is done I did not
understand this question can you repeat
it or like like let us say you have a
four node system correctly dies right no
partition that was or system so the
client requests will be landing to some
point from where it will be destroyed it
is correct yes yes so that is then
something in between some the some load
balance or something comes into picture
or how it is done no I will I will
answer both of them so first is load
balancer the second one is about the the
virtualization aim PR how they are am
yeah how is it tied to office Nicolas
Winding happen got it got it very good
questions right in there okay I let me
let me explain them yeah
so let me go back to the diagram here
let us go here okay so what happens here
is that you can have wet so okay so let
me first draw something like this if I
have a laptop okay
yeah so if I say have a laptop here and
I have another laptop here right so just
two nodes for example okay now what
happens here is that these are say
connected using a physical layer which I
can say is the by net okay now what
happens here is that both of them have a
component called as parsing engine okay
PE which is this component okay this is
your PE or the parsing engine so the
parsing engine is responsible for your
session management so what happens is
node 1 which is okay let me say N 1 and
n 2 so if I have these 2 so what can
happen is this software module which is
PE 1 can handle up to 120 sessions all
120 connections so I I fire my first
sequel ok
it is responded from this parsing engine
and this one takes it up ok similarly I
have another so once this 120 is over
what happens is this parsing engine
takes over ok and this can also service
up to 120 sessions in parallel so your
next sequel the 121st sequel will be
serviced from this parsing engine so
both of these nodes are capable of doing
it ok and both of them can submit their
request to thee so they will basically
do a parsing which is syntax check they
will submit it to the optimizer get the
data out and then finally get a final
sequel token out enriched with
later okay this is internal okay this is
this is clear so far you are living with
actually that when you talk the adapter
is it something the node that would
terror it unknown or what and let's say
I am just comparing that this weighs
upon my I am connected phone line my
left over I am firing somewhere okay
send me D or someone like monthly saying
something let's say and my table is
splitted across four node that's right
alright so in that case the my client is
single mum laptop I am some connected to
right climb next a serial hi do this
right there is a sequel yeah alright so
there is a sequel assistant app write an
application that makes this request so
one has to have an a an IBM correct and
then let me change the pen color so it
will be easier okay and then what
happens is this thing is your server
yeah right this thing is your server so
yeah yeah and on the server you need to
have a software module that listens to
incoming connections correct well so
holy right yeah that is what you will do
so you will have to listen to incoming
connections so your incoming connection
is from your sequel assistant so the
parsing engine has a module that called
as the session manager that listens to
it and then assigns a pipe so whenever
you push request right you are basically
getting a dedicated pipe using which you
can so once you do a log on right you do
not unless you don't do a log off this
will open this will remain open this
connection right yeah correct and you
keep pushing your request through this
pipe right this is correct this is this
is clear now what happens is when your
when this sequel reaches your optimizer
that's when your explained plan or your
optimized plan gets generated
that's the load balancing part
in that you are talking about right that
how do I get the data yeah my question
little depended say I have a for system
each system at for hardest and II system
have let's say I to know let's say four
processors okay the first thing it's not
that is like any single node that
concept is very clear it will some will
some port will be listening their
requests and it will do the unit of
generate the plan and send the request
for same system but if there are force
physical system okay okay right well
these right right right right
so these systems see these these systems
they are not so these are connected
right what will happen is these systems
are connected via a pipe yeah right they
have to be connected by so fast
requester the requires long blindsight
will go to one IV somewhere right
any one of these nodes take up so I am
not sure if you if you have experience
with like if you have Cassandra or if
you masterless systems right any of them
first service the request once it knows
that this is a requires that I have all
got service to then it tells all the
other neighbors that hey there is a
request and whoever has the data just
start giving it okay so that is I got
optimizer does clear down on them okay
open any one of them okay you get the
request and yes as on others note
section in okay based on that data where
data line it will distribute the request
to their regular moves right right
absolutely
okay what was the second question if it
was one more question second question
was the mapping dipping app and the
physical disk it does carry some like
where we map basically de vocht in this
process at this table or this it's a
configuration
yes absolutely you were correct it's a
configuration so see if I have so what
will happen is if I have a a processor
here right so what will happen is okay
let me let me
draw it in this diagram itself so say I
have this block here okay and this block
is currently using at the okay and let
me draw the physical layer using any
other color blue okay and in the
physical layer I have a actual processor
and I have a actual physical array
correct so now what happens is this disk
or this is called as a V disk okay this
part is called as a free disk or a
virtual disk okay and this is your
physical layer so this is your physical
array okay now what happens is if there
is a failure in the physical array but
your CPU is still running right your
physical CPU is still running so
basically this am P is still running
yeah correct now if this disk is not
available if I have virtualization built
on top of my physical layer what happens
is say this conflict this conflict gave
a number say 1 0 1 ok which is basically
the place in the disk for which it was
responsible for correct if I know that
there is one more physical array that
starts at 3 0 1 where my data is
replicated so will see all of that in
module 4 so if I know that from 3 0 1
the same data has been replicated fall
back copy ok so this V disk only with a
change of config it can start pointing
to this physical array right so there is
no need of any down I mean I really
don't need to do a server restart or
something all I do is so this is a hot
swap right I change the config and my
data becomes available again
so this replication is happening at the
rate let the physical heart rate
or it is a softer way and at both the
level yes
in the physical level I have read one
which is mirroring and radis okay which
is the parity bit at the physical level
so at this level oh yeah and then in the
software level what I do is the copy of
V disk here say if I have 10 which is
the ID I will have a copy of 10 in
another video it's elf so that is the
configure hornucopia we needed it l
fallback is always 2 unlike Hadoop or
unlike the no sequel systems like
Cassandra where you set the quorum or
you can have I mean basically you can
have a replication factor right RF equal
to you said that what it is - article
also has the same yes yes yes but here
the fallback is - oh yes the fuse okay
right yeah okay any any other question
any for any follow-up questions yeah
thank you all right okay all right any
anyone else no problem no problem
alright and any anyone else any more
questions okay all right so let's do
this so if there are no more questions
let me remove the drawing let's see if
we have something remaining right so if
there are no more questions then let us
wrap up okay and thank you for being a
wonderful audience right so I hope to
see you in the next class there is a so
this is okay this is the marketing slide
okay so I I really don't like this but
yeah if you if you want to join us there
is a flat 15% off that's going on
currently okay you just have to log on
to the portal and there is a carrier
booster as well that's going on okay
so let's meet in module one okay I hope
to see you in the batch and thank you
again for joining in have a good day or
a good evening for people in Asia and a
good day for my for people who have
joined in from the US and the Canada
okay
so thank you so much and I look forward
to talking to you once again okay thanks
for now</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>