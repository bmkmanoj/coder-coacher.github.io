<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Talend for Big Data: Secret Key to Hadoop | Webinar -1 | Coder Coacher - Coaching Coders</title><meta content="Talend for Big Data: Secret Key to Hadoop | Webinar -1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Talend for Big Data: Secret Key to Hadoop | Webinar -1</b></h2><h5 class="post__date">2015-06-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-HijBjFjf-U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is your host and trainer nine for
this webinar and on behalf of Mitrovica
I welcome you all on board for joining
this webinar and let's let's get started
let's get the ball rolling for this
exciting course which is called as the
non-programmers swiss knife for big data
which is talent for big data tool the
key for this course why this course is
different because it's a non programming
way of learning let me give a quick
introduction about myself and this is
like almost having a decade experience
into data analysis data integration big
data as well as business intelligence
domain and we have implemented many
projects for a lot of clients in terms
of starting from small-scale poz to big
scale implementation in the Big Data all
right and now why this post is different
and how this webinar has been
distributed I will just explain you very
shortly now this webinar has been
explained in the first 20 25 minutes I'm
going to take you through this exciting
content of what is talent for big data
and why talent for big data and then the
next 15 minutes are we have kept
especially for you for the different
question on some rounds that you might
have on your mind right so there is a
question on the board so i can keep on
tracking all of the questions that would
be probably popping in in the question
window so feel free to keep on sending
the question i may not be you know our
keep on answering them in frequently in
each minutes but we would be taking for
all of 10 to 15 minutes in between and i
have been i'm pretty sure of taking up
all the question that you have in your
mind and why as i said why this exciting
course of talent for big data because
this is non programmer the non MapReduce
programmer swiss knife those who do not
want to learn the big day
the programming way or those who do not
have the privileges of time to learn it
to the MapReduce programming way this is
the right set of technology this right
set of decision for most of them all
right so let's get into the business how
this serena has been distributed at the
end of the session you'll be able to
understand how the etl is complementing
the Hadoop ecosystem how does it adapt
to the etl Big Data industry and
understand why talent is used with big
data learn the big data that's a
challenge by Dallan public didn't learn
the big data not in months but in
minutes now understand the use case the
banking industry and implement italian
job with hadoop alright so that is
primarily is today's agenda and in
between i will be keep on looking at the
question window so i hope you be you
you're familiar how you can send out the
question to me unfortunately your audio
is not enabled you can send the question
through the chart to me I can I can see
most of most of the question that has
been asked through the session yeah
alright so moving forward that is more
or less than agenda for today's webinar
the most exciting one of the most
exciting slide ok what is what is this
etl district data all about here is
predominantly a graphical abstraction
layer on top of the Hadoop application
and this really makes life so easy in
the picture the buzzword and now the
surprise and stuff is the current balls
that is and the question that is
arousing at the end of ETL and even the
data warehousing is the lack of pushback
and the analysis of some of the
outlandish commencement I mean to very
honest the typical assertion is that
Hadoop eliminates the need of atl now
seriously that's that's not the truth
sale right
now what no one seems to question in
response today's sort of comment is the
Needham assumptions these comments are
based on is it really realistic for most
of the companies to work all of their
data into Hadoop just like that well
there are some basic fundamental
question which still needs to be
answered in a very basic level right now
talent for big data just answers one of
such pain factor most of the people and
there is a pigment in the market and in
fact the way the Big Data industry is
evolving first game sdfs the game
stories then came the retrieval
MapReduce programming then came a
different areas in technology to
complement the MapReduce aim to educate
n to benefit most of the programmers
across the world is high which helps lot
of sequel programmers and then comes the
big which is scripting again right
moving ahead what does etl will Big Data
if you can see the slide whether it's
machine data the transactional data the
business apps data all of them it's
about at the end of the day it's about
the extracting from Samaria and then
loading it into some media through atl
and the walkthrough big data ah well up
if you ask me then to me big data is a
never you know erotic science or a new
concept it is always there but the wave
big data has evolved in the recent years
is phenomenal right but what no one
seems to understand is before even you
jump into the pool of big data you need
to be expert in the data analysis or the
tenant aggression that's exactly what
Alan has to offer it's a fine blend
between daytime deposition and big data
all right
now is writing etl script in MapReduce
code is still etl yes it is now is Ethan
running faster in few cases and slower
in others unheard of eliminating the ETL
really no never now his introduction of
a Duke changing when where and how he
kill happens yes the question is not
really this is this is very important
the question is not really that are we
eliminating etl but where does the ETL
take place and how are we changing its
definition all right there has been some
hand raised give me a second already now
that's that's that's primarily what does
ETA will Big Data it usage the finest or
it combines with et al and what et al
does best Big Data uses half of it etl
uses half of it and they use best of the
both words and makes the most out of it
right obviously those who know and for
those who don't know etl represents the
extract represents the ability to
consistently then we extract the data
with high performance t cross stands for
the transformation retain the ability to
transform one or more data set in the
batch and L stands for loading the data
into persistent or the virtual data
store that's more or less the ETL and
now combining this power of extracting
transforming and loading just you know
settling down it on top of the Hadoop or
the SDM this platform is exactly what
talent for big dinner has done now why I
was saying why this combination of ETL
Hadoop is unique in addressing most of
the business problem and how learning
talent for big data will address most of
the business challenges that we have a
distance the reason is talon is not only
a data integration tool not only a big
data tool but also at the same time it
is a data quality to it is a master data
management tool it is a year's me it is
a business process management tool as
well yeah so it's a combination of most
of the platform that any business
practice of any any customer may need
who is working on big data because we
did i can come in any form in any size
that's the reason we talked about 3 v's
velocity volume in variety so data
quality and master data management also
plays a great role and in talent
platform they come very handy if you
learn data integration in del f or the
big data then rest other tools arrest
other concept just come as it is yeah
now why do we call this as a one-stop
solution this talent for big data
because it's supposed to do it supports
watching it supposed scoop it supports
higher it supports team it supports its
base it suppose x catalog it's supposed
to see you name it they have talent have
a connector for it right it definitely
you know it is open source ilco system
right it improves the efficiency of the
Big Data job design it adds trying to
generate the code it runs the transform
inside the hadoo the native support for
sdfs Scoob HBase mahood the apache
license too yeah the embedded in the hot
invokes data platform it's certified
with the market leaders in the Hadoop
which is Cloudera mapa n grid block all
right
and three market leaders are there in
Hadoop which is hot rocks Cloudera in
mapa now one of the most important
question being asked is why thailand why
not MapReduce programming and this is
what the talent Corporation has to say
because the more connected the world
becomes the more quickly the business
must adapt imagine if you have certain
business challenges and you want to
write a technical solution for that
using MapReduce programming and say for
example you end up writing a 2,000 line
or code of you know Java or complex
method is programming would you prefer
that or would you prefer a simple drag
drop mechanism with knowledge of which
component will fit with what and then
you end up doing the same thing but in a
much smarter way in in a much SL freeway
obviously we would you know in this
fast-changing world where we need to
keep us updated with the latest degree
of technology we would prefer the later
one right now what is why and what is
this Talon Talon is only graphical user
interface tool available which is
capable enough to translate an ETL job
to am a producer the stallion detail job
gets executed as a MapReduce job on her
too and get the big data of that in
minutes this is definitely a key
innovation which helps to reduce the
entry barriers in the Big Data
technology and allow the ETL job
developers whether they are basic
developer but then the advanced
developer it really doesn't matter to
carry out that data warehouse offloading
of course with its active space
graphical workspace talent open studio
for big data which is free completely
free under a partial license enables the
developer and the data scientist to
leverage the Hadoop loading in
processing technology like its space as
gfs high-paying without having to write
a dupe application form ado publications
the seamlessly integrates within minutes
goes in
now that's the beauty of it if we
understand talent then we really do not
need to write any programming we really
do not need to know hundreds of
different technology all that we need to
do is just to know how do we connect to
the big data arian that's it the rest of
the thing is being taken care by tangi
by simply selecting the graphical
components from a palette arranging and
configured in them we can create the
hadoo jobs say for example we can load
from local file system to a dope file
system which is horrible distributed
file system HDFS or vice versa we can
use a do ping to you know transform the
data of a using talent and we can also
use the Hadoop I've using talent again
to analyze the data or the load the data
into the hive very table we can in fact
perform the elt and we can even use the
scoop technology to take the data from
the traditional database management
system release military database
management system to the high purity
right that's exactly I was talking about
now incorporating or integrating the
super power of Hadoop along with the
flexibility that talent has to offer
comparison to any other tool apart from
being a ETL tool is not a technical
detail loop it's much more flexible and
it's built on the programming kind of
platform and the surprising factories we
do not have to do the programming the
best part is it provides Solomon's
capabilities of programming techniques
within the components that whitter just
with the flag drop and logical job
design we can achieve many other stuff
that probably some of the other tools
available in the market may not be
capable enough and will generates the
that's that that's where the talent for
big data comes into the picture right I
think we got some
question out there Surya is asking okay
let me take a few question now is there
julia is asking is there in no coding
learning talent absolutely not no now
the map how this how this trick or magic
happens see actually talent is based on
eclipse based java based platform right
so the back kind of alan is ultimately
job that is one of the major reason why
Alan gels so well along with Hadoop
distributed file system or the or with
most of the market leader and which are
the hot rocks Cloudera and mapa all of
these market leaders they've already
tied up officially with talent there are
components provided using which and
arranging in proper order there is
absolutely no requirement of any sort of
MapReduce programming or coding right
Celia let's move in for Hadoop
application to be truly accessible to
your organization they need to be
smoothly integrate into your overall
data flows so imagine if you have
already have some 10 or 15 set up let's
say your resources are your workforce
who has no clue or Java programming but
let's say they are having little bit
background of database along with some
part of you know of ETL trust me again
re learning something from the scratch
like MapReduce programming is not
everyone's cup of tea instead of that if
we learn something which comes with with
a combination of not only a big data but
also with with immense power of data
analysis and data integration so that
would be definitely up over the power of
a best competition in terms of what
exactly is required in the market is
excuse me talent open studio for big
dinner is the ideal tool for integrating
the adobe obligation into your product
architecture why this talent provides
more than 100 closed connectors and you
talk about any kind of your system there
is delimited file fat file positional
file complex XML unstructured data any
kind of database now my sequel or actual
teradata icicle suppose you name it any
sort of or maybe it's a cloud anything
talent just get seamlessly integrate and
gets connected to the connectors and
West all is Talon volume obviously you
can use the drag and drop and readable
components to create the data
integration flow that move the data from
delimited log files into the Hadoop type
and perform the operations in hand
extract data from the i went to the
municipal database more and more
enterprise wanted to scale up in the
Hadoop dictator technology with the use
of existing pool of talent and reduce
the overspending on the MapReduce
program and this is one of the key
alienware lot and lot of enterprises are
focusing right so having unloading the
MapReduce program on all the big data
experts they are pricing right but how
does a organization can use existing
pool of resources now high-risk job
trend in the data scientist and data
analysis Thailand also comes along with
basic business intelligence
transformation so the demo that I am
going to show the useless that i'm going
to show you the william is that how come
a big data to is being combined with bit
of analytics as well and business
intelligence features which reduces our
dependency on the simple Excel dash book
Gartner remember this gardener is
featuring talent is the best technology
in the market for data integration in
the big data right and mostly any level
person in the industry and quickly get
started on this without much Barry
because it is I repeat without much
previous acquisitive
the myth the Icebreaker is I don't know
java programming how this course helped
me learn an excellent the big data the
biggest advantage you get with a big
data or the talent for big data is
absolutely there is no prerequisite is
if you come with any prior knowledge or
you don't have any knowledge it really
doesn't matter okay ah she is asking his
talent Abby I dunno it's a hybrid tool
it's a combination of a data integration
along with data analysis plus big data
and few of the features of VI have been
given but it's not a typical business
intelligence tool okay ranjan is asking
very interesting question does talent
create MapReduce code in the background
by simply drag-and-drop exactly as I
said it's not a native support
connectivity do with the java based
platform because it is built on java
based platform so simply what talent has
to do it can it just has to connect to
the hadoop or the big data area and rest
of the thing is been taken here by the
component but at the end of day on the
back end it generates MapReduce
programming only because that's that's
the basic logic developed by whoever has
developed the Hadoop HDFS or MapReduce
programming naveen is asking ok there is
a lot of question now coming up hahaha
all right I like that okay one ish is
asking sorry I attended the course laid
ok not sure if question does talent
generates and execute MapReduce code yes
absolutely it is but on the back end now
he is asking the Stalin exposed api's to
do any customization well not typically
with the kind of flexibility that you
get with the HTML but yes there are a
few of the lexus
being offered where we can do some
customization Naveen is asking how this
helped him learning in ms excel now we
island is one of the best tool to learn
any kind of complex XML with multiple
sheets it can reel it can combine it can
merge anything you can do even generate
also excel as output is as well as input
mohnish is asking again is it equivalent
to writing MapReduce code in Java and
executing on XDA test well there is the
catch you do not have to ride the
MapReduce crew programming or code and
this is completely different in that
sense that is the reason talent wicked
is so popular we have to just design the
logical job which is a graphical user
interface job you can you can understand
how we are designing how we are you know
setting up the environment if there is a
particular set of requirement which
component need to be executed but
absolutely we will not reap our hands
into MapReduce program modern is asking
how different is talent from tableau
well mother and I am NOT a tableau
expert but i have done few basics in
tableau i can confidentially tell you
that talent in terms of handling any
kind of data okay in terms of processing
it in terms of getting the business
requirement done in the technical
terminologies talent is very flexible
write your name kind of source system or
any unstructured data and it is very
flexible julia is asking but what am
there are bugs in talent and we would
like to edit the generated source code
well Susan island is built on native of
a java eclipse based platform if there
is any error when i will show you the
demo you can understand that in the
there is a separate lock screen if there
is any failure any other it pop up with
the screen end
it hints you we're in talent what do you
need to fix but we do not have to dip
our hands as i said into the MapReduce
programming motto is asking I am
surprising without any coding knowledge
how it is possible to work even if we
get any error or something least
knowledge is in modern MapReduce hahaha
mother that's that's the beauty that the
beauty of talent and big data in it and
it absolves the pain part within it and
it offers you a very beautiful graphical
user interface to work on so it's all
about drag and drop now it says thanks
for answering the question you're
welcome I mean difference is asking can
talent generated code be modified and
run they were absolutely but not with
their open source edition but the one
that they offered with the paid license
version you can have access to the back
and reproduce book and every point you
can a change but not recommended one the
reason is the flexibility and business
easiness is being given through the tool
not through the program okay when it is
asking because I have heard that
language is like begin hype okay after I
will take up to three questions we like
it move further others will not be able
to complete the webinar right when this
question is languages like begin hi
provide an alternate to my writing the
MapReduce in Java but they are slow as
compared to Java well image I think most
of here the audience all of you guys
might be aware why the pig in hype came
into picture on first place MapReduce
programming was only benefiting a bunch
of Java programs because it's it's
written on Java not everyone in across
the world they understand our the do
Java so some of the existing pool of
people who has a background of sequel or
the database programmer of the DBS I've
benefits them because it's a sequel
equivalent now those people who do the
scripting language like UNIX pearl shell
and all that big benefits them so it is
again at the end of day it is my
programming only but a more customized
one to make you know to reduced anthem
right what about the performance is
compared to the MapReduce code well it
is still among it is still MapReduce
code so there is no question of perform
acid in the same thing the only
difference is in a produced programming
you have to write everything from the
scratch you end up writing the whole
setup program if there is a 2,000 line
of code in MapReduce program in Tallinn
you can simply build a job within 2-3
minutes right so they saying is talent a
replacement of all high it big all
technology no it is not replacement it's
a complementary tool whatever people
have developed allinger's talent was
already powerful and rita integration
area and then has just developed the
plugins to all this i pay sdfs mappers
in all this area the talent is just
taking the advantage of already
developed area with its powerful
features or flexibility that it has to
offer to use data integration media how
telling is compared to informatica well
I will not be able to comment on that
model but I can definitely tell you one
thing I have worked on informatica as
well as i invoked on talent in terms of
flexibility or in terms of handling any
sort of data talent is any time better
or objective erson do you have any use
case of outer networks yes at the end of
the session we are going to I'm going to
demonstrate for new skills okay now let
me a mold a question now over there okay
let's move end and then after 10-15
minutes I will I will I will take up
other questions as well read well okay
so as you see big data in 10 minutes it
has all the caps on its feather the map
out the cloud another hot rocks and the
hundred right who uses talent for
bikaner whether you are a developer
within your manager with a working
professional or the leads everyone can
start working on talent and everyone has
some more other thing to be offered in
telling ya
well that's the interesting part we have
now finally came to the use case right
we're all about to see the bigger
picture let's all whicli see what alan
can do in minutes reducing the man-hours
and doing the MapReduce programming in a
tube yep many of the use cases that we
have developed on the past whether your
requirement is like as a banking
industry use case you want to address
the challenges in the growing the
business with the use of the big data we
will use the customer film that log data
elected by the band and then with the
help of big etl job it will answer the
question the most logical and the
business making profitable question
answer to where should the back hold the
board marketing campaigns for the new
product launch to get more business
these kind of business analysis are just
being done within minutes using talent
for Big Dipper ok well the use case that
normally I will demonstrate because they
are using completely open source
technologies so what I am using here in
fact any of the in any of the simplest
hardware machine or any of the laptop
this single node cluster can be set up
using cotton ones and both 1.3 i'm using
also talent of the studio but big data
5.5 this is running the system is
running on the windows 7 64 bit
operating system did you through the
poor gb ram and i3 processor my simple
as that yeah so this is a single node
cluster okay
this is a typical pink instead of
writing the pink scripting language
instead of writing the pig language this
is how a normal or typical big job in
Tallinn looks like whatever kind of
business calm and you might be having
say for example filtering the data or
filtering the fields to reduce the
volume of the data so that the job can
run faster or you want to do some kind
of mapper and reducer job in terms of
doing aggregation or if you want to sort
all sort of all of these things are just
minutes job for again talent cooking
dinner now the the be a functionality or
the way things run in this use case also
with that we have also have done up you
know use case where a leading band has
initiated you a new product launch
campaign across the cities okay in the
post company the bank wants to analyze
the collected data increase in business
and attract more and more customer now
how quickly can the news log files will
be analyzed and made some business value
out of it within seconds wanted to know
now let's explore the talent for big
data and join us in the this webinar and
see how beautifully talent does the
trick without any complex programming
well obviously seeing is believing isn't
it if that's not enough the same talent
and generate graphical interpretation of
the business data giving defender
business analytics tool as well right so
and the most important sly right how is
the trend was a like a trend yeah it's
growing and it's going guns each and
every em okay now
the entire course curriculum we are
having two batches upcoming benches one
in June sixth and one in july nine I
believe you can go and check it out the
timings and the dates on the website of
replica is where the entire course
curriculum has been distributed in ten
modules as I said learning big data is
not a rocket science if you ask me
honestly I personally believe it has
been too much height but I am NOT
learning too much of thing has been
spoken over the internet within the
Internet of so-called intimate of things
now that people have worked on less so
this is where we are going to focus we
are going to do more and more hands-on
to understand that how knowledge of
talion will help you and reduce a reform
efforts not learning some five or
technologies like I big MapReduce
programming and all that but you just
need to learn one technology just and
once you know that then we just have to
put the it's like a universal you know
adapter it gets connected to each and
every kind of platform so mod you'll
want to focus on the role of this
open-source technology and how does the
talent is revolutionizing the vagina
industry on module 3 we will completely
focus on how to be read xml complex xml
files excel files database tables have
extract data from tables out of the
delimited files any kind of the
hundred-mile in positional file which is
coming for me from systems right and
both the source as well as the target
how do we done structure of our data
which is becoming very popular but when
you realize that how much potential
karen has in order to read an
unstructured data then you will be
surprised module 4 5 6 we are going to
focus from basic to advanced level of
knowing how do we transform our business
requirement into the technical solution
and seven eight nine ten is completely
focused on the Big Data idea which is on
SD of this big hide and followed by
three projects
out of the big projects complete
business requirement projects one a
certification project as well so that's
how then can pick lemons 29 so then by
the end of this curriculum you should be
in a position where you can go for a
visa deposition from Hortonworks on
Cloudera are made from Tallinn apart
from the integral certification that you
are going to have from a bodega okay
please keep on popping up your questions
once we have done with the you know use
case then we will jump into the question
how how this curriculum books this is
supported by the higher live online
classes you are always welcome to access
the recordings if you miss out any class
then you can always watch out the video
recordings of the previous classes in
your learning management system we are
having a fantastic 24 x seven technical
support with Erica you also get lot of
quizzes in the project assignment from
this course for my side and in the end
of day at the end of curriculum you
receive a certification from under the
guy as well and that makes a lot of
sense in the market well I was I'm
already started taking him the question
before I actually asked you if there is
any question right well let's let's I'll
quickly show you how these things work
and how does the look and feel right if
you see here i am actually using a
sandbox okay
this is nothing but what you call your
big data box and this is the web URL way
of accessing it right there are files as
well
this is how your typical ecosystem where
her too because system looks like
without using hot woks yep and let me
check out one of the use case that we
can see now in the class
we can work on home on the use case and
explore how do we generate a VI graph
after simple you know analysis of form
what we call a job now be a graph which
occurred
typically if you you know look into the
in fact the talent for big data platform
as well that this is how typically I was
like yeah you see most of the
connectivity is being offered by the big
data but then you will talk about ends
base let's catalog sdfs I Eve in fact it
has opportunity to mobile TV big school
yeah in fact row Cassandra yeah apart
from that it has also support to the
traditional database any kind of
database name you may limit sequel
server or my sequel or Oracle or
teradata you name it the hammer they
have a connector for it right
let me just quickly run a job
yeah and I'm just calling in fact I am
also demonstrating in this use case that
you do not need to always run the job
from the girl user interface in fact we
can kick up the same job remotely as
well yeah now before we do that there is
a particular outcome in this big data
and let me show you where this file is
getting created output most probably
this dashboard will get created this is
a kind of output that we are doing a
company performance analysis as I said
right so we took out the bank analysis
yeah and they have been created by told
if you see in 26 everyone and 7th of May
one if i run this where do i need to go
yeah
okay see dr tan lend have to go to that
path and then we can kick off this city
jobs di
mmm
we need to call this particular windows
fine VI graph muscat on down pat isn't
then let me come back and check in this
folder which file you got created now
yeah it is the dashboard file right 316
native them yeah
so if you mark here in fact I have
developed few use cases for you where
you know simply but simply there was a
famous in the market now there is a
famous use case going on that also i had
developed here in talent afflicted after
you wear a particular neuron structure
dreadlock data gets analed analyzed and
the boost frequently used word or the
most frequently spoken word gets
calculated out of that unstructured
weblog data and it provides a result of
the most spoken word or the most kind
word in the unstructured work log data
which has been extracted from the
facebook or twitter or any kind of
social media so the way it works is from
talent you have to connect to this genus
then we transfer the files from the
local file system to the HD witness then
once the final comes to SD units we
start reading it then we start doing
them then we start doing they'll let me
use a marker here then we start doing
and i think the marker is not working
then we start doing all the business
analysis over here so if you see already
should shown you the kind of flexibility
that talent is offering in terms of all
the areas within this big I and simply
kicking off a single command externally
observe from here also we can run I have
just made the connectivity that I am NOT
dependent again on Ellen forget about
MapReduce programming even this is much
advance that i do not even need to go to
the tool i can just kick it off from
outside and the desired output or the
desired result is achieved a simple
graph isn't that great ok now time for
taking up all the questions you might be
dying now for me to answer the questions
ok we will take up all the question and
then we will draw from decision from
mine 15 okay Ravi asked from mine to
clean and we keep on taking the question
based on the first come first serve Ravi
is saying how do will apply it does tell
and open studios in with any artifact
job something else which will be running
in production is exactly there are if
you are running on Linux there is SH
file that the talent rates if you are
running on Windows its run it generates
up I hundra be yeah for the deployment
along with the Jarls yes
well sue month is asking how the friend
is talent with her two vs penn coward I
do well someone I had at least used some
of the cattle jobs in mental prior
developing them as well but in terms of
handling any kind of data whether it is
unstructured data or in fact complex to
complex XML kind of file a talent you
will find very easy very innovative and
in terms of designing the job setting up
the dependences talent is very cool yeah
so they are asking talent digital and
replacement of all hype pagan all
technologies nope it's a complementing
it's a complementary tool to make your
life even easier than begin hi yeah
Julia's can you please show you
screenshot of talent tool I think Julia
have already shown the tool itself and
I've and the job as well right so that
is gone what else
money she's asking very a very you know
different question assuming an
individual has knowledge in both the
tools any reason why would someone
choose to write code in Java versus
using talent who is talent to testicle a
limited time which is neat and invent in
there well that is the reason why talent
for big tonight so popular right those
resources are those of teens of those
companies will which are not aware about
the capabilities of such tool existing
in the market they will end up doing the
MapReduce programming s influence that
Julian is asking how can i am the whole
ecosystem aperture who playing I'm
zookeeper and all that stuff for working
with talent so yeah the beauty about
talent is Alan itself is a great day 9
degree khatoon so all Italian has done
the cavernous is it has just developed
the conductor to get connected to these
environment that's it slowly I saying
will provide the ecosystem yes Julia
when you enroll into the course we
already have a multiple instruction
sheet in terms of how to you now know
now do you install all the guidelines
have already been updated in there in
the system so don't worry about that the
Pope is asking what is orchestration
orchestration the book is a family
within talent if you see this then the
components like or the process like if
you want to set up a loop like
programming loop or if you want to send
a batch batch of Records tender cuts
into iteration so that we have more in
both controlled on the records or let's
say I want to set up opposed to have a
bridge of that before my job what should
happen after my lord should happen that
sort of thing then I become in fact
among parent you can call a child job
all that stuff can be automated
completely automated in 10 the militias
asking does tellin installation also
enroll any server components like other
ETL tool well as far as open studio is
concerned no but their enterprise yes
we just need to install the client it
that's that's right at least for our
standalone installation so you're asking
as Talon works with big scoop and all of
the stuff then how can we have this
ecosystem for learning talent do you
provide the ecosystem for us yes we're
able to provide what about job
opportunities for fresher talent for big
data is just going guns mama ha it's
really booming and miss really demanding
more than is asking can't this be
integrated to read data from strong or
Windows Event log yeah I am sure about
Windows Event log Mullen I'm not really
sure on splunk because we are using
talent 5.5 what I heard his talent is
already developed 6.0 they most probably
might have given the connectivity to run
definitely all right i think i have
taken a most of the question there's a
more question my module is talent this
course NM to have job shipped or need to
learn other tools as well like height
big etc if i want to show to tell them
what would be the topic well mallu to be
very honest you do not need to learn
either MapReduce programming method sdfs
nor height nor p but just a basic
knowledge of what is what is more than
enough to excel in talent for big data
just learn talent Allen for big data
that is more than enough anyone else has
any other questions because we are very
close to us end of the webinar and
before all of you leave I would request
you to Eve the feedback what do you feel
about the webinar about the course check
out the course curriculum the batch
standings on the website
all right and I really appreciate your
presence of this webinar and on behalf
of a building I really thank all of you
we have some few more questions now so
you guys asking can you view the port at
once through here of the fourth tab in
the port am in big data talent of us
rapper Big Data there is no access to
MapReduce program whereas in the tannin
for data integration you can access the
backend code which is pure java
programming see the spin yeah excuse our
program on the back end all right
and I'm pretty sure with this webinar
session you have already got a very fair
idea of what does gavin for big data and
i expect to see all of you on the next
batch one is on june six then what is on
july ninth cousin theme singh is saying
I'm already learning talent I am on
Italy in Big Data Hadoop modelica how
does talent would help me well learning
that way is you have to learn the
MapReduce programming as well if you do
not want to team type on you know put
your hands down on the MapReduce
programming with java programming then
this is the cause for you man yep I
thanks thank you again for joining in
this webinar and I hope I'll see most of
you on the upcoming patches where you
learn that how the data integration in
the big data both helps for you not only
being a big data resources are but you
also become a caduceus for the
organization yeah this is mike your host
of the today's webinar and i hope to see
you as a tutor on the upcoming matches
and Shirley are you need to contact for
that if there is any big days
availability or not of the patches what
I noticed the upcoming matches they are
Saturday Sunday seven to ten in the
morning india time matches yep all right
this is Mike you are for any queries you
can contact the technical help desk of
erotica they definitely would assist you
in terms of enrolling in terms of
setting up the big data environment in
your machine now this is your host and
your trainer Mike signing off and I wish
all of you all the best and hope to see
you on the upcoming matches yep see you
bye</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>