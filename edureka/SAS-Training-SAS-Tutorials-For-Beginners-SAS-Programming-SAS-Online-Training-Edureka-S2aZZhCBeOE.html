<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>SAS Training | SAS Tutorials For Beginners | SAS Programming | SAS Online Training | Edureka | Coder Coacher - Coaching Coders</title><meta content="SAS Training | SAS Tutorials For Beginners | SAS Programming | SAS Online Training | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>SAS Training | SAS Tutorials For Beginners | SAS Programming | SAS Online Training | Edureka</b></h2><h5 class="post__date">2017-06-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/S2aZZhCBeOE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi my name is like a skipper and I'll be
walking you through the sastra me giving
you what's asses what the data analytics
how the job scenario is it says that
we'll move on to a case study to a
destroyed house as works in a real life
a little bit about my background I have
more than two decades of experience and
my first interaction with class was in
us during webmasters if that was in 2004
that was the first time whether I was
doing my thesis I learned fast and I
felt that it is something which I've
addressed it and along the way I had
been doing different projects with sass
and also I'm a bass a certified
professional owned by JD since 2006 had
been in two different analytics tool
sestak one of them and there are others
as well so I'll just focus on self
rather than going into other tools so
we'll get out with our training for
Sasha and our what we expect in today's
reading is data analytics
what is it out of the pick that Arabic
tools why sighs what is as Saskatoon's
pouring itself use case use cases the
case study that the SAS job threads
so you might have heard of that a date
aside this it's the sexiest job in the
31st century so what is data analytics
now if you go to Walmart or say big
bazaars here air or any other
departmental stores wherever you check
out you see small things like the free
goods or lip-balm
now how are these things place here why
not bottle of oil why not say something
bigger than that I detergent now there
is a logic behind it what they do is
they study the trades they send me how
people buy what things to be kept clear
it which will increase the sales so
there is a study behind it which is
called data science or analytics that's
how the things are placed where they are
it's called Market Basket analysis
people who are buying this should be
like this where you should be putting
something in the store to get more sales
now data is everywhere and it says that
you have to recognize a pattern we have
to recognize how it works to grease our
sails so there are analytic space the
way for the creation of Beckstead
products now as I was metric that where
to place it the insert this place when
you come up with a bottle if the body
can be developed into a product and you
can have that sold out in the market
that this product actually optimizes or
maximizes your sales data analytics help
manage resources so as to reduce costs
faster and better decision-making
earlier able to better work related
messages meeting customer needs through
better services so primarily it's a
Dutch cell it's actually helping the
customers helping the business customers
are finding their stuff easily the
business is getting more budgets so as I
mentioned it a small example so this is
all entailed in data analytics or data
aside so data analytics you get the data
you will get some historical data you
will actually prepare it better plate it
develop a bottle of it and take some
decisions based on it data analytics
exam it's large and different types of
data to uncover hidden patterns
correlations
site correlation is people who are
buying sub product a will buy a product
B there is some correlation between the
two he did package are in the beginning
of the bud people buy this kind of
products so those are the patterns you
can discover from the data there are
different data analytics tools you have
the paid tools and you have the open
source tools so you have the distinction
here paid tools SAS tableau excel click
view slug open sores are are Python
Apaches part which is getting go back to
the Apache a stop big at high the
difference between paid tools and open
sources paid to you can get support from
the vendors whereas open source you may
not get any support paid tools the
wherever there is a new patch it can be
installed and you'll get to know that
this is a new pick color yet you can
just selling it whereas the open source
it is red the bad anyone can actually
publish it kind of have its lab when you
are it could be pipe a red zone
so the question comes by fast there are
so many tool to the market SAS in the
got first magical quadrant it's the
leadership quadrant at this point it has
maximum market share it besides that
it's ease of learning data handling
capabilities graphical capabilities it
works but it boosts job scenario what is
ease of learning SAS is easy to learn it
provides easy options for people who
already those is equal R on the other
hand has a very steep learning curve as
it is low level programming language so
as it written that Iran has a steep
learning curve there are SAS or the
other hand be it's equal beads has
provided it's much easier to write those
codes or if you write a proxy equal such
as the sense that it's a sequel
statement which is coming up and you can
write after opening a proc sequel you
can write all the sequel statements and
that word acquit
data head like SAS is on par with all
leading tones it will regard piped when
it comes to pending huge amount of data
adoptions for parallel computation now
there is a SAS grid also in the market
now but
actually splits the partitions it kind
of had this news data here any analytics
tool if it cannot handle use data
because Bohr is the data better is your
prediction so data Headley is another
capability which SAS is good at
graphical capabilities SAS provides
partial graphical capabilities with a
little bit of learning it is possible to
customize of these plots so once you
actually get it to a size you can see
graphical plot edges it's like a
cakewalk SAS releases updates the
control environment heads they are very
tested added by third order that have
open contribution and there are chances
of errors in latest developments so as I
mentioned SAS is a licensed software so
whenever there is a new release as its
budget here so SAS release is updated a
control environment it's they are well
tested and you would know that there is
a deep patch with so many such and such
features you'll get a support as well
for our invited that would not be there
globally says is the market leader in
available corporate jobs
so besides jobs SAS also has a maximum
capture of the metro market share of the
data analytics so I think in 2050 the
data was like 35 percent market share as
far as job predator good search as the
pros about 70% of data analytics market
share compared to 50% for arts that's
indeed statistics
what is SAS statistical analytics system
is a software suit for advanced
analytics multivariate analysis business
intelligence data management and
predictive analytics so SAS has used not
just for analysis purposes even you have
the Quality Assurance project management
data integration all those things are
also exact they have the platoons for
that in fact there are customized as
tools or software's for my clinical
domain for integration or the EDF piece
you have a SAS data integrator so they
don't come up with several tools it is
developed by SAS Institute SAS provides
a graphical point and click user
interface for non-technical you
more advanced objects as language sass
features it's flexible exceptional
integrated powerful it provides missile
solutions so I'll be repeating what I've
been saying so business solutions of
course you can develop the models on it
analytics of course decision-making on a
predictive model data access and
management so it can access data from
different data bases also from the files
reporting it graphics of course you can
have SAS VA or it's the SAS reporting
tool and the good graphics as well as
even if the basis there is like a prop
summary of proc report which can
actually pull up the reports for you
visualization and discovery
visualization point to visualize or you
lotta graph you can even see there are
the outliers or hobbits is a variation
between the bottle of actual data points
so visualizing certain discovery is
another piece what you can travel here
let us look at some of the features of
SAS detail reporting as I mentioned it
could access data from the print sources
the flat files Oracle or other databases
it can pull the data a tape or out of it
or it gets said that it works to
recipients directly without you can
schedule the program a bit can't fit
that puts there are access of data from
different sources be the text file CSV
Excel or different kind of databases so
that there is a good number of data it
could corrective the pull of the reports
transformations SAS data integrator
actually helps you with the
transformations
it's a ETL tool like you have Oracle
data integrator it's America and so on
there are four capabilities in SAS
access manage analyze present now in any
of the data size project if you see
these are the four pillars access is
like a data collection marriage is like
a data preparation or manipulation this
is again I would say the four phases of
the data science project then you have
analyze
the building model at that year is a big
difference of the data access is the
data collection and as I mentioned in
the previous slide it could connect to
several databases of the raw files flat
files and once you actually access the
data now one thing to be noted is SAS
desert directly work on your database it
creates a data set in SAS you will
actually import the data into SAS mods
in a fast library in a SAS format which
is a SAS 7 B deck once you have that
only dead sax will work on it so once it
is it only that you can actually analyze
it
better check SAS provides excellent data
management given any subset data create
variables validate and clean data so in
any of the data size project the maximum
time goes into the data preparation or
as as it is budget marriage so you can
create the subsets you variables are
created if you want to drop some
variables those can be done you can
validate and clean the data so entire
matter Paula should be is that in the
marriage we can perform simple analysis
like frequency at averages complex
analysis including regression and
forecasting SAS is the gold standard for
statistical analysis so variables it's
asked is like the columns as we call it
they're called variables it says each
row in fact is called an observation so
observations are very add variables are
how we actually move into SAS and
whenever you break the data into first
you have the variables on which you will
be working on or the columns as we call
it in the table they call variables here
so you can data plate some variable or
addition of variables creation of
variables are may be part of the data
you want and then you could work on it
so so SAS for analysis now you can do a
descriptive as well as predictive
analytics descriptives could be the be
median modes and the predictive
analytics could be the would be a
regression forecasting it currently do
all the stuff it's at whenever you get
the data
the first thing what should be doing is
to check the better data by pro/con tips
so prop cards actually lets us know what
are the variables how many observations
are there all those pics are actually
defied in this result of the proc card
that once you have recorded prop
Brigance another one which you should be
doing to see what the data is at the
base of that if you want some better
palacios you can do that at that kind of
work from there depending upon what the
project is whether you want to see the
frequency of something or the bead or
maybe actually it's a progression at
forecasting project we can present our
analysis in the form of this report
summary reports graphic reports well it
depends upon what the Oscars eventually
they'll be a report what we are going to
pull out which you have to show to your
say sea level executive or maybe your
clade
so eventually they'll be a report which
actually when you collected the data you
manage it paralyze it though some it
prints has come out which you want to
present so you have different ways of
presenting it it could be a list reports
like a tableau report summary report
summary report is like aggregated record
graphical report maybe some
visualization is required so those
things are all present itself coding it
says has just has two steps what is a
proc step if the other one is a data set
that's about it so SAS is pretty simple
that way proc step
and data step so from approximate starts
with a proc and then you have contents
proc or dead drop rate the proc Beebe's
heads to the rod data step also starts
with a data statement edge without a
proc sequel starts with a proc sequel
edge with a quit statement for SAS to
understand that it's a sequel statement
coming you will open up our sequel write
the sequel statements quit head data
step is data some data set name and
whatever data whatever the sashayed
which you would write at that it's going
to be run same for prog-rock contents
you write a data set a editor do you
have run so data step typically
the SAS data set however you can use
data steps to create raw data program
files at the reports the data step is
very flexible appraoch step typically
creates a report here is a small code
SAS code a SAS program is comprised of
sequence of steps and a step is
comprised of sequence of statements
every step has bigger a boundary these
are called
step out SAS compiles are execute each
step independently based on the step
boundaries here is a data set as our
specific data if that you have that
library dot the data set date where
country is equal to AU and Rud Rud is
where you're a bigot titled if you want
to give the title covers actually the
preceding words will get the title view
sales employees you printing the data
with a proc print data is equal to your
library they've got the data set then
after that it's a run statement which is
letting it know that the proc step heads
here talk needs data is equal to lambda
e dot data set AB and that you have
grouping it by job title it what
variable you are actually calculating
the mean Don or the average out is a
variable cell with a right you are
actually letting it know that it is
ending here at NSF begins with a data
statement and a proc step that gives you
the proc cited SAS detects the end of
the step that it encounters one of the
following are word statement for most of
the steps which statement for some
procedures the beginning of another step
so as I mentioned beginning it ending
it's actually written here in this slide
the beggining with the data step ending
with the run same for the proc will
submit the code it check the log but
results are as follows the first report
is a proc print report here is the proc
print report profit data is equal to
work dot new sales will submit the code
I check the log the results are as
follows the first report is a proc print
report we already gave it a title the
title is new sales employee the next
report is the fleet report air SAS
calculated the statistics for the
analysis variable selling the beads to
Caesar provides data civilization tools
to compute descriptive statistics on
your data and displays output by default
now by default it can give you the
number of observations be steadily ship
maximum available there are several
other receptive statistics which brought
me a gift but by default is going to
give these the ones which you are
actually looking at the next report is
brought into the pod here SAS calculated
statistics for the analysis variables
entering the bead procedure provides
data summarization tools to complete
descriptive statistics on your data at
this place output by default so by
default these are the descriptive
statistics which rockweed calculate
depending on your result you might be to
repeat subsets the power of SAS is that
you can use it to read any type of data
including the following three major
files the raw data files data that has
not been processed by any other computer
program though so it's primarily the
text files what raw data files are and
it can pull that records there are
different ways of getting it in let it's
as though that it's the columns you can
defy the where each column is started or
you can let it know that these are the
variables which are committed so
different ways of actually getting the
raw data pilot SAS dataset are specific
to SAS a SAS dataset is data in the form
that SAS gets under stood like raw data
file SAS data sets contain data that it
says data sets the data is created only
myself and can be that only I said so as
I mentioned earlier has will not be
actually working on the data in the
database or external file it will
actually you have to import the data
into cells library that he created as a
SAS data set and on that you can
actually manage analyze whatever you
want to do so it is converted into SAS
format only dead sax word server SAS
program files can take SAS programming
code these instructions cell says how to
process your data and what output to
create you can say Madri
SAS program files so of course you can
make the data set as a public data set
or a temporary data center that Brady
data set the sides only as long as your
session is open the exits is open once
you close that it says the temporary
data sets are gone you can make them a
public data set by actually simulated a
coverage library that way wherever you
actually open the SAS you'll have those
files there data sets there and we can
work on it let's look at a case study to
actually understand house has works and
this will help us walk through our SAS
4Â° well it will relate it to the real
world so back data analysis using SAS
introduction for gada
what is this case that about came back
is a commercial market Delhi it has two
branches doors in southeast the bag has
a call center it eats up these two blood
stages to cater to the needs of the
customer data is stored in different
Excel files due to which it sometimes
gets complicated and then contribute to
retrieve information about the customer
so there are two call centers where
there are incoming outgoing calls for
the bags and the data is in silos so
Northbridge actually deals with their
own data south and east red beeps with
its own data the data store different
Excel files due to which the subjects
get complicated and time-consuming to
retrieve information about a customer
therefore they're looking for a way to
blend the data such that they have the
information they need in one data set it
also with that they are able to draw
some insights through the data what is
the problem statement
extract meaningful business side
insights from the bad customer by
merging both the branches data use excel
functions uses insight to fight high
value customers value correlations at
effect of sales calls or greatest
products the bag has to offer so so
we'll have for detail what we have to do
is analysis to be that
combined the data from both the back
brightest for further analysis find out
the total number of calls made to every
customer from outside his or her bread
so if a person is exotica today we have
thought about calling the south east or
south east for a customer calling to God
so the find out the total number of
calls with every customer from outside
his or her branch give a bivariate
frequency of customers by gender at age
group it's a cross tabulation that we
get there at age group find a relation
between customers age and the back
ballots
it is like the people or the customers
who are boring beige have a better bank
balance or vice versa
so those these are the things which we
need to figure out let's have a look at
this case study here I'm just going to
call the library where I've imported the
files and we will work on these files
now the files what we have are the
demographic files or the data set
demographic is like the gender or the
day date of birth it has the account
number of a customer ID and that there
are three more data sets what is about
the open accounts the accounts which are
active right now sir what is the not
call center data set which is about the
calls that the call was made what was
the duration of the call
similarly for South East we have our
data set for South East which has the
same data variables as there are in the
dot one but the only difference is it is
just for the south in the other word is
for that no so let's this have a
solution to few of the problems and what
we are going to figure out is bivariate
analysis as we are frequently in the
correlations and besides that we'll be
actually looking at some more I'll just
explain you what we are doing at each of
these codes here we are creating another
data set called demo one your formatting
gender to character type with a length
of 10 we have select the data from a
table data set regarding an output
library in format that is
how the data is covered in shame for the
date of birth now if cheddar I'm just
fooling if it's just F let me just show
you the file first if that it's going to
be easier understood why are we doing
this here as the data set the devil data
set which has a customer ID F name first
name last name city gave birth and
gender see the things here gender you
have FFN a la le so we wanted to be
consistent maybe completely or feeble
data but we have some basic data bus as
well
three same here so what we are going to
do is we are going to have this
concatenated as a day the date function
or say the date it says is taken as
first January 1960 as it's actually a
number exact first that we 1960 is taken
as a date zero from there on any date
going to the right of it it is actually
all positives anything before this is
all negative for example 31st December
1959 that's when we get as minus one
second January 1960 sass would read this
as one so that's how the dates are here
okay now I'm going forward what I'm
going to do is I'm just going to pull
let's say there is a blank here that
there is a dot here these are both basic
values if the data type of any variable
for example city variable the data type
is character it will be insured as blank
whereas here the data type is numeric
any dimeric basic value would be shown
as a dot so that's the difference this
is actually a basis exam question as
well where you then be asking giving you
something like this and ask you what is
a data type of this particular variable
and it's good to be a develop because
it's a dot here now for this actually we
are going to have the gender one gender
consistent how are we going to make it
consistent we'll just have a look at it
because we have some ma being M F it's
not consisted so what we are going to do
is in this code we are going to use a
character for seed called substring it
makes if this
variable starting from the first
alphabet going only to the first
positions
just pull the first alphabet R of this
if it is F that the dagger is female
else the terrorists bail so we are from
this particular data we just put in the
first alphabet if X M give it a bin if
its F give it a female regardless
whether it's completely le or away you
are just checking for the first letter
full name we are act like a guy dramatic
it is the uppercase using a compressed
function if there is a trailing or
Pacific black goes up to taken off and
then you could candidate it city
directly putting it in the uppercase age
what we are doing is today what is the
date today by this the date of birth can
be a number it may be a 2,000 or 20,000
divided by 365 converts it into the age
and here we are rounding the age 2.0
what so if I have a dress code
and now I pray that to see what I've
done of the code here is what I get
say we could wedded em ma as em into a
complete male-female right so there is a
statistic a via customer ID we did not
touch it City rewarded it to be debate
as capitals its capital so we wanted the
full name to be concatenated this is
concatenated age AG wanted it to be
calculated in ears so what we did was
today - the date of birth divided by 365
because it calculates days and by
dividing by 365 we are calculating the
years that we are rounding it up to two
decimals right okay let's move further
so there is a data for the dog call
center we are right now actually kind of
making the data in a forward where we've
ordered if then we can actually merge it
or affected depending upon what the data
is at what the requirement is if that
will finally come to the analysis let's
have a look at the data from North calls
it
with the call idea of the Count de Burgh
call type whether it's call coveted or
it is going out called duration a jebane
who called on this is a date
this is it assess form a date now what
we are going to do is we see the count
number is it needs more space to get rid
of this e so we are actually
aside you get 32 space called odd we are
putting it up forward we just have a
look at that account number we are
actually changing it to character there
is a put function which actually
converts DeBary to character from the
substring what we are trying to see is
whether the call was from outsider or
insider now the thing is to identify
whether the call was an outsider caller
don't you have a edit out is fine but
the better it's coming from north to
south east or south east north there is
identification so the code number is a
substring account number going from
first three positions not equal to what
do for not equal to the ring the broad
sector can't be recognized with
accountable if the account number is
starting with a point two four it is
from North if it is not equal to what do
for that the outsider else outsider is
equal to zero duration they died this is
it seconds we are actually converting it
into billets okay I have to print this
see if it says it's code numbers one two
four it's not an outsider but if the
count number is say one seven one
starting with what word seven one seven
word this is outsider call outsider to
what brought Center we have changed the
duration we have actually put this
instead of SAS format we have put it in
a different format here we we wrote date
died dot so that's our date night out is
coming so the way we have done it for
North Center similarly you have to do it
for the South Center because the data it
both of them it says the variables are
all the same the variables are all the
same but the data is different because
it's fraud north and the other one is
force also so what I'm going to do is
I'm going to repeat the same exercise
for so now since the data both of them
is the same what we have got we want to
do next is we want to actually combine
this data so there are two types of
combines what is the append the other
one is a much what is it a pen a pen is
a
cat edition of data meaning one below
the other
whereas mercy is a horizontal
concatenation of the data so for example
this particular one if this data let me
show you with an example here it looks a
variable a and B here you have some data
see zero zero one sees it is it a to see
zero zero four head here you have 200
300 400 and here you have variable a
variable see if the data here is let's
say C 0 0 5 3 0 0 1 3 0 0 2 and here you
have some other data car bike car when
you do a vertical concatenation which is
appending appending you will have this
data
Edie to have a variable
this is how the vertical concatenation
works what data above the other
regardless of whether there is a common
variable here so this is called vertical
concatenation
whereas bunching
different kinds of birds it's like same
like janitors equal you want the inner
joy and outer join left outer join right
outer join
that burns it here so it burn take what
you'll have is
variable ABC you have the data for this
one here
get the data for this
you know data here
hey Doc so this is a horizontal cut card
edition this is called burnsy
the birds at this is a bed right so
going back to our case study down in ER
case study what we had was the call data
the call data we have the similar
variables we are just going to append it
and have one file so we go to appendix
and have just one file it that we can
merge that with other data to actually
make some analysis so we did north and
south before actually appending it there
is another file which is called accounts
file I am just going to work a little
bit of the codes file what we're doing
is the count number we are very good at
the same format as they are in the
previous month so I'm just going to rub
this just to let you know that accounts
file has only de open accounts only the
open active accounts I would slip the
accounts which are active which are not
closed so it could be the data in the
call center files it could be that the
people call there and after that they
close the accounts and those accounts
would not be here in the accounts file
so accounts file is the one which has
the active accounts this is the counts
file you have the customer ID you have
the type the pallets what is the
direction of the balance open date and
account numbers so these are the code
numbers which are active big from North
Beach from south or east a dot I have
already told it's a dramatic data type
that's real it is dot balance direction
whether it's positive or negative and
the type whether it's savings CC current
account or ax
FB so the thing what we we need to see
is if this accounts file we have the
account number we have the customer ID
in the demographic file we just have
that customer ID P do not have the code
number add in the call center files we
have the account number we do not have
the customer ID so what that means is
the call center file cannot be directly
merged with the demographic because
demographic has a customer ID as a
unique key a call center files have
account number as a Greek key
but there is nothing covered with both
of that whereas it accounts file you
have both the keys here so through our
open accounts file we can actually
combine this data set we just have a
look at this now after we are done with
manipulating the data in all the old
data sets what we we are going to do is
we are going to append the door Fitz
outreach the data we just appending the
data sets
we just spread that
have all the data embedded here what do
for a good seven I'm just going to sort
it on the counter Berg and the called
out called out is a date with the person
caller that will do some analysis create
new variables here to actually answer
our question or the business questions
what are we doing here is we are
actually creating a call smart data set
by accountable we are starting it back
out number if the last code the birth
that last call I a DC Kate this is
another function which we are using for
calculating the number of bases last
fall this is an automatic variable which
is created but here we are actually
capturing that automatic variable last
sort account number then last call we
want the days called on egg today
difference between today and the day it
was called the day the person call we
are actually calculating the difference
if call type is if not call them the
last call is equal to this away we are
just capturing as I matured the number
of days since the last call if call type
it that content is equal to one else
call type is equal to zero whether it's
a caller outgoing call get is giving it
a type 1 or 0
so we have already affected two data
sets the two dog heads out and now we
have actually just spread this
for some of the codes which we have a
cover the code calling it it will be the
last one the last call see last stop
accountable is if the last call what was
a date from today you have to subtract
that day it come up with a number for
example here we have 2030 so one for a
three is the number of days it's the
last call this is negative two zero for
two died three should be we have data
for 2073 here so whatever the data we
have it's in future so that's the reason
it is negative and then you have here
call type whether in or out if it is in
we wanted it to be one else it is going
to be zero right now what are we going
to do is we are going to budge this not
a pendant we are going to birds this
data with account data so eventually we
are going to merge all the four data
sets to actually come up to the
bivariate analysis of correlations so
for magic the primary condition is you
have to sort the data by the variable on
which you are going to merge it so you
solve it you started the calls data now
you're going to sort the accounts data
here is the syntax for merging data call
account burst accounts and calls in a it
B so what we are saying is this is we're
calling the data is coming from a this
is coming from B and if a if a is like a
left join so whatever is the value it
accounts whatever the code numbers
president accounts those will show up
the reason for that is accounts has the
active accounts we want the active
accounts keep cost ID and account number
this is another option what we are using
the keep option we are actually keeping
the customer ID and account number from
the data set codes from calls we are
taking everything so it's just going to
merge this data
here there are active accounts which
have not called to the data center for
the time bid which actually this data
was captured and that is fine not
addition we have the customer ID account
numbers called on-call ID whether it was
in our duration who was age indeed
whether it was outsider the last call
and the call type he got out right so
we've already combined three data sets
we appended the call data from north and
south east dead we actually merge the
accounts data with it now the next word
is we are actually using a descriptive
analytics we are actually using proc
beads or the call count
what we are calculating here is class
customer ID a grouping it by the
customer storing the data it calls that
number of calls incoming calls be
duration of the calls average total
number calls some of the call types some
of the outsider calls that's have a
blast call so what we have this I'm just
going to run this
here we've got by default type and
frequency list it might not require
frequency is number of observations for
this particular customer ID is 2 3 4 and
so on total calls made 20 calls 1 2 for
whatever average total number of calls
just second we had the bead duration
sorry the average duration of course
number of calls which is the sum of the
call type sum of the outsider calls
which this is inside or the outside and
call outside recall is from one call
center to the other and the last call
last call is natural blast call last
call is where the last call was made to
the call center let's calculate some
more statistics here we are starting
this by customer ID and open date and
what we are going to do is we are going
to calculate the month of books one
third books is since where the person is
to bid the bank so we are creating
another rate effect or say the same data
set be a modified colligate accounts if
first start cast ID that month odd books
is equal to I D CK which is but we are
looking for buds I difficut function is
just going to calculate the interval or
the calculate the duration earlier we
calculated tour days here we are
calculating it of months but open date
today so you go to subtract from today
the open date opened a test bed that
hoodless open if that balance Direction
is equal to negative that we are
actually multiplying the balance by
minus month if the type is FB that the
ballot one is equal to zero so we are
looking for savings and current account
only dot the fixed deposits let us print
this
okay customer ID type we already change
it if it's negative we have multiplied
this by negative we can drop this
actually going forward because we've
already kind of concatenated there
whether the direction is positive or
negative open it
account number one phone book so my
third book says today - this date it's
going to give us one phone books ballads
but what we created is by multiplying
the side here with the balance this is
what we get here so we can drop some of
the variables for example we we have
this balance and balance one pretty much
the same so we can but what we have that
is if the type is FD we are putting it
as zero because we are looking for
savings read current accounts so we
don't want that and that's the reason we
put zero here otherwise a balance is
there but it's it six deposits
okay so we are actually reading the
statistics develop accounts for any
customer ID
how many codes are there some balance
the total balance maximum button books
is all be able to calculate here because
a customer ID they have different
accounts and the world what is the
maximum month on books for that
particular person he may have a current
account earlier but that he opened a
savings account so we are just looking
for that for example here this is being
captured with prop meets the descriptive
statistics what we have for each
customer ID we have the number of
observations one two three the lead Alex
study division since there is a squad
record so there won't be any further
division minimum at maximum similarly we
have the ballads open date but third
books 84 is a month on books here and
open date but I've made balances here
but needs rock beats may not work good
for open date it may not give you good
statistics but for balance it is going
to give you good statistics for method
books if there are two or three if they
give you good statistics so that's what
we calculate here but on books balance
it here are the number of observations
we had three here one here at broad for
balance we had the three observations
open date again there were three
observations if the person could have
opened a current account savings account
error Fe bud third books they were
opened up the single date the balance
again we had as mentioned above we had
balance positive negative or we they
have a current savings and FP here it
balance what we are actually eliminating
the FD and then calculating the bead and
here we are taking that time on the
correct savings and the FDA that is the
reason these two are different right so
just to have the data the previous data
look little better we are actually
dropping that type at Freck which come
by default number of accounts the total
damage in both our books
this is what we get for our account
stats which we created
right here okay right here this was
created here this data looks much better
than what it was earlier number of
accounts for each of them total balance
the button books total balance actually
excludes at least okay now we have bar
Zig the count stats which is the
statistics data what we had the call
stack which we earlier calculated and
the demographic before actually merging
it you have to first start it and we are
sorting it by customer ID because now
all the three data sets have customer ID
so after sorting it we are merging the
devil the count stats and the call stack
by customer ID we are dropping some of
the variables which are actually two of
them are coming by default data but we
don't want because we've already
calculated the age so we don't want that
here we see the gender customer ID city
full 8/8 number of accounts total
balance but not books total calls
average duration of calls number of
calls number of incoming calls outsider
calls in the last call so the entire
data set if I now related to the
previous one our slide when we started
we said access at that marriage access
was importing these four data files
manage is what we are doing or preparing
the data for our analysis which is that
except embed the presentation so all the
four pieces of the four framework phases
of a data science project which was
actually mentioned in the SAS framework
as access manage analyze add present so
excess emissions of managed piece which
takes the maximum time so much we have
this data in place with all the
variables what we can X do is go for a
bivariate by varying frequency if I go
back to our slide here give the
bivariate frequency of customers by
gender age group now with prop frac it's
always good if you have data categorized
if it is categorized
it's easy to interpret the
crosstabulation there as for example if
it's just ematic a person is in this
population has a 31 32 33 34 35 it's odd
if you have some other data where you
are actually doing a cross tabulation by
gender so if they don't give for 21 we
have one female for 22 year one man that
may not give you a bunch of information
but if you categorize it up to 34 very
hard 35 to 35 yard 36 to 50 metal and so
on that it'll make sense
I'll just show you what I'd say but but
this data we just have the age we do not
have this categorization and for that we
are going to use a proc format with a
proc format we are actually creating a
format called age and how are we
defining it loading 34 is calling at the
end twenty four point one to 35% ed
sword I'll just wrap this forward so the
format you have defied this format and
you have to apply this format on sub
dataset this case what we are doing is
we are doing a prop frac on this
particular data set what we created we
are doing age to gender cross tabulation
or the age variable we are actually
applied the age format and let's have a
look at it
senior this is a cross tabulation of age
versus gender or the contingency table
here what we have is the top row is the
frequency and underneath it is a
percentage so in this population we have
thirty five point seven one percent of
females which are young we have thirty
five point seven one percentage of males
which are middle-aged seven point one
four percent of bills are old and on the
sides what we have is this is a total
percentage of young people of this
population this is the total percentage
of middle-aged here the old coding even
person ages thirty five point seven one
eight bill percentages 64 for tonight we
have one digit which will not be
calculated here so that's how we
interpret this and the reason why I'm
saying was characterizing it or say
categorizing it was now we have young
little old except if we had left the
data the braid was it would be Kody what
would you do 33:34 exhort the villages
for twenty one you have one female
thirty two year one male but that's not
going to give us any good output or any
good inference but here we can have a
good it prints
now the next constant if we move on to
instead our relationship between age age
of the customer and the total balance is
there a relationship if I go here and
calculate a prop call prop cord is a
correlation between the two age of the
customer in the total balance so we are
doing a variable age big total ballad
and it would provide us the statuses
first of all it is letting us through
big variables talking where Alex
variable age mix it is telling us of
giving us a simple statistics so by
default it is going to give us a simple
statistics as we had 15 for age maybe
the date of birth was missing from one
of them so we had 40 whenever this is
calculated there is a basic value the
basic value is not taken into account so
this average what has the gap
space of the protein observations that
as lessons can collided on number of
observations here which is fatigue so
this is the simple statistics which
comes with proc means has been by
default discovered proc or what we are
interested in is best piece at the top
is a correlation they are negatively
correlated they are negatively
correlated and this is a p-value so
p-value most of the dust trees if it is
less than point zero five they say that
the relationship is significant and this
is called a roll call Pearson's
correlation coefficient we are seeing it
negative and we see this inflation as
significant what this means is as a
increases the total balance is
decreasing that's what it tells us
next what we do is is there a
relationship between the age of the
customer in the city is there a
relationship now we are tempted to use a
park or gate to find the correlation
Falkor only works on dimeric data so
what it is asking for is go over the
categorization what we created we have
to do with that where our stock or will
not work on the character data it just
works about thematic data so what we do
is we use a chi a chi-square test
chi-square test is actually a test of
Association whether the two variables
are associated or not so there's a null
hypothesis that they are not associated
or a dependent and the alternate
hypothesis in this case they are
associated so what we are trying to
figure out this if they are associated
or not this will give us several other
statistics but we will be concerned with
the chi-square test only it will just
see how it comes and what we are doing
here is we are doing a cross tabulation
of city and age and on the age we are
actually like the age format which we
described here right so first thing what
we get is the cost of elation between
age at City here is the prof like cross
tabulation of the continued stable
and here is what we get what we are
interested in the chi-square we get the
value of chi-square a 13.3 one the
p-value is point zero one which tells us
that this is significant and we will
reject that null hypotheses and say they
are associated because our alternative
hypothesis is that they are associated
and null hypothesis was that they are
not associated how is the degrees of
freedom coveted degrees of freedom is
rho minus 1 multiplied by column minus 1
so that low- was is you have got 1 2 3 4
5 rows 5 - what is 4 and you have 1 2 3
columns 3 by this one is 2 so 4 into 2
is 8 that's what the degrees of freedom
is meaning if you are calculating
degrees of freedom for this you still
have 4 rows left at 2 columns here
that's the degrees of freedom for each
of the cell so as I mentioned earlier
that it's actually a test for
Association the chi-square is a test for
Association what you are trying to find
out is whether they are related or not
so in this case with our p-value
significant we will say that they are
associated CP and 8 are associated so
there is a relationship right ok now
let's see with our case study we have
come to the end of it and let's go back
to our slides the job threads so here
what we see is of the job for each this
is a february 15 2017 what what the data
has been pulled out or set a job
postings what we are seeing is that our
sorry the data is not pull up everybody
it's just a mark what we are seeing was
for February 15 2007 t of February 15
2007 T they were SAS the following is a
job thread force a success model across
the word SAS has been market data when
it comes to data
the next jobs so 47.2% data analytics we
will see SAS it says modeling as 11.3%
but this trade actually kind of peaked
in 2015 which was like around 58 percent
in SAS save in the SAS modeling also we
would see the terms where SAS modeling
was used in the Job Description that
also spiked in 2015 to like twenty four
percent or so so at this point I'd
probably fifteen when it was pulled out
we can see forty seven point two percent
of data Arabic jobs short SAS it says
modeling was another eleven point three
percent so quite a substantial data
analytics job has Farid in that so
that's what this graph tells us
now let's summarize before we conclude
we learned about data analytics as I
mentioned data is everywhere we have to
find the patterns you have to find the
sub predictions for the future a base of
that we can actually plan our inventory
the kind of increase our sales or the
markets data analytics tools that are
paid as well as open source tools SAS is
the leader it's the leaders quadrant the
paid tools the it's the leaders quadrant
of garter and there are several other
tools cavalo excel click view it's plug
open source tools in contrast do not
give you any support the new patches
it's not nested it's just people develop
it at this I just put libraries in our
chain that other tools the SAS is that's
easy to learn to hear the data handling
capabilities are pretty good graphical
capabilities it works for the tools is
like they are covered up with different
tools for read for each of the verticals
for example is image in the clinical
data for clinical analysis they have
like medical SAS it said for other
verticals as well so SAS actually is
used for analysis it can use for quality
assurance you can use for project
management it can use for reporting can
be used for data integration so
different kind of tools for SAS or the
combated SAS which actually makes SAS
useful in several areas feature success
so as I mentioned the four pieces of the
framework the access the management the
analysis at the presentation so it
provides the business solutions by
accessing the data manipulating it
analyzing it coming up with a bottle
which gives us a prediction whether this
is going to be good or bad for our
business and it is accessible integrated
and powerful tool we also learned about
the Corrigan says we went through the
case study to actually see the business
use of SAS and it had we actually saw
the SAS job threads which was
we are seeing quite a good number of
data analytics ups on I would say almost
half of the data analytic jobs in the
market a crossword actually shows SAS so
it's a good tool to learn and of course
has a good potential
good job market as well so I would say
it's it's good tool to learn with that
I'll come to the end of this
presentation well thank you I hope you
enjoyed listening to this video please
be kind enough to like it and you can
comment any of your doubts and queries
and we will reply to them at the
earliest to look out for more videos in
our playlist and subscribe to our red
Rica channel to learn more happy
learning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>