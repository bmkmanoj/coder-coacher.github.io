<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Docker Tutorial for Beginners - Part 1 | What is Docker? | Docker Training | DevOps Tools | Edureka | Coder Coacher - Coaching Coders</title><meta content="Docker Tutorial for Beginners - Part 1 | What is Docker? | Docker Training | DevOps Tools | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Docker Tutorial for Beginners - Part 1 | What is Docker? | Docker Training | DevOps Tools | Edureka</b></h2><h5 class="post__date">2016-10-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/h0NCZbHjIpY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi folks this is vaudeville America
today I'm going to tell you why doctors
the hottest technology in the devop
scene doctor is a software
containerization platform if you don't
know what that is then you don't need to
worry because I will explain it in
detail in today's session now before we
move forward let me show you the agenda
for today in the first section of this
video you will understand the subtle
difference between virtualization and
containerization and you will learn how
containerization is an upgrade to
virtualization I will then tell you what
is docker and show you what comparative
analysis between virtual machines and
docker containers proving out docker
comes out on top in every aspect after
that I will talk about Dockers working
architecture the second section of this
video will be a practical hands-on
session where I will show you how to
build your own images and it's been
continuous all of them this also happens
to be a practical lab Neturei karta ops
course so first let's talk about the
difference between virtualization and
containerization virtualization is the
technique of importing a guest operating
system on top of a host operating system
this technique was a revelation in the
beginning because you have developers
run multiple applications in different
virtual machines all running on the same
host this eliminated the need for extra
hardware resource and enable backup
allowing for easy recovery in case of
failure conditions thereby lowering the
total cost of ownership but
virtualization has some shortcomings
running multiple VMs in the same host OS
leads to performance degradation this is
because of a guest OS running on top of
the host OS which will have its own
kernel and its own set of libraries and
dependencies this takes up a chunk of
the system resources another problem
with virtual machines which uses
virtualization is that it takes almost a
minute to boot up this is very critical
in case of real time applications where
fast processing is a priority this along
with the fact that's carrying up the
number of virtual machines being a
tedious and costly affair gave rise to
containerization but what is
containerization it is a technique of
bringing virtualization to the operating
system level while virtualization brings
abstraction to the hardware
containerization brings abstraction to
the software do note that
containerization is also a type of
virtualization containerization is more
efficient because there is no guest OS
here binaries and libraries of
containers are run on the host kernel
which makes processing and execution
very fast even booting up a container
takes only a fraction of a second
because all the containers run on the
same host they are lightweight and
faster than virtual machines folks to
make this video more interactive I will
post a number of questions and expect
answers from you I will do this to check
we wanna so the concepts properly you
can pause the video for a few seconds to
read the question and you can put your
answers in the comment box if you don't
know the answers you can rewind the
video to the previous slides and learn
every moneyö detail and then comment
your answers in the comment box this is
the first of the many questions I will
be asking you today which is the below
options is incorrect containerization is
rebasing virtualization containerization
brings profits level isolation and
hypervisors manage the virtual machines
the correct option is continuation is
replacing virtualization that is because
this statement is not correct it is not
replacing virtualization it is just the
next step in the evolution process there
are still many circumstances where
virtualization is a better option if you
want to run an application in the Linux
machine and if you have a Windows
machine then you cannot run the
application and at that point of time
hosting a do not VM on your Windows
machine would be very beneficial I will
ask you many such questions in this
video so what is the entire video to
have fun while learning now let's see
what is docker
docker is a software container ization
platform which packages your application
and all its dependencies together in the
form of containers so as to ensure that
your application works seamlessly in any
environment be it development or test or
production this means that each
application will run on a separate
container and will have its own set of
libraries and dependencies this also
ensures that there is process level
isolation
meaning each application is independent
of other applications giving developers
surety that they can build applications
that will not interfere with one another
as a developer I can build a container
which has different applications
installed on them and give it to my QA
team we'll only need to run the
container to replicate the developer
environment you may have questions like
how does this help it helps because the
QA team need not install all the
dependents are and applications to test
the code helping them save lots of time
and energy this also ensures that the
working environment is consistent among
all the individuals involved in the
process the number of systems can be
scaled up easily and the code can be
deployed on them effortlessly now let's
learn in detail the benefits of docker
our virtual machines the image you can
see on a screen is very typical of how
docker is when compared to virtual
machines the space consumption in case
of a virtual machine and docker can be
related to the comparison of space
occupied by an elephant and a rack
starting up a virtual machine and
starting docker can be related to the
difference in speed between a tour toys
and a cheetah and when it comes to
integration virtual machines will say
what on earth does integration where as
docker can be comfortably integrated
with many DevOps tools for automating
manual processes now let's talk about
this more detail consider a hypothetical
situation where I have a system with 16
gigabytes of RAM and have to run three
virtual machines on it to run the
virtual machines I divide my RAM such as
my first VM gets 6 GB of RAM my second
VM gets 4 GB of RAM and my third VM gets
the remaining 6 GB now even if my first
VM uses only 4 GB of RAM my second VM
uses only 3 GB of RAM and my third BM
usually 2 GB of the allotted 6 GB of RAM
then I will be wasting 7 GB of RAM in
total this 7 GB of RAM cannot be used
for setting up a new virtual machine
because once any virtual machine is
allocated memory it cannot be taken back
later this is a major issue because Ram
is a very costly Hardware now how can I
avoid this problem if I use docker my
CPU will only allocate the docker
container exactly the amount of memory
that will be used
my first container will be using only
4gb of memory the second container will
be using only 3 GB of memory and my
third container will be using only 2 GB
of memory since there is no RAM that is
allocated on unused I save 7 GB of
memory by using docker I can even create
additional containers from the leftover
Ram now when it comes to start up
virtual machines take a lot of time to
boot up because the host system needs to
be set up first which will then run the
hypervisor which will in turn set up the
different virtual machines this is time
consuming and will prove very costly at
times when quick startup of applications
is needed in case of docker since the
container will be running on your host
OS you would be saving precious boot up
time this is a clear advantage of of
virtual machines so consider a situation
where I want to install different
versions of Ruby on my system if I use
virtual machines then I will need to set
up two different virtual machines for
running the different versions each of
these will be having its own set of
libraries and binaries were running on
different guest operating systems
whereas if I use docker even though I
will be creating two different
containers where each container will be
having its own set of binaries and
libraries I will be running them on my
hosts OS running them straight on my
host OS makes my system lightweight and
faster this is the advantage with docker
but what about integration integration
of different tools using virtual
machines may be possible but even that
possibility comes with a lot of
complications I can now only a limited
number of devops tools running on a
virtual machine as you can see from the
screen if I want many instances of
Jenkins and puppet then I would need to
spin up many virtual machines because
each virtual machine will have only one
running instance of these tools setting
up each virtual machine brings with it
infrastructure problems I will have the
same problem if I have to setup multiple
instances of ansible Nagios selenium and
gate it will also be a hectic task to
configure these tools in every virtual
machine this is where docker comes to
the rescue
using docker containers we can setup
many instances of Jenkins puppet and
many more all running in the sea
container or running in different
containers which can interact with one
another by us running a few commands I
can also easily scale up by creating
multiple copies of these containers so
configuring them will not be a problem
summing it all up I can confidently say
that docker is a more sensible option
when compared to words and machines
learn more about how different tools can
be integrated using docker please watch
our video titled DevOps tools you can
find the link to that video on your
screen and in the description below
folks it's time for our next question
suppose I have a system with only 4gb of
RAM and I want to run four instances of
a particular DevOps tool then which of
the below is the best choice for VMs
with four different instances of that
tool one VM with four different
instances of that tool or four different
docker containers with different
instances of that tool do take your own
sweet time to answer this question you
can put the answer in the comment box
which will validate at the earliest and
the correct answer is docker containers
that's because docker containers utilize
very less RAM and compatible machines
another advantage here is that these
four docker containers will be running
on the same host operating system making
your system lightweight and faster and
the other thing is that virtual machines
cannot be used here because each virtual
machine requires at least 1 GB of RAM
and we do not have that much resource
since our Rama is only 4 GB we cannot
use a complete 4 GB on virtual machines
but in case of docker there is no need
to pre allocate RAM and hence docker is
the obvious winner here so who can use
docker the answer is everybody docker is
designed to benefit both developers and
system administrators making it a part
of many DevOps tool chains developers
can write their code without worrying
about the testing or the production
environment and system administrator's
do not worry about the infrastructure as
docker can easily scale up and scale
down the number of systems for deploying
on the servers so how is docker used in
DevOps
doctors used 90% of the time in the
continuous testing phase and probably
10% of the time in the continuous
deployment phase dhaka plays a major
role in the continuous testing because
it sets up the testing environment it is
also used to deploy the code to
production and that's how it plays its
role in the continuous deployment phase
let's now look at how docker works
docker engine is the heart of the docker
system it works like a client-server
application matures a server which is
the type of a long-running program
called a daemon process and a command
line interface climbed the REST API with
the combination of a socket IO and a
tcp/ip connection is used for
communication between the CLI klein and
the docker demon in an energy operating
system there is a dark line which can be
accessed from the terminal and a docker
host which runs the docker demon we
build a docker images and run the docker
containers by passing commands from the
CLI client to the dock a demon but in
case of Windows or iOS there is an
additional docker toolbox component
inside the docker host this docker
toolbox is an installer to quickly and
easily install and setup a docker
environment on your windows or an iOS
system the docker toolbox installs
docker client machine compose kite
ematic and VirtualBox ok now it's time
for the next question how does the
communication happen between the docker
client and the docker demon is it
through the REST API is it a combination
of the REST API in the socket IO or is
it a combination of the REST API and the
TCP or is it just the combination of the
REST API socket IO and TCP you can pause
the video here and put the correct
option in the comment box and then
resume the video and the correct answer
is the combination of REST API socket IO
and TCP even though the rest the API is
the primary mode for communication the
dock edemen can listen to the remote API
requests where are three different types
of socket Unix TCP and empty this
information might not be there on the
slides but I specifically mentioned this
a couple of
back and folks that is why I request you
to please be attentive in class
so moving on to our next topic let me
tell you what our images and containers
images can be related to an executable
file images are the building blocks of a
docker container these docker images are
created with the build command and these
read-only templates are used for
creating the containers by using the run
command continue to the ready
applications are created from the images
containers are instances of images and
they hold the entire package that is
needed to run the application the docker
registry is where our images are stored
the registry can be either a user's
local repository or a public repository
like a dr. Hopp so that multiple users
can collaborate and building an
application even multiple teams within
the same organization can exchange your
shared containers by uploading them to
the docker hub docker hub is Dockers
very own cloud repository very similar
to a github let us now understand the
docker architecture in detail we have
dr. client a doctor who is running the
docker demon and a docker registry the
docker demon is responsible for the
images and the containers now if I have
to build docker image I have used a CLI
to issue a build command to block a
demon the docker demon will then build
an image based on my inputs and save it
in my registry which can be either a
docker hub or my local repository if I
do not want to create an image then I
can just pull an image from the docker
hub which should have been built by a
different user and finally if I want to
create a running instance of my docker
image I can issue a run command from my
CLI which will create my container this
my folks is a simple functionality of
docker
ok folks it's time for a couple of more
questions which is the below options is
correct with respect to creating docker
containers I can build my own image and
used for creating a docker container I
can pull an image from the docker hub
and then run the docker image or I can
directly create it off a container
without the docker image do take your
sweet time and comment your answers both
option one and option two are correct
because you first bill your image and
then you create a container
if you don't want to build your image
you can just pull an image from the
docker hub and then run that image and
create a container out of it but the
third statement says that I can directly
create a container without the docker
image this statement is false and that's
why the first two options are correct
now let's move to the next question
where does the docker demon store the
docker images is it in the docker client
from where the users type the commands
or is it from the docker host which is
running the docker demon or is it the
docker registry the correct option is
docker registry all the docker images
are stored in the docker registry which
can be either a local repository or a
remote docker hub this is the second
section of the video where I will be
showing you some practical hands on
these are some of the basic commands in
docker to pull a docker image from the
docker hub we can use the command docker
pull image name colon tag the tag
specifies the version of the image the
different versions of the image are
identified by the time to run that image
we can use the command docker run and
image name or docker on the image ID to
list down all the images in our system
we can give the command docker images to
lets down all the running containers we
give the command docker PS and to list
on all the containers whether they are
running or not we give the command
docker PS - a now let me run a sample
hello wall container and show you how
docker works let me go to my terminal so
here I am on my term loop let me first
run the command docker images
this lists down all the images that are
in your system since there are no images
there are no entries for me
same thing with docker PS as you can see
there are no running containers so there
are no entries let me show you by
running a sample HelloWorld container
how docker works the command is docker
run HelloWorld
since the hollow wall container is not
present in my local repository it will
pull this container from the docker hub
as you can see it says pulling from
library hello world this is the image
and it says pull complete and here is
your message hello from docker this
message shows that your installation
appears to be working correctly now let
me run the docker images command again
as you can see there is a new image
that's created with this ID let me do
the docker PS command and this is the
hollow wall container that's created now
that you know water docker images and
doctor containers let me show you how to
build your own docker images images are
comprised of multiple layers and each
layer is an image of its own they
comprise of a base image layer which is
read-only any changes made to an image
or saved as layers on top of the base
image layer the containers are generated
by running the entire set of image
layers which are stacked one above the
other for the demonstration purpose I'm
going to show you how to run a tomcat
and since on your local system I will be
considering this Tomcat in an ubuntu
village to build an image we have a
docker file the dock file is used to
install applications and build new
images the daka files contain
instructions for building a docker image
these instructions contain various
keywords like from run and many more
from indicates the base image from which
the container is build and run indicates
the command that needs to be executed on
that image for the demonstration purpose
I am going to show you how to run a
tomcat instance on your local system I
will be configuring Tomcat and Ubuntu
image to build Tomcat and one to image
we use docker file the documents contain
instructions for building and docker
image these instructions contain various
keywords like from run and many more
from indicates the base image from which
the container is built and run indicates
the command that needs to be executed on
that image let me now show you the
docker file that I've created for the
demonstration purpose
my dacha file is present in my demos
folder so let me first clear the screen
and go to the demos folder I'll do a G
edit docker file from a bun to indicate
that I wish to use a boon to run my base
image Tomcat will only run if I have
Java present so I need to make sure to
install both Java and Tomcat and my
ubuntu village and as you can see there
are three run commands my first run
command is to add a Java repository my
second run command is to install Java
and my third run command is going to
install my Tomcat this is the command to
add a Java repository along with this I
will run apt-get update command first
and then installed coal I installed coal
because later on I will be using curl to
download the tar file of Tomcat these
are the commands that will manage the
repositories from where we install the
software and this command is used to
create the Java repository now to
install Java this is the command used
and these are the other licenses which
are involved to install Java so the
third run command which will install my
Tomcat will first create a directory it
will create a Tomcat directory in which
it's going to download the Tomcat tar
file it will download the tar file using
curl and dwell on tar the package using
this command then I'm going to use the
RM RF command the Tomcat users or XML
file has the properties to manage the
roles in the Tomcat so this command is
going to copy the properties in this
file to this particular location let me
show you the properties in this file
as you can see these are the properties
to set the roles these are the different
roles manager GUI manager script manager
JMX manager status admin GUI and admin
script I am assigning the same username
and password to all the roles in this
line as you can see I am separating all
the roles by a comma
manager GUI is one manager script
manager JMX these are the different
roles and I'm separating them with a
comma and I am assigning the password at
Rekha and the username at breaker to
them so the next command in my daugher
file is the expose command expose is
used to ask Tomcat to run on the 8080
Porter after that I set my environment
variables for Java then I have the CMD
command the CMD command specifies the
entry point in a docker file I use the
CMD command to start the Catalina or
shell file in the bin folder by
specifying run now that my docker file
is ready let me build my docker image
let me go to my terminal I'm going to
clear the screen the command to build
the docker images docker build - T and
the image name colon tag and I give a
dot specifying that my TOC file is
present in this folder my demos folder
enter as you can see the base image that
is being used is Ubuntu and it's pulling
all the layers this is going to take
some time so my first pull is complete
now it's running the applicate update
and it's going to install my call
okay the first run is complete and now
is the third run my third run my java is
being installed
so my fourth command is running now
this is where my Tomcat is installed
as you can see my image has been
successfully built now I can run my
image the command to run my images
docker on I'll give a - p li 0 e 0 : a
throw a 0 this is to map my container
port to my host port folks do note that
I have used a - P flag here where the P
is lowercase now only if I am using a
lowercase P flag well I have to mention
the host port on which I want the
instance to run whereas if I use an
uppercase P flag then the command will
run the default host port to which the
container has been mapped and then I'll
just give it a name but then and the
container name as you can see my server
is up and running if I open it in a new
terminal if I do a docker PS command
you can see there is one container
that's up and running the Catalina shell
is running and it's active on this port
of mine so I'm going to copy this I am
go to my web browser and paste it here
now if I go here I would find my Tomcat
is configured as you can see my Tomcat
is configured let me go to manager app
and all my roles are visible here so
folks this shows a tomcat has been
successfully configured I downloaded one
to image and I installed Tomcat on that
and I created a new image and I created
a container out of the new image so this
is the ID of the container
and this is the name of the image
we can just start uh pstop containers by
just running a command from the terminal
we need to specify the container ID as a
parameters to to swap a container I can
just give a docker stop and the
container ID or the container name and
if I want to remove the container
altogether then I can do a docker RM and
the container name or the container ID
to delete an image I can do a docker RMI
and the image ID but do remember that I
cannot remove a running container so I
need to first top the container and then
give the RM command to remove the docker
container let me show you that in my
terminal this is the ID of my running
container I'm going to copy this I am
going to do a docker stop so this is
going to stop my Tomcat yeah now if I go
here you can see my container has been
stopped and have exited that container
now let me do a dock of PS command as
you can see there are no containers
running if I do a docker PS - eh it will
show all my containers which are exited
so I have a HelloWorld command and a
tomcat container which I created so I
can delete these containers by giving
the docker RM and the container ID copy
this and paste it here
so that's remote in the same way I'm
going to copy this do a docker RM and
paste the container ID here and I'm
going to remove so now if I do a docker
PS - eh I am NOT going to find those
containers similarly my docker images
are here I can also remove my docker
images by giving the docker
RMI and continued right and image ID
let's revise some important topics
around docker functionality that we
learned earlier the docker daemon is the
process which runs on the host machine
it manages different docker objects like
images containers networks volumes data
etc the docker client is the
command-line interface using which the
users will communicate with the docker
demon for managing various objects like
the images and containers the docker
images are the read-only templates which
are used to create the docker containers
the docker image is an executable file
built by packaging all the application
and the features the docker registries
are where the images are stored you can
store the images in your local
repository or in the docker hub which
this dock was very own cloud repository
containers are the run component of
docker and the actual running instances
of images okay folks that is the end of
our session and these are the topics
that we cover today first I told you the
difference between containerization and
virtualization then I spoke about docker
and then I told the difference between
docker containers and virtual machines I
then told you what is Dockers role and
DevOps and I spoke about docker engine I
spoke about docker images containers and
registry and finally I finished the
session by talking about Dockers working
architecture then I also showed you
hands-on where I told you how to build
your own docker images and it's been
continuous all of them ok folks these
are further questions that can test your
learning please take your time to
understand the questions and then answer
them you can put the answers in the
comment box and I will validate your
answer you can also comment your doubts
and queries to which I would respond add
the earliest I hope this video helped
you understand some important concepts
around docker if you are interested to
learn more about docker you can check
out our DevOps course at
www.archives.gov/calendar in our channel
to learn more happy learning
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>