<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Introduction to DevOps Tools | DevOps Training | DevOps Tutorial for Beginners | Edureka | Coder Coacher - Coaching Coders</title><meta content="Introduction to DevOps Tools | DevOps Training | DevOps Tutorial for Beginners | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Introduction to DevOps Tools | DevOps Training | DevOps Tutorial for Beginners | Edureka</b></h2><h5 class="post__date">2018-04-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lpWjKXa_4Hs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so at a time and companies want to get
ahead of their rivals by developing
quality software the Riggin also to
implement DevOps and hire engineers
skilled in DevOps is at the highest so
this session is dedicated to each and
every one of you who is interested to
learn DevOps and sort of career in this
field
my name is Vardhan and on behalf of ad
Rekha I will be conducting this devoxx
training for you let me get started by
first showing you the topics that I will
be covering in today's DevOps demo class
so the first topic that I will talk
about is the various challenges that
come with software development
especially with agile development and
after that I will talk about what
exactly DevOps is what kind of
challenges of agile does DevOps overcome
that is nothing but the need and then
I'll talk about its rise to prominence I
will of course talk about various DevOps
tools involved and there are five
different tools which I'm going to talk
about in detail and those tools are git
which is a source code management tool
selenium which is a testing tool Jenkins
which is an integration tool docker
which is a continuous deployment and a
containerization tool and ansible which
is also a continuous deployment but
which is a configuration management tool
and after I'm done talking about these
tools I will talk about the structured
DevOps training that you will receive at
Ed Eureka ok so if you guys have any
doubts during the session then I request
you to put that in the chat box and the
meanwhile let me get started so as
expected the first topic is what are the
different software development
challenges there are plenty of
challenges ok but no matter what the
challenges the root cause for that
challenge is one and that common reason
is there's a sillas that exists between
the development team and the operations
team because traditionally how software
was being developed who is that beaten
waterfall model or beat an agile model
will have two different teams ok so you
will have a development team which will
only do the development of the software
and then you will have an Operations
team which would basically take care of
deploying that software or provisioning
that software to your clients or your
customers now since there's a silos that
exists between these two teams there's
going to be a lot of challenges ok so I
have a question here
Rajesh is asking what is silos Rajesh
silos means there is separation between
those two teams ok or let's say that
these two teams work in isolation
the development team would just do their
part of developing the software and the
operations team would do their part of
you know deploying the software and they
are not working together for one
particular cause okay I mean their end
goal is the same but they're not working
together to achieve that task
that's what silos means and because
there's this silos between these two
teams whenever there's any problem that
occurs right minora client or customer
complains that you have your software
which you delivered as this problem then
that time what happens is there's a
conflict within your develop within your
company your development team would
start pointing fingers at your
operations team your operations team
will start pointing fingers are your
development team saying that it's your
problem and we are not the ones
responsible and since there is this
blame game that takes place there's a
lot of chaos there and well chaos is not
good right I mean it's not helping the
team spirit and the blame game is just
gonna make things worse and the next
time there's gonna be bad blood people
are not gonna talk to each other and
well the client is the one that's gonna
get affected at the end of the day right
because he's not getting what he wants
and the company's business would
eventually go down and drops is
something that overcomes all these
problems but before I tell you how to
ops overcomes these problems let me talk
a little more about the various
challenges that generally these people
face let's start with developers so the
number one blame game that takes place
is that the developers would say that
there's a bug not in my code but the
problem is what you have deployed in
your production server right so whatever
you've deployed that's where the problem
is and then the operations team would
say that well whatever code that you've
given me are not modified it so how can
the problem be at my end so if it's your
code
it's your bug and you fix the problem
this is the kind of communication that
happens between these two teams right if
you look at it then neither of them are
at fault so even the developer team is
not at fault maybe the software is
actually running well at his machine
maybe it's the dependencies and the
packages which are not up-to-date in the
production server because of which the
software is not working well in
production server right so the developer
team is technically not to be blamed and
neither is the ops team and well even
though nobody is to be blamed the
problem is eventually they're right and
you cannot take the blame away from
either of them
they both are equally responsible for
whatever problem that's caused and that
needs to be solved in one way or the
other and
hood dopes aims to solve the developer
team have more problems like the legacy
system which is which are being used I
mean they are developing their code on
probably the best software right they're
writing the best software and they are
doing it on the best machines but if the
off steam is using legacy systems which
is very common because a lot of teams
today are not moving out of the legacy
systems because of various factors which
they fear that's one thing and besides
the legacy systems being used they
company off for there being tool
turbulence and there's tool turbulence
which causes a lot of problems right
they cannot use a lot of other tools and
there are a limited set of tools which
the operations team would give the green
light for but unfortunately if they
cannot use it then they just cannot use
it right it's not gonna be used and they
are gonna have a tussle eventually the
developers would you know ask for
automation in place they would say that
how they are supposed to do things
that's how they want to go forward but
yeah that again may be a hands down from
maybe a thumbs down from the ops team
and if you look at what's happening on
the operation side they would say that
monitoring any application is tedious so
even though we need automation the
problem is security right we cannot have
bar monitoring being done by any other
application because of lot of security
issues a lot of confidential issues and
all those things and they would also get
back to the same point that you've got
to fix your bugs and then we won't have
any problem whatever it is you have to
deploy it to production so build your
application based on how it is in
production environment and this is
basically what happens throughout and
there is no solution to it right but one
clear solution which eventually came out
is the unification between these two
teams and that is exactly what DevOps
even represents and what DevOps even
stands for DevOps is the solution
what does devops do DevOps does
continuous development continuous
testing continuous integration
continuous deployment and of course
continuous monitoring of the software
throughout its development life cycle
with DevOps you don't have like multiple
people right you won't have two
different teams who are working in
isolation the development team and the
operations team is one team now they are
called
the DevOps team and the DevOps team
could probably consist of a group of
individuals doing the same thing or it
could contain a group of individuals who
are doing one single thing right so one
person maybe is take care of development
and the other one is take care of
operations but they will make sure that
they are aware of exactly how things are
going
happen the kind they'll make sure that
the environment is consistent and
probably they will have to take
ownership for any problem and more
responsibly simply means less errors and
that is good for business
that's what the DevOps strategy
emphasizes on right and what you see
here on the left this is the dopes
lifecycle there you will first plan
whatever software you want to build
whatever application that is and then
you would code based on whatever your
plan is you would collect all the system
requirements and all the software
requirements from your vendor and then
you will code based on that and you will
create boundaries and executables so
that the code can be easily deployed to
your production servers or seeding
server or any other remote server and
once your code is built and ready to be
deployed you would first test that
application right and then you would
perform whatever unit test or
integration test all sorts of tests to
make sure that there are no bugs if
there are any bugs they would be
immediately integrated back your
planning or coding phase and made sure
that those bugs are fixed but in case
there are no errors then that would be
then integrated to deployment and from
the deployment phase I mean once it's in
deployment phase basically your
customers or clients are getting access
to it and whatever they are doing
however the system is performing
everything is going to be operated on
and monitored and once it's monitored
whatever bugs we think that the software
is coming up with whatever shortcomings
or drawbacks the software has and
whatever problems the clients they face
right whatever expectations they needed
and what they don't have everything is
noted down and all those problems are
fixed in the next
vielen in the next iteration right so
that's why we have something called as a
feedback loop over your through the
integration whatever bugs are raised
over here those are sent to the planning
phase and the whole cycle continues
right so you have the second cycle where
you will plan code build test and the
features would be tested and then it
would be deployed then operated
monitored and then the next sprint or
the next cycle would continue okay so
it's a never-ending symbol so if you
look at it in a way it's an infinity
symbol right that's how a DevOps
actually stands
that's a DevOps logo and that's what is
represented here also it's a
never-ending cycle and the neverending
cycle basically is because of the
integration phase which holds the entire
DevOps structure in place so that is
about the DevOps strategy guys any
doubts here so Kumar is saying
the image on the right has the same guy
doing two different things
welcome Aria that's just representation
where we are saying that the same guy is
doing both the development and analyzing
and he'll also be the one that will
deploy to production or and do the
reporting or whatever right so it's
basically giving that one particular
person more responsibility and more
power over what he's doing okay so that
is about the DevOps strategy if it's all
cool then I'm gonna move forward all
right so in brief there are various life
cycle phases in DevOps and we will
consider that the first two phases which
is the planning and coding phase to be
the continuous development phase where
work will always be ongoing in
developing your application all right
and then you have the continuous testing
phase and the testing phase also
includes the build and the test the
build because this is where you'll build
your raw executables your binaries your
packages everything would be downloaded
and made sure it's ready when the code
is deployed okay basically packaging
your code along with all the
dependencies it needs and then when it's
built it would be imagery tested so
that's what continuous testing refers to
and once your testing is done next is
all about integration where this goes if
there are bugs it would go back to your
planning and coding phase if there are
no bugs it would go to your deployment
phase and in your deployment phase we
have it called as continuous deployment
where you will be doing two things which
is deployment and after deploying you
will do the operations and when you
operate you will have to monitor also
and monitoring is one of the most
important aspects because if you want to
improve your software then this is the
place where you go to write and your
customers and clients but also given
your feedback and when that feedback is
given that would be integrated with the
help of this phase back to your planning
phase so that would be planned and coded
and done here okay but the thing you
have to remember is the monitoring phase
which is really important because you
don't want your customers or clients to
come up with problems you want to
proactively monitor your application and
fix the bugs before they come to no-one
before they complain so that's why this
part is very important so that's about
the different phases but now let's see
what are the different tools which are
used by the top moves the ops engineers
in today's world okay so we have the
same set of phases but now let's start
with the tools which can be used in each
and every phase let's start with the
planning and coding phase so planning
and coding we have various or two
called version control tools and those
version control systems are examples of
those version control systems are git
and github we have SVN then we have JIRA
and we have many more but yeah these are
the most popular ones and get is the
notable winner here okay undoubtedly get
is the one that is the best in the
market and this is the most used because
of its various integrations with other
tools and other lifecycle phases okay
you'll be able to write your code over
here and then share that particular code
with multiple developers of yours your
team how many web developers are there
with every one of them you can share
that particular code you can now
collaborate with them and you can
maintain a revision basically of
whatever you've coded so you're whatever
you've worked on is never lost
so these are the tools right and for
building we have various tools like
maven Apache ant and Gradle now what we
mean by building is basically that these
tools will help you download all the
binaries and packages which are needed
by your code so if your code has to run
right then it needs certain libraries
and certain packages where your
functions would be present where your
inbuilt libraries will be present so
you're building tools would do that you
would make sure that your code has
everything that it needs and after the
building phase comes your testing phase
so on your testing phase we have a
selenium and tests ng so selenium is the
automation testing tool and tests Andy
is another tool which supports selenium
in various places right it complements
selenium because selenium has a few
shortcomings like test case management
and repulsion aeration and a few other
things and that's where testing he's
like something that's used along with
selenium for performing testing that's
how it works in the industry so that's
about your test ng and then for our
integration of course we have the
various tools like bamboo Hudson and
Jenkins but please note Jenkins is the
standout tool it's again the most used
DevOps tool and I would say that Jenkins
is that tool which holds the
underdeveloped
structure in place it integrates
basically these four important four
different phases ok
it has plugins to basically all of the
tools it has you know integration
available with different phases and
various advantages are there with
Jenkins I will talk more about Jenkins
when I get to Jenkins ok for now just
keep that in mind and moving on to the
deployment phase we have six different
which I'm going to talk about but the
first two tools are docker and Cuban
it's now these two are both deployment
tools but in deployment they are
containerization tool that's because
they deploy in the form of containers
they deploy the application in the form
of containers so they are called
containerization tool and then we have
these four set of tools which are
nothing but puppet chef ansible and salt
stack and these four tools are
configuration management tools and
configuration management again is
deployment in one way but the difference
is that whatever application that you
want to deploy you can deploy to remote
machines and you can quickly or
efficiently scale the number of servers
or the machines you want to deploy your
application to so I mean all the six
tools do deployment but yeah that's the
difference containerization and
configuration management and moving on
to the last part which is nothing but
continuous monitoring from monitoring we
have bar tools like LK stack Splunk
Nagios and many more the most popular is
a nag yours because it's very old but
off late the ones that are catching the
trend are LK stack and Splunk right so
LK stack is it's the open-source version
and Splunk is the paid version but these
two tools work very similar and I would
say these two are the best right now if
you want to do monitoring so monitoring
is done by basically analyzing your logs
analyzing your raw systems helped your
applications performance and many other
things so these are the tools which are
used and if you guys know these tools
then you're good to go right so you are
a dobson genome but then here comes the
question if I'm Alice right so on the
left is Alice and if I'm Alice then I
would have this problem as to should I
learn all these tools right and even if
you are thinking in the form of you know
if you're thinking as Alice if you're in
her shoes you would want you be
wondering there are like some 20 tools
or 30 tools out there and should I have
to learn every single tool to become
into ops engineer and the answer is no
you don't need to learn every tool
because a lot of these tools work in a
very similar fashion so all the
configuration management tools works
similarly okay and even if you know one
tool among these for configuration
management tools then you're good enough
because a company would not be
implementing all the tools they would be
proudly implementing one
containerization tool maybe one
configuration management tool maybe one
continuous development tool and maybe
your
continues testing tools and one out of
the continuous integration tool so it's
important that you know at least one
tool from each of the so it's important
that you know what is one tool from each
of these phases okay and just to sum
things up we have git selenium tests ng
Jenkins docker and ansible
so these six tools is what I will be
talking about in detail going forward
okay and let me start with git and
github okay
so git and github like I said is a
continuous development tool where you
can build your code where you can store
revisions of your code and share that
code with a group of members could be
your team okay so github is the version
on the cloud and get as your local
installation so basically what is git
git is a distributed version control
system for tracking changes in your
computer okay man we say tracking
changes and computer it's not just gonna
be restricted to code where it
developers or programmers would be
building it could also be any sort of
file like a word file or a presentation
or basically any file right whatever
files are there in your system if that
is a git repository then versions of
that file can be maintained what changes
you made the previous day and what I did
the day previous with the previous day
everything will be maintained and if you
want to suddenly switch to your state
what was the - raised back then you can
easily switch back to that day and
that's what basically a version control
system does for you and the best part is
this is shared by multiple users okay
multiple people can be coordinating
together building on that particular
code okay and they can share that code
base is shared with them so how was it
shared its shared because they will all
be deploying or they will all be
committing that code to one particular
server which is nothing but which is in
a distributed manner and this server in
case of git it's called a distributed
version control system this subdued
because people can access this server
from anywhere they can access it from
home they can access it from any part of
the world as long as they have the
Internet okay if it's a centralized
version control system then you can
access that particular server only from
your office LAN
right from your office network and that
is a problem because you will have the
dependency of coming to your office you
cannot work from home you cannot do
anything else if there is an emergency
and if you want to quickly fix your bugs
then you cannot do it you can do from
home with
version control systems and get as one
and that's why I get is a highly popular
and highly used tool so this is your
server or your repository where
everything would be present okay but
then you have local repositories also
supposing these three are the local
working machines at your end let's say
workstation so there are three
developers then these are the three
different workstations these three
developers have how can each of them
would be working separately on their own
code and once they work on their code
what they can do is they can commit
their changes to their local repository
and once the changes are recorded your
local repository from there those
changes can be pushed or pulled to your
central repository okay
your central but your distributed
repository so that's your server and we
have various commands like push and pull
which does the coordination over there
and then you have your commit or update
which does the coordination over here
okay so first of all from your whatever
changes you make from your system that
has be pushed your local repository and
from your local repository your push or
pull has to be made to your central
repository okay in our case it's going
to be a distributed version control
server so that's what is good and that's
how how multiple users can use at the
same time okay now let me just revise
whatever I spoke about by talking about
the benefits of using git first of all
there is team collaboration because a
lot of people can be contributing to
your codebase from different locations
maybe you're from the same location but
the point is they can contribute and you
will have one single database where a
lot of people will be sharing their code
and this developer team who's sharing
the code could have a number of people
like 30 or 40 or 50 people and they can
want to be present from anywhere in the
world right so that's the advantage
second thing is that there is revision
control so whatever changes you make a
version of that would be stored right a
copy of that particular change would be
stored so if I have the X today and
tomorrow if I have X plus one and
tomorrow if I think that X plus one is
not good enough and if I want to switch
back to X then I can F it then I can
efficiently do that right so I have
something called as the rollback where I
can switch back to my previous version
and I could just go back to X and I'm
all back to normal right so Mike my bugs
whatever would have come up in that X
plus one then that is gone right and I
don't have any other problems that's
revision control third is backup
everything is on the server nothing is
lost so even if your local machine
crashes then you can be rest assured
that you're a central server is not
gonna phrase the same thing and the
fourth thing is analysis there are
various benefits because if you can
analyze whatever you've coded and
whatever you've you know whatever
features you've developed then you can
analyze your you're basically can
analyze your tool you can analyze
whatever you've built and you can come
up with better versions of it okay so
those are the different benefits of
using git now moving forward let's look
at a use case and it's gonna be a use
case about this company called orbits so
what and who exactly are orbits orbits
is an online travel site which is
operating in over 180 countries ok and
let's see what was their condition or
situation before they moved to get since
they are an online travel site which is
very similar to an e-commerce company
and of course which is operating number
180 countries there's any bug even for
one second or of this downtime of their
servers for even one second then that
will result in millions of dollars okay
and that is definitely not welcome when
it's serious business on a deeper level
let's see what exactly their challenges
are the first thing is that they have
over 40 feature teams which are working
in parallel ok 40 different teams which
are doing coding at the same time okay
now that's the number one problem the
second is these developers use a
centralized version control system for
working on the same code base now all
these 40 feature teams need to be
present at the office to be able to
access this particular centralized VCS
ok that's the number one problem and of
course this particular base is that they
are using right the centralized VCS it
was not scalable that was a big problem
that they had and if they had 40 feature
teams in they could not accommodate a
lot more and they were restricted to
manpower and another problem is that the
developer could deploy a ratio is 50 is
to 1 these were the problems that they
had before gate came into the picture ok
now remember git is a distributed
version control system and with git you
will not have this problem ok they can
access the code from anywhere they want
and get is scalable and gate can net
multiple people working on the same code
base because it's not going to be the
local server it's going to be a remote
server the cloud the internet where you
are going to be deploying and because
it's going to be the internet the
pasties are very high now let's go into
details and talk about what exactly
happened after they moved to get since
gate is a distributed VCS it had them in
scaling the systems globally if they had
40 feature teams initially working in
pathol then they had to be present in
the same geographical location but with
git they could have probably 50 more
feature teams and those could be located
in geography Clee different places maybe
in us maybe one team in India maybe one
team in Australia and something like
that and the next advantage is that it
allows these developers to branch and
merge flexibly now that means that you
will have multiple teams and they will
be working on the same code base but if
they had to eventually merge the code
together then they had options to do
that they could do branching and merging
and it didn't require any extra effort
to get all the code together it gives
you this option to branch and merge code
which is there which is coming in from
different developers and get help them
achieve automation because it could be
effectively or easily integrated with
other tools like your testing tools your
integration tools also with your
deployment tools and most of the other
tools get hat plugins and the next
advantage is that get helped decrease
their build time by more than 20% and
that was attached to the implementation
of stash which is a git repo management
solution okay so this is your main
highlight letting them decrease at Build
time by more than 20% okay that's how
Orbitz moved to get and that's the
success that they faced with git so now
that I've spoken a lot of theory let me
go show you a demonstration of this
thing so for the Neman situation let me
move my virtual machine okay
so do give me a confirmation if you can
see my virtual machine here okay so this
is my open to virtual machine and this
is my terminal okay so let me know 1ls
first and you can see that I have or
gate rep over here okay so for the demo
purpose I've already built a gate
rapport or let's say technically I've
already initialized or gate rapport
where I have a file already present now
what I'm going to do is I'm gonna make
changes to this particular code and show
you how the changes would be immediately
reflected on my github okay so first let
me move to this git repo
unless okay so I have my hello world or
Sh
I'm gonna do a chat hello world or Sh so
I have two lines of code one basically
specifying that this is going to be a
batch file okay so that's for my Linux
UNIX for shell purpose okay but the one
code which I have is echo hello world so
I don't have any major code since it's a
busy tutorial and introduction to the
developer tools I've just had a simple
line which says echo hello world now let
me open up my github account also in the
meanwhile and show you that this same
line is present over there
okay so let me verify the same thing
from my github repository so for
accessing github let me go to my Firefox
and say go to github.com and yep am
currently logged into my account so let
me go to my repositories first okay so
actually HelloWorld is a repository
which I'm talking about and the hello
world file that you see here right so
this is the file that we have over here
so there's echo hello world and the same
thing we can see here echo hello world
now what I'm going to show you is I'm
going to make a change to this
particular file and this change will be
immediately reflected in my github
account okay it's gonna be cool right so
if you're new to get then of course this
is cool so first of all let me open this
particular file let me say sudo G edit
hello world dot Sh so here goes my
password so we have this and what I'm
gonna do now is I'm gonna say this is
line number one all right and I'm gonna
enter a line number two and say echo
hello from Eureka and let me add another
line sing
but first let's say line number three
and here let me say echo your instructor
oops
your instructor is varda okay
so yeah let me follow it up with this
smiley here okay guys okay so I'm gonna
save this file and let me close this
clear this and let me do a cat hello
world or Sh and now you can see that we
have these two extra lines in fact this
third line is modified so we have three
new lines over here okay now what I'm
gonna do is first let me show you the
github account and let me refresh it for
you and yeah so there are no changes
right now okay you can't see any change
but give it a minute
because what I'm gonna do here is gonna
impress you let me clear this and first
let me add the commands to first push it
to my local repository and the commands
for that is git add - eh okay now
remember this the flag is gonna have a
capital e now that you are done you have
added your changes to your local
repository okay now it's up come at your
changes so the command for that is git
commit - M so - am basically stands for
message good comment is good enough but
if you want to find out what is the
change then for name sake if you just
are giving a name to your particular
commit so in my case I'm gonna say this
is my DevOps tool or let's say DevOps
tools session okay
intro to DevOps tools session okay
perfect
okay so now let me hit enter and as it
says two files changed three insertions
and four deletions based on whatever was
there I've made those changes okay so
don't worry about all these things but
the good news is some changes been
tracked by my system and that's what I
bought now I've done my tears to my
local repository now I have to push it
to my git repository and for that we
have a command called git push origin
master alright so when you hit enter it
asks for your username and password
because git has to basically
authenticate which user account I am
pushing it to okay so it's been linked
to my github account so I'm gonna
basically enter my username and my
password
so first let's okay
Vardhan Anna's okay and then the
password is this
okay so now that my teens are committed
to my central repository or my git
repository let me refresh the same file
and you would find the new new lines
over here so like I said line 1 line 2
line 3 with all the modified ones right
so this is what I did and yeah and this
is the comment like I said
intro to devups tools session right so
this is how it works so that is pretty
much the basic demo that I want to show
you now let me move on to the next tool
ok but before that let me just clear the
screen out ok and let me exit this
so getting back to my slides I spoke
about orbits and now let me go to the
next set of tools which is nothing but
maven a selenium and test energy now
selenium is your main tool which does
your testing but we have maven and
destiny because Mammon is your build
tool and destiny is going to be the tool
that supports selenium and desk waste
management okay so in the industry
destiny is heavily used and I'm going to
show you how it works so the first thing
you have to notice that what happens
you're right whatever is done with the
help of these four tools it's called as
continuous testing because automation
testing is basically automated which
means it's going to be continuous right
so whatever your testing is if you
automate your testing it's called
automation testing and the very act of
automation testing if that is done on a
continuous manner then it's called
continuous testing and these are the
four tools which are involved Mayman a
selenium test injury and jenkins also
because jenkins is the one that is going
to do the integration so that will be so
you'll be able to integrate it with your
other tools so let me show you a
demonstration of these tools first so
maven for continuous testing now like I
said maven is a build tool okay it's
gonna be useful for building now what
building means is that it's gonna help
you manage your projects structure
efficiently and it will help you
download the dependencies and libraries
which you have mentioned in your code
now supposing I'm writing a code for you
know supposing I'm writing an angular
code then my angular code but need a lot
of dependencies right a lot of
boilerplate and all those things so if I
mentioned that and maven then I can
download that but yeah that's just an
example that gave you alright with
angular in general you can do anything
especially for selenium ok my demo which
I'm going to show you later on is a
selenium demo where I have mentioned
selenium and tests ng dependencies in my
pom dot XML file so your pom or XML file
is your raw is technically your maven
file and your pom or XML file if it has
the dependencies mentioned then it will
download those dependencies and then
your code will then run successfully
because those will be the dependencies
your code needs right so that's what
maven does it downloads your
dependencies for you and lets you
execute your code without any a problem
when it comes to selenium it is the main
tool which is used for testing it does
web
stink and it does web testing only okay
it's wrong useful testing your desktop
applications for webpages websites and
web applications only
that's what selenium webdriver does but
it has a few limitations like test case
management and report generation now if
you are working on a very big tool or if
you have an extensive project which you
are testing then you will have this
problem because your code is gonna be
very big it's gonna involve multiple
test cases and in that case if you want
to find out which test case pods which
one failed and if you want a reporter
for everything then you're gonna have a
slight problem okay it's gonna be
slightly tedious and to overcome these
problems of test case management and
report generation we use something
called as tests energy so test injuries
are - which complements selenium with
these problems and yeah tools like meme
and test engine Jenkins can be
integrated with selenium for performing
continuous testing okay but you have to
note that selenium is the most important
tool which does the actual automation
testing for you and moving on to test
Angie let me reiterate that again
it's used with webdriver for overcoming
the browser's limitations like tests
annotations which helps in managing your
test cases okay and at lets you create
or generate structured test reports you
will get to know if you have like 50
test cases it will tell you exactly
which desk is filled and if you know
exactly which desk is filled then it's
easy for you to locate your bugs and fix
your problems right so that's the
advantage and tests energy helps perform
unit testing that's something which you
probably know now moving on to the last
tool which is used for testing we have
both Jenkins and like I said it's the
tool which lets you connect to other
parts right so your automation is done
by Jenkins it's the tool which is which
does your continuous testing actually it
enables continuous testing okay what
Jenkins does is it lets you schedule
your bills and deploy is the code to
production or to ceiling server or
testing server based on those builds
supposing you're testing field then it
would basically send a notification to
your developers over develop the
application will talk about the bugs and
why the error occurred and if your test
key is passed and if it was successful
then it will just build and deploy that
particular code to the production server
or the seeding server or bit of a server
you wanted to and the best part about
Jenkins it can be integrated with most
of the testing tools so I will talk
about Jenkins in a little more detail
but
before that let me just go and show you
a demonstration of how these tools work
together so like I said we will have one
test energy XML file but this tests ng
XML file will be called by your palm dot
XML file okay so we have two XML files
here the Palm D'Or XML file is used by
maven and over here you would save which
tests in the XML file to execute and you
will say which other dependencies which
are needed for executing the code in
that particular test and the XML file so
the dependencies would be download over
here and the code which is present here
that would be executed and coming to the
destined seed or XML file what it does
is it would say which is your selenium
code and it would be able to first
execute your test cases and as and when
your test cases are executed your tests
andrey helps you analyze whether your
test case is passed or test cases failed
that's the most important thing right
you have to verify if your test case
pass or if your tests fail and destiny
does that for you it tells you if your
selenium test cases pass or fail and it
gives you a very brilliant report simple
easy report which you can understand and
your job is very simple
that's what is the benefit with this XML
file and like you know selenium is the
most important tool which basically does
your testing for you and whatever the
result is that is automated or the
future steps the build steps are taken
care by Jenkins and that's why it's
continuous testing so let me again show
you the demonstration but the
demonstration has to be shown on Eclipse
this time ok I'm not gonna use my VM I
load on my Windows machine and I'm gonna
use my Eclipse so I have again opened up
my sng XML file my maven dot the Palm
D'Or XML file and then my selenium code
okay this is my selenium test case so I
have everything present let me just
explain what's gonna happen on a high
level so first of all I have the various
packages which I've imported these are
among the libraries which I've imported
and everything is present in this
particular package of mine when we say
package it's basically the repository
where this class is present and where
these libraries would be present this is
the place where it's special my local
repository ok in my workspace now get
into your domain code so my class name
is Ed you rake our demo and over here I
have a trig test which is basically an
annotation and this is what lets me test
if my test case pass or test case fails
okay so this is the role of tests in G
over here
now the code over here this
is all about selenium okay given the
assertion which happens your it is taken
care of by selenium now essentially what
it does is if this assertion passed or
failed that would be analyzed by my ad
rate test annotation and that would be
reported to me later on in my report and
with that I achieved both report
narration in an effective way and
automation for testing now let me
explain my code and tell you what
exactly I am doing so the force is just
a println statement which says hi this
is Vardhan and this is a very simple
exponential line when it comes to
testing what I'm doing is um first of
all setting my system property now why
should I set my system property I have
to set it because I will have to work
with one of my drivers if I want to do
testing on one of my webpages or some
given URL I have to open up that URL
using one of my browsers so in this case
I am using my chrome driver okay I'll be
doing the test on Chrome browser and I'm
going to use the chrome driver which is
going to basically control my Chrome
browser okay and the command to set that
property is the driver dot chrome door
driver which would say it's sound
perform testing on the Chrome browser
and I'm just specifying the path where
this particular chrome drive off -
present so it's present in C users
Vardhan downloads and this is the name
of the file okay chromedriver dot exe
and once I've set my properties the next
thing after do is I have to create an
object of this particular webdriver
class yeah so I'm creating an object
instance of this particular driver class
and I'm doing it with this okay this is
the command webdriver driver is equal to
new chrome driver so I've created my
grabber instance for my chrome driver
and that's this object and now again
straight away perform my task this is
again a very simple testing where I am
going to ask my driver to navigate to
this particular URL new tools dot demo
or com okay so this is the stands for
demo automation and this is a testing
page which lets us test ok and what I'm
doing here is I'm getting this page
title so every page will have a page
title right so on top of the tab you
will see there is a name that comes up
so that is what it is so I'm creating a
variable called title a string variable
called title and Here I am storing the
page title so the driver would get title
right so the gate idol is
function which is basically imported
with one of these packages and this is
gonna do this for me he's gonna obtain
the page title and store it in this
particular variable and what I'm gonna
do is I'm gonna assert if this is true
if the page title I'm getting from my
chrome driver is it the same as this
welcome current mercury tools because if
I open up my chrome so let me open up
that URL new tools or demo marcom so
this is the page title and the page
title is welcome coolant mercury tours
with the space ok and I have to make
sure that the page title is equal so I
have initially fed this is my expected
title welcome : mercury tools and I'm
saying whatever is obtained over here
this has to match whatever is expected
okay expected and actual so that's it
that's a simple assertion and since I
have add the rate test this test as you
would bring out a report saying that
this particular test case
ok so whichever method is present or
whichever method has this add rate test
annotation that particular method has
passed or not so if the actual and the
the real values are the same then this
test case would pass but however if the
title which my driver is getting and if
this is different then it will fail and
that would make my test fail ok so
that's how things are going to work so
this is my selenium code okay but we
have to use maven and Tessa you write
because that's how the industry works
and the reason we are using destiny is
because in this case it's going to be
very simple you just have one simple
code that we had you just have one test
case and you can just use one adder it s
annotation but in case you have like
hundreds or thousands of test cases and
you'll be dealing with an actual website
or a web page you have two tests all the
functionality so in that case you'll
have to use a test lead or XML file
where you can mention which all classes
you want to execute ok that's a very
brilliant option that we have and as you
can see here I've done this right so we
have a surname test name and class name
but first concentrate on this class
frame over here so what I have here is
have said execute this add record demo
ok so this is a class name I'm saying
execute this particular class which is
present in this particular package okay
so that's the format your class name
would have to be specified in this form
and where you have the package name
what your class name and if your package
name again you know if you have
different directories inside your
package then it will be separated with a
dot
so maven dot selenium test in C dot
Jenkins dot ed u rake our demo ok
so that's how things work ok and I can
have multiple classes executed like this
so this is one class ok which I have
closed within these tags so if I open
one more tag over here with same class
then it means I am executing a second
class and like this I can execute any
number of tests so my one test can
contain one or more number of classes
and similarly this one particular test
can be contained inside this particular
suite and prettiest obvious but this
suite can have more than one test so
this particular suite of mine will have
the one or more number of tests this
particular test would have one or more
number of classes ok and in this class
is I can have tags inside the class tag
where I can have one or more number of
classes so that's how simple it is with
your XML files ok this is your test and
you don't XML file now if you want to
execute this just need your XML file
with the help of maven you have to write
a Palm D'Or XML file ok so this is the
Palm D'Or XML file and the template is
like this so this is how a Pommer XML
file would look like in general you have
the few things here which you have to
remember and those things are your group
ID and artifactory so these are the
things that will change ok the remaining
things would pretty much be the same the
only thing that will change are the ones
which I'm going to explain now so the
first thing is your group ID and your
artefact ID so your artefact ID is
basically the package where it's present
of or your workspace repository ok and
of course the name of for the class
which I'm gonna execute is ed record
demo alright and once I'm done
specifying where the classes and where
it's present I have to specify the tests
and e dot XML file which I want to
execute so my destiny dot XML file is
going to be present over here ok inside
my package so I've just specified the
name over here and I'm specified at
inside these tags of suit XML file
now this suit XML file I'll I'll explain
it later okay so why it's present inside
the properties inside the properties tag
I'll explain that later now coming down
I'll specified both there my code is
present and what I want to execute so
now it's time to specify the
dependencies right so I have basically
two different dependencies one is the
test any dependencies and the other is a
selenium dependencies and
my destiny dependencies can be called
with the help of this group idea for
this and artifactory of this okay you
will find this oil in the internet and
similarly for downloading my selenium
jars these are my dependencies so again
these come under a dependency tag like
you're testing your dependency and these
two dependency would again be inside
these dependencies tag okay so we have a
dependencies which opens your and which
ends over here
and once you have specified your
dependencies you can simply do the
building over here okay in your build
and in your plugins you can save what
you want to basically run so there are
two things which you have to remember
there is maven surefire plug-in which
you have to specify and your demand
compile a plugin when these two are done
then y'all ready these are your main
plug ins which need for others to work
and if you come down you have your
configuration so your configuration is
what controls which XML file you want to
execute and the XML file which you want
to execute you were after specified
within your specifying that the XML file
which is present inside my suit this
suit XML file is what is there here ok
so inside these tags we are active on
does find this okay so my plugins build
and project everything all the tags are
ending over here so that's how simple it
is now let me execute this name and file
now the fun part is the main file can be
executed three or terminal ok so let me
open up my command prompt for that so
right now I am here so I want to say CD
workspace okay so Mayman dot selenium
dot destiny dot Jenkins so this is where
I want to go edit enter
so if I do a dir then I will get know
what are the contents right so I have my
Palm D'Or XML file present here and I
have my destiny dot XML file present
over here so this is what after execute
so afterwards get my palm read XML file
so the command for that is actually the
command is just maven but before I
execute the Pamir XML file after make
sure that I clean whatever Allah of my
previous build was so for that we have a
command called maven clean ok
ambient clean basically removes what was
there in my cache so I mean Fein will do
that for me and it would let me build my
project next ok so let's just wait for
this command to execute successfully
okay building into a car demo okay so
this is done so now what I'm gonna do is
I'm gonna do a maven install okay
ambient space install so this is the
command which builds your project okay
it's going to run all your dependencies
so if I hit enter all my dependencies
would download one after the other
if I have it already when I'm good if I
don't have it then the dependencies I
mentioned over there they would all be
downloaded okay so it would use these
plug in the maven resources plug-in the
short fire plugin and the compiler
plugin okay so let it get completed
okay perfect it's running my tests hi
this is warden from Eureka and it's
opening up my chrome now okay my test is
gonna run now so this is my chrome
opening up wait up for it to open up the
new towards or demo art page and then
the page title would be verified this is
the page I was talking about title
should have been verified by now okay
so let me just minimize this window and
you can see that my build is success and
it's finished
over here okay perfect so this is how a
Mayman test works and this is how we do
it using your Windows command prompt now
that my task with respect to these three
tools of maven selenium testing is done
okay but I'm not showing you with
Jenkins so the next one I'm going to
talk about is Jenkins so when I talk
about that I will execute the same file
using my Jenkins ok and show you how the
execution of the continuous integration
happens over there so this is the end of
my demo with respect to continuous
testing so let me just close this
particular eclipse of mine okay and let
me open up my PVD this is what I
finished and yeah I will continue that
demonstration of Jenkins when I talk
about Jenkins in detail so Jenkins for
continuous integration okay so what
exactly is Jenkins Jenkins is a
continuous integration tool which is
used for automating various stages in
your DevOps lifecycle and automation is
basically achieved by using plugins to
various tools involved in the process
and this is why Jenkins is the best
right so you have everything that you
want you can automate your various
stages in your DevOps of cycle if you
have a building phase you can automate
this part if you have a testing phase
you can automate this phase if you have
a deployment phase that can also be
automated same thing can be done with
the deployment the monitoring and your
development and how is this automation
actually done it's done because it has
our plugins basically every single tool
out there if it's a DevOps tool then you
can be pretty much sure that Jenkins has
a plug-in to that particular box tool
and since it has so many options that's
why Jenkins is the most used
CI tool in the market this is the
leading tool hands down no doubt about
that
if there's one Dobbs guy who tells me
that he's not using Jenkins for CI then
well something's wrong with that person
okay no offense to other tools but
Jenkins is just that good there has to
be a really strong reason for anyone to
not use Jenkins instead of some other CI
- okay so
Keane's is that popular and that's about
Jenkins right so it's a continuous
integration tool but how does Jenkins
work I mean if you're a newbie and I'm
pretty sure you have doubts right so
like Rajesh is already asking I mean
what actually happens here so let's
answer that question here by seeing how
Jenkins works so you as a developer
would first come and your changes to
your source code okay which could be on
gate or Esswein or some other VCS tool
once you commit your changes to your
source code okay so this is your source
code various developers once you commit
your changes over here you will have
your continuous integration server or
your Jenkins server which will trigger a
build based on that particular commit
okay since you did a commit it would
trigger a build and that bid and that
build would involve pulling the code and
once the code is built to that
particular server the next thing it does
is it deploys it to the testing server
okay so the build application is then
deployed on the testing server for
testing and at this point of time if
there are any errors or if there are any
bugs or any shortcomings then you have a
feedback loop from which all the
feedback is taken and it's sent to the
developers okay so the test case fails
your Jernigan server would notify the
developers by sending an email
notification okay so that is why BR or
saying CI is good so that is a feedback
loop the email notification to the
developers is the feedback and they will
be able to rework on the code and the
build phase so that's about the testing
phase but in case of your test is a
success and there are no errors you can
still configure there to be a
notification to be not to be gone to the
developers but in general what happens
is the same application is then deployed
to production server or any other server
of your choice
okay it is deployed to the production
server and once your production server
is also deployed then whoever the
concerned teams are they are constantly
notified about the build and test
results so the testing and the building
would again be happening in a regular
fashion so that's why it's continuous
testing right so you might be testing
probably every night and you will be
expecting the results as in when you
come to the office then XA morning so
that is what how wha
Jenkins box okay pulling and deploying
and it makes place for your feedback
loop so that's the working of Jenkins
now let's talk about a case study of Jen
and let me show you how it actually
impacted this famous company called no
here so before they were using Jenkins
and before they were using continuous
integration this is what they have this
is how they were working okay so they
had something called as a nicely build
which was their way of building and
integration and what happened here is
every night they would have an automated
system and that system would pull the
code which is added to the shared
repository so the developers would be
there and all the developers would come
in their code to a shared repository
okay and they would be doing it
throughout the day and thus they would
build a particular code and since this
particular code was built throughout the
day and various applications would have
no functionality so various applications
would have been defined and a lot of
other build packages should have been
downloaded all those things would have
happened so you have code and various
dependencies which should have been
downloaded but of course it didn't
happen okay and it's waiting till the
night and during the night this
particular code which is a very huge
code okay since the code that was built
at night was quite large locating and
fixing bugs was a real pain I mean yeah
like I said you have a real big code and
you have various dependencies for that
particular code so everything would be
done at the night all the dependencies
for that particular code is downloaded
and the entire code which is built is
tested over here okay and once you test
it that's when you find out your bugs
right you have to do your debugging and
the problem is since you have such a big
code finding your bugs and checking
where your bugs basically are it was a
real pain because there's so much code
and there are a lot of developers who
are contributing and it's tough to
differentiate and tell which developer
or tester should work on what on which
particular code right so that's the pain
that's what they were facing at nightly
builds ok this is what was happening at
know here but when Jenkins came in right
so the Jenkins see I saw up solved the
majority of this problem because they
don't have to wait to the very end of
the day to do your build right to
trigger your build
so what Jenkins does is as in when a
developer commits his code to the
repository immediately a build is
triggered and as and when the build is
triggered that particular developer
would be notified of the error or the
bug that is there in his code because
some test case would have failed and if
that test case failed and he'd have
known where exactly the and when Nokia
started using Jenkins the situation was
a little different so as you can see
Nokia adopted the 20
integration server as you know that
comes with Jenkins and when Jenkins was
in use for every commit a developer used
to make immediately build used to get
triggered because they used to wait till
the very end of the day all the jobs
would get you know triggered at the same
time and then if there are any bugs it
was tough to locate but since in this
case when Jenkins was in use since the
jobs were getting you are triggered
immediately what used to happen is if
there were any bugs those could be
reported immediately right it was easier
and each and every developer whoever
used to make the commits that person
would get a custom email notification
saying that your commit has been you
know I mean whatever you had committed
from there there has been a bug detected
and this kind of a test case pause or
this test case failed so it was very
specific and it was very to the point
and that's why using the Jenkins CI
server made a big difference at Nokia
right so that is about the use case now
let me show you a demonstration of the
same now for the demonstration let me
open up my chrome first and let me open
up my Jenkins dashboard okay so this is
my Jenkins dashboard so Jenkins is
usually active on this port number okay
localhost:8080 but you can change the
port number you can change it as per
your wish but by default this is the
custom portal where Jenkins is at one
and as you can see this is my dashboard
okay and so for our demo purpose I have
already created one project this one you
can see your right mammal selenium tests
engine Jenkins so this is the one which
I created and here of configured things
already okay so let me just show you how
the project works let me go to configure
here this is where you can do all your
settings with respect to Jenkins now one
thing which I might have skipped at this
point of time is that I have created
this project as a maven project so
whenever you want to create a new
project you have to click on this option
here okay new item from your Jenkins
dashboard you click on new item and then
you can enter your project name and you
can choose free sub project or maven
project or any of these options so in my
case I have chosen maven project because
my project involves maven and it
involves execution of a pom file right
so that is why I chose mimin project and
once you do that you will get this tab
and in this tab ya you enter the name
here and if you can just go to the
source code management tab you can enter
other
if you want to pull it from get or SVN
but anyways what I want to show you
forces let's go down to the build tab
here this is the place where you have to
specify where your palm XML files
present okay so I have specified this
path users Vartan workspace and then the
path the project directory where it's
present right so once I have fed this
path we have to specify what are the two
commands that you want to run now since
it's a maven project I don't need to
specify ambient clean and ambient
installed separately okay so we have
golden options and since it's a maven
project its pre understood that these
arguments would be added with ambient so
we can just simply specify clean with
the space you can specify install so
this would execute two commands first it
would execute the ambient clean and then
it would execute the ambient install so
earlier from my command prompt I did
those two commands separately in this
case that's the benefit I have a journey
ends ok I can just specify the two
arguments I want to run and the pom.xml
file would then be executed now the
other thing which I would also want to
show you is that if you come down to the
post steps over here we have email
notification options so if you check on
this you can choose which email ID you
want to be sent to and the email ID
could be sent in case of there's a
failure in the execution so if your
build fails or if you know for every
unstable build you can send the email so
that's what I've done here you can do
that or you can choose to get an email
even if your build passes so what do you
do what usually happens is when you go
at the end of the day you might want the
testing to start so you will have
Jenkins to start the testing and in the
morning when you come in or whether the
test case passed or not you might want
the reports so usually people do this so
they would ask for the email reports and
Jenkins would send to them whether it
pass or failed or whatever and then you
will just get the report all right so
that's how it happens here and so now
that I've shown with this let me just
quickly go on top and show you the
execution of this thing so let me click
on build now so when I click on build
now my pom maximal file would be
actually executed and this time I don't
have to do it through I don't have to do
it manually through my command prompt
Jenny Keene is doing it for me so my
project is being build here
build number 297 okay so if you go to
console output you will get the actual
console which you usually get on Eclipse
IDE so this is what I used to get
earlier right so yeah first it's
executing the first command mvn clean
and then a Mian install and yeah just
wait up for the entire thing to complete
so if you notice it is the same log
which came earlier right so whatever
came in the command prompt we have it
here now but this is one thing which you
people might should notice actually
there's one difference with respect to
executing it on the command prompt does
anyone here know what that is Rajeev
Raji you actually are anybody so Rajiv
says that the chrome window didn't open
up does the actual testing actually
happen so Rajiv the thing is with
Jenkins you don't get the chrome window
right now that's what I'm gonna do
people to notice because earlier you
will have your chrome window popping up
and the whole thing would happen right
if the testing would be visible to you
but in case of Jenkins that does not
happen because Jenkins is considered to
be a server right it's a CI server and
usually when you're having such builds
in a remote server probably a cloud so
then you don't need a GUI in fact you
won't have a GUI so why do you want some
chrome to open up and show the whole
process right so that's why with Java
the tests with Jenkins and general don't
have the Chrome window coming up okay so
anyways as long as you see this result
right finished success that's the most
important thing your build is a success
and the same thing which happened
earlier has happened now now getting
back to my project here I showed you how
to execute it manually but when we use
Jenkins we use it because we can
schedule the bills right so that's the
power of Jenkins so that is something
which I am not sure yet so if you go
back to configure there's an option of
build precursors now this is what it was
the best part about Jenkins and this is
what loci are used and that's why
Jenkins is so popular you can choose
when you want your test cases or your
jobs to be built you have an option to
build periodically so check on this box
and you get this option ok so here you
have to enter then you want to do it in
cron format so for those of you who
don't know what a cron format is I would
request you to please go GLE what Kron 4
matters and just learn that ok because
it will take me too much time if I start
explaining that and let me just simply
tell you that Kron 4 matters is simple
you will have five different parameters
okay the millet of
our the our of the day date of the month
month and then day of the week so there
are five different options that you have
and if I say something like this right
with five asterisks it means that I can
I choose to execute it at all these
times a spec basically means all or
every so if I if there is a spec in the
first place then it means that execute
or build the job for at every minute of
the are okay a bead zeroth minute or be
the 59th minute the job will get built
okay and if the second option is a
strict then it will execute at every
hour of the day zero third and till the
twentieth 23rd R and same thing if
there's an asterisk over here day of the
month then the explanation is
straightforward right every day of the
month and in this case it would be every
month of the earth and in this case it
would be every day of the week if you
want to customize this and if you don't
want the bills to basically execute
during the weekends then you can choose
not to have a secure and if you want to
customize these things and if you don't
want your jobs to be basically a built
or get triggered during the weekends
then you can do that too let's say you
want the days on which you want the
bills to be happen only on Mondays to
Fridays then you can choose the days of
your week Monday is basically my first
day right so zero is Sunday one is
Monday so I can say this one two three
four and five I can do this
with this on my five different days this
build will get executed right my job
will get built and this is how kron4
matters if I don't have a structure and
if I have one in this place then it
would then the bill would be triggered
basically only on the first minute so
please just look up how the pron format
works and then you'll be able to play
around and work around with this now
what I'd rather show you is if I replace
this with asterik and if I save this
then see what happens it's 1:30 now
basically for every minute from now the
build would start getting you're
triggered that's what's gonna happen
okay
so just beat up you can verify the same
thing from here also so here it says
that with a strict the last time this
would have ran at is that this time
April 19th
at 1:30 okay and the next time this is
gonna run is again at the same time
because it's gonna basically run every
single minute so right now it's 1:30
so just wait up then it's 1:00 1:30 1
you will have another job that gets
triggered
yeah so did you see this earlier coming
up on its own that's because of the
trigger which I had set over there right
that's because of the crown format I had
wanted the bill to be higher built to
execute basically every minute and
similarly for unsewn only when it's 132
the same thing would happen the build
would start getting triggered again and
this thing is never ending right so
that's what happens with your triggers
and if in case your tests fail you will
get an email notification and you will
get to know that okay whether this
happened or whether that happened so let
me just close this for now and then save
it so that I don't want it to be running
completely and also note that my
previous execution it's a success so my
ball is blue in color so it's all good
had it been red in color that means my
build would have failed okay so that's
the meaning over here that's it with my
demo on Jenkins alright so let me go
back to my slides and continue with my
PPT so the next thing that we have for
today is docker now what is dhoka dhoka
is is considered a container ization
tool okay but as a continuation tool
what does it do it basically does
deployment right so it's very similar to
configuration management tools like
ansible puppet or chef and our
unanswerable saltstack docker does
something similar but does it in a
different manner okay so the end product
is yeah deployment but the whole
deployment your books by
containerization so let's just let me
knees read the definition once again
docker is a containerization platform
which packages your application and all
its dependencies together in the form of
containers now what that means is for
your project to run you might have a
particular code which basically runs
your project and along with that your
code will have various dependencies
right if it's angular or a node then you
will have various boiler plates which
have to be there and various libraries
which have to be downloaded now all
these libraries all these boiler plates
along with your code right they will be
packaged together and they will be
packaged in the form of containers so
basically your containers will only
contain these things and nothing else
okay even the memory allocated to your
container and even the space would that
would be allocated your container would
be only for these purposes and nothing
else but in case of virtual machines it
works a little different right VMs
you allocate a little more you allocate
space and we allocate RAM to the VM
itself and then the VM after that
allocates memory and the RAM to your
application but that's the advantage
with docker nothing extra is consumed
because you're not giving anything extra
the docker container you're only giving
the container how much your application
needs so that's what you see in the
architect's diagram here ok now this is
our docker usually runs you have a host
operating system and on top of that you
have your docker engine running ok and
then your docker engine would power
multiple containers so take for example
container 1 you have the application 1
running and this is basically running
with the help of the binaries the code
and all these associated items ok and
whatever contents are there in this
container 1 they are limited and
specific only to container 1 another
container running in the same docker
engine cannot access this understand
until you want it to access ok they're
all specific now they are all just
separate but there are options where we
can have one container interact with
another container so in that case we
would open port numbers and we would say
that yeah do whatever you want right so
that's what docker is and speaking of
the benefits that docker has or the
number one benefit is that the RAM that
is consumed by docker is very less for
the very reason I told you earlier with
VMs there is some extra RAM that you
allocate to your VM and there is also
some extra space which your VM will take
because what your application needs that
much RAM and memory would be allocated
by your VM but your VM will also have
something extra right so that is of
course underutilized now that's
allocated to your VM but it's unutilized
so since it's unutilized that memory
goes for a waste but in case of docker
you not have that problem that Ram or
that space will not be occupied at all
it would not even be your allocated and
with docker it's also easy to run the
applications because once you need to do
this once you have to set up your dock
or environment and once your application
is running all you have to do later is
run the container to get your
application active and if you want to
stop your application then just close
the container okay stop the container
and kill the container and all these are
one single line commands you don't have
much to do but in case of VMs you might
want to start or boot the different VMs
or the different servers and then get
the application to start running inside
them
so maybe to run the application you will
again need a couple of commands now the
benefit is you don't have
run those all those commands every time
when it comes to docker with VMs yes you
have to run all the commands in those
servers or VMs in case of docker
just start the container and then
whatever commands which are needed to
run the application those would be
started or specified on its own that's
the thing and most of all these
containers are very lightweight for
again reasons obvious and since they are
lightweight they can be easily shared
you can either upload it to your doctor
hub and share it with your collaborators
your fellow developers or you can do one
more thing you can just export your
container into your machine you can
export it to a tar file and then share
that tar file to another person and then
that person would import that a file
into his docker engine right and then he
has the docker image and then by just
running one command he spends a
container of that particular docker
image now that is what docker is and
that's why docker is really beneficial
okay along with Jenkins yeah docker is
one of my favorite - and I love docker
because of the benefits that it has an
of the power that docker has and now
moving on to talking about how do we
create these docker containers we
basically use a docker file okay you can
either pull a docker image which is
already present on a docker hub and then
you can run a continuing out of that
image okay but in that way you're not
doing or you're not creating your own
docker image or just using a custom you
are using your default image which is
already there okay if you want to start
your an application then you have to
build your own docker image first okay
your own docker image for your
application and that docker image is
built with the help of a docker file so
that's what it says right your docker
file will have all the commands which
are needed to build your docker image
and it will also contain all the project
codes and all those things it will have
the place where your docker where your
project codes are present that would be
present in your docker file and you can
create a docker image out of that
particular Otaka file and then you can
use that one docker image to create any
number of docker containers you can
create 10100 any number as long as your
system has that much of bandwidth and it
has that many resources you can start
any number you want so that's how docker
works okay and this is a diagrammatic
representation of the same you have a
docker file and then this dhaka file is
used to create a docker image and then
this docker image can be made into a
docker container just execute this
docker image and then you have a running
instance of that particular docker image
so the running instance is
docker container the inert version is
the docker image and this docker image
you can be shared with other people also
you cannot share the docker container
okay so Akshay has a question can we
share the docker container no you can
share the container but yeah it's wrong
the container Percy but you're sharing
you are sharing the docker image which
is like a template so think of it as a
template Akshay once you share the
template with your other collaborators
it can be either by uploading to docker
revolt by export and import you can do
one of these things once you give to the
other person then on different servers
on production server or on seeding
server this person can run this docker
image and get the running instance of
this image the running instance is the
docker container so they can do the
execution on their end okay so that's
how it works he doubts cleared okay
perfect
okay so that is it with my theoretical
part let me quickly go to my VM and show
you a demonstration of docker okay so
it's the same me image I showed my
earlier demo on anomie first bring up my
terminal
so I hope my concealer is visible now my
terminal the first command that I want
to run this docker PS and what this
command does is it lists down all the
docker containers which are running let
me just clear the screen and run it
again so right now there are no docker
containers running and nothing's active
so that's why there are no entries now
however if I include the a flag over
here docker PS - II then I would get
listed down all the containers which
were ever active in my daugher engine
even the stop containers they would be
visible so as you can see here I have a
number of containers your you have the
container ID image from which it was a
spun the command was used to create them
and then we have the created day the
status port number all these serials
right so there are containers which I
started a few days ago and then we have
some which started a few months ago and
yeah many more like that so that's how
this command works if you want to see
the docker images which are present in
your core engine then just simply run
the command docker images and then yeah
all the images which you can consider to
be templates they are listed down so
using any of these doctor images I can
create their respective containers so we
have a demo app one we have a mean stack
app which are you of course have showed
demo on previous videos and those videos
are there on YouTube so you can watch
those videos and then there are yeah
many more images your out of which we
can create various containers but I
think for today's session I will show
you a demo on this one particular demo
app of mine where am i right now okay
I'm on slash home slash at Eureka so let
me just list down all my folders there
is this folder demo one now the demo app
which I'm talking about it's all about
it's an angular application basically on
a particular port number it's going to
launch an angular application of mine
let me bring up that application first
and before I do that let me do a CD go
to this demo one folder and here or
let's do LS
and it'll actually go to this folder CD
demo so let me know CD demo and do I
have what I want here yes top movies so
this top movies is the annual
application I'm talking about it has
periods about probably the best 250
Hollywood movies ever okay so it's our
ratings one of our folks are Eddie Rekha
created this project and it's as far as
we are concerned this is what we think
are the best English movies ever so let
me just show you that
all my project codes are present here I
have an SRC folder I have a package.json
file which basically starts my container
okay it has cereals about everything
whatever is needed for my annual
application to run and then there are
known modules so this is the folder
where all my libraries and boilerplates
are present and then I have all these
things with the respective docker I have
my dock of five here okay so this docker
file lets me create a docker image for
this particular application or project
of mine and once this docker image is
created I can spin a container I've
already done it before but let me just
go about the steps and show you how it
actually works so let me do a gee edit
and show you the docker file I'll show
you what are the lines that are present
inside mundaka file a typical docker
file would look like this always the
first word would be in caps and this
basically means when we say from it
means I'm asking my daugher engine to
download know it as a base image okay
from is used when you want to specify
the docker base image that you want to
build your application on okay and then
you have other commands like run working
directory copy and all these things so
when you specify run it basically means
that so this directory would be created
inside my docker container and then what
I'm saying is change the working
directory to this particular directory
so make this my working directory of my
docker container and then I'm saying
copy the package dot JSON file which is
there copy it to inside the container so
if you see over here there's a package
or Jason right I'm saying copy this
inside my docker container so that is
about this particular line okay
and after that I'm simply running these
two commands which are used for my NPM
so NPM is my known package manager and
I'm saying
first clear all the cache and then I am
doing an NPM install so when I do an NPM
install my package dot Jason would be
used to download all the boiler plates
and whatever dependencies are needed for
my application to run and it would just
set my environment up when I do copy
with the full-stop and then this
directory it means that copy everything
all the files which are present in this
particular directory into my container
directory over here okay which I've set
here so I'm copying everything into this
particular container of mine and after
that I'm saying expose my particular
port number photo double zero meaning my
angular application would be
hosted on port number photo double zero
of my daugher and by specifying this
command NPM star I'm basically running
my angular application so that is
technically the final step to start your
angular application okay I mean if it's
a node application whatever if it's a
mean sack application or use NPM start
so that's what I'm specifying here
through my docker file command NPM start
now if I execute this docker file then
all these commands would be executed in
turn and when all these commands are
executed I get what I want right my
application is also active how is my
application active because a docker
container is running so let me do the
first thing let me execute this docker
file and create a docker image for this
so there we go let me just clear the
screen
since my docker file is present in this
particular path let me run the command
to create a docker image using this
docker file so the command is docker
build - T followed by the image name so
if you remember my image name is demo
app 1 so I'm going to use the same name
and then I'm going to say that
particular docker file to build this
docker image demo app 1 is present in
this particular path full stop or dot
here represents the same path same
directory look for the docker file in
the same path but if my talk a file is
not present over here or if it's present
somewhere else
then I have to specify the path of my
daugher failure if it's in slash home
slash a dirac I would say instead of
this dot here I would specify slash home
slash at Eureka if it's in root I would
just specify the root path here so let
me enter this would start building my
docker image first so step 1 step 2 step
3 4 5 6 7 8 9
I have already built this before so
that's why it was pretty quick otherwise
if you're doing it for the first time
trust me it will take a long long time
ok but yeah I have my dock ramiz ready
so lucky me right let me clear the
screen and run the command docker images
so you can see this right demo app 1 so
this is the same image which we built
now let me run this image now ok when I
run the image I will get a container so
the command will run this image and get
a container is docker run - - RM and ok
- - RM basically tells that run this
container in
mode that that's what it means okay so
remember to use this flag after that use
the flag - P and do the port mapping now
for those of you who don't get it
hold on for a minute let me explain what
port mapping is if you remember I told
you that the angular application would
be active on one particular port number
right so in the docker file I said port
number four - double zero because I want
my angler application to be active on
port number photo double zero of my
docker container now in case I want to
access it then I cannot access it on my
VM because I am running running a VM if
I want to access this particular
application then I have to access it on
Dockers port number so since I can't do
that what I am doing is I am asking my
Dockers port number photo double zero to
basically share whatever it has on this
particular port number of my web okay uh
this particular port number of my my VM
so here basically I'm mapping my host
port to my container port so with this
I'm asking my system that on my port
number photo double zero of my host on
this particular low close photo double
zero over here
whatever is active on this particular
port number that has to be visible over
here so let's say that in my my angular
application is since it's running on
port number photo double zero of my
docker container I am mapping this to my
host port
photo double 0 ok that's how that that's
all it is and after this I need to just
simply say what is the image I want to
run in my case it's demo app 1 so if you
were to enter my container would
eventually start getting built and then
it'll be active in just a couple of
seconds or maybe more than a few seconds
so just hold on until that happens
so basically my nd servers just started
and it's telling me that it'll be host
it will be active on this particular IP
address right so 0.0.0.0 basically
refers to localhost on my own machine
and since i said port number photo
double 0 i can access my application
over here so either put in this firefox
or mention localhost colon photo double
0 both mean the same and yeah my project
is almost built
92% done
okay bingo the
successfully this is the message that we
usually get whenever we run any mean
stack or annular application okay so let
me just go to my firefox and open this
particular IP and port
so yeah this is Firefox over here and
I'm going to type in localhost
yes photo double zeros right here when
you hit photo double 0 the angular
application is up right so this is my
angular application I was talking about
so yeah that's how things are right so
you can access whatever you want and
whatever whatever needs to happen would
this happen so that's how easy and
that's how effective docker is okay you
can easily spin containers like this
have you know get your application to be
built you own the docker image and once
the docker image is ready are shared
with everyone you want and then your
application would be easily working even
if you want to scale it you can use
docker compose technique to have you
know to scale up your number of
containers and then if you want to have
them on remote machines you can again
use docker swarm for that so docker is
one really amazing DevOps tool I would
say love the docker tool and probably
when you try it yourself then you will
know how brilliant it is so for now let
me show you one more thing let me do
docker PS again and this time if you see
the container which I just started a
couple of minutes ago that is that entry
is here right since I didn't give any
name for my container so just it has
taken any it's taken a default name that
usually happens we have the image name
though so that is the thing if I want to
like manually stop this particular
container which is running then from the
new tab back in just run the command
docker stop and I can I need to specify
the container ID copy paste so yeah my
container has now stopped you can see
alright so this is the entry has gone
and if I go back to my Firefox and
refresh the page
yeah the application is lost that's
because I shut down my container and by
shutting down my container my
application has also been shut down
along with it okay so let me just clear
my screen and now let me get back my
slides and let's go to the next topic
which is continuous deployment again but
this time the deployment is with ansible
so what exactly is ansible ansible is a
configuration management deployment and
orchestration tool which automates your
entire IT infrastructure so it's a push
based of configuration management tool
now what this means is that I can have
one system okay so my system which can
be a controlling machine which is yeah
ansible controlling machine
I can have any number of machines or any
of the servers or remote servers which
we can see those would be my as well
hosts okay if I want to suddenly scale
up my servers and if I want to deploy an
application on these many servers and I
can do that what a meet that what I'll
be technically doing is I will be
deploying my configurations so I can
deploy my configurations on any number
of servers and in my case I will be
deploying probably my configuration and
one on the server okay that's what I'm
going to do my demo and ansible is
called a push based configuration
management tool because and whatever
configurations or code you want to
execute on remote machines right by
scaling up that is done in a push manner
so from your controlling machine you
push your configurations to your other
hosts in your controlling machine you
will specify which are the hosts that
you want to run the script or the code
on write deploy your configurations so
you will have a hosts file in your
controlling machine and in that machine
you will be specifying the IP address of
the other of the hosts machine okay so
once you do that then to all the IP
addresses mentioned in your particular
hosts file the configurations will be
deployed okay so that's how as well
works and so for just summarizing things
it's a configuration management tool
which means your contact raisins would
be deployed on multiple other machines
all right so that's about ansible so
ansible is also popular because it does
these things like provisioning it
supports orchestration with multiple
other tools automation it's push based
and deployment so these are the details
you have to know about ansible so here
let me just talk about ants well I mean
this summarizes what animal is by
talking about its features
number one ant Ville is simple to use
because you don't have to install ants
bill in all your machines okay because
sometimes with certain machines you will
have the problem with ansible you don't
have the problem you just have to
install ansible in one machine which is
you're controlling machine which is like
your master from you're controlling
machine you just need to specify the IP
addresses of your rational hosts and
whatever configurations you deploy it
will be automatically deployed on those
servers or host machines so that's
simple and ansible is powerful because
you can do it to any number of servers
you can create any number of servers and
if you
just bring them up in the blink of an
eye that's how powerful it is and Sybil
is agentless because you don't have to
be an external agent to always be
checking for configurations okay you
just have your controlling machine which
would do everything for you and most of
all animals efficient as well as fast
and as well as simple so that's about
the features of ansible alright so now
that I've done with the theoretical part
of ansible I just want to quickly open
up my beans and show you a demonstration
so for the demonstration let me open up
my VM and in case of for Advil I will
have two beams okay like I said one will
be my controlling machine and the other
will be my host machine so this is my
animal controlling machine which would
deploy my configurations and then I have
another machine which is nothing but an
animal host and this would be the one
that will receive the configurations
from my other machine okay so I'm not
gonna take things make it make things
very complicated and show you an actual
configuration what I'll do is I will do
a simple ping
okay and now before I do that let me
first run this IP config command okay
that's because I'm gonna identify what
is the IP address of my machines for my
ansible host my IP address is one and a
two dot one sixty eight dot one dot one
or two okay so over here let me do the
same thing and yeah so the IP address
over here is one ninety two dot one
sixty eight dot one dot one hundred now
the reason I'm first identifying the IP
address is because I have to specify the
IP address of my host machine in my
hosts file in this controlling machine
okay if you guys have a doubt if you
guys didn't get it then just follow
closely because whatever IP address you
mention in the host file those will be
the IP addresses where the configuration
will be deployed so let's first of all
go to that particular host file okay so
let's do a sudo GRE further Etsy
hosts okay so let me do an enter and let
me give a password over here so this is
my controlling machine right now most of
the lines are commented out so these are
the only two lines which are not okay so
this is because my specifying a group of
servers in this case I've just specified
web servers from my reference so we can
say anything DB servers or any server
for your reference okay and here I have
the IP address 192.168.1.1 not two so
this is the same ip address as my host
machine so the thing which you have to
notice I can have one IP address or I
can have a set of IP addresses then say
if I ask ansible to you know deploy
configurations to this particular group
then all the IP addresses inside this
group will receive the configuration
otherwise I can do one more thing I can
just simply choose is a particular IP
address and say ping this particular IP
address I can do that or if I want to
and well in case if I have more than one
one group then what I can do is I can
use the parameter all to specify that my
configurations need to be sent to all of
the IP addresses present in my hosts
file not just to one particular group so
I have all these options okay so let me
just close this hosts file and quickly
show you how to deploy a configuration
so I'm not gonna actually configure I'm
not gonna actually deploy a
configuration what I'm going to rather
do is ping my host machine okay so
that's equivalent that's equivalent to
basically deploying a configuration
since it's a basic demo and since you
people are beginners so this is good
enough so the command is ansible - M
let's say I wanna ping
basically all the IP addresses present
in my machine so for that I would say
ping all okay when you hit enter
just wait up for what happens
yeah so now we get it right so the IP
address 1.1 or 2 is pinged this is a
success and that's a thing ping pong so
this is how ansible is used to basically
deploy your configurations on multiple
servers and if it was an actual
configuration then even that would have
been deployed to all these hours but
since it's a basic demo you might not be
able to understand it so let's resolve
such demos or such hands-on for future
classes where we'll go into more depth
ok and in the meanwhile let me just go
back to my slides and conclude today's
session but before I come to today's
session let me just talk about Enriquez
DevOps course ok for those of you who
have yet not enrolled for the upcoming
DevOps batch then do note that on
completing the course and on completing
all the projects you get certified by a
two-acre ok and you'll get certified
that you're a devoxx engineer and you
know that you're a person who's killed
on these these these tools and those
tools are get docker puppet cue minutes
Jenkins selenium ansible and Nagios so
what's happening here is our DevOps
course at at Eureka is being upgraded ok
so we are adding a few more modules and
we are adding we are explaining a few
more tools tools like cue minutes
selenium and we are talking about docker
and details so docker which was which is
right now or which was earlier a 1
module course is now going to be a 2
module had ok and same thing with the
fact that we are adding a module for
queue minutes and for selenium and for a
few more tools so these are our changes
or upgrades to our DevOps course ok and
these rules are what you will be
learning and moral wise break up is
going to be this so in the first module
you will be talking about DevOps in
general ok you will get an introduction
to DevOps what exactly it is and how it
is in the market and you get the DevOps
in essentials ok that will you will get
it on a high level and after that in the
second module you will understand what
is version control and the tool that we
will be talking about exclusively is get
ok you will learn everything that you
need to know about gate and github and
how source code management works and the
third module we'll talk about Jenkins
which is a continuous integration tool
like I told you you will learn a lot
about Jenkins and you'll be able to
build a complete delivery pipeline
followed by that is a modular
selenium where you'll talk about how
testing actually works and how it can be
integrated with Jenkins and other and
other tools and now for that we have a
model on puppet and then we have a model
on ansible so both are configuration
management tools puppet is a popular
tool and ansible is the other popular
tool in the market and these would who's
a good enough for you to have a good
knowledge on configuration management
all right and then we have our two
modules on docker
so since docker is really important we
have given more time we have emphasized
that you have to learn more with respect
to networking and the ecosystem aspect
so you will have a basic introduction
over here with respect to
containerization and all these things
and here you will learn more about
docker and then modules 9 and 10 will be
about cuba nets and Nagios so cue
minutes is again a containerization tool
and Nagios is a monitoring tool so after
completing the tenth module your course
at a dareka would end your training with
respect to all these or tools would be
done and you'll be skilled enough to get
a job and start a career as a DevOps
engineer okay so so at any point of time
if you guys have any doubts and if you
want know what know any details about
our course you can always go to our
website at www.irs.gov here and like I
mentioned this will be the various tools
that we will be training you upon ok so
on that note I would like to conclude
today's session so Rajesh Thank You
Amarinder thank you for being a part of
the session and hopefully I will see you
in our first day ops training class ok
so thank you for running this demo class
and bye-bye
until we meet the next time ok so happy
learning I hope you have enjoyed
listening to this video please be kind
enough to like it and you can comment
any of your doubts and queries and we
will reply them at the earliest do look
out for more videos in our playlist and
subscribe to Eddie Rica channel to learn
more happy learning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>