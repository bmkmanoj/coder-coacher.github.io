<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>TensorFlow Tutorial | Deep Learning Using TensorFlow | TensorFlow Tutorial Python | Edureka | Coder Coacher - Coaching Coders</title><meta content="TensorFlow Tutorial | Deep Learning Using TensorFlow | TensorFlow Tutorial Python | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>TensorFlow Tutorial | Deep Learning Using TensorFlow | TensorFlow Tutorial Python | Edureka</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yX8KuPZCAMo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone this is sorted from Adi
Rekha and welcome to this tensorflow
tutorial on deep learning in this
tutorial we'll be covering all the
fundamentals of tensorflow to implement
a use case that is a level mine
identified &amp;amp; m.i so let's begin guys
nevermind identify is a pretty serious
problem in which one needs to identify
whether an obstacle is a rock or a mine
on the basis of sonar signals bounce are
reflected by it so let's get into the
details of this use case imagine you are
hired by the US Navy and your task is to
create a model that can differentiate
between a rock and a mine we will call
this model as a naval mine identifier n
M I unlevel mine is a self-contained
explosive device placed in water to
damage or destroy surface ships or
submarines if you want a better picture
just consider the diagram that is there
in front of your screen so here we have
three submarines out of which one is
broken out into small pieces when it
passes through a naval mine the major
use of these underwater mines or naval
mines began in World War one similarly
in World War two nearly 700,000 naval
mines were later accounting for more
ships sunk or damaged than any other
weapon so now you must have understood
the importance of this use case this
model can actually save a lot of lives
now let's look at the data set that
we'll use to create this deep learning
model here we'll be using the sonar data
set this data set contains sonar signals
which includes 111 patterns bounced off
a metal cylinder and 97 patterns bounced
off a rock both at various angles and
conditions and every record in the data
set represents a pattern now let me show
you the data set so there are total 61
columns in the data set in which the
first 60 columns is a set of 16 numbers
in the range from zero point zero to one
point zero and the last column of every
record is a label which represents the
name of the class that is either a rock
or a mine let me explain you with an
example if the pattern is defining a
rock then the last column would contain
the letter R similarly the pattern
represents our mind then the last column
would contain the letter M so if you
notice in the data set as well in the
last column we have either R or M so
this is nothing but the class to which
the particle
- whether it is a rock or a mine so this
data set contains both the patterns
which can be analyzed for prediction and
the actual outcomes that is whether the
pattern represents a rock or a mine
hence it can be used for training the
tens of know model that we want to
create now is the time to understand the
flow to implement the naval mine under
fire now don't be scared the fancy terms
that I'll use her you'll understand them
all in the coming slides
for now we'll understand these steps
that will be involved in implementing
the tensorflow use case so we'll begin
by processing the data set that we have
well-defined features and labels we'll
divide the data set into two parts
training and testing then we'll train
our modern on the training data we'll
try to reduce the error after that we'll
test our model on the test data and will
calculate the accuracy here our ultimate
goal is to achieve the highest possible
accuracy so guys let me quickly execute
the tensorflow Bourne that I've already
created for you for that I'll open my
pie chart so this is my pie some guys
over here have already written the code
in order to execute the use case so I'll
just go ahead and run this
so this is how the output looks like
weather deep learning model is getting
tripped
if you observe with every iteration the
accuracy is increasing and the error is
decreasing so we'll stop it right here
so guys any questions any doubts with
respect to what is our use case and what
is the data set about you can go ahead
and ask me any questions emma is a
question she's asking what is the size
of the data set so the size of the data
set is 208 cross 61 which means we have
208 rows and 61 columns all of which the
last column is nothing but the label or
you can say the class represented by
that particular particle any other
questions any other house guys
fine so we have no questions so with
this we'll get back to our slides and
understand the fundamentals of tensor
flow first before we get into the
implementation details of this use case
in order to implement this use case
we'll be using tensor flow which is a
Python library intensive flow data is
represented in the form of tensors so
let's understand that first tensor flow
programs use a tensor data structure to
represent all data you can think of a
tensor as an n dimensional array or list
now consider the example that is there
in front of your screen
so the first tensor has dimension zero
the next tensor has two dimensions
because it has rows as well as columns
and the last tensor has dimension three
because it has one more speed now
intensive low system tensors are
described by a unit of dimensionality
known as rank so let us understand that
so arrived two tensor is what we
typically think of as a matrix and the
rank 1 tensor is a vector now let us
focus on the table that is there in
front of your screen so rank 0 is
nothing but a scalar which has magnitude
only you can think of its example as 483
689 numbers like that then when I talk
about Rank 1 it is a vector which has
magnitude and direction both and you
have the example in front of your screen
one point one to point to three point
three similarly when I talk about rank
two it is nothing but matrix tables of
numbers you can say rows and columns and
you have an example here as well
similarly when I talk about rank 3 you
can see the example here so this is how
we actually define the rank of a tensor
now let us move forward and understand
various sensor data types you can see in
the table that there are multiple data
types
there is integer type of 8 bits 32 bits
etc similarly even for flow type then
there is even string and boolean type
however intensive law you don't need to
specify the tensor data type it will
automatically assign the correct type
but if you want to save the reserved
memory for example if you know you
require only 32 bits then there is no
point in reserving 64 bits so at that
time you can specify the tensor data
type to be of 32 bits so that way you
can save some memory so guys now is the
time to understand what is tensor flow
tensor flow is an open source software
library released in 2015 by Google to
make it easier for developers to design
develop and train deep learning models
or neural networks now tensor flow works
by first defining and describing our
model in abstract and then we are ready
we make it a reality in a session now
don't worry guys in the next line I will
explain what exactly is session this
description of the model is what is
known as your computation graph
intensive job and remember guys only
tensors may be passed between the nodes
in a computation graph now if you note a
stencil flow is nothing but the
combination of two words tensor which we
saw in the previous slide and flow which
is nothing but the tensor is flowing
through a computation graph so guys let
us dig a bit deep and understand the
tensor flow code basics the tensor flow
programs consists of two sections one is
building the computation graph here we
just described the computation it
doesn't compute anything it doesn't hold
any values it just defines the
operations specified in your code when
you execute it the output will just be
an abstract tensor no actual
calculations will run only operations
will be created to actually see the
result we need to run this session
generally you build the graph first and
then you launch the graph right this
session allow us to execute the graph or
a part of the graph let us understand
this with an example so this is how you
build a computation graph here we have
defined two constant nodes node one has
a value of 3 and node 2 has value 4 then
what we do we need to run it inside a
session in order to execute the graph
now let me go ahead and execute this
practically in my Python this is my
Python again guys first thing I need to
do is import tensorflow
as TF
then we'll define two constant nodes
node one equal to t f dot constant and
the value will be stored inside it will
be 3.0 it is off T F dot slowed 32 bits
then we'll define one more node and let
it be T F dot constant again and the
value that will be stored will be four
point zero next up when we try to print
these two nodes let's see what happens
let's go ahead and execute this now the
output here is just an abstract tensor
no actual calculations are running only
operations are created now to execute
this graph let me tell you how you can
do it first I will comment this line now
to execute this graph we will run it
inside a session as I've told you
earlier as well
so session places the graph operations
on two devices such as CPUs or GPUs and
provides methods to execute them so I'll
type in here says is equal to TF dot
session so this will basically launch
the graph and create a session object
next up we will run the results so for
that I'm going to type in here print
says dot run and we want the values of
node 1 and node 2 so let us go ahead and
type that node 2 yeah this is fine now
and we are finished with the session we
need to close it in order to free up the
resources that were used so that is also
very easy the stipend says not close
that's all you need to do go ahead and
execute this
so we have got the output as a three and
four which is absolutely correct these
are the values stored in the constant
nodes 1 and node 2 there's one more way
in order to launch the graph and close
the graph apart from the one that I've
shown you so let me show you how you can
do that for that our I'm going to do I'm
going to first comment this line even
this line so for that what I'm going to
use I'm going to use the bit statement
of Python so for that I'll type in here
with TF dot session as says output equal
to says dot run node 1 comma node 2 go
ahead and print the output so if you're
not familiar with what this does
basically it will use a session for the
block of code following the statement
and then automatically close the session
when done the same way it works if you
open a file with the width statement so
let us go ahead and execute this and
we'll see what happens so again we
haven't got the same output 3 and 4 so
I'll explain you a couple of ways in
which you can start and stop a session
so guys let me explain you this with one
more example for that I'll open my
slides once more here I first defined a
constant node a which has a value 5 in
it then I've defined one more constant
node which is B and the value stored in
that node is 6 after that I've defined
one more node and this is nothing but
the multiplication of a and B so till
now we have built our computation graph
next up we need to run it inside a
session so when we run the session what
will happen the values that are stored
in a and B will be multiplied let us see
if that happens
yep so after running the session because
the output as 30 which is nothing but
the multiplication of a and B so when
you multiply 5 by 6 obviously you will
get 30 now guys I'll open my pycharm and
execute this practically let me remove
all of this so first I am going to
define one constant node the value that
will be there will be five point zero
one more constant node the value inside
that node will be
6.0 then see is nothing but the
multiplication of the two nodes so we
have build a computation graph next up
we need to create the session object
which will launch the graph success is
equal to TF dot session so guys you can
even use a wit statement of Python in
order to do that but I'm comfortable
with this so I'll continue from here and
then what I need to do is just run the
session says dot run see that's what I
want to compute and yeah finally just
close the session says start close go
ahead and execute this so we have got
the output as 30 which is nothing but
the multiplication of nodes a and B
which throws the value 5 and 6
respectively now I know multiplication
of two numbers is not a big deal but it
is a good example for understanding how
things work intensive throw now what if
I tell you that you can actually
visualize a computation graph let me
tell you how for that I will open my
slides so for visualizing tens of no we
use 10 support tents abroad is a suit of
web applications for understanding your
tensor flow graphs for that what we need
to do we need to first create the object
of class for writing summaries one such
class is called file writer so it has
two arguments the first argument we need
to just specify the path of the
directory where we want the information
to be stored that will be used by 10
suppor in order to build the graph after
that we need to run this particular
command the command line and we see the
tensor code will run as a local web app
and port 6 double 0 6 so I'll quickly
open my pycharm and I'll execute this
practically let me close this here so
after that I just need to create an
object file writer object file writer
equals to TF dot summary dot file writer
and I need to provide a path here so
I've already copied the path I just
paste it here and once you have written
the path just type the name of the file
so as this type in here graph
that I need to add a fifth graph which
is used for creating a graph object so
this type in here says dot graph alright
so now if I execute this I'll see a
directory here by the name of graph that
will contain the information which will
be used by 10 suppor in order to build
the graph so let us see if that happens
or not I'll run the code and yeah you
can notice here that there's one more
directory created that is called graph
next up we need to open a command line
and execute one command let me show you
how you can do that so over here first
I'll move in the pycharm directory yeah
and then I'm going to type in here
tensor board - - log dir
equal to the path 10 to flow just go
ahead and execute this so it says that
10 suppor runs at the local web app at 4
to 6 double 0 6 let us see how our graph
looks right now
so this our graph looks like it has two
constant nodes here and one node for
multiplication so when I click on each
of these nodes there will be some
information displayed about that node so
if you notice here it is a flow type it
also contains the value that is stored
inside this particular constant node
which is fight there are zero inputs and
0 input similarly for this constant node
as well it is a flow type and it holds
the value 6 similarly when I click on
this particular node we can see that it
is again float type and it has two
inputs Const and constant is code 1 so
these two inputs will be multiplied and
we'll get the output
I have a question popped on my screen
this is from Michelle she is asking why
aren't we seeing the output here it says
output 0 alright fine so I'll tell you
this is just a computation graph this
explains what are the operations that
you have specified in your code it
doesn't execute that all right so this
answers your question all right fine
she's happy with answer any other
questions any other those guys go ahead
and ask me and mole jostle Emma Janis
any questions fine guys so there are no
questions so I'll go back to my slides
one spot and now is the time to
understand what our constants
placeholders and variables so constant
as the name tells that it will always
produce a constant result so I'll
explain this as an example so over here
we have a couple of constant noise first
though it has value 3 another load has
value 4 so when I execute this
particular graph I will always get the
values 3 and 4 or you can see the values
that are stored inside these 2 nodes now
what if I want my graph to accept the
external input now let me explain that
with an example of our use case only so
here we want the features to be fed back
to the graph that we cannot do with the
help of constants for that what we need
we need placeholders now a placeholder
is nothing but a promise to provide a
value later let us understand this with
an example so over here we have a couple
of placeholders a and B of float 32 bits
and notice that we have initialized no
values then we have one more tensor
added underscore node which is nothing
but the addition of two placeholders
then we have first launch the session
and then we are running the session we
feed in the values of the two
placeholders as you can see here so the
value that will be fed back to the
placeholder a is 1 comma 3 the value
that will be fed back to the way
placeholder B will be
2 comma 4 so let me execute this
practically in my Python let me remove
all of this all right
so undefined a placeholder a TF dot
placeholder which is of float 32 bits
similarly B will be again a placeholder
of TF dot float 32 bits then we define
one more node other underscore node
which is nothing but the addition of
these two placeholders next up we need
to launch the graph for data type SS is
equal to TF dot session and next up we
need to run the graph print says thought
run and adder underscore node and we
need to feed the values of a and B as
well so for that I'll type in a 1 comma
3 b2 comma 4
now let us go ahead and execute this and
see what happens
so here if you notice I get the output
as the sum of the two placeholders a and
B so the first value one will be
assigned to the placeholder a and value
two will be assigned to the placeholder
B so their sum will be three similarly a
will be assigned to the value three and
B will be assigned with value 4 hence
their sum will become 7 now let's get
back to our slides ones would now the
questionnaire is how to modify the graph
if I want new output for the same input
I mean if I want my model to become
trainable I need some parameters that
can change after every iteration so that
the model output can be as close as
possible to the actual output for that
we need variables now variables as a
name explains the value of the variable
will keep on changing when you train a
model you use variables to hold an
update parameters variables are in
memory buffers containing tensors and
remember they must be explicitly
initialized
unlike constants and placeholders let me
explain you the code that is there in
front of your screen so here we have two
variables W and B and I've initialized
both of these variables with value 0.3
and minus 0.3 so if I train my model the
values of these two variables should
change in order to reduce the output
don't worry you'll actually understand
that when I explain you the loss
function and optimizes there you'll
understand how we actually train our
model and how actually variables are
updated after every iteration and you
know in order to initialize variables we
use TF global underscore variables
underscore initializer this will add an
operation to initialize the variables
then we run says dot so an EIN it this
will run that operation and remember we
only run it after launching the model
for now let us go ahead and execute our
first model so this is our first model
guys over here we have imported the ten
to flow as TF then we have defined
couple of variables W and B and we have
initialized them as point three and
minus point three values respectively
then we have a placeholder X after that
we have defined one linear underscore
model which is nothing but W into X plus
B then we have initialized the variable
launch the graph and then we are running
the session and during that we are
running the session and feeding the
values of X so this is basically what
our model is but we don't know how good
it is yet so obviously we cannot
increase the efficiency without knowing
the error
let's understand the general flow of how
we increase the efficiency so first we
create the model as you have seen in the
previous slide then we calculate the
loss loss is basically how far our
models output is from the actual output
then we try to reduce the loss by
updating the variables then again we
check the loss and update the variables
and this process keeps on repeating
until the loss becomes minimum and now
is the time to understand how we
calculate loss so in order to find out
the loss we should first define a
placeholder and we have named it as Y
which will hold the desired output or
you can say the output that we already
know then we will find the difference
between the linear underscore model or
the output upper model with that of the
output that we already know the
placeholder Y or you can say the
difference between the model output and
the actual output then we find the
square of that particular difference and
then finally we sum all the squared
errors that we have calculated in the
above light so we'll sum all of these
squared differences then what we have
done we will run the session calculate
the loss and we'll feed in the values of
x and y so I'll execute this practically
for that I'll open my PI charm let me
remove all of this so you are first will
define a variable t f dot variable with
the initial value as 0.3 and it is TF
dot flow 32x then we will define one
more variable TF dot who variable minus
0.3 comma T F dot float
32-bits
a placeholder that we will use in order
to provide the inputs or to feed in the
inputs so let me throw in a comment here
inputs and outputs
I can throw in one more comment here it
says model parametres alrighty then
so now we'll define a placeholder X
which will actually hold the input
values TF dot placeholder it will be of
flow type 32 bits then we'll define one
more placeholder wire which will
actually hold the actual output of the
model which we already know placeholder
TF dot float 32 bits all right and just
between that will define one more node
linear underscore model which will give
the output of this particular model
which we don't know so that's the
difference guys this y is a placeholder
and the values of this Y will feed in
when we are running the session so that
will be the actual output of the model
and this will be the output of the model
which will come after executing the
model so this will be nothing but W into
X plus B fine and now we are going to
define the loss function so on type in
here square underscore Delta is equal to
TF dot square linear underscore model
minus y which is nothing but the model
output of the output that we already
know so linear underscore model is the
output that we'll get through our model
and y is a placeholder which will have
the output values that we will feed it
then we are going to define a loss
function so loss is equal to TF dot
reduce underscore sum of all the squared
Delta so we have to find a loss function
here next up what we need to do is
initialize all the variables for that I
am going to type in here
ein it is equal to TF dot the global
underscore variables underscore
initializer so this global variable
initializer will add an operation to
initialize a variable now we need to
launch the graph for that we need to
create a session object and we know how
to do it says is equal to TF dot session
yeah and now we are going to write in
here SAS dot run
I knit so this will run the operation
that we have defined when we were
talking about global variable
initializer and after this our variables
are initialized so now what we need to
do is just run the session says dot run
calculate the loss feed in the values of
X so let it be 1 comma 2 comma 3 comma 4
and now to placeholder Y feed in the
value of space on the Y so we'll keep it
as 0 comma minus 1 comma minus 2 comma
minus 3 now let us go ahead and see how
much is the loss so the loss that we
have calculated is 23 point six six and
let me just close this once now or if
you notice if I change the value of W
and B I can actually reduce my loss let
me show you how I can do that I'll take
a pen so instead of 0.3 and minus 0.3 if
my W becomes minus 1 and my B becomes 1
then linear underscore bottle will
become equal to Y that means the output
of our model will actually become equal
to the actual output the output that we
know so let me tell you how it will
happen
so a linear underscore model is W into X
plus B so we'll take the values of x one
by one so the first value of x is 1 so
let me take that first and the value of
B is minus 1 so minus 1 into 1 plus 1 is
equal to 0 so the value of our leader
underscore model is 0 and over here also
the value of y that is our placeholder
or the actual output is also 0 let us
take the next value of x which is
nothing but 2 1 minus 1 into 2 plus 1 is
equal to what minus 1 which is again
equal to Y similarly minus 1 into 3 plus
1 is equal to minus 2 which is also
equal to our placeholder why finally if
I take the last value of X which is 4
plus 1 it will be equal to minus 3 so
this is how when we update the variables
we can actually reduce the loss so here
if I keep the values of W and B as minus
1 and 1 respectively
the loss that I will get will be 0 so
this is how you can actually reduce the
loss by updating the variables so when I
was explaining variables where I told
you that in order to make the model
trainable we need to update the values
of variables so this is what I was
talking about so by changing the value
of variables we can actually use the
lots they can make the model output as
close as possible to the actual output
now if I make this as minus one point
zero and this as one point zero we
should get zero error let us see if that
happens or not so we have zero rows but
over here I have manually done it I have
manually updated the variables W and B
what if I want my model to do it on its
own what if I want the machine to learn
the new values of W and B that will
minimize the loss so that time we need
optimizers so for that I'll open my
slide one spot and let me remove all of
this yeah and keep this to its normal
value of 0.3 it was plus point three and
this will be minus twenty three now I'll
open my slides so in order to increase
the efficiency and minimize the loss and
update the variables we use optimizers
these optimizes modifies each variable
according to the magnitude of the
derivative of loss with respect to that
variable now what does that mean it
means basically that an optimizer will
check the magnitude of the derivative of
loss that means an optimizer will check
the change in the loss with respect to
the change in the variable and if the
loss is decreasing then it will keep on
changing the variable in that particular
direction I hope I am clear guys if you
have any questions or doubts you can ask
me right now it is a very important
concept all right a Jason wants me to
repeat it fine Jason I'll do that so an
optimizer will actually calculate the
change in the
with respect to the change in the
variable and if the loss is decreasing
then it will keep on updating the
variable in that particular direction so
that loss becomes less so I hope you
have understood adjacent now yeah so
here we'll use gradient descent
optimizer let us understand this with an
analogy suppose you are at the top of
the mountain and your task is to reach
the lake which is present near the
valley and the catch here is that you
are blindfolded so how will you approach
this task one way of doing this is to
observe the ground near you and move in
the direction where the land tends to
descent consider every step that you
take as learning rate and the position
as with the whole process is called as
loss function when you reach the lake
consider that point as global loss
minimum now you can apply the same
concept on our model as well where the
ground tends to descend
similarly the optimizer checks in which
direction should the variables be
updated so as to decrease the loss and
will keep on updating the variables in
that particular direction so let's
understand the math behind gradient
descent optimizer first we calculate the
loss how we do that by summing all these
squared differences between the model
output and the actual output and then
dividing it by two so here our target
output is nothing but the output that we
know and output is nothing but the model
output after that we calculate the
change in the variable Delta W this is
equal to the learning rate multiplied by
the rate of change of floss with respect
to that variable after that the new
variable or the updated variable is
equal to the sum of the change in the
variable plus the old value of that
particular variable so it will be W plus
Delta W now let me simplify this
equation for you so we're here will be a
calculating Delta W J which is equal to
minus of learning rate into Delta J by
Delta W J or you can say the rate of
change of error with respect to that
particular variable we put in the values
of J then we find out the derivative and
we get the equation as learning rate
into summation of target I minus output
I that means the actual output minus the
model output into XJ or v which is
nothing but your input so guys any
questions any doubts till here
any questions related to what our
optimizers
and how does the gradient descent
optimizer work any questions you can go
ahead and ask me all right today once we
do repeated find a well do that so the
first thing that you do is first you
calculate the error what do you do you
find out the difference between the
actual output and the model output then
the difference is squared and you sum
all of those squared differences and
then divided by two this is how you
calculate the error then what you need
to do is you need to update the
variables so as to reduce the loss or
the error so how you do that you first
find the change in the variable which is
equal to minus of learning rate
multiplied by the change rate of change
of loss with respect to that variable
del J by Del W J so after that what you
do you calculate the new updated
variable which is nothing but the old
variable plus the change in that
variable which is nothing but the old
variable plus the change in that
variable Delta W that's how it works so
we have got a new value of the variable
so again the model will check how much
is the loss and again the whole process
will repeat again we'll update the
variables again it will check the loss
update the variables until unless the
loss becomes minimum all right he is
happy with answer fine guys so we'll
move forward and see how we can apply
gradient descent in our model now in
order to modify the variables in our
model we'll use a code that is there in
front of your screen here we'll first
create an object of class TF dot train
dot gradient descent optimizer and it
will implement the gradient descent of
algorithm it takes one argument as the
learning rate the second part this
minimized returns an operation that
applies gradients it will reduce the
loss by updating the variables finally
just run the session and feed in the
values of x and y and then evaluate the
variables W and B so let me go to my
Python and execute this let me comment
this line first so after defining loss
we will optimize our model
right in here optimizer equal to TF dot
train dot gradient descent optimizer
with a learning rate of point zero one
learning rate is nothing but the steps
steps in which you change your variable
then what we do we will write in here
train is equal to optimizer dot minimize
loss all right no doubt still air guys
if you have any questions write it down
in a chat box fine to the run no doubt
and after initializing the variable we
need to run the session so for that I
will use a for loop so I'll type in here
for I in range thousand self-taught run
train come up feed the values of x and y
so I'll just copy it from here and I'll
paste it there alright then go ahead and
evaluate the variables W and B
so we have got the new value of W as
minus 0.99 9 9 9 6 9 and the new value
of B as 0.9999 and 0 8 2 now if you can
recall when we were calculating it
manually we got the output for W as
minus 1 and for B we got it as plus 1
and these two values are almost the same
so minus 0.99 a 9 can be rounded off to
minus 1 and 0.999 and 0 8 2 can be
rounded off to plus 1 so this is how you
actually build the model then you
calculate the loss and then you train
the model I hope I'm clear if you have
any questions any doubts go ahead and
ask me no questions fine so I will go
back to my slides so guys this brings us
to the most a varied topic of today's
session which is the implementation of
nmi that is a use case which is
nevermind identifier so guys let me
first tell you the steps that are
involved in order to implement this use
case first we need to process the data
set that we have well first read the
data set then we are going to define the
features and labels so what are labels
labels are nothing but the class to
which the pattern represents in our case
it can be a rock or a mine then we need
to encode the dependent variable and
here the dependent variable is nothing
but your label so we are going to encode
those dependent variables after that we
are going to divide the data set into
two parts one for training another for
testing and by the end of the step our
data set is now ready next we are going
to use tensorflow data structures for
holding teachers labels etc so here will
be defining weights biases I will have a
couple of placeholders for inputs as
well as for the desired output that we
already know and will also define one
tensor that will be our model output
then we are going to implement the model
we are going to write the project in
order to implement the mod then what we
are going to do we are going to train
the model on the training data that we
have so in this particular step we have
divided the data set into two parts
training and testing we'll use the
training data to Train Aman then we are
going to calculate the error that is how
far your model output is from the actual
output and then we'll try to reduce this
error and when we reach to a point where
the error becomes minimum they are going
to test our model on the test data or
you can say we are going to
make prediction on the test data and
that will give us the accuracy of our
model so this is how we are going to
implement the use case now I'll open my
pycharm and execute this practically
guys so guys we'll first start with
importing the necessary libraries
first we'll import matplotlib which is
used for visualization and tensorflow
the numpy pandas and SK learn as well so
these are the libraries that we are
going to use so we need to import these
libraries then we are going to read the
data set for that we are going to use
pandas so we're going to convert this
data set it into a data frame a panda's
data frame and then we are going to give
the path to where our file is stored or
our data set is stored then we are going
to define features and labels so here X
will be our feature so basically the
first column till the 60th column will
be your features and the last column
represents the label as I have told you
earlier as well so the last column will
be our label and it will be stored in Y
after that we need to encode the
dependent variable which is nothing but
our label now we'll perform label
encoding first and then we are going to
perform one odd encoding so guys I'll
explain you one hot encoding and label
encoding with a pen so suppose if I have
labels like rock then mine then again
rock then one more mine first we'll
perform label encoding in which I'll
assign values to it so suppose if I
assign 0 to a rock and one to a mine so
I'll keep it that way for the rest of
the rows as well alright so now we'll
perform one whore encoding in which
we'll have two columns one for mine and
another for rock so wherever the data
represents a mine it will be one so this
basically represents a rock so it will
be 0 this row represents a mine so it
will be one this represents a rocks will
be 0 similarly this represents the vines
it will be one now the second column
whether the data represents a rock we'll
keep it as one so this represents a rock
we'll keep it as one this represents the
mind so that be 0 this will again be 1
because it represents a rock this isn't
the mind so we'll keep it as 0 so this
is how you perform a one horn encoding
so what is one out encoding basically
only one input will be active at one
point so basically what is one or
encoding only one input will be active
so let us move forward
off so this is the function that
actually defines one hot encoding so
this is where we have performed one hot
encoding then what we are going to do we
are going to read the data set so X is
basically your feature and Y is one hot
encoded label then we are going to
shuffle the data set we need to suffer
the data set because the whole data set
that we have it is presented on order
for example in the beginning we have
minds and then we have rocks so we need
to shuffle it so after doing that we are
going to split the data set into two
parts training and testing how are we
going to do that you can see it over
here so we have defined the test size is
point two zero which means the 21st of
the data set will be your testing data
set now if you can go ahead and inspect
the shape of the training and the
testing data although it is not
necessary but still if you want to go
ahead and do it you can do that as well
then we are going to define the
important parameters and variables to
work with tensors so first they're going
to define learning rate so we have seen
what exactly learning rate is then they
were defining a pork a fog basically
means the total number of iterations
that will be done in order to minimize
the error then we're going to define a
loss function cause history then we have
n underscore dim so what is ending so
basically end M is nothing but the shape
of your features which is stored in X
and that too it will only include the
columns the number of columns so then
we'll print it
and you can still avoid this step if you
don't want to print it it's all fine
then you define a number of classes so
since we have only two classes that is
mine and rock we're going to keep it as
two then we're going to provide the
model path which will be nothing but the
place where we want to store our model
so I've given the same path in which I'm
currently working so you will see a
couple of files created when we execute
this model then we need to define the
number of hidden layer the number of
neurons for each layer so basically I've
talked about hidden layers neurons
multi-layer perceptron perceptron
everything in detail in the previous
tutorial so you can go through that if
you have any doubts then we have the
number of neurons for a 10 layer one two
three and four
so they're going to take four hidden s
so this is nothing but an example of
multi-layer perceptron so X is our
placeholder in which we are going to fit
in the input values or you can say the
data set it is off toed 32 bits and then
the shape of this particular tensor is
non comma ended so endemism earlier so
if I tried here none which means it can
be any
then we'll define a variable W which
will be initialized with zeros and in a
large shape and underscored in which we
know what it is
and then underscore class which is
nothing but class to which a pattern
represents we have two classes here so
it will be n underscored M comma two
then we have one more variable B we'll
fill it with readers or it will
initialize it with zeros and it will
have a shape of n underscore a class
that is two then we're going to define a
placeholder y dash which will be nothing
but the output of our model that we
already know and its shape will be non
comma n underscore class one can be any
value and we know n underscore class is
equal to 2 because the eye only 2 plus
is my another so now we are going to
define a model they got a name it has
multi-layer perceptron because it is an
example of multi-layer perceptron
so first we'll define the first hidden
layer in which it will be nothing but
the matrix multiplication of your input
and the weight and then we are going to
add it to the bias then we're going to
pass it through a sigmoid activation
function there's a second hidden layer
also the same thing will happen and the
input for the second hidden layer will
be the output of the first hit in there
so we're going to type in here layer on
the score 1 and then we are going to
define the weight which will be H 2 so
matrix multiplication of that and then
add it to the bias
similarly for later hidden layer 3 is
when and in a hidden layer 4 instead of
using sigmoid activation function will
use reloj activation function and then
you finally comes the output layer in
which so we get a perform matrix
multiplication output of the previous
hidden layer and these eight and then we
can add biases to it so now we need to
define weights and biases for each layer
so H 1 is the weight for the first
hidden layer so we're going to define
that it will be a variable and it will
be a truncated normal of N and this code
trim and end in the score hidden
underscore 1 which is nothing but the
shape of this particular tensor or this
particular variable and underscored M we
know and an underscore hidden underscore
1 is nothing but 60 similarly for other
weights as well and the same goes for
biases as well here we'll have shape
which is equal to n underscore hidden
underscore one here n is equal to 3 and
4 and then finally the output bias will
be equal to n underscore class which
will be nothing but 2 because we have
only two classes then we need to
initialize all the variables which we
have seen how to do that after that we
are going to create a saver
object in order to save our model then
we are going to call the model that we
have defined above then we're going to
define the cost function and optimize
the cost function is nothing but the
loss function so this is a loss function
that we have defined there so over here
if you notice let me just show it to you
yeah so this is how we have defined a
cost function so we're going to use the
softmax cross entropy and logits y is
nothing but your output and that labels
y dash is nothing but your actual output
or you can save the output that we
already know and this is the mod log
then we are going to perform
optimization you're going to use
gradient descent optimizer and then this
is the learning rate will be point zero
three which we have defined above and
then it will be minimizing the cost
function or the loss so this is how we
will optimize it then what we need to do
we need to create a session object that
will launch the graph and this will
initialize all the variables then we
need to calculate the cost and the
accuracy for each epoch how are we going
to do that they're going to use for loop
for that so first we'll define MSE
underscore history and accurate history
we'll keep it empty then we are defined
for a pork in range training underscore
a pause over here first we'll run the
training step you're going to feed in
the values of train underscore X and
train underscore Y which is nothing but
the training data then we are going to
run the cost function or you can say the
loss and again a feed in the values of
train underscore X and train underscore
Y then what we're going to do we're
going to define cost history which will
be append the cost history comma cost so
whatever cause history we have whatever
cause we'll get it here it will be
appended and it will be here cause
history so we can see that for every
port that's why we are doing it so it
should be appending one by one then we
are going to find out the correct
prediction which will be equal to TF dot
RM X Y comma 1 and arm XY - comma 1
which is nothing but the difference
between the actual output of the model
output and after that we're going to
calculate the accuracy here and then
what we need to do we'll define a
parameter print underscore Y which will
be nothing but says dot run and the
actual output and feed in the test data
in order to see how accurate our
modernist similarly we're going to
refined MSE mean squared error which
will be nothing very difference between
the predicted value and the test value
then we're going to launch the graph
here and that we're going to find the
MSCI history dot append so this will
actually keep on updating the MSE values
are every 1/4 then you're going to find
out the accuracy of the training data so
basically we will be finding here the
accuracy on the training data nor on the
test data and we'll keep on appending so
that for every epoch we can see that
then we're going to print that value for
every epoch after that we going to
define one more parameter save
underscore path which will be savoured
saves says comma model so this will
actually save the model in the model
path now we're going to plot the graph
of MSE and accuracy MSE is nothing but
the mean squared error and accuracy will
be there on your test data and mean
square error we know what it is so we
have calculated MSE here if you can
notice then what we need to do we need
to print the final accuracy for that
will first find out the correct
predictions made by our model and then
we're going to find out the accuracy and
finally these are printed by running the
session and feeding the values of test
data in x and y finally we need to print
at the final mean square error which
will be nothing but red underscore Y
says dot run y comma feed it survives
our actual output and feed underscore
date is just we are feeding the test
input then we are going to calculate MSE
mean squared error which is nothing but
the difference between the predicted
value and the actual value which is
there in the test data and the square
and print is so we'll now start training
our model so let us go ahead and run
this
so in the beginning if you note it has
printed this
then it is printing the test in the
training data shape as well and now it
has started training a model so you can
notice the training accuracy that we are
getting here so it will keep on
repeating this process four thousand
times four thousand a pot spacing these
a thousand iterations after that our
model will be trained
so guys this is the accuracy that we
have got on our test data so this mi
axis represents the accuracy and the x
axis represents the number of efforts so
we have thousand a box here that means
it's going to chain it thousand times so
let me just close it now and yeah so we
have got the test accuracy as 85% and
the average mean square error is twenty
four point four five zero five and our
model is saved in this particular
directory which is my current working
directory guys now let me close this and
open the project structure and you can
see a couple of files that have been
created here so guys we have
successfully trained our model and we
have saved it as well now what we are
going to do we are going to restore this
model so basically we will be providing
some input to this particular model and
it will predict the outcomes for us so
when it will predict whether it is a
rock or a mind so the whole code remains
the same it's just that you need to
provide the model pass which you have
done when you were actually defining the
model and training it and then what you
need to do is you need to again create
one saver object and after that finally
you need to call this restore function
in order to restore the model that we
have over here you going to provide two
arguments one is set and another is
nothing but your model underscore pass
which we have given in the previous step
so guys this is how it is and you're
going to provide the input from the data
set only which will be from rows 93 till
101 but it won't include 301 throw it
will only be that an hundred throw fine
guys so let us go ahead and run this
so this is how the predicted values
looks like over here the original class
was our we predicted value is 1 which
means we have correctly predicted this
particular class and we have got the
accuracy 100%
similarly for other values as well but
if you notice over here we have got the
accuracy as 0 because we have predicted
the Krong value of the class
similarly here is then it is a mind but
we have credited it as a rock that's why
we have got accuracy as 0 so guys this
is how we actually train a model and we
restore it so this is all about Nevel
mine identifiers now let me give you a
brief summary of what all things we have
discussed and now so guys first we
started by understanding what is our use
case we saw what exactly we are
executing we saw what the data set looks
like so the name of our model was and
nevermind are in the file after that we
understood what exactly are tensors and
what is 10 0 then we went through code
basics of ten to flow we understood
various data structures like variables
placeholders constant and then we
implemented the model using tensor flow
so guys any questions any doubts till
now you can go ahead and ask me any
questions all right they say is amazing
session thank you today for those kind
words
so we have no questions so this video
will be uploaded into your element you
can go through it if you have any
questions or doubts you can bring it in
the next class we also have a 24/7
support team that can help you anytime
you want thank you and have a great day
guys I hope you enjoyed listening to
this video please be kind enough to like
it and you can comment any of your
doubts and queries and we will reply to
them at the earliest to look out for
more videos in our playlist and
subscribe to our retro Rica channel to
learn more happy learning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>