<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Talend Components | tMap, tJoin, tFileList, tInputFileDelimited | Talend Online Training | Edureka | Coder Coacher - Coaching Coders</title><meta content="Talend Components | tMap, tJoin, tFileList, tInputFileDelimited | Talend Online Training | Edureka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/edureka/">edureka!</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Talend Components | tMap, tJoin, tFileList, tInputFileDelimited | Talend Online Training | Edureka</b></h2><h5 class="post__date">2018-04-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5f0i6xKd00o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone this is sugar on behalf
of Erica in this video today we are
going to learn about talent components
so let's see the agenda of this video so
today we will be discussing again a
brief introduction about talent and more
focus will be on the talent components
what is component what are the different
families of components available in
talent how they are used and then we'll
move on to specific components which are
widely used that is file components and
then processing components and then
database components so the end of this
video should be able to understand what
is component and use the file processing
and database components for simple use
cases so that's more so what is the
talent to give a introduction about it
talent is an open source data
integration platform and also a vendor
it is also a company which provides you
all these data integration tools not
only talent DEA but then Big Data data
preparation all other products talent
will provide for all our data needs it
provides various software and services
which helps companies to become
data-driven everything about data talent
has a tool for you it helps organization
in taking real-time decisions
you put given all the data whether it
can be master data management or your
sales trend or your business management
decisions can be taken over your data
analyzing over it so talent helps you to
do that in a better way so it enables
customers to adopt new innovations and
scale to meet market demands so
recognized as leader in the Gartner
Magic Quadrant so it is in the quadrant
of leaders actually so it is giving very
tough competition to the market leaders
like informatica and datastage since it
is very user friendly and java based it
has got the position in challenges
quadrant in very less time so that's
talent for you so what would valiant
components what actually a component
means we have also been telling about
you know talent and components in our
previous videos as well so today we are
going into a very deep dive into the
components topic so what is talent
component it is just a piece of java
code whenever you drag and drop any of
the component into talent design
workspace it will generate the java code
which is
quí to do that work of the component at
the back end well where do you find the
components the pallet is a place in
Tallinn they do a window called palette
window as you see in this slide so in
this window we'll be able to find all
the components who are organized into
groups and again it is a snippet of Java
code that is generated when job is
executed and Tallinn provides you more
than 900 components in your talent di
and in your Big Data talent Big Data
will have between a components as well
so all these standard component is
widely used and will be taking which are
very required components like as I
mentioned that is file components
processing components and database
components so as I said you there are
more than 900 components but then it
should be in groups right for us to
understand what category they belong or
what family they belong so they are
broadly classified into so many families
that he saw big data it can be business
intelligent it can be ETL or lakhs and
adders
orchestration processing or it can make
some unrelated or it can be cloud
related or MDM related a system related
so they are all divided into different
families and is one component can fall
into different families as well so let's
move to file components now so for
example how talent components are named
is it starts with a letter T and what is
the format of it well insert file when
it's a DB what is that we are having as
a company and then the next set will be
like whether it is an input component or
an output component it will be named
like that and after that the format of
the file whether it's an XML file
delimited file excel file whatever it is
so T file input Excel is the component
name which will be used to read an XML
file so whenever I use this component if
I probably fine name and if I tell
whether it is XLS or s Alexis it
extracts the data line by line so when I
drag and drop this component I'll be
able to read the excel file which is
available in my system line by line so
we'll be showing you in the demo like
how we can use this component as well
but then first understand how it is
named and what is this component for so
it opens a file and reads it row by row
in order to split up the data into
fields using regular Express
like you can create schema read line by
line if we want to filter out you can
filter out everything can be done in
talent so using the RO link whenever you
right-click on any of the component the
way the data can be taken out of the
component after reading so it will be in
the main row using that main draw from
this component I can take the data out
of this and I can transform it filter it
whatever I want I can go with all that
so T file input Excel is a component
which helps me to read an excel file an
XLS or XLS format line by line so that
is a usage of this component so let's
look into other widely use component
this is one example for an input
component so the next one we are seeing
is T file so it is an output related
previous one was input Excel and this
one is output and D limited so as the
name suggests it's a output component
which is a delimited component so it is
capable of generating a delimited file
so it can be used to read whatever data
you are giving it to this component it
will create a delimited file in the
place where you provide like where do
you want to create this file by using T
file output delimited company I'll be
able to write the data into a delimited
file like where it has to be created and
which should be the delimiter for that
file if I provide those inputs to this
component it should be able to create a
file in that path with that delimiter so
this is one of the output component it
can be creating the output file with the
delimiter which I provide so let's move
on to the next widely used style
component so it is called T file list
component so T file list component
helped me to I trade through directory
sub directories and give me the list of
the files which are available the input
I will give for this component is path
of a directory and it will go through
all the files and subfolders inside that
directory and it would give me the
result and that also I can configure
whether it has to go to subfolders or
not so it retrieves the set of files and
folders based on the particular file Mak
suppose I want to only filter out the
error files and then archive it or
delete it then the T file list will help
me so dynamically I can get the file
names in a folder
so using this component it can even I
trade
sub-directory elements as well and the
next widely used component is T file
exits so wherever we are looking for a
file suppose you are waiting for some
fire or something like that so we will
have to check on whether that file is
existing or not we may be expecting one
file in one server path arriving today
but we are not sure whether it has
arrived or not so should be always
checking first whether that file is
available or not and then we'll have to
move reading that file or something like
that so this component helps me in
checking whether the file exists or not
so it helps in you know streamlining the
process by automating the tedious tasks
like checking your file X's so we can
share do a job for every 10 minutes and
it checks the file if it is available it
will continue otherwise it will end the
job so this component can be used as a
standalone component so it doesn't need
any you know excellent input to be
worked upon it just needs the path of
the file name of the file it has to
check whether it is existing or not
so next widely used component is e file
copy so whenever I'm done with
processing or something like that I will
have I need to move the set of files to
another folder or copy them so for
copying we have a component called T
file copy very simple thing as the name
suggests so this component helps in
copying the source file to the target
file like the directory wherever it has
to move it helps in streamlining the
process by automating the recurrent and
tedious copy tasks so this component can
also be used as standalone it needs only
the source directory on the destination
R it once the execution is completed all
the source directory files again
mass can be given so it can be moved to
the target directory these are the
widely used file components we'll be
seeing the examples in the demo so now
let's see what are the widely used
processing components let's see what is
the first processing components
so T map is very widely used component
in talent because it is multi-purpose
and very user-friendly to configure so
this is an advanced component which is
integrated to the talent studio as a
plugin so it helps in transforming and
routing data from single or multiple
sources it can be heterogeneous sources
to a single or multiple destination as
well again destination can also be
heterogeneous you can read from
excellent XML file you can put it to a
database and
normal delimited file so that's the
capability of it and it can do filtering
it can work on expressions we can create
temporary variables there are many
features which FEMA provides which I
will be demonstrating in the demo as
well it is used for simple
reorganisation of feeds and most complex
data transformation can happen in team
map so team up is one of the widely used
component for processing so next we have
T joint and T map also it can be useful
joining one or more heterogeneous
sources so but T join does the same job
as well so this component helps in
joining two tables doing an exact match
on the several columns so it is used for
joining alone but then it cannot filter
out or change the number of things
something like that which T map does so
it is a light component what I mean by
light component is the number of lines
of code for T 1 is less than the number
of code of lines for team up so T join
can be used only in the place where our
requirement is only to join and not to
do any of the filtering or other
expressions is not needed so it compels
the column from the main flow with
reference columns from the look of flow
and outputs in the main flow for
rejected data so it gives you two output
one with the joint and another with the
reject so I didn't show the data quality
of the data from any source again as the
reference data source so we can adjourn
whenever you're choosing it ratio is
your requirement so let's move on to the
next component which is T filter know
again the naming convention is like T
and what action does it perform so
whenever you think of filtering and
whenever you think of sorting can just
go and type in the functionality in the
palette and you will get the component
for acting talent so basically as the
name itself suggests it is used to
filter the rows so it helps in filtering
the source data for more than one
conditions and you can also put
conditions more than one column with and
and or conditions so it helps
empowerment raising the filters on the
source they turn incoming data the
scheme of this component is read-only
like whatever you are taking whenever
you are taking the source data same
schema will be copied along with one
error reason like whenever your filter
data is rejected we should know for what
reason it is rejected so maybe I am
giving five conditions I got fire rows
rejected all fire rows can be rejected
for different reasons
to row the reasons right so there'll be
one read-only scheme int filter which is
error message so let's more as I said
again the functionality disorder T sort
row as the name suggests it will sort
your input source data which is coming
into T sort in ascending or descending
order and it can sort your numbers it
can sort alphabets it can sort date for
you so this component is defined as an
intermediate step as it requires input
and output to handle the flow of the
data so it helps in creating the matrix
and classification table like whenever
you want to do a sorting the rank
operations you can use fruity sort so
the next component these are the widely
used processing components I'll show you
them how does it work and how we have to
configure them in the demo so now let's
see what are the widely used database
components and for database
there are many databases which are
supported in talent but for demo purpose
we have taken my secure so let's see
what are the different components which
are widely used so database components
these family provides talent components
which cover various needs like opening
the connections reading the table you
know committing performing rollback
error handling and capture how many
lines has been inserted how many lines
has been updated deleted so those stacks
as well so more than 40 a DBMS are
available to Amazon I should post-crisis
base whatever you name so my scale is
what we are taking as an example here to
the first component is the connection
component in database combines which is
widely used which can be reusable in the
job or whenever it is created in
Metairie where it can be reused across
the jobs so this components is nothing
but heal herbs in creating your
connection for the database for a
current transaction so it is used to
open the connection which you have
specified and it can be reused in the
job
so if I am using more than one input
database or one output database
components in my job in each component I
will have to define the connection thing
right so instead of that I can create
the connection component which will be
reused for all my input and output
database components so let's see the
next component so T MySQL input so as
the name suggests as we saw in the RT
file input delimited or T file input X
in so this component helps in reading
the database and extracting the fields
based on the query
I can query a table using this component
so it executes a DB query within a
strictly defined order which must be
corresponding to the schema which is
existing and then as I said whenever we
right-click on any of the company we
will get the main row or dietary so
using the main row I can read the data
of T MySQL input so in time is Cal input
there will be an configuration where I
can say you use the connection which was
created by T MySQL connection component
so it does not end up in creating
another connection for input alone so
similarly we have T MySQL row so this
component is to whatever scripts you
want to execute a dog screams or you
want to drop all the indexes before
loading a huge data and then once the
loading is converted you want to
recreate the rena build indexes so in
such cases you can use all these C MySQL
row component wherein it access an
actual DB structure on the database and
the nature of the query in the database
so it will just execute the query which
is available inside this component so I
will just have to tell which connection
again and what is the query that has to
be executed so it will execute that
query so the next component is T MySQL
output component so again similar
function only so whatever data is coming
in with the data it will be capable of
creating a table and loading the data
inside the table created and there are
multiple actions can be performed like
whether the incoming data should be
updated or inserted or deleted so all
those things can be managed by team is
kill output so connection input DB row
and output are the widely used
components in database family so now
let's see a demo on all these components
a simple demo I'll be showing how to use
this component or how to configure this
component so let's proceed to demo as
you're all aware and as we have been
telling in the previous videos so
downloading and starting talent is very
simple steps you can directly go to
talent calm and download the open source
talent data integration tool it will be
a zip file when it is downloaded once
you extract the zip file it is nothing
but it will have all the executables for
different operating systems like the
separate executables for Windows and
Linux so based on your operating system
you can just launch the executable of
talent open studio and you can start
working the only prerequisite needs is
the
adding of java should be installed and
it should be configured I can
environment variables should be set
that's the only prerequisite so you can
simply go to talent calm
so I can just click on download section
here
so you can just click on download free
tool for talent data integration and
then your tool will be downloaded as a
zip file so it would look something like
this so we'll have to extract this zip
file so I'm using Thailand Open Studio
for big data 6.4 version so Thailand
Open Studio for big data is a superset
so it has all the contents of talent
open studio for data integration along
with big data conference so if i
download talent oopall studio for big
data it is as good as downloading your
talent data integration for da as well
so you can download the talent big data
version as well whichever you want to
work with if you are not dealing with
big data it is better to install only
talent data integration but for the demo
purpose I will be using talent data
integration for big data which is having
all the features of talent data
integration as well so I will just go
inside the extracted folder and as I
said all the executables will be
available since I am using Linux I'll go
with Linux executable and double click
on it
so once the talent is launched you'll
see all the windows open here most of
them will be inactive once you create
the job under repository under job
designs all the inactivated windows will
get activated so let's create a new job
see job one component demo so per person
description we can fill as per your
requirement so once you have created the
job so it will open a designer window
for you along with activating all other
windows so now to show you the demo on
the components which you have seen in
the PPT so let's take one of the example
like I have an employee details file
with me so I'll have to read that file
that is the first example which he saw
for reading an excel file in the input
components family so to read that file
the component which we had learnt is D
file input Excel so either I can
drag-and-drop the component to my
designer window and I can configure them
by double clicking on it and in the
component window I can give what is the
file name and the most important thing
is the scheme of it what is the column
names which I have to be right from this
file so this has to be either created
manually or we can create metadata so
let's go with the metadata approach
which can be reused so under repository
under metadata which file are we going
to create the metadata for its file axle
so let's just say create file Excel and
I'll say metadata for emp1 so I have
another look of file as well so I'm
naming this as emp1 and then I would
provide the part of that file so EMP
details 1x ill sx this is the file so
I'll also show you how does this file
look like so once I give it to the file
path and then it has already recognized
this as xlsx and this is the data which
I have in the file employee ID employee
first name employee last name and
employee deed of showing so this sheet I
am going to read so it will
automatically read the file and prepare
the structure form that is a usefulness
of the metadata so as you saw there in
the previous window even the column name
has been treated as data so I can just
say either header one row
or there is a customized option here
saying set heading rules column me so
I'll just click it so automatically had
that one will get populated here so then
I can refresh the preview so the first
line will be treated as header then the
data follows and just to show you how to
review and make changes we have added
one empty column next to the proper data
talent will also read it like how we are
seeing it as a read ID first name last
name date of journey and it also has
read the empty column so in the next
step whatever changes we want so it is
just like providing review for us if you
want to change any data type any length
or if you want to delete a column or
something like that you can do it in the
review step and finally create the
metadata so my ID is being populated as
integer and all others as string that's
fine for my demo but I don't need this
empty column so I'll remove this so my
meta data is ready now so now either I
can give reference of that metadata here
by choosing repository and telling which
metadata to refer that could be one step
one way of doing it it will point to the
metadata which we are created another
way is I can directly drag and drop the
metadata into my designer window it will
come up with all the repopulated data
including the file name so whenever you
want to use the same structure on
different file names you can change only
the file name so once you drag and drop
it will give you a list of components
where you can use this metadata like it
is only the structure irritating and the
file properties right so it can be used
in the input as well also output so
we'll select input component as per our
requirement so my requirement at the
first step is to read the file so now
this component has all repopulated data
it has the file path as well and it also
has metadata reference so if you can see
the schema the schema will be
pre-populated so let's read this data I
can just put it to console window all
the data by choosing a component called
T log row by just clicking on the
designer window and typing out the
component name also will allow you to
get the component inside the designer
window so now I'll right click on the T
file input Excel component choose row
option and main to select the data
and I'll give it to the output component
called T log row so this will
automatically copy the schemer however
it is coming from the input just output
the data in table format so I'm choosing
the data to be printed in table format
here and then I'll just run this job so
this simple job will be able to open the
file which we are given read the data
row by row select the first row header
and then populate that data into console
by using a T log row component will be
able to see the output in the console
here
so we'll be always getting the real-time
statistics as well over here how many
rows has been passed now we can see all
the data in that file has been populated
in console here
so this is how you can use an input
component to open the file and read the
data line by line so this was our first
input component which we had learnt in
the next file component we saw was T
file output delimited so as we have read
the data from Excel and we have just
displayed the data in the console we can
now pass on this data to delimited file
so I can tell T file output delimited so
I can just take the main row from the T
log as well or I can take it from the
previous component also if you want to
remove this log we don't want to print
it in the console so now I have to
choose where I have to create this file
so let me choose a Drakkar demo put and
we create a new file sync EMP data
delimited dot txt so will generate a
text file with five delimiter raster
delimited and /ns third row separator
and we can just copy the schema from the
input component no need to again create
a metadata for it so it will
automatically take the structure which
is coming from this link so with this
simple settings we'll be able to pass on
the data from an excel file to the
delimited file so now let's run this
show
the job has been executed so let us see
whether this file has been generated or
not so in the demo output folder data
delimit dot txt so this one will open so
from Excel will be able to load the data
to a simple delimited file so now we can
see all the data is available over here
in the file which we are created with
pipe delimiter so with the simple steps
we were able to read a excel file and
transfer the same data into a delimited
file the next component we saw in file
family was our T file list component so
T file list component as we know from
the PPT what we gone through it will
help us to read through directories and
subdirectories and give us the file
information over there with also the
mask option so let us create another job
use Kies for the file list so let me
name it as J - component demo I'll
provide the same purpose and description
suppose I had a requirement to I have
similar structure D by D data or month
by month data as a separate files in a
directory I'll have to read through all
the files and give the data to some
processing or put them into one single
file basically going through all the
files in the directory and merging them
into a single file so if that is the
requirement if I list will help me out
in putting down the solution for it so
let's see how does this work let us
create three files and we'll open them
so suppose in demo input I have three
files called day one day two and day
three which has employees details which
I have got on date one the same employ
data which we use it in previous example
and D - I have another fire employees
and date three also I have few employees
so basically I'll have to come to the
demo input directory read through all
date day level files and then merge it
to single file so let's provide solution
furnace your skills for this I will take
T file list component and then
I'll choose directory which is demo
input
I'll see okay and in the mask I would
give it us D like all the file names
which contain a day in it I'll have to
read it so let me put regular
expressions for it that is stalled a
star dot text so this will read all my
day level files and then I need a teef
file input delimited to read those
delimited files so I already have the
metadata that is structure which are
created in Excel that can be reused here
as well so first I will give my t file
list or put two t file input delimited
so it will eye trait through all the
folders and get me those 3d level facts
but every time it I traits my file name
changes so d1 will be in first iteration
day two and day three in the last so it
has to be dynamic so I cannot hard code
the path I'll have to use the standard
variables in outline section of T file
list that will be T file name with path
will have many other standard variables
like only file name and the extension of
that file so now I'll remove the file
name in the T for input delimited
configuration and I'll use this standard
variables which will give me the values
dynamically so T file list one current
file path in that current iteration
which file path will be available that
file path will be provided and what is
that file I am trying to read it's a
delimited file and it is pipe delimited
as we have created it in the previous
example and then now I need the schema
so only schema I can take it from the
employee schema which are created for an
excel same schema I will be able to copy
here as well but not the file properties
only the structure I can copy so even
the structure which I had created for an
excel I can reuse it for a delimited
file so now these two steps will enable
me to read through the directory get the
file names dynamically read all those
three files from here but then I will
need T file output T limited or it can
be anything else as well like you can
try with Excel or XML whatever you want
and
now what I'll do I'll take the data in
each iteration this data should come to
this file which I'm going to merge and
this one we can give it to output folder
demo output and name it as employing
merge
and even for that I can tell pipe
delimited and schemer will be copied but
the only setting way I have to do is
since I'm merging it every time it will
go to the same file I'll have to choose
this up and header and if I want the
header to be included I can use include
header but usually when I'm appending it
I'll go without header so let me now run
this job and check whether the Moi's
data is available we had five employees
each in each of the file and he should
run for three iterations that is one
main thing because of the file mask the
directory also had other files it should
not consider those files it should only
run three times so as you observed three
times and in each execution fire rose
has been provided to this file so let me
go to output folder and check if I have
all 15 employees merged a time EMP
merged a level txt so now I have all my
15 employee details which has been
merged from three different files so by
doing these simple steps we were able to
only filter out the files which we need
and then process them read them and then
put it into a single file so this is how
you can make use of the file list
component in the file processing family
now going forward in this example the
next component which we saw in the file
family is T file exists component so
once you have generated the most file
say suppose there were no data for today
or none of the day files were available
then obviously this file would not be
generated or it will be of zero recalls
or something like that
so every time when it is not generated
then we will have to check whether that
file is available or not and then only
proceed for your further transformations
the first of which you do is all-day
level files you are merging into one
file and on that one file you are going
to apply transformation rules or
something like that
then let's do a use case for that to
check whether that file is available or
not and then try out some messages so
for that let me deactivate this section
now the very good option in Thailand is
a part of the job you cancel it and tell
deactivate it so that they don't execute
and you can easily debug where the
problem is
so now we have already generated the
main file over here which is EMP merged
a level so now my use case is to check
whether this file is available or not
and then continue working on it
suppose assuming that file will be
always available if I had return key
file input
delimited to read this file so I'll copy
the file path over here and then I need
structure for it so since there is no
connection structure would not be
available the one more method is to copy
the structure like I can say it it's
schema for this where schema is already
available I can just select all of them
and say copy and I can come to my input
delimited and address schemer the paste
option will be enabled I can just paste
it so I got the schema ready for my
input file as well
so this file which I'm going to read is
pipe delimited and I will simply with
the contents of it into log as my
previous example which we did in the
beginning so since the file is existing
this job would run without any problem
so let's run this show so remember only
this activated part of this job is
running
read the whole the 15 drawers and I have
the output over here right but this will
not be the case every time when I am
providing solution for this yes yes
because someday maybe in the weekend all
the files will not be available
something like that so in the same case
if I go and rename the file here say for
example underscore backup and nemetes so
that that file will not be available in
the same path which we are given in the
job in that case when we run this job
this food result in an error because
that file is not available so it said
it's zero rows because I have not you
can see here so it is not available
there are few components which will only
put on this error and not kill the job
suppose it is design thing which I have
to maintain if there is no data in this
file my job should not continue so we
have options for it so I can see die on
error if there is any error you can die
so since that file is not available I
don't want to proceed further because
that is a main file which I have to read
and that is the source for all my
upcoming components so this will put
down an error for you because that file
is not available so this should not be
the case even then if the file is not
available the job should successfully
execute and it should give out some
message for me so for that case we can
use T file exists so before even I start
this execution of it I should control it
by checking whether that file is not
there so that the job does not result in
error I can take the file name which I
want to check and give it to this T file
exists component as we know it will just
check the file availability if it is
available it would give me true if it is
not it would give me false so only in
the true condition I should execute the
input component well take a run if and I
will give it to it because I'm
conditionally controlling the workflow
so I will also take T message box which
is a component which will pop up the
message based on the condition which we
provide so I'll take another if
condition and I will give it to T
message box and
this message box will tell me that file
not for this should be in the negative
case and now to define the positive and
negative case click on this if condition
and then take the standard variable off
t file exists so in t file exists there
will be a 1 standard variable called
exist so I am dragging and dropping it
if this is equal to equal to true then
the file is existing and I will take
this path and if it is not existing then
this standard variable will be equal to
equal to false so in that case I'll tell
file not 4 so by using this component I
am able to not put down an error so
let's run this job and see so in the
case now we have a case where fire is
not existing so it should throw open
message back for us
so it says file not fall so without any
problem in the job successful job
execution but we got to know the file is
not available so let's execute the
positive scenario like I'll change the
file back to normal finally by removing
the backup in this case also our job
should execute file by reading the file
and putting it to the lock and not
coming into the file not phone message
so now it has taken this path and we
have the output in the console so this
is the usage of D file exists component
so the next component which we saw was D
file copy so once your processing is
complete you can move this file or copy
this file to a different directory say
suppose after this step your raw
execution is completed then I want to
move this file which was there in output
to processed folder or something like
that ok so I can go back and create a
process folder and limit as demo draw
cyst
something like that and I want after the
successful execution of this I want the
file to be copied to the process folder
so once it has put down the all the
transformation is complete I can just
tell on component ok copy the file and
which file I have to copy the same file
which we heard generator that is de
level but then I will have to change the
name so I will give the directory as
demo processed and then I'll tell dreamy
and I'll give it us D level processed
something like that dot txt
so now after all my transformation rules
it should copy that into a different
folder called process so we can come to
know by reading that directory which
all-day level or month level is
completed or something like that so now
let's go and it has executed
successfully so if I go to demo
processed I have my de level processed
file with the same data the file name
has been changed so you can copy the
file
and you can change their names all the
stuff you can do using the D file copy
component so as simple as this so these
were the components which you saw in
vial family
so with these use cases you should be
able to visualize how easy or how simple
it is to put on and use all your widely
used five components family so nest
family which we are looking into is the
processing component right so I have
used one EMP file in demo one where we
have read the EMP details so in the
similar way we have another file called
our T file second input which has the
country and state information so I'll
show you that file so EMP details too so
everything is same so structure is
different for this so it has my EMP
employee ID and state and country
details for it each of our IDs so this
is the ID city and state column right to
read this file again quickly I will need
to create the metadata because the
structure is different so I can tell and
the metadata again create file axel so I
would say MP underscore two
you
so it has read the empty columns as well
so I'll go and delete the empty columns
in the review strip
I'll just remove these extra columns
and Elsa finish
the look of fine as well which I can get
the details of state and country of my
employees right so I'll just drag and
drop the in protection so now we'll have
to join these two data so first I would
like to demonstrate the thief join
components so let me remove this T log
row and say T join here now and connect
the mean which is my employee details
and then employee state and country
details I would gain mean I will take it
and put it to join but it will be
converted us lookup row for this
component right because it is look up
for it the second one which I join the
first one whichever you join will become
the main and the second will become the
lookup say T joint will have only no
options to join and take the columns
from the lookup right so I can just
still include lookup columns in output
and then in edit schema I'll have to
choose two files over here because I am
trying to take the column from the
different file as well so I will tell
all the columns from the file 1 and then
in the file - I would need city and
state ID is my key so I don't want it to
come again so I will have now date of
joining plus city and state as my output
schema and this output schema from where
it has to take the column from so ID
like this input column city it should
take it from lookup city and you now put
again state should come in row two dot
state the row two is nothing but this
lookup identifier so mapping has been
completed and what is the match so ID
coming from main row and ID coming from
row two is the key so that's all I have
to configure and I'll take the output
and give it to this the old structure
was different so it will show that
schema is different so I'll just come in
here tell added schema since the input
schema is different that is it is having
two column extra it is showing that
warning I can either take these two and
move it here or just say sync columns
and this warning will disappear
facing columns and it has taken care now
change this filename to employee data
master with all the data we are looking
up from the lookup and I will just run
this draw it will generate me the file
which has employed details plus the
details of their country and state from
the lookup file
so the execution is successful so let's
see in the output folder whether I have
the master file EMP data master so if I
open this file I have all employees
state and country detail as when
operated in my master so this is how
very simple steps you can use the T
joint component and also if there are
any rejects in this joining operation I
can even capture the rejects by having
simple option over here so I have inner
join with reject output so I can just
click on this and I can choose a file or
even the log to capture the rejected
records so this will capture the
rejected records and I'll tell them to
put them in the table format and now
we'll go back and create one data so
that it will not have the inner join so
let me add an neuro so she'll not match
and I'm saving this and now I run this
job again
they happen because it is already having
the data so now I'll run the job and
with this this case we are expecting one
inner join to be rejected
so it has not rejected anything because
we have added the inner join rejecting
the lookup which is not the use case
we'll have to add it to the source
so let's go and add it to the source why
I'm showing this use case whenever I
added in the lookup I was not able to
capture it because in team-up we'll have
those options to capture them which
we'll be seeing in next example so I'll
just copy this again do the same
operation which I did that and now again
I'll run the choke
so I had zero rows here in the rigid
before so now let's see what would be
the output so now we can see one row has
been rejected and it should be the row
which we entered in the master that is
double or double 1 so it has rejected
because it doesn't have any lookup value
so it is null for city and state so this
is the maximum capability of t-joint so
similar use case we will do it for Team
app
so I'll just remove T join and then I'll
introduce team up here so T map is a
heavy component what I mean by heavy
component is the number of lines of code
which will be added to my job when I
choose T map is more compared to when I
add T joint right so it has to go on use
cases if you are using this component
only for the joining purpose without
filtering without altering the number of
columns or something like that then you
can go to T joint and make your job more
optimized but if you have some filtering
criteria as expressions to be included
and the business rules to be implemented
at column level then you will have to
come to tema so similar conditions so
correcting main to tema and connecting a
lookup to team up
and then have to generate the output
over
and to show the capability of tema I'll
be adding one intermediate variable
inside the team app so now I have the
source and look up so with dragging and
dropping the key column I am able to
join these two and after joining I can
drag and drop them to the output saying
again master and then take all these
four columns from the source right away
drag and drop it to the target and then
take city and state from lookup drag and
drop it to the target so how my master
structure ready but then I want to
introduce one more column which I will
be deriving the value for it inside the
team app itself so I'll come here and
add a variable and then I'll see ma lady
and what I'll do I'll take the first
name and last name to this variable and
then I'll create or generate the
emulator it is just for Emma purpose
from just taking my employee first name
and last name I'm not doing any
validations over here so firstly plus
that is first name dot last name
appended to it at any record calm so I
generate an email for the employee
so this email-id I want it here so I'll
come here the Creator same email ad for
this and then I will drag and drop this
email ID column to melody so it will be
vial dot email ID which will be coming
here so I was able to you know change
the number of fields and I also deriving
the value of it inside the team app
itself so this is a capability of team
app so now again about the team of we
were telling it will be available to you
know filter the data all the stuff so I
can also filter it by adding the
expression editor so I have to click on
this expression editor and I can see if
I want to consider only employees which
are there in particular City so I'll
drag and drop the city from my look up
and then I'll have to check the data so
which city I'll have to consider
maybe I'll consider city called Columbus
so I'll copy this value come here and
see only if it's equal to equal to
Columbus then accept only those rows or
we can even put dot equal to in Java
program we can use Row 2 dot city dot
equals
this valid if it is true
only then those employees when we
captured it so this is filtering after
the join so join will not have any
effect on it
so once the join data is coming here it
is getting frittered right and then I
can create the same thing which we did
it in key map like is create one more
output telling rejects
so I can minimize this in the rejects I
will only like to capture which I D got
rejected so I can just take drag and
drop the ID which got rejected and then
in the settings I would just tell catch
in a joint trajectory that's true so
this completes my settings for Team app
so I'll just give master to this again
one column is extra so it would give me
the error of different schema so you
already know how to resolve it just tell
sync columns and then I'll give rejects
to T log row then again T log who
previously had three columns now I am
only taking ID so here also and sync
columns and now let us run this joke
so now we can see the same output of
previous steam of whatever used
but then same one row has been rejected
which was our expected output but in the
data only idea have captured so with ID
I'll get to know what is that record but
in the output delimited I will have my
email id generated so EMP data master is
my file at the end I will have the
appended data so let's go and check
whether I have the email id generated
so I can see we have generated email ID
for all the employees with first name
and lastly so this is the capability of
the team app so you can add the
different columns over here you can
filter out the data we have filtered it
only those data which are needed for our
Columbus country so we can check that as
well so you can see all the employees
who are having email ID are from
Columbus only those data we have
generated the email ID and others should
not happen so it starts from you
so before other countries not having to
email it so this is the capability of
Team app right so similarly after this
data has been generated we can filter
out the data for only one country and we
can sort it out in alphabetical order or
something like that so data coming out
from this output component I can just
give it to T sort row component but
before sorting about filter it for
certain condition so I'll take T filter
row simple it can give multiple
filtering options over there
so I can just say same schema will be
copied for filter I can give the date of
joining or I can give the ID less than
or something like that so that I get a
little bit of Records
or I can give the state so state as ma
go Columbus data and inside Columbus
only Emmy we are going to consider so I
can tell state equal to
within quotes have to give this value em
eek so it will filter out those data
once that is filtered I can sort that
into alphabetical order T sort row
so in t soart - same schema will be
copied so I'll see what is the short
column I need maybe the first name and
it is a alphabetical and I will want it
in the ascending order so this output
let us put it a delimited further I'll
just copy paste the same component and
I'll use it here by changing the file
name
I will just say
the master filtered and sorted so I can
done this job discovers the scenario for
filtering and sorting both of them
so now less
output so it is the sorted output
Franklin first and Thomas next and this
is how we can use the sorting and filter
components so now we have the Fresnel
data we have the master data so it is
according to our needs so to introduce
you to database components let's first
create metadata for database components
so under metadata DB connections I would
just say create connection
and this would be for EMP database so
metadata MP and database which are
trying to use here is MySQL
so I'll select MySQL and login let me
give it as a root and since it is
residing in my local I don't have to
give password server is localhost and
then the database name before I provide
the database name let me go and create a
new database for our developer purpose
I'll say MySQL - user root create
database C underscore dam and then use
database C underscore demo
so database I can give it us see demo
here and just check so connection is
successful so my metadata for DB
connection is ready so in the same job
I'll drag and drop my metadata
and this will ask for again which are
components I can use them in two
so I'll just say for now I need only T
MySQL connection so let me continue is
Cal connection then it is available
so initially we'll have the connection
done once the connection is successful
then only we'll start this process so
let me remove sorting now since we have
finished that use kiss so we'll end at
the master data creation and once this
master data is created as a next step I
want to load it to my SQL table so for
that tea my SQL input so this will be a
component I'll just put it down here so
once this whole sub job is completed so
that is all on some job okay
I'll give it to this component and this
component settings
use an existing collection I'll sneak
all this to map to this connection as I
have explained in the PPT and we will
chill which connection to use and then
we need schema for this like what is the
schema for the database so if it is
input we'll have to give the schema so
what we'll do before even coming to
MySQL input we will load this data
however it is there in the master to
team MySQL output to let me for now
deactivate this component whatever data
is coming in in the master or either I
can directly take it from dimmer which
is master
and give it to my MySQL table and here
I'll tell use existing connection which
I've already created which is EMP and
I'll give a table name called EMP master
and the action on table is like if table
does not exist create it
an insert is the command and here only
thing difference you'll see is we will
have the DB type as well so the same
schema and corresponding DB types will
be populated so with the simple steps I
will be able to load my data to my
database as well so let's run this job
you
so now the filter data has been
populated to this table so now if I go
and check my database whether we'll have
data so that is the first question so
let's take whether the table is created
or not
so here my master table is created so
now I'll turn select star from EMP
master
so there is no data because we have not
committed the data right so I will use
steam MySQL commit and I'll commit this
data right
so all component okay of this commit the
connection which is you're pointing to
and don't close the connection and also
I'll remove the filter over here so that
I get all the data not only Columbus for
this use case so I will remove this
condition
and now elegant read on this job here
table is already created so to not
create the table it will just check
whether it is existing or not and then
it will try to load all the data and
then commit
and once all the data is loaded we will
read it from the database by providing
filter only for Columbus or that state
and one more use case will be completed
further team is Q input so let's see
let's just draw execute successfully so
it has executed successfully so let's go
like in check
so now you can see the data available in
the table so now quickly create a use
case for input so I'll activate this
component why I had not given the
metadata for it is there were no table
available in database now we have
created it by our job itself so what I
have to do to get the structure not to
come to TMP schema which is the database
schema and I have to tell retrieve
schema so it will knit a scheme off the
tables which we provide so since there
is only one table I will just go ahead
so it has so many tables in the schema
and I can select this table which I want
to select the schema so I'll say finish
so in my input component now I can
provide what is the table and what is
the schema so I can just tell schema
from repository
schema for my EMP master and I can also
tell you guess query so it will query
create the query for me and I can't
filter out no by adding filter directly
where EMP underscore master dot
country city equal to
only that data I'll retrieve let's see
whether the syntactically correct and it
executes
I'll just logged data over here
you can actually deactivate this section
because already data is populated and I
can execute only this part so let's run
this show and see whether my finished up
condition works directly emitted in the
query
so now we can see differential has been
applied and only those employees which
are from Columbus has been populated
over here so this is how you can simply
use the T MySQL input and out of large
data you can fill it out and get those
data without any problem so this is all
about your database components so hope
you liked this video and to get deep
understanding of each of the components
step by step please join it Erica
telling Big Data training and take a
step up in your career how every day
when I got I hope you have enjoyed
listening to this video please be kind
enough to like it and you can comment
any of your doubts and queries and we
will reply them at the earliest do look
out for more videos in our playlist and
subscribe to any rekha channel to learn
more happy learning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>