<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning DataScience interview questions What is K-Fold Cross validation | Coder Coacher - Coaching Coders</title><meta content="Machine Learning DataScience interview questions What is K-Fold Cross validation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/MyStudy/">MyStudy</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning DataScience interview questions What is K-Fold Cross validation</b></h2><h5 class="post__date">2017-04-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1mgmwXDqe5o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello friends let's see one more
important question what is k-fold
cross-validation technic so what is this
cross-validation technique there is a
lot of misconception and a confusion
associated with this cross-validation
technique so let me clear with this
model related stuff how this model is
related to cross-validation technique
first of all this is not a model
building technique not model building
technique so you are not using this
cross validation technique for the model
welding building but this mater cross
validation k-fold cross-validation is
used for a model evolution model
checking
model checking so let's see how this
technique is working and how it is
helpful for checking whether particular
model is good particular model is better
than some other model or particular
model is performing worse in some
salario and performing good on in some
scenario so let's be clear that this is
useful for the model evolution model
checking not for model building so I'll
make it as a red and I'll make this part
as a green okay so this is for the model
evaluation now let's see how it is
helpful for the model evolution and
model checking technique let's say we
have a thousand data point and we have a
we need to classify those data point
into two different class so it's a
classification problem now for the
purpose of classification we have a lot
of different machine learning algorithm
like a logistic regression we can use
let's see logistic regression we can use
we can use a decision tree we can use
even SVM we can use a neural network
I'll just name it as a NN okay
so we can use number of technical but
how you can decide that whether
particular technique or particular
machine learning algorithm is better or
model building via this technique of
logistic regression or a decision tree
or even SVM or n and which one is better
how we can evaluate it that's where this
cross-validation tactic comes into
picture so what happens that we have a
thousand data point in a
cross-validation torille as a training
point thousand training point
let's keep aside the all testing point
and we do not bother about the testing
point because the first rule in model
building or even any kind of machine
learning algorithm building never use
testing data as a training ring so we
are not going to bother about
tasting data at all we are just going to
work on a training data and on that
training data only based on evolution
criteria we will choose whether logistic
regression is better working on this
thousand data point or a decision tree
or even SVM or even a neural network at
working so let's start with a
cross-validation technique will apply on
a thousand data point so what happens
that we will divide this thousand data
point into my different chunk of 200
points let's say 200 point here 200
point here 200 point here 200 point here
and 200 point here five different fold
so we are dividing this thousand point
into five different folds so in this
case our K is equal to five that's where
this K is so we are folding this input
data point into five different for and
we will iterate this training process
five times so first training process we
will take this first four set of data
I'll make it as one color like green
so total 800 point as a training data
and remaining 200 point in a training
data we will make we will use it for the
testing purpose I'll make it as a red
now in a second iteration we will make
this fold as a testing data and
remaining as a training in a third
iteration we will make this one as a
training data in a fourth this one and
in a flip this one remaining all we will
use as a train training data for our
model evolution purpose I will make
everything green and then I will explain
you how to proceed ahead
okay so we have divided the whole
training data into five different folds
in a first iteration we have taken first
800 points as a training data and
remaining 200 points we will use for the
testing purpose it is nothing but the
validation of your model in a second
iteration you will use this first 600
points and last 200 points as a training
data the middle this 200 point as a
tasting data you believe same way you
will go for all those training data five
different times and in all different
times you are going to use all those
data as a training data keep aside the
200 data as a onefold training data
aside for the testing purpose now this
task we will do for all those four
different algorithms now let's take
logistically aggression now we will use
the logistic regression to evaluate this
model so how we will go for the logistic
regression what we will do we will apply
training data this 5 times so in the
first time we will get some error like
even so logistic regression in a first
iteration we will apply and this part
will use for the testing purpose and we
will get some training error and some
testing error based on that we will
decide some even then we will get some
p2 then III then eat for then if I so
for five different fold for logic stick
regression we will get some five
different error every time we will get
some different error and we will make
average of all those error so we will
take an average of all those thing even
plus C 2 plus C 3 plus C 4 plus C 5
divided by PI and will take an average
for this so for logistic regression we
will get some average error based on
this cross-validation our a technique
the same process we will apply for the
disease and
and we will get some album by different
errors because in a first poll you will
apply for first 800 sample as a training
data at remaining 200 as a tasting data
and you apply for the decision tree and
you will get even in a second iteration
this much train data you will use as a
testing remaining data you'll as a uses
a training data and you will get e -
same way you will get 5 different error
and you will take an average for the
decision tree same you will do for the
support vector machine also and same you
will do for the neural network also now
for 4 different model you will get 4
different average error now for those
model which has an average error minimum
then you can conclude that this isn't
tree has a minimum error average error
so decision tree is working better on
those training data and it will
hopefully work better on a testing data
also if SVM has a less training error or
less average training error out of this
even e 2 e 3 E 4 E 5 you can conclude
that it's good to build a model with SPM
so this is the model checking process
and you can evaluate that for those
input training data thousand data point
which model to choose so now we have
choose all those model model let's say
we have choose the decision tree model
decision tree model based on the
training data so till now we have just
selected that which algorithm technique
or which model technique building we are
going to use so till now we haven't been
any kind of model and that is nothing
but the cross-validation we are doing
across all different machine learning
algorithm with this k-fold different or
technique and after the key fall
different technique for all of those
algorithms we will take the average
error and the minimum error out of that
through which algorithm we will get that
algorithm we are
going to select as our model building
process now in case of once you decide
about them which algorithm you are going
to use on those thousand training data
you will forcefully apply all those
thousand training data on the decision
tree whichever is the algorithm which
gives the minimum error and that is
nothing but your final building so
thousand data as a training apply on
decision tree algorithm so that is
nothing but the final model you will get
so that is nothing but the final model
so that's it for this lecture friends
and that is all about the k-fold
cross-validation matter before start
building about the model its some model
evolution model checking process not the
model building process and a first very
thumb rule we have used for the model
checking process that we have never used
this testing data as a training based on
the training data only we have splitted
this training data into two different
area training data plus validation data
and we have come up with the algorithm
which gives the minimum error based on
the crisscross valuation technique so if
you haven't understood anything please
write into comment I will be happy to
answer your question that's it for this
lecture friends if you haven't
subscribed my channel please please
please to subscribe and support this
channel at last thank you guys for the
watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>