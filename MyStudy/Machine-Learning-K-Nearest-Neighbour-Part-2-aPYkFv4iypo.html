<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning K Nearest Neighbour  Part 2 | Coder Coacher - Coaching Coders</title><meta content="Machine Learning K Nearest Neighbour  Part 2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/MyStudy/">MyStudy</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning K Nearest Neighbour  Part 2</b></h2><h5 class="post__date">2016-08-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/aPYkFv4iypo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi friends welcome to the video lecture
series on machine learning
so in the last lecture we have define
about the problem of K nearest neighbor
in this tutorial we are going to see
about how to implement the very near
implementation of this K nearest
neighbor algorithm inside the Python so
for that we are going to use about the
random data so for the random data I
have already done some necessary inputs
and we are going to use about three
different Python library like pandas
this is one of the very famous data
science and data analysis related
library numpy for the numerical
computation in a Python and plot
visualization we are going to use this
matplotlib library as a PLT and this is
for in line display of my plot length so
it will display all graph inside this
jupiter not book only and I have already
created a simple data set so let us try
to put this data set inside the data
frame object of the find us so that we
can is actually visualize the individual
data even the class of that data then we
will go for the actual distance
computation and nearest neighbor
computation so let's define data frame
objects so
in data frame we'll apply this data
which has been created with the help of
this array function of numpy and we are
addressing this with the help of this NP
only then will assign it to DM reference
now if this data each having either very
default column name has been given so
let's put this column name then I will
explain you what that column means in
our case so I will put in X Y and
category
and let's can just display it okay so
this is our actual data bite
okay this is a typo here okay
okay so you can see that there are total
six instances are available each
instance has been address with zero to
six numbers 6 e says excluded and each
point has a one x-coordinate and a
y-coordinate and each point belongs to
some category so in this case we I have
defined there are two categories there
is a see one category Ana see two
category so there are two possible
classes are there in output so cat is
nothing but a category which is lying
into two different class c1 and a c2 an
individual data points at the two
dimensional data space so this is a
tabular way of visualizing our data
there are total six records each record
has a two two dimension and individual
record belongs to one category either in
a c1 or c2 now let's try to visualize
with the help of Python matplotlib
plotting functionality so we you can
actually visualize this data and we'll
put this query point also query point is
nothing but know what is Theta side so
in case of our K nearest neighbor our
task is to find which are the points out
of the six points are nearest to this
query point so let's try to plot all
this point inside the multi-dimensional
or even two-dimensional space so we are
going to use this PLT I
so for each and every point I'll just
look through
so we'll use this PLT functionality and
we use the scatter plot of this PLT
functional reading so for one category I
am going to display with one color and
another category I am going to display
with another color so let's just
so what it will do it will try to find
first of all the category if the
category is c1 you plot it this way PLT
dot scatter and we will supply x and y
coordinate
will supply size is equal to 150 and
let's say color is equal to red else
same thing will display but color let's
change it to some blue okay so this is
the all data point we have iterate
through the full individual rows of this
data frame object and we have supplied
to the scatter plot if you don't
understand this scatter flood I have
already created one lecture on a mat
plot label library having a scatter plot
functionality explaining it so this is
all about the individual record now
let's display this query point also
so we'll supply query very zero and
query one
we'll make little bigger query points
you can visualize and let's change color
to the yellow so you need to supply the
swine okay so this is how we have
iterated now let's just put it in grid
so I will come to know about actually
the data point in a two dimensional
space okay let's run it okay so it has
visualized this seven point for us six
points is one is the red class category
so this line will part or red class
category which is having a category C 1
so these three points in a class C one
these three points in a Class C 2 and
this red part which we have displayed
here in a query point which is nothing
but query this data set so if you see
this x and y coordinate of zc 1 minus 1
minus 1 minus 2 minus 1 so this even
part it has displayed here minus 1 minus
1 minus 2 minus 1 n minus 3 minus 2 and
our task is is to find a nearest
neighbor with respect to this yellow
point yellow point is nothing but our
tastes data set point
so this is how we have defined a problem
now let's try to find the distance of
this individual data instance of inner
training data set this is nothing but
our training data set with respect to
all our query point and we are going to
use simple Euclidean distance so we are
going to use the square root and square
functionality so let's just import this
mat function and we'll be find at
distances in one error MTR M now let's
just look through each and every
what point in a test dataset and let's
compute the distance between query point
and each and every day is there as it
so whatever the distance will calculate
will upend inside this dysfunction and
then we'll put sorting on the top of it
so we'll come to know about it what are
the nearest point with respect to this
query point yellow point to any point is
the yellow one okay so this dot opinion
now our task is to find the square root
so we'll use this math dot square root
and the first point is X point minus
query zero square so X point is like
this is for the squaring of the
difference between query point and
individual data point x-coordinate now
all data is in an object format so in
our case we need to supply this float on
the top of it so it will convert
everything inside the float will iterate
to individual rows and for individual
rows we will just extract this X element
into queries zero okay this is all looks
like a correct
so this part is finishing here
same we will fly on a query one point
which is nothing but the y-coordinate of
this dataset we why okay so it will
append all distance okay there is some
bracket mismatch I hope okay there is no
issue here
ok-hee Rizzoli we need to supply to one
more bracket I think let's just run it
over some syntax error for calculating
this distance
so this part is about to finish here so
this is over
this will be nice here
okay some issue with the brackets here
so des dot obtained not
hopefully should work no actually
Mack
lord
okay this is the culprit I think okay we
have got it
there is some bracket mismatching was
there now whatever this distance has
been calculated with respect to all
those point in our training data set
let's assign it to the one column of
this DF so we'll create on one more
column of this data frame object and
we'll paste those distance and let's
just print it okay so it has calculated
all those distance so with respect to
this query point yellow you can see that
all this c1 distance are much more near
one is 0.7 and there were is also 0.7 so
these two points are very much near so
that's why I think it is 0.7 because
minus 2 minus 1 so minus 2 minus 1 is
this point and minus 3 minus 2 so this
is this point ok these two points are 0
points and another one is the 1.53 eight
remaining all points which are the blue
point is which is lying in Class C 2 so
it lies inside the very far away from
this VL notice data say point so which
is having all bigger distance now let's
just sort this value so in the data
frame we have a one-shot value function
then we will apply on top of this dis
column ok so it has sorted for us so
with respect to query point we have got
these two points looks like a very near
so whatever the number of point we want
to take like a 1 nearest neighbor or two
nearest neighbor or a K nearest neighbor
or 3 TN nearest neighbor we can take all
those points from this top rows
basically so we have almost got this
first and second one looks like a very
nearest point with respect to the taste
data set so that's it for this lecture
friends I hope you enjoy listening this
video
in the next lecture we are going to see
the same implementation with the help of
scikit-learn library when we will
compare those result then we'll go for
even more optimized algorithm because in
this case this algorithm is very new
approach and this comp computational
complexity is very high while iterating
for individual each instances of inner
training data set thank you guys for the
watching I hope you enjoy listening with
this video please do like comment and
subscribe it</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>