<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning  K Nearest Neighbour Distance Measure in Scikit Learn   Part 8 | Coder Coacher - Coaching Coders</title><meta content="Machine Learning  K Nearest Neighbour Distance Measure in Scikit Learn   Part 8 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/MyStudy/">MyStudy</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning  K Nearest Neighbour Distance Measure in Scikit Learn   Part 8</b></h2><h5 class="post__date">2016-08-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/nu0yeoYCX_Q" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello friends welcome to the video
lecture series on a machine learning so
in this tutorial we are going to see
about the different distance matrix or
distance measure and what are the
distance measure has been implemented
inside the scikit-learn library
so let's classify different distance
measure with the help of the kind of
data you have available so you can
divide this whole distance meter inside
like real-valued space data or a 2d
vector space data or if you have a
integer valued data as a training data
or if you have a boolean data so for
each of the different kind of data
available what kind of different
distance measure you can apply on the
top of this data for finding the
distance between de to point that we
have seen which is one of the most
fundamental component of K nearest
neighbor search so let's see about the
real-valued so for the case of real
valued there are like a Euclidean
distance Manhattan distance J by CEO or
me know what is SC Euclidean or ma
Bolinas distance so this is the sum of
the formula I have listed for each of
the distance V that is minimally
distance is a very generalized form of
all Euclidean and Manhattan distance for
different value of P you can calculate
either l1 normal l2 norm or l3 no this
way so this type of distance measure is
generally used when you have a real
valued as your input training data
two-dimensional vector space so there is
a cosine distance measure this is the
formula to calculate this cosine
distance this type of distance measure
will be helpful for finding the distance
between the two document in a whole list
of document so generally in case of a
retyping very similar document this type
of vector space related distances use
two-dimensional
space so this is for the integer
distance so if you have all data which
is the integer value or Litton you can
use this Hamming distance or Canberra
distance coming distance will tell us
that how many points are different and
how many characters are same we have
like a boolean vector space so in
boolean vector space you can use jakarta
distance or matching distance lies
distance so these are all just to give
you idea that what did this much
different types of different distance
metrics are available you can use any of
them based on your requirement and these
are all has been already implemented
inside the scikit-learn library so now
let's see how any of this distance
matter we can use inside the
scikit-learn okay so I have already
opened the documentation of scikit-learn
so we have seen inside this s scale and
neighbors module we have a whole family
of class of algorithms like a nearest
neighbor out of this nearest neighbor
there is a one more module which is sub
module which is a distance matrix okay
so I'll go to distance so if you see
this in a distance matrix whatever I
have just now shown you these are all
distance measure has been used for real
values field these are for vector space
these are all for integer value space
and remaining all this distance for the
boolean space so we if you have a data
like the 0 &amp;amp; 1 kind of data you can use
those kind of boolean now let's see how
in a very general way we can use it so
let's just import this library so for
importing purpose I have already listed
one simple data set X and we will try to
calculate the distance between each and
every individual point of this
okay let me run it let's import the
necessary distance metric plus so from a
scalar n-- dot neighbors we will import
the distance matrix okay we have
imported it we have now input data so
out of this distance matrix if you'll
first define what kind of distance
measure you want to calculate so let's
just define it like a Euclidean
Euclidean and we'll assign it to
something like you will give an
efference so it will create one distance
matrix reference and whose scaled
distance calculation will be done by
euclidean so there is a whole family of
identifiers has been given Euclidean
Manhattan share by so any of this you
can use for distance measure this way
you can define your distance identifier
now let's apply some of the matter on
the top of it so we have something like
a pairwise distance so this is the
Euclidean distance it will calculate
between the pair of the points of input
data X which will supply okay so it has
given as total a nine value so there are
total three points so distance between
each and every points comparison so half
of the value are almost same so and this
0 0 0 indicate that the distance between
that point with respect to that point on
you so if you see this 1 comma 1 2 2
comma 2 that is nothing but 1 point 4 1
so under under root of 1 minus 2 whole
square plus 1 minus 2 is square so under
root of 2 is equal to 1 point 4 1 so
this way you can import a hell lot of
different distance which is defined
inside in the documentation of SK learn
distance matrix
so this is just give you idea that how
you can use the different business
matrix inside the scikit-learn you can
change this identifier you can calculate
other kind of distance also so I hope
you enjoy listening this video please do
like comment and subscribe it thank you
guys for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>