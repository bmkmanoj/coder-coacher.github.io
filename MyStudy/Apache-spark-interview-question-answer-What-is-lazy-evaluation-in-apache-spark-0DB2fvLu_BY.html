<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Apache spark interview question answer - What is lazy evaluation in apache  spark? | Coder Coacher - Coaching Coders</title><meta content="Apache spark interview question answer - What is lazy evaluation in apache  spark? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/MyStudy/">MyStudy</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Apache spark interview question answer - What is lazy evaluation in apache  spark?</b></h2><h5 class="post__date">2017-07-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/0DB2fvLu_BY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi friends let's take another question
regarding to Apache spark open source
software
what is the Lazy evolution in Apache
spark which is not available in case of
Hadoop ecosystem or it's processing unit
MapReduce so let's try to understand
this Lee's eeveelution with respect to
one example generally there are two
kinds of operations are available in a
apache spark one is the kind of
transformation another one is a kind of
action so what does this transformation
and action and what are the difference
and how it is related to Lee's
eeveelution in Apache spark so let us
try to understand transformation is
nothing but it just tried to convert one
form of idd data or resolution resilient
distributed data set into another form
of or another RDD data set so that is
just giving the transformation of one
rdt to the another ideally an action is
nothing but you are actually asking for
the data from the database or you are
actually asking for the data after
whatever part has been processed so here
I have taken two example one is the
example where I am giving the exactly
the correct path where my actual
database exists which is nothing but the
airline database l-line dot CSV file it
exists so in a very first file I am just
giving the reference that to my database
file exists at particular location so
that is nothing but a transformation
because it is trying to create the high
DD for me and after did the next
immediate statement I am applying the
take matter on the top of this file
variable which is nothing but I am
trying to take the action that give me
the first five actual record which you
have read at the same another example I
have taken just the very simple thing I
have change that I have taken a
different path so both the example I
will try to execute and will try to
understand what
tech revolution means in a case of
Apache spark so let's try to run this
first piece of code with the correct
path and we will try to understand lazy
volution so I have already installed
this Apache spark on my machine and I
have just started with dot pi spark
command inside the bin folder of Apache
spark once I execute dot PI spark
command it will give me the interactive
cell of Apache spark and I can straight
away write all Python code on the top of
it so let's just paste it so very first
line I am trying to paste you can see
that successfully I have created file
variable from the database exists at
this location and text file is nothing
but it will read those database and it
will create RDD now let's check the
database type of this file variable you
can see it's a kind of idd file and this
file path is completely correct
now suppose I want to extract or I want
to see first few data so I can just
three it away write file dot take
command and I just supply the Phi
because I need to first just fire course
only ok so it has successfully displayed
first by our DD records for me so that
is nothing but the Airlines data set so
the first line which I have executed
here that is nothing but the
transformation because it has
transformed into already kind of
database and the second one is the
action I have taken because in the file
path is already exists it has not given
me any kind of error now let us try to
relate this phenomena with the lazy
volution men before that let us try to
understand piece of code now I am giving
the another let's make it file one so it
won't get confused in the second example
let I am trying to give the wrong part
and let's see whether it gives the
error or not so file one but this is the
wrong part this is where the data does
not exist it's okay but it has
successfully executed and it has not
checked whether particular file Airlines
dot CSV exists that particular path or
not now if I want to get the first few
records you can see it has given
immediately the error that that file
does not exist
now what does this mean that in a second
case while executing this command only
it has given error but herein while
running this code no error came that it
signifies that while doing the
transformation there is no execution
transformation kind of command when you
apply on the top of this spar context it
doesn't check for actually that
particular part exists or not that's why
no error occurs so that is the kind of
transformation now when I ask for first
few records first by records when I
apply this take matter on the top of
this RDD data type of file one it has
immediately given me error because at
that time only it has started executing
the very first line what we have what we
feel that it has already been executed
so in a case of spark whenever you do
any kind of transformation it will just
compile it and it will put all those
statement into line edge graph it won't
actually executed and whenever we ask
for any kind of action on the top of
this RDD data set at that time only
immediately it will call for execution
of all transformation what we have
applied till now that's why it is very
lazy in execution and that phenomenon is
nothing but the use eeveelution in case
of apache spark so whenever any
transformation we will apply no
execution occur it will just compile the
code and it will put it into line edge
graph but whenever we ask for any as
it will keep executing all those for
what we have already compiled and what
we have given as part of instruction
earlier so when we start executing this
take file it has already started
executing it first this text file
reading into data SEC ID d and after
that it will try to take the first fire
course here but when the first set of
statement is third executing at that
time only it didn't find that particular
file and it immediately throws the error
so the conclusion is that whenever you
ask for any kind of action at that time
only all transformation related action
or transformation related statement
starts executing that's why opposite
SPARC is very lazy when you ask for any
kind of transformation it won't do
actually any kind of transformation so
that's all about the LEAs eeveelution in
apache spark and I hope you enjoy
listening this video if you haven't
understood anything please write it in
to come in and if you haven't subscribe
my channel please please do subscribe it
to support the channel at last thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>