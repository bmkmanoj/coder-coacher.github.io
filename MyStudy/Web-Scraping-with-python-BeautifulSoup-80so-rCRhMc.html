<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Web Scraping with python BeautifulSoup | Coder Coacher - Coaching Coders</title><meta content="Web Scraping with python BeautifulSoup - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/MyStudy/">MyStudy</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Web Scraping with python BeautifulSoup</b></h2><h5 class="post__date">2016-07-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/80so-rCRhMc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello friend sir this is the second
tutorial onto video lecture series of
web scrapping with the help of Python so
in a last lecture we have seen how to
fight the remote URL we tell of a URL
open function in a Python with the help
of URL Lib model of Python in this
tutorial we'll see about how to use
beautiful slope library which we have
installed into last video tutorial let's
see what we'll learn in this lecture so
in this tutorial we'll see how to use
this beautiful soap library to get the
content of individual tag like do
element contained or even H even element
content of what is the title of that
page or any kind of element how can
usually extract from the whatever the
HTML strip you have got with the help of
URL open function and we will see what
is the how to use the exception handling
while fetching the URL so let's start
with coding okay I have already created
my development environment on Jupiter so
let us first write the code till what we
did in the earlier
lecture
and is the URL Lib library we are
importing and there is one more in this
lecture we need to write be a sport that
is a beautiful soap library and we'll
import beautiful soap function
okay so we have successfully imported to
function URL open and a beautiful so now
let us read this HTML stream we'll use
the same URL what we used in earlier
lecture
okay and we will supply as argument okay
so it has we have got every full content
of this HTML page in this one you know
HTML object here let's print it
so we'll confirm it we can use the read
matter of okay so we have got HTML and
inside the rich head tag and title and
the you've element h1 element okay so
now so we want to extract suppose the
individual element this D or even h1
element how can we use it because we
have a complete this object as a string
we can't individually go to the
individual element and we can extract it
that's where the beautiful soap library
plays an important role so let's apply
this HTML string to the beautiful soap
function and it will create
and we'll grab it in two Bs object so
what we did actually we have supplied
the complete HTML string what we got
from the URL open function we have
supplied to the beautiful force so
function and it will create the brand
new object OBS from where we can easily
get the content of individual element
okay okay don't worry this is just an
warning why this warning because we
haven't supplied which parcel to use
while parsing this HTML content so if
you don't use the any kind of parser it
will assumes it's a default parser
better to supplies some parcels so you
won't get any problem there are other
parts are also available and they are
returned that based on different
environment they are using different
parcels so here we'll use the L XML
parcel which passed this HTML string and
put it into place object
okay so error warning has gone okay so
now suppose we want to see the content
of this h1 element or even a title
element title so we'll just write from
this BS object we can grab actual and we
can print it
okay let's first sprint and BS no
content is there
hi friends disease sure with some kind
of session so don't worry we will use
another flight or not book and we'll
paste all contain there hopefully we'll
get answer
okay now suppose we want to bring them
h1 tag so we can use this h1 on the top
of this BS object okay hopefully we have
got it so that is the interesting title
now bring full this be a HTML string so
there are some issues with a different
different cell what we are running it
has issue with some kind of session but
we already know about that this is the
h1 tag and there is a development inside
that and now so suppose we want to
extract the title so we just put the BS
dot title okay so we got the useful if
that's what here it's useful page the
title is a useful page okay so now it is
coming up with the hot type tag also
associated with now we just need the
string or means the actual content
inside that that just put the streak and
turned up the and it will return just
the content okay so it's working fine so
that is how we can grab the individual
government content we can get the
develoment content also do you okay so
it has given a full new content here
this is what the new content is okay
suppose we want a full body contains to
be yes dot body
Oh on a body yes okay
this is the body so full body tag it has
displayed it so in this way we can use
the beautiful sofa and we can extract
the individual component out of it so
this is the first step and this is the
second one
how will use the exception handling
while fetching the URL why this
exception handling is required friends
because I this is all of content you are
fetching from the remote URL and you
never know that or whether that URL is
correct or not whether even if the URL
is correct and now it may happen that
site is and now an aura
it may take little more time and it will
be difficult to get the content within a
small limited amount of time so every
time you put this exception handling
so did your code won't break and it will
continue right so let us see with the
same example here let's try with this
one this part which part
and we need to import
URL late
dot HTTP error
you put star okay now you know that this
is a completely correct URL so you won't
face any problem okay we got some error
okay this is the issue with some
function okay rather than putting here
we'll put this star here and we'll go
ahead okay so it has successfully frige
the content
now suppose let's keep this variable
aside
and we'll put some random URL and we
doesn't exist on the internet again so
it has thrown us some kind of a aware
that this kind of URL doesn't exist so
how exception handling will be helpful
in this case so what we'll do here we
will try put whole code into try/catch
block and we'll accept it
as a HDTV exception HTTP error exception
as e and we'll print it
okay so we have got those exception here
they're telling that HTTP error is not
defined so might be
some issue but this is a complete
correct code I will correct into this
code into next lecture but this is where
how you can handle the exception
handling with by putting the code inside
this try and you can catch those
exception in to accept block that's all
for this lecture in a subsequent lecture
we will see how to extract different
links from the individual wiki pages and
how you can do manipulation on the top
of that little expert ones level of
scrapping how to get tax from the based
on the class or even different
attributes and Heidi thank you guys for
watching and please do like comment and
subscribe the channel
I hope you enjoyed this video</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>