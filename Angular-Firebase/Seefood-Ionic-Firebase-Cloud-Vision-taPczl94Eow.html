<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Seefood - Ionic + Firebase + Cloud Vision | Coder Coacher - Coaching Coders</title><meta content="Seefood - Ionic + Firebase + Cloud Vision - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Angular-Firebase/">Angular Firebase</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Seefood - Ionic + Firebase + Cloud Vision</b></h2><h5 class="post__date">2018-01-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/taPczl94Eow" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">today I'm going to take you from zero to
a deep learning powered mobile app with
ionic firebase and Google Cloud vision
you might have seen this out before it's
ready please
ha ha just do pizza yeah hey Zach not
hot dog wait what the and not only
will our app be able to detect hot dogs
but it can also label any image using
Google's deep learning infrastructure
and it's actually a lot more
sophisticated than you might think as
you can see here if we upload a hot dog
it correctly labels it as such but what
happens if we try to trick it by sending
it a picture of a pug in a hot dog
costume it's smart enough to know that
that's not an actual hot dog and labels
it instead as a pug if you like building
cool apps make sure to subscribe and
follow along with the source code at
angular firebase comm let's take a
closer look at how this works the user
will upload an image from our ionic app
to firebase storage that's going to
invoke a cloud function which will send
the image to the Google vision API it
does it's deep learning magic and
converts the image into a set of labels
we save those labels in fire store so
they can be read in our front-end ionic
app in real time to get started with
this project you'll first want to start
a new ionic app using the blank template
then CD into your project and run
firebase and net functions this will
associate your project with firebase and
create a folder called functions and the
root of the project and make sure to
select typescript when prompted for that
option after that you're going to want
to CD into the functions directory and
then we're going to install the Google
Cloud vision library cloud vision is a
library that takes an image as its input
and returns a whole bunch of data
extracted from that image it exposes a
high-level API to access deep learning
algorithms that have been trained on
millions of images it can also do more
advanced things like facial recognition
and text extraction which I'm going to
cover in a video for pro members our
next step for this app is to go into the
storage console and create a brand new
bucket for the cloud vision function the
reason we do this is because firebase
functions can't be scoped to specific
file locations
so it's best to have a dedicated bucket
specifically for invoking the function
after that go into the rules tab and
make sure to enable read and write
access for this bucket as you may know
every firebase project is also a Google
cloud platform project cloud vision is
not enabled by default so you need to go
into the cloud platform console to the
api's tab then find cloud vision and
enable it before we build the actual
mobile app in ionic I want to build out
the cloud function just so you know how
everything works on the backend so go
into your indexed ES file in the
functions directory then import firebase
functions as well as the admin SDK
because we have cloud vision enabled on
the cloud platform console we can just
import it and then instantiate a new
vision client there's no need to add API
keys to the environment or anything like
that then we need to set a variable for
the name of the storage bucket otherwise
firebase is going to try and use our
default bucket from there I'll export a
constant for our actual function which
I'm calling image tagger it's going to
be a storage function that points to our
bucket name then we'll call object on
change and return an async function
which just ensures that we return a
promise from this operation now inside
the function code I'll set up a couple
variables here for the actual file data
and the file name which is going to be
important later on because the file name
needs to correspond to the document ID
in the firestore database the image URI
is the actual stored file location which
is going to be used by cloud vision to
read the actual raw file so we'll upload
the file from ionic but for right now
all you need to know is that that file
path is going to have the same ID as its
data in fire store so we'll just split
off the JPEG from it and then use it to
make a reference to the actual document
in fire store which is in the photos
collection at this point we can do all
of the deep learning magic with a single
line of code we can await the results
from our vision client by calling label
detection and passing at that image URI
it responds with a big object of data
but we don't need everything there so
we're just going to map it down to the
label descriptions that we want to show
the user on the front end we also want
to know if there's a hot dog in this
image so to do that we can just
look at this array of strings and use
the fancy new includes method to see if
there is a hot-dog string in this array
which will return true or false
now there's only one step left and that
is to save this data in fire store we
already have a document reference so we
can just say doc ref set with the
corresponding data now you can go ahead
and deploy this function and try it out
go into firebase storage and upload an
image that you think might be a hot dog
but just aren't 100% sure then jump over
to the fire store database and go into
the photos collection and you should see
a document that looks something like
this
we have a hot dog boolean value and then
an array of a bunch of strings that
label this image our back-end is working
perfectly
let's see D back into ionic and generate
a new page called vision then we have a
couple dependencies that we need to
install on our project the first one is
the native camera Cordova plugin which
will give us access to a camera on a
native mobile device then we'll also
install angularfire 2 to make firebase
more friendly inside of an angular
environment follow the install
instructions for both packages and then
open your app module file for angular
fire you can see we're importing
firestore as well as the storage module
import the camera here as well and then
make sure to add your firebase
configuration to this configuration
object the firebase modules are going to
go in the import section the vision page
goes in entry components and the camera
goes in that providers array after that
we just need to go into the app
component and instead of using the home
page as the root page we're going to
swap that out for the vision page now we
can switch over to that vision page and
write all of the front-end code first
we'll bring in the loading controller
from ionic and also a few things here
from rxjs
and angular fire store and fire storage
and of course our ioniq camera then
we'll go ahead and set up a few
variables here in the page the first one
is the upload task then we'll declare an
observable for the actual results that
we get back from fire store we can also
set up variables for the loading
indicator and the image itself to show
those in the front-end as well from
there we need to add all of our
dependency
to the constructor again those include
fire store storage the camera and the
loading controller we can also
instantiate the loading object in the
constructor which we do by calling
loading controller create and you can
customize this as well at this point we
need to define a method that will start
the actual upload process it takes the
file as an argument and then it will
present the loading spinner once it's
triggered then we'll generate a random
ID for our document and our file name so
the actual file name is going to be the
document ID followed by jpg and then
we'll use that ID to make a reference to
firestore again it's important that
these two values match because that's
how we keep track of the file in storage
and its location in the firestore
database then we'll make a reference to
an in fire store even though that
document doesn't technically exist at
this point we call value changes to get
it as an observable and then it's going
to emit null initially so we want to
filter that value out when we do get a
value we want to dismiss the loading
indicator so the user can see the
results in the front-end for that we can
use the tap operator and then call
loading dismiss now we're ready to
handle the actual file the camera is
going to return it in a base64 format
which is just a big long encrypted
string but firebase needs it in a
specific format so all we have to do is
append it to this string here then we
can just make a reference to that
storage location which again should
match the document ID and then instead
of calling upload we call put string
with the actual image itself the only
missing piece at this point is how do we
get the actual image from the camera for
that part I'm going to set up an async
function because the camera returns the
image as a promise and it's important
that the destination type is a data URL
then because this is an async function
we can await the operation which is
going to return the actual base64 string
so we await the camera to get the
picture with our configuration options
and then after that we'll go ahead and
start the upload now we just have a
couple things to setup in the page
template first we want to give the user
a button that they can tap that will
start the actual process to capture the
after that I set up an ng if statement
so we can unwrap the results observable
and based on that result we should know
if the image is a hot dog or not so if
it is then we'll go ahead and display a
green button if it's not we'll display a
red button then we also have an array of
labels in that result so we can go ahead
and loop over them and we'll display an
ionic chip for each one at this point we
should be good to go if we run either an
iOS or Android emulator we should be
able to get the cloud vision API results
in our actual front-end ionic app I'll
go ahead and run the Android emulator
with the pixel - and we'll see how
everything turned out I've saved a
couple of images on this emulator and
we'll go ahead and select a hot dog and
you can see it uploads to storage and
then after a couple seconds or so we get
the results back and of course this is a
hot dog if this video helped you please
like and subscribe and if you're serious
about building apps consider becoming a
pro member at angular firebase com go
get access to all kinds of exclusive
content designed to help you build and
ship your app faster thanks for watching
and I'll see you soon</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>