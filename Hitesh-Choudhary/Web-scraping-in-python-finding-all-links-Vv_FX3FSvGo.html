<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Web scraping in python finding all links | Coder Coacher - Coaching Coders</title><meta content="Web scraping in python finding all links - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Hitesh-Choudhary/">Hitesh Choudhary</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Web scraping in python finding all links</b></h2><h5 class="post__date">2018-02-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Vv_FX3FSvGo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey there everyone they share back again
with another video and today also we are
talking about web scraping I realized a
lot of you are liking what we are doing
about this regex and these python-based
scrapping and stuff I didn't realize
that the first that people will like it
but thank you so much for liking this
video series and I am really totally
happy with that okay and the second
point is very very kind of a thank you
and really good support all of the
students who have actually posted the
answer of the last question that I asked
or the small assignment that I gave you
this shows that how dedicated you are
and I checked out all of the comments as
well so moving further now we are gonna
move on to another web scraping part
which is interesting and interest a lot
of people and a lot of people think that
finding all the links on the web page is
certainly easy it is not it is not it is
not like you can write one scraper for
all the website is gonna work for that
now it doesn't really happen with that
because all the websites have different
structure and you need to understand
that structure and according to that you
write a scraper yes there can be a
little bit generalized scraper for most
of the website but eventually you have
to customize this so we're gonna look
forward some of the cave it points about
how to web scrape all the links from the
website and again if you are watching it
for the first time make sure you watch
the previous two videos as well because
otherwise this is not going to make much
sense so let's fire up our Python editor
here Python 3 luckily I'm on a Mac and
Python 3 is can be used directly like
that
okay so previously we have done some of
the stuff we are gonna do again that
here and I'm gonna give you a couple of
assignments here as well so first of all
just like always we are gonna import
requests and I just onto a side note if
you are using like you are a labourer
you are a Lib to any that may be
libraries to make a request that's fine
too no problem at all so we're gonna
import requests and we're gonna import
bs4 for beautifulsoup and if i bring
back the documentation of beautifulsoup
where that is there we go so it's all
about the documentation and reading this
stuff and one of the thing that we are
gonna be looking for is gonna be this
find all and you can see there is a find
all and you can just work for there
there is you can find all the a tags
there we go
we can make a soup and can make all a
tags and we can also pass on a couple of
string values that if it is true or not
so we'll be using something like this to
find all the links on the website and
then I'll give you a simple assignment
for this I hope you're ready for that so
let's just get that and let me explain
you what we are gonna do first of all
we're gonna make a request
oops we are gonna make a request and
there we go requests dot get and I'm
gonna be making a request for let's just
say I'll use my website HTTP colon slash
slash learn code oops I can write that
correct for sure learn code online dot
in and I think that's it and if I check
res dot text text it should give me all
the things and there we go I have got
everything here which is looking like
okay there you go my youtube channel
link I hope you're watching it there and
make sure to subscribe there as well so
we have made our request and the next
thing we usually do is kind of making it
a soup we have been doing this on all
last two videos as well so shouldn't be
a big deal so let's make a soup out of
that request again right now we are into
the type of request we want to convert
that into the type of beautiful soup so
what we're gonna do is we have been
doing this for long so because for dot
be-you-ti-ful soup and it takes two
parameter you know that already from the
last videos the first one is res
text the entire webpage and the second
is how you want to like beautify it or
kind of a parse that or tree structure
that whatever you call that
I'm gonna be using El XML you can use
HTML parser as well no big deal there we
go and now we have an object here okay
so now we will be using this guy here
which is soup dot find all to make sure
that we get all the links extracted here
now I love this Alex ML approach or this
Dom based approach because it is far
more easier as well as less error-prone
compared to the other approaches so
that's why I used
and even if you'll work quite a lot on
this you'll realize that this is
actually a little bit better as compared
to the others so we'll be using that and
just right now we're gonna write a
simple loop here so we're gonna say for
let us call this as link for link in
soup because we have a soup dot and now
we want to use that so it's really
simple we're gonna say find underscore
all we just read that in the
documentation and what you want to find
find the first mention thing is the tag
so that is gonna be a tag now then after
you can mention a string value that it
should be there or not her in this case
I'm gonna make sure that href is equals
to true because there can be other a
tags as well which don't have h RF
values and stuff like that so that's
what we are looking for but there are a
couple of issues here as well so let's
talk about them as well and that is
gonna be your assignment so we're gonna
simply say print and what we want to
print is link and we are gonna be
interested on the links which are having
H ref values so that's why I'm making an
H ref here and there we go I hope it
closed that properly so there we go and
I forgot to wrap this around in the
codes okay so there we go
now it's looking good so this is it and
it gives okay why are you having a
problem okay oh my bad I am into not
JavaScript I'm into Python so T of the
true needs to be in capitalized so there
we go and then I can have this and there
we go so all the links are being
displayed here that's all things are
same I just forgot to write the true in
the caps there T should be in the caps
no big deal again so now we have got all
the links properly and we have got a
couple of issues here which you are
going to solve for me the first issue is
you have to use a simple if and else
Clause here and if the pound sign is
being detected
you will be just writing a pass there
completely ignore that thing okay so
that's the first step that you'll be
doing first check the second check is if
the website or the link is starting from
the dot slash you have to replace it
instead of the dot slash just replace it
with HTTP colon slash slash learn code
online dot in slow
and then concatenate it with this FAQ
dot PHP and all these stuff so this is
what the basic stuff so this is kind of
a simple customization you can do you
already know from my courses if an else
condition and how to detect some links
or slicing the link so it should not be
really tough for you you can do that
pretty easily so this is what I'm but
obviously it is working pretty
rock-solid good not a big deal here yes
there are a couple of issues that still
needs to be cleared up in order to
properly extract all these links like
for example JavaScript what do we won't
go into much of the depth we are somehow
able to extract all the links now how
much you want this application to like
be big it all depends on how you code it
because it is just working for like one
page if you have to scrape like 1500
pages or maybe thousand pages this
script is not at all good we have to
write codes so that it can work on to
multiple threads or maybe things like
that but that's a different story
we won't be going this is a big nerd
friendly stuff we are talking here so
again your two assignment don't forget
to submit them I read all of your
comments you can submit that on my
Facebook as well if you are really
really exclusively dedicated learner you
will definitely be submitting that to me
it's not about your doing it or not it's
about how much dedication you are
showing towards learning the things so
step number one ignore all the hashes
and step number two detect this dot
slash in front of any result and replace
it with that string some simple slicing
and concatenating of the string so I
hope you're enjoying these series as
things are pretty awesome
and once you show that we love that I
really love to make them more let me
know in the comments section how you are
enjoying them as well and to hit the
like and yes of course haven't you had
to subscribe my channel Y so go ahead
hit that subscribe button I'll surely
catch you up in the next video</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>