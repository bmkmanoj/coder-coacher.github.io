<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory SF 2016 - Julian Squires - What If Your NIF Goes Adrift | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory SF 2016 - Julian Squires - What If Your NIF Goes Adrift - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang Factory SF 2016 - Julian Squires - What If Your NIF Goes Adrift</b></h2><h5 class="post__date">2016-03-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5Qkqs2oNboA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright so I'm going to talk about nifty
bugging the the first thing that I
wanted to say was just you're not sure
if you don't if you don't already
maintain any nifs if you don't have any
nips already kind of you can and you're
just wondering should I write nifs I
mean you can skip this talk basically
because I'll tell you right now you
should avoid writing nifs it should be
you know as a matter of last resource
that you actually write an if ya so if
that's all you needed to know then you
know go watch go watch scott scott for
cheese talk instead because it's
probably going to be awesome but
otherwise i'm going to assume that you
have nifs in your system that you have
to maintain right now i've got i guess
about about a dozen that that we use in
production that I have to keep track of
and so I'm going to talk a bit about
where where those come from go ahead and
go ahead crypto is a great example i
know i'll talk about it and it is going
to say since we're so few feel free to
interject and feel free to comment
because there's not really much point in
not asking questions right away there's
enough people but but so like crypto is
is one of the classic cases it's like
like where do you end up why do you end
up writing an if right so your first
period with Erlang is just awesome you
go through that honeymoon period where
everything is great and performance is
great for some things right and then you
hit a wall where suddenly you need to do
something highly computational you know
or you know a variety of things but
usually some serious number crunching
and Erlang is just way too slow and so
well about crypto specifically well let
me talk just about like what usually
happens I think like I've seen the arc
typical arc here is that programmers
come from you know especially you come
from a background of speeding up
languages like any of like Ruby Python
Perl even Java before hotspot you know
basically the the rule of thumb was you
reach for the foreign function interface
or you know write an extension and so
that's just like the natural habit so I
think that when people come to Erlang
there's a tendency to when you see a
performance problem jump straight to
implementing an if because clearly
that's the FFI and that's like the
logical thing to do but in fact that's
not so and there are few exceptions like
in the case of crypto well so like
what's it what's a better way you know
you have a number of other ways of
interacting with external code in Erlang
I think the most Erlang anyway is
actually as another service like if you
can actually abstract that code out into
a service that you talked to through a
you know some network or inter-process
mechanism you know that's that's that's
the really early or lining way to do
that kind of thing and plays really
nicely with the whole system the the
next you know closest analog to that is
ports right which are basically you know
where you run run a program that's sort
of supervised by Erlang and you speak to
it through standard in and standard out
and like obviously one of the problems
with that is that you have to you
basically have to serialize everything
that you're communicating back and forth
so there are a couple of cases
particularly anywhere where you have to
work with a large volume of data or the
case of crypto is just interesting just
because usually you want to minimize the
ways in which you're transmitting secret
data and things like that so these are
things that that I'll often end up being
done as an ifs and you may not have an
alternative to writing them as an if
yeah yeah well for sure right and and
crypto is always like a big thing
especially because you often want to
take advantage of you know specific CPU
specific optimizations and
things like that and obviously there's
like so many orders of magnitude between
like trying to implement that in Erlang
or even as a port where you'd have to
transfer all everything that you were
encrypting or decrypting to the port and
back again so I should mention port
drivers right we're before there were
nifs you could link a port into the vm
process you still had to communicate but
you know you basically you didn't have
you had a much tighter communication
mechanism but of course that actually
was the worst of both worlds because now
your port driver code can crash the vm
you know but you're still you still have
this isolation and how you speak to it
so from that point of view the NIF api
seems like a much better way to do that
sort of thing but so i mean things that
i'm going to point out it's like nifs
very easily take down the vm in a really
bad ways right this is where you don't
want let it crash they they can have
memory leaks that are quite difficult to
track down just measuring their
performance is difficult and
specifically I think it's well known but
you know their impact on the scheduler
is really significant and I think
underestimated by people who start to
write nifs as long as you're your nif
performance is really really predictable
it's one thing but as soon as you get
into especially crypto is a good example
because you may be calling up to the NIF
for a long time and basically you have
you have a lot of really hacky
mechanisms to try and make that work
well with the scheduler the least hacky
which the least happy of which is the
dirty schedulers most recently but even
then even then there there there are a
lot of caveats to do with dirty
schedulers so like and even then just
writing the NIF to actually use dirty
schedulers properly is significantly
more work than sort of the default if
implementation that you would you would
do kind of naive
and there's almost no way to win there
right now like in terms of scheduling
problems you know it's just it's very
difficult to estimate what you have
calls to you know to sort of consume
time slices but it's extremely
inaccurate and in practice seems to have
a lot of really bad impacts on
scheduling in the vm so i think that's
something to really strongly consider
like everyone seems to find nifs perform
really well in the small but as soon as
you start using them in the large where
you've got a lot of processes and a lot
of scheduling happening there you know
performance is much more erratic right
and I mean we've seen all kinds of weird
behavior so I think that those these are
all things to bear in mind and they're
one of the reasons why you know in
general I now that I've inherited all
these nifs in this code base I really
like against nifs I really feel like
it's like it really should be the method
of last resort a you know it's
definitely not it's not a free speed win
let's put it that way but so let's
imagine that you do have nephs and
basically everyone one way or another
has neff's we'll talk about sort of what
can you do we're going to go I'm going
to look at three different kind of
throughout this I'm going to be talking
about three different use cases you have
like validating correctness just you
know is this actually behaving correctly
there's like debugging like where you
actually have something he's actually
going wrong with the NIF like it's
taking the vm down and how do you debug
that and then there's benchmarking and
improving performance because that can
be a really tricky thing and I'm going
to describe some tools that I've built
but first I'm going to describe the
tools that are already out there one
thing I one last note about like when to
write nips so the other seduction of
nifs is you think Oh Anne if is just a
Biff right yeah sone if stands for
native implemented function Biff stands
for built-in function
people often want the same benefit of
built-in function from an if and they
think they're able to achieve that but
in fact the NIF api is quite different
from what a Biff has access to in the vm
and just as an example you like you look
at jiffy has to call like a dozen
functions from the NIF api to do
something that i ab if that does the
same thing like checking the type of a
term only has two masks to bits out of a
term and do a switch statement so
there's like there's actually you know
quite a quite a disparity between what
you can actually do in an if versus what
Biff's are capable of so it's also
something where if something is really
of performance importance you know it
might not be too extreme to actually
consider I don't know begging the OTP
maintainer to implement it or submitting
it as a PR as a Biff because they are
quite different right so we should avoid
the illusion that that nifs are
basically just user-provided Biff's yeah
I I love this quote from Richard O'Keefe
recently you know and I think that that
kind of sums it up nifs violate Erlang
they violate everything that you wanted
to have in your vm and especially they
they make it really hard to they mess
with scheduling they messed with
reliability and robustness and so you
know so then you try to go and I note
about well you try to you try to debug
these things and so first I'll show some
things that go wrong a note about
pronunciation and so pedants will note
that this is I'm going to say Val grind
but the correct pronunciation is
actually valgrind because it's from
Norse mythology but just as a habit i'm
going to say Val grind so i apologize go
ahead
did you say milliseconds yeah yeah I
mean so my latency window is like 10
milliseconds that's I can't be doing
stuff like that I think if your nips are
running for more than one milliseconds
you're really going to screw up
scheduling that's my experience no it's
good to hear it's good to hear different
things but like are you actually
measuring sort of how that's affecting
the scheduling right fair enough then
you know all the better right and and
good luck to you so for example one
thing that you may want to do if you
have myths that are crashing or leaking
memory is you want to Val grind them but
okay first usually there's before you
discover what tools are there usually
try the naive things like trying to Val
grind the vm itself and yeah it just you
can see here so running these that the
test Suites took you know less than a
second normally but under Val grind
first of all it didn't report anything
useful it was filled with error messages
which I didn't reproduce here and it
took you know forever so so that you
know that doesn't work and other bad
things so some one thing about like nifs
if your nips allocate a lot of binaries
turns out that some of the binary
allocation stuff calls out to the lib
see allocator which has really bad
contention in the case where you're
doing you're doing a lot of allocation
across many threads across many cores
right so you might try to drop in
different allocators and luckily je
malik does happen to work which is great
but you tried
preload TC Malik and you just get a
segfault and so there's a there's a
bunch of things that are iffy about
trying to work with work with the stock
vm but so there are debug builds of the
runtime system and this is a really
handy thing I think this was like I I
mean if you've been maintaining and
debugging this for a while you're
probably quite familiar with this but
this just finding out about this because
it's not extremely well documented I
feel was a boon to me you know you can
actually you have to go into the Earth's
emulator directory of of OTP and then
you make type equals whatever and then
your flavor which can be SMP or normal I
think anyway and you get you get special
builds of the beam and you have to use
this Cyril script to invoke them it is a
ton of different options it's really
worth looking at all the different
options some of them are quite confusing
for example- gdb is what you would think
would invoke gdb but actually it invokes
key max which is is surprising at first
it invokes GV inside of Emacs our gdb
just runs gdb and so that's like the
debug build there's a Val grind build
which makes the runtime valgrind able
there's a lock counter LCM T which I'll
talk about in a bit and you can build
the whole system with a configure option
with dynamic trace equals system tap for
example and that enables a lot of system
tab probes which is very useful for some
kinds of introspection I'll talk a bit
about that although so far I've not
found it that useful compared to other
approaches so the lock counter is really
handy in this case is allowed me to
determine that locks were not a problem
for this code you can see there's like
almost no collisions over hundreds of
thousands of runs compare this is like a
good
example of badlock count output where we
have like forty four percent collisions
on the process table lock and you know
it's a bad scene it's a and so that that
that's actually really useful that's
extremely useful for sort of diagnosing
some performance problems but well I'll
talk about the caveat seviche in a
second all these builds basically have
problems with lock counter in particular
you know instruments the vm in ways that
completely change its performance so you
can't use it in production right this is
basically true of all these special
builds when you fire up the debug
version of the the thing you also get
something which is is super useful as
the emulator toolbox for pathologists
this is a large set of gdb scripts that
actually allow you to introspect things
in the vm this is this is really helpful
not just for gdb like you can use the
same logic that they use for decoding
things like this like doing stack traces
from system tap for example so it's
actually it's actually extremely helpful
you can see for example in this case
I've got a an if where I've set a
breakpoint and so when we when we hit
that break point I say I'm able to print
out the terms of the arguments to it
look at the process info if I do EDP
stack trace and frock I would get the
stack trace of that situation so that
like that can be incredibly handy for
some kinds of of debugging but like
beyond that something about ETP is just
it's filled with it's filled with a
great condensation of information about
how to introspect parts of the system so
the other thing if you're writing yeah
system tap probes or for example i'm
experimenting with some kind of crazy
stuff involving perf counters that needs
to read snapshots of the vm memory
and do things with it and and the
easiest way to figure out how to do that
and how do that introspection is
actually just looking at the ETP script
which is you know this kind of monstrous
gdb script that actually partially gets
generated in the build process but it's
still it's incredibly helpful and and
it's filled with I don't have the
snapshot of ETP help here but it's worth
firing up just because there's a ton of
commands and you can see processes that
are running stack traces all kinds of
stuff and it knows how to print terms
which is really handy but ultimately so
there are a lot of places that you can't
use a custom vm continuous integration
so for example we do a lot of builds on
Travis CI and things are slow enough
without me building 20 different
variations of the the vm at the same
time and you know it just i think it
would be very inconvenient to to do that
also the invocation of these things is
inconvenient like as far as i know and
maybe someone can correct me if I'm
wrong but it's really not trivial to get
rebar to you know to invoke likes a
rebar shell or whatever using the Cyril
the debug Cyril for example or or
similar so this is there's things that
are inconvenient about about those tools
so AFL fuzz American fuzzy lop is a
great great fuzzing tool incredibly
powerful fuzzing tool that kind of not
unlike what cost us showed yesterday
like it's kind of a reduced form of
testing it doesn't use an smt solver but
it does instrument branches and do
coverage directed fuzzing but you know
it's it's not it's not really possible
to use it with like use it on the vm for
example i know someone just recently I
saw an IRC somebody is actually working
on using clangs lib buzzer on OTP which
is awesome but I mean I think it's a
mammoth undertaking and finally like
production that's the most important
thing you can't use this for diagnosing
you can't use any of these
for diagnosing faults in production
really all of them even am pretty sure
the Val grind build introduce enough
overhead if you're already pushing your
machines really hard that they're not
really they're not really practical so
in response to that especially because I
had a lot of problems with nifs I had an
idea which is why don't we implement
just enough of the NIF API that we can
load an if outside of the vm right and
run and run things with it so that we
can run things under Val grind and under
gdb and you know and fuzz them and so on
so I implemented a little little harness
called Miffy that basically so it loads
an F for multiple nics you can supply
several SOS on the command line you can
see there that it's loading jiffy it
prints out what functions are defined in
there arity and then you can actually
you feed it Erlang terms and you get
binds variables and you can get the
output the output is formatted as I
relying terms part of the reason for
this is that we can integrate it really
well with so we can integrate it really
well with like our existing test
environment and especially tools like
like proper and other things like that
because you can just really quickly
generate examples pump them out to it
with you know I Oh format or similar and
read them back in and so that's really
handy NL let's say it's going to say so
I'll go through a couple of cases where
I've applied that and some other things
so one of the nifs that i use seized for
looking up IP addresses and net masks in
like out of many lists of IP addresses
and it you know it's like has to build
an index and and does queries and so
there were a lot of change is happening
to the sniff
and we wanted to really make sure that
it was correct this was actually one of
the inspirations for writing the harness
because we had some really really fun
bugs like I think my favorite war story
from this sniff was that it would at one
point it would crash when built with
clang and it would work fine when built
with GCC and that's the kind of thing
that's that's spooky enough that you
don't like but and that that end up
being quite interesting because it
turned out well obviously it was a
mistaken in the code but clang ended up
allocating quite a lot of things on the
stack and GCC elided the allocation and
just as a random word of warning the
stack that the NIF has available to it
is quite limited I think the default I
think the default stack the vm gives you
is something like a maybe a maximum of
eight Meg's anyway which is plenty for
many things but if you actually are
especially if you have C++ code that
does a lot of allocates large things on
the stack it's very easy to blow it so
that's worth knowing but so we wanted
some ways to maybe ensure that this was
actually correct especially I wanted to
run it under Val grind and check for
memory leaks and things like this so
this is an example of from the Nifi test
suite Valley keen if and what what Val
grind will report so one thing about
Nifi is like obviously there's no
garbage collector but what it does is it
just keeps track of every allocation you
made right it's not intended for long
runs of your neph it's just but every
allocation is tracked so that basically
at the end you know we can easily sort
of free everything that was actually
that would have been accountable to the
garbage collector and so in this case we
were able to at the end detect that you
know this this nif call Dean if a lock
and didn't didn't use an appropriate
like inna make call afterwards to to
attract it yeah in an if yeah yeah for
sure and in fact many nifs do that right
and so we Nifi to obviously that's a it
keeps track of the environment just like
the same thing bully in both cases in
the vm and an iffy you each and if has
associated with it an environment that
actually all the allocation basically
happens sort of within that environment
and there's a bunch of things like
usually there's a process associated
with that environment yeah and although
you can create new environments there's
a bunch of things around that but
basically there are a lot of ways to if
you do end up doing allocation in your
neph there are a lot of ways to shoot
yourself in the foot and so yeah so it's
definitely possible to leak memory and
and so yeah so running an if under
nephew is one way to potentially detect
those things so you can use Val grind to
to do that or a San the address
sanitizer one thing that's nice is you
can build everything with minus f
sanitize address minus f sanitize I
think I discussed this yeah minus F
sanitized equals undefined behavior
these are really handy one thing that
turned up was a case where we actually
shifted something did I think a left
shift by more than the Machine word size
and of course this is undefined behavior
so you have to be super careful about
that because one day your compiler may
decide to shoot you for using this for
not masking your your shift and yeah and
it's certainly usually the unexpected
it's some unexpected behavior occurs so
that was one thing that that we
discovered by building with UV San but
so it's something that apologize for the
duplication there this is something that
like that we do right now is just
generate random cases and
run it under Val grind this is actually
really handy for especially when making
changes because you very quickly detect
bugs that I just find are quite
difficult to detect just running a
normal unit test suite and so one of the
other things that we do for this so you
can actually trace user Lang's tracing
facilities on your test suite and just
send everything everything that your
test suite is is sending to the NIF in
the vm you can send to niffy so here we
spawn niffy under val grind as a port
and then we trace all the calls to the
to the NIF module and then we had just
have a little loop where every time
every time we get a call we send it to
tune iffy and this is actually super
handy because then you just spawn this
and then you run then you run your test
suite or whatever else and just all the
calls get passed on and then if it
crashes well you get tons of ugly Val
grind output but but it's super useful
for detecting them well I'll talk about
that in a second yeah and also American
fuzzy lop so the other things over to
use American fuzzy lop you have to build
everything with AFL GCC or a LG plus
plus so that's one of the reasons it's
quite difficult to actually get the vm
to build properly and then AFL fuzz to
run on it and even then it's not very
practical because it creates a ton of
branch points so in this case you just
have to build Nifi and the the the NIF
itself and you can just path you can
just set the environment variables to
point to AFL GCC and run invoke rebar
compile and it'll do the right thing or
if you're using rebar 3 you may have to
tweak your your make file but but after
that you can run American fuzzy lop on
on the NIF and it's quite handy so this
in this case there
is nothing that was only running for 35
seconds this is another case as
interesting as like 57 unique crashes
after 23 seconds you usually like the
number of crashes it's like number of
unique crashes flattens out pretty
quickly most of the time but this is
actually really nice for finding
especially anything where you might be
if you have any kind of miffed that
there's any path for unsanitized input
going through it you know if you're
doing just like you know base 64
decoding Jason encoding and decoding all
sorts of things like this I think it's
really worthwhile actually fuzzing and
using an intelligent fuzzing tool like
American fuzzy lop yeah just because
it's it's much more effective than I
don't know trying to trying to come up
with your own fuzzing tools or trying to
do this purely through property testing
so so another case finding an elusive
bug so this is something you never want
to see right performing a unit tests
segmentation fault yeah when your unit
when your your unit test segfault that's
really not good and so this was actually
this was something that that was this
was what drove finishing actually
getting a working version of Miffy
because I really wanted to track down
this bug because occasionally it's with
seg fault and the the unit tests for for
one of our our systems and you know
trying to reproduce it you open up like
for example you set the un's at the core
limit so a core file is generated and
you pull it open and it's really not
clear what's happening especially
basically the crash is happening like it
appears that the crash is happening way
after whenever the damage is done and I
mean that's classic in NC right usually
there's actually some corruption that
occurs that's why Val grind is great
because it detects that corruption
the time it happens and you know it's
often much later when the segmentation
fault actually happens it's like the
damages long long since done and it's
hard to trace back to it so this is what
this crash looked like in GDB just on on
the run time and then under Val grind it
was much better valgrind reported was an
invalid read it turned out that it was
actually a race condition that if the
tests ran fast enough basically I won't
go into it but this nif like the sniff
loads other dynamic objects that have
been created have been compiled on the
fly and it turned out that it was using
timestamps to differentiate the the file
names and of course there was
possibility of collision and then there
were certain cases where it didn't check
some bounds but anyway this is great
because this like sort of definitively
finds where that is we're bound checks
need to be added and so the third case
is profiling and you know measuring
performance things benchmarking so like
in this case I'll talk a bit about GFE
and Jason encoders in general one thing
that I think I have a slide for this
yeah that so like one thing I noticed
for some some workloads that we had like
basically the the 99th percentile for
for pretty much all of the NIF based
Jason encoders was great you know was
fine but the variance with lots of
workers was awful yeah and just
basically occasionally you'd have these
real like really brutal variance and so
just in the process of trying to to rule
that out there were a bunch of
techniques that you can use so one of
the things that we speculated about
because the fact that
the variance increases does the workers
increase so that that last that tail
measurement is really bad right so this
is an awful hack this is a terrible hack
but it actually works really well for
quickly figuring out identifying calls
that were potentially too slow an l note
you can also do this with system tap and
I have also done it with system tap but
it's extremely person okati to actually
get exactly the right system tap
invocation and get everything on your
system set up to do it with system tap
where is this is really easy you drop
this into a header file right and it
basically just wraps all of the dnf api
and you build your nif and you know in
this case like i'm doing our DTSC i'm
reading the timestamp counter of the
processor as a terrible idea because of
course there could be a cpu migration
and you know then the value would be
meaningless and so on but in practice it
was enough you know this is simple and
it's simple enough to to pick up on
really egregiously long api calls so
this actually doesn't run in if he this
runs in the vm you build the NIF this
way you run your benchmark in the the vm
and do i say if no but i but basically
so then it outputs whatever call was too
slow and how long it thought it took and
that very quickly showed us that like in
this case inna free Alec was
occasionally really really slow and it
turns out that they'll I mentioned it
before but when you're reallocating
binaries ref count of binaries they
actually get allocated by the Lib C
malik and there can be really terrible
contention between between threads so
this was a way to catch that and it's
occasionally handy for for catching
other other things like that other
performance outliers
the other thing that's really useful
here is cash grind as one of the val
grind tools actually there's a lot of
those tools are quite useful but so with
cash grind you know we get kind of very
predictable count of like how many
instructions executed and a lot of
things like that and there's actually
much more information we can get from it
but this alone is really useful for
especially for comparing different
implementations and just seeing like
with the same input are they you know
sort of what is the instruction count
and sort of as justification for that as
a way of working i want to cite one of
my favorite quotes from a you know hero
of mine Richard D hip wrote SQLite and
many other great things he's talking
about how they made a fifty percent
improvement performance improvement in
SQLite over the course of a year like
and that's SQLite as a very mature
product already and you know says that
each micro optimization might improve
the performance by as little as 0 point
0 5 percent if we get one that improves
the performance by 0 point two five
percent that's considered a huge win
each of these optimizations is
unmeasurable on a real world system we
have to use cash grind to get repeatable
run times but if you do enough of them
they add up and that's one of the
reasons I would say it's actually very
handy to be able to cash grind your
neff's especially when you're trying to
really squeeze everything out of them so
Nephi is available on github there's a
lot of stuff that's not implemented maps
aren't implemented sub binaries aren't
implemented but that will probably be in
soon theres some timing stuff that's
coming that allows you to especially so
an interesting aspect of timing and
performance measurement is sometimes for
micro benchmarks you want to exclude
measurements where any interrupt
happened whatsoever so I actually have a
branch where users per event open to
keep track of basically in all
performance counter events that happened
during the execution of one measure
and and just to discard measurements
that happen if any context which has
happened for example so that's that's
kind of a handy thing and if you know if
you have a lot of nifs you might find
this convenient so feel free to
contribute and I want to thank my
employer add gear for giving me time to
work on this Thanks yeah and questions
obviously because we sure we have plenty
of time yeah is probably more than 10
minutes I I went through that faster
than I thought so so please any
questions any any any nif problems you
have what's up so it's not entirely
fixed yet but moving to je Malik
actually made a huge difference and like
I mentioned luckily it happens that LD
pre-loading j malik works okay with OTP
as it is but you know yeah that's still
sketchy and so ultimately actually so
what I'm actually doing I'm working on a
new Jason encoder that will be open
source at some point while Jason encoder
decoder that has a quite a different
approach to how it produces its output
that really tries too hard to get a
nihilist that gets that is as close to
an i/o vac as possible when things get
written out and tries to avoid doing
lots of large binary realloc basically
I think it's better but I think the
biggest thing is of course the
availability the less experimental
availability of dirty schedulers right
which you don't get by default but like
definitely is much more helpful than I
mean they've definitely tried to do some
some things it does make a difference
but really if your if your nips are
running for more than one millisecond I
highly I well I don't know for a you've
got any if consumed time slice just
helpful but the dirty schedulers would
definitely be the thing i would go to
that's other questions too many things
too many things yeah right no it's good
it's good they you know like i mentioned
have very interesting indexing problem
that requires that requires some very
creative compressed bitmap techniques
and you know that initially was an if
that actually has been moved out to an
external service but yeah that's that's
one thing and there's like all sorts of
all sorts of things that have to be
really fast basically like we have
really tight latency requirements things
like geo radius queries and things like
this all have to be like way faster than
just a naive implementation Erlang would
be a machine zone mentioned atomic
counters that's definitely something
that we're into as well which actually
reminds me like one alternative to one
alternative to sort of tune ifs that you
can use is you can use one nif like am
map to to access you know shared memory
basically but use that as fast
communication with external processes
that also read that that also and map
that page and that's still safer than
having an if it still avoids a lot of
kinds of issues with with that what else
ya lots of things babe a 64 it quoted
URL decoding Jason tons of stuff yeah
pretty much everything and anything that
could anything that isn't I always in a
certain sense like yeah another thing I
hopefully we'll have some interesting
work on perf at some point thats related
to this ways of basically
probabilistically sampling you know the
system state and especially what's
happening in the vm from outside instead
of i feel like any any approach based on
instrumenting it inside is really
difficult to actually pull off in
production as pretty much anybody who's
tried to trace in production is seen it
so hopefully that will come out at some
point other questions nope ok well
thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>