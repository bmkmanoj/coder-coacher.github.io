<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Profiling and Tracing for all with Xprof - Péter Gömöri - Elixir.LDN 2017 | Coder Coacher - Coaching Coders</title><meta content="Profiling and Tracing for all with Xprof - Péter Gömöri - Elixir.LDN 2017 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Profiling and Tracing for all with Xprof - Péter Gömöri - Elixir.LDN 2017</b></h2><h5 class="post__date">2017-08-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AAXtjPiXbWE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I will talk about profiling at racing
and how it is made a bit easier with X
prof so few words about myself I started
using air long about ten years ago I'm
working at eppley scale which is a
consultancy company based in Krakow
Poland specializing in in large scale
and low latency or software town systems
and also another focus is DevOps and
clouds engineering we have several AWS
certified engineers in our team so what
is X profits a library and open source
production safe real-time visual
profiler for a long and Alex here it was
started two years ago by Mohammed and
now the core team also consists of my
colleagues baba vikulova Tchaikovsky and
myself so production safety so Alex here
from the beginning was focused on like
easy to learn and start and very good
development tools but now it's getting
made sure more and more products are
more and more
yeah products are going into production
alive with more and more traffic more
and more load and we also need tooling
to handle observe and debug these
systems and extra is just one addition
to these tools or tries to be it's a
single function profiler that means it's
between regular profilers and debugging
tools because so regular profilers
usually measure all the functions in
your system like in a back box and then
you can just spits out like the five
slowest ones
there's expose just measures one or a
few functions that you've select so it's
a bit similar to debugging just without
the fact that you cannot just stop the
world in a production system and then
look at the variable bindings so you
need other means so the motivation why
this extra force creatively actually
have the actual performance problems in
the live system that we were working on
two years ago and we had some metrics
instrumented code in the monitoring
system we measured some parts of the
system but they were not fine-grained
enough so we needed more metrics but we
didn't want to go through the deployment
process wait one week for one extra
metric so we needed something that and
it was ad hoc measuring and measuring
any function that we like immediately we
looked at profiling tools like F probe
which as I said it measures all the
functions in the system and with that it
gives so much overhead that it's
basically unusable unusable in a in a
loaded system it just brings it down to
its T's and also because of this it's at
distortion to the measurements also it's
only gathers co account and average
duration of the functions and we needed
more details like some kind of
distribution of the durations like high
percentage and maximum values and also
more details in the sense that at least
so for some function cause we wanted to
see the actual arguments and return
value so we can have a closer look and
after of how it works is you measure for
a given time and then it analyzes the
gathered data and then it spits out the
result but we wanted to see the results
continuously like in a monitoring system
so updated every second and also the
result that after of creates is like a
huge Alex year term which is very hard
to digest or see what well so we wanted
to create some more intuitive visual
feedback so that's how Explorer was born
and yeah more about my single function
profiling it allows us to gather more
data about about that single function
the duration of that because very often
there is like a fast pass and the slow
pass of a function depending on it sorry
and looking at just the average actually
hiding this fact so there can be like
outliers which are completely take a lot
of time and then if there is one user
who gets a very long response on the
website he will be quite unsatisfied
just because the average is good so it's
very important to observe the high
percentiles and the maximum values and
you look at a live system so how does X
prof look like so you include this
library in your release you can start it
when you have some problems go to the
web interface up in that query text box
you can type the module function that
you want to measure like one and then
you get this nice graph on the right
hand side there is the call count on the
left hand side there is the durations
and then you get like minimum maximum
average percentile values you can show
and hide none I think you can see that
this function is called 200 times per
second that's on the right scale and it
takes like I don't know 100 milliseconds
hundred and 60 milliseconds and you can
we also have something like capturing
long calls so you can set a threshold
let's capture calls that take longer
than 120 milliseconds and let's just
capture three samples of them and then
you get a list of how long they took the
which process executed them and what
arguments it were called and what was
the return value and then we can spot
some patterns the first argument is
always the autumn long so from the
arguments from the samples we can like
get some intuition that maybe it's
related if it's long when the first
argument is long so let's do some
additional filtering we can even do that
measure the function when the first
argument is not the autumn long we don't
know what value it can be just check
that out yeah we can see now that on the
right hand side that there are about
hundred such calls and the duration is
much shorter so less
capture again some samples again three
samples and now we can see that the
first argument is short so now we can
definitely see that there is some
relation and we this very explored how
that kind of arguments this function is
called we can also measure private
functions so now I select like the net
long and a short private functions so
you can also measure multiple functions
at a time and then if it fits on your
monitor then you can like compare how
which one is the slower or if there is a
spike there is a correlation if the
phone is slow the other is so or since a
graph so that's a different kind of
profiling which is more interactive but
let's look at first tracing the along VM
has this great hidden feature which
gives some basic tooling to four other
tools to build upon so how that works
you can specify like a set of processes
and a set of functions that you want to
trace and then the intersection will get
traced which means that an ellipse your
message will be sent to a trace your
processor which is in currently an extra
tracer process so you can specify one
process that you want to trace or all
the processes in the system or only the
existing processes or only the new
processes will be spawned later and in
the pattern part you can specify exactly
like module function ret or module
function with all era T's or all
functions from a module and additionally
you can specify something like the match
back night spec which is only to narrow
down it further in X probe it only a
subset of this is supportive so you can
only select all the processes or none of
them this relates to that big green
button on the extra UI so there's a big
on/off switch so you can turn on and off
tracing and then the function you can
specify it in the text box so what our
math specs they are these horrible terms
that you can see they are hardly on
understandable or if you still
understand you probably make a mistake
in them so it's better to look at them
like an anonymous function which which
serves to to filter the functions that
are traced so they have like like as a
function has a head guard and body the
mass spec also have a match back head
and match back guards and match back
body they have they are used in two
places in the along V M one is for ets
tables and one is for for tracing they
have a slightly different flavors so it
yes you might have met that met with
that registry so the difference between
the two flavors is first the ets one
receives a total which is like one
object or one row in an ETS table
whereas the dbg flavor received the list
of arguments the function was called
with and then in ETS flavor the return
value is actually the result of the
selection and in tracing the return
value is ignored it's only executed for
it for its side-effects
two modifies in various ways the
behavior of tracing the body is very
limited it cannot be like a normal
function you cannot do function calls
there you cannot do conditions like if
for case you cannot do matching there it
most of is like term construction and
something like gods plus in DB G you can
also add some these action functions
which you look like local function calls
but actually they are not but let's see
some examples and how they look like
what what format you can put in
in that extra flurry textbooks you can
put the module functionality that's
that's fine and the module function
followed by something which is something
like the part of an anonymous function
so one example when you only filter on
the arguments like let's measure the
register lookup cause when it is called
only on the my AB dot registry so all
other registries we don't care about
that's already very useful but you can
even add guards so only measure registry
dispatch calls when it's called on topic
one or topic two so with the guards you
can match on any on multiple values as
well and here is the body part the the
most important action function is the
message which modifies actually the
trace message which is sent on the low
level on extra flavor it doesn't have
any effect when you just look at the
graph it only has an effect and you
actually captured the arguments and then
instead of the arguments it will show
what you put in the message so you can
actually change what you want to see and
that's very useful because this way you
can reuse some noise and really look at
what you want to for in this example you
can like capture who called the enum map
function and it took like too long
because you know map is like a library
function is called million places so
it's good to identify where it is called
the other most common part is when you
want to only capture like part of the
arguments or some derive value from the
arguments in the first example you can
so they are you measure et s in that
cause inserting some data into the data
table and then you capture the second
field of the data structure which can be
a possibly huge
Tuttle with all kind of non interesting
parts but you want to see the second
field and that that's not just useful to
reduce noise so you can actually see
what you and you don't have to search in
a big Tuttle like which is the
interesting part but also it reduces
overhead because the overhead of tracing
concepts of sending messages and copying
terms and if the arguments of a function
are large large terms have to be copied
from one process to the other and the
live system it's very important to try
to reduce the overhead and the impact as
much as possible and then the other
example is like measuring a new match
when an infection it is called with the
list and then only captured the length
of the list because we don't care about
the elements we only care about how long
list it is usually called with and then
the most complex example this sampling
implemented with my specification so we
can see how powerful my specs are there
is something called the trace control
vert in the Erlang VM which is like a
global integer which can be read and
written both from Mad Max and also from
elixir code so this mass spec will just
capture every tense function call so
this is like a down sampling so if a new
map is called I don't know hundred
thousand times it will only capture ten
thousand cause of that but on a
statistical level you can still get good
samples so how does that work exactly so
the first function close or match back
close it checks if the controvert is
nine orrible and then it resets it to
zero and then does the default behavior
which is to do the actual tracing and
otherwise it increment this counter by
one but this message force will
basically silence this code so there
will be no trace message
that's very smart so if you want to
really dig into mass tax which I
strongly advise you can look at the air
long reference manual to like
investigate what what kind of these
action functions are allowed there are a
few more of them also there are some
written about the restrictions of the
body you can find some description in
this MS transform documentation and then
finally we create the or started a wiki
page of some aspects very everybody can
edit it so we would like to try to
gather like useful or tricky patterns
that others can use as well currently it
only contains these examples that I've
shown but I hope it will grow day by day
and then let's see some real-world
examples the first one is the original
one which I called fat request so the
system we've seen like increase response
times and general slowness and so how
that worked is before the processing of
the request there is a preparation phase
with where we fetch all kind of
configuration data for that object from
ETS so from memory it should be very
very fast but actually it as it turned
out some objects had huge configuration
so that's what we saw so this is the
preparation phase we can get some
impression that there are about 200
calls per second 200 requests the
average is down there below 50
milliseconds or maybe even last 2000
milliseconds but actually the 95th and
99% eyes are able to hundred
milliseconds so it's horrible it
shouldn't be like that and then
unfortunately I don't have a screenshot
from two years ago but we did capture
some samples and then we seen that
actually which objects are which have
huge configurations at which part of the
configuration issue it was very useful
because we could go to that team
who configures the thing that come on
here you go you configure these few
things and also we could tell the
technical management that this problem
actually occurs quite often so like
every second there is a few such
requests so we need to do something
about d3 have to fix this other example
it it's it wasn't a performance issue
although it looks like so what we've
seen in the monitoring system that the
maximum load balancer latency was
sometimes backing to five seconds so I
started to use extra to go down from the
handle request function and go deeper
and deeper and then at some level I
found that there are some MySQL queries
so first on the graph it was visible
like how often this happens so it
happens like not even even every second
like a few times in a minute and it is
also visible that all the requests take
5 seconds so you can see like the
pattern like how the system behaves and
then capturing some samples it was
visible that all of them returned an
error connection lock timeout which
looking at the code it meant that there
is no free connection in the connection
pool so the request couldn't even be
sent on the wire so after expanding the
resizing the pool the problem went away
we can see that the request time went
back to normal
like a few milliseconds but this is
generally very useful when not just when
you have like this duration related
performance issues but when you try to
find out what the function returns maybe
it written somewhere or you want to
capture it and you can use it without
like printf debugging so you can just
turn on extra finger on that function
and first you look at the graph so you
can have an impression like how often it
is cold or is it safe to to to capture
some samples or what threshold should I
set to
capture some samples actually you can
even set zero milliseconds and then you
capture all the messages so then it
works as regular tracing like wreckin or
extra tap for these kind of tools and
after you've seen the big picture you
can zoom in then and see actual the
return values and arguments which which
give you some impression like exactly
what's happening so this is kind of the
general workflow you you don't start
with a crop you start with some
monitoring system then you get some
alert or you spot some spike when there
is a issue so you fire up X probe and
then you try to trace some functions you
go usually top down and also check your
source code like what functions are code
cold you can compare two functions which
one is the slow or which one is the
problematic you can use some math
specifications to narrow down your
search and then iterate deeper and
deeper until you find the issue so
summing up tracing itself is a great
tool to use non-intrusive
debugging on life systems extra add some
nice features like visual feedback
safety overload protection and it has
very subtle usages so so please try
extra feedback if you have issues send
some github issues or even contribute
it's available as a hex package and
sources on the top with much that's it
about extra funds thanks for listening
thank you any questions I'm not sure
maybe you've mentioned that but what's
the security of this so you integrate it
with your say web app and then you
you've got a port number that you access
it and is it protected yeah that's a
very good question so it is not
protected it is kind of outside the
scope of this tool so you can you should
put it behind some VPN or some like
Ingenix or something and you definitely
should do that if you were running it on
a web application which has actually
exposed the ports yeah so you should
take care of thanks thank you yeah all
right it's quite talk really interesting
do you do anything for proactive
alerting so monitoring thresholds and
pinging anything yeah no so so extra
fees like a second level so you should
have your regular monitoring system in
place and alarms and this is only like
for ad hoc debugging when you see there
is some issue but you don't see the
details so then you turn on explore and
do some investigation yeah
Oh
do you have any way to look at pieces of
data that take a lot to a large amount
of memory in the in the system yeah I
think we do need another tool for that
so this is more for for like function
calls and dysfunctional aspects and that
part of the runtime yeah so there are
other tools like web server which can
show like which is the process which has
the highest memory or which is the ETA
stable which is the largest so this
requires some other kind of analysis
I'm just wondering what you use for your
regular monitoring sorry but what do you
use for your regular monitoring you're
the top level yeah so in this example we
use data dog but or we used graphite or
yeah there are a couple of other options
I know there is up signal or pry in
which our Alex ear specific like
performance monitoring systems thank you
as well
I was actually wondering whether it
would be possible to send the matrix to
something like graphite or an external
tools when you captured on WebEx both so
so to send the graph or the actual trace
messages the matrix you capture some
numbers for example yeah so actually so
we are actually in the process of
splitting exstrophy into two parts the
UI part which is just the web interface
in the cowboy server and and the expo
core which then would have like an air
long hair long or Alex ear API to export
the raw data which can then with some
cost like with the Jen server or stamps
does the integration it could export the
data but actually the use case for extra
fees it's not running all the time
unlike some monitoring system
it's rather you just fire it up the data
that you see it's only in a one bin one
minute window and then it's forgotten so
it's it's pretty much for live
investigation so you usually don't want
to have it on day or night just for just
to be sure like just for safety on the
production system thank you all right
thank you thank you run of applause
[Laughter]</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>