<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang on Xen - a quest for lower instance startup latency: Maxim Kharchenko | Coder Coacher - Coaching Coders</title><meta content="Erlang on Xen - a quest for lower instance startup latency: Maxim Kharchenko - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang on Xen - a quest for lower instance startup latency: Maxim Kharchenko</b></h2><h5 class="post__date">2012-06-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1FgTjSY8YgU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you everybody for coming somebody
expects me to talk about supercomputer
center oh and so then you are in Iraq
there was a substitution and I will be
talking about Earl and implementation to
run directly on exam so our first of all
I would like to give you some history
some some context so that you understand
how this thing pop out into existence I
was actually I almost had no connection
too early in my professional life my
professional life I was a Salesman using
developer and actually never almost
never did any programming but on my
spare time I quite a good chunk of my
spare time I was planning on
implementing new airline commercial
machine I did it for probably four last
seven years and culminated in a few
versions of complete realization of
machines implementations some of those
actual visual machines they're open
sourced so you could look at them and
the last two versions I was targeting
them so I
cited so let it will be cool if Earl and
virtual machine is capable to run
directly on them without without
greatest
it's just very original expired so that
you have a look at the Earl and is a
system including runtime so it resembles
a full-blown operating system very much
so you've got all these processes you
got the complicated driver subsystem
applications running on top of weights
and you even got the shell so it makes I
think that it makes everybody wonder why
do we need another layer of an operating
system underneath the early why not just
to use her Lane as an operating system
so that's my way of thinking was a for
quite a while for a few years and
probably two years ago I started to
really put effort into this into this
and this actually what I'm describing
today is the second question which runs
on own curriculum
another motivation to have to have early
and run directly on them was the
existence of so-called slashdot which
affected me personally I was as they say
slashdot with my with my another startup
i created this very very cool
verification and after it was getting
steamed so then it was like you knew it
was mentioned on various websites like
and a huge traffic was decided to float
and iphone to my web app and it just it
was after after minute because it was
there and it happened a few times so
probably I I just didn't I wasn't able
to capture even a small portion of those
visitors they're supposed to get and it
annoyed me quite a bit and I think how
to make the infrastructure was using
mana and definitely the the web
application was written in early so I
thought how to make it more and more
nimble or easy to just to run not just
run but easy to bring in more instances
so that's the here you got the this
depiction so that's essentially you may
you may think that the that's the
traffic for your web application just
the right is linear with the soft always
is not always the case for must always
not the case
yeah so the traffic rising spikes and it
just after a spike you've got the new
level but if you are not able to capture
that spike sure essentially you got the
yo-yo will be back on your initial
initial level so that's just very
difficult to tackle this this thing with
the existing tools and technologies so
that's two motivations for 44 to run our
main directly on them Berlin is a kind
of quasi operating system itself and
another thing is that you need to really
tackle this unit to be able to bring in
more instances within reach this short
period of time so you want to keep to
make to have your infrastructure very
lean in during this period when you are
not sure that whether your your
application will get traction at all so
you don't want to spend ten grand a
month to keep a redundant such key but
after it gets traction you want you to
really scale it very fast and it's that
this is the the additional layer of
operations system kind of guessing work
so this slide is humor eyes whatever
what I've just said so I i believe so
that the shared shared IT
infrastructures for for applications the
ec2 or google app engine is not they did
not live up to their promises so they're
they're promised so that you just start
low and then you just add more capacity
when you need it you just don't have
enough time to bring in more capacity
than you really need so i think that
this is just it is really the broken
promise and this whole shared
application environments they should be
they should really think how to make
things much more much more scalable okay
so everybody's talking about scalability
and and then contingent at the little
this tradition just a few internet ports
from just a random holes so that i don't
know how to remove it but it says that
typically it takes 40 seconds to start
on your instincts on ec2 and if we are
talking about Winston with Windows
instance it may take 40 minutes so you
will be well after this fight and all
your potential clients will be
disappointed that you're a website or
application is that
okay here we go so just colors not that
good so this is a typical typical
software stack so everybody looks like
these pics grams they symbolize that the
schedulers and memory management and
input/output subsystem so just very high
high level look at this at the software
stack as it is now definitely makes one
wonder why we do we need so many layers
of schedulers so many layers of memory
management so many letters of drivers
input/output items why not just get rid
of something what I did that I just get
rid of space layer and I just have early
on xen hypervisor is now it's not just
any hypervisor about Sam and we got
applications we should not again not any
applications for killing so what I'm
just skipping right to the results of I
obtained so whatever water is water
whatever was targeting I'm where I was
when I was developing this thing I was
really watching so with how I can shave
another millisecond from this startup
time how to make it so that's how to
make this time between the they said
time between the underscore start label
is heat until the first erling comment
is executed so this time I was trying to
make it as short as possible and on my
machine it's usually a less than
100 milliseconds so from the first
comment in a you know Colonel and until
the first Earl in command is executed I
don't know what was the exact figure 4
for this whole thing which is includes
linux and beam and all this but I expect
this is a war like a hundred seconds so
I I would think this this difference is
orders of magnitude or the two orders
money probably even three orders of
magnitude so so my startup latency is
very very very small but again this
preliminary these results are
preliminary and because of that just to
compare apples to apples oranges to
oranges first of all I need to complete
this system it's not it's not yet
complete so development started
September last year and it's kind of I'm
getting close to to having to heaven to
heaven shell standard
Earl and she'll Eric it's quite close
today
as I said that if we just break down
stop and start up latency as it is now I
will see that most of it most of the
most elite latency eight percent of it
is spent setting up page tables probably
this can be reduced by by delaying page
table set up to some later time so still
I think could be optimized by the first
date but the first snapshot of what was
going on now most of the time you spend
on that page table top 15% they spend on
a on a set up of nine hundred and metro
tribe and they anything else is quite
quite quite small so I don't think that
it would be it or should be optimized
any further
so now the most interesting thing so
this just demonstrates where I am in the
process of making this new thing mhm or
a viable alternative to length multiple
so I selected a subset of of standard
standard emulated tests because some
tests some emulated tests they are quite
quite obscure and they are very specific
to you being so I'm not tasting those
I'm tasting things like that are in
documented in documentation adjust i'm
testing what's what's important for for
development so here we got this this
list of tests and so I I just think that
this is the where I now just I'm mate
like we're kind of fixed all the all the
bugs which revealed by by all those
sweets as you see that this binary
binary sweet was quite quite tough I had
to skip a few
if you test because of that because they
were using some undocumented features
within being on one side and also they
used files for testing and my I decided
for myself so that I do not change tests
so I just have tests as they are there's
just like copying them from from all TV
so I was always changing my system to
run the tests and you mean you see that
I have three tests failed but these
failures are a one failure is a from our
because of the one of the beefs is not
implemented a portable cash to is not
implemented yet another thing is that
there is a quite often I got out of
memory thing because my I limiting the
virtual machine to to some reasonable
size because I'm really targeting much
smaller smaller racial machines so I
probably most of the test will run in 64
megabytes of RAM and some of the some of
these tests we would require 1 2
gigabytes to it just depressed I'm not
doing that
and we got 10 more switch to go okay so
what else ok so how it looks from from
inside I guess it has quite quite a few
interesting things cuz I'm was not
limited by maintaining backwards
portability or maintaining existing
clients that would what Erickson is
doing in many of people from the
communities have to have to take this
into account so there is no constraint
like this for me and thus for instance I
I got rid of of the code transformation
during the Cold loading because because
in in standard beam then the the bin
file and module getting gets loaded it's
just the format the instruction set in
in the bin file is very different from
what you've got in that in a virtual
machine and this transformation is made
right then the holding build it so it
just takes time and adds to startup
latency but also but also this engine
this transformation engine is in itself
a virtual machine which is you know
children complete and similar to to
prologue so you got you get a virtual
machine for for early and on the side
you got a semi prologue virtual machine
just for code transformation so I got
rid of of those so all my my code is
transformed statically and just just to
ensure the
it's loads for first another thing I'm
kind of proud of is a dynamic
instruction specialization which is
which is the particular set of
instructions for for the folder virtual
machine is not fixed and it's not known
beforehand is it's a there is a step in
when you build this system then you can
give it a large number of bin files I
use all the bin files from our OTP
distribution and I just analyze it to
understand what specialization are there
should be there to make called smaller
for instance you you have AB you have an
instruction which loads a literal value
into register 0 and after analysis of
always being files you understand that
it's better to have a specific
instruction which Lords a zero value to
to register 0 so then the system will
generate automatically a special
instruction for for that and a new
implementation code will be generated
with just whether we just plugs this the
value zero steadily so we just I guess
that the result of all of these is that
just the code is smaller and it's if
something is small and transmitted
because of the you know cash
issues okay next so nothing no almost no
inputs like nothing no no external
libraries exist so there are a few a few
routines I just pulled out of internet
like you know men popping or some few
things for for floating-point
manipulation because 14 point is kind of
just too many small things and I just
like to do that but I just it would be a
waste of time so I just poke it things
like that but it just probably like 57
external routines nothing nothing big so
everything could be reimplemented just
to to remove all the all the
dependencies like that another thing i
did and i'm pretty sure that that that's
that's the way to go is that I got rid
of tcp/ip stack because my my previous
version which run also on them rather a
tcp/ip step implemented as a making
as a imported from external library and
I'm was never satisfied is that solution
because of that because this it happens
that this tcp/ip stack has its own
memory management has its own you no
errors and you don't know how to recover
for them and essentially it's a tcp/ip
stack is that kind of reimplement ation
of certain portion of Berlin one once
more so why do one need that so I
decided just to to do all this always
the network stuff with inner line so one
of the things i wanted to do to to be
ready to be able to do is to use this
famous IP datagram parsing but i like to
use that and also early the this virtual
machine is for smaller for smaller
instances it's not for four huge 616 or
servers it's just for one sixteenth of
that for her go of that server so only
on a typical server you will have eight
of those for those sometimes dozens of
this based machines right so an a and I
thought that probably they do they will
not need a tcp/ip networking at all
running on the same machine so what kind
of router do you need so probably just
different protocols that should be
in for it so nowadays I just receive
ethernet frames from from my natural
charm front end of the network driver
which is talking to a backhand inside
them okay the currently code is very
dependent on being 32 bits and just for
x86 this is just
yeah this is what what what I got at
home this is there I can blow up this
thing and I think it's quite hours quite
quite quite a bit of that where they
stayin my rock the size of the code
studied for the UK lines of code mostly
seed samsung early it's quite quite a
bit of code generation is going on in
stages so I don't like that I always say
that if you if you got if you have code
generation in your system or probably
you're just using the wrong tools but
for for system which is kind of a
grading system funky called Colonel
thing I think that cogeneration extends
to code generation is quite in evitable
again no code was borrowed from early 90
but I had to look at it just to
understand this man various
so what's what was my vision for for how
is this whole thing can be applied so my
vision on this kind of change in because
of I'm talking to people here one one of
the agents that may may shift this this
vision by current vision is that it is
possible to build a super elastic
computing fabric for our land use on
this kind of
so the uniqueness of this fabric would
be so that you may have no instances
running before the actual request for
service usually HTTP request arrives
into your system at that point of time
you will have enough time probably 10
milliseconds to fire a new instance and
to set up at and reconfigure it and then
let it service the client's request I
believe in a just I had studied that I
mean it was probably a spender good
couple of weeks on rescissions so that
that the the infrastructure for for
things like yo ho or App Engine could be
reduced ten times without any compromise
to the you know responsive the
responsiveness for performance of the
client
so that I'm thinking so that it's
possible using this kind of thing to you
so I believe so that it's possible to
using mr. Landon's a very lean small
virtual machine to decreased by decrease
the infrastructure
yes really good yeah you are absolutely
right so what what I'm autumn was
focusing on I was focusing on on the
agency within within the colonel within
my colonel but there is also the latency
associated with zen itself because of
their they they the Zen is built about
with the assumption so that you are
going to run linux within within a
container so it may it's very lavish
when it comes to using you know bash
scripts to set up an instance so
definitely this this site should be also
dressed and probably some direct library
calls should be used to fire the things
but i didn't get to do that here it will
be available after give up trying to
make something too much water so but but
you may have a look at my previous
versions I don't hope it so if you could
write it down so it's a te e RL now te
et erl so let's name of the order of the
product so so it's a the last open
source version today because it's has
very little resemblance go to this newer
it's also quite small it's quite similar
to what you it's like a templating for
for website so i just use the same thing
i generate the code using the templating
engine which is supposed to be used for
generating websites I mean HT for
generating C code just later combined
yeah you thought I'm just on generating
something oh and just it's all all
planes C code what it just generated in
in multiple steps
where
accessory
yeah yeah i do understand that got up it
is more offer you know similar to lease
priming lease and this is practical
thing and it's not a computer
theoretical so I 'not Lee there is no
there is no C library so I was
considering not using ASCII codes for
that I just do daleney teske calls here
I could devise anything I mean I just
there is no no no limit so I decided
yeah I think that this print it's more
or less the best thing I mean just best
best thing out of what I was able to two
made up myself a ski but no UTF on a
kind of sea layer definitely all the UTF
is done because Earl and is everything
is mostly over land just then there is
always almost always there's a few if
you just various very specific
exceptions there is always a known
context within a system so what what
what process you're executing right now
so there is no no almost no places then
you hit no memory situation and you do
not know which process you should should
k so this this system has a very
specific behavior with respect to no
memory condition so it's I believe this
is not so for for bin and also it's it's
impossible
to make defining behavior form for no
memory in a systems like you just to
begin to to too many dependencies too
many things memory and it's just I hate
to see that being the freshest it
shouldn't rush it's the whole thing is
wealth not crashing then you resort to
to to bash scripts which we start beams
abomination ed the idea here work will
be applicable to the FCP yeah so again
the direction is kind of shackled
weather with a necessity to to to
support all these existing installations
so it just will be very very difficult
to them too I am quite sure so that
whole bunch of smart people there and
they they do understand all these things
they just don't have a room for this
kind of freedom so they would do that
these things immediately if they would
be allowed not to disregard all this you
know existing plans
i I just I have a what I have today is
they just the thing which receives
ethernet frames well they what I know I
haven't done it yet so that there is
exist there are a pure early
implementation of tcp/ip step I will
just take notes but then I this is not
complete I will I would like so that
first the virtual machine should I
should go through all these conan cases
and have the older tests so I'm homes
there in life I just I'm working on
tests so it may probably take me another
couple of weeks months to do that but
after that the shell will will be
runnable so it's already all the all
these tests you should understand so all
these tests are huge in terms of what
what they do so they touch everything so
essentially what they do is I kind of
bring up the shell and then just do
something so it's not i think that the
shell will be not a problem it's all if
if that's
no and I'm not going to because I think
that just do your thing good and I
believe that so I want to make it very
small very reliable and also the week i
got them which takes care about the
scheduling things on a multiple
processes just so i could delve into it
but I just unconsciously don't touch
that because there is not not because it
is complicated but and just not needed
for this kind of thing
I don't think I understand what's yeah I
i want to to be able to fire thousands
of instances within one second and
adjust to have all this request coming
up to all instances I do not want to
single instance to to to have more force
to spawn more processes inside of it it
was because inside of that you just this
you have this small box and you have for
instance eight cores okay you will will
be able to scale 28 pores but what's
what's next what if you've got not not
eight clients coming in about eight
thousand plant so definitely needs to
kind of break out of this you do not
need to worry about the course for
voicing cleanses needs to be able to
just to fire them this is the same ease
as you fire process
we have any other questions
okay great thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>