<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Stefan Karpinski - Julia: Fast Performance, Distributed Computing &amp; Multiple Dispatch | Coder Coacher - Coaching Coders</title><meta content="Stefan Karpinski - Julia: Fast Performance, Distributed Computing &amp; Multiple Dispatch - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Stefan Karpinski - Julia: Fast Performance, Distributed Computing &amp; Multiple Dispatch</b></h2><h5 class="post__date">2014-01-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rUczbQ6ZPd8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right um since we're already running
late and it looks like a fairly full
room at this point I think I'll start hi
I'm Stephan Karpinski I'm presumably
you've heard of Giulia if you're here
otherwise you're in the wrong room I'm
one of the co-creators of this language
together with Geoff Bowes Anson and burl
Shaw we started this project and back in
2009 based on our own personal
frustration with the existing tools in
the numerical and technical computing
space so we you know I think we're all
what you could term you know expert
MATLAB programmers and have a sort of
love-hate relationship with MATLAB and
our patron at MIT Allen Adelman is the
fourth name on this on this list is
actually the first he was the first
commercial the first user of
commercially licensed matlab's so he has
a very long and very mixed relationship
with the language because he keeps
trying to replace it and really it looks
like it might actually be succeeding in
that direction where his other efforts
have not didn't quite pan out so without
without further ado I'll get going with
my talk so this is an interesting space
this is like a very different sort of
comparison and language space than
everything else that's going on at this
conference I think the things that we
get compared to often is you know our
matlab mathematica Sipe i I mean some
other smaller names that you you you
know may or may not have heard of but
it's a it's a very big populated space I
mean they're sort of like almost as many
things in those like general programming
language space as there are in this like
niche area of just technical computing
systems so one of the obvious questions
to ask is you know what what actually
makes one of something a numerical or
technical language so the obvious answer
is there's just something that
specializes in numerical work right
that's you know the sort of obvious
thing thing to say about that
and that that sort of sheds a little
light on why there are so many things on
that I in that picture it's because
everything specializes in a particularly
you know its particular way so for
example you know MATLAB the idea of
MATLAB initially was that it's just
everything is a matrix of complex
doubles and that's actually a brilliant
brilliant type system until you have to
do something else
until you have to use something that
isn't a complex you know a matrix of
complex doubles and then all of a sudden
you start having you know current trying
to cram like make strings into some sort
of array which is weird because you only
have matrices so they're actually not
even one-dimensional arrays they're
actually two-dimensional arrays of
characters it gets very very awkward
very quickly in are there's sort of this
this very you know complicated data type
of a data frame which is sort of one of
your built-in fundamental types and
that's that's a little strange to have
something so sophisticated I'm the only
other language I can think of that has
something so complicated built in as a
basic data type as PHP where they're
hashes are really this like sort of
crazy amalgam of you know many different
data types in one and another
fundamental design principle here was
the idea of supporting representing the
fact that you have missing data at a
very basic level so anything in our a
floating-point number or a or an integer
or string can be na which means not
available it means you know we didn't
have this data and that's important and
treated specially in various analyses
and in appropriate ways but this
complicates your system in a very deep
way right because you you now can't just
add two floating-point numbers now you
have to look at them and be like well
was one of them na which so the hack
they use there is Steve man for that but
you can't use nan for integers for
example so what they do instead is they
use the minimum you know the negative
integer value the one that doesn't have
a positive you know a positive you know
pair is is the special na value but now
that means that every integer operation
has to be checked right you have to like
look at it and be like oh is it this
special value if so do this thing if not
do an actual regular operation so you
pay this cost of overhead it's like
we're
to optimize things as a result
Mathematica is interesting because it's
not really a numerical language it's a
symbolic language so it really takes the
idea of symbolic computation to its like
logical conclusion and I think it's
because everybody has their own angle
that they're approaching numbers and
numerical computing from that you have
this like explosion of things on that
previous slide and what and why people
come and you know make a new one because
they they have they're like well you
know that's not really the angle I was
looking for so the question is what
what's Julie is a numerical specialty
and and the key answer here which may be
surprising is that we don't have one we
don't we don't make any of those sorts
of decisions we're not looking at a
particular numerical angle we've sort of
have stepped up a level and said well
what what do you need in a language so
that you can define your own numeric
types and their own behaviors in the
language itself and so instead of baking
them in we're going to give you all the
tools you need to make your own and you
know this is the question is why is this
hard you know why hasn't anyone else
done this previously I mean people have
tried and fortresses actually a really
good example and they came to a lot of
the same decisions that we did not
because you know they obviously didn't
copy us I don't think guy steel has ever
heard of me but you know the fact that
we came to the same conclusions is for a
reason it's convergent design so this is
your numbers seem really easy right they
they seem pretty basic but they're
actually really hard surprisingly
difficult a huge huge amount of the code
and specification of pretty much every
programming language ends up being
devoted to numbers and arithmetic in
their behavior and just you know I'm not
just talking about things like on that
you know list of numerical languages
those obviously like you know they
special case you know they're special
for numbers they're supposed to be
numeric so it makes sense that they have
a huge amount of you know special case
stuff for numbers but you know even
scheme and C so I'll come back to the
slide in a second but just one take a
look at this this is a table of contents
for the
RSR 6rs spec and it looks you know
there's a lot of different material here
it's a very like notoriously simple and
concise language with a you know a
relatively small spec this whole trunk
here is all numbers and that whole chunk
over there
this looks bigger but that's just a you
know visual artifact that section there
with arithmetic and boolean the
arithmetic every other section of the
base library is like at most one page
right that one is nine pages it's you
know Garg it's you know the giant among
among dwarves and it's just it's you
know much more complicated than you
would necessarily anticipate it being
the same thing this is about it ends up
being about 20% of the spec is dedicated
to numbers and arithmetic I was hoping
for like 50 when I started looking at
this but you know K 20 is still pretty
big and C is about is similar it's about
20% so the kinds of things you need to
special case are well I mean the obvious
one is syntax right numbers have you you
want special in fixed syntax for things
you don't want to write necessarily plus
of you know a comma B you might want to
write it that way sometimes but you also
want to be able to write a plus B you
want to be able to do exponentiation and
various other things if you if you've
tried writing out a polynomial in s
expression syntax it's it's very
difficult to read it's certainly much
harder than the mathematical notation
that we're used to but we also want
special behavior so in most languages
operators are not functions they can't
you can't write plus as a function so I
mean C is a good example right the plus
operator can take you know functions can
only take a fixed you know set of
argument types in C there's no
polymorphism whatsoever but plus can you
know you can add an int and a float and
a float and a float and a internet int
and all manner and even see 99 you can
even throw a complex number in there and
there's the read that's why the spec
gets so big it's because there you have
to bake in these rules for how those
things promote and how they
combined I convert between them so this
polymorphism is sort of baked into how
math mathy things work you know indexing
in mathematic is insanely polymorphic
just doing basic things like addition is
also a couple other sort of interesting
things that you know numbers are
naturally immutable there was a bug in
an early very early Fortran compiler
that allowed you to mutate integers so
what this meant is that you could assign
a different value to the number two and
then anywhere you use to you would get
that value and I mean obviously you're
like that no you can't do that you can't
change the value of two two is immutable
two is two so I think no numbers are
really the prototypical immutable data
type so if you're going to want to
define your own numeric types you want
to be able to express the fact that
they're immutable otherwise you're going
to have you know you're gonna try to
define complex numbers and just
semantically it's gonna be weird because
you you know if you use copy don't use
you know full copying semantics you
wanted to use reference semantics like
you know scheme or Python then you're
gonna you know make a make an assignment
and then one you know Z is equal
something W equals Z and then you change
the imaginary component and they both
change no no that's not what I wanted so
you want immutable types you also need
to represent them compactly and and well
I'll get into sort of how we address a
lot of these different things with the
design choices in the language there's a
couple other things just to make things
interesting that scientists and you know
people who do numerical work want they
want extreme convenience they do not
want to mess around with making your
type system satisfied I mean some people
are okay with that but a lot of
mathematicians and physicists that I
know would just like not put up with it
for two minutes so it's not gonna happen
they want code that looks like pseudo
code they want you know they want FFTs
baked in and like Biggins and all this
other stuff baked in that
to come sort of standard shipped with
what the thing they download and they
want really really good performance so
that's you know this is a bunch of
interesting things to try to satisfy at
the same time traditionally the the the
way we have gotten performance and this
sort of high level thing is to have two
languages right so you you have your
high level language and then anything
that's performance critical you
implement in C or Fortran and that's
actually a really reasonable compromise
and it's worked very well for a long
time there are a lot of benefits to be
had from being able to write things in
the high level language as well one of
the ones I didn't anticipate being as
powerful as it is is the fact that
because most of the language is written
in itself people get suckered into being
developers so they're just they come as
users so a good example is like numpy
right MATLAB is not a good example
because you're not allowed you can't
modify my MATLAB legally but numpy you
totally can
you're allowed to go in there and change
it and they welcome that I'm like RR is
actually like kind of very much it's
very hard to submit to are for like
totally social reasons but with numpy
they welcome it but when I was at SCI PI
one in 2012 I expected because they're
like you know so many people using
sci-fi that it would they would have
tons and tons of developers and it
turned out they don't there's only like
you know three or four people who were
qualified to actually hack on the
internals and that's because it's this
like crazy crazy C code that's not just
C code you also have to know C Python
and you have to know how numpy works and
you have to like it's just so much stuff
you need to know and we've had people
contributing core pieces of
infrastructure after like programming
julia for like two weeks with one guy
Carlo Botha so you came and you know
program Julia for about two weeks and
then wrote a bits type array in which is
packed packed boolean array that just
uses one bit for per boolean and you
know it's a complicated piece of piece
of work and he's a very good programmer
but you know he didn't have to be you
know steeped in like you know many many
years worth of knowledge to be able to
do that
so just a design overview of the
language and I know I made this too long
because it does not fit on the screen
all at once
Julie is its high level it's dynamic its
high level of meaning that you know you
can write a times B and it could either
be it could just be you know two
integers being multiplied but it also
could be like huge matrices that are
being multiplied or it can also be you
know a distributed matrix that's living
on a cluster of like a thousand machines
and you're multiplying it by another
distributed matrix so that that's very
high-level at that point if you just you
know write a times B to makes that much
computation occur it's dynamic I think
we all kind of know what that means
gonna talk about a little bit more in a
second it has an unusual for dynamic
languages it has an expressive language
for talking about types so I mean all
you know dynamic languages if you say
they're untyped that's just not true
that it everything has some type you
just don't have a way of like expressing
it in some languages you do Ruby you
know in particular and Lisp they have
you know first-class objects which
represent the types that things have but
you still don't really have a good way
of talking about it very much you can't
say that something is of a particular
type so we have a fairly sophisticated
system for that you know if you're
really into type systems a parametric
dependent the the parametric is is
invariant not covariant and
contravariant concrete types are final
that's actually turns out to be very
important if you have an implementation
of something you can't subtype it it
sounds restrictive it actually turns out
not to be a big deal it's surprisingly
you know because you can make out
various abstractions and write code to
them over that you actually get pretty
much all the things you wanted from
inheritance anyway because you can
inherit behavior the only thing you're
missing is the ability to tack a couple
of fields onto something which is really
usually not that useful anyway one of
the design goals was to make it
unobtrusive so if you want to write code
that does not mention types at all
you're totally free to do so and it'll
run fast and it
is not a problem at all it the type
system is only there for the cases where
suddenly need to express the fact that
this array only codes holds
floating-point numbers and therefore you
can represent it compactly and you can
it has the same layout as LA Packer at
TW or something expects multiple
dispatches although is top to bottom so
everything you interact with you know in
the normal course of programming every
function is generic it has you can
extend it you can for example take you
know the built-in plus operator my
favorite operator keep talking about it
you can just add new methods to it so it
can operate on new types you can you
know make new different combinations of
things work no problem
everything's open that's sort of the OO
heritage so the trick there of course is
making it making it fast enough
we have served fancy things that
multiple dispatch systems traditionally
don't have I'm not going to talk about
it now I'll talk about it in a second
we've quantified methods in diagonal
dispatch
but metaprogramming I actually don't
really think meta programming is all as
interesting as it's cracked up to be
I just think there's no excuse not to
have a dynamic language would be home
electronic there's like no design cost
you can just do it and it doesn't cost
you anything on the flip side it's a
little bit of complexity in the language
but it's it's not complexity that comes
at any expense it was like there's no
performance trade-off for example it's
just like the way you really want to do
cogeneration concurrency and parallelism
I kind of have to mention this because
we're you know we're at a very
distributed systems heavy heavy
conference here we go routine based i/o
and a distributed global address space
so you can sort of you can have
references to things on other machines
and pass them around I was I was during
the during the the keynote this morning
I was sort of thinking about how nice
all of these immutability and
concurrency approaches that Erlang and
other other similar languages have and
wishing we could have them we can't
because we have a very different reason
for distributed computing we
is that we don't tip you know you have
so much data that you can't fit it on
your machines so you need to split up
the problem across 100 machines just so
you can load your data into memory and
at that point obviously making copies of
it or have it you know just appending to
it is not an option you can't do that
you actually have to mutate your data
just for performance and overhead
reasons you can which is unfortunate I
really wish I love I love the approaches
that are lying in clothes or take with
that sort of thing but it's not not an
option for us I'm afraid so just to get
a little real here I'm gonna look at
some code so suddenly we have a lot of
performance tests so these are actual
this is our performance well maybe I'll
just look at the the webpage if you
haven't looked at this this is some you
know these are actual performance
benchmarks that we time and this is sort
of the the untyped unobtrusive urgent
which looks a lot like matlab where you
just you know define a function this
computes one point in a Mandelbrot set
you you know give it Z which is some
complex number presumably it could
actually be anything because we haven't
typed it so so apply to anything the
expectation is that it's kind of a
complex number and you just write you
know your little loops and return stuff
and you know take some squares and add
stuff this is more MATLAB even more math
that you wouldn't want to do this in
MATLAB you could do it but it would be
really slow because MATLAB is not really
good at for loops and such things this
runs at C speed and Julia so it's you
know you don't you don't have to mention
types to get the good performance this
is just some matrix manipulation you
generate some random matrices take some
powers and traces and whatever and you
know it's within 2x of what you would
write by hand coded see that was
everything sort of an optimal way but
then there's also very different styles
of of coding julia we have these one
line function definitions that
you do a cool like you know you very
common to write very small definitions
which is very uncommon in in MATLAB for
example because they require you to make
a file for every single function so you
sort of like cram everything into these
huge sprawling file that functions we
have tons of very small definitions like
this another example so if you want to
define your own your own type so for
example complex numbers are just defined
rather simply in the language so here
you see immutability in action this is
the declare is an immutable type it's a
complex number and then the this
declaration says it takes a type
parameter T which is some kind of real
type so there is actually a complex type
for every real type you can you know lay
your hands on even new ones that you
happen to define later
this thing is itself a type of number it
has two fields re which is of type T and
I am which is of type e so this have to
be the same real type it's sort of usual
programming stuff and then we provide a
couple of different ways to construct
one of these guys and this this will
I'll talk about this a little bit more
later this promotion system this is
really this is just a function defined
in Giulia that takes two objects and
figures out what a common type to
promote them to is and then converts
them to that type so a lot of very
generic things can be done with this
this you know allows you to do stuff
like well this is to two reels that I
want to turn into complex right so if I
have complex one and you know 2.5 I'm
going to get a I'm gonna get a complex
float64 whereas if it was just you know
1 &amp;amp; 2 they're both integers so now I
have a complex integer and that
promotion system applies so that
definition actually applies to like you
know new things that haven't been
defined yet so if I defined a new real
type and I explained to the system
through a couple of method definitions
how to promote it and how to convert
it suddenly it'll just work and that
that's that's very handy and extensible
and it's great for people who do
numerical computing and do actually want
to do things like to find their own
numeric types and have them be efficient
have them have the nice syntax that
you're used to from everything else all
right so why dynamic typing I mean we
sometimes quip that Julie is dragging
MATLAB programmers halfway to Haskell so
why not all the way to Haskell and like
I mentioned before I think I don't think
I could convince most mathematicians
despite the fact that they you know
they're mathematicians and you would
think that they would love the Haskell
type system I don't think I could
convince most of them to actually put up
with the type checking there's also the
issue that when you're working with data
you really really want this exploratory
interactive tangible property of it
right when you're when you're you're
typing things into the repple I want to
say that you know you know a equals R
and then I want to be able to just sort
of do this and see what the result is
immediately I know it's the same thing
in principle is writing a C program that
does this but it just feels real to me
it feels like I'm touching the data and
that's really really essential to this
kind of work and that really sort of
dictates a dynamic language Scala does
an amazing job of being having a repple
and being sort of feeling dynamic
despite being static but I think that
being react chilly dynamic makes is
makes this less of a problem
you know dynamic languages also have
this property that the customer is
always right the program will just say
like okay you know that seems like a bad
idea but I'm gonna try it anyway and
we'll just see what happens you can do
things like have a function that
sometimes returns an integer and
sometimes returns a string okay if you
really feel like doing that and it just
kind of gets out of your way and lets
you move on with your life we we are
actually so I really like this quote
Leah Hanson was a hacker schooler and
while she was learning Julie she
observed this she kind of had this
epiphany moment where she clicked and
she got it and she was like aha Julia
uses the type system and all the ways
that don't end up with me
arguing with the compiler so for
performance for documentation for for
expressiveness for dispatch so being
able to express complex polymorphic
behaviors but never in the way that says
the IU can't do that no no it'll always
just say yeah fine we'll do that and
we'll see how it goes if you don't call
this code it won't be a problem if you
do call it and it's broken then it'll be
a problem she's actually working for a
master's thesis on what we're calling a
type critique er just sort of like a
type checker but is hands-off it'll look
at your code and be like yeah this might
not be the best idea this is probably
going to be a no method error this is
probably you know going to fail for
whatever reason or or a crucial one is
that for example you you know a loop the
the type of a variable changes over a
loop that's a terrible performance trap
and even if you do optimize we there are
tricks we could do to optimize it but
it's actually a bad idea because usually
it means that you also have type
instability so a good example of this is
so so let's say okay so T equals zero
for I equals 1 through n T plus equals 1
over I and then we just return T okay so
you know you okay that's good this is
actually a performance trap because the
type of T changes over the course of the
program initially it's an integer and
then it immediately becomes a float so
we could actually do fix that by peeling
off on the iteration of the loop and
then the like main body of the loop
would just be consistently float but
there is always this case where it
returns an integer so we're actually
just hiding a deeper problem which is
this function returns different types
and so even though you're allowed to do
that you don't want to do that because
has terrible formal rooms properties and
it sort of has implications that sprawl
out through the system if you have
we typed functions and that's one of the
things we've done with the languages
like be very careful that the entire
standard library has good type behavior
even though it doesn't have to which
which is you know a design consideration
that was not made when most dynamic
languages were designed so a little bit
about multiple dispatch the way it works
it's actually this is basic multiple
dispatch if you've used any sort of seen
any sort of multiple dispatch languages
this will be completely normal
F of writing a colon colon any says that
a is of type any but everything is of
type any so that's actually equivalent
of just ill just leaving it off so this
is you know this is the same as that
nothing different you can say I I want
when a is a number and B is a number I
want you to call this version of F and
it will return the string a and a and B
are both numbers you can do less
specific things like if a is a number
but B is whatever it's for type a is a
number implicitly even though there's no
negation going on because we won't you
always call the most specific version if
B is a number this will not get called
because the first thing will get called
and likewise if you know a is a number
for this fourth method you know if a was
a number for the fourth method it
wouldn't get called because you call the
first one and then you can do more
specific things like if they're both
integers to do something else so you
know the obvious thing here you just try
it out you're like okay those are both
numbers okay a is a number B is a string
so we're calling the correct method a
and B are both integers it's as expected
neither of those things is a number or
an integer so it's just you know gives
you the fallback crucially these this F
is a is a single first-class object you
can you can pass it to other functions
like methods is just a regular function
that just prints you know shows the
methods of F you can pass it around you
can assign it to another very
you can you can do all the like
functional programming things with it
that's the functional side the
object-oriented side is that it's
extensible you can add new subtypes that
it applies operations to and I'll talk a
little bit more about that in a second
some fancy things we did we do we've
never added any feature that was fancy
just for the sake of fanciness we
encountered this because we were trying
to define numeric behaviors in the
language and we needed it so this is
this is what we call diagonal dispatch
and I think we just made up that name
because I don't think any other language
has this feature so what this method
definition says is it says F where F is
a method parameterised by a type
parameter so for all T where T is some
subtype of number defined this method F
for you know where a is of type T and B
is of type T so the difference between
this and the above definition where we
just had to am having scrolling issues
where we just had a and B both be
constrained to numbers is it that these
have to be the same kind of number and
that happens like pervasively in
mathematical stuff where you're like I
know how to do this operation if they're
the same type of thing so not the same
type of thing I have to do something
else I probably have to promote them and
you know your C compiler is doing the
same thing it just it has rules baked in
to do it it knows that in order to add
an integer and a float I need to convert
the integer to a float and then do the
addition there's no add an int and a
float instruction that doesn't that
doesn't exist so we can we can see this
in action I give it two big floats and
it's it recognizes that a and B are both
big floats and calls this method instead
of the more general number method you
can see that for integer begins it also
works but in this case the integer rule
is more specific because if you look at
the sort of space of possible
combinations of types that is strictly
more specific so we call it doesn't
apply to strings because we had that
number constraint it of course doesn't
apply when you have only one argument
yeah okay so any questions about that
oh the reason it's called diagonal I
don't know if this makes sense to people
if there's if it's clear why it's
diagonal it's if you if you have a table
of the tight the possible types of a and
the possible types of B the things that
this actually will dispatch on are the
things down the diagonal so that's why
it's called diagonal dispatch
vard methods for arcs functions are you
know that they've taken a variable
number of arguments like printf and see
these are a compiler implementers
nightmare but they're really really nice
everybody really likes interacting with
them so you have to have them pretty
much for for the sake of your hat
programmer happiness so this is this is
a definition to to method definitions I
apologize for the rap here you never
know what's I screen you're gonna be on
the first one says that I'm gonna have
zero or more arguments that are all
numbers and then I'm going to do this
thing and in inside the method body of
access to args as some sort of you know
iterate iterate Abel collection of of
things often a tuple but it can be other
things too
the second method definition is subtly
different again it's got if one of these
parameterised method definitions it says
F for you know for any T that is a
subtype of number I want to have F with
zero or more arguments that are all of
type T so the difference here again is
that it's like and you know
n-dimensional diagonal it's only applies
if they're all of the same type and so
we're gonna you know one of them is
gonna print heterogeneous any elements
get a predicament homogenious I'll leave
this one out for a second
so you can see okay if you only have one
argument obviously it's homogeneous
there's nothing to disagree if you have
three arguments and they're all in then
you're good it's a it's you know trinary
homogeneous call if you throw a
floating-point number in there now you
have a heterogeneous call there's no
magic promotion ever happens promotion
only happens if you have
for it so in this case it's just you
know this this these are different types
of objects this is an interesting case
zero the zero area has to be
heterogeneous and the reason is because
there's no way to bind T to anything
because you don't have any examples of
it and so so you if you you you can
actually use this T parameter is just a
like runtime value inside the method
definition and so we wouldn't have
anything to bind it to see that that one
can't apply so technically this one is
actually one or more arguments because
there's no way to for it to be zero
which is why you could if you wanted to
change that behavior you could just you
know go like that and add it back in now
you get if you prefer that to be the
case introduced method is still more
specific you know non numbers don't
don't do anything because we never have
we've always constrained it to be
numbers so it this multiple dispatch
thing is actually really convenient and
I think one of the things I realized I
was looking at Ruby and I was like a
bunch of these things are actually doing
multiple dispatch except they just like
you know they baked it into the standard
library and they did it with like
if-else blocks in C code but they they
have all these different operations
where you know depending on the types of
two of the different arguments
dynamically at runtime they pick a
different implementation so this is
something that is convenient enough to
put into your standard library but
there's no convenient way to do it
yourself you can of course write if-else
blocks but then it's not extensible and
it's not particularly performant and
it's it's not very elegant it's from it
ends up being monkey-patching like you
see all over Ruby on Rails it's also
very addictive once you start using
multiple dispatch you you don't want to
go back you sort of are like wait what
do you mean I can't just do a slightly
different thing when this thing is an
array or a hash or you know whatever so
what I realized is that it's actually
very linguistic that natural language
has this this multiple dispatch property
and you see like related meanings of the
verb go depend on
what type of adverb your your you know
pairing them with you know this is a
literal transition to whoa sorry
this is this is a literal transition to
another location this is like you know
the metaphorical go it's a different
sense and you also have default but they
work with either of those things right
so like you can have default you know
default values for certain things and
they can be before or after the verb and
this is you know this is very multiple
dispatch II so this is like how you
would write this definition I just
thought that was kind of a cute example
I think it might explain why it comes so
naturally when you start using it so
this is sort of the two sides of
multiple dispatch its object-oriented on
the one hand because it's all about
subtyping and you can add new subtypes
of things and you can have new behaviors
and sort of stick them on there which is
exactly what you would do with a
classical oo type hierarchy and you know
virtual methods which you then provide
specific implementations of so I don't
think it's very you know it's not
surprising that all these the hola
languages are emulating it and I you
know it's a great way to express
polymorphism of that type of
polymorphism there are other kinds of
polymorphism like generic programming
but it's also functional right because
this thing is a first-class object in
these object-oriented languages there is
no kin there's no good way there's no
object that represents the so let's say
you have you know a foo method in a lot
of different related classes there's no
way to talk about that foo method in all
of those classes as a thing itself you
can call them all separately the closest
you can get is a lambda that call it
right you can say you know lambda of
this thing applies food to it and so
that gives you the so a function that
calls that thing if you have lambdas but
it's not really the same thing as
reifying that that collection of
operations as a single object and that's
what generic functions give you and
that's very powerful and the combination
of the two allows you to do things that
either one by itself doesn't really let
you do so this is a fairly basic example
defining
new type this is good not just for
numeric stuff but imma stick with
numeric stuff because it's kind of our
wheelhouse and I really like this
example I'm gonna define some modular
integers so essentially this is this is
the meat of it it's you define an
immutable type because it's a number so
it's you know you want it to be
immutable plus you get really great yeah
this this definition ends up being you
know no more overhead than just an int
it's the exact same size as an end and
you you find the type mod' int it has
one type parameter n which is
interesting is not a type it's a it's a
dependent type system so you can
actually have a number here be your type
parameter so there's going to be a
different type for every single modulus
n and it doesn't make for we're going to
define operations between modest of the
same n but not not if then doesn't match
right because you can't you can't add to
you know you can't add a mod seven
integer and a mod nine engineer just
doesn't make any sense it has one field
which is of type integer we could make
it you know we could have a type
parameter for the type of integer you
want to have in there but let's keep it
simple as an example and then a
constructor which is mod int you know if
you give it some K I just want you to
take K reduce it mod N and then just you
know the new pseudo function is is just
a way of constructing an object of the
type that you're talking about inside of
a type block that's how we express the
construction of a new thing defining
some some behavior is pretty
straightforward you just say so that's
you know because plus is my favorite
let's do that one first so we have a you
know plus is just a function so you're
just adding a method to it and it has a
type of parameter N and then you say you
know if type mod int and and B as a type
mod and what's this type parameter here
is now serving the role of enforcing the
fact that a and B have to be of the same
type
they can't be of different ends if you
have a modular entry of you know one end
and a different end it's not good this
is not going to apply you're gonna get a
no method error all you got to do is
just add their inner fields and then
construct a new mod int out of it all
the other definitions are very similar
so let's let's just do a little code
with that see how that goes
I'm using it so now I have a modern type
you know you know what this is sometimes
this gets a little this I'm using this I
pi thon / I Julia notebook thing and
sometimes it jumps around a lot so okay
so that's a type you can you know
construct that that's a type if you want
to make one of these guys you just you
know say that okay straightforward
enough I'm just gonna make up some other
random number okay and so now already we
can do a plus B that works it just does
wait you know you know a plus B plus B
plus B is gonna wrap around so that's
exactly what we wanted for modular
behavior if we for example try to do you
know so a plus B works because they're
both mod 11 we try to do a plus mod int
13 of some number no promotion exists so
that's not it's not quite the no method
error but it's you can't see that at all
but you can kind of see it what ends up
happening is if you look at this
what's hat what it does is it calls this
very generic fallback function to find
here four plus which basically says if
you've got two numbers and you have no
idea how to add them promote them to a
common type and then add them the crazy
thing the hard thing to do actually is
that if you look at for example the code
for plus on an integer and a float 64
you know if this is not fast you're kind
of screwed so the LLVM code for this is
just signed extension integer 2 FP
operation and then a floating point add
and that's it so the tricky part is to
somehow take this all those abstract
layers of def
missions which you know invokes
promotion and splatting and all sorts of
insanity and somehow manages to figure
out that this is all you actually need
to do and that that's sort of the secret
sauce that's how we get good performance
despite having all of this abstraction
so interestingly you already have a lot
of stuff that's very powerful beyond
just you know basic integers so map not
into leaven I'm gonna create a bunch of
random so that that inner expression can
creates a random 5x5 matrix of integers
between one and a thousand and then I
just apply I mapped the mod int 11
constructor over it to get a matrix and
you see I get an array of modular
integers but there I added a little
secret sauce here these two show
expressions make you know make modular
in terms print nicely and in arrays and
but it's nice it's like two lines it's
very simple
the you already can do things like this
you can do you know for example a
squared takes a second because you can
see the jit happening second time it's
instantaneous like there's the first
time it doesn't it's never done this
before
you can you know this is a very
efficient generic definition of matrix
exponentiation if you want to define
another matrix B which is you know gonna
have slightly different values this can
also work and of course you have you
know a plus B so all of this came for
free from just defining plus and plus
and times and of course we also had in -
we also already from these two
definitions with the convert and the
promote here so what this is doing
convert is saying if the first argument
is the type object mod int n and I have
an integer and I want to convert it to
that type this is how you do it you just
you just apply mod int the mod and n
constructor to it that's it it's pretty
straightforward the promote rule is
telling is hooking into that promote
system which is all defined in julia and
telling it that if you see a mod intend
object type and
and meet in the int type the thing that
wins is mod in end this is how all of
the promotion's like the floating in
stuff is done and that's all you need to
do and now you already have you know a
plus one will work even though one is
not you know and you know two times a
will work two times a squared will work
all of this stuff just works it you also
you know for example you can get you
know - a cube - you know five B squared
plus one a one you know all of these
things just happen actually I shouldn't
do the negative thing because that kind
of exposes the fact that the modulus
operator is doesn't do the right thing
this is one of my pet peeves about x86
and like we've got a million
instructions at this point you can't
give me a proper mathematical mod so the
mod instruction is actually it has less
good coach in then then the remainder
instruction so just throw me one
instruction and come on so anyway I hope
that sort of displays a little bit of
the stuff you can do we've sort of been
addressing the expression problem here
without realizing I don't know if
anybody's familiar with this but my
favorite definition of the expression
problem is Matz torgan 'sons because he
doesn't really throw in type checking or
modularity as red herrings I don't think
those are essential really it's about
you know to what extent you can you can
have new types that you apply existing
operations to and new operations that
you can apply to existing types you need
to do both of those things and you know
the former is relatively easy you know
oh and hard and functional and the
latter is easy and functional and hard
in oo languages and we just did both or
actually we didn't we didn't create a
new operation but we can do it right now
we're gonna create this foo operation
which is defined to do this expression
with modular integers you know it infers
the type of end from the modulus of the
objects but you know in the case of
integers to integers we're going to
define it to just use mod 11 because you
know that's apparently my favorite
modulus
and what you can see what's interesting
is that the the code for this ends up
being very straightforward this goes
from two intz to a single end and all
it's doing is is basically the you know
these ends up end up being no ops and
you just end up doing some remainder and
shift left and you know addition
operations which brings us to
performance so how's how's the
performance of this whole business seems
very complicated seems slightly
implausible that any of this would be
fast so this is a little hard to see
because of the colors and because of the
screen but basically this is a log scale
plot of performance across a couple of
different benchmarks they're micro
benchmarks we originally wrote them
because we were bad at them and we
wanted to get better but now they're you
know they're real-world code is also
comparably fast it often some there are
we have a whole suite of case test cases
where we're not as good as we would like
to be but in general within we're within
1 to 2 X of C this is all relative to C
performance this is the amount of time
it takes in each of these different you
know systems to execute these various
micro benchmarks you can see that
Fortran is very fast
except for string parsing which it does
very poorly add and it's insanely fast
at recursion apparently and various
other languages to go is you know pretty
fast but has a little bit of a spread
sometimes you get up to 10 times slower
than C octave is just a dog it's it's so
slow like running the benchmarks is all
octave I'm just waiting for octave the
entire time and you know python is a
fairly fast interpreted language
mathematic is impressive javascript is
crazy fast for something so dynamic
interestingly so there there are a bunch
of very fast dynamic languages these
days so JavaScript you know v8 was the
pioneer there but now there's a bunch of
very fast execution engines Lua JIT Mike
Paul is a total genius at writing fast
dynamic languages pi pi is a really
impressive project it gets pretty good
performance we do not work at all the
way those do
doing totally totally different things
and I think a good way to put it as Karl
bolts who actually works on pipe I at
dinner a couple weeks ago he said I
didn't get it at first but he was like
Julia just a static compilation at
runtime I'm like what are you talking
about we're dynamic and it's because I
when I think of Jude I just think like
you'd defer your code generation until
when you actually need the code but what
he's talking about what other people
seem to have conflate thrown in with the
JIT definition is that not only are you
doing that but you're also doing tracing
to try to figure out types and guess
them you're also doing you know
speculative code stuff where you like
you know at the extreme sometimes we'll
generate code that doesn't do null
checks but then waits for you know an
exception to occur and then like fixes
the problem afterwards all right crazy
clever things like that that can get you
good performance even when you can't
infer the types of things what we've
done instead is we've just levered
leverage the language of design to try
to make it easier to do those things we
don't actually have to do any of that
stuff I mean some of the things are
really you know pretty basic decisions
but they're important for performance
like use native data types you know if
you have integers that in dead that
never overflow then how are you going to
make that fast it's really difficult
MATLAB uses saturating integer
arithmetic which is like good for signal
processing and terrible for everything
else it makes integer addition and
multiplication non-associative and they
don't distribute over each other so you
like cannot optimize anything the
immutable types are really important the
fact that concrete types are all final
you can't inherit from them that allows
you to delete into you know once you've
narrowed it down to int there's no
subtyping int so you're done you're good
you know that this thing is gonna be an
int you also know that int can't get
bigger there's not like that anybody can
come along and make a subtype of int
that is you know twice as big or ten
times as big so that means you can you
can store them compactly in an array
also you know in a format that C and
Fortran are familiar with and so you can
call C and Fortran libraries without
copying any data
mention type stability obviously we've
been using type annotations so you know
we're letting the programmer express
things about the types of stuff
we don't have to just guess we can
actually let the programmer tell us when
it's convenient to do so multiple
dispatch it not only is it crazy
expressive and intuitive and powerful
but it also provides like amazing type
data like you get all sorts of insane
information that can know the compiler
is so happy about and the way we
leverage do that is through this
dataflow type inference technique and so
just it's it's not hindley-milner it's
not unification in particular unit
unification is all about actually
figuring out the exact type of
everything and so instead what we're
trying to do is put a conservative upper
bound on it so some of the time we can
figure out the exact type about 60% of
expressions and this is like totally
hand you know ballpark hand wavy because
it all depends on what program you're
running but in some some you know
somewhat typical code in some sense of
typical we got about 60% and and the key
thing is that performance critical code
does not tend tends to be pretty well
typed you know at the top of your
program you're doing some stuff with
dictionaries of any Danny and you have
like no idea what the types of anything
are but you know it's it's your business
logic at the top but then you get down
into some sort of like inner inner loop
and you know that everything is floating
point that is tends to be the way that
goes down and it's really nice to be
able to not care about types at the high
level where you don't care about
performance and then not and in the same
language also get really good typing in
in the inner loops interestingly
different than other systems like the
the type of the code with type
annotations isn't static it's still
dynamic it's just dynamic with better
type information and in particular one
of the things we can do is we can
recover from ill typed transient ill
typed problems so a good example so it's
so I'm not sure what order to explain
this yeah I'll just look at this code
this it's pseudocode for what we're
doing and the type inference engine so
on the one hand you have for example you
you've inferred some stuff from looking
at the code and you know that tooth to
element two objects are have to be of
the same type you don't know what the
type is but you know they're of the same
type so you have this type TT you
interest you type intersect that because
you apply a function to
and you know that there's only certain
methods to that function say for example
you let's say you only have this method
to that function what ends up happening
is like now neither of these are
particularly well typed but the
intersection of them which is what are
the only things you know can have ever
happened is actually completely
perfectly typed so that happens more
it's actually fortuitous that this works
this way it's really great a more
complicated example is you had kind of
have an abstract array you know the
element type is float64 you don't know
how many dimensions there are and you
know you're gonna get a tuple with that
many elements in it but you don't know
what n is and then you apply it to a
function that expect that only works on
matrices well you know and it only works
on matrices and these these dimensions
have to be integers right because you
know dimensions often are given as
integers so now immediately you actually
know exactly what the what the code to
generate the only thing you need to do
is you need to put some types type
checks ahead of this may be to be like
well okay if these assumptions aren't
true it's not that we need to bail out
and execute slower code we just need to
bail out because it's an error which is
much easier to do so a good example of
this is this you know it will behave
square root function so our square root
is type stable in that if you give it a
floating-point number it always gives
you a floating-point number back if you
give it a negative floating-point number
to give you nan some people don't like
this and they want it to give me a real
number when it when the when the
argument is positive and a complex
number when the argument is negative for
performance reasons and type stability
that's a terrible idea it also is often
not what you want in code if you write
code that operates on reals you do not
expect a complex number to suddenly crop
up most of the time you actually want
that to be an error but you can define
your funky square root that does this
and you can see that you know square
root of 2 is a floating-point number
square root of negative 2 is a complex
float 64 so this is very now this is
poorly typed and you you know you can
you can't really do great things with
that in terms of code generation but now
we define a function that uses this X
square root and says you know Y is equal
to X square
of some square that I'm trying to find
the square root of and then I want to
return apply the high pot function to
that which you know this is a totally
nonsensical function but it you know it
it's just for didactic purposes what we
can do here is we you know we define
that and we look if you know the the the
system looks at the methods of the high
pot and notices that all of them are
real there are no non there are no non
real arguments and so as a result if you
look at the code this is this horrible
sort of typed intermediate
representation that we still expose to
you but it's like very hard to read and
you can see that at the end the return
type we have inferred that the type has
to be float64 so what happened here is
you were you for a while we had bad
typing and then we've recovered it and
the rest of the code that calls the code
that calls X square root is you know as
has to deal with poor type information
the code that calls D doesn't you have
to have some runtime type checks in
there but you don't actually have to the
code that calls this D function doesn't
have to worry about it some other things
that I'll mention that we have like I
said metaprogramming Julia's home iconic
I could give examples but I'm at a time
distributed programming so you can hold
references to in progress computations
that can either be in the same process
or on a different process on the same
machine or on a different process on a
completely different machine and you're
connected via TCP SSH MPI whatever
nice things that so you know this is not
always the easiest programming model
it's not as nice as you know doing
something like Erlang but again like I
said earlier we need to deal with the
fact that people need to mutate huge
amounts of data this is significantly
easier for a bunch of reasons than doing
for example like raw MPI programming
this is sort of what the HPC world has
converged on as like a good model for
doing this kind of stuff
and some niceties that we bring to it is
that you know any Giulia to find data
structure just gets automatically
serialized and deserialize you don't
have to do anything to make that happen
closures get serialized too so you can
write code in particular you can write a
macro that then you know implicitly you
know wraps of something in a funk and
then sends the funk across the network
and then you call it on the other side
and you basically just say you know at
spawn and then something and it just
goes and does it
remote references so a reference to the
operation that is in progress you can
also send those across the network so
you can delegate the responsibility for
waiting for something to someone else so
this allows a lot of like fairly
sophisticated you know HPC style
distributed computations to be done with
relatively little pain we just call it
we can call C code very easily so it's
just you know you just you just it ends
up boiling down to just a c-collar call
function and same thing with Fortran and
then basically anything that exposes a
good C API which unfortunately does not
include C++ so calling C++ is a
nightmare and it always is right c++ is
only easy to call from c++ and even then
it's not even possible to call c++ from
a different c++ compiler you have to
have the same compiler see no problem
different compilers there's an api we
can do it we had live julia there's a c
api which someone works like it only
just now is getting documented and
standardized and totally rounded out so
that's not super mature we're very good
at calling c we will probably in a month
be very easy to call from C it's already
possible but you know it's not as not as
mature as it should be yet we're
practicing extreme open-source we've
been on github from you know day one
because I did get on everybody which
they weren't sure about at the time but
have subsequently recognized as a good
choice
we also have a git base package manager
so which I designed and people thought I
was a little bit crazy at first but I
think might be coming around I don't
know will
see it actually works now which is
really like that's the real selling
point is that it actually installs
things correctly which was not true for
like the first six months of its
existence a lot of the time one of the
design goals here is that if you have a
package installed you already have its
source code you already are in a
position to make new commits to it and
you are already in a position to submit
those I'm going to live on the edge here
and demo this so for example I'm going
to K nearest neighbors package see how
this works nothing to be done okay I
already have it okay all right so I am
going to clobber the readme okay so
where am i there we go
so I'm gonna go in there you can see the
get status is this I'm going to make a
get commit
okay how many screens do I have okay so
now what I'm going to do is I'm going to
submit that change
so this made a fork of the repository
and submitted the the change is a pull
request it hasn't actually submitted the
pull request the whole design here is
that it pops up a screen at which you
can review the clobbering you just did
and then decide if it's okay and hit
Send pull request which I'm not going to
do because they that's obviously not a
good change okay so that's it that's it
that's what I got I guess do we have a
moment for questions or yes okay so the
question was that it looks like go was
that a coincidence I don't really think
it looks like oh but I don't know I
don't I'm actually not super I'm
somewhat familiar with go but I haven't
done any go programming so I don't know
I don't actually think that's true I
don't think you can solve the expression
problem easily and go but maybe you can
I don't know the interfaces maybe allow
you to do it so you can go you can
actually you can define the interfaces
and then your time automatically
implements those interfaces if it
matches the shape that you define in the
interface and you can then define what
we need to find a type you can then find
operations outside of the body of that
type so very similar to how you define
your your new numeric type in Julia and
then defined operations that you can
perform on those types okay so the
immediate answer is no clearly if I
didn't know about this I wasn't
influenced by it but I really wanted
let's talk later because I want to see
how go does this and actually understand
that so
from theoretically yes done by itself
but I don't know how much the practical
side the practical side how much you
know who used it and how much is
succeeded in that field and the other
thing about the community so I've been I
think the question was heard on the on
the tape probably cuz she's got the mic
but um i-i've been downright surprised
by the eagerness that people in the
numerical and technical computing field
have adopted this and I think they have
the same frustrations that we did when
we created this which is the MATLAB is
really great for some things and then
really awful for other things in our is
the same same story and Python is you
know is numpy as good but it's like an
awkward fit the language isn't super
really designed for these things and so
a lot of things become kind of difficult
and hard to express and hard to do and
so we just wanted to do something that
was better and it very much from a
practical standpoint I mean I was a data
scientist for a long time and I was
doing this is the tool I wanted I
haven't done this you do excellent job
and it's really worth to study it and
learning because it can learning many
languages it's one language with address
all of these things
well that means developed by community
and how much you have this community and
how much explain that talks to kind of
market this language for developers need
for such kind of life yeah the community
I love our community it's very active
and there's some sort of pulse thing on
here right there you go I mean you can
see this in
last week there have been you know it's
not a huge amount but you know it's like
a bunch of pull requests a bunch of
other things it's there's a lot of
activity going on on on github and a
huge amount of traffic on our mailing
lists and we have about 25 people who
have commit access to the main repos so
that's you know people who have done a
lot of work on it and are trusted to do
things without you know having to make a
pull request necessarily I think it's a
fair number of contributors</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>