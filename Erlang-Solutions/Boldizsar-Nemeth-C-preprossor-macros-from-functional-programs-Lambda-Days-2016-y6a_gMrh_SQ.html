<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Boldizsar Nemeth - C preprossor macros from functional programs (Lambda Days 2016) | Coder Coacher - Coaching Coders</title><meta content="Boldizsar Nemeth - C preprossor macros from functional programs (Lambda Days 2016) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Boldizsar Nemeth - C preprossor macros from functional programs (Lambda Days 2016)</b></h2><h5 class="post__date">2016-03-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/y6a_gMrh_SQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well as you can guess from the
I will be introducing a netid to
transform functional programs into
professors or macros first then then I
would hear something like that then
apparently two questions come to my mind
why would anyone want to do that and and
how it can it be done so these will be
the topics of my dogs now let's start
with the vibe part because I think it's
the strongest question now than
programming in C the programmer usually
uses the purposes or to enhance the
languages capabilities this may include
writing purposes or libraries for maybe
source source River iting or or code
generation or or just inspecting that a
constant value is the correct Vance so
they may be used the purposes sorry in
such a ways not just defining the the
common text as macro now as you can
guess the professor is not designed for
writing high level programs so ver I
think these libraries can be very hard
and an understanding them can also be
very hard so this is our motivation to
propose a method that uses healthcare
code to write these professors or Metro
libraries and transform the haskell code
in to see professor macros that can be
used by C programmers as usual so
developing these libraries can be done
on a higher level of abstraction and
using them is as usual now let's
continue and and see how the professor
serve works because
and I think that you are familiar with
how Haskell works so I have only to show
how the propeller serve work so
basically the processor is untyped there
is no type system applied it usually
works on token streams and the
invocation of these macros are
considered pure so no side effects can
occur when I expand see macro also a
branching can be implemented with token
concatenation so in this example you can
see that by concatenating with these
double ashes the graphics with the value
that is given to the macro I can select
which macro will be expanded if X is
true than if true will be expanded by
foo and if X is false then if force will
be expanded to bar so by using token
concatenation I can implement branching
with the practice or but unfortunately
for us a recursion is not allowed at all
the practice or explicitly stops us from
writing recursion recursive macros
because then it expands the records with
macro it memorizes that it had already
expanded the macro Vance and and it does
not let us to expand it again so this
will not be expanded it this this macro
will remain even even that it's defined
but it will remain the same because it
will not be expanded because the
purposes are already memorized that it
had expanded this macro level so this is
a this is a large problem for us now to
to have some motivation I present the
implementation of very familiar
the restructuring of code that is
implemented in Haskell and it is
handwritten with purchase or macros
using the boost library as you can see I
don't present this to let you understand
that what it's it's done it's basically
dissimilar that the version on the top
now as you can see the Haskell version
is much smaller but this is not the most
important point the most important point
I think that it's it expresses the logic
of this river I think much more
explicitly so in the Haskell version you
can see how these pointer declarations
are generated well in the process or it
is very hard to see if you concentrate
very much then you can see that there is
an Asterix in the middle of the the code
but it's not so obvious than then in the
first version so it's just a bit of
motivation why I would be like to write
and understand the top level van instead
of the down below now I will speak about
how this transformation can be done so
let's continue that's our architecture
of the method that we use basically we
implemented a plug-in into getc that
that works as a core two core pass so
this is our algorithm that is
implemented in as a plug-in to GHC and
we use the fact that the core language
is much much simpler than the source
haskell language so the compiler already
simplifies the Haskell definitions that
we like to generate these professors or
microbes from and our core to corpus
basic
it doesn't change the representation the
core representation of the program but
rather hide effect it creates a macro
definitions that are stored in a sea
header file so we created this bus that
does not change the representation but
creates the macro definitions now let's
see how can haske definitions and
haskell constructs mapped to perhaps or
contracts now from integers maybe
unboxed integers because we deal with
primitive values on that level we create
we've wrapped them into a so called
value we also have exceptions and
tongues exceptions are errors that can
occur while computing function and
thunks are basically functions that can
be partly applied so they can collect
arguments until they have enough
arguments to perform themselves and in
this example we can see how the
application is performed when when we
apply F to an argument then the argument
is inserted into the last part of the
tank and if we have enough arguments to
evaluate that one that in this example
we only need one argument for this
function to to be able to be performed
then the macro that is stored in the
second part of the tank is expanded and
we get the result that we want now let's
see some other constructs and how can
they be translated to macros when we
translate variables our parameters we we
use the
gacs unique names to distinguish between
different variables with the same name
and then we translate algebraic data
types we use the value construct that we
introduced on a previous slide but we
tag the algebraic data types with with
the constructor they are generated from
so when I construct an ill it will
contain an ill tag and when I construct
accounts that it will have the constant
along with the parameters that had been
applied and then when i see a
constructor then i create a tank from it
so i can use the constructors the
partially applied now let's see how
pattern matching can be done because
it's interesting part of the compilation
a pattern matching consists of three
steps first I have to check if the
parameter of the pattern matching is an
exception because if it's an exception
that it then it must be propagated
unchanged if it's not then I check if
it's Cavor covered by the different
patterns that are matched and if so then
i select the correct case so i select
the one that that's applied and here i
use a token concatenation that i have
told earlier this can be seen here now i
have some issues when i'm doing such
translations from Haskell programs to
macros because the scoping rules of
Haskell and from the professor is very
different the professor has has a
shorter scoped each each macro
definition is is Vance scope so I have
to translate local Haskell definitions
into total
Vance to be able to use them and I I
have to translate implicit data passing
from in this case f2a to explicit
parameters as it can be seen on this
example now the other translation that I
have to do is that I have to remember
all the bindings that are implicitly in
scope in Haskell so I have to write them
explicitly in the process or that it can
be seen here so I had a parameter E and
it is implicitly in scope than I
resolved the body of the second
abstraction so I had to explicitly pass
it as a macro parameter now as I said
there are me and my main use cases our
program transformation and source code
generation and these need to have to
handle large parts of becks the source
code of the program so we had to come up
with a solution to work with large text
and and we found that representing text
as strings or list of characters is is
insufficient because first of all we
would lose or white space information
because a white space cannot be treated
as a token in in the practice or macros
and and we only had half tokens to store
the information so and it would be very
inefficient of course to do to store all
text with large algebraic data types
like list so we created a new type in
Haskell that is called token stream and
a token stream in the generator purposes
or code a token stream is translated to
row stream of tokens so we have a very
very
a simple representation of our texts and
well we can't use usual string
operations on them because we cannot
select the character in a token stream
but we can use concatenation and token
contamination and we created operators
in Haskell for them in this example you
can see that those those tokens dreams
are concatenated to each other and in
the generated code those literals will
be translated to simple tokens now let's
continue we have two difficult things to
handle the first is recursion because of
course the processor doesn't allow
recursion but the user might want to
write recursive functions so we had to
do something and and basically we we
allowed the translation to enroll the
records if functions to a given limit
and the user can the author of the
library can write how many recursions
must the function be able to perform
before going over that limit so
basically the author of the library can
control how much unrolling is done in
the generated code of course that means
that a lot of processor code will be
generated in in the case of recursive
functions but for cogeneration usually
we don't need that many ricker recursion
that so it's it's it's a partial
solution but it works for cogeneration
purposes and and you can see that the
annotation that controls recursion is
implemented as part of the type of the
definite
so it's important because GHC can
sometime transform those definitions and
this way the type annotation remains
very want it to be now the other problem
we have is higher order functions
functions that receive functions as
arguments and we actually have a partial
solution for this when a when a higher
order function is applied to itself then
we can generate different
representations for the different
occurrences of this function so here the
first occurrence and the second
appearance will have a different
generated processor code and their prep
Sasori invocations will not not
interfere with each other resulting in
strange errors so this case is solved
but well for arbitrary functions we have
the problem that that if this function
receives an arbitrary functions a
function and applies it in a nested way
then then we we don't really know that
that this function could be evaluated in
in a nested way so so basically in these
cases we we have no real solution now
let me summarize the talk we developed a
method to translate Haskell into
purposes or macros and we implemented
the tool to do that the tool is
basically capable of of translating
anything in haskell that is not
recursion or higher order functions for
for those we have partial solutions
because we work on the core
representation in the in the haskell
programs all syntactic features
and and language extensions can be used
because they are obviously desta gerd
into the core representation and the
implementation is on github so you can
check it out thank you for your
attention user it for some real-world
application having translate something
new to market so the question is that
did we try it for a real world
application v.v.v did try it with
smaller examples and parts of real
application code but as you can see the
author must must transform the haskell
program to be able to to translate it to
Professor macros so to do that we we
have to know how many times will record
the functions be called and so on
because because we need to do that but
but we implemented a transformation a
source to source transformation that was
the work of my colleague nautical
actually he implemented it by writing
practice or code and then we wrote it
using we brought it in Haskell and we
compiled the Haskell version to perhaps
a circle and check that the the to work
the same so well we we had a a example
of this
if you compare the performance of two
two programs while Hughton in Haskell
another common to us yes we did that
actually it's in the paper that I'm
presenting and the results was that that
the performance is is like an order of
magnitude less than the handwritten
version but it must be done that that
this transformation is is not optimized
so optimization of this is for further
research is just present the repo see if
that is basically direct to direct so it
has come to c++ so there's no like in
turn intermediate language a
representation that you have in between
actually actually vu so the question is
that that there is no intermediate
representation between Haskell and see
professor macros well we did not write
the intermediate representation because
it is already generated by the GHC
compiler so so we use that
representation and we did not write our
own because we did not have to please
forgive me by
classes I did some
look like
product is one to get
this pipeline is
thus eco-drive like under after the
preferred purpose of kissing get this
done all support its compact right so
why do we do this Parker transformation
has the code
marcos
convicted of
now so the question is that vai Vai V
translate Haskell to macro definitions
instead of C code now the main task of
this library is to provide a way to
write macro libraries because because
makorra processor macros are very
platform independent and widely used and
not all architectures support higher
level programming tool chain especially
bit architectures that has strong
performance requirements usually support
lower level tools and and we had to come
up with a tool that is is compliant with
these architectures</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>