<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Saša Jurić - 'High Availability' ElixirConf EU 2015 | Coder Coacher - Coaching Coders</title><meta content="Saša Jurić - 'High Availability' ElixirConf EU 2015 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Saša Jurić - 'High Availability' ElixirConf EU 2015</b></h2><h5 class="post__date">2015-05-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wYttHG3S76Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">optimization Privacy Information now
we're using along a lot and make you
want to sound a little white paper
available how we approach this might be
fun to talk in Berlin they're
lightweight stop hello and I really want
to provide some reason silly girl in
many cases choice and I also want my
attention to find more what I kind of do
on Chavez and a lot of coffee single
entity to a language are more oriented
toward some foundational stuff tomorrow
am this is where a personal five biggest
and most down breathing for choosing a
new complaint jizz which is everything
their own right very enigmatic table but
I really needs to be avail today folks
and I will sound incorrectly any
language Patea was worthy of Frank now
challenge custom very late Rowley she
described the property system provide
more historical records all the time we
can love some down time as little as
possible
none and to do this for some period
lasts forever and my pins very important
property I don't think an option anymore
these days for any form any timesystem
there was because essentially available
free conveyed property in our system
Republic very you some real people the
cement users because users may come
annoyed frequently in the cells and
ultimately we may even end up being ugly
and I really think anyone was on being
in place so i reckon think something for
some special domains i also think it's
cale don't need to be like super huge as
the real users perished on campus or
defend its require those other hand easy
that have a chance in helping you
because essentially top system is
complex me in our limited bonus there
may be punching Nemo we gave you some
third-party services may be thoroughly
payment gateways or not and because we
can make elaborate their system there in
be ingested something will go wrong
someone is illusionary believe that will
always work perfectly and regarded
o'clock all this lieutenant article on
track making more resilience to any kind
of people and provides an advertiser on
some work so it's worth considering some
and r 1 is one such tool for male and
the challenge that involving production
or more to that is mahogany all kinds
system large numbers and really proving
yourself production deal with challenges
such as you know what personally I delta
T case practically all choice for
anything server-side with rationality
once the reliability is almost always
five let's not nice problem and parent
has a proven track record that's one of
the to be fine and i was using
personally quite audibly because i
believe is the tool helping in the mall
in one of the target areas i would have
to face no matter what that's kind of
mattress coalition and i won't make it
clear in this possible move slow so this
doesn't happen by magic right Justin to
providing our stuff nice coral and not
make magic available for reliable or let
us order that for you and I really no
one else can essentially your system if
your own store it's very unique mental
health out there in the way it's built
in the way durable component go defend
revival service and what is that you
should have when the video pieces are
fail is a York
go on please and no one else but you so
what you can expect to get Merlin have
some kind of globalization very simple
building blocks with we're stronger in
peace practically no gunshot there you
sample you those things to work your way
gradualreport more relaxed kind of the
way I see and in the process I think you
should aim for top of high-level
technical problems does it should happen
to be resilient to any kind of failure
right 88 what was wrong it actually
involves possible to be provider water
service without Rogers it should be able
to self heal to repower magnet is
impossible we need scalability so we can
wrestle all she'll hopefully become
popular time I users paki more work to
do with which things from powder and we
had more hard work the signals got
beautiful to make and what without
saying it should provide responses in a
timely manner whatever that means
particular use case but obviously it
tastes like days or months to get
practically number and this is very
important some critical time to time
with failures grid load is done power
some conditions seconds 30 minutes per w
the movie wanna avoid it we can forget
all this in Berlin systematically by
relying heavily on peeps currency this
is kind of like magic ingredient and my
opinion
parallon response to call separation run
expiration be precise do prepare think
of two separate front enemies now
currently our alliance called process
normally read and she provided p and
it's a computational in sequence of
expressions and parts latex is memory we
like two distinct front and engines now
for being partisan same system how can
you need to call brick elaborate and for
this purpose we can use message they can
send them self messages per message
essentially just beat the Baker whatever
it is going to arrival place and when
we're sending it to real singing
snapshot copy by this copy data sharing
blah this cop is placed in the mailbox
sealer under standard and move down
during its own stop the receiver is
nothing wrong in any way okay message
when we have time one message in the
sample about this is a very simple but
they are powerful very important
collaboration communication about this
we bring your local server processes and
this is where Rolen is said to resemble
the extra one so a server processes
vanilla processing point
but the gist of it is super cross cross
of the longer period of time and it
maintains its state again arbitrary data
which supports internal private process
and it runs a loop I'm in the loop it
wait for one message to rise and then
right angles does happen with a message
right based on the message content and
the current state mae-rus patients may
God clutter processing system may create
additional processes and may send
response message back to polar process
and it will compute the new state
valuation current state and message you
get new state moves real estate and then
repeat the operation so you can think we
kind of like a single for the server
right angle one message at time the old
messages of are literally request that
articles used incorrectly make it do
something little program to help certain
process responsible for single bank
account and the simple implementation
stake here would be number right the
money people to help clients themselves
they can use messages to interact with
it to manipulate or a query this
particular bank account they may send
their messages at the same point in time
and yet those messages will be handled
one by one in the order of arrival and
this is how we synchronize competing
actions this is how a process can
protect the integrity and consistency of
its state and we don't need semaphores
new Texas locks and stuff like that to
do this right so its way simpler
approach to concurrency in my opinion
for me personally concurrency becomes
more or less something I'm afraid of and
more something the timing client to use
in many cases where applicable and where
I can get some benefits and it's also
cheap thing this hour long process is
way cheaper than a heavyweight processes
or threads in terms of memory overhead
when you started by default on 64-bit
p.m. it will take up about two kilobytes
for stack and heap and then of course it
may grow if it needs more and you can
really create those things in
London's like in billions if needed and
we rely on this we use this property
because concurrency is cheap and because
it's easy in Ireland we use it a lot we
write highly concurrent systems it is
possible that I don't know a smaller
system can easily be powered by a few
hundreds or maybe a few thousands of
processes while medium to large system
might reach for tens or hundreds of
thousands or sometimes even millions of
processes and the general idea are very
broadly speaking is whatever can be
labeled as a distinct activity in a
system should probably be implemented by
at least one dedicated process usually
there's opportunity to subdivide even
further right so this is kind of like a
generic diagram I will provide a more
concrete example in the last part of the
talk but the idea is that we use a lot
of concurrency and you to the way it
works due to some of its benefits and
some of the supporting tools we can get
some nice benefits in our systems right
so first of all because everything is
separated is the so-called share nothing
concurrency a failure of one thing does
not disturb anyone else in the system
right the process fails everyone else
keeps running and a failing thing could
not leave any garbage any corrupted data
behind so we have like thousand
processes running one of them fails you
have 999 processes running and providing
the most of your service this is the
isolation part right now obviously being
a part of the system those survivors may
need to depend on the phallic thing so
we need we want to bring it back up as
soon as possible and this is possible
because the crash is not abrupt but it's
also not silent anyone can be notified
about the process termination any
process can ask from a vm to get a
message if some particular process
terminates so it's a process i can say
to my vm hello this is me please let me
know when processed food dyes and if
that happens i get a message who has
terminated with the reason bar and then
I handle this message I can do something
about it this is what I like to call a
failure propagation through a concurrent
system right so if you like one thing
fails someone else can get an
information and do something about it
and there are all kinds of interesting
patterns here by
to possibly arguably the most important
one is supervisor which really builds on
top of this foundational stuff it's
implemented in plain or longest part of
the OTP framework and it kind of
realizing this simpler stuff so a
supervisor is a process it is in fact a
server process which we can use to start
supervise and monitor worker workers
worker processes which are the bread and
butter of our system this is where the
action is happening and we are providing
some useful value of providing some
service right so i can tell to my
supervisor please start me these workers
with those arguments and it does that
and it also wants to be notified when
some particular any of those processes
terminates and if that happens it get a
message it handles the message by
starting new worker with the same set of
arguments and the new worker of course
starts with a clean fresh and stable
state does not inherit any corrupted
garbage from the failed one now
supervisor can supervise multiple
children not all of which need to be
workers and this is how we build
so-called supervision trees we're
usually workers should be leaves should
be workers and note non-terminal nodes
should be supervisors and there are all
kinds of interesting options there but
I'll just discuss the most basic case so
let's assume that a single worker
somehow crashes due to some exception it
terminates parent supervisor gets the
message and it handles it by starting
the new worker right and if that works
then great what we experience we had a
single failure everything else runs
without any interruptions we recover
from failure automatically and
concurrently to everything else so
that's kind of like the best case
scenario now sometimes of course restart
may not necessarily help and we will end
up in a restart loop right the worker
fails we restarted it fails again we
restart it again and so on and so forth
and at some point supervisor will give
up right when some configurable
threshold is exceeded we have too many
restarts per time period then supervisor
gives up terminates it's complete
subtree all of its descendants together
with itself and it essentially escalates
the restart procedure one level above to
the parent supervisor so what's kind of
happening here is we are trying to
recover from a failure at a very local
scope very narrow scope and if it
doesn't work we are moving wider wider
wider
until we are able to find some area of
the system that needs to be restarted to
resume the full service and the
rationale that this should work is
because one system was originally
working right we started it it was
providing some service for some time and
presumably now it's failing because
there is some corruption in the state of
single worker or maybe of some workers
and we are trying to find the minimal
possible surface that needs to be
restarted so we can restore the full
service and somewhat magically but it's
actually quite quite logical because
this supervision tree is kind of
established in orthogonal way to the
main code the main code of those workers
is in many ways liberated from error
hanley constructs paranoid try caches
and whatnot it usually follows the happy
path describes its intention we even
frequently I use better matching to
assert our expectations and fail fast if
those expectations are not met and then
we rely on the supervisors as a safety
net to recover us from some unexpected
situations now because the system is
highly concurrent there's a lot of
potential to be more efficient to run it
more efficiently and this is where we am
steps in it does it's magic right so
when we start the vm it's a single
lowest process and it uses only a
handful of always threads to do the job
the most important of those threads are
schedulers we have by default one
scheduler per CPU core and there of
course schedulers are in charge of
running are processes and they do
frequent context switches no matter what
your process does like beat cpu-bound IO
bound or some combination you can be
pretty sure that it will be frequently
switched out and this is a good thing
because it prevents a single process to
paralyze your entire system or some
significant part of it for some longer
period of time right so the way it works
is when a process gets the slot in a
scheduler if it's waiting for a message
and the message is not there it's
suspended and someone else gets the slot
if it is doing an i/o operation then
this will in fact be performed on a
separate thread so called async thread I
believe we have 10 of those by default
and in the meantime scheduler can do
something else run some other processes
right and of course the long-running
cpu-bound process will be preempted very
clear
you can expect this to happen in
sub-millisecond time so there are a lot
of those switches I should also mention
that garbage collection is not done on a
system level we don't have a global
system GC pause we have this what i like
to call micro GC per process which is
possible because we have nothing share
concurrency so when a process has the
slot in the scheduler if it needs more
memory if it needs to expand its keep
then during this expansion there will be
this micro GC and it's perfectly
possible that you have a single
scheduler doing this and micro GC thing
while all others are in fact providing
some useful service in doing something
meaningful and all of this makes your
system more predictable in their nature
right you find units you get some
latency and you can expect less for
riences less deviation in your response
times and of course it's obvious that VM
goes to great lengths to make efficient
usage of all the resources it uses
hardware as much as possible and you can
also scale up right if you reach limits
of your current hardware you can put it
put the system on a bigger better
stronger machine and it will just spread
itself over all available course the
final piece of the puzzle is a support
for distributed systems so it's possible
to connect multiple VM instances in
fully connected cluster and this
improves our scalability and fault
tolerance because now we we can scale
out right we can stack multiple machines
to support the total load and add
additional machines to accommodate the
extra load and also it improves our
fault tolerance because we cannot
tolerate crashes of the entire machine
right and survived them and provide our
service now even though you don't
necessarily plan for it in many ways
you're highly concurrent systems in
Erlang will already be distributed
because what we're essentially doing is
by being highly concurrent we are
distributing a huge workload over a
large number of not separate entities
which are processes and those things of
course communicate wire messages and
they use the same preventive regardless
of the locality of the target right away
the receiver can be in the same vm
instance or it can be on another machine
we use the same thing so in many ways
our systems are already down the road to
being full
booted this is not going to be an easy
task I will not lie to you there are
some inherent challenges with
distributed systems no matter what you
do or how you do it most notable dealing
with Metro partitions but you get some
boilerplate already available you have
support from third-party libraries and
of course you should reach for stuff
like a react or for example from react
that can simplify your life so yeah
that's a general idea a lot of
concurrency share nothing semantics some
supporting tools from vm and a lot of
effort by the vm itself and then we can
get some nice stuff which in my opinion
ultimately bring makes our system more
available right providing service so
what does it mean to be highly
concurrent right this is a kind of the
last part of the stop or I'll try to
provide some example an adapted example
inspired by the feature I have built
from a previous former employer and it
is for this particular feature that I
originally reached for her lungs and
five years ago and this feature is in
many ways powered by air land and to
some extent also even by elixir now the
feature is so-called live betting it
works in the online betting domain and
it allows end users soccer players to
visit the online betting site and the
place bets on matches which are
currently in play now because we are
dealing with something that is happening
right now obviously we are dealing with
the continuously changing stream of
information that we have to cause them
to transmit to connected users a couple
of thousand of them simultaneously at
peak time and we have to do this in near
real-time right you cannot afford
significant delays between what were
showing there and what's really
happening and the changes are happening
fairly frequently this is not obvious
here because it's like a partial screen
shot at big times we have about 50
simultaneous matches this central area
it goes wider to the right and those
numbers that you probably don't see very
well in the central area are so-called
betting odds or coefficients and they
determine the amount of money a player
may win in the case of a successful bed
and we generate a lot of those oats per
single match especially for some more
dynamic sports such as basketball or
tennis where things tend to change
pretty frequently now high-level
overview of the participants there
we have a third party company which is
the origin of our data we give the money
they give us data where they give a
stream of XML messages describing
changes to multiple matches and then we
somehow transform this data to suit our
purposes we add some of our data from
our own database apply some of our own
business rules in code the JSON and then
we use a long polling based HTTP push
server to distribute this data to supply
connected users or rather their browsers
and once the jasons reach the browser we
render that shiny colorful GUI players
pick their beds and they return to the
system with the bed and we validate if
everything is fine and then we store it
if it's all okay now I'm going to focus
on this transformed data thing this is
kind of a curious choice it's a
seemingly unimpressive unspectacular
think it's a job literally I started it
connects to the server it takes the data
transform the data sheets data further
it has to direct clients like these
server components but it has a lot of
requirements to work as much as possible
because of this these components tops
everything stops right the whole feature
stop that screen is frozen doesn't
resemble reality anymore and essentially
we don't have a working feature and
because this feature plays are fairly
important to share in the total revenue
of the business we wanted to run as much
as possible so again you don't need to
be whatsapp to have high availability
requirement now also this feature has a
lot of potential for concurrency and
this was completely unobvious to me when
I started implementing it so I'm going
to expand on this right what's happening
in there are we establish a TCP
connection to the third party server and
then we receive a stream of messages
with somehow assemble interpret those
messages and continually incrementally
maintain our own in memory model our own
view of the world the way we want to see
it then we usually have to store some
stuff to the database most frequently
those are betting odds we strip some
fields we don't need on the client side
we encode the JSON and then send it
further to the long polling based server
now what you see here on the screen is
literally the architecture of my initial
attempt
it so I built this thing purely a
sequential single-threaded if you will
right so I would establish a connection
then run a loop take the message perform
those steps return take more data and
repeat and this was working surprisingly
well in production for like first five
or ten minutes and yeah it would fail in
all sorts of ways which can kind of be
summarized as poor efficiency and poor
fault tolerance right so the problem is
being purely sequential this thing is
kind of like a software equivalent of a
superhuman it tries to do everything
single-handedly and if it gets stuck
somewhere which will usually be
unsurprisingly a step number four if it
get stuck then everything else is on
hold right and we waste time and it
would pretty quickly fold the kind of
reality even at moderate load of
messages now also it's very its fault
tolerance is very poor right something
goes wrong everything goes wrong and we
really don't want that we want this
thing to run as much as possible right
so what really needs to happen here is I
need to run different things separately
and after spending some time with your
along this really to me is concurrency
right so I need to become concurrent I
need to run those different things
separately and there are some
constraints here most notably these
steps or most of them needs to be
executed in this particular sequence
because most of those types produce some
intermediate that is needed for the next
in line also I want to preserve the
order of my messages those external
messages I want to produce my output in
the same order because this determines
the sequence the timeline of events now
given this the initial take is fairly
straightforward each step is implemented
there is a server process and I can
establish a pipeline out of them right
so each step will produce some some kind
of an intermediate it will send it to
the next in line so if I'm a process
right i'm waiting for the intermediates
to arrive as a message i get this
message I handle it I do my own stuff
produce my own intermediate send it to
the next in line and as soon as the send
this message I can immediately take more
work right because I'm running
separately concurrently to
one else so this whole thing can
definitely be more efficient right I
could still be working on a message
number one and already starting to
process and receive message number six
while at the same time I'm preserving
the order of those messages and this is
essentially improving throughput at the
cost slight cost of latency due to the
cost of this message passing this thing
is still are as efficient as its weakest
link which is again step number four
store into the database but as it just
as it happens at the time at the point
of one store stuff to the database I
actually have everything ready for my
user interface so I can can in fact a
run this thing completely concurrently
to this main pipeline and because this
is of course an oversimplification of a
real thing there are some other tasks i
need to do based on those incoming data
and I can do this concurrently as well I
need to read some stuff from my own
database and I can do this concurrent
and then inject it to the pipeline where
needed by sending a message right I'm
relying on some third-party services
again the same thing and by doing all of
this i'm making this main pipeline
focused on its main task right which is
to take the data transform it and ship
it further and this is first of all this
is of course more efficient but it's now
more fault tolerant i can tolerate all
kinds of weird situations a controller a
database Croatia's third party services
crisis and i can still get the data and
bring it to the user at new real time
right so this will of course not be a
full service because I display the data
on the user interface they come back to
the system the validation fails because
we require this data to be in the
database now even this could be worked
around we discuss some options but
legislations and other business
constraints prevented us but this is
still a huge thing right even when
database crashes I have some part of my
service and I will resume the full
service as soon as I reconnect to the
database now putting this storing thing
out of the Python does not relieve the
pressure there there's still a lot of
pressure but we have to store a lot of
data frequently so it's further
subdivided but I have different
processes / different types of entities
so I can store those things concurrently
then especially for those betting odds
which is where the biggest pressure is I
have a separate process for explicit
queuing and another process for storing
those things so I can do some funky
rearrangement I can I want to do is I
bet
adaptively batch multiple items and I go
to the database with a single round trip
and I can store multiple things at once
right this improves my efficiency I also
rearrange stuff I prefer new stuff to
old stuff so if everything is fine I
store everything but if something goes
wrong maybe database becomes a bit too
slow for me then I discard some stuff
and this is the old stuff which is more
probably already obsolete and then then
I can do some some of those
interventions it's not perfect right but
it keeps me afloat in some problematic
times and there's a whole bag of tricks
i'm using here and again concurrency is
the main driver but what really boost my
concurrency level is kind of
acknowledging the fact that i'm dealing
with multiple matches which are for the
most part if not completely independent
things and i can exploit this fact and i
can process matches concurrently right i
can hear like those mini pipelines per
match for as long as the match is
running and then just for each incoming
message ice cracking split / matching
forward to corresponding things and this
of course makes me way more more
concurrent right just a few slides ago I
was purely sequential and now given that
we have some 50 matches at peak times
i'm already in lower hundreds and of
course it goes without saying that not
all of these things will be always busy
right but whatever work I have at any
point in time that work will be shanked
I will have more smaller independent
chunks of work which the vm itself can
and more efficiently spread over
whatever Hardware is available to me so
this is more efficient this is more
scalable and this is more fault tolerant
because failure is now it has less
impact what if something goes wrong
while processing a single match it's
confined there well everything else is
pushed without any interruptions most of
my service works perfectly fine I
recovered from this failure concurrently
and resume the full service and
ultimately this approach sets the stage
for going fully distributed to run
things on multiple machines have
multiple machines or different machines
process different matches have some kind
of a mapping rule and because the number
of simultaneous matches is the load
generator here right the more matches I
have the more messages are coming in the
more work for me to do this kind of at
least in theory gives me the possibility
to deal with an endless
number of matches it will of course
break at some point but I have some at
least some direction and I'm already
there and concurrency is the driver for
that thing so yeah let's more or less it
if you're interested maybe one no more
the expanded transcript of this talk is
available in form of 400 pages book yeah
there should be some discount available
outfit about it soonish and with this
same with shelf so Sheamus L plug I more
or less than so yeah thank you for your
attention
ok we have questions yes yeah well first
of all the Erlang cluster is a fully
connected everyone talks to everyone so
I think there is like some limited well
what is it is hundred or something like
that we should hear about it when today
tomorrow today we should hear about it
today more but it kind of the more you
have the more note you have at some
point you break but I really think even
without this property I'm not sure how
it will work so I'm curious to hear what
the cover in store today yeah yeah
that's a good question that definitely
all options are possible now I don't
have a lot of experience with react or
but I think it does some of this stuff
but it's kind of a guesswork it's
definitely possible right you can you
have to just program around it if it's
not implemented that goes without saying
for this particular case the database I
was talking about is a microsoft SQL
server I like the company like some year
and a half ago so I don't know at which
version are they now the thing the
interesting thing about it is that it's
a legacy thing used by many different
applications so this is just like the
one smallish application in the system
and many of those things are using even
those same tables there are some complex
rules there and I don't really have even
a quite or didn't have a control over it
a lot of control right I couldn't do
like what I wanted with it especially
not change it had it had to be there in
that place we have here Jim there
I don't know I'm personally a fan of SQL
stuff so I would probably go maybe
postgres or something like that it's
hard to tell it's a very very question
it really depends on your use case but
if I don't know anything else I would go
always for SQL
yeah that's a good question first of
first in the first iteration I had just
like some tons of logs and basically it
was grape and stuff like that and that
in gradually kind of went to I'm
blocking sorry the graphite es so we
were kind of putting some metrics and
stuff to graphite but the main debugging
tool for me was always tons of logs yeah
you have to log a specially when stuff
is happening concurrently this is
impossible to debug you have to log many
things that are happening for many
different points of view so you can kind
of reconstruct what went wrong
well first of all we are talking about
this slide here right yeah so maybe I
wasn't clear enough this is science
fiction right so this did not happen but
when it happens basically you have
multiple options most probably i would
go for the mathematic one which somehow
you compute the hash module or something
and then you put it and then you feel
like unique rule of no matter where the
data lens how you go there and there are
some then finishes like constant hashing
because this is of course prone to
adding new notes or removal of notes and
then you have some other other
approaches to how to minimize this move
ability of data so to speak but yeah
that's kind of one one approach
well it's hot it's kind of a good
question so you have definitely a lot of
stuff ready right this messaging thing
it really works no matter where it is
and because you use it a lot in your
system most of your system doesn't even
care where the target is you have some
simple but very powerful support from
the standard library of her lung I tend
to use the ominous global module it kind
of has a bad name because you think that
you shouldn't use it but it has a nice
support for elekton elect a leader so to
speak a thing that is Authority for
something in the system right and it
works in a very chatty way it's blocking
but for some simple cases worked fine
then you have libraries like millions
iterations or instances of gin leader
and those kind of also can help you to
elect a leader it's not a simple problem
but it really I don't think there's like
one size fits all solution there so you
have some building blocks in place and
there are some libraries that might work
for you definitely yeah
well it was definitely hardest getting
into this mindset right I came from an
object-oriented perspective and I did
like million things wrong it's I should
do a whole talk of what I didn't you
shouldn't do right but kind of elixir
connection is the book which is aimed to
kind of guide you towards the proper
place right so that was definitely took
me a while to stop abusing things I have
to say I was really impressed even when
I didn't really know what I was doing
and did many things wrong that even such
situations this foundational stuff the
vm would take care for me and some
things would survive some bizarre
failures and stuff like that but still
the system would survive and keep moving
on and i would be able to see the logs
and recover from them so yeah DEP thing
is definitely there is a learning curve
because it's a different mindset if
you're coming from it oh oh it's not a
rocket science and that's that's my
position but it will take some time to
get used to it yes we have in front row
no I actually also used elixir but it's
in the quantity ratio it's almost all
along some crucial Parts I have written
in a lecture at my own spare time
because i felt like it and it actually
even helped me refocus on some stuff and
improve something but most of the things
yeah we can say it's a long based well
probably it depends very coming from
right so if you come from like an
object-oriented world a special Ruby i
would say elixir would be easier for you
maybe some other especially ireland
program is full of of course enjoy it
more in Erlang right so now these days
i'm doing a long completely at my
current company when i came there was a
lot of code based in orlando already and
those guys know Orleans so it didn't
make sense to insist on converting right
so it's really a point of view I think
personally that if I were to start I
would choose elixir because of some
support I get in language and some
support that are getting tools right but
there are interchangeable and they're
mixable in some way
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>