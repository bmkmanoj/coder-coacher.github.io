<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Mark Allen - Before Unix: An Early History of Timesharing Systems | Coder Coacher - Coaching Coders</title><meta content="Mark Allen - Before Unix: An Early History of Timesharing Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Mark Allen - Before Unix: An Early History of Timesharing Systems</b></h2><h5 class="post__date">2016-11-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UYb6WqWBTE0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's really exciting to be here with you
today thanks for coming to my talk I
know there's lots of other talks that
are going on that are also really
interesting so thank you for being here
with me but I do want to talk about time
sharing I got really interested in this
topic last year actually I did a talk
for another conference which was sort of
the early history of concurrency /
distributed systems and in that talk I
went through about 15 years of history
in 50 minutes something like 21 papers
anyway a big part of that was like
centered around operating systems that
dealt with concurrency and so I really
got curious about where did this idea of
time-sharing come from I think most of
us in this room are a little bit
familiar with the origin story of Unix
in terms of you know it got created in
this small research lab you know and
just sort of grew and grew and grew and
there was sort of a number of very
fortuitous circumstances that led to
UNIX becoming quite popular one of the
big big ones being that you know
computers cost significantly less than
they did in the 1950s and the second one
was is that UNIX was a portable
quote/unquote it's a it was able to be
moved from system to system to system
and and that was something that was was
actually quite useful in an unusual
certainly the systems were going to talk
about today are very tied to specific
hardware implementations and all of the
time sharing implementations that I'll
that I will be talking about today are
very tied to specific hardware
properties that those systems provided
to their to their software developers so
this is the agenda for today I want to
start off talking about project World
Wind project World Wind as we're gonna
as we're gonna get into here is a really
interesting project that was started in
1944 it was started at MIT and one of
the reasons I wanted to talk about it is
for two reasons one is is that I think
the the sort of super early history of
early computing is really interesting
and project whirlwind is certainly one
of the earliest parallel computing
platforms in fact if you look on
Wikipedia they sort of say that it's the
first supercomputer of its day I don't
know if I would be that grandiose about
it but it's pretty it's a pretty
impressive engineering achievement and
also I think the the history of computer
memory it was really fascinating to me
so I'm gonna tell you about it because
you're already here you know so yeah
you're kind of stuck so sorry you're
gonna learn about computer memory in the
1940s today I hope that's all right with
you the next i want to talk about the
origins of time sharing so this is kind
of like a quick sketch history of like
who came up with the concepts and how
did they come to be popularized and
we're gonna dig into that quite a bit
then we're going to you know see our
hero protagonist appear is a man named
fernando corbata we're gonna talk about
him quite a bit today he actually ended
up working on project whirlwind and was
at MIT and built the system called cts s
under the supervision of some professors
there and he later became a full
professor at MIT and finally we're going
to talk about multix which is sort of
the immediate predecessor of Unix
certainly many of you may be familiar
with it from from the discussion of how
it impacted UNIX history but we're going
to talk about multix a good bit today
too so let's get going
because I do have way more material than
I could possibly talk about in this time
slot so yeah time is precious but
hopefully I will have enough time for
some questions but anyway let's get
going so like as I mentioned world winds
started in 44 it was a project by the
United States Navy they wanted to build
an airplane aircraft simulator they had
a lot of aircraft that were brand new
towards the tail end of world war ii
it's very expensive to train new pilots
and it's especially expensive to train
them an actual aircraft that can crash
and kill people so what they wanted to
have was a simulator this might sound
sound familiar they wanted to build a
simulator that that could be controlled
by some machine or some apparatus that
would simulate flight instructions so as
a pilot would move the the control stick
around in the simulator the you know
surrounding sort of artificial
environment
the simulator would change with it and
this was led by a man named Jay
Forrester who is actually a fairly
famous MIT professor he started on this
project in 44 as I mentioned and worked
on it for a number of years they started
out building an analog computer they
felt like an analog computer would
probably be fast enough and that was
actually quite a common decision to make
at the time the number of digital
electronic digital computers in 1944 was
very small and there's really only a
handful of them in the whole country and
even in the whole world and so they
built this analog computer and it just
wasn't fast enough it couldn't do the
computations quick enough to respond in
real time to a human moving the joystick
and and I think it's something that's
really interesting to me is a parallel
that we see with artificial I'm sorry
Virtual Reality developers today one of
the big things that they have to deal
with is this latency between the time
when your head moves in the perception
that you have changes and they were
dealing with the same thing in 1945 when
they were building these experimental
systems to try to build flight
simulators so they built an analog
computer but it's too slow it didn't
work well enough and so what they
decided to do was build a digital
computer one of their team members went
to the University of Pennsylvania where
they built a machine called ENIAC that's
really a fascinating machine and if
you're interested in that there's a
really great book that you should buy
whose co-author is actually sitting in
the audience today and so they saw ENIAC
and they thought that well maybe what we
should do is build a digital electronic
computer and that's what they set out to
do so the specs of this were that they
needed to be able to do thousands tens
of thousands of computations per second
and they were able to achieve twenty
thousand offs per second in 1952 they
felt like that was the lower bound of
acceptable the the actual specification
was to do fifty thousand operations per
second and they were able to achieve
that later in like 1957 but the the
biggest issue and the biggest blocker
that they had at the time was that the
memory system was too slow I just wanted
to show you this is a photograph of Jay
Forrester he's working on this console
back here and then over here on this
side is is the actual sort of output
module that controlled the
me later the thing that was really
interesting to me is this is a lady I
don't know if you can tell that but
there's there's been a significant
achievements and contributions by women
in this field even from the earliest
days working on computing even even in
the 1940s all right so this is a great
quote that I found in a paper that I
read about whirlwind was written by
Robert Everett Robert Everett was one of
the chief engineers it worked on
whirlwind he was a j4 stirrers kind of
assistant but I think this is true now
and it's certainly true in 1952 he said
what the computer business needs and has
needed it and will probably always need
is bigger better and faster storage okay
who disagrees with that no one okay all
right so let's talk about computer
memory because I told you we're going to
so now it's time whirlwind needed to
2016 bit words of memory and in the 40s
and early 50s there are only two types
of memory that could could provide that
much capacity and I know that sounds
like a miniscule amount that's that's
basically like 4k of what we consider to
be memory now which is you know
literally you cannot buy chips that
small anymore but in the 40s and 50s
there were only two types of memory that
had that capacity there's one that's
called delay line which was a really
interesting system that we're going to
talk about next and then another that is
called electrostatic that uses magical
physics that I don't understand so don't
ask me a lot of questions about it but
that's how they did it so delay line is
a really interesting technology that had
its roots in radar technology from World
War two it was actually invented to
remove static objects from radar
displays so if you send a radar signal
out into the world objects that are not
moving will always respond in a constant
time and early radar systems didn't have
a way to remove those and so operators
would get confused by you know really
tall buildings or Hills or you know
things that were obstructing the radar
signal and they would give erroneous
information to pilots that were
scrambled to you know go off and
fight sorties and so what they wanted to
have was a way to eliminate them from
the from the display system and they
came up with this technology called
delay line and what delay line does is
it basically delays a set of information
for a given amount of time and this was
what was originally used for so they
would they would send the signal out it
would come back it would be processed
they'd send it through this delay line
signal and then things that were didn't
move in that amount of time basically
were removed from the image they could
take the original signal and the one
that came through the delay line and
merge them together and they would
cancel each other out excuse me
so in delay line memory bits are
represented by sound waves it had a
microphone that sat out at one end of
the delay line and it would emit sound
signals into a medium they used mercury
for this and you know there's a lot of
reasons why mercury is a less than ideal
circumstance to store information in one
is that it's really heavy and two is
that it you know it's really toxic and
the third reason is that it's really hot
because sound moves through mediums at
different speeds at different
temperatures the delay line circuits had
to be kept at a constant temperature of
about forty to forty degrees Celsius is
about hunt' degrees Fahrenheit and the
the picture that I have over here is
this was maurice wilkes he's a really
famous computer scientist from
manchester and he built the EDSAC and
he's actually it's hard to see in this
photo I'm sorry but he's actually down
here inspecting a coffin and they had
all these delay lines that were like you
know 18 feet long tubes of mercury that
weighed you know about 25 pounds of
piece they had over 500 pounds of
mercury in this whole system and and
they would be heated up in these coffins
that actually laid between the racks of
computer equipment and that's how they
stored that's how they stored their
their memory one other interesting thing
about this that I found out was that one
of the primary inventors of delay line
memory as a as a storage technique was a
man named presper eckert and you may
know presper eckert
as the was one of the entrepreneurs that
started UNIVAC and also worked on ENIAC
and some other early computing systems
and and so he he actually worked on
radar systems in World War two and
that's how he came to - to deal with
this engineering principle all right so
let's talk about electrostatic memory
now it this this is a picture of an
electrostatic memory tube it's about
this long it's probably about that long
and it's that that entire tube stores
one bit of information and it also cost
a thousand dollars in 1940 that's ten
thousand dollars in today money and it
lasts for about one month so you get one
month of storage for one bit for 10.4
for ten thousand dollars okay and and
remember that you need four thousand of
these okay so yeah so this is not a
cheap thing to do right and so Jay
Forrester was like we can't afford to
buy 10,000 or 4,000 of these things
because we don't have even the US
government was not going to pay four
million dollars for them to go out and
buy all these electrostatic vacuum tubes
and so he was like there has to be a
better way to work on this and it turns
out that there is a better way there had
been some really interesting and
groundbreaking physics that was going on
at the time in about 1948 there was a
breakthrough in magnetic storage
technology and the breakthrough was is
that they had finally worked out a
system where they could charge a
toroidal magnet on a grid and they could
apply a charge to it selectively and
they could use that to replace all of
this stuff and so that's what they
invented this is magnetic core memory it
was patented in 1951 it was invented by
Jay Forrester who we've talked about a
few times already
essentially the way that it works is you
can see that all these there's all this
grids basically there's a columns and
rows and at each intersection here
there's a little toroid which is a
little iron doughnut basically and they
would apply a charge to that and it
would selectively apply electromagnetic
field to it and it would charge itself
and then they could tell if the presence
of electromagnetism or not would
indicate if a bit
was to be stored there right and so it
was random access something I left out
that's really important about delay line
memory is that is sequential right and
on EDSAC it took about four hundred
microseconds to cycle through an entire
storage array of memory so if you needed
to store a bit at position ten and you
were already a bit position 50 then you
would basically have to wait for the
entire thing to cycle through again
before you could inject the new value
into the memory stream so clearly it was
too slow too expensive too toxic too
heavy too hot so there's a lot of
reasons why they wanted to invent stuff
like magnetic core memory all right so
it's reliable fast cheap like I said it
was invented by by Jay Forrester and and
they specifically built this core memory
this picture is actually from a part of
whirlwind and like I said they they fit
they finished in 1951 and in 1952 when
Robert Everett wrote that paper I quoted
earlier they were still using
electrostatic memory but by the you know
within a couple of years they had
replaced all of the electrostatic memory
with with magnetic core all right so so
let's talk about the origin of
time-sharing
again I think this is a really
interesting topic excuse me
all right so everyone probably knows who
this is if you don't it's John McCarthy
he was a professor at Dartmouth in the
early 50s and he later came to MIT as a
doctoral of research fellow so he wasn't
even officially on staff he came to MIT
in about 1957 and he did all sorts of
interesting things like invent Lisp and
garbage collection he worked on Algol
for a number of years if you're
interested it's sort of more in the
biography and history of John McCarthy I
did talk a couple years ago it's strange
loop about early programming languages
and if you're interested in that I
highly encourage you to watch it on
YouTube he wanted Turing award in 1971
and so he's he's pretty famous he wrote
this really interesting memo in 1959
where he proposed to to the to the
the director of the MIT computation
centers means professor Philip Morris
Morris was the director of who is it was
in charge of the relationship between
MIT and IBM at the time IBM and MIT had
a really close relationship and IBM was
actually giving MIT millions of dollars
worth of computing equipment for free
essentially to you know train engineers
to use IBM equipment later when they
graduated and you know went into
industry and stuff like that so he wrote
this reminiscence and what I really
wanted to do here was try to describe
what time-sharing means in the sense
that John McCarthy meant it because
there's an earlier paper in 1959 by
Christopher strikey who is a professor
also at Manchester for a long time and
actually talked about yesterday at
Rachel Reese's talk about the sort of
the history of F sharp
but anyway strake he wrote this paper in
59 they talked about using time sharing
as a debugging aid but John McCarthy was
thinking about it really is a way to
interact with computers in a totally new
and different way where every user could
pretend that they completely controlled
the all of the computing device so they
could use the computer as if no other
users were using the computer even
though many other users were actually in
reality using it and so he describes
that in this reminiscence and I think
it's important to talk about what the
sort of normal mode of operation was in
the 50s and that's this it's a batch
mode so so what they would do is they
would take a whole bunch of jobs that
usually came on punched cards they would
run the punch cards through a secondary
computer and those would get written on
a magnetic tape so the magnetic tape
would be the unit of transfer they'd
take the magnetic tape off the secondary
computer over to the big main computer
they would run all the jobs from that
one magnetic tape through the big
computer and this might take hours and
then that would go onto another magnetic
tape that was the output they would take
that magnetic tape off of that main
computer go back to the secondary
computer and then they would do line
printing so it would print out all the
results from from all the jobs that got
started during that batch run so it was
like a bus right as everyone gets on the
bus the bus goes somewhere everyone gets
off the bus you're done and it was super
frustrating for people especially
programmers who wanted to have more
immediate fee
back on what their programs were doing
and you know as a single error would
basically cause your your entire run to
abort it could be hours or even maybe
days before you got to run your program
again this is what McCarthy said and I
think it's really good quote computers
were developed with this idea that
programs would solve general problems
and the time would be spent running
these standard programs against new sets
of data but the actual situation is
closer to the opposite and this is this
memo that I mentioned earlier that he
wrote to two Phillip Morris and Phillip
Morris was was supportive of the idea
but as corbata
mentions in an oral history later that
he didn't appreciate time sharing he
didn't really understand that you know
it was something that was revolutionary
and new and the the thing I love about
this quote is that corbata says that you
know the appreciation of time sharing
was proportional to the amount that you
personally programmed right the more you
program the more you knew what it meant
the more you understood how valuable it
was and how new it was all right so I
wanted to run through a quick timeline I
felt like the best way to do that is to
just build a chart so in 1957 McCarthy
arrives as a research fellow he proposes
right away modified at the time they had
an IBM 704 704 is a super early IBM
computer total 100% vacuum tube
technology very slow very cumbersome
extremely extremely expensive but also
quite productive many people in industry
already had one especially very large
companies like you know engineering
heavy firms like Boeing aircraft
companies car car companies stuff like
that and so so IBM had already done a
real-time what they called a real-time
package that allowed Boeing to input
wind tunnel data into their IBM 704 and
so they had IVM had already done the
engineering work to to do interrupts and
and things that were necessary for doing
quote real-time operation like
interactive time sharing and so he
proposed that you know MIT acquire one
of these and modify their computer and
move forward with that so they made this
request but it actually wasn't delivered
for two more years so in 1959 IBM
delivered a new version of their
software or their hardware called a 709
which is also all backing tube
it had all these real-time modifications
that they had asked for and he
demonstrates an interactive list with
one of his students and this is a very
crude custom system so they had a
professor at MIT named Herbert Teager
and he was the leader of the real of the
of the time-sharing committee that
they'd that they'd set up and he
actually modified built from scratch
three Flexer writers which were like
these you know basically electric
electric typewriters that had computer
output and he modified them to be able
to interface with the with the up links
for the for the wind tunnel modified
modifications but one of the things
about Teager was that a lot of
colleagues at MIT felt like his
ambitions were vague and so they didn't
support him very well and then I
mentioned about strake he down here he
published his paper at a very large
conference in Paris in 1959 it's called
time sharing and large fast computers
but it mostly deals with this idea of
multi programming if you're interested
in the history of multi programming I
did a talk last year about that which is
also on YouTube and you can find it but
McCarthy had this idea of a virtual
computer that's a little more expansive
and encompassing than than streaky's
concept alright so McCarthy starts
consulting with bolt Beranek and Newman
and I in 1960 he happens to run into
someone named JCR Licklider Licklider
czar also a really interesting guy it's
pretty famous has written some
interesting papers at the time in 1960
he had just finished writing a paper
called man-machine Simbi symbiosis which
is a really fascinating paper and if
you're interested in that you should
read it but he talks to people at
digital equipment about time sharing and
he also talks to a lot of other people
including JCR Licklider about time
sharing and how useful and renovate and
and and revolutionary it is and they
agree with him and so they start working
on their own parallel time sharing
projects in in concert with with MIT in
fact Digital Equipment gave MIT a pdp-1
to work on a time sharing system that's
worked on by Jack Dennis and Jack Dennis
and his students have published quite a
bit of papers about time sharing too
from this general time that are
interesting and worth
looking on alright so then in 1961 the
computation center is run by Morse as I
mentioned a few times and they they
finished an early version of CTS s that
runs on the 709 now keep in mind the 709
is all vacuum tube technology does not
have any magnetic data storage outside
of tapes and punch tapes at punch cards
and paper tapes and and some of these
flexure writers right they had these
three special flexor writers that had
been custom-built and it's led by this
man named Fernando Corbett oh and time
sherry is it's demonstrated by Corbett
Oh also Mahaney Bryce's paper that I
cite later on in my talk and then in
1962 there is the functional prototype
so this is a little bit more cleaned up
and they call it C TSS he writes his
paper and it enters regular production
usage in 1963 one of the things that's
very important about 1963 is that IBM
finally supplies a transistorized system
so one of the big changes that happened
from this time line from all the way
over in 1957 to 1962 is that transistors
were invented and become available in
commercial scale so they can start
building computers out of them and
transistors as you might imagine to are
about 30 to 40 times faster than vacuum
tubes so it's huge huge huge all right
so this is for nano Corps bot oh I've
already mentioned him a few times he
actually was a was an electronics
specialist in World War two when he
graduated from high school he went into
the Navy and this was before he went to
college so he was in the Navy for a long
time and he learned how to do a radio
technician work and sonar work and a
whole bunch of other electronic things
that the Navy was putting on ships after
he left the service he went to Caltech
in 1950 and studied physics because he
was interested in physics and then later
he went to MIT to get a PhD in 1956 and
at this time he he started working on
whirlwind the reason he wanted to work
on whirlwind was because he needed to do
computations for coefficients in his in
his physics works of generating the
coefficients by hand was quite laborious
and took a long time and the computer
could spit them out in a you know a
matter of hours so that's how he got
involved with programming and understood
that real-time interaction was very
valuable to him he was also the the
deputy director of the computation
center later and he led the design on
multics and also programmed most of CT
SS and he won a Turing award in 1990 for
that work here's the video that I
briefly played earlier in this video
clip I just wanted you to see this
there's a fantastic video of corbata
demonstrating the entire system for
public television a program that was
shown in Boston and in 1963 corbata
actually has to had a digital copy of
this it was transferred to videotape and
then to CD and then now it's on YouTube
because everything ends up on YouTube
and so anyway this is core Bato kind of
explaining how time sharing works to his
his the reporter that that he was
working with what we have is we actually
know he's one master program which I'll
call a supervisor and this is the
program that is going to run everything
and normally this computer when it's in
the time sharing mode is operating a
program in the supervisor we also have a
program for each of the typewriter users
the u 1 u 2 u 3 u 4 and so forth they
might not be the same size no they're
not all the same size that's quite right
that's what I meant to try and convey
now the consoles have to type in to the
computer and they type in to the
supervisor and back out so the messages
are handled by the supervisor for each
of the programs now the supervisor is
going to relay these messages to the
particular programs as they are and keep
keep track of which users talking to
which typewriter of course and so forth
and in this would be straightforward
enough except that quite often we'll get
more programs and we have room for yes
all right so so that's one of the
problems they had was that they had more
user demand than they had resources
right
so they had to share them somehow and
we're gonna get into some of that in
just a few slides here I'm gonna I'm
gonna give McCarthy the last word here
he says I still don't understand where
all the computer time goes in time
sharing installations and neither does
anyone else
so you know there you go all right so we
talked about CT SS as I mentioned the
prototype rain on the 709 the supervisor
ran in the core memory and all of the
other user jobs were in higher memory
locations and the the neat thing about
cts s and the reason it was called
compatible was because it could continue
to be used in batch style operation even
as time sharing users were connected to
the system so that's how they meant
compatible most of the people at MIT
called it the CT SS and they never even
knew what CT SS stand for they just knew
that it was the system that they used to
log into the computer and run their run
their programs so I wanted to talk just
quickly about the effort and the size
just to give a sense of like how much
work was involved in building the system
there was a really interesting paper
that was put out in 1966 by Gerry Salter
he actually was a really interesting guy
who wrote a bunch of interesting
programs that as I probably tweeted and
if you follow me maybe you saw that but
one of the things he wrote is a program
called runoff runoff is like the the
early early earliest version of of Roffe
which you may be familiar with and then
later you know turned into stuff like
latech and other typesetting systems so
this was like this is a this is a paper
that he wrote so he described how long
it took and how much effort it took but
the contemporary compilers of the day so
things to run Algol things to run
Fortran those those systems weighed in
at around 11 to 16 thousand words and a
word in this sense means an 18 byte our
18 bit sorry not 18 by 18 bit word so
we're talking about you know we think
about bytes as 8k or 8 bytes or I'm
totally getting confused we think about
bytes as being 8 bits and in those days
they had 18 bit words so that's you know
a little bit bigger than then 2 bytes
and the CT SS supervisor was 12,000
words and then they had 6,000 more
words to describe commands so the some
of the commands that people could use
were log on log off us you know edit
input load start you know sort of the
standard system you know utilities that
you might expect to have in a time
sharing system I think just you know for
interesting contrast my slide deck here
including the video and all the all the
all the pictures is about 100 megabytes
you know so so it's significantly bigger
than the CT SS supervisor so I also
mentioned that corbata was the lead some
of the other programmers that worked on
the system were were a lady named
Marjorie merwin Daggett and Robert
Dailey and they also wrote papers and
and had published works about CT SS that
are interesting co-authors on on one of
my citations so corbata said that you
know most of the battles that they
fought during the development were
solving problems that that no one ever
had thought about solving before and
some of these things are like memory
protection io device how to decide who
gets to see what messages saving and
restoring user state right between time
slices you know when it's time for your
your slice to go off the the cpu how do
you store it how do you get it back into
memory also how much time does the user
get like what's the right time slice to
give a user for their computations how
much do they deserve how much do they
get and then is there satisfactory
responsiveness right so if you press a
key on the on the on the typewriter how
long is it before you you see a response
from the computer you know and that's
actually something that was interesting
this this next slide is a great picture
we've all seen pictures like this right
in our graphs and in metric systems so
this is this is from a paper that was
published in 1962 and what it describes
is the service level versus the number
of users and we're all familiar with
this curve right we hit that point in
and then basically it goes to zero so
corbata saw that a long time ago and
wrote about it in this paper so corbata
described this as a breakthrough success
in later writings and in oral histories
you know users were very
five with CT SS they were very happy
with the online storage of programs and
data they could do remote operations
remember prior to this you had to drop
off your card deck somewhere and then
later you'd magically get a printout of
your results now you could go to a
computer terminal that was not
necessarily right next to the machine
but you know could be in your office or
it could be in your professors office or
it could be in your laboratory and you
could interact with the computer run
your data sets run your programs and get
results right away and it also made it
really convenient for users to share
information between one another so you
know if professor was working on a
program and his colleague wanted to look
at it or be able to access it it would
be possible for him to do so in the past
it would be very difficult to share that
kind of information with someone else
all right
also transistors and random access disk
files were really important so one of
the things that that I cut the video off
but corbata goes on to explain how the
the the disk devices that they had made
it possible for them to store very large
quantities of data and by very large I
mean for the day right like in absolute
context my phone has way more storage
than then then all the computers at MIT
for the entire 60s but but certainly for
the time it was very very important to
them but users once they got used to C
TSS started to demand some some
improvements they they you know we're
satisfied with it but it could always be
a little better right we've also heard
this from everyone so users who endured
hours of waiting for for batch processes
would be annoyed by the fact that would
take a second you know for a response to
come back from a computer we've all been
there right a one-level file system
right C TSS had a very simple one level
file system at you can imagine that over
time that gets really cluttered and it's
hard to figure out what does what's
yours and what's new what's what's dead
what one needs to get rid of and then
finally you know he felt like the more
and the more we provided them the more
they wanted which you know I think all
of us can sympathize with that too
one really interesting thing that
happened during C TSS one day was as the
system grew in importance and also in
complexity they had about a dozen system
programmers the system programmers were
responsible for maintaining and
extending the system software
and they had an editor system and the
editor system had an assumption that
what that was only one person could be
logged into a directory at one time and
so the editor wrote a temporary file
with us with a static name it used the
same name for every file well one day
assistant programmer at one terminal
logged in and started to edit the
message of the day and in another
terminal another system programmer
logged in and started to edit the
password file and so what happened is is
that the password file got put in as the
message of the day and the message of
the day got put in as the password file
and so what happened when you logged
into the system was that you saw
everyone's password in clear text and
this is before they ever had like
one-way hashing functions and certainly
computer security was not even an
afterthought at all so so that was a big
problem fortunately what they had was
that any user could actually crash the
system what they would do is go into a
debugger mode and then they could type
in a direct assembler they could type in
the assembly directly to the computer
CPU and one of the instructions that you
could do was called xec and XTC would
put the computer into an infinite loop
and it had to be hard reset right
completely shut down and restarted and
so what happened after this is one of
the assistant programmers saw that
dropped into the debugger typed in XC
seed star hit enter and then the
computer crashed and so no one could log
into it so that's what happened he he
recounts that in one of the one of the
papers also if you're if you're
interested in that story in the full
context I have a citation for for
reminiscence from from one of the system
programmers who talks about the event
too so let's talk about multix in the
last little bit that I have left to talk
today so first of all I want to talk
about some myths and a lot of people
think that multics was a failed system
that it was never completed it was never
released to production and never ran
anywhere but that's not true and we're
gonna talk about like why that's not
true one of the questions I that's that
I've that I've asked is why why do we
want to develop multics right see TSS is
really popular everyone's pretty happy
with it I mean there were user
complaints right but there's always user
complaints you could have the most
perfect system in the world and someone
would want it to be different somehow
but basically they the development team
felt like they could start over so they
learned from CTS s they really felt like
it was a prototype
it was a mature prototype it was
successful people were happy with it but
they felt like they could do more they
could really if they just threw away
everything and started over from scratch
famous last words
then it could be a lot better right
we've all thought this right has anyone
here not thought that I mean all
software developers I know I always
think well if we just get rid of the old
system and I could just tore a
completely new system would be a lot
better well they had the same thoughts
about you know let's build a new time
sharing system that's really going to be
great so one interesting thing about
multics that was unusual at the time was
that they spent a lot of time trying to
find industry partners so this was not
just you know an MIT led project they
wanted to find people in industry to
work with them and one of the reasons
they wanted that was because they had
some ideas about how they wanted to
handle memory protection and other
things that require hardware support and
at the time IBM was really not
interested in pursuing this they felt
like batch operation was you know great
for everyone and they sold lots of
computers doing batch style operation
and there was no reason that you'd ever
want to do time sharing and the systems
that they were working on the platforms
they were building at the time didn't
lend themselves in a hardware level to
doing time sharing systems and so they
went out and they found a partner at GE
that had a new computer division they
just started because in the 60s every
company that was large enough built
computers like literally every company
you can think of there's like seven of
them I think Philco RCA General Electric
Honeywell Burroughs Sperry Rand at the
time they were called Remington Rand and
remember Remington Rand is a is a
company that builds typewriters and also
ammunition cartridges and other things
but anyway everyone built computers in
the 60s and so they found partners at GE
and Bell Telephone labs and maybe that's
where you've heard about multix in the
past here's some first that multics did
in the system it was the first one to
use memory segments and pages so maybe
you're familiar with the idea of pages
they had privileged rings around the the
the the kernel so there were different
privilege levels and as you you know
moved up in privilege levels you got
more memory access this was a means to
protect programs from malicious users
and also from errors in the
I'll code the virtual memory system
including this idea of swap and mapping
files to virtual memory is something
that that multics accomplished and the
hardware sister was could be composed of
multiple CPUs Ram banks storage devices
and they can be reconfigured online so
you could you could modify the system
online without having to take it down
and one of the other firsts that's
really unique for for multix was it was
written not an assembly language so if
you if you follow the history of
computing programs you'll see that you
know writing things and not assembly was
a very uncommon especially for operating
systems so they decided to use this
language called PL 1 that was the new
hotness III called the JavaScript of
1965 it it had good points and bad
points let us say why did it take so
long so multix started in 1965 1964 and
it really wasn't delivered as a product
until 1972 and that's an extraordinarily
long time and famously Bell Telephone
labs dropped out of this of
participating in this project because
they felt like it wasn't moving fast
enough for them and that's kind of the
genesis of where the unix creation story
starts is at that point in 69 anyway it
took so long for a number of reasons
some of them was that there was no
benevolent dictator for life
there was no arbiter of taste it was all
these companies trying to work together
there was no like decision maker that
could say yeah that's a good idea that's
that's not such a good idea
they would have to basically build up
prototypes and make sure that they were
strong or weak something else that that
was a big problem was that there was no
functional po1 compiler until about 1967
so they were already two years into
their project before they actually had
functional compilers before that they
were using sort of compilers that that
were built ad hoc were partially
complete that used languages like BCPL
and stuff like that and interestingly a
Rachel Reiss talked about BCPL yesterday
in her talk so if you missed that you
should you should watch it later on on
YouTube this is a great quote from from
core bot oh you know he says there was a
brutal period when we discovered we
built a monster there were a lot of
instances of
inside multix one of the problems was
that we were all young and naive we
couldn't see we'd built something that
was complicated only under the duress of
realizing it was awful did we dig in and
realize it didn't have to be that way I
think we've all been there at one point
in our careers and there's something
else he said I really liked was it's
trial and error a SPECT of system
synthesis which i think is a major
factor that people underestimate in a
huge amount of the difference between
engineering projects to me is a degree
that the participants have done it
before if they've done it before it's a
piece of cake sometimes if they have
never done it before it can be a hellish
adventure all right well I think we've
all been there too and then finally
there's this one which I thought was
really interesting which something that
I had a media question was is you know
in 1965 choosing pl-1 was a pretty bold
like risky thing to do and so he
provides some rationale why they did
that you know he says in retrospect it
was a monstrosity to use this but our
conviction was that we had to have a
compiled language and I think it was
dead right
the next problem was that we wanted one
that was relatively advanced and
flexible and there weren't many choices
and then that is true
the third key ingredient was that Doug
McIlroy and Bob Morris at Bell Labs who
had considerable expertise and wanted to
take responsibility for language as well
as quite persuaded that peel one was
good choice so their partners had told
them and you know and he sort of cajoled
them into into being able to to use pl/1
as their primary development language
but it turns out that that maybe that
wasn't such a good choice and you know
corbata in retrospect agrees with that
assessment
so anyway multix was a successful
product in 1970 honeywell the people
that make thermostats they acquired GES
computer business from them lock stock
and barrel they also acquired all the
multix
IP that the General Electric had been
working on and the team at MIT MIT and
Honeywell worked together to complete
the system in 1972 it was commercially
available for a number of years that was
mostly bought by government military
installations and installation sites and
actually started to run some of the
liked radar systems and defense systems
that would track missiles and a sorry of
other you know flying objects
UFOs but you know aircraft and stuff
like that aircraft control systems for
military installations mostly so that's
what multics was mostly used for in
production and and was actually
available commercially for a number of
years all the way up until about 1987 I
think is when it stopped being sold as a
commercial product and then it actually
lived on until about 2000 there was a
site in Canada that was used for air air
defense that was turned off in October
2000 and that was the last multix
installation these days if you're
interested in playing with multics
they're emulators for all the hardware
that you can actually download and run
and there's multics is available
open-source Bowl has the company that
that owns the intellectual property has
donated all of it it's downloadable from
MIT so all the source code is available
I just want to talk quickly about you
know what is the legacy of multics and
corbata said in his 1990 turing award
speech this the unix system was a
reaction to multics and even the name
was a joke Thompson's strategy was clear
to start small and build up the ideas
one by one as he saw how to implement
them well and as we all know UNIX has
evolved and become immensely successful
all right
so that's all about multix I wanted to
talk about a bunch of other systems
because some of these had direct impacts
on how UNIX behaves - but I really
didn't have time to do that so I'm just
gonna mention them in passing and then
cite the papers where they describe
fully if you're interested in them Jules
Swartz was also a software developer
with professor of computer science who
worked at a company called the the
software development company which is on
the west coast and in 1963 they had some
excess machines that had been built for
the sage program and sage was this Air
Force US Navy program to build air
traffic control systems for the military
maybe that sounds familiar
and then the Dartmouth time-sharing
system which sort of begat basic and has
a very interesting rich history of its
own is an independent time sharing
system that has developed at Dartmouth
in 1964 in 1967 at Berkeley there was
this project Genie which is a system
that Butler Lampson worked on and it's
really interesting and then finally
there's at the bottom there's this paper
by BBN called TEDx and then digital had
another sort of sister operating system
called tops-20 that was in a paper about
that was published in 1972 which is also
pretty cool anyway that's what I have
and thank you for your time and I'd love
to take any questions if there are any
so thanks in the development of the
early time sharing systems how much did
the hardware influence the time sharing
system and then how much did time
sharing systems eventually influence
hardware like what was the interplay
there yeah that's that's a great
question the question was you know how
much did Hardware influence the software
and vice versa for the most part in the
early days they had to custom-built
hardware to do interrupts to do things
to signal to the computer that it should
pay attention to the user input and so
in the early days it was really Hardware
driven and the software was sort of a
side effect of that in later days as
time sharing became more prevalent and
more desirable as a feature those things
those features those hardware interrupts
and things were just they just came out
of the box right they weren't custom
engineering things anymore you just got
them and it was easier for people to
implement systems like UNIX that you
know could just piggyback on top of the
sort of you know interrupt systems that
already came by the hardware
manufacturers so that's that's a good
question so in the early days very
Hardware driven in the later days not
really driven by hardware at all hi two
questions first how big was the magnetic
core memory how much could it store know
how big you mean the tube was roughly
the size you mean like like the delay
tube was basically the length of the
stage and and magnetic core was how big
was it mm-hmm it's probably about the
size of it like a poster oh yeah I see
probably like about this big something
like that that's yeah thank you
and second question what what was
happening abroad outside the United
States and in England for all that
period did you study anything did you
see anything yeah so there is a rich
history of
computing in England that I that I
didn't really touch on very very well
and that's mostly because the the
history of time sharing mostly was
focused around what was going on in the
United States and then what was
happening outside of that was a reaction
to what was going on so in in in the UK
specifically there were a lot of systems
that were being built by a lot of
companies and also research projects a
lot of which were built at Manchester
and others were built at Cambridge and
you know developed by people like Alan
Turing and other and other you know
early computer pioneers for the most
part time sharing systems didn't come to
the UK until later like you know in the
middle of 60s and stuff like that and by
that time CT SS had already been
developed so that's why I didn't really
talk about that I do any other are there
any other questions this will have to be
the last question I think yeah thank you
very much and I was just quite intrigued
when you mentioned the development of
interrupts as something specifically
driven by user input output and is that
does that mean interrupts and to drive
IO like we understand it nowadays
basically all IO was polling based yeah
so so in so interrupts were a thing that
that in in McCarthy's memo he talks
about he can't remember who invented
interrupts or even where they came from
but but the idea that they should be
that they should be signal from a user
from a human that was a new idea that
was a new concept before that it was all
driven by hardware devices so you know
the tape and the magnetic tape system
would signal hey I have some new input
for you or I would say I need to write
some new output to you and that's really
the way that interrupts worked it was
completely driven you know from device
to device and so having it come from a
human via a device that that was a new
idea so thank you
okay thank you so much all right</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>