<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>EUC 2013 - Kevin Hammond, Chris Brown - Lightning talk | Coder Coacher - Coaching Coders</title><meta content="EUC 2013 - Kevin Hammond, Chris Brown - Lightning talk - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>EUC 2013 - Kevin Hammond, Chris Brown - Lightning talk</b></h2><h5 class="post__date">2013-07-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eHrJaJgWuZ0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay right so good evening on thank you
thank you for coming along we thought
we'd take the opportunity to show off
some of the work we've been doing on the
paraphrased project over the last year
and hopefully try to interest you in
some things we're trying to do now I
appreciate the last act was very hot
follow in fact I can't even stand up
properly after that last demonstration
but I'll try to keep you engaged for a
few minutes here and what I'm going to
tell you about is a project called
paraphrase project fiercest and what
we're doing are you can follow us on
Twitter here here's my email and here's
our website to pleat there are lots of
papers lots of deliverables lots of
additional resources that you can
download from these websites to follow
along with the work what we're trying to
do is to create a new way to think about
how to program parallel applications
we're doing this using by automatically
generating Erlang programs are from very
high level patterns of parallelism we
think this is a fantastic way to build
really large really scalable parallel
applications we've seen lot talks
through here today about parallelism
about taking advantage of new multi
cause many calls and beyond
architectures this going to be
incredibly important it's going to be
increasing important so the project it's
a three-year project started in 2011 it
involves 14 partners now from eight
countries we've just had three new
partners join from Hungary and from
Poland they're going to be telling you
next year hopefully about how we
automatically discover patterns apparel
ISM in our line code and how we can
present to you the best possible
paralyzation of your code using simple
and easy-to-use tools all future program
is going to be parallel roughly speaking
no future system is going to be a single
core and parallel programming is going
to be a seat essential to everyone in
the future even mobile phones today some
of the samsung mobile phones have eight
cores and the future they're not going
to get any fewer and in fact as
said on in his talk I week except
perhaps millions of course megacorp
machines at some point in the future
it's not just about dealing with
performance forms is great but it's also
about managing energy usage multicores
many course are the best way to get a
high a decent amount of performance for
your energy budget so this is why these
things going to continue to grow in
scale in the future what we need to do
is to make it easy tributes massively
parallel systems that can take advantage
of these incredible hardware piece of
hardware that people are building today
and as as is demonstrated as casas
demonstrated in his talk concurrency is
extremely hard manage on a large scale
what we need a packaged ways of dealing
with parallelism that eliminate a lot of
the problems so we don't even have to
use tools like concur error you won't
have to detach the errors in your
programs because they simply won't exist
if you write your programs properly you
don't have the errors you don't have to
detect them it isn't that great avoid
the problems so thinking parallel
requires us to develop new high-level
programming constructs perhaps dealing
at the same time with millions of
threads I'm going to we need to avoid
dealing with issues like deadlocks etc
it's great that you can detect deadlox
but it's a lot better if you don't have
them in your code in the first place you
need to avoid dealing with issues that
are too low levels or explicit
communication etc i guess most Earl
angers I wore a gel with that and of
course you need to include directly
information about performance will show
you that in a bit so how do we do this
well obviously the only thing that works
for parallelism is functional
programming I know this is true because
Bob Harper said it on his facebook page
how are you going to do this well what
we're going to do is to start bottom-up
to identify strongly hygienic that is
nicely functional components using
something Chris going to show you a
semi-automated refactoring approach
think about the pattern of parallelism
so these can be things like map produces
task forms parallel searches parallel
completions etc then structure these
components into a parallel program turn
the patterns into some concrete code and
finally repeat and rinse if necessary to
get the performance that you actually
require and we're going to try to this
both for new programs but also for
legacy code so it is not to have a
system which will only work as a
development methodology for new programs
but we also want this to work if your
existing erlanger coat so here's the
approach start off with your raw Erlang
put it through our sausage factory that
is the refactor ER which is going to
take in a library of patterns plus
costing profiling information this will
spit out fast parallel Erlang which is
then going to run on a variety of hash
genius architectures maybe parallelize
intercourse with GPUs Xeon Phi is with
the 80 core suggestion announced this
year AMD's with their NVIDIA GPUs etc
etc all linked together in some complex
heterogeneous form going to do this
using refactoring so refactoring is
automatic software transformation under
programmer guidance what it does is to
help us choose the right abstractions
introduce parallelism what we're going
to do is to introduce some skeletons and
then we're going to tune them for
different instances and architectures as
we need so we're going to shoot it to
the parallel for the intel cpu for all
the different head genius architects
that we might have we hand over to chris
is going to show us this working live
from italy we hope thank you Kevin okay
so I'm just going to take you through a
very hopefully a nice example so this is
a image processing example that we've
set up so on the Left we've got a
picture of a helmet and on the light
we've got a picture of Joel I don't know
if Joe's in the audience I can't see him
but and what we're going to do is we're
going to firstly we're going to take the
helmet picture we're going to make all
the black pixels white
and then we're going to take the picture
of Joel and we're going to merge the two
pictures to put the helmet on top of his
head okay so let me just let me just
rescaled is one second okay so here I
have a a session on a a 24 core
multi-core machine that's in Pisa and
I'm just going to start running the
sequential version so that hopefully
should start chugging away there we go
and you can see it's using one hundred
percent of a cpu so it's using one core
at the moment okay and in my other
window I have the code so this is the
basic structure of the algorithm here so
we have a basic a three stage pipeline
so we read an image we do some
conversion and submerging on the image
and then we write white it back out okay
so I want to make this parallel so how
do I do that well i'm just going to
really hard to use this with one hand
okay just going to select this
okay I've got some choices here that I
can apply so I'm just going to select
one of these so I'm going to select
introduce a pipeline so it's gonna it's
telling me it's gone to replace the
thing on the left with a thing on the
right okay so it's going to rewrite my
program into the thing on the right and
it's going to be parallel when it's
finished so i'm going to tell it to yes
i want to a boops doing in the wrong
place yes I want to apply this when I
want to commit that and fingers crossed
it should work the problem with live
Devils isn't a joy why isn't that worked
yes commit there we go okay so it's as
you can see it automatically completely
transformed the code and what we see
here is some calls to a a parallel
library that we've implemented called
scale and which hide all of the power
lism for you so you don't have to worry
about it and if I go back to my terminal
he'll flee this is finished yes it's
finished so it's taken about 66 seconds
to complete so now if I run my new
version and I go back to the I'll just
show you top that so it's starting to
use about nine hundred percent and it's
finished in eight seconds so let me just
do a quick speed up calculation it's
about an eight point two five speed up
okay
of course at 8.25 speed up is quite
small when you think about it here's
some other performance results we've
managed to obtain as you can see here we
get about a forty one speed up so this
is Erlang combined with using opencl
with the GPU implementation and Kevin
mentioned predicting performance before
we can predict performance and we can
also predict how many components we want
in our parallelization how many cpus we
need to use how many GPUs we need to use
to get the best possible parallelization
of that so these are different
configurations different performance
ones and we've managed to obtain the
best the best possible of those that's
basically all we wanted to say we'd like
to thank you all for your attention and
if anybody's interested if you could
give us your names and your email
addresses because we'd love to keep in
touch with you to send you any updates
that we're we're doing on the project so
please please come to either myself or
Kevin thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>