<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Using Software Refactoring to Form Parallel Programs(...): Chris Brown, Kevin Hammond | Coder Coacher - Coaching Coders</title><meta content="Using Software Refactoring to Form Parallel Programs(...): Chris Brown, Kevin Hammond - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Using Software Refactoring to Form Parallel Programs(...): Chris Brown, Kevin Hammond</b></h2><h5 class="post__date">2012-06-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7hyQzH7x0Q4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">get good afternoon Stockholm
so if you don't know me this is because
my background is in Haskell palicki as
one of the Haskell commission members i
edited one of the versions of the
Haskell report but I was talking to Joe
and Joe told me there about 30,000 of
you I stalking to Francesco Francesco
said there about 100,000 of you I
thought well maybe somewhere in between
it's decent number of people to go and
talk to and try to get some of our ideas
out of the hospital community in into a
wider audience so I'm very pleased to be
working on this project are which is
about looking at the limit scalability
in parallelism are is about taking
Erlang and other languages to the next
level in terms of hardware so it can't
have escaped many of you that were the
start of the dawn of a new multi-core
age this is up here in AMD opteron it's
one of their latest chips what we got on
this chip six independent calls 66 and
processors are with very interestingly
connected using our their own arm hyper
transport link interconnect so it's not
just a shared memory system this thing
is actually a complete network on a trip
and this is just the start internal have
announced a the Haswell architecture
with forty eight cores are there going
to be even larger announcements coming
in the in the very near future some of
which I can't tell you about so that's
the present the few connecting this kind
of shaped together this is our example
of four of those AMD man you core chips
connect together into a network giving
as a 24 core what's going to happen
beyond that by the way that's quite good
pun I guess you will realize that manic
or place in France a very good name for
a chip that has many calls in it I think
it was intentional what's what's the
future well the future is going to be
vastly more parallel we can see today
six cores twenty four cores 48 calls for
the future what's the future going to
hold why i think it's going to hold
something like a megacorp computer a
megan cause in a single device are
working together
has anyone heard the term make a call
before you have you been to all my talks
Joe no whoa someone else's stole
someone's stolen the name so I i I've
deliberately invented the term mega call
remember you heard it here first and
please have tribute me please write a
Wikipedia entry for me so what are mega
call computers going to be like well
they're not going to be like the typical
computers we have at the moment they're
probably not too scaled versions of
today's multiple because the memory
buses and other hardware starts just not
going to cope with that that may be
going to be hundreds of dedicated
lightweight interested units or
thousands or millions are they going to
be hundreds of floating-point units not
just GPUs but once the better integrated
with CPUs it has anyone don't need GPU
programming few of you you're still
alive you're still here you're still
happy it's not easy right one just
moving data between the CPU and the GPU
is a major exercise a major performance
bottleneck a major obstacle to actually
using these devices it's very
frustrating you've got hundreds of calls
sitting on your chip and you just can't
use them because the costs fault
floating them is just too high but in
future I think we'll see better sharing
between CPU GPU combinations better
integration between these chips we'll
probably see I see a few heavyweight
general-purpose calls the kind of things
we think of as cause today I probably
going to be almost obsolete in the long
term because a lot of the functionality
is going to be off flight offloaded to
these lightweight units if you think
about it most the computations you do
are not that complex if you have the
choice between having hundreds or
thousands or millions of course each of
which can do a relative restricted our
amount of computation laughs you are
there to really sort grind out the
microsoft word etc then that's the way
to go in terms of performance not having
a few hundred really really heavy weight
cause thousands millions of lightweight
course that involves change in thinking
we can't get to those kind of systems
are using hind thought patterns that we
have at the moment
we'll also have things like dedicated
cause to deal with of course graphics
but also authentication security network
are biometrics all kinds of interesting
specialist devices Muslim won't be
active at any point in time we'll just
turn them on and off as we need it I
also will have things like soft cores
are very likely there will be chips
where you have a small amount of
programmable fpga or similar space you
can just well tune it to your
application get really really high
performance for our very specialist
accelerator functions are very hard to
program these things all together the
task is going to be humongous you think
it's difficult programming GP us with
CPUs imagine if you have 30 or 40
different types of processor plus some
soft processing sitting around the
possibilities are endless they're
exciting and the average programmer
frankly they're incredibly frightening
worse to the average programmer we're
probably not going to see on what we
have the moment in terms of a fake model
of shared memory these things are going
to scale so quickly and so rapidly but
the conceit we have that all memory
space is the saying that all memory is
shared is just going to go away in a
puff of smoke and people who are stopped
that are kind of model I can find
incredibly hard to transition to to this
new world we have to get away from this
idea that we have a single shared memory
space now of course the airline model of
concurrency is quite good for that you
have shared nothing and that's that's an
accessibility for this kind of
large-scale system so Numa type
architectures are going to be very
important you're very quiet by the way I
don't like an audience thats quiet it
makes me think you're asleep if you're
asleep please put your hand up good art
please ask me questions if you don't if
you don't ask me questions I'm going to
start asking you questions my questions
are harder than your questions
so the implications for programming are
quite tremendous we're gonna have to
learn to program these heterogeneous
systems in some kind of integrated way
clearly it's going to be impossible to
program each kind of core in exactly the
same way what we hope we might be able
to that's part what project is all about
really each of these kinds of course has
to be programmed differently because
they do continue different things it's
going to be impossible to take static
decisions about where the tasks are so a
lot of the research in the scheduling
community is all about while you start
off with your parallel program oh yes
you got this perfect schedule you put
this thing here you put that thing there
you put this thing here you've got 10 15
20 programs may be running on this chip
how on earth you're going to get all
those programs which may be dynamically
creating tasks with 30 or 40 different
types of core and maybe 100,000 or
200,000 calls sitting around how earth
you going to manage that statically
you're not the only way to deal with
these is to do is to have a highly
dynamic highly adaptive model and it's
also going to be impossible to know
exactly what each thread does how do you
program concurrent systems okay mostly
good how many how many threads do you
have in your systems thousands how many
different kinds of thread you're having
a system few hundred you're doing pretty
well you never teach those dots and how
it interacts with all the others you're
doing very well this is this is why Joe
is the founder of a 150 million dollar
company Crona okay dollars the average
programmer this is a huge amount of
complexity so managing that kind of our
system knowing what each strengths is
doing at any point in time knowing how
each stretch interacts represents an
incredible amount of complexity it's one
that has to be managed so the challenge
is that are the whole web designers in
his quote from and while ghulam whose
principal engineer at Intel is the
hardware designs again providers with
hundreds thousands millions of course
but at the same time are the dilemma so
here's quote from the software guy and
vice president of the product
development from rogue wakes brie whoa
work work work rogue wave software is
the large percentage of mission-critical
software are is not going to
automatically to run faster on these
multicores in fact a lot of cases or
people are finding is they even run
slower because there are huge amounts of
sequential dependencies in the code we
have to break those dependencies and
make the leap between the software
development techniques and the harbor
capabilities that's what we have to do
so programming wise we can model through
on 26 to 28 cause maybe 16 or 32 or so
and on those kind of systems modified
sequential code may work if you have
four cores but I can have one running
Microsoft Word I got one running
powerpoint I can have one running Safari
or Internet Explorer may be true for
internet explorer I can keep the calls
busy when I get to 32 comes a bit harder
when i get to hundreds or thousands it
comes incredibly hard you really have to
start thinking in terms of very large
scale systems and typical concurrent
concurrency approaches usually do not
work there are too many problems to deal
with too much complexity to deal with to
match this kind of scale particularly
with the kind of add activity that we
need so let me show you how to build a
wall this is with apologies to in Watson
who said well if you're building a wall
you have to build it sequentially right
you start at the bottom and you place
your brick and then you place the next
brick and the next one and so on and
having done those you can then start to
place the next layer of bricks so you
put them on top of each other and then
you place the third layer of bricks and
now you've got a wall fantastic
a process of calling here in Watson
who's next about in parallelism is one
that is impossible two parallel lines
well let's think about how we could do
that so type up for builders Eaton Place
is a brick in parallel you can place the
next brick in parallel now we can go on
to the next layer each of them can place
a brick in parallel three of them can
place a brick in parallel three bricks
in parallel and then we complete the
wall lots of subtlety going on in that
so although eyes doing this in parallel
there's dependency between the layers I
also have to get the brick placement
exactly right if any of those builders
are was at all in precise and didn't
communicate with any of the others in
the right way than war wouldn't work so
altering is important our placement is
important our communication is important
here's how not to build a wall place to
break up their place one over their
place on down there and then one and
then one and so on that is not going to
work in terms of building a wall so
eventually work well Joe look so the
specification is perfectly correct right
I've got a wall the form is getting the
implantation to do the right thing are
given the laws of physics as we know
well gravity if I ignore gravity yes so
I seem there is no gravity than the
sched work some of my assumptions this
is a good decomposition unfortunately
live in the real world and walks tend to
fall down it's not built properly as
does software
Jeff say yes yes so maybe it was right
after all so in the real world maybe we
have to live with sequentially built
walls so tansen identification finding
the right brick is not the only problem
we also have to worry about issues like
coordination communication placement
scheduling it saturates that all these
things are important you think deeply
about the wall example the stuff that
shows all of those problems in some form
or another so we can't build a parallel
wall but we have to worry a lot about
the detail we need structure we need
abstraction we don't need another brick
in the wall so what's the problem panels
in the mainstream is mainly procedural
do this do that do the next thing panels
and is typically a bolt-on afterthought
in those likessee etcetera we have
threads horrible low-level constructor
threads we have message passing so we
have to think about messages that are
going around our system and possibly
debunk them we have to worry about
mutexes to ensure exclusion we have this
horrible concept of shared memory which
gets in the way doesn't abstraction off
and to be honest doesn't match the new
architectures that we have shared memory
evil kill it get rid of it sooner the
better yes yes what do you think it's
essential is Joe part of them is real
yes so sir
yes yes correct that's right so
concurrent concurrency is there to
ensure sequencing is there to ensure
things happen in the right order
concurrency mechanisms can be used to
express parallelism but they aren't the
same as parallels and parallelism means
things actually happening at the same
time are in the real world and the
reality is when you have parallel
behavior you have things just can't
happen in a concurrent systems running
on a sequential system so you can
happily debug your program on a
sequential system concurrently you're
all the right locks blah blah blah
follows the latest theory blah blah blah
run it on your paranoia prison it
doesn't work and that is because the
real world things really happen at the
same time on a parallel system why don't
you in the real world I can't even have
an observer Joe I can't leave happen
observer observing these two things at
the same time with sufficiently
complicated clock system so the result
is a lot of pain and and this
unfortunately is where a lot it's well
awful is coming from so loved the world
is coming from this model they're
thinking we we know about concurrency we
know how to do with small-scale
concurrency all we have to do is just
scale up increase the number of mutexes
and everything is going to be hunky dory
will rue when we run or massively
parallel hardware that is not going to
happen there are going to be an awful
lot of very sad very disappointed
programmers out there in the very very
near future we've gotta move beyond this
people are still doing this I was a
workshop in the UK about three weeks ago
and this throw to communities so there's
community of language people people like
ourselves and as community of people who
are working on concurrency primitives
and the concurrency people think they've
got the problem solved all they have to
do is get a slightly more complicated
concurrency primitive and or a slightly
more powerful memory access operation
and bingo all their problems will be
solved and they'll have parallel code
okay a lot of the key a lot of community
thinks like that unfortunately so
deadlox race conditions blah blah all
the all these things horrible things so
the problem is that watch a lot of
application is that applications
programs in dealing the parallelism have
to be on sistance programmers there's
not enough support for abstraction
there's earned a lot too much complexity
to manage perfectly as you start to add
new hardware times it's difficult
impossible to scale this unless the
problem is relatively simple easily d
structured it's also difficult or
impossible typically change the
fundamentals even things like changing
the schedule in order changing the task
structure changing changing migration
can be almost impossible because the
typical approaches are what people do is
to build this into the application that
is completely wrong there's these are
systems issues they are hardware
middleware systems issues they are not
application issues application programs
should not be writing schedulers so what
we want is to move beyond that are to a
way where programmers can think in
parallel using high-level programming
constructs and clearly you cannot think
effectively whilst worrying about
deadlocks etc so what's the solution
well the solution according to Bob
Harper from Carnegie Mellon is
functional programming he said this in
an unguarded moment on Facebook but he
said it I've written it down it's a
valid quote
be careful watching say on facebook this
is what this the problem we're trying to
act in the paraphrase project it's a two
and a half million euro fp7 strap line
partners across nine countries started
about six months ago and it's we
coordinate it so I'm I'm running this
thing in addition to my day job
consortium includes ourselves running it
a couple of universities robert gordon
university university of pisa University
of Torino and queens belfast or well
known for their parallel they work on
parallelism also our line solutions
limited are the high-performance
computing center in stuttgart we're
giving us some really beefy parallel
machines to play with to take about one
of those and second software competence
centre Hardenberg we're coming up with
some nice applications and i'm also very
interested in what people doing here if
you got some good applications are in
Erlang i am very very interested in
those because you really want to try
this out on as many real-world examples
as we can plus large companies mellanox
are is involved in this are there
us-israeli company that produce
infiniband are so they're a networking
company so the overall aim is to reduce
a new pattern based approach to
programming parallel systems
specifically what we're trying to do is
to that high level designer
implementation patterns are develop new
mechanisms to support our activity for
these heterogeneous multiple many call
megacorp blah blah systems and verify
the pattern snaps between mechanisms can
be used efficiently and effectively and
finally ensure the scope for widespread
take up so one of the key things is how
a good user community with as I've just
said very very interested in people who
use another line with launch snail
paralyzing programs we will sign any NDA
that you like I will find my firstborn
to you in order to get Google
applications go ahead double main use is
perfect perfect with real paranoia
problems fantastic come talk to you
afterwards and say goes for everyone
else please please please come talk to
me so
what we trying to do said is there are
not possible parallel approaches the one
we're using is based around patterns
what I mean by pattern is an abstract
generalize this fraction of common
algorithm so typical patterns that we
come across things like Maps Ford's
function composition divide and conquer
etc are here's his a map in Erlang Chris
going to show some more examples later
and then the idea in paraphrase is to
start with Erlang c++ or Haskell etc
code to use a common refactoring tool
with a common suite of patterns
governing the parallelism patterns are
using cost being or profiling
information for example from dialyzer
tool to then produce paralyzed Erlang
etc programs we're not expecting to put
Erlang in and get see out by the way if
you put LAN you get Erlang out if you
could see and you get see out etc doing
that doing the other would be a little
too hard given stage the tools so
refactoring what's it about it's about
changing structure the program's code so
I'm going to do to rewrite the code we
going to take advantage of the
concurrency mechanisms that we have
available in Erlang whilst preserving
the semantics so the idea is that start
off with your code which may have some
concurrency or maybe sequential and the
refactor will allow you to add in the
the parallelism fire yes oh not yes yes
yeah what I should probably said is
without changing the semantics too much
you're quite right you're quite right
you change changing changing the
changing the timing is is this what
strange dream now there's question of
whether tiny as part of the function is
the function props program or not
there's a big debate going on moment I'm
going to work at this faster yeah even
even worse they better not do that and
indeed we this is exactly what we're
trying to influence the behavior we want
the program to still do the right thing
whatever that means if you have a search
algorithm I have you've got a parallel
search then you may find a completely
different answer in your database when
you do look up you've got more peas and
look up multiple identities in the
database do a lookup you make it
different entries back their equivalent
but different as that's not changing the
semantics you need to go from the design
pattern to the solution all the way
around right that's what Krishna shares
hi I hope yeah so what we're providing
is tool support to help you do that
we're not saying this complete magic it
moves the problem up a bit and it gives
you some tools to help you deal with the
problem and that's the name of the game
so rather than having completely
unconstrained space we will give you
some tools and guidance issue with error
messages I hopefully say two things like
well if you do this then you're going to
get this much speed up or if you do that
you get that much speed up
well if you have to think yes we're
always saying I think it's actually what
we're trying to do Jay so what we're
trying to do is to identify common
patterns the people think about they
have the right pattern they know the
pattern is potentially embarrassing Lee
parallel and then the problem is just
translating the embarrassingly parallel
problem into one that was okay well if
you know how to do that fantastic and be
granny that's yes that's not necessarily
the right answer it's not necessarily
the right answer because gang arity
overhead but because granularity never
had another other issues yeah sorry more
questions okay
yes yes yes oh so the point down here
which says the refactoring it there's a
transformation which is what saying
about so the tool will apply some valid
re-writing there's a condition are that
needs to be satisfied for the tool to do
the rewriting for example you don't
actually change things but of course if
you violate the condition because you
know that it's safe to do that that's
fine what we're not doing here is fully
we're not trying to do fully automatic
parallelization while trying to do here
is programmer directed parallelization
with tool assistance so we're going
beyond our the purely implicit are
towards something which is semi implicit
or completely explicit parallel
polarization some one of them Joe yeah
yeah we think we have anything to have a
handle on that I think Krista's gang
shows that produce passion later are
what we think of is that MapReduce is a
skeleton here Chris will explain this
later but the pattern is some sort of
data parallelism pattern made its
MapReduce if you're really thinking like
that and then there may be a series of
stats serious transformations that you
have to do to go from your original
program through to the MapReduce
implementation
you need you need various types of
information including some extra
functional information about performance
etc which we're hoping to provide you in
the tall so we're model teens fully
automatically you went you ain't sort of
put your line program in crank a handle
now pumps like a sausage factory
MapReduce I'm trying to ignore J take
take your turn take your turn Toronto's
so they will be like sausage factory you
won't you ain't pop your program in
crank the handle out it comes what
you'll have is a tool that allows you to
transfer form your program into one
which is which meets the MapReduce
implementation that's that's part of the
problem Joe having done that you've
taken a fixed decision about your
process structure and your paternity
month good so fine right so now i go
from so i got my program it's working
nicely on its CPU model now what i want
to do is to change it so it's working on
GPU model pot let's remapped to GP model
how about how do i do that can't that
Joe is my point so it's not it's not
just about writing the program in first
place it's about rewriting it taking
advantage of what may be very complex
and very highly variable set oppressive
resources and possibly even doing this
dynamically on the fly there's a GPU
become available you have one
millisecond to decide whether to use it
or not do you use it yes or no if you do
maybe it runs faster you need to know
that
not necessarily yes nope the system
designer has to tell us how to do it how
to do it with the tool assistance but
the idea is that the code will be
compiled in such a way that it can do it
if the opportunity arises so we need to
know when should we do it okay so needed
more so refactoring it really enhances
this creative process okay people really
need these tool to really help them
through the processes of writing
skeletons of the software engineering
process in general the tool can guide
program through all the necessary steps
as I showed you it can warn use if
they're going wrong this is very
interesting so for example at the
threshold in process the tool could say
don't do this because it's not going to
work you need to do a threshold a step
and that avoids obviously all the common
pitfalls that most people go through and
spend days weeks months whatever trying
to figure out what on earth is going on
it helps to build an intuition which is
probably the main philosophy that we're
trying to get across here this work is
described in a lot more detail but for
Haskell programs rather than airline but
the principles are the same then we have
a paper in the trends and functional
programming conference should be
appearing about now I guess in the
proceedings so please go away and read
about this and if you have any questions
about the what the ideas and please feel
free to speak to me or Kevin
and as obviously still a lot of work to
be done here okay so this is a basic
prototype we want to have lots and lots
of these refactorings identify patterns
they generate skeletons but we don't
want to do this just for airline so the
basic principles that I've shown you
here can be easily taken to other
paradigms C C++ for example a lot of
people use C and C++ to make these kinds
of things so we shouldn't really ignore
that we want some kind of language for
expressing these kinds of things okay so
if you're an expert in skeletons you
want to say I know how to identify
pattern I know how to generate a
skeleton I need a way of doing that
proving these things correct as was
already spoken briefly what's more
interesting is proving these things give
you Paul ism and how do we do that
that's very interesting area of research
that we can go into just a quick slide
on some of the some of the projects that
we've had at st. Andrews the pathways
one is here a similar project with
science which was investigating
skeletons for computer algebra advanced
is feedback directed compilation it's
about inferring costs costing and in
isla HPC gap is all about making
computer algebra systems parallel so we
have lots of projects experience in this
kind of area but some of the partners
that we've worked with line there Kevin
do you want to talk about the factory
light or
you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>