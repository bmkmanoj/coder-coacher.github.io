<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Zandra Norman - Scaling Distributed Erlang (ElixirConfEu 2016) | Coder Coacher - Coaching Coders</title><meta content="Zandra Norman - Scaling Distributed Erlang (ElixirConfEu 2016) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Zandra Norman - Scaling Distributed Erlang (ElixirConfEu 2016)</b></h2><h5 class="post__date">2016-05-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/usEs3GPnZDg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">can hear me that's better yeah i work in
the ER language be team at ericsson and
I this isn't working either
there I first encountered Erlang during
my master studies where I focused on
distributed airline another distribution
systems and what I love so much about
Erlang it is its concurrency and
distribution model as I'm really happy
to see how the LXE community is growing
now since it's using the same
concurrency and distribution model that
I loved so much I have been working in
the OTP team for a bit more than a year
now and for the last few months I've
been focusing on distributed or life and
that's what I'll talk about here so you
get distributed Erlang or I'll start
with how it works today and then some
plans for the future and then more
specifically what I'm working on right
now so you get distributed Erlang when
you or distributed elixir for that
matter when you have two or more notes
that are communicating with each other
over the Erlang distribution carrier we
keep a peer-to-peer topology which means
that we don't have any centralized
server or something like that to keep
the network topology but we keep all the
nodes have kind of the same roles and by
default we set up a fully connected
network which means that if you connect
node a two node B and then no be to note
C and node a and C will also be
connected automatically so everyone will
be connected to everyone what I mean
with a note here in case some of you
don't know that already it's an erlang
virtual machine or a beam which has been
started with the name or ass name
property to give it a unique name which
is used to identify the note
and it's a really an operating system
process as you probably know so you can
have multiple nodes on each host or you
can spread them around on different
hostess if you want to doesn't really
matter on H know there are many many
concurrent processes running and the
virtual machine is handling the
scheduling load balancing and message
passing and so on between the processes
if you use the process ID when you send
a message it's the myth it doesn't
really matter if the process you're
sending to is running on the same node
as the sender or if its own running on
some other node because the virtual
machine will handle left for you and it
can do so because there are some node
information embedded in the process ID
so the virtual machine will make sure
that the message is sent to the the node
where the process is running and the the
virtual machine on that over there will
handle that to put make sure to put the
message in the process IDs message queue
or process this message key if you use a
registered name with sasha was talking
about earlier it's not transparent in
the same way because that's only for
local registration but you all know you
know all about that right now yeah I
guess so I'm not going into any details
but you can send the message but to by
specifying the note where the process is
running or registered on as well and
this is the API or interface for local
registration but we also provide a
global version which was also mentioned
during such as presentation and it looks
like this so it's through the global
module and you can see the similarities
in the
api here or interface the only
difference is the difference is that we
have a reregister name function as well
and the global module is what is setting
up the fully connected network and it's
using the full mesh to handle the
registrations so when you register your
name global will first acquire lock by
sending a message to all the nodes in
the system and when it has the lock it's
just locking the name it's not looking
everything but it's still a lock there
when you have the lock it will send a
message to all the nodes in the system
again to ask them to save the name
process ID pair locally and finally when
that is done it will release the lock
and the same thing goes for the
reregistration and done registration
more or less the lookup functionality
through where is and send is really fast
though because there you have all the
information saved locally on each of the
nodes so you don't have to go out on the
network to get anything and one more
details its global is handling the fully
connected network when an old joints
there are quite something's happening
one thing or the first thing is that
each of the nodes locks their own
partitions which are the notes they know
about and then they exchange information
of about which name process IDs are
registered in each partition and finally
they make sure that all the notes being
all the other notes so that we keep the
fully connected network so how do you
think this will work when for hundreds
or thousands of nodes
not very good right so everyone is
talking about scalability when it comes
to Erlang and the elixir and here I come
and say it doesn't scale what but this
is kind of the next level of scalability
where we're talking about many many
nodes so this works ok for up to 30 to
250 notes and but then it's starting to
get really slow and you might have some
other issues as well and we're working
in this area to to make a scale better
so we have some some different issues
that we need to look into to solve this
the first one is that if you set up a
connection between two nodes the
connection will stay up even though if
you don't send any more messages over
the connection or any signals otherwise
either so we want to automatically
disconnect notes where no communication
is happening kind of garbage collecting
in inactive connections but to do so we
need to also remove the need for a fully
connected network and another side
effect from that is that we get way too
many connections in the network as the
system grows so we really want to remove
that fully connected network to avoid
that to the next thing is the expensive
no joints that we get and finally global
chat slot it sends around a lot of
messages so we want to make it less
chatty and all of these we can kind of
solve by removing the need for a fully
connected network if we do it in a good
way so you can actually avoid this full
mesh right now as well by setting the
connect all flag to false when you start
the notes in the fist
so that might be useful if you want to
make your system scale but then you'll
need to handle the network topology all
by yourself so it might might add some
extra complexity to your code and you
will also not be able to use the global
functionality okay let's look at the
global again so we had the registration
reregistration and unregister asians
which are really expensive right now
when the system grows but the lookup
functionality is really fast so what we
want to do is making it possible to for
the system to scale and decrease the
heaviness of the first three functions
why but try not to lose too much of the
fast lookups that we have but there will
be a trade-off since we cannot have the
fully connected network anymore you can
see global or view global kind of us a
key value store where the name is the
key and the process ID is the value and
luckily for us a lot of smart people
have already thought about this issue so
it's a good opportunity to avoid
reinventing the wheel so what we want to
base this on is a distributed hash table
which is really kind of a distributed
key value store where each node is
responsible for a range of keys and it's
using consistent hashing to make sure
that you don't have to update all the
ranges in the system when new nodes join
and so on we there is no centralized the
server or centralized synchronization
here so it's really really decentralized
which we want to keep so that's good any
good distributed hash table is using
orissa guaranteeing big o log n look at
time which makes them scale really well
and it also makes
to replicate that name process ID pairs
over multiple nodes so it can handle
node failures and so on yes we have two
chosen to there are many many different
distributed hash table algorithms and
we've chosen to base our new global
version of ankh ademia which just like
most other ones guarantees a big ol log
and look up time in store time it's a
bit easier to maintain the Academy o
structure than many other distributed
hash tables and configuration
information is spread around in a system
during the lookups which and with
configuration information I basically
mean information about which nodes we
have and so on so that each node routing
table can be updated only from the
lookups but there will also be some
extra configuration messages sent around
at least but we can decrease that amount
Ka'Deem Leah can be viewed as a binary
search tree where the nodes are the
leaves in the tree and in each node has
a node ID which determines its position
in the tree so here we have an example
of the nodes 0 2 4 5 6 7 10 11 12 14 and
15 and this is in this example we use ID
size of 4 bits but usually we have a lot
larger number or a lot larger size maybe
160 bits or something like that and
because otherwise it wouldn't work
really it would be too small and this
will also be the key space that you use
so we get the node ID by hashing the
node name that I mentioned in the
beginning we know the node name to be
unique and we want a node ID to be able
to put it in there or give it a position
in the binary tree and we use a hash to
do that to give a good distribution of
the node IDs and this node ID is also
look used to determine which node is
responsible for which keys so each node
ID will be responsible for the keys that
hashes to four key terms that hashes to
your key which is the close ones closest
to the node ID each node has some sub
trees or its own sub trees so here is
the an example of the sub trees for note
15 and the sub trees are determined
based on the common prefixes the notes
in each sub tree have with the note the
sub trees are for so in this case we
have four node 14 in it which is in the
closest sub free because it will have
all the three first prefixes in common
with 15 so it's it gets its own little
sub tree and then the further away from
node 15 you get the greater the subtree
you get and in the last one there will
be no common prefixes so that would be
half of the sub tree and here is another
example for node 7 and you can see that
its closest neighbor also gets its only
those up to here and the further away
you get from node 7 is the bigger the
subtree you get
or the less common prefixes so we have
sub trees and from these sub trees we
can each each node guarantees that it
knows at least one node in each of the
sub trees or its sub trees and that
builds up the routing table for each
node it can have up to k notes per sub
tree but always at least one so the
routing table doesn't grow infinitely
since we have this K limit upper limit
as well and it might look something like
this in our example so node 15 knows at
least one node in each of the sub trees
and so it knows note 14 since it has its
own sub tree no 12 cities since it's the
only one in the next one and at least
one in each of the other two subtrees as
well and here is the example from the
node sevens perspective so this will be
routing table for node 7 in kidding via
we can wait determine the distance based
on X or so the distance between node a
and node B will be the ID of node a X or
the ID of node B and so in this example
we have seven or 0 1 1 1 and node B has
the ID 11 or 10 11 and the distance
between them will be 1100 and to
determine which sub tree you'll find the
node in or the key or whatever you're
trying to look up you can mask out the
most significant one from the distance
and then
case will get 1000 which shows us that
there are no common prefixes it was in
this case so we note B would be in the
subtree 84 no day and snow day would be
in sub 384 not be as well so we can see
here that node 11 is in the sub tree
furthest away from seven this us we
calculated whore okay so we have the
routing table information and let's do
something more fun with this and look at
the note looks up lookups and this is
what is used to look get closer to the
key which you're trying to look up or if
there is no or if you just do not know
look a few locate the K nodes that are
closest to the key and and this
procedure is used for both storing
lookups and also during the joints so
for when we call global register in this
new version we would locate the K notes
that are closest to the key or the hash
of the name in our case and then we
would store the name process ID pair on
all those notes for where it should be
named there too ok never mind for the
where is function we also use the same
look at functionality to get closer to
the name and then eventually we'll be
able to return the process ID and the
same will happen if during the send but
when we have the pro society will send
the message to it as well so let's look
let's visualize this so we have this
name which we're trying to look up
and this name happens to hash to the VAT
25 so if I will be the key and we'll try
to look it up from node 15 15 here and
I'm showing a worst-case example just
because it's good for the visualization
and also i don't use any replication in
this example which would usually be the
case but to make it simpler we don't
have that here since this name will be
hash 25 we know that node 5 will be
responsible for it since we don't have
any replication and node 5 is the one
closest to key 5 so remember the
wrapping tables for node 15 so note 15
does not know note 5 and but the first
thing it does is 2x or its own ID with
the key it tries to look up five in this
case and then it will mask out the most
significant one to get to see which
subtree it should look in and this is
because to avoid going through all the
routing table each time you want to look
up a value but just to be to look
through at most K nodes which would be
in the specific sub tree and then we see
that there are two nodes in that sub
tree node 7 and node 0 so we compare the
distance 25 for both of them them using
X or again and we can see that node 7 is
the one closest to five so we ask note
15 asks that node if it knows what the
process ID for this name is or how to
get closer to it
the node 7 does not know the process ID
45 or this name but it so it it looks
into its own routing tables to see how
to get closer to it and the one it knows
to be closest it snowed for so it
returns note for to note 15 and the node
15 can ask note for if it knows the
process ID for this name or how to get
closer to it and the same happens again
a note for looks into its own routing
tables since it doesn't know the process
ID and it will return five since it's
the closest neighbor which it will know
and then finally we can ask note 5 if it
knows the processor ID and we found them
bid so great this is called an iterative
look up and it can be done in parallel
so if we go from the beginning we would
send out two messages at the same time
to the two nodes we know to be closest
or even more messages depending on what
parallel parallel et level hard to say
that yeah I guess you get what I mean
anyway what level of parallel EP you
want and then the look I put continues
so I'm not going through although those
steps again and get the picture you can
also use a recursive look up which would
look like this and so instead of
returning how to get closer to the
process ID or the key that you try to
look up each node will ask the next one
itself and then finally we when we found
the process ID it can be returned
I haven't made any measurements and
investigated these to compared them to
so much but it seems like the recursive
one is faster in most cases but during
the a31 you update the router you're
able to update the routing table in an
other way because then you discover new
notes on the way on the way that can
also be fixed in a recursive version by
sending a few extra messages around but
yeah since I haven't made measurements
and so on I I'm not sure which way to go
yet or which way will choose so I
thought it would be worth mentioning
both of these both of these but we'll
see which meant which one will end up
with they both provide a big ol again
look of time anyway in a worst-case okay
so back to the global API so I've shown
how we can implement register name
through this and where is name and send
but I one thing I haven't mentioned is
that if a process dies it should be
re-registered and not returned if
they're from the global registry anymore
and since we don't want extra
connections we cannot set up links or
monitors and all the processes that each
node is storing storing it in its own
table so we have to unfortunately add an
extra mr. message round trip there
during the lookup and since we have the
we know which know the process is
running on we can easily just ask that
note if the process is still alive or if
it's dead and if it's dead we can return
undefined and also if the node has
crashed we now know that the process is
also dead since it was running on or
yeah process is also dead since it
running on that node and in that case we
can also return on defined and the fact
that we have to do that makes the
unregister a shin and reregistration a
lot simpler to implement since we
already have that extra round trip
message round trip to the node where the
process is running we can decide if that
notice the owner of the name process ID
registration so for when doing an
unregistered we can tell that node okay
this process isn't registered under this
name anymore so during the where is the
last round message round trip there
during the lookup we can also ask if
it's still registered or not and the
same thing goes for the re-registration
because it's basically a non
registration and registration again so
and this also makes caching a lot easier
since we have this natural owner where
the process is running we don't have to
if if we we are able to save the name
process ID somewhere else in the system
we can just go ask the node where the
process is running if it still
registered and still alive and so we can
avoid the extra message passing and in
that case so we can optimize the look up
a bit further to try to mitigate what
we're we're losing compared to the old
version of global as well we're also
looking into how to improve the caching
here but we haven't decided anything so
I can't go into any details about it yet
but we might try to improve it even
further to avoid even that's extra one
message round trip
they're great so then we have
implemented all the functions of global
and we also try to mitigate the lookup
trade-off that we've gotten through
caching but will we have the no joints
left to look into so I'm just going to
show how know it works when a node
joints and what happens then is the
first thing that happens is that you
need one other note to connect to in the
system so but that's the case for the
old global version as well you need one
node two ping or something to to connect
to the network then you're looking up
your own ID to get to know the closest
neighbors or your closest neighbors and
then the node looks up one random ID in
each of its sub trees and so while doing
this it will both populates its own
routing table and also spread around
information about itself so that other
nodes can also find it during their
lookups let's just look at this quickly
so note 8 is joining through note by
pinging node 11 and it puts know they
put snowed 11 it in its own welding
table and then it tries to look up
itself or key 8 so it asks node 11 if
how to get closer to eight and node 11
no stats 10 is closer to eight so it
will return 10 and then node 11 will
also try to add it to its own rod add
node 82 its own routing table if there
is still space there and so we have
found our closest neighbor will also ask
no date or node ten-four if how doing it
shows or 28 and no 10 will return itself
since it's the one it knows to be
closest and then it will add node 82 its
own routing table again Justice 11 did
before and after that we will randomize
one node ID in each of the sub trees
from no date so in this example I
randomly chose note 10 3 and 13 and we
will perform a look up on those notes
and during those look gaps we know date
will populate its own routing table and
make sure that it knows at least one
note in each of the subtrees I forgot to
mention that it should also do a lookup
on node 9 which is not very visible but
it's here so it it will notice that it
doesn't have any closest neighbor as
well but if it had if it was there it
would get to know it as well
ok so the note and also forgot to
mention the synchronization of name the
process ID registrations it's a lot
cheaper as well since you don't have to
synchronize all the name process IDs in
the system but only the ones that are
closest to a node 8 in our example since
that's what no date should be
responsible for with some add additional
replication so now we have removed the
need for a fully connected network so it
can start garbage collect connections
and so will try to bring down in active
connections while still making sure that
you don't lose any messages soil this is
happening so if you happen to send a
message while we have set up a
disconnection procedure will either
interrupt it and we'll be able to send
the message over there same connection
again or if will we have gotten past a
certain stuff in the disconnect
procedure will have to disconnect but
then we'll set up a new connection
anyway so that the message can still be
sent so you don't really have to care
about this that this is happening in the
background and we'll make sure that the
message is still sent so you don't lose
any messages because of this and
actually we really need to fix this to
be able or to make sure that we don't
get it fully connect the network because
using condemn liao we tend to talk to a
lot of different nodes in the system so
if we don't start garbage collecting the
connections they would still stay up and
we would have end up with the fully
connected at work anyway after a while
so we'll need to add that before we can
say we're done with this this
improvement
so do you think this would work better
when the system goes well I hope so sure
research supports that at least we
haven't gotten so far in the procedure
yet but I've made some initial
measurements and it looks very promising
there is as I mentioned before and I'll
mention it again a trade-off with the
loop gaps but it's something that we
have to do unfortunately there are a lot
of more measurements larger scales and
so on left to do and a lot of
optimizations and a lot more details
that needs to need to be implemented so
there are a lot of fun things left to do
which is lucky for me and not so lucky
for you if you want to use this because
you'll have to wait for it I'm sorry
about that I am also going to mention
some other things that we are discussing
for the distribution just in case any
one of you is interested in this Jose is
mentioned in an email said a few months
ago that our PC is kind of a bottleneck
I've looked into that a bit and made
some measurements it looks like it's a
lot better than when those measurements
were done and I also made some further
improvements but we might still want to
discuss the ideas that came up from the
thread but the small optimization sigh
mate is in the nineteen release anyway
so it's a pro improved a bit at least we
also want to add a remote spoon monitor
which we don't have today and when we
have that we can actually
make some further improvements to the
RPC module by using that spawn monitor
but we might have to wait for it
unfortunately because we don't know when
we'll get to the spawn monitor thing we
want to port the airline port map or
demon to Erlang and we have some
contributions on that which we are
considering bringing in 20 to be we want
to make some improvements on the on the
protocol that we provide for the Erlang
distribution carrier right now by
default we use TCP but you can specify
that you want to use SSL or TLS if you
want to that we might want to provide
even more protocols to use and we also
want to make it possible to mix
different protocols for different parts
of the system which is not possible
right now we want to fragment large
messages because right now if you send a
really large message over the
distribution it will delay other signals
and messages that tries to get done out
on the same connection because there is
only one connection between two nodes
but by fragmenting the large messages we
can sneak in the other signals while the
large message is still transmitting so
we want to add that and finally we also
want to preserve sub term sharing to
make sure that the terms doesn't explode
in size when copied because of deep copy
that is made there
yeah the feedback is always welcome and
so you can if you have any bugs or
feature requests please add them to our
deira which is on bug suit or language
work or you can if you have any
discussion points or questions you can
contact the use our mailing list which
you can find on there Erlang org slash
community and there you can also find
some other channels to contact us on for
example our slack and so on and if you
want to talk to me and you can talk to
me during the conference I'm really
happy to discuss these things or other
early things or and so on with you and
or if you want to contact me after the
conference that you can use my email
here soundrenalin.org so thank you so
much for listening
at all yeah thank you so much that's all
banquet is working on the foundation
which makes it this
well it's been under discussion for a
while even before i joined the erlang go
TP team but everyone else is so busy
with other things basically and so I was
fast to grab this part because I think
it's really interesting with the
distribution and yeah so when i joined
we got an extra person too so we could
be able to focus on this as well
question response question the very good
rationale just people you're building a
large base enters big data key value
stores and java and 20 some types of it
that's very way of saying something like
side
yes
maybe nerds in the light switch special
good stead
yes thank you
responsive
sorry I didn't hear that which work yeah
i'm guessing not them
so you're asking about the nodes
function or okay the list of notes oh
sorry okay so we have talked about this
issue I wasn't able to fit that into the
presentation but the nodes function
there is an airline notes function which
which returns a list of all the notes
that the note is connected to and now it
will not be connected to all the notes
in the system anymore so it will change
that property because some people use
this note to get the notes function do
you get all the notes in the system for
different reasons we will provide a
snapshot opportunity instead to but that
will take a lot longer so that's that
way you will still be able to get all
the notes in the system but it would be
slower and also we will provide the
opportunity to actually seal set up
before fully connected network but
instead of being the default way you
might need to add a flag or something
like that and in that case case you can
still use the notes function that dancer
great
oh okay so the first question I think I
tested with 350 notes or something like
that but I used really quite large
machines to test on so I didn't use that
much of a network delay and so on during
the tests but it was improved a lot
compared to the old version of global
but we need a lot larger tests before we
can say that it will work for real I
think the replication works a bit like
as so when you do a lookup for
registration you will return k notes and
this K is a configuration variable so
you'll get the K nodes that are closest
to the hash of the name and then they
will be those K nodes will be
responsible for the name process ID
repair so it will be replicated on all
those notes so it's not replicated
everywhere but it's still it should be
sufficient enough if you don't have any
very dramatic crashes in your system
so you it was exactly like 50 / 50 goals
what people want to be the limit but
that's the default wings like you steal
50 goals right for because I'm sure if
you don't want to give you the
contribution you can just start it off
you can wear on without options you talk
to each other
so I like noticing and I do a person is
no type and again i want to say 50
became early connected to five when I
would be you wouldn't send the data
through the routing table because that
would make it really hard to keep the
message or ordering guarantees that we
have today we're considering to add
something like that in the future but
that's quite far in the future because
we think this should be sufficient
enough for a long time so for the moment
you will send the messages directly to
it yeah
they use thank you once again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>