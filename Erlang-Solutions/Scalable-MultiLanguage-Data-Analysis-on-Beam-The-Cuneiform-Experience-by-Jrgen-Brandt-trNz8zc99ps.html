<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Scalable Multi-Language Data Analysis on Beam: The Cuneiform Experience by Jörgen Brandt | Coder Coacher - Coaching Coders</title><meta content="Scalable Multi-Language Data Analysis on Beam: The Cuneiform Experience by Jörgen Brandt - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Scalable Multi-Language Data Analysis on Beam: The Cuneiform Experience by Jörgen Brandt</b></h2><h5 class="post__date">2016-09-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/trNz8zc99ps" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay welcome everybody so my talk will
be about a scalable multi-language data
analysis language which runs on Erlang
and to tell a little bit about myself so
I'm a PhD student at the Humboldt
University in Berlin I'm in my fourth
year I am looking forward to finish it
soon and I am working on the uniform
workflow language which is as I said a
language for large scale scale data
analysis and the major area of
application of this language is in
bioinformatics so the data analysis
workflows will we will look at are from
bioinformatics and what I hope to
achieve in this talk is first of all I
want to give you an introduction to what
Kenneth um actually is feels like and I
wanna I hope to explain to you how one
can implement a large-scale data
analysis programming languages how you
do this in Erlang and and why you would
do this in early anyway why the earning
is a very good platform to do this and
so first of all I want to introduce you
to the the term of a scientific workflow
system because when you when you want to
do large-scale data analysis you go to
kind of programming model would be
scientific workflows and a workflow is
essentially a graph a directed acyclic
graph in which the nodes represent tasks
and edges represent data dependencies
and as you can see here in this upper
example these tasks can be very
heterogeneous so some of them may be
Perl scripts or R scripts or
even Java programs so you don't have any
guarantee about yeah
you can't afford to stay at a stick to
one programming language in order to to
build these kind of workflows because
what you want to do is you want to reuse
your software so most of the time the
scientific communities are spread all
over the world everybody has their own
program a favorite program programming
language and yeah
you can't force everybody to use the
same language and what you end up with
is this kind of sometimes large
dependency graph which is which you can
paralyze and distribute over many
machines and to make an example so here
we have a workflow that is consisting of
three steps and the first steps takes
two input files and you know the data is
processed in these three steps and the
first challenge or the first also
opportunity that is prevalent here is
that the for bioinformatics for
especially for next-generation
sequencing the costs of sequencing
genomes is constantly dropping so this
is a logarithmic scale and we see here
this line Moore's Law so having in
sequencing costs every 18 months and we
see here that the sequencing costs drops
even even faster than Moore's Law and
this means that we are constantly facing
large and large amounts of data which
are generated cheaper and cheaper and
also if you look at the kinds of
machines that produce these sequencing
data it's easy to imagine that you can
run a sequencing many sequencing
machines in parallel so what you want to
do is
if you if you are able to sequence in
parallel you have also have to do the
data analysis in a in a parallel and
distributed way and the third challenge
is this is kind of hard to see but this
is a screenshot from a website where
tools for bioinformatics are summarized
and there's a huge amount of tools which
are used in this kind of setting so you
can't help to re-implement everything in
a scalable way you have to deal with
whatever the bioinformatics community
gives you and and the trick is then that
you most of the time it's it's possible
to partition the data the input data and
paralyze all the tasks and run them
distributed Li and this is what
cuneiform is for so if I have to
summarize for cuneiform is in one
sentence I'd say it's a functional
language for large-scale data analysis
which is implemented in Erlang and if
you compare it to other distributed now
as frameworks what what for example set
set up from from systems like SPARC is
that it has a standalone it's it has
it's very own syntax so it's not a
fluent API in scala and most importantly
it integrates a different programming
languages like Perl like Scala like
Electra like are so that you can reuse
software that is already written in
these kinds of programming languages and
it is also different from the kind of
go-to workflow languages that you would
use in this setting because it doesn't
depend on a static dependency graph
which is traversing but instead it is
reducing a functional expression and in
functional programming we have a richer
this is a richer programming model and
then just ascetic dependency graph
so the the kind of recipe that cuneiform
follows is its functional programming
combined with foreign function foreign
language interfacing and the functional
programming part is so important that I
want to reiterate on this so what we
gain from functional programming is two
things first of all we we get a
programming model that is very very
expressive in which we can express all
kinds of programs it has natural
operations on lists like map cross
product dot product all those kinds of
stuff which is very important when you
want to do data parallel yeah when you
want to iterate over lists and it also
has a natural way of expressing
iterative algorithms through recursion
so what we gain here on this side is
that we have a very general way to
express how a large-scale data analysis
program can look like and the other
thing that we gained from functional
programming is the is the possibility to
automatically find out what is what is
what can be done in parallel yeah what
can be done in parallel so so the in in
functional programming when when you
have an expression that is that is
combined of sub expressions it doesn't
matter in what order you you evaluate
the sub expressions and if you if it
doesn't matter in what order you do it
you can also do it at the same time and
from this we can automatically derive
from a script that you give us without
the user having to do anything what can
be done in parallel and and and the
other part is the is the foreign
language interfacing which I will be
explaining with an example so this is a
very very simple example of a
it's it says Steph tasks here but
actually what you're defining is a
function and has the name G unzip
because we will be extracting a file
from from a compressed format and it
will produce one output file and it
ingests one input file GZ and now what I
can do is I can jump out of uniform and
I for every function that I want to
define I can always say okay this will
be in bash this will be in Python now
I'm going to R and and this way I can
easily integrate libraries and tools
that are already there so in this file
in this case I will bind the the value
of the out variable to to the name
output file and then I will use one
called
gzip - Z means decompress - e means
write it to the standard output and here
I'm reusing the input parameter and then
I will pipe it out to output file and
then the system will know that it will
have to look in the out variable for the
name of the output file that was
produced and if I want to call this kind
of function I do this like I like
normally as a function call where I bind
the the argument G's it to a concrete
file and what is done is in this kind of
graph you see that you have here in an
input file it is an operation an
operator is called on that and output
file is produced and now what I can do
is I can easily extend this example to
extract three files because I can easily
just find lists here and will
automatically know ok these three
operations
not depend on each other so I can run
them on three different machines if I
have them questions so far
and from this I can examine assemble
quite complicated workflows and on the
Internet
side you can you can look up several
examples from bioinformatics and
next-generation sequencing we have for
example a variant calling workflow
methylation analysis and rna-seq
analysis where we compare expression
levels and also kinds of other workflows
that are variants on also already
existing workflows and if you look them
up on the internet what you always get
is a chef cookbook which which helps you
to set up this workflow so essentially
what you have to do in order to run
these examples is you just download this
cookbook and then you can create from
this virtual machine and we'll install
all the tools for you it will install
cuneiform for you it will download all
the data and all you have to do is run
the workflow and it will give you the
results so it's pretty easy to to get
started and when I started out in 2013
when I began my PhD there was a blog
post which was a type of flow based
programming and Erlang style message
Erlang style message passing a biology
inspired idea of how they fit together
so this is essentially a workflow about
how well Erlang fits the world of
large-scale data analysis and I wish I
had known this blog post back when I
started out which I didn't
and so I had to learn the hard way how
data and large-scale data analysis
programming languages were built and
also the the hint that Erlang is a good
idea to do this in is something I only
learned much later and essentially what
this article is about is the observation
that a large-scale data analysis system
is essentially a two-tier computational
system and on the on the one hand there
is you have this the system level the
algorithm level computation the which
does the heavy lifting the number
crunching which has to be very very fast
it doesn't matter if it is parallel or
not it can be also sequential and the
computation is only very local and the
other component is the organizational
where you synchronize the computation
where were you where you make the system
wait for the input data to be produced
so that you can start the consumer's
where you organize how the communication
with the distributed file system is the
scheduling and and and so on and so on
and what he did there in this post was
he did he he compared it to the way that
a cell does the way a cell transcribes
and translates genes inside it which is
very very fast and very very efficient
yeah let's say computational machine and
the other side was how cells interact
through hormones and and the cell to
cell signaling systems which are perhaps
not that fast but a lot more aesthetic
but
they make the sales function as a whole
system and ante and he observed that
these two-tier yeah let's say organized
organizational levels also and access in
nature and what was perhaps the most
important take-home message that that
Erlang is a very good fit to do here the
the workflow level the organizational
level thing in workflows and let me show
you just as an overview how the the
architecture of an overall workflow
system could look like so on the on the
top level you have here these these
queries which could be several workflows
that are running at the same time and
they all talk to a cache so when they
have to produce partial results for
their workflows they first ask the cache
and if the cache already has the answer
that I will answer this from the cache
and will not talk to anything else in
the system but if it has so because the
the answer is not already there then it
gives the task scheduler and the
scheduler make sure that the workers get
informed and can produce the results and
only here down here in this very bottom
level we have the actual number
crunching and and the fast computation
going on and also here it is where the
bulk of the data is is were just
produced where we communicated to a
distributed file system so the upper
levels here never never have to do any
heavy lifting in the computation and
also never have to send around large
amounts of data this all happens down
here in this kind of level this picture
is very nice to understand
how
a distributed workflow system could be
set up but it doesn't actually tell you
what is difficult about designing
workflow systems so here I like this oh
this is very hardly readable so here in
this upper box it says execution
environment so what I'm trying to say
here is that there is two things that
are hard to do in distributed languages
programming languages the one thing is
that a workflow expression is an extra
program and it is written in a
programming language I do it if you want
to do proper a proper programming
language then you have to model it and
there is a whole lot of literature and
and difficulties you can we could have
there and what is more in the execution
environment which is essentially all the
rest this is a distributed system and to
severe systems are as you perhaps know
also kind of hard and now I want to look
at Asian each problem isolated so how do
you program model a program in English
this is kind of the first important
question and it turns out there are
several ways to do that and at some
point you have to decide for some method
and and follow this along and the way I
have done this for cuneiform is so
essentially you have two specifications
for the for a programming language the
one is the specification of the concrete
syntax which we give in a backus-naur
form I don't know if these terms are
familiar to you but what you can do from
this kind of specification is you can
generate a parser automatically from
that this is this is kind of a very very
well researched area so parser
generators are very well understood and
I don't understand them yeah but other
people are very good at that and
and there's really a lot of useful
software out there and the other thing
you need is a semantics and only when
you have a semantics you can actually
formalize what what the interpreter does
yeah I mean you can sit down and program
it from scratch and never have any
problem with that
but it turns out that it's very very
hard to come up with a component with a
with an interpreter for for a decently
for a decent programming language if you
don't have this kind of semantics so
yeah to two things the specification of
the syntax and the semantics and how the
semantics works is in essentially you
have an an expression in a language and
the first thing you make up is how can
what kind of an expression be yeah and
an expression in this case can be a
string literal a variable name a future
to a computation that that has started
but not or but where the result is not
known yet a condition like an if then
else expression or a function
application and function applications
can be either native like where you stay
in can you form or they can be foreign
where you switch to another language
like Python or R or something like that
and this is a description of how each
and every expression and cuneiform can
look like and there's nothing more
anthesis this picture shows already
everything and then you go through this
and say okay when my expression has this
in this form what do I have to do in
order to transform it to a slightly
slightly reduced expression and you
follow this process until you cannot
reduce the expression anymore and then
it is a normal form and you terminate
the interpreter and and this kind of
thing
when you describe operational semantics
essentially it's a text yeah it's a
description of how an expression can be
evaluated and here I want to show you
how this can look like in the in the so
in the text form if you have a
description as I said and and for each
and every yeah like statement you can
have an inference oh you describe the
evaluation in terms of inference rules
and these inference rules tell you how
the evaluation is done and essentially
you end up with a number of formulas I'm
sorry you can probably not read it but
what I want to show you is that each and
every formula that appears here in this
paper in the in the text has a
correspondence a one-line correspondence
in Erlang so you have very neatly you
can say okay this is this is just a line
of formula in the text and it
corresponds one-to-one to a line of code
and Erlang and this is something you
don't get from most of the languages
around there so if you try this with
Java you will not get this one
one-to-one correspondence but with
Erlang is it's very very nice to come up
with a model implementation for what you
have described here in text and right
now so when you have come up with a with
an operational semantics or a semantics
in general then it's very easy to also
create interpreters and other
programming languages like Java like
Python and right now I'm maintaining
also a Java version of this thing but
but when I when I didn't already have
this it was a very valuable thing to
have this one-to-one correspondence
because I could immediately try out an
idea I had like on the scratch board
and it was very directly implemented and
I could try out what the language would
do and so this was a back and forth
process and and in the end I ended up
with something
I knew that would that it would work and
only afterwards now that the semantics
is finished it's it's actually feasible
to go in into other languages that are
more verbose or or more slightly more
difficult to to define this
correspondence but it's but but it's not
hard yeah for the design process was
very very very valuable to have Erlang
and the other component that is
difficult about this kind of distributed
data analysis system is that the
execution environment essentially the
distributed system but that it is and
now the question is how do you model a
distributed system and if you're from
the Erlang world you probably are a
little bit biased towards the actual
model but if you use OTP then you're
probably familiar also with the finite
state machines and stuff like that these
these are all very valuable models for
for modeling systems and for cuneiform I
have decided to to look at a system an
approach called Patriots I'm sure
everybody knows everybody knows for
unions but the kind of advantage of
Petri Nets in this kind of setting is
that is a very mature theory where you
can reason about all kinds of properties
like liveness and you can find
invariants and traps and code traps and
what is also very very advantageous is
that the decision making and the
synchronizations
are always very local in the net so if I
look at
one transition I always have to only
consider the preset of this transition
to know whether this transition can is
enabled or not I don't have to look at
the whole system and also when I look at
distributed runs of the system I can
always tell which of the transitions
fire independently and if they fire
independently then of course I can do
these things concurrently and also here
Erlang is a very yeah a very good
programming model because concurrency is
is very doable and here I want to show
you a patriot model of the execution
environment I'm going a little bit into
this yeah so when when function is
applied essentially the function
application appears here and if the
function application is has already been
seen in the system then you can just
look up in the cache what the result is
and return the result and if but if it
doesn't if it's not the first time if
it's the first time that the see the
system sees this function application it
will have to submit it where it were and
then the function application appears
here and what happens in X is that a
machine is scheduled to this function
application and then it goes out of the
system where it is computed this is
where the the number-crunching happens
and also when when we take us as a
machine out here it is yeah it appears
here so this means that the machine is
yeah that is occupied and after some
time yeah the computation happens we
might see the result here on this place
in which case the machine is released
again and it appears here in this and
ready pool
the result is put in the cash and is
also communicated to the to the workflow
system so and what I wanted to show you
here is that that as a Petri net that
fits on one slide can exhaustively
describe all these features like caching
scheduling partial failure and and all
these things and so this is a very dense
way to to describe this and exhaustive
and yeah sorry now you don't have Petri
nets in Erlang but what what do you do
when you don't have a Petri net library
in Erlang you built one and this is also
what I did so there's an OTP library
that does Petri Nets so and you can look
it up you can give me feedback you can
yeah it's kind of work in progress right
now but this is the way I'm I'm
intending to to implement these kind of
models in in the Erlang world where you
yeah
and going back to this to this blog post
of Sami lanta you need programming
languages to do the heavy lifting and
they are always there most of the times
their system languages where you do
where you can do the heavy lifting very
very efficiently and this is where
cuneiform goes out and employs other
languages and and also what I just
showed you these two models the
operational semantics for the for the
language and the Petri nets for the for
the distributed system they are all for
the organizational part the others so so
in the analogy and the biology and Alex
eat
the communication among cells and also
there's two reasons why large-scale data
analysis is hard and the one is because
programming languages are harsh but I've
shown you how you can model these and
the other reason is because distributed
systems are hard but Erlang is a good
fit for both because the functional
programming paradigm is already very
close to the operational semantics which
I used to model the programming language
and also because it's not not hard to
get the Petri Nets out of the
programming programming model of Erlang
it's already very also very close so for
this is from my experience why Erlang is
a very good fit for the organizational
part and not C data analysis and this
was a very concrete overview that I gave
you here and how we modeled these kind
of problems but the I guess the blog
post is much much more general and yeah
and to come to a close
uniform is a this language really exists
it's it has a wrapper you can call it up
and and play around with it you can just
download the binary on the website it's
just a few kilobytes big and to
summarize what it does what you get is
the combination of a functional
programming language and a very very
versatile foreign length for a language
interfaces so that you can jump out and
back and forth
it runs on I didn't I didn't really say
this it runs on multiple distributed job
queues for example HD Condor and Hadoop
you don't have to bother about
parallelization the script gets analyzed
and the the parallel pieces of work are
derived automatically and you have a
very expressive way to to express
workflows and a lot of languages that
you can interact with
for example Bosch Pro are Python and
this is where my close where I close my
talk I thanks for the attention
questions okay there is a question
so the question is whether there's a how
did we implement this on a Hadoop is
there a Hadoop library and this is - we
so the way you do this on Hadoop is so a
dupe was originally for the MapReduce
programming model right but recently the
Hadoop has opened up its kind of
programming model with the release of
Hadoop yarn it is now possible to put
any kind of programming model into into
Hadoop and in our group there's a very
interesting project called highway and
this is essentially a an implementation
of an application master for Hadoop that
one runs scientific workflows and the
scientific workflow languages it
supports include cuneiform what I just
showed you but there's also other ways
to run these workflows distributed lis
but on Hadoop you have this highway
application master you have a question
so the question is how we interface to
other languages so essentially we open
an Erlang port where we run the the body
of the script that you gave us and the
body of the script is not enough so what
you first have to also do is you have to
bind the input variables to the
arguments that were given in the
function call and what you also have to
do is you have to collect the output
variables again so that you can send
some further on downstream and and the
dependency deck and of course when you
when you ingest a file and output a file
this also has to come from the
distributed file system and also has to
be safely out the distributed file
system
there was another question well what
what's the first part so right now we're
not using distributed Erlang we're using
either Hadoop or HD Condor to do this
but with the models I just showed you of
the distributed system it would be very
very easy to do this also with with
distributed Erlang but we haven't done
this yet this is still future work so
exactly if you run it bare only on
Erlang then you you only get a single
node setup but if you want to run it on
an HD corner for example then it also
runs in Erlang but but the part that
that the the handling of the job queue
the scheduling the staking out and
staging in of the data this is handled
by HD Condor but it's it's feasible to
do this in Erlang only we but but this
is not not has not been done yet okay
Apache so the question was what is the
license of the Petri Nets OTP library
and and it's Apache too so no strings
attached
yes
so the question was do we generate code
from the model because the pattern it is
model in another library so so so this
generic generic Petri net library that I
give you allows you to define
transitions and places and it will
orchestrate the occurrence Roulettes and
and the consumption of tokens and the
production of the tokens in other places
for you so you have a way to
programmatically Express the the
structure of your Petri net yes we don't
have that so so the analysis of the
Petri net and the the derivation of the
properties and then and all that stuff
we don't offer we just offer you as so
in this interest generic Petri net
library perhaps this is something we can
add in the future I don't know but right
now what you can do is you can express
your pattern you can run it but if you
want to analyze it and and and reason
about the properties you have to stick
to other other frameworks other tools
other questions
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>