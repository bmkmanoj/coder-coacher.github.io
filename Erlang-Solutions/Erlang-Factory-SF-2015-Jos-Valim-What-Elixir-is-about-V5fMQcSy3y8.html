<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory SF 2015 - José Valim - What Elixir is about | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory SF 2015 - José Valim - What Elixir is about - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Erlang Factory SF 2015 - José Valim - What Elixir is about</b></h2><h5 class="post__date">2015-03-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/V5fMQcSy3y8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello more and everyone thanks for
coming to this talk about Alex here and
the title of this talk like the official
title the talk is what elixir is about
and it was really interesting to prepare
the stock because today is like the
third or fourth year i'm speaking about
alex here at this event earning factory
and when I was preparing this talk I
decided to take a look at the previous
presentation slides and you know there
is there was one common thought in all
those talks right like there is the the
backbone the skeleton was always the
same but it always changed a little bit
right the things around the skeleton and
it's really interesting because that's
exactly software design right beat
you're working your application or a
library a framework a programming
language you have problems and then you
need to come up with solutions to those
problems need to think about
abstractions and some of those you know
you start you think about a possible
solution some of those you figure out
after three months or six months that
they were not really good right and then
it kind of need to throw it away start
again from scratch and think about the
problem over again but on the other hand
there are also abstractions right that
you think about them initially they work
really really well when in the future it
grows way beyond you you felt was
possible right it open up a lot of
possibilities that you end up exploring
more and more in the long term so that
wasn't on the interesting parts of doing
this talk and it's a little bit what
this talk is about also about those
those those abstractions that became
more and more important as Alex or grew
as a language okay and yeah and those
are this is one of the main points okay
so to get start with the talk right what
are the theories about I just have one
quick disclaimer which is it's not about
the syntax it was never about the syntax
and not even when we started and
definitely it's not about the syntax
today and this is the only slide you're
going to talk about syntax and I'm going
to talk about syntax at all during this
presentation and one of the reasons is
that we cannot have an object
discussion about this right we cannot
say like which syntax is better right
some people are going to say oh if you
really wanted optionally needs to look
like see someone is going to say well
you know for functional programming
language it needs to look like something
from DML family and then Robert Verdi is
going to yell from the end of the room
like needs to be Lisp and it's never
going to be objective right everyone
brings a lot of opinion and we cannot
have an objective discussion about it so
let's get past this okay and let's talk
about the DL a virtual machine so the
way I look and at the end of your own
machine today is that we have three main
things okay so we have data types and
those are the lists tuples numbers okay
that we use in our code and we have
modules and the modules where we
actually have our code code rights where
we have the behavior and those modules
their work with the data types and we
also have processes okay and the process
our identities that are actually running
our code and everything is
interconnected right because the modules
they are working with the data types and
the processes they are running code that
is defined inside those modules and most
of the data types they belong
exclusively to a singular process okay
so everything is interconnected and and
then at the end right when you have all
those things you we need to package them
with a very nice tooling okay to work to
write code and be productive and whatnot
so what I realize no looking back in
retrospect is that if you look at more
if we start with processes right process
they are like the main star of the show
when it comes to link your towel machine
right they are excellent they are the
main entity that run our code we have
the OTP team puts a lot of affording
ensuring the processes they are
efficient they are there our also
abstraction our abstraction for
concurrency okay and for distribution
that's where the message past is
happening so you know we have a lot of
fermentation in there they are
definitely the main star of the show
okay and
I don't think anybody here would
disagree with that modules they are also
quite well developed right because for
example modules is our all codes that we
have in that we're on beat earning or
elixir it needs to exist inside a module
right modules are also our abstraction
for doing hot cold swapping and we even
have things like behaviors that allow
more just to specific contracts okay so
they are very well developed to and
looking back right what I think about
this is that the data types when we look
at those three things here okay they are
the one that they were not well
developed as everything else and elixir
came as a reaction to that okay its one
of examples what elixir is trying to
solve so to give some examples of you
know why I think data types they're not
as well developed as everything else
right we cannot really have custom data
types okay records they kind of aim to
add taggat opposed to early but you know
there's plenty of discussion that in the
main amazing talks and the
implementation kind of backfired because
they are mostly a compiler hack the the
top of modules call there's a bunch of
discussion about it too and in my
opinion I know that not everyone agree
with this maps they are a huge
improvement when we are talking about
adding kind of like our own our own data
structures right so map their
improvement because you can have our own
keys and then we can specify which kind
of values and we want but they do not
official eyes tagging I cannot say no I
have this map and this map has this
layout this is structure and then I can
tag it and I know that all other maps
with this tag is going to have the same
layout we don't have this idea yet and
if we look at other proposals so before
maps they were added to the RNA inverter
machine if you look at other proposals
like the frames proposal from Richard
oki if he actually talks about tagging
and why tagging could be helpful to add
this idea so we don't have it yet that's
one of the issues right another issue
that we are talking about data types is
that when we talk about polymorphism in
Erlang we have
just one basic way of doing polymorph is
based on the data types which is the ad
hoc polymorphism and we have papers from
88 from Philip water and stiff and blot
it's almost as old as they're laying
that says why ad hoc polymorphism is no
it's quite limited and why we need to
think of better solutions we are going
to talk about this later okay one of the
things that actually I first noticed it
when star started working with valeting
again when it comes to data types is
when we won't think about collections
airlink does not have this idea of
collections okay you you cannot so we
have a bunch of data structures right
like set lists arrays kills but we do
not have a unified way to look at them
to look at collection to say those are
all collections and this is very common
to think about collections it's very
calm when the bunch of functional
programming languages and it became
actually fantastic in Java 8 so here's
some Java 8 code java 8 introduced it
lambdas and they already had this idea
of collections but when introduced
limiters they also introduced this whole
function of vocabulary that we are used
to work with like map filter and so on
all those functional names and
operations reduce and why not and when
they introduce that they you know they
mix that with collections so here we
have like widgets and then we are
filtering the widgets by color and then
we are getting their weight and then
some it okay and in this code here it
doesn't really matter if widgets is a
list or if it is a set okay if it is an
array it doesn't really matter you can
use those functions filter maps some and
whatnot with anything that is a
collection right with anything that
behaves like a collection and this is
really important because you need to
learn just one set of API are all right
just one set of functions that's going
to work with everything and you don't
need to learn a bunch of different API
is specific for every data type and not
only that okay and a few even in Java 8
they also added the idea of laziness in
collections which again is very common
in other functional programming
languages
and the whole idea here is that you can
see her that the difference is that we
are calling widgets not string okay and
not to understand how this works I will
go back to the previous slide so what is
happening here is that we have widgets
not filter and then what these do is
getting the widget let's match let's
imagine it is a list it's getting the
widget as the lease and then filtering
and then after filtering it creates a
new list and then you're going to call
map to int that is going to get integers
right but as a new list and then you
some everything together so it is
happening here is that we are traversing
the list multiple times and generating
intermediate lists okay intermediate
lists which may not be very good in
terms of performance depending on the
size of the list for example so what
laziness does is that when the same
widgets dot string next time you call
filter it does not actually traverse
this stream does not actually traverse
the widgets list it just stores the
computation okay and when you say map to
ain't is going to again storage this
computation it's not going to evaluate
it and just when you call something like
some that actually needs a result like a
number or when you call to list is that
it's actually going to get all those
computations fold them into a single
thing and traverse the list only once
okay so that's one of the things again
for laziness and it's very useful if you
have for example very large lists or if
you have an entity a collection that is
hard that is expensive to compute so you
don't want to traverse everything if you
don't need to okay and that's one of the
things that we don't have either so you
know given the citroen introduction
right I think it's it's time to talk
about Alex here because Alex see one of
the main things that we have in Alex you
came as reaction to that and we are
going to explore explore that in this
talk so every time I give a talk about
elixir and I said at the beginning that
there is a common you know common things
that I say every time and those common
things are the language grows so every
time in giving a talk I like to explore
whatever you talking about from the
perspective of the language grows and we
have three goals extensibility
productivity and compatibility and those
are the trade topics are going to
explore for the rest of the stock and I
use them to explain what an elixir is
about okay so let's get started so
accessibility and there are many things
that make a language extensible right
and that's true for the most of language
features and characteristics right so
when we say like over Lang's fault
tolerance not only one thing are many
things that play together that allow
that makes it easy for us to write
photo/laurent soft in ireland and
excessive it's the same thing right
there are many things and I want to
explore one in particular for this talk
which is data type polymorphism so this
is not the correct name you can read the
paper mission early but I'm going to
call it data type polymorphism in the
hope that's going to be very clear what
it is about so if we go back to our
three entities that we are talking about
right datatypes modules and processes we
have polymer fields with modules and
processes but we don't have it for data
types and what is mean is this we can
write this code in earning okay if I
have processes i can say i have a
process identifier and i want to send it
a message and we don't care what is that
process identifier we don't care which
code it's running who is started we
don't care anything about it the only
thing we care is that that process knows
how to handle that message giving a
contract that was stabbed shot earlier
right so basically it's polymorphic
because you can say you know I don't
care what is this process as long as it
is a process that handles this
particular message okay and you can have
any shape right we don't care if it
handles that's that message giving a
contract we are good to go we have the
same thing for modules right so here is
their link code let me say I want to
call a a function in a module and
modules in inner laying an elixir they
are first class because we can pass them
as atoms right so we can pass them
around so you say no I don't care which
module you are giving to me as long as
it implements this function right so
again is the same idea of polymorphism
and we rely heavily on that every time
we use a jewel server every time you use
a Jenner vent is exactly this right the
gems server module doesn't care what you
are passing the name of the module
you're passing
argument with the callbacks as long as
you implement all the callbacks okay so
you know we don't care as long you obey
this contract and when it comes to data
types we don't have that right we don't
have a way to say you know you can give
me any data type you want as argument as
long as these data type this X right we
don't have this X and one example of why
this is useful and and I like to use a
lot is the JSON example right and
everything we need to think that need to
use for example sterilize any kind of
data structure or traverse any kind of
data structure okay is where these
polymer fees becomes really useful so
here's how I would imagine like we are
an airline developer and then we create
this JSON module and what is Jason watch
does is that it can encode different
data structures to Jason so all we do
here is that you know we define a bunch
of clauses right so when I receive an
item and this item is a list here is how
I'm going to encode it to Jason if I
receive an item we design as a binary is
how i coded to binary and so on and the
issue if that is that it doesn't because
all the clauses they are packet in the
single module it doesn't really compose
so imagine that we have this code right
we have this this JSON library and then
Robert he's working on loro one of his
projects okay and the lure of project
has its own dictionary has its own
internal representation of how it
represents Lua object and he wants to
use the JSON library okay the issue is
that the lure Oh project because it has
its own word presentation the Jason
project has no idea about this new
dictionary thing right it doesn't know
about it and because Robert needs to
depend on it right he has like a couple
options so one of the option would be to
fork the Jason project okay and let it
know about his real data type maybe if
the person who designed to James the
library allow a function to be given a
call back he can try to use this
function call back okay and then he can
kind of use this JSON library but now
imagine that someone come later Joe
right
is working this virtue project and he
wants to interface with the loro project
right and also use the JSON library so
he wants use both and Jareau also has
his own data types okay because it's the
new earning version rights or choose so
it he has a new data types and what he's
going to do now because the Jason
project doesn't know about his data
types okay so i can say okay i want to
fork the Jason project to let it know
about my data types but Robert already
forked the project so he needs to now
create a fork that has both Robert
changes or his changes right if he was
using friction callbacks he needs to
represent need to get all the function
call backs and implementation from
Roberts project bring it to his project
okay and then he can maybe it will work
right so it really doesn't compose right
you cannot like have different projects
just extending the JSON library and the
issue about is exactly because it's just
ad hoc polymorphism all the code is in a
single module is in a single place while
the truth about this is that the data
type is the one that knows how to
convert itself to j ism is not the json
module right the Jason Roger cannot know
about everything right the one that
knows about that is the own data type
and the data type is the entity we need
to ask about you know how do I represent
how can you represent yourself in JSON
and this is exactly what protocols in
Alex retain to solve okay is to bring
this polymorphism okay so what we can do
is that analogy would say I want to
define the JSON protocol and the Jason
protocol has a encode function and we
can call this in code function as any
function in our code like JSON that
encode passing the item and the thing is
that after you define the protocol you
can implement it to any data type that
you want so the person that implements
the JSON library could implement the
protocols for all the native language
types so you could say the
implementation of the JSON protocol for
lists is going to be this the
implementation of the JSON protocol for
bit strings is going to be this other
thing okay and that's it and then if
someone else in the future has their own
data type right like robert or Joe dear
just would say
the implementation of Jaisal for my own
data type is going to be this other
thing and at the end of the day what we
can do is that we can write a JSON
library that is accessible to any data
type B this data type existing in the
past or a data type that someone defined
in the future so we have basically
answer this question right now if I want
to say you know now that I have
protocols I can say you can give me an a
data type that implements a protocol and
your code is going to work it's a
contract that is happening at the data
type level and with this we can do a
bunch of interesting things one of those
things is exactly to introduce the idea
of collections into Alex Syria so one of
the protocols we have is the numeral
protocol and the newer protocol tells
how we can traverse data structures how
we can traverse collections so here's
how I can use the newer protocol to map
over the numbers in the list multiplying
every element in the list by two okay so
it's just mapping over this list but the
same function can be used to map over a
range ok and then and you can if you
define a new collection if we define a
new abstraction if you define a special
key I special rate implementation you
can teach the numeral you can teach the
new module that comes with Alex here to
work with your data types right you do
need to reimplement all those api's so
what is the inner protocol right
internally its base or something called
hasko authorities and what this means
the titles based on haskell authorities
is that it not only works with in-memory
collections like lists ranges and so on
but it also worked with resources it can
also abstract resources like file i/o
socket as collections okay so here's an
example in Alex you if you have if you
have a path to a file you can get this
this file as a string as a collection
and then for example by default pirate
stream is going to get a file and
traverse it per line so considering that
every line in the files is an entry in
this collection so here
Alex your code to taking the first 5
lines of a file that's all you need to
do right to create a pilot stream and
then you say I want to take the first
five entries by default which considers
every line an entry and then it take the
first hive entries is the same function
we use to take the first five elements
of a list and the thing about fios train
is that you know it already start giving
us this idea of laziness because when
the save file dot stream it doesn't open
the file it just contains a
representation of how we need to open
the fire when there is a need get the
entities out of the file and then close
it okay so fired up string just returns
this representation and just when we
need to actually traverse the file that
the file is open we get the pipelines
and close it and we don't even need to
traverse the whole file okay so this is
a really a nice example we are going to
come back to laziness later okay another
example of a protocol is the inspect
protocol that we have in Alex ear and
this is some airline code so earning has
a dictionary data structure and when you
create a new dictionary if you are in
the terminal it's going to spew all the
dictionary internals in the terminal
okay and you're not supposed to know
about this right if you're if you're
going to check the types packs for the
dicks mod it says this thing is opaque
right you're not supposed to know about
these aren't supposed to feel with this
and there are ways that you can do so it
doesn't show all that okay but that's
that's what we get and and again is the
same issue right we actually want to ask
the data type you know what is the best
way for you to represent yourself to a
developer and that's exactly what we did
with Alex series so analogously we have
a hash dicked which is the equivalent of
addicting air link and the hashtag
implements the inspect protocols so
anywhere in the terminal and you create
a new hash dick that's why the sea right
and this is really good because you know
if you have an error in the origin
server or if you're logging something
you're not worried about all those
dictionary internals right your word
just about this representation and if
for some reason you are kind of
debugging some cold and kind of want to
see what is inside there is a flag you
can set and then you can see the whole
internal representation but by the phone
that's not what you want right
someone who care so you're going to see
just this just the part that the the
beats that matter cool so that was about
accessibility and the basic example I
gave here was about no introducing
polymorphism and allow us to define
contracts that say you can give me any
data type that you want and the code is
going to work as long as you obey this
protocol okay the second one is
productivity and it's going to be really
really short i'm not going to explain a
lot of it on this talk and one of the
ways that we sure it's kind of hard to
measure right productivity how can we
say that one language is more productive
than the other but one way that we sure
that elixir is going to be productive is
by providing very good tooling okay so
we have a bill to called mix so as soon
as we saw Alex here we are going to you
have this mix to that can create
projects compile and test them for you
we have a package manager called hacks
Eric's going to give a talk about hacks
later which is worth checking out the
and hex is a package manager it's really
nice because since the beginning we kind
of wanted hacks to be a package manager
for the whole hour lyrical system and
now you're talking if there were three
folks I think they're going to mention
it on their talk to integration with
hacks right and also documentation
you're not going to be productive if we
are in an environment where developers
they don't write documentation right all
what you need to do to know how project
works is that you kind of need to go
look at the source code that doesn't
work out right documentation is to be
easy to write and easy to read so just
to have an example okay if you install
Alex see you can run those five comments
and the first one's going to create a
new project then you go into that new
project and the mix test is going to run
the task going to compile a project and
run the test for you and then mix hacks
that publish is going to build a package
and release this new project as a
package and then you can run mix hacks
docks that is going to generate the
documentation for our project and upload
it to a version page okay so if you go
to the electric projects all the
packages release the huge majority of
them has documentation publishing online
in this dome
this version okay and this is really
really good this is really important if
you are talking about productivity cool
so that was truly really short and we
can get to the last part of the talk we
just talked about compatibility so
compatibility it's how compile a daily
came to be a goal is that when I was
first still playing up really developing
with Alex serious kind of playing around
how it could do evil language where we
can putting it out what we should live
out I've mastered things so much that I
was able to break things like no hot
swapping could not work at all for a
reason because I was messing something
the bytecode and then you know
eventually I I figure out that if you
are creating this new language and one
of the reasons for this new language
that it's going to run on the airline
through town machine it doesn't make
sense to sacrifice the the important
features that the virtual machine and
the real time gives to us and then we
say okay compatibility it's very
important and then we put it as one of
the language goals and for a long period
compatibility meant in a mint this weird
relationship where would say we don't
touch the airlink part so if you wanted
to use the gel server we say like use
their lingual server if you wanna do
this we say like use the ER link one and
it took time for us to get confidence
that you know we that we could start
seeing compatibility not only as this
distance right but also in a way like we
are going to value this airline
foundation but they are also going to
start discussing right and bring people
from both alex en la communities of the
discussion to see how we can improve
things and take things forward ok and
that's the place we are right now so
this last part of the talk it is going
to have two parts which is what we have
right now with Alex you're not 0 and
while we are planning for future elixir
versions ok so you know in in a lecture
we have supervisors we have applications
and they are basically the stock ones
that come about to be we didn't add
anything really so when you're running a
supervisor in Alec series is actually
the same code as running the supervising
airline
okay we didn't change anything that area
yet but we did some changes for except
when it comes to John server and we are
planning changes when we want to talk
about Jen event okay and I really like
the changes with diligence serve it was
actually one of the top the topics we
had in the keynote last year here at
earning factory and the thing about your
server right is that it is a generic
server as the name says and the issue
about that is that sometimes it's very
hard for her to look at digital server
and figure out what it is actually doing
right because you need to go hop for all
the callbacks to do you get and
understand what that Jill server is
really supposed to do and sometimes
there is no other way right because the
gel server is keeping state and do a
computation this state but there are
cases when you go to the extreme right
where we created your server only to be
about computation we created your server
for is securing a task every 30 seconds
right is acute some particular code
every 30 seconds and there is really no
state in there right it's only about
computation and we have also the
opposite right when a jewel server
doesn't really do anything it doesn't
really do any computation it's only
reason is to is to keep state right
that's the only go of it to keep stake
because that's one of the Rays you have
to share state between different
processes in Alex ear so what we did is
that we introduced two new obstructions
which are tasks which is exactly this
extreme where if you want to do
something that's only computation okay
and we introduce agents which is only
about a state and the benefit of this is
that if I'm reading some application
code and I see they're using an agent I
know it's about a state it can not be
anything else and that makes the code
when you look at it the first time it
makes it much easier to understand
because you know this is only about this
state it cannot be about anything else
and the same thing for tasks okay so
let's take a look while we gained we've
done so a task for LA developers it's
very similar you know when we say task
startling it's very similar to proclip
spawning that we have in erlanger
the difference here is that we are
really pushing forward to the use a
usage of tasks so when you are for
example in our gotta start a guy or say
no instead of creating a process with
polling use task start link because
you're going to get nice logger messages
and we can do a better a fork in there
okay so we're really putting it out okay
and that's to start pretty much with
these right just a startling start link
and it doesn't do anything more but with
time they start to encapsulate other
common patterns one of those patterns is
the async await pattern we stole the
naming from from.net from C sharp okay
and so this is a airline code that I
already wrote multiple times and already
seen multiple times which is basically
what we want to do here is that we want
to start a process to compute something
and then read the computed value later
okay so this one is called this means it
gets the current process right it
creates a reference and then it spawns a
child process that is going to compute
something and then send a message with
the computed result later and they late
when we care about it we read the result
and it's also common that I said okay
there needs to be an easier way to do
this ok so we introduced a sink away so
just say task data sync the function you
want to calculate and then you can do
whatever you want to do concurrently
right with that computation and when you
care about the result you call task dot
await and that's going to wait for the
result for the default amount that we
have on five seconds ok so that's one of
the patterns that we added on three
sorry to have tasks another pattern that
came once we start to work more and more
of task is distributed tasks ok so we
ship with a task supervisor and you can
start this task supervisor anywhere you
want in your application so what you can
do is that this a test supervisor is
startling and give it a name and then
from another node i can say task dot
supervisor dot a sink and ask that task
to be as acute in the other node and
then it can read the results later i can
also justice pawn simple tasks in other
nodes and so on earning developers they
are actually going to
realize that this functionality is
similar to what we have in the RPC
module inner link Fred even mention it
last year and but the difference here is
that the RPC module is that it's it
starts 1 jul server ok for each other
node and all all the RPC calls go
through this single server and here we
kind of have more of a building kit you
can start as many tasks supervisors as
you want and they are not sterilizing
everything through this one RPC server
you kind of can create many of those and
each application takes care of their own
tasks supervisors ok so those are very
useful patterns that came to be and that
we are using them ok and the other one
so that was tasks which is about
computation and the other one is they
are agents right and there isn't really
much about agents because because
they're just about state so what we do
that you start an agent and you pass a
function that calculates the initial
state and then every time you want to
update the the agent ok we send another
function that's going to receive this
state and return the new state and every
time you want to read the state get a
portion of it right or it all you just
call agent Doggett that's going to get
whatever we care about that particular
state and that's really useful right and
one of the main triggers for for for
creating agents and we saw that
happening multiple times is that people
would start to learn Alex here ok and
they would come to to our you know to
IRC channel to the main enlist and they
would say you know I just want to read
this file and keep this file content
somewhere I can access because I don't
want to read and parse this file all the
time all right so they just create
wanted a very simple agent that keeps
imparted file content ok but we didn't
have agents at the time right and then
we would say you know oh I don't need to
do is that you need to create the server
and then need to implement this callback
this callback this callback and then you
to implement the client functions right
and that was extremely confusing right
people would really have turbo rockin
the whole server pattern when they were
just starting with it ok and then agents
they basically you know they solve this
problem and
after introduced agents we cleaned up
some of Alex your code too and if you
look at the common commits it's much
much clearer right the parts were just
keeping estate agent makes the code much
more readable okay cool so this is like
the present this is what we have now
right we have tasks and agents and
everything that I'm going to save from
now to the end of the talk are the
things we are currently researching and
exploring for future versions so one of
the things that we can do is that
because agents start teaching developers
to think about state as a single entity
we can bring some research for example
from the alvars right so we can have
agents which are lattice basis basically
this means that we can have agents that
if we have multiple processes trying to
change this agent we are just going to
expose an API that guarantee
deterministic parallelism okay so
basically we can do is that as you are
doing more and more parallel
computations with the agent lattices
they're going to guarantee that you
cannot have method results are that they
are not going to corrupt this state and
depend depending on the order the code
is a security they're going to have
different results so that's one of the
things are exploring right what if we
have a set of agent and operations that
they are guaranteed to be deterministic
for parallelism and the alvars research
talks a lot about that okay there's even
more interesting research happening
which is when it comes to see our duties
right what if we have an agent crdt
which allow us to guarantee that we can
replicate the regent state across loads
so what we can do with that that imagine
that you have like two ur length nodes
right and they all they all have this
version of this agent and you want them
to be communicate with each other so if
this node rights to this agent this
change should propagate to this other
agent right and we want to write it in a
way or guarantee that the change they're
always going to converge ok so it's
because already thinking about this
state is not a huge leap to think about
those abstractions and they're going to
be really useful when we are talking
more and more
about parallelism which is as a quad is
coming next ok so this is its way to be
in alex 0 1 dot one or one or two not
the lattices or the crdt stuff but
better constructs for doing parallelism
this is what we are this is what we are
putting a lot of effort for upcoming
Alex your versions okay and in order to
talk about parallel is where we talked
about refunds laziness pipeline parallel
lives and the data parallelism so we
talked about collections at the
beginning of this talk right we had a
Java 8 code and this is kind of how we
would translate it to Alex here we have
a widget which is a list and then we
want to filter calling the enum
functions we talked before right so you
want to filters only the ones that are
red and then we want to get the weight
okay and we want to take for example the
first five ok so those are collections
and those collections they are eager
right they have the same issue that we
had in the Java code in the sense that
when I have the widgets if we'd is a
large list when I call filter it's going
to traverse the whole list and create
another listing memory when we call map
it's going to again traverse the
filtered list and create another list in
memory and so on but Alex Siri has the
idea of laziness and they are called
streams and all we need to do is to get
laziness is to replace the in no module
by this string module ok so the code is
the same we just replace the the
operations we want to be lazy by string
and then when you want the actual result
you call a function from an um that's
going to evaluate this train and get the
result you care about so we could call
in them to list to get a list or in them
some to some those results okay and here
is lazy right so the widget where we
pass it to a string filter it's not
going to filter the widgets is going to
restore this computation and then when
we call a stream and that map is going
to store this computation to and
streamed uptake is going to start the
computation true and when we call them
to list everything is executed and what
is really nice about is that when the
same is trimmed up take it's going to
execute just the first items not even
going to filter or try to map all the
other items as soon as you get five that
makes your criteria it stops right it's
not traversing everything all the time
so that's one of the benefits we get
with laziness right we can work with
large collections even infinite
collections right it doesn't matter
because we can say give me the first
five and don't care about the rest but
when we were talking about laziness it
opened up another big possibility which
is if we have this abstraction of the
computation if we have this
representation of the computation what
we could do is that we can say well it
doesn't really matter if this
computation is being executed in this
process it could be executed in this
process and this other process at the
same time right our could think of a
pipeline patterns showing up and this is
act what we are discussing is that we
want to introduce pipeline parallelism
so this code is the same as the previous
slide except we added this call here
streamed async and what this is going to
do is that you know we have all the lazy
competitions here filter map and take
and when we call string that a see what
it does that says oh when you want the
results what I'm going to do is that I'm
going to create a process to compute
everything that you have so far so
everything all those three operations
here everything up to Israeli think is
going to happen in another process okay
and we can have pipeline parallelism
unch of operations you can just call it
straight up a sync multiple times when
the call is turned up I think multiple
times each of those going to start a
different process and then as soon as
the data start to coming the first
process is going to perform the first
computations send it to the other
process right so the other process is
computing the first item and the
previous process started to compute the
second one so have many like stages in
this pipeline and there are all
receiving data right and processing them
all at the same time right so we have
these having put and then we have this
process let's process some of it and so
it's done with the first it sends to the
next this starts computing the second
and this starts computing the first is
just received and the data is just
flowing through your system okay because
we are building everything on top of
those abstractions right on top of
collections and then on top of laziness
and let you know we're looking at this
right and we say okay what is going to
be those red boxes
right what can we put in there to
encapsulate this pattern and then we
were discussing about and then we fall
to know is there a pattern in OTP that
is about receiving input right and then
sending this a little processing it and
then sending it out to two different
entities and then we we said well this
fits gen event right so we are we are
extending gentlement to fit well this
pipeline of parallelism ok and it's not
only pipeline pearl is it's also about
introducing a bunch of data parallelism
functions right because the pipeline
parallel is we are parallelizing the
computation right like each step there's
a different computation so each process
is doing a different computation but
sometimes when you have a lot of data
you want all those processes to do the
same computation and spread the data
around like say hey now you compute this
thing now you compute the senior
complete this thing and there are many
strategies that we can use right we can
think about farm we can be a we can
think about pin map that starts for
example one process for every data and
we don't care we if we need we start
like 10,000 processes or can think about
Chung ket P map that starts a process
for every ten entries in the data okay
and basically what these allow us to
think about the data parallelism which
is exactly a general vent pool that is
receiving put delegating it to a child
gen event and sending it as output okay
when we put everything together we can
really have those pipelines right of
data coming through and then going out
cool so this is what we are actively
working on and what really makes me
excited about this right because we are
adding those abstractions and we are
thinking about those constructs in terms
of dealing virtual machine and no TP
okay so what is interesting is that if
we look at other languages if you start
if you have a like data problem you
would you would start writing your
application in a way that uses like the
memory collections and whatnot and then
when you start to have a lot of data
okay you need to completely right or
cold maybe start thinking about
something like spa
okay need to think about going into a
completely different direction but here
we can really grow incrementally right
because of the vm and OTP because what
I'm going to do is that you're going you
write our code and everything is eager
then you say oh this is not as fast as
it could be so I'm going to introduce
the idea of laziness right and that
improves a little bit and then you say
okay laser is not enough what I want now
is concurrency so we introduced this
idea of parallel is beat the pipeline
parallel is where data parallelism but
if at some point come curse is not
enough right because we can have
distributed airline and we can use that
it should not be hard for us to get that
and then start running in a distributed
set up okay so that's really exciting
and not only that right we are going to
use all the guarantees we have from OTP
for beauty parlor and software it allow
us to think very well about the failure
semantics right what is going to happen
if one stage fails okay we need to think
about this stuff and this environment
forces us to think about this stuff okay
so we have like a lot of interesting
challenges right even if you are
starting from polymorphism we can start
discussing what is the most efficient
way of doing the polymorphic dispatch
what is the most efficient way of you
know when I have this data type I need
to know how to dispatch to the proper
implementation how we can implement this
revolt any overhead right one of the
common techniques is inline caches right
how i can add inline caches are
implementing lino cash is in the
elevator machine that's just about
polymer please write as soon as we go up
from cash collections laziness and
parallelism there are a bunch of
interesting challenges which is how to
provide back pressure right if you have
data going for this pipeline if you have
one stage that is low how can we provide
breakfast and how that's going to
manifest itself throughout the whole
pipeline okay if you're talking about
data parallelism uchi strategies
relevant because processes they cannot
share data okay so many of the patterns
we have our data parallelism they rely
on sharing the data multiple processes
working with some char data we can't do
this now so which one are relevant
fervice okay for the elevator machine
yeah so that's it for the talk if you
want to learn more about Alex you go to
our website
we have a getting started guiding there
we have a bunch of books are available
there is a learning section on the
outside which talk about different books
from to get started and finally I want
to thank my company platform attack we
have decided since early on to invest in
Alex here to invest in the ecosystem and
I'm really excited that allow us to push
forward and think about those very
interesting problems and one of the ways
if you want to keep to know what it's
happening in the Alex your community is
to subscribe to Del X rate of this
letter you receive a pamphlet in your
bags then you can get more information
or can come ask me and that's it this is
the talk about Alex here if you want
stickers i also have stickers and then
come talk anytime you want and we have
time for questions okay so questions we
have any questions oh yeah yeah
implementation is start the stream would
start an actor for every element
industry go do all of this work
okay so the question is yeah exactly so
the question is you know if we have this
code right I'm not even going to risk
parallel is because it's going to answer
a question even without so imagine that
this map operation is super expensive
okay for some reason got into wait you
need to like go to the scream do
something crazy imagine it is super
expensive we just care about the first
five right so we don't want to map
everything we want to take just the
first five that comes out and this is
exactly what is going to happen here as
soon as you get the first item comes
okay and then this if it's filtered it's
going to stop here but as soon as you
pass five items it's not going to
compute anything else it stops there
okay so so that's that's one of the ways
then we were introduced apparently this
is going to depend a lot which of those
strategies you are using because for
example Chung ket P map is going to
start them in chunks and so if you're a
chunk is a hundred you are going on it
to take five they a hundred is going to
be processors at the same time because
that's the kind of granularity that you
chose okay so that's why we need to
think about different strategies to
because the foetus is going to cut off
as soon as you get five maybe you're
doing it in eager steps somewhere before
did I get to answer a question
what we care team you're going to do
computations do yeah oh I see yeah yeah
so it so probably probably again it's
going to depend a lot on your strategy
because we're if you have a farm
processing let's supposed to have a farm
or master-slave set up doing eight at
the same time you're always going to
have some going above this five limit
right so it really depends on a strategy
and that's why we need to think about
different strategies when it comes to
computation right because you say like
okay how can I guarantee the five cut
off it's going to really depend on how
are splitting it apart okay and and when
you put everything together is one of
the concerns you need to have cool yeah
you need to think yeah yeah okay so come
talk to me right after the talk if you
have more questions that's it so thank
you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>