<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The story of Whisper (..) | Coder Coacher - Coaching Coders</title><meta content="The story of Whisper (..) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The story of Whisper (..)</b></h2><h5 class="post__date">2014-09-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kKquHBHvQ0s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello and welcome to the Erlang
solutions monthly webinar my name is
blood animal extra hundie solutions
director here at hurling solutions
today's webinar represents a
continuation of a series of webinars we
have been organizing across topics of
interest in the world of airline and
dealing with solutions based on the
airline programming language
specifically today we will talk about
the creation of the whisper application
by in our cotton airline solutions
company whisper as we all know is the
largest anonymous social network and
Anaka worked with whisper to build from
the ground up a highly scalable and
massively concurrent application in our
line now most of us are aware how
efficient Erlang is in prototyping and
product development and the whisper
application is yet another testament to
that fact the application was created by
naka through use of Erlang in just three
months as with any live event please
excuse any technical issues that we may
face today but to start by telling you a
bit about airline solutions we are a
products and services orientated company
completely devoted to the airline
programming language since our founding
in 1999 we have worked with
organisations and individuals using
airline helping evolve the language and
supporting people and businesses using
it today we are just over 100 people
across our offices in London Stock own
crack OH Budapest Seattle and most
recently Buenos Aires and working on
projects across the globe we're really
keen on creating value and competitive
advantage for our customers across
industries and truly unique features and
characteristics of our land as a
language and we're equally ambitious in
developing your line based products and
you'll know that some of those include
the Mongoose IM messaging platform the
react distributed data store and our
wombat OA n monitoring and management
technology for our line systems as well
as other solutions applicable across
sectors and problem areas where lying
makes sense I'm very pleased to say that
our speaker today will be Chad depuis
the CTO and whisper and the founder of
ananka chart will elaborate on
whispers technical infrastructure and
the use of our line in building
massively concurrent highly available in
scalable applications now please allow
me to finish by saying you are very
welcome to post questions throughout the
duration of the webinar by using the
chat facility on the webinars interface
our speaker chad will answer as many
questions as time allows at the end of
the webinar but if any questions do go
unanswered you're welcome to raise them
via email using the following address
webinar at Erlang hyphen solutions com
if you're interested in learning more
about Erlang or wish to establish
whether it could be a solution for the
challenges your own business may be
facing by all means please feel free to
contact me directly my email address
will be displayed in one of the final
slides of the presentation we will share
with you today the same goes for any
other questions you may have feel free
to contact us I would now like to hand
over to Chad who will be glad to start
us off great thanks so much modern as
image and I'm Chad appeal of no sitio
whisper and founder Binaca which is
recently part of rolling solutions we
make n doing apps for startups and media
brands and we focus on high performance
apps a little bit like whisper so I
started knocking 2010 in its current
form with Martina Frears who's the CEO
of a knockin out um and we're a team of
30 working on into an applications
mostly iOS and Android apps both native
and HTML and um we do one thing that's
different which is most of our apps are
remote bootstrapped projects so the team
is typically remote we work with
founders often founders which are don't
have a technical background and we
really focus on high-performance apps on
iOS and Android and we really focus on
scalable server architectures and often
that involves early so as of August this
year were part of earling solutions and
we're super happy about that um and what
that really means is that instead of a
team of 30 we now have over a hundred
people that have a variety of skills
across
some bunch of different time zones so I
think the question is to start out as
what is whisper so when I think about a
way to describe whisper is it's a
anonymous social network it allows users
to talk about all the things that you
would typically not want to say on
facebook or twitter on it's very visual
and character limited I think the
easiest way to describe as a show a few
and actually it's funny this is a slide
from the original version of the app and
I'll show a slightly newer version but
um I thought it was interesting to show
sort of the way it's evolved so it's uh
essentially almost like a postcard and
was inspired to some extent by the by
post secret which was a anonymous art
project if you will where people could
mail postcards and they will be
published on the web so that was sort of
the spiritual of inspiration for a
whisper and whisper took off we launched
back in April 2012 and it really to go
from there so you can kind of see the
evolution of it the on the left is a the
old size thumbnail than the the right is
sort of the new newer more full size so
people talk about things they wouldn't
always talk about on facebook or twitter
or more public forum google+ forgot your
name associated with it but it's a
moderated in and curated place so that
it's a safe community and it's often
very confessional and people really find
that it's a safe place for them to talk
about things that you know maybe they
don't really want to have their name
associated with so it's a top-20 social
network I really can't talk much about
total number of users but I can say that
um you know we have many many millions
of users and billions and billions of
whisper views per month um so we're
talking about the story of whisper and
so this is going to be technical to some
extent and going to assume there's a bit
of knowledge about Erlang but i'm not
going to assume that you are sold on
using Erling for your project
so think of it as um I'm assuming you
don't have a lot of knowledge I'll talk
through some things I don't I won't
assume you'll understand everything but
I can maybe talk a bit above the level
of your early understanding that way you
can come back later and watch it and
sort of put the pieces together so um so
we're going to talk about sorry
Worcester and sort of five snapshots
we're going to cover the story of
whisper why we chose Erlang OTP why we
chose to how we use distributed Erlang
some of the tools that makes early and
great and in sort of a brief note on
training and hiring erling developers um
and is it from my perspective as
somebody who has built a consulting
company and somebody who is running a
technical team as well so so yeah so
let's go from there so um I think the
first part of this of the the story is
sort of like you know why did we use our
line versus something else so um just to
recap sort of what we did we started in
the beginning of 2012 we had to client
developers to server developers on we
went from end to end three months and
our founders are not what they would
consider technical co-founders in other
words they were not coming to the table
saying hey we're going to help code on
this project on they're expecting us to
take that piece of the of the puzzle and
eventually we built the app and hand it
off to a team at whisper which is you
know doing the day-to-day work now so on
the original app was ios-only you know
full of restful interfaces had a socket
for doing some background administration
tasks you know used upload images and
used Erlang and react and then
eventually switch to my sequel later
elasticsearch and cassandra has features
changed and is the app evolved so I
think the and this is not really too
early at all it's just sort of like what
made whisper work and I think this is
something that as a consultant building
apps I often people often ask me how do
I make it a successful app and I think
there are a couple of things that every
single app project must
must do i think the ones that i've seen
their successful always do these things
one is they pick a limited feature set
to start and this has nothing with
technology this is about the actual
thing you're building the next is they
do rapid experimentation in terms of
that feature set to get product market
fit the next is they have typically
focus on one device not to at the same
time because or one platform so they can
get those features right and figure that
out before they actually duplicate all
their mistakes on every platform they
don't spend a lot of time on settings
they just launched something that's sort
of you know designed for the user to
work in a certain way and they don't
give the user a lot of choice and it's
always built on a platform that can
scale quickly so that comes back to sort
of why we at we chose Erlang and you
know I'm going to walk you through our
thoughts at the time so I think at the
time I guess now I could give you a very
nuanced description in technical terms
of the Erlang vm and how / process
garbage collection works and how versus
the way the JVM does garbage collection
and I could talk about supervisors and I
can talk about all these sort of things
about erling that make it great on the
way multitasking model works and but the
thing is I realized that there are a lot
of talks on the webinars on YouTube and
on the Erlang solutions site they can
cover a lot of those details so I want
to talk a bit more about just sort of
our more high-level decision making
process really briefly so the first
question was why don't we use Java and I
think what we said was you know on when
I look at and I've done a lot of job
I've built a lot of projects in Java
over the years in Java things are often
more cumbersome server to server
communications are often more complex so
you have to use sockets you don't have a
lot of tools that you can use to make
that simple it's gotten easier with
things like acha but it's definitely not
something that out of the box gives you
a lot of those tools on clustering long
lines what you get an erlang is not
generally working without paying a lot
of money for a custom clustering
solution there's no rapel that allows
you to
um work in the shell during runtime and
javis very verbose and I've had a lot of
experiences where I was sort of burned
by java and I said you know I just want
to do this again so um I think we also
compared erling to Ruby and rails and we
said you know Ruby's great for web apps
it's there's some great features in
terms of rapidly prototyping in fact for
whisper we actually still use rails for
the backend admin tool because it's big
it's really nice to just rapidly develop
web UI for that uses you HTTP interface
into the early API um but it's a little
bit slow and it doesn't give you some of
the things that make early and grade in
terms of static analysis in terms of
some of the runtime tools and often gems
can be difficult in terms of code
management I think also we looked at
Python and node and go um we sort of
made a little chart at one point and
said okay you know and it didn't look
like this this is kind of my memory of
it but it's sort of like okay what do we
need we need if you nice to have a
ripple it'd be nice to have some of this
cost server communication we knew that
probably some of the databases we would
use potentially jabber for instance for
I am and then react we were poor in
Erlang's we thought there'd be some nice
interop there um and the one thing we
were like you know this is not great as
Erlang's sort of web story is not as
good you can do anything it's HTTP it
doesn't have the killer web framework
and so I'm at the time that was a
negative um I think the thing is though
we're very heavy volume messaging app we
felt we would be we would have API
endpoints for the clients iOS and
Android clients they would be
essentially I need some real time
moderation and some ability to delete
content via this background socket and
so it felt like erling was a good fit so
and I think that there's one little
detail that grid is a little bit
misleading because i think you know of
erling is this whole platform at OTP
giving all these services and I think
you know um maybe it's not misleading
but i think what
we looked at was you know I'm gonna have
to build some of this stuff from scratch
in go or node whereas a lot of this
stuff comes for free and early because
it's part of the platform so anyway
let's jump into the architecture of
whisper we're on Erlang 17 now I think
we launched on 14 it's a fairly typical
architecture for an erlang web api we
used we did not use cowboy we actually
use mochi web which is an erlang web
framework or web server um we use
Cassandra for a lot of our data store
now we use my sequel for some data as
well reddit's for some temporary caching
although over time it's slowly being
replaced because its most it's always a
single point of failure I mean we use a
lot of elastic search for searching so
originally launched you notice the
before we added a lot of those databases
we had a couple of H a proxy servers a
couple of my sequel servers summerling
servers and before we've done a lot of
optimization and then a bit of elastic
um at this point we have a lot of
servers and I think this is probably a
little bit behind on but you know we
have about 20 to 30 or linked servers
and a number of elastics and kassandra's
and Retta TSA's so um one thing is
really nice though is yeah I don't
really think a lot about the number of
servers we have in terms of you know I
mean we think about in terms of
efficiency we don't think about it in
terms of can we add more because the way
the system is set up OTP allows us to
scale in many ways horizontally because
we can just add more servers and we
don't really need to worry about where
processes are running so um you know
what I want to do is talk a bit about
what how does it do that and what are
the ways in which that becomes really
easy for us to build scalable systems
and so um you know data from those data
is this needs to get to those machines
somehow and so that will is really where
distributed earlene comes in and so I
want to talk a bit about you know where
we have a cluster of Erlang nodes and I
want to
you know make a quick statement now and
early we don't typically talk about
servers we talk about nodes so an early
node is an erlang vm running on a server
it could be running you could run
multiple nodes on one server you could
run one on one server um it kasoor
depends on your typical situation and
what your workload is some people like
to run more than one note on a server
some people don't sometimes it's better
sometimes it's not kind of depends but
it doesn't really matter for our
purposes so um let's take a quick
example of what it would look like to
build some of these cashing services
that we've built for whisper on top of
Erlang oh darling OTP so in whisper we
have sort of three main feats and we
have thousands of sub feeds so the and
whisper a main feed would be something
like popular fee to the latest feed on
there's a nearby as well which we'll
talk about separately in a minute and so
what we have with popular and latest are
these are feeds of whispers and we need
to be able to actually have those
available in any one of those numerous
Erlang servers right so you think about
it what will you do is we'd to build
some sort of layer that that actually
either retrieve that data from the
database every time which could be kind
of slow or we need to cash that on the
individual servers and so with popular
and latest you think about it it's sort
of a we have a lot of fees that are very
long tail so if I go and look at what
are the know people saying about um you
know any particular topic there could
only be a few people in that particular
topic but if I look at what people are
how many people are actually looking at
the latest feed or the popular feed
there could be a lot so um that's the
kind of feed you don't want to have to
go query from some database every time
it's going to be vastly too slow if
you're getting thousands of requests per
second so we use a gin server which is a
construct in early no TP that allows us
to
basically cash we can use it for
anything but in this case we're using it
to cache the data from the piper latest
feeds so in this case the things we want
to cache are a subset of the users the
hearts and the replies for these
whispers and so um what we want to do is
build a cache that that holds that data
locally and it broadcasts the other node
so in this case we use an LRU cache and
it uh it actually will keep the you know
the latest information in the cast and
it will purge out the stuff that becomes
older over time so for instance if
something becomes popular maybe it's
it's in the popular queue for a few
hours depending on whether it gets a lot
of up for a lot of hearts and then it'll
eventually fade out so but as something
becomes popular becomes puffer because
it's hearted and because it's replied to
and so as it happens we want to actually
broadcast that local new heart of that
local new reply to the other nodes so
each server is running a gen server and
we use this this some module and early
that's built in the platform called pg2
to get a list of the other servers the
other actual sorry the other processes
underlying that are running the same gin
server catch so what it allows us to do
it allows us to say ok I have a new
heart or a new reply I can go get the
all the other processes across all the
servers in my cluster that are also
serving up this cache data that can
broadcast to them so here's a quick code
sample so I'll say you know this is
actually not is like sort of pseudo code
version or simplified version what we're
doing I can say here's an lr you list
which we create with it holds a certain
number of cash items whenever I create
that I can join a group in PG two so pg2
allows us to to create groups of
processes and I can say okay well hey
you know this is a my cash group and say
hey Petey to join me under the cash
group name and put my
self and self is the process idea of my
of my own process and I can return in my
gen server some state which um you know
hangs onto my cash and so as I am
getting new events coming in I actually
get an update cash message that comes
into that gen server and I can actually
say um if I'm on the server where that
event occurs I can create the message I
go get all of the members in my group
and i use a list comprehension and I say
okay for although the actual members of
all the for all the processes that are
actually running caches send them that !
means send them a message send on the
message above which is this to pull
update cash I process I pass in my
process ID and I passion the data I want
to change so I say for all the processes
of my group send on this message but
don't send them the message if it's
myself so in other words I came in one
line say send this message to every
every server but don't send it to myself
so I don't have to worry about
infinitely recursing is i'm updating
myself over and over so literally what
would be hundreds and hundreds of lines
of retry code and logic and and you know
thinking through socket connection cases
and registries and all this of you to do
in java um you know or any any other
language doesn't have these constructs
is Lily one line of code this is the
kind of thing that as you build a bigger
system you just you you want to cry
tears of joy because it's one line of
code you can do so much so quickly so on
in practice with it or does that look
like a heart comes in to an early node
pg2 has the actual process ID on all the
other servers we write that to disk RDS
is like the my sequel database in this
case it at this point it might go to
some other databases to but gets written
to the database but it also updates the
other servers so think of it as almost
like a distributed right log if you will
um so that's that's how we handle the
the simple feeds I think as if you think
about some of the types of cashing in
this type of data access that we have we
think about nearby it's a little bit
different so um nearby you need to to
actually think about all the the
whispers and all the content that's in a
certain area you want to pull older
content from a certain area that has
less content you want to pull only the
very latest content for a very heavily
populated area on and so we actually
need to think of a slightly different
models so in this case erling is still
incredibly powerful because it allows us
to do some really interesting stuff
around caching as well so I picked a
random area in the u.s. I picked
Nashville Tennessee and I said okay you
know i'm going to walk through sort of
how we think about storing this data so
if you think we're actually cashing in
three dimensions you've got the the two
dimensions of the actual locations of
the content and then in the third
dimension is time so you want to
actually travel back in you want to
increase your range as you search for
whispers to show but you also want to
expand the time window because in some
cases maybe you don't have as many items
in a very rural area so you know these
these could be old on or you know
another area I don't have a pointer here
to show but like in a certain area you
might find lots is you don't actually
need to expand the radius as much so how
does erling help with this well just to
build this sort of tag model of the
world or we can actually tag these these
places with zip codes or census blocks
or we could use shapefiles to make very
specific geographies like say on campus
at a college or university so in this
case we we use on geo hashes and we
don't know if you're familiar with two
hashes but you can break the world into
these um base32 representation of a lat
long and it's a really simple way of
dividing up the club so I don't have to
go them to these tags um I use zip codes
in this case just to make it simple we
they become tags in the database um
they're stored in X which is the Erlang
term service which allows
to store on it's essentially a shared
database that's running on each Erlang
node and we store these in ads so I can
do something like when new whisper comes
in I can use another OTP construct
called gin event which is essentially a
very general and and easy-to-use means
of subscribing to a stream of events and
I can store new whisper to come in look
up there lat long do some fuzzy sort of
observation of the exact location and
then store in our location database so
as new whispers are coming in these are
streamed into these Erlang processes
which are essentially representing each
of these geographies so you think about
it imagine that you know on campus you
might have a few dozen of these
geographies all of which are interested
in this new piece of content so each one
of those has an actual erling process
thousands of which are all over the
world running on our servers each one of
which is listening for new events so
this concept of new contents coming in
and i can actually you know stream that
and actually listen and store that in
the proper Erling process and the proper
at stable for that geography it's
incredibly simple to do a very very
powerful sort of publish-subscribe
system that's allowing us to represent
the geography of the entire world and to
show whispers in that area so I can you
know say ok if someone says give me the
nearby for this area I figure out which
tags should actually show this
chills content I can go to those tags
and say hey okay do I have enough no
expand my radius get a few more results
and we sort of put a little bit of an
intentional randomness to it so it feels
fresh and different each time but we
also need to be deterministic about it
because we need to be able to page
through the results and so we can as we
expand out gravel these results that we
can actually render them and show them
to the
so um you know we used to have a do all
this actually just by hitting an elastic
search directly and we had a pretty
significant load issue I have an old
graph and I apologize for the lack of
units it um it doesn't really give you a
exact representation of the of the
difference but it was about a 5x drop
and so building this sort of nearby
caching system dropped our load by about
yeah by about five times maybe a little
bit more and the other thing is it made
it a lot more stable so the load is a
lot more consistent because we're
essentially listening to and handling
these events as they come in versus
doing a massive elastic search query
across the entire space of whispers on
every every request and I apologize for
the lack of units on minecraft so on
that was actually sort of version one of
our nearby cash um to go in a little bit
more detail we actually recently
switched to an archery model which
allows us to be a little bit more
granular about how we actually pull
those whispers in and so we've been some
interesting stuff from that and it's a
little bit I don't think it would really
fit to go into that for this talk but um
suffice it to say we've been iterating
on that as the product it's bigger and
um you know it's but this this model of
sort of run time using gen servers
broadcasting that across the nodes as
whispers come in listening to these
events as incredibly scalable and it's
very very powerful so um it also to be
quite we still use elastic search
because we read all that data n from
elastic when a server boots up so you
think about it I don't really want to be
in the in the business of rebuilding my
own elastic search the database it
doesn't really make sense at the same
time um you know elastic has great use
cases in terms of or it's very powerful
in terms of returning results for nearby
queries and for geo geo tagged and you
know data but it's we can do better than
elastic in terms of knowing our exact
use case and how we need to retrieve
from it so we use it as a primary store
on but we're
sitting to new data and we're pulling
that data into the cache as we start the
server so um yeah so I think you know as
after a region's running we need to
wreak weary so there's one more type of
caching I want to talk about and so this
is a little bit of a different model but
this is kind of a similar shows you
another way in which we use Erlang OTP
um we want to also cash whispers and
retrieve whispers based on how often
their access so we have these feeds of
whispers so something might be oscars
2014 or something like that that might
be a popular topic there definitely is a
use case for whisper where people use it
almost like a second screen app and
they're talking about something that's
happening in real time um so as whispers
are coming in on that topic we're going
to see a lot of people searching on that
query and again that's going to go into
elasticsearch or it's going to go into
Cassandra to go pull off of a particular
topic that we've fanned out our whispers
into and so what we wanted to do is
build a generic system at the end of the
day I think we have about 15 different
types of data that we want to cash in
some way so we want to build a system
that allows us to generically cash but
we want it to detect when we need it so
I don't want to I don't want to catch
every piece of data I've got almost a
billion whispers and all this amount of
you know this mass amount of data how do
I actually um you know distribute this
cash but how do I not load everything I
need so if it is this cash called
fireman which I guess some of an inside
joke puts out fires and fireman allows
us to implement a behavior which is a
little bit like an interface and in
other languages but it allows us to
build an early model that says I've
implemented this behavior and I with
that module if I'm going up behavior
then fireman can expect that this module
will respond to certain method calls so
I can implement behavior and I can
create a anything that can return a
paged query can be cached so that allows
us to not only think about cashing any
more in terms of like
what I'm you know how it actually is
happening internally and how it's being
moved around it allows us to focus our
testing and our reliability around
getting this one cash system really
really solid so there's sort of a two
modes to it one is a manual or and
automated one's mental ones automated so
um in the mail mode I can say hey
fireman activate and for example we have
a cash around related feet so I can go
into the app and I can if I create a
whisper it'll actually say oh you know
this is that's you know thanks for
whisper here's some other words was that
are kind of like this one and um
depending on the on the whisper
depending on the subject that could be
expensive so in other words if
everyone's talking about a current event
that might be the kind of query that we
want to cash so um you could say hey I
want to cash this ah here is you know
the ID of the feed I want to cash here's
how long the duration is a constant that
we can set and then you can say true or
false whether you want to broadcast that
to all your notes so just one line of
code boom you're you're you know you're
returning this cash across the entire
system um there's another way to do it
which is essentially I can say hey
fireman just give me this data here's
the module here's the key I want here's
the page I'm on here's how many I want
to return so this is like more of a
read-through model where fireman will
actually say okay great I'll go get this
data but when it does it it actually
keeps track of the actual amount of time
that we or sorry the number of accesses
per second there being that are being
requested for that exact cash key so I'm
going to walk you this code really quick
so we say um an debts we do Nets look up
and says hey do we have for this table
which is the name of this cash for this
key do we have anything in here and if
it doesn't have anything it'll just
insert a new key that says okay this is
my first request starting now I cut out
the top and the bottom of this code or
the top of this coat it's a couple of
these variables were defined above it
but it wasn't quite room but now just a
current time the tid is the name of the
ettes table in this case it would be
like friends with related it would be
the fireman cash for related
and then if we do have something we get
back a a tuple that's the key the
average and in the count and then the
last time we access that so then we
recalculate the accesses per second and
then we re restore based on that on that
cash key without you back in Ed's now
elsewhere when we do that we can say our
access per second high enough that we
should actually flip on cache mode or
should we leave it off so in this case
you can essentially think of anything I
can fetch from the entire system and
pretty much everything in whisper is a
feed of whispers I can just use a couple
of lines of code I can say fireman fetch
and underneath it it's actually going to
flip on a caching mode and broadcast
that cash to everyone as needed so
there's a couple of things you know down
the road that we're going to add we'd
love to do more time series analysis
right now it's very basic how we decide
to cash currently once we catch
something we never stop cashing it on
which we know how to do we just haven't
done it and that's not a huge issue
because you know we're constantly doing
deploys and we it you know caches get
flushed sort of as the result of doing
business but it'd be nice to not have to
think about that and then um you know
we'd also love to change refresh
interval so once caching comes on we
essentially rerun that query every X
seconds based on configurable settings
so we might say hey you know there are
less there's a lot of traffic this we
should be refreshing that every second
versus others not a lot we should
refresh it less often so um summary
there's sort of three types of caches in
our architecture and these are three
different ways of thinking about
distributing data in Erlang and and then
thinking about the way in which you know
communicate across the network so the
three ways are by popularity by the
location and by request volume and all
three use ettes and they use a judicious
amount of broadcasts because I you know
cross no communication is so easy
distributed caching is very very easy
now one thing I'm going to have a couple
caveat
here and this is I'm going off off grid
I don't have a slide for this um with
amazon so most of our stuff is hosted at
amazon we definitely have found you know
we learn some tips and tricks and we're
going to publish this soon on on
probably the whisper blog but I think it
could also be a good anaka blog article
as well so we'll figure out where we
publish this but it's a at least we'll
link to it so a lot of the issues we've
had around using Amazon with Erlang are
around the fact that the network is not
as reliable on amazon as we would like
it to be so um definitely with a number
of servers you start to see things where
maybe a server disappears for a few
seconds and it comes back maybe you lose
some some packets and what we found is
we actually use this very special mode
of broadcast called sin no suspend
whenever we broadcast on in and using
Erlang's so if we say hey ghost in this
message to another erling node we always
say send it but don't wait for a
response and the reason why we do that
is um if you are in your own network and
you're on your own dedicated Nick and
you have maybe you know an outbound Nick
for the web traffic you have an internal
network interface for the rest of the
servers to communicate on their own
backbone that ah you can cut it you can
sort of have a bit more assurance in
actually finish you shouldn't have more
assurance but you you can get away with
assuming that the network's a bit more
reliable amazon is definitely a
difficult environment when you have a
lot of Erlang notes and so once we found
that out we've made it a lot you know
like using send no suspend it solved a
lot of our sort of difficult issues
around you know amazon network
instability so so there we go on I think
you know that's a good example of some
of the tools we use I'm going to talk
very very briefly about some of the
runtime tools we use and then I'm going
to talk about hiring we're going to wrap
up so I don't have time for questions so
runtime tools I think you know this is
not a confession this is like
statement i'm a bit proud of we've never
used the early debugger you just don't
need it you can trace you can look at
call stacks you can look at crash dumps
and with some really nice tools and you
can just hop on the server in production
and check things out in real time you
don't really need to debug and I think
that's you know i remember at microsoft
one time we had a problem with a
production system and we you know just
literally hooked up visual c to the
runtime the 11 time web server or one of
the servers and just started stepping
through the debugger and you know real
time to figure out what's going on and
you know I remember thinking I never
want to do that again you know so one of
the things i like is we don't have to do
it early a lot of tools um so of those
tools what are the indispensable ones i
think ever is a set of tools that we use
that give us some real interesting stuff
it gives us things like d top which
allows us to almost like a top-four
Erlang this is like a sort of Erlang run
time debugging for for dummies it's go
and start with I think one it's
incredibly powerful is red bug which is
just a simple wrapper around the built
in tracing API is that are in the actual
run time so i can say a red book start i
can give it a process like a gin server
i can give it a module function and a
set in an era tea or set of arguments
and it'll actually returned to me on the
console every single message going into
or out of that process so if i'm like
why is this you know jens over acting
weird what's making it crash i can flip
that on have it run for 500 messages or
10 seconds and it'll just dump to the
console that you know set of messages
and its really really powerful um in an
observer which is a tool built into
Erlang I've never we never uses in
production but it's nice when you're you
know building a system it gives you a
visual view of your supervisors and it's
very very powerful and then really the
the most important tool is the ability
to connect to a Erlang remote shell so
we have a command I can just type amazon
attached and give it a server from my
desktop and assuming i am VPN and
everything
boom i'm actually on that erling note i
can start looking around i can do any to
do to figure out how to debug a system
and that's incredibly incredibly
powerful it allows us to look at things
in real time and I don't need to go add
some logs deploy something check out I
can just go in there run time and do it
um so and then lastly I think you know I
want to talk a bit about hiring and
training so on one of the concerns that
people always have only talked to me
about Erlang and I think it's a
legitimate concern is hiring and
training so if you think about it out
there um you know they're there are a
lot of people that know how to do some
Ruby and rails out there a lot of Python
developers out there on there a ton of
Java developers out there there aren't
as many rolling developers in its
growing but I saw this slide deck
recently on Korra or a slide and that's
on the deck in it um they're talking
this concept of you know a little bit of
slope makes up for a lot of y intercept
and so the the whole idea was um and
really anything if you you know have
something good and you have some time
you know if you hire for a particular
set of skills like you can go find the
best java developer out there and you
know great they come in on day one they
have x skills um that's great but if the
rate at which they learn is a bit slow
well over time they're actually going to
be far below somebody who had less
skills coming in but just knows how to
learn and so I think you know if you're
taking this approach to hiring it really
doesn't matter what language you hand
them and ironically Erling is such a
simple language that you can pick it up
very very quickly excuse me so um now I
can hire that java developer with skills
in X or I can hire any developer and
teach them skill why and so that's my
philosophy always with hiring and always
so people just don't be afraid to dive
in so you can just you know jump in and
figure it out whisper for instance on
has a number of developers and no a new
developer comes in in two weeks they're
productive and writing airline code and
getting stuff done um there are ton of
resources online on learning some Erlang
youtube videos erling factory videos and
compras themselves and it's really quite
easy to just dive in so um that's you
know pretty much it for the overview I
want to do a quick conclusions um you
know um you know there are a couple of
things that are improving in Erlang that
I didn't talk about but I'm really
excited about maps have been introduced
which cleans up some of the the legacy
records syntax to some extent especially
with newer code and also frankly as I
just mentioned that as erling becomes
more popular on incomes were mainstream
it just seems easier to jump in so you
go on hacker news and there's like a
bunch of erling articles you know today
on in fact um Fred Hebert released a
amazing book on Erlang runtime debugging
and it's actually think about like an
advanced course on what I'm talking
about with pepper and and read books so
he's got a ton of tools that weaves a
lot of those tools to debug runtime
systems that'sthat's on hacker news you
know for last 24 hours it's been on the
front page so I think erling is becoming
much more mainstream and it seems easier
to easier to dive in um other things
that are great about Erlang is OTP just
force you to make rational decisions
about your architecture supervisors help
you build a system that can survive
chaos and crashes um hot-swappable code
which we use in I didn't get a chance to
talk about but in our and some of our
uploader systems which allow us to make
change to code where the system never
goes down attaching to knows as I
mentioned on the broadcasting facilities
and then and lastly the Erlang community
so you know um quick mention of elixir
as well the you know elixir is
definitely bringing a bigger community
in and you know the conference are
growing lots of big companies using it
and people are published a lot of
content so bottom line is that with ur
languish / is able to move fast and
scale and I think that's really what
anybody wants from any platform so um
we're very happy with the decision and
how it's gotten us to this point so
that's pretty much it I'm going to leave
it open for questions and we can go from
there
thank you very much ad and I'm sure that
all the attendees of the webinar will
join me in saying thank you in fact
we've gotten a lot of messages that are
sort of really just saying thanks for a
great talk so thank you for that again
and like I said at the beginning of the
issue that we have is obviously that the
webinar is time constrained and there's
always a number of questions coming in
so we will try and answer as many as we
can so the first question for you Chad
comes from Julius and Julius is asking
have you considered PHP when building
whisper yes I can you repeat the
question one more time so Julius is
asking have you considered PHP when you
started and when you were sort of
building whisper as a no oh yeah sure so
no I mean I think I know PHP actually
you know it's look it's a it's a
obviously really you know robust system
and you can do a lot with it and people
have built amazing things with it um I
use it a lot in the past um we didn't I
think partially to be honest I there's a
bit of a stigma when I when I do hiring
to say hey we're a PHP shop I think
that's not a selling point I'm one of
the things i think has been great um
about Ruby for instance is I think
people look at some of the pain of Java
and the configurations and all the stuff
you have to do in all the book actual
code you have to write and it's tiring
and so Ruby is like I think an answer to
that to some extent which is hey look
convention over configuration on rails
at least and and write less code and I
think erling in some ways is a similar
answer to it um I think there's some
boilerplate with Erlang but I think
relative to the amount of code you'd
have to write to build distributed
systems the bordeaux plate is quite
small and so i think um you know I guess
maybe as I've gone through my career as
it goes on i want to write as little
code as possible um and so I think we
didn't look at it super closely thanks
Jonathan that's that's a great answer
now i'm a bit of a fan of react myself
so if you don't mind on string this
particular question one of the members
of our audience is asking what was the
deciding factor for you to sort of blues
react in favor of Cassandra / elastic
yeah um so I think like it's a great
question and I think you know my opinion
of rick has really evolved over the last
couple years i think when we actually
started with react we just embraced it
too early um i think it wasn't quite
ready for what we didn't for what we
wanted to do with it um and I think we
weren't using it the right way so um for
instance I think if we had gone back and
use react now the way we're using
Cassandra it'd be fine with Cassandra
we're doing fan out so of all the
queries we need and just duplicating
data in order to make sure that the
runtime performance on Reed's is really
really good um and I think it's pretty
similar to the way other folks are using
Cassandra um I think with react we were
thinking hey we'll do a lot of map
reduces and secondary indexes across a
large set of data and it was just we
weren't looking at the right way and I
think it was a lesson learned um I think
it it really you know it teaches a
lesson because you need to make sure
you're you're writing data to the
database you pick one right way so i
think yeah reacts great i think it's
great for a ton of use cases um but you
know at this point we sort of already
switched that makes that so thank you
for that John are we just a sort of
continue on all that node we have a very
interesting question from the react side
of the fence and one of the members of
the audience asking have you tried the
new reactor cuanto which has in fact
been released two days ago uh well not
in the last two days but I've played on
with react a lot in last year so um no
it's got some amazing stuff and I think
I'm the a lot of those guys are friends
of mine at a show and so I have I feel
like it's become a really robust
database and so ironically i still
recommend it I think um what I fully
found with whisper was we really just
need a lot of different databases for a
lot of different needs we use um you
know elastic for search capabilities we
use a key value store for what we need a
key values
for we use we still use my sequel
because it's great for a lot of
administrative stuff that's not getting
a lot of traffic it's just simple to get
stuff done in um and so you know just
pick the right tool and I think what we
realized is there's a point where when
you're starting out you just want one
database you don't want to deal with all
the hassle of all these different
databases there's a point we get big
enough we're adding one more isn't that
much of an operational hassle relative
for all the other operational assholes
you have so um you pick the right tool
for the job thank you for commenting on
that Chad and the problem we're having
is gonna be receiving more questions
than we can answer and they're actually
piling up we'll try and the owner as
many queries as we can in the remaining
time one question for you vassilis is
asking in regards to the pg to topic
that you talked about and regarding the
update cash process is there time needed
to synchronize or update the cache or
does this happen in real time when
needed to be served by the second node
that's a great question so um it's all
happening in real time are we don't wait
for it to be updated in and so they're
obviously could be in you know
inconsistencies um I think for the type
of application we have it doesn't really
matter so for instance there are ways to
minimize that you can turn on sticky
sessions and make sure that in general a
user that comes into the system is going
to stay on the same server so their view
of the world is there's a bit of like
relativity to it but their view of the
world is going to be consistent with
what they see and so if it's a second
later or whatever it doesn't really
matter um yeah so that's sort of you
know we take a very loose approach to
replication in that sense because
there's not a huge cost if it was
financial data you might want to think
differently about how you're cashing it
but I think in this case it's okay thank
you for that another question is
basically asking you know in the whisper
application is it true that our line is
used for distributed caching only and
why don't you use a generic cache server
instead um well that's a good question i
think you know our particular needs have
evolved over time and so we've sort of
you developed
the caches that we needed as the service
has evolved there's a couple of things
that I didn't go into in terms of of why
we want to have caches for server um you
know it's the the way that we actually
move things around and we in our popular
feeds is depending on a sort of
algorithm that updates the relative
position based on a bunch of factors and
there's some business logic there that
it's easier if that's being done on all
the individual servers than it is if we
have one master doing that and we're
kind of hoping that things running and
you know kind of updating it for
everybody we have it just sort of done
in in place um one of the sort of design
philosophies of Erlang is um if there's
a way to paralyze something it's
generally better because if that one
thing breaks it doesn't affect anyone
else and so um actually doing it this
way makes it very very robust so if you
imagine let's say we have one process
doing the position changes of our
popular feed and that dies now no one's
seeing an updated feed until we figure
out what's going on whereas if there's a
bug in some little area of you know our
popular algorithm that's only going to
affect the person that it crashed on so
that's that's sort of a fundamental
Erlang philosophy that it helps youth
frame problems differently and so that's
probably um you know the best simple
reason why we did that way Thank You
Chad not just to say to be receiving
questions faster than we're answering
them so what I'd like to say to everyone
in the audience is that we will pass all
your questions to chat and we'll ask me
to answer them and obviously then send
the answers to the person's asking a
question so just to sort of removal and
an answer as many questions as we can
into remaining couple of minutes Chad
how did you come to the decision and why
did you use ETS instead of simple DB for
caching um that's a good question um I
think you know that the one thing a bit
about ads that I like so much is just
how insanely fast it
is um we did a little Erlang la meet up
last week or two weeks ago and we all
talked about our configuration
management tools do we use and you know
we use a net stable to cash all of our
configuration changes that are in there
configures in this sword and zookeeper
and the runtime performance is just
insane it's so fast and so you know I
think at the time it felt like that was
a really nice solution because it's just
incredibly fast to read from at so once
you've updated that little in-memory
cache I can you know blaze out a Jason
response on our mochi web to that you
know it's just it's just fast and
reliable and so I don't know we didn't
really look at simple DB so yeah thanks
for that there's an observation that's
coming from one of our audience unis
unis is basically saying in one of your
slides you mentioned you know the call
ETS look up / 2 and he's basically
saying that this particular call can be
very problematic unless it's used
synchronously but if that's the case if
you're using it synchronously you're
losing ets concurrency would you share
any views on that observation um you
know what I that's a really good point I
actually think that we might have
changed that since this slide was
updated in other words i can actually
look at the code and get back to you so
um I feel like we're using fun too we're
doing a fun to ms query now we're
generating a a match spec and we're
running that so I think we've actually
changed that query so the you know
conceptually the code that i showed is
it makes sense but i think the actual
code we're using in terms of performance
is a little bit different so that's a
very astute observation thanks for the
child given the time remaining will try
and answer to to bring more questions
max so just quickly to sort of go
through these particular questions
here's one that I'm fond of myself
because in our line solutions were big
fans of elixir so one of our audience
are asking do you think that you will
use a lixia for the
velopment partly or fully going forward
yeah so a great question in fact we're
using it a lot we have built a lot of
ancillary services in elixir it's they
for instance we have a very very large
xml sitemap for all the content that we
have that we've created in the last
couple years so the system that bills
that is an elixir um we also have a
runtime like a real-time statistics
platform that's similar to something
like Google Analytics or mixpanel and
that is all written in elixir and
handles literally billions of events a
day and so we're very very happy the liq
sir i would say um I don't think illness
they replace all of our line cooks but I
think that it's um it's going to have a
place in the in the system for sure
fantastic thank you chad not just one
further question I'd like you to answer
one of our audience are asking did you
consider an architecture using something
like rabbitmq as the message queue yeah
so um that's a good question I think um
we actually do use rabbit for a couple
of things that are a little bit less
real time so some push notifications are
queued up in rabbit on we have a a sort
of background process system that we we
sort of built an erlang version of
rescue which is the the github created
framework in Ruby and that currently is
using rattusses its back end and that's
why we have radisson the platform for
the most part and we're going to replace
that with rabbit so we do like rabbit um
I think the volume of updates I'm sure
rabbit could handle it but I think sort
of the way I really feel like it would
be a bit of a hassle to go through
but when you've already got this
clustered set of Erlang servers so yeah
I think that makes perfect sense no
charge given that we have about a minute
or two left I'd like to ask you one
final question which i think is the
perfect question to finish with how do
you see whisper evolving and how do you
see your use of our line evolving you
know in the future it's a great question
I mean I think um you know we definitely
are not a religious about Erlang we're
using a lot of Python for data science
and I think that will continue I see
erling is glue for us I see us using lik
certain places a lot of Python for
analysis um I see I mean I think we're
trying to keep core api's you know in
either early elixir just because we know
how to maintain and support those um but
I think you know um as the platform
involves for instance we're releasing a
dev API and there's it's in limited beta
right now but it's going to be out soon
and um that's in Britain elixir and I
think so you know we're sort of saying
hey let's try elixir for this this could
be a good fit so it's you know easy to
prototype etc so i think it'll always be
core but i think you know if we say hey
we need to do some some data science
will use we might use python for that
I'm tastic Thank You Chad and as we like
to say you know use the best tool for
the job so Chad I'd like to thank you
for a very inspiring talk about the
Whisperer application I'm sure our
audience will join me in death many
thanks to all of you who have joined us
for the webinar I just like to thank
everyone for all the questions you've
sent and we promise to answer all of
them following the webinar itself is
just a time sort of role model run out
on us on this particular occasion now
please join us again for our next
monthly webinar in October and following
today we will be sending you a short
survey to make sure that we capture your
feedback of today's webinar please also
note that the recording of the webinar
and the presentation that will share
today will also be available for you to
collect on airline solutions
corporate website at WWF and solutions
com Thank You Chad thank you everyone
and thank you once again and we look
forward to seeing you on our next web
thanks might appreciate it</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>