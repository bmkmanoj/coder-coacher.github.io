<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory SF 2015 - Lukas Larsson - BEAM - 'The Times They Are A-Changing' | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory SF 2015 - Lukas Larsson - BEAM - 'The Times They Are A-Changing' - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang Factory SF 2015 - Lukas Larsson - BEAM - 'The Times They Are A-Changing'</b></h2><h5 class="post__date">2015-03-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gfsc2MyP8p8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">first of all I want to apologize in the
beginning for the bad puns in my slides
so it'll be happening when you're
working with time stuff it's hard to not
make parallels to things and so on and
also as I know when I go on these talks
after about 20 minutes I start to drop
off so I'm going to start with telling
you the important bits and then you can
drop off if you want to and we get into
the gory details so what's happening
what I'm going to talk about is the time
changes that are coming in the 18th of 0
release of the a-line distribution we've
been working on this for about six
months now I think the revision of the
API CC is probably the sixth seventh
revision or something like that it
doesn't look anything like the previous
traditions at all we're quite happy with
the way it is so what we're doing is
that we're deprecating the Erlang now
function because the way that is this
design is a catastrophe in scalability
concerns and was never possible to make
the same functionality and make it work
so we're eventually hoping to remove
that completely instead we're
introducing Alan monotonic time and Alan
system x which are primitives we need to
fetch time from the virtual machine
monotonic time is a time from some point
in the future that just progresses
monotonically it doesn't jump anywhere
and system time is a time that's fairly
close to POSIX time the way we see it's
a UTC at the moment we've added time
work modes which is a way to handle
backward compatibility for us so that
you can run your application either in
saying no time warps or a single time
warp or multiple time warps the
preferred method is to do run multiple
time warps but almost all applications
will break if they start running with
that at the moment so the backwards
compatible and the default way will be
no time warps as part of this we've
implemented scalable timers which we
will think was created very nicely but
it's not a scalable as we would like it
yet and by 18 I don't think we have the
perfect solution yet we'll continue
working on that but at least now we have
the api's to support us to do the things
we want we've also implemented as a side
effect of this lock three references so
that we can create parallel references
so many we want and that solution is
completely permanent
block free at the moment which is really
nice so that's the summary of the talk
so now we go into the gory details i
want to start first giving a talk a bit
about time and what that is so if you
look at wikipedia you can see some quote
saying that time is what keep is what to
make sure that everything is not
happening at once or time is what clocks
measures which is totally innocent
doesn't make any sense at all and
doesn't isn't helpful at all luckily for
this talk i'm going to focus on time
measurement and the way that works are
not actually what time is there so we
have this time that's called UT one and
this was it's been used to 0 UT two and
different things so universal time and
that's based around how the earth
rotates around its own axis and make
sure that the Sun in Greenwich in
England is just about your head when
you're at the right place unfortunately
due to tidal stresses and the way that
Sun revolves and solar flares and
whatever that's not really a precise
unit of measurement when you want to do
measurement of time it kind of varies
depending on the seasons and so on our
fastest works so we have something
called you to see which is an acronym
that doesn't mean anything its a mix
between a British an English acronym and
a French acronym and both of them don't
translate to that specific name and it's
based on the standard Institute second
so the atoms decaying and how long time
that takes and obviously these two don't
match so that's why we have things like
leap seconds being introduced into UTC
so the next one is gonna happen in June
and then that specific our there is
going to have one more second so take
care to use that second wisely as it
doesn't happen that often and it's
impossible to predict when this will
happen because it depends on earthquakes
and tornadoes and huge storm events on
the earth and so on so you don't know
when they happen so far it's always been
increases in times of the added seconds
but there it is the possibility to
remove seconds as well in the standard
and then we have what we normally work
with in computers post six times which
is kind of like you to see time as its
Bay
is in UTC but every day is always a
specific amount of seconds so they don't
have leap seconds in POSIX they just
repeat the same second twice or they
remove one second when these keep
seconds happen so there's a lot of
different ways to do time measurement
and when you try to communicate in
between different worlds depending on if
you're an astrophysicist or if you're a
computer science guy you talk about time
in different ways the airline so getting
closer to the subject matter the way
that time has managed in the aisle on
button machine throughout time has
varied the first version of it just used
what the Linux permitting world is
hilarious at that time I would imagine
may get time of day which jumps a lot
when this when ntp comes in and tries to
adjust it runs longley the system
administrator for some reason things
that it's a good idea to change the time
on your computer all of these things
happen to you and it's become quite
annoying so in I don't know when at some
point we added something called like
that I would like to call anyway Alan
corrected time which is what we're using
at the moment so what this does is that
it uses the oldest monotonic clock which
is kind of correct but it not as quick
as you don't like and then from that it
tries to extrapolate and try to adjust
according to what the get time of day so
the current post six time of the system
looks like it is a very useful
extracting in that it's almost always
correct the correct way to do things
there's this almost thing that's a
problem and it's also problem in a
scalability concern doing this because
you always have to sync the virtual
machines a view of time so so the
different ways that we can get time
today is that we can they get until
Justin we get the same vernacular and
talking so we have the OS system time
which is your operating systems times of
whole sixth time where the u.s.
monotonic time which is a system clock
that's on the normally on some computers
anyway it measures the CPU cycles could
be the monotonic time for instance
and we have the Allen corrected time and
now that we have the introduction we get
a summary of what I'm going to talk
about so we have a brief history of time
we're going to go through how time works
today in the air language machine how it
will work in the future we're going to
look at timers are they work today and
how they're going to work in the future
so some of the properties that are nice
about the current Allen corrected time
is that it never jumped backwards or
forwards this always progresses forward
at the steady pace it never differs in
speed by more than one percent of the OS
monotonic clock so it always is either
one percent slower one percent faster
than the OS monotonic clock and it
attempts to be as close as possible to
the OS system time so post six time now
there's a in the basic algorithm to
figure this out is something you're
recording of these lines will get them
on at any time and if it's time to set
check sync we'd get the time of day
which is done about every second we
check that and then we either increase
the speed decrease the speed or start
using the same speed again if it's if we
caught up the basic problem with this
model is that what if system time jumps
very far so in our embedded devices some
of them that are pressed in the factory
they start with 1970 and then they get
ntp contact when the alembic machine has
been up and running for a while so it
takes quite a while for the a language
machine to recover and it's quite and
during this time unfortunately since we
when you call a line now for instance
you will read this kind of time so you
will see 19-7 even though your post six
times C says something like 2015 your
airline now will say 1971 1972 and so on
for until you catch up which is sometime
in the future when your software might
be running or not but this also that's
kind of a problem but the real issues
when you come to relative time so when
you're setting timers so when you have
external protocols that are trying to
work with this so if you for instance
there
doing sipped transformations then you
have time out saying okay after 1 1
minute I need to do a retransmission of
this protocol and then after five
minutes I need to do a reset up and
whatnot if you loose connections and
that time then it's one percent shorter
on all of these machines that are
running this and this is a real issue
when we're working with these things so
that's not good and that's one of the
problems that we set out to solve when
we did this thing's this this is
actually a initial problem that
triggered the entire rewrite and then
all of the parallel is and things just
were happen to pile on as we wanted to
make a good baby i for all of it and
getting to a line now and the reasons
why we remove that is because of the
things that you get out of our line now
at the moment you get you get a unique
value that's always increasing and it's
kind of posting time so it's kind of
close to POSIX time and because of these
different things many users have been
working forced to use like oh it's time
stamp instead to get the current
operating systems view of time and so
it's a terrible broken piece of things
and we've been wondering a long time how
to change it so how did we change it so
we're introducing something that's
called the Alan monotonic time so we're
getting a rid of Alan corrected time
kind of and we're introducing something
that's called the Alan monotonic time
the element of turning time is very very
similar to the way that the OS monotonic
time works the only difference is that
it's corrected by MTP so if you have
some kind of hardware where the internal
clock is not very synced with a real
time works the Allen monotonic time will
try to sync up with that and the
resolution and accuracy of the Alamo
know time is very system specific you
will see huge differences in different
systems depending in this time and they
will there are quite some API is to work
with them and we have also introduced
something that we call a length system
time
which then isn't a posix approximation
of what time is and that this time is
based off the island monotonic time and
we have a offset that you add to it so
that you can say that okay you take the
monotonic time and you add a time offset
to it and then you get the system time
at the moment now this time of that can
change or it cannot change depending on
how you configure your system so just a
basic look at the API so we have a line
kaalam monotonic time like this we it
returns an integer for you and it's some
time value from some point in the past
or a future and we measure from we have
a new API also called a long time offset
the returns an integer so you add these
two to get some kind of the Erlang
system time and if you want to so this
time offset and a monotonic time as in
as you might notice it says that it
resewn in native time units which is a
nanoseconds microseconds it might be CPU
cycles for instance on Windows its CPU
cycles so if you have a 4.9 gigahertz
something it's the amount of CPU cycles
it's very different difficult to get an
actual value out of it on Linux it's a
nano seconds on OSX it's microseconds
and lots of different variants so you
use this function to convert the time so
you get the monotonic time and then you
send in time from unit 2 units because
they native to I don't microseconds and
you get in a microsecond resolution in
there the reason why we don't give you a
standardized value from the beginning
because we can't really know which
resolution you want to have or which is
expected of us and we wanted to build an
API that didn't limit us we had a lot of
thoughts saying that okay so a
nanosecond should be all right but what
if the computers in future needs
picoseconds to work with the resolution
so we wanted to design something that
would be future proof and this is what
we came up with them
there's also a convenience API for a
long system time which is basically just
calling together monotonic time and time
offsets so using these on my Mac here we
get along monotonic time you get some
kind of value up there and you get in
time offset of 0 and you add them up and
you obviously get the same thing and you
convert from native two microseconds and
we can see there that they actually the
native unit on my Mac was microseconds
so quite convenient there and then you
can convert it to your normal now to
pull if you want to and then use
character now to local time and you can
see the time when I wrote my slides on
my linux ubuntu machine it returns
negative something huge this monotonic
time and then we have a time offset that
sets it correct again and we add it up
and we get this figure that's kind of
the same the reason for the difference
here is that we want to have a
predictability in the timing api's in
the amount of data they build on the
heap as they are executed before it's
always been when you call our line now
you get the three tuple with two with
three small integers in them so you will
always build three words of heap data we
want to keep it predictable so that
after 20 years all of a sudden you don't
start to create twice as much garbage on
the heap if you're using these api is as
much as possible so by placing this
point of monotonic time in the future we
can make sure that for if your system
runs for or is it 256 years then we
start building big nums before that we
always use smalls on this linux machine
while on the mac that used microseconds
that doesn't happen as often because
this is nano seconds then we can use a
more human readable way of working with
it so it all depends on how long you
system are going to be up and running so
predictability is very important and
then you convert it from native two
microseconds and we get we cut out the
bus zeros and so
so and this also has the nice effect of
making sure and since it's quite to
quite common operating systems it really
makes sure that you use the api's
correctly and don't take any shortcuts
with using them so the different time
units that you can use to send into this
conversion API seconds milliseconds
microseconds and you can give a
arbitrary integer so if you want to have
it in the thousand 124 resolution you
can give thousand at 24 and it will give
whatever binary unit of time that you
want to have it in there's a bunch of
convenience functions that you can use
like monotonic time time of it and
system time all take a second argument
that might be that's the unit that you
want to return so if you say monotonic
time microseconds it will return
microseconds for you but know that this
is a more expensive operation and might
build more things on the heap and so on
so the basic API so therefore
performance and then you can use these
ones for convenience there's also an ad
long time stamp that gives you the
familiar three tuple of time for you to
use in all the API so you don't have to
rewrite your code we're also adding a
system time that returns this integer
rather than returning the three triple
from the OS module if you want to get
the OS Poohsticks time at the moment
okay so we were talking about now now we
were talking both about time and about
the new uniqueness and the monotonic
increasing values so we would didn't
want to create a new API where we had to
bundle all that information together
again so we've created a new function so
a long time stamp is of course what you
use to get the 32 bit of time as similar
to me now as possible now we have a new
API called a line unique integer which
you can give a list of arguments saying
either positive monotonic or both and
you give it an onion you get a integer
value and depending on your needs you
will use different variants early if you
want to have a monotonically increasing
in the system that requires a global
look if you don't need a monotonically
increasing value just
a unique integer for some reason then
you can just skip the parameters and
then you will get a integer that doesn't
it's not locked so you can it's
generated on a per scheduler basis so
you don't need any looking at all to
generate that so take care when you use
these things and work with them when
we're talking about uniqueness there's
another data type that comes to mind and
that's the reference you might wonder
why don't we use the reference to do
these things rather than using the
integer there it seemed we don't use it
for two reasons the first reason is that
we want to be able to write these things
to a file and then read them back up
again doing it right thing something
like in an online term format I'm doing
five consultant and having references in
there it's not very a very good idea so
you wanted to have integers in there and
we found places in the OTP code
specifically where we wanted to have
this behavior in order to be backwards
compatible in the way that we were using
line now at the moment and one other
thing to remember is that references are
only guarantee uniqueness they do not
guarantee any order at the moment in the
current virtual machine they do
guarantee order but in eighteen they
will not anymore so you will only
guarantee uniqueness at that point I'll
get back to that a bit more later on so
if you're reading the documentation of
how this works there's quite a big
section about time work modes and the
time work modes is an unfortunate side
effect of that we need to be backwards
compatible with these changes we've been
thinking a lot about how to make that
possible and how to make systems that
all systems that have been running
forever be able to use on you api's to
get scalable time without having to
rewrite large amounts of their code and
so what we come up with is this what we
call time warp mode so it's different
ways that you want time to warp
in your emulator as you run them and the
time warp mode control the way that a
long time time offset behaves and also
the way that a leg monotonic Klein
behaved so and specifically it happens
it changes the behavior of when you're
posting time jumps for and before I
think it's more than five milliseconds
so if it jumps by more than five
milliseconds that's a far jump and if it
jumps less it's a small jump and then we
just adjust time a little bit so
starting with the first mode which is
the default mode and it's the backwards
compatible mode so in here we have time
offset it remains constant it will never
change you don't get any time jumps just
as it works a day and we have the Ala
Moana tonic time work is trying to
compensate for how fast how much time is
jumps if it's jumped one year into the
future a-line monotonic time will run
one percent faster for 100 years to
catch up and this is the backward
compatible way so if you're starting up
the 18th of 0 emulator this is the mode
that you will get and that's the way
it's always worked which is not the
right way to do it we also have a single
time warp so this is for applications
that want to be able to use the new time
api's but are not really am therefore
using like converting their entire
application so what you can do is that
you boot up in a specific mode so and
then you only run on the OS monotonic
time so the airline monotonic time and
the OS monotonic time will be aligned
and work as one and then at a certain
point when you know that ok now I've got
in connection with my ntp server and my
time should be kind of okay you say now
i want to start do a jump so the time of
that does one jump and after that it
behaves just the same way as in the no
time warp mode this is for you so that
you can start up a small core of your
application first that just takes core
takes care to measure that ok now my
time is correct and then you set the
time and you do a boy
and then you start the rest of your
application that is not converted to use
the new primitives yet it all depends on
how big in a much of effort it takes for
you to convert the application and then
we have the multi time work mode which
is the recommended mode and this
probably the one that's going to be
default in the future how far into the
future that is we don't really know what
happens here is that monotonic time will
be constant it would be an ntp adjusting
monotonic time the time offset will jump
backwards and forwards on its own will
depending on how the POSIX time of your
computer works you can monitor when
these events happen by doing a line
monitor time offset on the clock service
then you will get messages to say I'm
out i time-jumped to this point or it
actually doesn't say where jumped in sir
said time jumped and then you would love
to figure out where jump to this is good
if you for instance building a crontab
or a similar in in your system things
that work with absolute time and this is
the preferred way to run things and it's
the most for one of the good things
about this is this is the most scalable
and most performant way to run your
application this is the way you scale
you get the most performance out of your
system all of the other things have to
do extra computations extra locking in
order to manage to get this behavior
this behavior is the one that you won't
get the most scalability out of so if
you want to make sure that you don't get
any contention on locks and whatnot you
want to start to use this mode so that's
that about time so let's talk about
relative time specifically the only
relative time we really have an ailing
is timers and the way that we measure
these things at the moment either
supposed to be corrected times at the
moment it's based on Alan corrected time
and as I mentioned before you have this
problem with timers triggering I alluded
to earlier too fast if you compared to
an external source in the system the
guarantees that we have is that a timer
is not allowed to trigger before the
timeout
we have timers that are either
associated with a message so there's the
timer Biff's like send after or
something like that or we have something
that's not part of a message we have
received after timeout and the timer
module despite its name has nothing to
do with timers in our longing the timer
module is an airline implementation of
how to manage timers there so these when
we talk about these things internally we
call them Biff timers because they are
and that's a long time as the timer
module so the AP is that you use this
end after start timer canceled timer or
received after milliseconds for that the
timers that have a message associated
with them are put into a hash table
first so you get a reference for your
timer and the message that should be
sent to whatever process is put into a
hash table that at the moment is
protected by a large mutex so normally
when you try when you have a system that
gets maybe 12 16 cores and you have a
lot of things running on it this is the
bottleneck that you will be hitting you
would be clashing on this mutex all the
time now we've been quite sure that we
could eliminate this mutex for quite
some time the problem is that beneath
this we have a timer wheel
implementation that again is predicted
by a global mutex so even if we solve
the one with the Biff timers we would
have fallen back on the timer wheel
mutex and getting that in there instead
so that's why we haven't solved that yet
or until now I should say and then the
receive after obviously only goes
directly into the timer wheel it's not
part of this hash table so I thought I'd
spend some time just explaining a bit
about how the timer wheel works so the
timer wheel is a big see array I think
it's something like 65,000 539 elements
or something like that whatever 2 to the
power it is and with slots and you put a
timer you have a linked list of timers
and a counter for each time or to say
how many tie
in the wheel it should survive so since
we have something like 65,000 slots it's
it and we have a millisecond resolution
it takes about 65 seconds for entire
loop of the wheel to go around and when
that so when we do timers we move the
timing once let's see you move it
forward and we trigger the time at zero
and we decrement the value so on the
slide before we have there we had 2 and
0 there so we trigger the timer at 0 and
we decrement it by one the other ones we
loop through all of them in there and
then as time goes on we you can see we
do a jump in between here so we sleep
for that amount of time if there's not
any other airline related work that has
to be done like a process executing or
something so we sleep until the next
timer which we get that one on that we
decrement that one because it was not 0
then we go through the all of the things
and sleep and then we're back at the
beginning and then and keep on going and
going and going so that's why it's
called the wheel because we go around
the array and then we go start on the
beginning and go around and around
around around this is very used in a
very useful data structure to work with
timers so how will they work in the
future so it will instead of being a
based on the island corrected time we
base it on the Ala Moana tonic time
which will mean that time jumps and so
on won't affect us unless we're running
into no time work mode because then of
course we have the it's the alan
monotonic time that's adjusted by a
one-percent speed increase so then we
would have the same problem as oh but if
we run in a multi-time work mode then it
should work fine and we have one timer
wheel / scheduler each at the moment
each of these timing beads is guarded by
mutex so any scheduler can do operations
in any of them eventually we will most
probably remove this and do it by as in
a synchronous message passing instead
and at the moment the Biff time be so
the message timers implementation has
been moved into pure our line so there's
no c code at the moment with that so we
have one timer process
/ scheduler that's running that so
that's an a-line process and it's not
bound to any scheduler or anything like
that it's just that we have one process
/ scheduler that's started so when we
get timers working like this one of the
consequences is that a process will have
timers in multiple wheels so if we say
that green is one process and yellow is
one process they all have timers in
different wheels and because of time
being local to each scheduler the way
the order that you put timers into the
wheel might not be the way the order
that they are triggered remember the
only guarantee would give about timers
is that a time I should not be triggered
before the time it happens it doesn't
say anything about the order which
timers are put in or how long afterwards
they might be triggered this order thing
is already present today in the emulator
you have to insert a lot of timers in
the same millisecond in order to see it
but it's there today so you're not if
you put if you do like a list sequence
and then put a lot of timers into the
timer wheel the message order that you
get them in will not be the same as you
put them in and this will become more
evident with this solution with this new
implementation as you will have largely
latencies in between the different
wheels but that behavior has always been
like that and it will always page like
that and it's a huge benefit when we're
doing the scalability implementations I
was talking about reference as well so
when we were working with this we
realized that timers and specifically
the timers with data attached to them
they return some kind of reference when
they are there so in order to make the
time implementation scalable we wanted
to embed the scheduler data into the
reference so normal reference is about
85 bits long and if you create one every
nanosecond it will wrap in 160 million
years so for the foreseeable future we
are okay on that front
in 18 we will take 18 of those bits and
make it into a scheduler specific part
so now instead of 160 million years it
would wrap in five hundred eighty four
years we thought this was an okay
compromise if you have systems that will
run for longer let us know and maybe
we'll give you another bit and you can
run four thousand and something years
the nice thing about this is that you
can see which scheduler has created a
reference so we can do a reverse lookup
so when your for instance want to cancel
a timer we can say that oh but we know
that this scheduler created this
reference with these timers we know
which scheduler the specific timer
process we should say send the
cancellation message to so we don't get
any conflict at all when we're doing
this one of the bad things or badish
things is that references can no longer
be used to order events so if you take a
reference and then take another
reference and you compare those they
might compare so that the one that take
is taken afterwards it's smaller than
the one taken before and that's a change
that's going to happen in the voting
machine that's I we don't know but we
haven't found any people using
references in that way yet I'm sure
there are but that was something we
needed to do in order to get this yes
yes it will become more scalable because
you create references much without
taking any because at the moment when
you create the reference you take a
global mute x and the increment the
value and then you release the mutex
with this you just have to bump a
pointer in the local scheduler data and
that's it for making a reference so it
would become much more scalable it's
still fine yeah it's still fine because
that for that to work it needs
uniqueness it doesn't need the order yep
okay so as I said the timer's with a
message attached to them is a pure Allah
implementation at the moment it uses
this reference trick to look up the
process it has one ordered sets table
for timers so that we just take the
first one of the ordered set and put
that into the timer wheel and then when
we we get either we get a message saying
we need to insert a new time or a
counselor timer or we wait until that
time in the receive after we have one
order and one set for faust elysian so
that we can just get a reference to an
index look up into a hash table get that
timer and delete it quickly
unfortunately that implementation is not
really as fast as we would like it to be
at the moment so most probably by the
release of 18 we will have moved it back
in to see but for the release candidate
that's out at the moment it's in pure
line our measurements from internally
and at the different ericsson customers
we've seen too much I don't know what
too much isn't is constant but they have
quite strict requirements and say so I
would imagine that 0.1 percent overhead
would be too much for them so we'll see
what happens there either will optimize
our languor we'll put it into scene so
to sum up we deprecated our line now we
have a new scalable API we have time
warp modes to handle backwards
compatibility we have somewhat more
scalable timers but not perfectly
capable timers yet
we have lock free reference creation
questions
that will depend on the operating system
you're running on unfortunately so there
is no clear way I think we have decided
that sleeping or hibernating your PC you
will get you I think on linux we use the
clock monotonic clock which I believed
us jump when you go to sleep I can't
remember but it will do it will depend
on what operating system you're running
on I'm pretty sure I don't have the
exact answer unfortunately how it would
work it's something we've thought about
but I can't remember the arguments on
the different sides
and with that number it's just what
happens when you take the number of
whatever time unit it was and do it 2 to
the power 64 so it's the guess it's an
amount from today it's the amount of
nanoseconds that you get when you do 2
to power 64 they are they are registered
by a name I believe and then you create
at them and then you send a message to
it we don't you will get that scenario
as you generate it will be you have won
if you have a if you have a scenario
where you're only running code on one
scheduler because of the work migration
has only migrated all the processes to
one scheduled ask you're running on what
one eighth of the load that the system
can comply then all of them will put be
put in the same process but at that
point you don't have a scalability issue
because you're running on 18 of the
power but if you're running on one
hundred percent of the things then all
of the schedulers really will be busy
generating timers and being put into the
different parallel processes so that
should be fine
no no now we've thought about it to do
it but it was way too much work to do
that and I think we kind of decided that
we will not handle that at the level
that we're working in a way if we're
right high level constructs do that
later on on top of these primitives that
might be something but we're not going
to do any low level primitives for doing
that at the moment anyway
possible yes probably probable probably
not it i mean if you have the scenario
where your for instance running a
long-running nif in one of the
schedulers that you're not supposed to
be you would block the blocking all of
the timers within that scheduler for
that amount of time that you're running
so if you're running it for ten seconds
that Alzheimer's in that we will be
delayed for ten seconds until boom all
of the sudden we get back to running
again but by now I hope everybody has
learned that they shouldn't do that so
we hope that that won't happen we'll see
you see how much it will differ hmm no
not really I don't know as such no no
how much oh how much they differ in that
way not a lot normally but we've had
some wonky hardware where it's been very
different so we're trying to compensate
for that I haven't been involved with
those measurements so I don't know the
answer the specific answer and some
other guys that they've done
it does it can't be done on the Austin
Colonel they would look for the
primitives and it's been impossible they
don't allow it to do that kind of
binding it's only the Linux kind of that
allows you to do that my information is
about four years out of date on this but
the last time i checked with these
things is not possible yeah who does
okay thank</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>