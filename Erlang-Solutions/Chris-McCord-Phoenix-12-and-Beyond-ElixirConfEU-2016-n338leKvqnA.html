<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Chris McCord - Phoenix 1.2 and Beyond (ElixirConfEU 2016) | Coder Coacher - Coaching Coders</title><meta content="Chris McCord - Phoenix 1.2 and Beyond (ElixirConfEU 2016) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Chris McCord - Phoenix 1.2 and Beyond (ElixirConfEU 2016)</b></h2><h5 class="post__date">2016-05-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/n338leKvqnA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">but now we're talking about Phoenix 1.2
kinda where we what I've been doing for
the last six months and what I want to
do from there on out but before I talk
about where we're going I wanna talk
about where we've been in for the last
six months we've had a couple big
milestones one was the Phoenix book yeah
it's out
Prague is giving a 25% discount for this
conference good a bitly slash phoenix
book you can use it lick sir calm me you
2016 underscore phoenix which i want to
remember is there like someone tweet
that out but this was a ton of work it
took about eight months right this with
the Jersey and Bruce you know super
excited to have it out and I think it's
it's important to have first class
learning materials for the community
outside of our are kind of the basics
the online guides so excited to see the
reception so far so check it out and
then also the Bragg slide that will hear
about later from Gary but we had a huge
milestone with two million channel
clients on one server and not only is
this amazing from a marketing
perspective but it's also just
incredible because it kind of approved
what I hoped and what we've been saying
all along that Phoenix and elixir give
us this crazy Performing environment but
we don't have to sacrifice our
productivity so we have this channel
layer that extracts WebSockets the
abstract long polling you have this
really nice API you don't have to worry
about how's the client connected what
happens when the connection drops how do
I notify clients if there's a crash on
the server but the connections still
good like all these things that take
work we're able to take care of for you
but still get kind of world-class
performance so that's super exciting and
the only reason it leveled off there is
because I miss configured the server but
we're here about the whole story of how
this happened and what led to these
charts here from from Gary later on and
I want to talk about kind of the growth
I realize since 100 last year we're
seeing about 4,000 downloads a day from
hex which like it's hard to quantify but
during elixir comp us late last year it
was about a thousand or 1500 gallons a
day so occasionally I just checked that
download number like oh wow we're like
four times where we were just several
months ago yeah I'm told that there are
focus books in the works around using
Phoenix with gaming like we heard from
Keith working on a book for Phoenix and
phaser
there's Phoenix being used with embedded
devices so I want to dispel this myth
that people will ask is elixir have a
life outside of the FINA
or outside the web and it's like of
course it does but like it's an absurd
question to ask just because Phoenix is
trying kind of redefining like what is a
web framework because like it's not only
just about building browser applications
like we're already seeing Phoenix used
in these areas that you wouldn't
typically think of a web framework so I
think we need to dispel this myth of is
it looks are only good for web it's like
no elixir is amazing for pretty much
anything connected to a socket but
Phoenix just gives you a nice window
into your crater elixir application so
I'm really excited to see kind of
Phoenix use outside of the standard web
application space and where that's they
go and we're also seeing job
opportunities so there's a lot of like
hacker news who's hiring thread this
month had 5 elixir related jobs that
mentioned that by using Phoenix for API
backends and you know channel
applications kind of really interesting
use cases and I think it's showing that
companies are actually really using this
and making money and hiring people so
that's really exciting to me
but phoenix 1-2 has been kind of what
has consumed my life for last several
months and it's out today feel like
steve jobs available today it's actually
been available for like a week
and as far as I know we don't have any
like working bugs so as soon as ecto -
oh go stable Phoenix one two ago stable
unless someone reports an issue so
please don't but the big feature of
Phoenix went to is really Phoenix
presents but we also have some other
changes like live is reloaded in
development now so there's no longer
this question of like do I put things in
web or live it used to be well if you
want them reloaded and development put
them in web so really the answer from
now on and just put your Phoenix related
files in web and everything else goes
and live like any other part of your
lecture project and we're exploring
changes in the future - maybe the web
directory can just go back inside the
project now that there are changes to
the Electra compiler that allow this and
then we extracted Phoenix pub/sub so
Justin asked me for a number of months
to please extract Phoenix pub/sub so he
didn't want the web dependency of
Phoenix but you wanted the pub/sub later
and we finally have extracted it and we
included Phoenix presence within phoenix
pub/sub so you can get this distributed
pub/sub layer but you don't you don't
need the web portion it's now separate
dependency and then obviously we were
able to focus on Phoenix presence which
was the kind of defining feature so I'm
gonna talk a lot about enix presence and
a lot about conflict-free replicated
data types which hopefully I can kind of
give some insight to how they work but
then I was thinking last night that it's
the first talk of the day so I'm
surprising everyone with how CRT T's
work at 9:00 a.m. but so we'll see how
it goes
but it seems like a simple problem so I
want to get down to the nitty-gritty
details so we can appreciate what we
have a backup in user land because when
you think about presence at least when I
was thinking about how to solve this
problem I think I don't know where josée
is in here but I think Josie and I were
like hey you people aren't solving
presents correctly here's how it would
correctly be done
we'd hop on skype and we're like we'll
write a blog post like we don't need to
make a feature in Phoenix but write a
blog to us not like oh this is how you
would do it correctly you just so we hop
on skype and it was like a three hour
Skype conversation that started with
okay what do we go say in this blog post
and then they're like there were so many
edge cases and it became like hours long
of like oh my gosh this is like a really
hard problem so I'm gonna walk you
through that so at first you're like
here's what we want to solve we have
users connected from two different
browsers or two different devices and we
want to show like on our web browser hey
which users are online so like just
display list on a browser tab is it was
the problem like how that's gonna be too
hard but it's more nuanced cuz there are
a couple features of presents like what
does it mean to be present because if
user one opens three browser tabs
they're logged in from their browser and
their iPhone that's three distinct
presences for the same user so presence
is really defined as like something like
a connection for each of those users so
we need a way to distinguish that
because the client the client might say
that you know I might want to show an
icon say on the browser tab saying I'm
online for my iPhone but what takes
precedent or I might set my status to
online or away but on my desktop if I'm
online but if I set my status to away on
my phone which one who picks what so you
need the ability on the client to figure
out priority so it's a little more
nuanced but that's like the easier
problem to solve the harder problem is
solved is the distribution problem and
this is an issue I think at large where
people will come into a licks er and
they'll develop something on their
laptop and we have really nice
primitives like agents engine servers
where we can put state so what we exceed
users doing as they would have someone
join a channel and then they would just
push that user into a named agent and it
would work beautifully on their laptop
but as soon as you deploy that you know
how like a presence agent running on
separate nodes and anytime you asked for
that state you would just get the users
I had connected to that note so this is
a problem and at this point most other
recommendations for among other
libraries and frameworks that we're
seeing with similar features they'd say
I know how to solve a shared state
access we'll just deploy Redis and put
him in database and we have solved all
problems and I think Redis is a great
little piece of technology but I think I
inferior platforms they push us to these
crutches and we just think like Oh what
does Paredes then we're done and I think
this does a disservice to at least it
looks on erling because we have this
amazing platform so presence is
ephemeral State it's state about a user
that is currently connected and as soon
as they're not connected that state can
be thrown away so we have a ephemeral
State and the language has an amazing
place afloat formal state and we put
that in processes so there's no reason
for us to deploy write us because we
have a single point of failure now our
operations overhead is now we have to
figure out where to put this thing it's
a it's going to be a bottleneck not only
because we have to send all traffic
through it but we also have to now
deserialize and serialize the data in
and out of Redis but if you accept all
those deficiencies you say okay like you
know what it's gonna be fast enough it's
gonna work for me you're still missing a
key point because it appears to be
solved and this is like the best-case
scenario of what other recommendations
are doing there were like blog posts I'm
like okay when a user logging the
application which put them in Redis you
can detect when they leave and we remove
them from Redis and this is where this
is a really the best-case scenario that
I've seen from other solutions and it
seems to work like the president's list
will grab from Redis and now we have
shared state no problem but almost no
one solves the issue we heard about
yesterday with like you know computers
suck so no - let's say catches on fire
and now what do we do
because we have written data into Redis
in the node that was responsible for
cleaning up those users that are now
disconnected because the node died are
just going to be orphaned forever and
most people just say well this is not
going to happen that often simulator
what we hear with people coming like oh
the network it's mostly reliable we
don't have to worry because it's Moses
networks fine so we can ignore this
problem or we can actually say let's
solve it properly and this is what you
want to do with these presents and we
can do that with a CR DT I'm gonna try
to break down not teach any maths but at
least give give you a mental model about
how to think about CR ETS and and why we
have the constraints the way that they
are and how this makes us kind of
changes our thinking about when we have
distributed systems there are just
certain facts of life certain truths
that we can't ignore but Co T's give us
strong eventual consistency so it's
something that as long as all nodes
receive all messages will eventually
come to the same result and that gives
us conflicts that are mathematically
impossible so the goal is we don't want
to have to have a distributed consensus
protocol or global locks we want to be
able to just send messages they can
arrive out of order they can arrive
multiple times and we can still remotely
synchronize but without actually having
to lock the cluster or rely on a central
database and there are a bunch of
different types of CRD teas but there's
a paper here at the bottom that we base
our CR DT on and this is where I started
out this process like all CRE T's this
is gonna be so fun to learn new things
and I started reading this paper and I
entered a stage of like crushing
self-doubt because this is just a random
sentence that I lifted out that it's not
even saying much so it wasn't even like
the the grits of what the CRE T's are
but it's you know it's like you read
this it's like in this way for each
replica there is a monotonic sequence of
states defined under the waters partial
order for each subsequent state subsumes
the previous state when joined elsewhere
and I'm like what is this I don't like
this isn't even talking about maths and
I don't even comprehend what they're
even trying to convey to me yeah
it's not the fault of the authors
because this paper is like the basis of
a really great research in really great
ideas we put into presence that we
wouldn't been able to do otherwise but I
think there's an issue with like
academia is using like they're coming
from the math background very
theoretical background and I just wanted
to know like please help me implement
this like how do I turn this into code
but it gets worse because like I was
like okay I'm gonna keep reading I'm
gonna keep reading maybe it's just gonna
start clicking and then like a paragraph
later they they prove something with
math and then literally they're like
proof trivial when I'm like what so yeah
so there was like crushing self-doubt
phase where I was like maybe this is too
much like maybe I I'm gonna be unable to
accomplish this and this is where
Alexander song who really was
instrumental in helping with our CRT tea
implementation great talk last year -
what's accomplished brtt's he kind of
had multiple Skype sessions with me to
break down like what this lattice
partial order or subsuming states and
like turn it into words that are just
like English that make sense and it was
like oh this is like you can actually
put these in terms that are just real
but I was still thinking through this
process they're like oh yeah I'm gonna
be unable to achieve this myself like
maybe I thought up you know I try to
take on too much and I have to pay
critic today and this is I don't maybe
this is a quote but it's something along
these lines where I was having this
crushing self-doubt phase and I
literally like asked him like maybe like
is this crazy like maybe trying to
implement the series he thing like maybe
we should just let people figure it out
or just use Redis like it maybe I can't
do this and he just made a comment like
no you can do it just like just matter
of fact like just like that and I think
we're fine
must be but the crazy thing is I think
this is a testament to Josie that I was
like like just that little nudge it was
like my back in my head like oh maybe
maybe I can do this
and I took like a three I had a three
day weekend and just just that little
extra nudge of like removing that little
bit of doubt like I went back to the
paper using also Alex Alexander's Hodges
example implementations we have been
working on and in like three days
I could actually digest and understand
the paper so it's just like Jose I
changed my frame of reference a little
bit I think that's kind of a testament
ow he's helped everyone in community
level up or it's just like instead of
trying to make this insurmountable
problem which is just a little nudge to
say like now I think this is possible
oh so now we get to learn about CRT T's
but no math and no subsuming states and
partial orders I just want to give you a
mental model to think about these
problems like why are we the why DS
necessary so we're using a or SWAT CRT T
which is like all these words are gonna
be like why did they pick these but or
swipe it'll make sense in a moment
it means observe remove set without
tombstones this is it's a type of CRT
team but ignore that so let's say we
have three nodes and we want to say
which users are online and these nodes
have different states at different times
and they need to synchronize and
replicate this so let's see like why is
it cieariy to necessary so it knows
let's say we have three notes that start
out with a state and I know they're
gonna send sets over it so observe
remove set so it's just a a collection
that has no particular orders and it's
got a hold users that are online so no
twos good replicate saying hey here's my
set everyone's gonna merge that with air
set and node one's gonna say hey I've
got user 1 in my set and then let's say
no three is gonna get this first because
we have a network we can't defy the laws
of physics there's gonna be the speed of
light there might be some packet
congestion so let's say that that node
one replication at the top is still in
transit no.2 has not received it yet but
what happens now node three says no I'm
gonna remove user one I'm gonna
replicate that
so now we have inbound sets - no -
saying hey I have no user one of my sets
and hey I remove user one so now how
does this know to act like does it
discard or add user one and the answer
is it just depends on when it arrives
and this is a problem because now we
have no consensus if it arrives after we
get the message from node 3 we're gonna
add user 1 to our set and now we're
gonna be we have a global conflict so
these things are supposed to be
impossible but this is an issue so how
we were gonna solve this or how I
thought we saw this initially it was
like oh maybe we can just like timestamp
each message it was like my naive
thinking like maybe your time span and
no 2 can say oh if I have a conflict
here I can look at the timestamps and
figure out you know what should have
been added first but this turns out to
be like like the worst question asking a
distribute system because turns out
there's bad news that like time is an
illusion and in disturbia system like
you have to totally change the way you
think about time when you're thinking in
addition your system mindset so it was
like okay I can't really apply wall
clock time I can't just put a time stamp
on things that come from like a web
background it's like oh we just have a
time stamp in the database and problem
solved but we have to come up with new
ideas and this is like Alexander Sanj I
have some quotes from him we're like I
would ask them questions like like naive
questions probably you know from a CRT
point of view saying like well why why
can't we just like why do we care about
things that were removed from this set
why don't we just keep the things that
we have and that's all we need and then
you would say like the past will always
come back to bite you like you can't you
can't ignore the past but I would be
like but if you can't ignore the past
but we can't have time like what how
does this work
so it's just it's just a really
interesting learning process so it's
like how you model system without time
if like how you were how do you resolve
conflicts if it's they're gonna be
dependent on when they happen in the
past and I couldn't really think about
how this worked but you know I found
this graffiti here like time doesn't
exist box exists so it's just this like
thing that we use but we can say there
is a solution to this we can say time
doesn't exist but vector clock Cygnus
and back to foxes is the answer here and
this is one of those other words that
like a year ago if you were to ask me
about vector clocks I would have said
like ooh that sounds really academic
it's probably something I don't
understand but it turns out it was
conceptually it's pretty simple vector
clock is just going to be an integer
value and it's a way for a node not to
record its server time that it perceives
because that server time could be
different even if we try to synchronize
server times we get a flock drift like
you know Earling now isten pretty early
eighteen would actually drift your clock
so servers cannot rely on their actual
clock time being set but we can just say
well if we can identify a node with a
tag couple and it's just good to use an
integer value instead of having a
specific timestamp in history it's just
good to represent some change that I've
had so if I experience an internal event
that has changed me to go from one state
to the next I'm gonna bump this integer
value and if I here experience another
internal event I'm gonna bump this
integer value and that's all vector
clocks are essentially and in this way
you can't we don't know the wall clock
time that that happened to pass but we
were able to actually see that something
had caused this node to go from one
state to the next were able to at least
have like to say like a causal history
which is another word that I was like
causal but we'll see in a moment what
that means so the idea is now we can
ship a vector clock with each element in
the set as we're replicating information
so instead of just sitting there all set
every element in this set will get the
vector clock and anytime we add or
remove something from the set we bump
our thoughts so we'll have a unique kind
of tag tuples sitting along with each
element in a set and now if we have this
conflict here where node three says I'm
going to remove
but during transit we have a user one
that was added no two can actually look
now and be able to distinguish ah I have
this clock here or user one from this
node but node three says that we have a
tombstone here so that's where that
crazy word comes from node three remove
the data about user one but it kept its
vector clock and it's set so now no two
can sit and look at these and say oh
node 3 has seen that tack value that
means it must have removed it from this
set because I had the tombstone so we're
able to resolve a conflict figure with
vector clocks but it has a severe
limitation in that the only way we can
resolve these conflicts is if we keep
tombstones around and remember I told
you that we have an observer remove set
without tombstones
so tombstones can't be the solution well
to kick the can be pleased if we have an
infinite memory tombstones are great we
could just keep a tombstone for every
user that we removed until the end of
time and then we'll be will be conflict
free so like every time we remove a user
we would just add a tombstone and we
could look at those tombstones but
obviously that doesn't scale so this is
where you know part of the paper and
part of this data type says that we can
apply an optimization here that's kind
of neat so it's like as users are
removed or elements to remove from the
set we will keep tombstones temporarily
and after we merge sets from another
node we can just sort the vector clocks
and we can actually compact all of that
information so I imagine I had this set
here and I could say I'm gonna sort it
and I can look and say look you know
what I've seen node 1 from vector clock
1 2 vector clock 3 or in a real system
you know factor clock one do a much
larger number and that means I've seen
the causal history of the causes that
have the effects that that node has has
gone through from that range since I've
seen all that I can just delete
everything between there that was a
tombstone and I only have to keep
the irrelevant information of user still
in the set and a separate map of the
causal context so the context of the
causal history of this node is just to
be stored in a map for the cluster so
this is like extremely efficient
compared to what we had before right we
can keep just the elements that are
still in the set plus an extra map
saying okay I've seen node 1 from 1 to 3
scene 3 all the way up to 4 so we just
keep these single key values around for
each remember on the cluster and then
our set remains thinit in size and
that's how we're able to get the without
tombstones part of the observed remove
set and then the observe remove part
just means that anytime we're merging a
set from another node we can just parse
it look at our calls our context and if
a node doesn't have a member that we
have in our set but it has the causal
history that the it what it should have
seen based on their vector clock number
we know it must have been removed so
it's a really interesting data structure
and very hard to understand especially
from the academic sense but once it's
explained in English terms hopefully you
have some frame of reference to think
about this thing
so now wipe that from your memory that's
how our swats work but the whole reason
I want to go through the exercise one I
wanted to pay it forward to if you're
trying to understand these things but to
you have to you know have to think about
it right like the whole goal is like now
even I don't have to think about it day
to day it's like up in Phoenix land use
Erling that you're gonna call it's like
as trivial as can be so if you want to
track users that are online in your
channels now you just it's like two
lines of code after someone joins we can
just say presence track so track my
socket it's gonna use that sockets topic
I have some user ID and I want to keep
track of and I can even store metadata
about that user like maybe I've set my
status online or away maybe it's gonna
be information about the kind of device
I connected with and then I can just
push all the presences information down
the socket and show that lifeline so
like two lines of code on the server the
fact that this has happened with CRT TVs
we don't care about
and then on the client we also have a
new presence object and it's just as
trivial it's almost like a CRT T on the
client as well what we can say if we get
some initial state we can call present
sync state and this is gonna resolve
conflicts because in between disconnects
we're going to be recent the whole state
but we already have some state upheld
internally so it's going to sync that up
properly with a server between
disconnects and then anytime we get any
kind of users coming and going we get
this special presents diff event so
instead of like si is replicated across
the cluster let's say 500 users have
come and gone we don't want to send that
as 500 events right that's that's much
worse for the server and it's much worse
for the client receiving all this data
so instead that will go a single event
of like chunked discs so that will have
like 200 joins 200 leaves and we have
the sink tip function and this is just
gonna sink this with a JavaScript object
on the client but you can also pass
callbacks here to say okay has this user
join from a device for the first time or
maybe they just joined from a second
device so we give you callbacks you know
be able to display if I log on for the
first time I want I want to alert
everyone but if I log on from up I open
up new tabs I don't want to always keep
flashing Christa sign online so you can
detect that and then you can also figure
out strategies for listing presences by
default we'll just pick the most
recently join users so if I'm online
from three different places by default
it's just going to pick the most recent
one but you can pass a function here to
list that will say maybe pick one that
is showing you as a way that will take
priority or maybe pick one that is using
some custom priority about maybe mobile
it takes precedent we give you those
visibilities but at the end of the day
it's a few lines of code on the client
and server and this just works you don't
have to think about oh is this going to
Redis is just a scale what happens if a
node goes down like everything just
works and it's just a few lines of code
for you to use to solve something that
you have in your app day to day so I
kind of wanna drive this point home with
a demo so I've got a application running
here on two nodes and we're just showing
a list of users that are online with
very pretty much identical code
with a little bit of bootstrap and make
it look pretty that you saw in those
last few slides so I'm left and right I
have four thousand one employ 4,000 two
with nodes clustered together I clear my
scroll back here so I got these two
nodes they're running on my laptop but
they could very well be on a data center
separated over the wire so let's see
like um the basic features I want to I'm
going to add a new user to node one and
I'm gonna name it
Safari prefetches the page which we're
like troll me because someone is show
online and it would look like a bug so I
need to use a paste buffer so Safari
won't prefetch this and show a user is
online so let's say that justin is gonna
be on line from node 1 Justin I just can
pass a name as a URL so it's easy and
you can see it replicated that
information almost instantly and we'll
try to replay that but now justin is
online on both nodes and since he's
online locally on note 1 that node 1 got
that information instantly so I'm gonna
close Justin's tab and if we watch we
should see him disappear from the left
hand side and then probably within a
second or two he'll disappear from the
right as a remove is replicated so I'm
on Chris's tab I'm gonna close Justin's
tab or movie remove instantly and then
he'll be removed from the right in about
a second gone gone and I was actually
super fast but we happen to catch the
heartbeat cycle like right away but
these this is just being replicated
there's no like central place that we're
like asking like red it's like hey
what's the user list this is just
happening which is nice but we also can
detect multiple users so let's say Joe's
a opens up a bunch of tabs so now it
says ok Joe's days online from 3
different places and this is just that
optional callback I can say given all of
Joe's days presences just add account to
that let's ensure that online and as I
close these tabs you'll see this
decrement like instantly to one so we've
solved those problems right
but we've solved the most difficult
problem is what if we have a net split
but what if a node goes down so I'm
gonna clear the scroll back here and
let's say that we I'm gonna simulate a
net split it's by disconnecting these
nodes
I'm gonna disconnect from node 1 1 at
127 127 0 0 1 so doesn't those are
disconnected so what happens nope nope
what happened so that goes those users
became unreachable and as far as each
node was concerned they that the other
node is gone and must have died because
we haven't heard from me so what we
wanted to have happen on the front end
was not that orphan data we wanted back
to just those users are gone right so
that was cleaned up for us automatically
we didn't have to do anything and we
have some verbose logging enabled I bump
up my font here I mean you see that
these nodes detected that there was a
replica down for me to know like oops
this node must be gone but they're still
up so like you want this to happen when
a node actually goes down but how do
they that you recover when you come back
up that's it's even harder problem
because now imagine these these things
are still running now if I if I open up
maybe Justin on node 1 again so these
nodes are currently running
independently but having things happen
that aren't getting replicated so that's
running independently so we've missed
that join let's say we have Eric on o2
now so now we have data I think like
this is a problem because when we heal
from the cluster we can't say oh let's
just go check Redis now and try to
resolve our conflicts like what do we do
especially if we had a hundred nodes so
with Nestle recovery let's see what
happens now
so have no disconnect how much missing
node connect
oh my gosh it just for Co the users are
back online like we didn't have to do
anything this is just recovered for us
and the client just got that information
like there is no extra code on the
server that you had to write or on the
client JavaScript client just say like
oh what happens now if this recovers
like it's literally the same code and
the cool thing is watching the logs like
what happened like had that work what we
can see maybe with the font that there
is a replica up detected so node one
said like hey I see a replica that came
online from node 2 but I have previously
seen it
I didn't mark it as down permanently I
say like whoa I can't see this thing so
I'm gonna assume it's down
so both nose detected that the other one
had come up but the coolest thing is and
then they looked at the their vector
clocks and I said oh I need I miss
information from you I can see that from
your vector clock now from what was
before you must have had internal change
internal events that caused you to
change so that will send a transfer
request so we can see I blow up this
screen node one received a transfer
request from node two saying like hey
catch me up
give me those give me Justin that I
missed and then no to send it CRT over
saying okay I'm gonna catch you up and
both nodes went through that process
sending their CRT T's across and this
works for the case of a new node coming
online as well so not only Nestle
recovery but you also have the case of
what if they knew no joins a cluster you
were trying to scale up you provision a
new instance like where do you read that
information from because if you have a
hundred nodes out do you ask everyone
you ask all hundred people give me all
your CRT T's so for a large cluster
that's a problem because if you have to
ask hundred nodes and we have to send me
hundred thousand active users across a
cluster all at once we're going to like
to flood the network we're gonna flood
that node so see what happens if we
start up a node on another poor with
another name let's say node 3 here how
is it going to get those
what's the users okay both of them
detected that there's a replica that
came online and notice how it
transmitted as for a transfer request
just from one node so no through II sent
a transfer request to node 2 this time
and no 2 said okay well I'm gonna send
my whole CRT to you to you because we
need everything but it didn't have to
ask node 1 for anything and if you go to
the browser to load for node 3 maybe
with a name Paris all those users are
just there so it was able to look at the
it was as sample the vector clocks in
the cluster
when node 3 came online and it said ok I
only need to ask no.2 in this case for
information and because I can see the
causal context of node 2 I know that it
must have seen everything that node 1
has so I can ask the minimum amount of
nodes to give me information instead of
asking everyone so and you don't have to
think about that like it's you have
maybe a frame of reference 208 it now
with the CRT T but like all of that is
same care for you so at the end of the
day it makes your life much easier
so that's beings presents I'm super
excited about it
and check it out use it and please
report your experiences with it but as
far as we know we have no working issues
so we're super excited to have that and
just about ready but I want to talk
about maybe what's next maybe um I
talked about this a which would come
from last year and we had some ideas but
that this have kind of gone on the back
burner because turns out that I may have
accidentally accomplished my goal from
the beginning if you've seen the very
first elixir comp talked about my bear
first talk on Enix I talked about like
okay I think this true I think Enix is a
distributed web services framework is
what I had like my first slide and like
maybe in the far future I would
like service discovery thing and like I
had no idea what I was talking about
like somehow it would that would be but
like but I knew the platform could do it
like I knew that like that would be cool
to be able to just say I've got these
services on the cluster and I can
discover them and ask them to do work
for me and in the back of my head over
the last two years I've been thinking
like I still want to accomplish that and
people would ask me like so how's that
what what's the progress on that and I'd
be like well that's that's way off but
it turns out we accidentally did
something pretty nice we just we solved
the problem accidentally it turns out we
sex it we can build on top and presents
to get this like we're suddenly like we
have this vast untapped potential
because we started out with this trivial
problem trivial problem I'm like I want
to show a list of users that are online
was how we wanted it to start and
somehow we ended up with oh we have
services the service discovery
accidentally I just really need because
I thought I was gonna be a lot more work
but let's see how that works because
like we talked about the CRT and users
that are online sending data back and
forth at some point in this process it
was quite far in you're like you know
what what is the difference between
sending sets of users and sending sets
holding services instead of saying this
users online it's really just a process
that says hey I can do user session
stuff or like hey I can send
notifications like it's the same exact
problem and we still want the same
semantics of no conflicts being
resilient to net splits like we still
want all those same principles and we
can go further than that it's we
accidentally created a distribute
process group and this is not something
it's not something I realized right away
I think was Josette I said like this is
basically like pg3 like there's the
Erlang PG - library is a distributive
process group and we accidentally made
some things that is kind of a step above
that with some nice features like we can
attach metadata to the processes but
let's see how how is this a phosphorus
group because the API is started out
track my presence on this topic so hey
this user is now online and I can
list the users later on rooms 11 so
imagine instead of doing that listing a
user their process online instead of
saying which users are in a room what if
I just said okay give me all the web
crawlers on the on the cluster and that
would return something with the paid
that I could contact and even metadata
like what the current work factor the
number of jobs and I can look at that
data and say like I'm gonna call the one
that is doing the least amount of work
right now so you can get we realized
like there's some really neat features
in here for service discovery with the
metadata we can store so the client can
actually do load balancing just by
looking at the work factor and like this
is just there like there's no like this
is this is a real thing that you could
do in C + IX today like I went from
topics and users to topics and any
process in the cluster and let's say you
know we could wrap that up in some nicer
API because you don't want to know the
details of topics and have that key
value words but maybe you can just list
anyone on the cluster that can do web
crawling get the process send it a
message do some work and that's just
there by accident but we can do other
neat things because with that metadata
we realized we could do client load
balancing but there might be different
strategies and one maybe you just want
like the default to be a random like if
I have three game servers or three web
crawlers I might I just want to randomly
send if I detect three on the cluster
they're present from three places I'll
just pick one at random to sin I maybe I
by default
shard them and this is something that we
would just do for you by default so that
way you're at least balancing the
messages going to them but as the end
user is concerned you're just saying
well there's three of these things out
there somewhere and I want this thing to
be fault tolerant so one of them goes
down I'm still gonna send a message and
have a game sessions served for me and
we can do that for you and it's just
there we would just have to write the
code that hashes and then sends a
message to a process so you know and
userland
if you wanted to write like we heard
from Keith earlier about like he was
spawning these game sessions so instead
of having to run those game sessions on
the local node we still have the problem
of even if we can globally register a
game session we
we don't necessarily want to run that on
the Phoenix node that is serving the web
request we just want to have some big
box somewhere that can do game servers
we probably want multiple of them if you
want to be fault-tolerant so you could
write some API that says hey it's fine
your game session for me and you get a
process back just like any other code
but internally let's say you want to
call a Jen server but maybe this is just
a pseudo API but maybe we have this
thing called you know service call give
it a module and this is gonna do the
service discovery on top of Phoenix
presence and by default it's just good a
shard saying if there's three I'm just
gonna pick one so it's well balanced and
it's just a do that call and you're good
at response back and let's say since we
have access to that metadata maybe we
can allow an API like this and do custom
load balancing based on your application
where if you say I've got these game
servers somewhere and their metadata is
going to be periodically updated with
the work factor which is just something
you come up with so maybe say given the
available amount of CPU and memory on
this box because maybe if you shard and
you have a giant server and a small
server giving the same service you don't
want that to be equally balanced so
maybe periodically the node says my work
factor is gonna be 0 to 100 based on
available resources and we can look at
that from the client and say I'm going
to just do a sort on the services
available and pick the one that has a
smallest work factor and otherwise we
can treat it just like a gin server let
me get a process back and we say that
messages directly so that's pretty cool
and this is something that would just
happen by accident which is even nicer
so I'm really excited about that so that
you know just that API is not
necessarily exactly what we'll end up
with but I think that we've got this
kind of goldmine of possibilities and
something that I thought was way off
that's included so I've had this insight
in like how did we accidentally do this
and to me it's a testament to the
platform that we started as we've
started off how do we solve this trivial
problem and we ended up thinking like
well since we have the platform we can
so we have the platform that can do all
this great distribution and we can solve
it in the ideal way and we solved it and
ended up being something far greater
than we thought possible and I think
like that's not a coincidence
I think the fact that we had like the
primitives in the language the
primitives in the virtual machine to do
this distribution it's no accident that
we ended up with something that was
extremely powerful and I think in any
other language Lisa I'm familiar with I
would not have ended up here it would
have been I would have ended up saying
hey I've got this thing that we can use
Redis and it's gonna be fast enough so
it's pretty cool I think it's a
testament to the platform but outside of
that so outside of those big ideas we've
got some other areas that we want to
look into one is first class umbrella
integration so maybe having a - -
umbrella flag - the Phoenix generator
that will just do some niceties for you
because umbrella applications I think
are a little under served in the
community and they're they think a
little bit of plumbing to set up like
you just set up the dependencies
properly so maybe you know by default if
you pass the umbrella flag will generate
a web separate application for you in
one application for your application
domain and we'll suppose dependence is
that properly for you so then you would
have literally just an app that service
web request that called in to your
greater OTP infrastructure and we also
want to have more essential extensible
transports sasha is here somewhere
you've done all this work and we just
have to review it and resolve some
conflicts that have changed with
presence but we want to have the ability
to write transports without a bunch of
duplication because right now the way
our transport is is really just like a
lot of cut and paste if you want to do
something similar to the WebSocket
transport but your own custom way like
you just have to duplicate a bunch of
code so sasha has gone in done some
refactoring is to make this much better
and we want to focus on new generators
that really push you towards better
isolation so generators like the mix
makes Jin HTML mix nice Qin Jason
they've always been about
they've always been learning tools so we
want to focus on doing really teaching
you better so I don't think there's
anything wrong necessarily with our
current generators but we are saying
that you know Beck DOE has this idea of
separating the persistence from our data
structures which is great but I think
it's not enough to push people into how
to perish
sure they're greater application so we
want to wrap the ecto code your repo
code into a module and just so you can
call modules and functions separate your
Phoenix application from the details of
how this is happening and then I also in
the back of my head like I talked about
Lister grant last year I really think we
can solve client-server data
synchronization and I think it was
probably good that I got not sidetracked
with presents because we are seeing in a
community now like there's some new
ideas this is a hard problem like meteor
has a their DDP protocol and then graph
QL has something they call subscriptions
that is it's not a finalized spec yet
but it's coming along and we have folks
like Bruce Williams Ben Wilson and Josh
price that are working on really great
graph QL libraries in elixir so I think
if I wait a little long enough finish
service discovery and then I think there
might be a really good story on here's
how you would actually do client-server
data sync and oh we have some things and
elixir already they can handle it and
then at that point we can say okay how
do we tack this onto channels and
someone else has solved all the harder
things for me but that's still in the
back of my head it's like we have the
technology we can solve these problems
so that's that's Phoenix one two and
really what's on my mind before I finish
I want to thank Dockyard where I work
I've been able to focus really almost
all of my company time on Phoenix for
the last six months so I've been working
nearly full-time on Phoenix and that's
allowed me to build presents that's
allowing me to go on a deep dive into
research papers on CRT T's and it's
something that I would not have been
able to do without their support so I
really appreciate it and you see them
yep Wow
I want to action
yes so one of one of the issues are one
of the ways we saw that is with the DIF
so instead of if I replicate across the
cluster especially across an netsplit
imagine that I've been disconnected for
a while and I have a thousand joins and
leaves and imagine for that I also we
don't want to put information into the
the metadata about the user let's say we
still want the users name their current
profile information but we don't want to
put that into presence because now we
have a caching problem so if I replicate
a thousand users that have joined and
then I also need to fetch from ecto or
my database layer the thousand profile
informations like I don't want to
perform a thousand queries so it's kind
of a similar problem and I actually left
one of I left to slide out where we have
when you generate mix Phoenix Chen
presence it creates a myapp presence
module which is empty by default but
that has a fetch callback which is a
ability to say here's a diff of all
these things that have happened and
you'll get a bunch of user IDs and you
can make a single query and then
populate the metadata with extra data
using in one place so we have basically
features in place to allow you to
collapse all of those things into one
one event and then we'll push that out
as one broadcast
No and like I said hopefully I meant it
I tried to make sure when I was
rehearsing that I didn't put them down
too much because I mean they did did
some amazing research pushing on the
their Delta brtt's which which we've
implemented so if you fall behind we
don't have to send our entire sierra TT
back to you we'll just send a snapshot
in time of maybe a hundred or a thousand
users and keep those around for a while
so if you fall behind I can just send
you the minimum amount of information
and fall back to the tragic case of
having to send my entire state but no we
haven't had any contact with them about
really great work so I think that it's
just unfortunately I'm not an academic
yeah there is a there is a so Phoenix
tracker is our lower level that presents
on top of any trackers doing the Sierra
TT and the cluster membership so there's
a Phoenix tracker state module on the
Phoenix pubsub project and that's the CR
DT and it's publicly documented so so
yeah you could use it if you depend on
Phoenix club sub you have a Sierra TT
that you can put information into as
long as you have a a process you can
attach state it to it and use it just
like we've talked about
yes
Thanks
yeah I mean the no limits so one thing
we're doing is to do cluster membership
we're using a heartbeat protocol which
just means periodically as if we have
information that has changed we are beat
more frequently but we just send
everyone a message to periodically which
does not scale entirely well but that's
actually what the current Earling
distribution does is they heartbeat
there are other protocols like there
like uh we were looking into swim which
is another way to do cluster membership
but guarantee that you're not gonna
flood everyone with a thousand messages
so if you have a thousand nodes you're
not gonna get a thousand messages every
second of where everyone's at you can
hit a subset so I have there's actually
a swim branch on Phoenix pub/sub and I
ended up saying that you like I think
heartbeats are gonna be good enough for
now instead of trying to implement it
like I was I was excited after josée was
like you can do this and then I was like
yeah I can I need more research papers
okay I can do some crazy stuff but but
no so I was like since this is good
enough for Earling it's good enough for
50 to 100 nodes we've pretty much said
if someone hits a bottleneck with our
heartbeat protocol so maybe it's good
for 40 50 nodes I'm not sure you can
sponsor Phoenix to support more because
you're gonna have you know millions of
millions of active users but that is
your question I forget the exact okay
corruption in what way so unless you lie
if you lie about like your vector clock
because there is no sense of time yeah
yeah I mean you know in our system like
we have trusted actors so as far as SAR
as far as Phoenix tracker is concerned
there's a tracker running on every node
that's sending the vector clock
heartbeats and if one of those starts
lying I say you have a serious problem
but it's not it's not code that I wrote
so so yeah it's not it's not a federated
distributed consensus so for us as long
as we've implemented this correctly it
should be complex to be mathematically
impossible and as long as there's not
some rogue commit that does some of the
various things what's that
or bad memory yeah well I mean even from
like bad memory yeah that's like the bad
memory case yeah I don't know yeah we're
only using the V vector clocks to
determine unique pieces of information
so if that memory or if that data in
memory somehow changes all bets are off
but I think that you have bigger issue I
mean that applies for any parts of your
program
yes so it works I yeah after I crapped
on write a sandwich
it works on Heroku with the Redis plus
of adapter it just works with reddit but
you deploy Redis and it works it's gonna
be fast enough no yeah it's really neat
that we were able to like Phoenix
pub/sub was a way for us to do
distributed pub/sub but then we walk we
also wanted to be able to support people
that weren't that couldn't run
distributed elixir so we added a system
for pups of adapters and then it was
like oh we went to make presences we
were like hey we have this really nice
way to send distributed messages across
a cluster and it would just happen to
work on Heroku because we can build up
in top of Phoenix pub/sub and then we
made presents work and then we were like
oh we can actually build service
discovery on this thing that we tried
like so it's like these layers have just
naturally kind of fallen out but yeah I
did just work on Heroku today even
though I just just so everyone's clear
like you should never ever ever use the
reddest puffs of adapter if you can use
this root elixir like there's no good
reason to unless you're forced to
because Heroku can't cluster donut</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>