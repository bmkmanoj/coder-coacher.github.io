<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Keynote - Without Resilience, Nothing Else Matters - Jonas Bonér - EUC17 | Coder Coacher - Coaching Coders</title><meta content="Keynote - Without Resilience, Nothing Else Matters - Jonas Bonér - EUC17 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Keynote - Without Resilience, Nothing Else Matters - Jonas Bonér - EUC17</b></h2><h5 class="post__date">2017-07-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ktBlGj5gGUY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">here we go so how many of you would
serve how many of you would like to go
to production with an application that
is you know beautiful scalable highly
concurrent meeting all the SFA's in the
world and high throughput low latency
yada yada yada yada you raise your hand
yeah we all will do right the problem
though is that none of that matters
unless your application is actually up I
was actually able to serve its purpose
and service users without brazilians
nothing else matters I'm really honored
and grateful to be here thanks for the
invite Francesco I started acha a long
time ago now eight years ago and I had
to say that without Erlang there would
be no arc I'm immensely grateful for all
the hard work that you've done and
learning so much from people like Joe
Francesco and many others in the
community here and trying to take your
your foundation forward in the server
line when I found it but like a
lightning rod you know in the dark scary
forest that was lost at nowhere to go
really and it chilled away unfortunately
I was not able to continue using it
though but it showed what was possible
that sorrel later led to me trying to
re-implement those on the JVM little
attract etc so some of you might serve
my correctly nice so sorry I just need
audio sorry I'm just cool down for some
decent some of you might recognize this
the intro the intro song here it was
from you know if you didn't it was from
the first rocky movie in a rock is about
this underdog he gets a shot at the
title the media he knows or boost him up
calling the Italian stallion etc and one
of the most memorable quotes from that
movie is this one no but actually from
don't we love rocky right it's actually
not from this movies from the one what
one of the latest series preserve
captures these are the whole theme of
the rocky series quite well
this is fault tolerance I mean you you
get hit you survive you limp along
hopefully eventually you will win right
but often you don't in the first movie
rocky didn't actually you got knocked
out of the ring the problem is that
fault tolerance is not a sustainable
strategy okay what we need and what this
talk is all about is resilience what it
is
why it's needed how their interest rates
sort of deal with it and what we can
learn from that
etc etc so what is resilience so if you
go to merriam-webster and look at the
definition of resilience it says that is
the ability of a substance or arbic to
spring back into shape to recover the
capacity to recover quickly from
difficulties it's really to be able to
restore full functionality not just limp
along like rocky but actually to not
just survive but to fully self heal and
be back where you were where were you
when you got hit there's a lot of people
talking now this about and our fragility
as well be able to whenever you take a
hit you grow stronger I don't think
really as an industry are really ready
for that yet but it's an interesting
concept in the software system today are
incredibly complex Harrison diagrams to
serve you circling around the internet
the last few years need Netflix
architecture Twitter's architecture etc
these are course exceptional cases right
but but it shows a lot with what we're
dealing with here so I really believe we
need to study resilience in complex
systems and I don't really understand
what that means
what is complex then and how is it
different from complicated a lot of
people confuse the two so a complicated
system
usually consist of very a lot of small
parts all usually different but that
each one has some a precise role in the
machinery yeah
it is possible however often quite hard
that's in this picture I can look at
this one forever I won't let you do
those though but it is possible to fully
understand the complex complicated
system a complex system however is made
up of many these are index or similar
interacting parts with simple individual
rules and it's the interaction of these
rules that leads to globally consistent
behavior and it's by definition
impossible to understand a complex
system that leaving at least to some
some some that's some very definition
you can only try to understand a complex
system by understanding the underlying
rules in how these parts interact
running one example for example is game
of life it doesn't look that complex it
has a very set of very very simple rules
right but when you scale it up it
generates an immensely complex behavior
that is close to that is rather larger
almost impossible to understand even
though it's extremely simple in terms of
look at the just individual rules it's
really important to understand that
complicated it's not equal to complex
and probably one of the most important
piece of wisdom in this talk is from
this great paper but by Richard cook
called how complex systems fails Richard
is an mg been doing research in in
medical systems and resilience in
medical systems for four years in
sexually so located here in Stockholm
and he says the complex systems running
degraded mode complex system run as
broken systems in a non trivial complex
system something is always failing
somewhere it's a fact and it's too hard
to understand how and why etcetera so we
need different strategies also Donella
Meadows she's been doing a lot of
research on on system thinking and she
she writes about supports for human
intervention in the system in the
complex system where humans cleaning and
efficient fiddle with things
Colten leverage points and I quote
counterintuitive
that's foresters word to describe
complex system leverage points meaning
points with humans green and fiddle the
things are not intuitive or if they are
we as humans then intuitively use them
backwards systematically worsening
whatever problem we're trying to solve I
mean humans generally just makes things
worse
so we really need good models in order
to understand fail what failure means
and especially how failure behaves
itself in complex systems why it happens
and what we can do about it
and since software systems are
incredibly complex and systems always a
complex system always run as broken
systems we need to learn to fully
embrace failure I believe you'll need to
learn to design for failure from the
start find ways of managing it
the most fundamental lesson in this talk
I believe this is a resilience is by
design it's nothing that you can just
bolt on afterwards you need to build
your beautiful app and then oh yeah
resilient yeah we just turn on you no no
WebLogic clustering if you run in a job
out whatever it needs to be part of the
design from day one yeah it's a core
concept this is the photo from from from
the home in gil christ texas it's a home
that was designed to deserve resist
floodwaters and then when Hurricane Ike
came in in 2008 you know the whole city
was wiped out more or less this this
this house dissing still stood strong
because it was built with the resilience
in mind from day one but let's now look
at some factor in terms of Australia's
how to how to manage failure and
increase stability and mark Burgas is
he's a professor in at the Oslo
University he wrote in his book in
search for certainty which is a great
book I really recommend it to read it
that autonomy makes information local
leading to greater certainty and
stability and one thing that you will
learn in this talk is that autonomy is I
believe is the key to resilience
building autonomous systems you know
collaborative components they're
decentralized
Jernigan isn't and that's offer that can
serve be self-managed itself in a way
and Mark Berger C also introduces this
theory in this book and other other
books called promise Theory I really
believe it's really recommended to read
this book it's really gives a solid
foundation how to think and understand
sort of complex and collaborative
systems made out of autonomous component
you know we're used to thinking in terms
of obligations and and and and serving
positions in what we call you should
call commands that we one process tells
another process what to do okay what
what but what's wrong with that if
something's wrong with it yeah the
problem is the thing is that promises on
the other hand you know they are local
you take local serve decisions what you
can promise to the rest of the world
okay while obligations in commands they
are non-local they're distributed by
definition long run non-local and since
you can only control local information
the stuff that you actually sit on you
know you can't control others commands
or make up loose control it leads to the
little to deserve a lower degree of
certainty and stability the promises
expresses our intent of what to do that
at the at an endpoint defining the
ultimate outcome what we want to happen
okay and that sort of independent of
current status while commands on the
other so that they sir they define what
to do at the starting point it not
served what what the end outcome
necessarily will be so and you know
convergence is a topic in physics in
current and converges can ideally lead
to serve stable fixed point instability
in complex system is a really good thing
okay
why divergence leads to instability and
the interesting is a command you know
they start with the definite with a
certain state but they diverge outcome
certain states that leads to sort of
decreased stability and certainty in the
system while promises on the other hand
they usually start from
unpredictable beginnings to bleed you
converge into a stable state in the
system and and convert is essentially
same thing as idempotence
that we are in computer science you know
really really pressure since if we have
arrived it means like when we right at
the desired outcome then do nothing
we're already there okay so let's now
take the Lisa just some food for thought
that that I really helped refrain my way
of thinking and especially in discerning
protocols which is the essence real of
distributed systems so let's look at how
just briefly have some other sciences or
like fields manage resilience first look
at resilience in biological system one
of the interesting story that I that I
learned as they're at a TED talk by a
guy called Nicholas Peroni was that that
he did that that TED talk recommended to
watch it is just ten minutes long it
took he talks about complexity theory
and he's doing two studies on on animals
in animal kingdom and in this particular
study was Amir cuts and meerkats they
are apart from sort of being funny and
cute I just love them they're correct
interesting animals they're very social
animals with very rich social behavior
so they're really interesting to study
and what one thing for example is that
is only the dominant couple in you know
in a big group that is allowed to have
to have children all the rest in the
group need to sort of serve as servants
or babysitter's who want to get kids etc
and in in this particular experiment GPS
trackers were added to the meerkats and
they were observed moving from one
feeding place to the next an interesting
that there was a road in between so so
you can follow sort of see how the the
dominant female she led the group all
the way up to the road and then she
stopped and then she saw Gabe gave way
to to the sabor subordinates to search
the looks like let them to test if it's
safe to cross the road if they got run
over yeah sure it's fine
he was still doing okay right and evil
was safe she also crossed the road and
then took charge of the group again and
led them to you know to find food and
same thing on the on the way on the way
back and when what's interesting is that
you know nature has are developed this
way this sort of behavior for thousands
of you probably hundreds of thousands of
years millions of years perhaps you know
the dominant female is extremely
important to the group is only that she
is she that can have children so that's
why that's why the groups or sacrifice
itself for the greater good of the group
than in this case the dominant female
and this is like it's a way to improve
resilience of the group as a whole I
find it quite interesting welcome okay
we'll come back to this pattern Nicolas
Peron is some sup pistol with this quote
that in three words in the animal
kingdom simplicity leads to complexity
which leads to resilience I think it's
interesting that nature uses complexity
to achieve in resilience as a way to
resilience I think we can learn a lot
from that and let's now look at one
example from Brazilians in social
systems as also quite interesting these
are from this paper dealing in security
understanding vital services them and
how they keep you safe I don't know if
you've seen it is quite an interesting
paper
it essentially describes you first as an
individual and then that there are six
so six ways to die essentially if that's
where the pie slices in these in this in
this diagram you can either die from
being too hot to cold hunger or thirst
illness or injury okay then we have two
or three sets of essential services that
protect us from going shelter protect us
from dying being too hot and too cold we
have supply the prayer that helps with
hunger and thirst and that we have
safety that helps with illness and
injury and serve these these these
services and are laid out in layers in a
protecting us as individual in the in
the in the in the innermost center of
the circle
so starting from from from from the
outer circle first where the world there
we have a global markets like you know
energy market food markets fuel market
country we have the setting of the
military perhaps regional we have Police
City we have like hospitals water plants
etc neighborhood we have like food shops
grocery stores you know 7-eleven gas
stations etc home yeah we have heating
toilet tap water these times the release
things that we take for granted whole
way down to the individual and you know
it takes quite a big of a catastrophe in
order for everything to break down and
you to die
it happens still but it's really
interesting how the world is laid out in
layers protecting us as individuals to
achieve high resilience for us as a
species ok we'll also come back to this
a little bit later so what can we learn
from biological and social systems yeah
first thing they feature diversity and
whatever and redundancy you know systems
with many different components are
generally a lot more resilient systems
with few components simply because if
certain component dies and others can
make up for that or take over their
their work etc that's how you know
brains work and everything is we give
you brain in your injury
I mean others just other parts of the
brain can actually learn there what you
could what you lost to some extent etc
so this leads to redundancy and that's a
good thing this sort of insurance policy
you may say these systems also according
to some of the papers of Regina having
and obviously in an interconnected
network structure they are decentralized
made up of autonomous components they
usually spray wide raishin of of
structures across a lot of different
scales where fine-grained scales all the
way up to large scales and also they
have the capacity to self organize and
to self adapt which is also core trait
that I think we can learn a lot from in
computer science so let's look a little
bit now from from the remainder of the
talked about resilience in computer
science and also try to we've been how
we can learn
some for some of the ideas in other
fields
unfortunately I mean they went too many
times we react like that it was like
first not at all and then we complete
panic but I really think that we need to
fundamentally change the way we think
about failure failure is inevitable
failure is actually something that's
natural it's not something we enjoy
right you're like but we it's still
natural
it's it's nothing exceptional about
failure it's really a natural state in
the applications life cycle just you
have start you've stopped you have not
wheels update pop pause just look at
fail there is being something like that
a completely natural state in the state
machine of life's over the application
and when you then end up in the failed
state there's nothing to worry about
because you know exactly why I got here
and how to get out of that state so we
should design for failure and manage it
instead not trying to avoid it so one of
the core philosophies that I think is
important is what it's often called sort
of crash let it crash you know and in
crash your only software that we just
actually named of a paper bike a candy
candy on Fox you see all that the type
to the reference there at the bottom
here if you're interested in reading the
papers I have links at the end of the
talk by the way
so can there in did they define
crash on the softer s you know stopped
being crashed safely and start just
recover fast and this way of thinking
can the can can serve help us escape sin
on non determinism thanks to
inconsistent state and things like that
it's sort of a sledgehammer I believe
but it's a useful one and it's sort of
something that's of course you knew you
guys Erlang developer to live and
breathe you know let it crash such as
something we've also adopted in ARCA
kandia folks took this idea further in
this this paper called recursive restart
ability turning the crashing of this
sledgehammer into scalpel where where
they show how you can define this
recursively fine-grained all the way
down to the tiniest components or vice
versa all the way up to two largest
types of systems
and it gives us an extremely good way of
looking at systems I believe something
that will come back it come back to
later so but first I mean let's let's
look at traditional state management how
are how are we you know we as developers
often taught I mean I I'm preaching to
the choir here a little bit I know that
but I mean most Java developers C C++
developers etc I mean they are talk you
know a very different way of looking at
the world that I think is actually very
very very harmful in the legend here is
that this white bowl is the client blue
is some some sort of objects and then
you have your critical state that that's
the absolute they absolutely can't lose
that this Red Square here and the dog
Linus or the thread boundary for a
specific request for example so we have
a bunch of scattered objects here then
you have a critical state a little bit
here a little bit there okay and then a
client comes in and he makes a request
to somebody some object and if if your
service if the only conflict of
execution is the thread then you will
make a bunch of serb synchronous calls
down this all-big hierarchy okay all
fine you know I'm when the happy path is
beautiful it's really easy to understand
but what happens when things don't go as
expected okay
then well then then if one of these
objects or blows up trickles you know it
burns you know or baked after object of
the after are baked all the way up to
the client like blows the whole stack
straight up into the clients face so
what should it what should the client do
what they used to do with this that's
non-trivial and the problem here that
you know you're only giving us a single
thread of control and if that is that's
all you have you know that's lost you
lost everything so what you need to do
then is code extremely defensively you
should holding onto the Condor context
that you have that's why we see them in
Java code little with trike
a statement example coding extremely
defensible protecting the context that
you have and to make things even worse
you know exceptions in Java for example
or C++ or yeah pick your poison don't
sort of propagate between these threads
so unless you catch it and do something
useful with it
it's just lost no one will ever ever
know that something went wrong except
this poor client that's no idea what
happened you know so so so at least a
very defensive programming has to and it
leads to programming that we're failure
manages scatter across the whole
application because something can go
wrong anywhere there's not as a
structured way of dealing with state
it's not a structured way of dealing
with with with failure I really believe
this business model is actually broken
and we need to look for other
alternatives
I think structure can bring sanity back
here
Sydney Decker said that accidents come
from relationships not broken parts I
think this is also we extremely core
piece of wisdom here it's how things are
connected that usually makes things fail
in catastrophic ways I mean a single
failure is usually fine if you can
handle it the right way ok so what are
my requirements for saying for failure
model yeah again this is from the Erlang
cookbook more or less but I really
believe that there's something way
deeper here than just the guts Erlang
it's really the way we should think
about failure managing about failure so
I believe a failures first need to be
contained to avoid cascading failure the
failure snip we ought to leak to
Waterman without without control we see
that way too many times times in Java
and C++ applications you need to be able
to materialize reify failures as
messages and especially if your based on
the Fulda message driven system then
method in failures just any other many
other message you can treat it like any
message can treat it almost as workflow
know that also changes the dynamics if I
look at failure failures need to be able
to signal and in an asynchronous
not synchronous then you still end up
you know with it's blowing the whole
call stack you need to be able to be
observed and what's interesting if you
if others can subscribe you can have
more than one subscribing to to message
know just like I mean in in Anarkali
have something called watch and you can
subscribe to errors it's not just the
survey the guy that created it that sort
of limit that manages its life sizes
that can subscribe it anyone can and in
Erlanger blinks cetera and interesting
here that if you have this model and you
can manage you know the failure from the
safe context outside the failed
component
did you have an asynchronous boundary
between you can sometimes you have the
network you between even you can
actually operate safely and manage the
failed components but if that's my
cookbook for a sane failure mode first
time you look at the isolation we need
to be able to contain failures to bottom
to leaks life aux avoid cascading
failures etc and this is the key here is
compartmentalization containment or
failure and and the bulk heading is you
know it's is the sort of pattern that
has you know a long story it's been it's
been the way that the ship industry ship
ship construction industry have have
solved this problem for us for hundreds
of years where they sort of divide the
ship into watertight compartments so a
bunch of them can I should be ripped up
or ripped open but the failure is still
contained it doesn't it doesn't leak it
doesn't spread taking down the whole
ship oh people always bring up yeah what
about the Titanic it obviously didn't
work that well yeah the interesting
thing with the Titanic is actually it's
a perfect example of cattle bulkhead and
gone wrong these you know these walls
didn't go all the way up to the roof so
with enough was a gap to gas or ripped
open the ship star kill thing starts to
spread over from one to the next locks
it's actually a perfect example of
cascading failures in one usuai you
should do bullet proof bark heading so
and so I believe this is a great way of
achieving fault tolerance best but I
think we can actually do better we can
bring resilience and self-healing into
the picture and healed
could these ball kids and restore full
functionality as well but this is not
sufficient right we isolate in is not is
not it we need a way for a failure to be
signal observe and managed as well and
that by health care connoisseur of
component and what I really think we
need something like supervision where we
have where we have someone that can
serve X or subscribe to these events and
do something with the failure to manage
the failed component do this allows you
to build systems that can truly sales to
you again I'm preaching to the choir
here but but it's telling my story and
also I mean you know almost all phasers
are somehow related to state to state
management inconsistent data partial
data are the wrong data loss data
application of data etc etcetera
etcetera
so it can be helpful to try to classify
state and and and this this paper out of
the target which is another great paper
a committee to read define state is two
types of data you have input data that's
data given to you by others okay and
then you have derive data data that you
derive from the input that you get okay
it's the input data that is the critical
data because that's nothing that you can
recompute if you lose the input data you
need to go and ask the client again or
do another request to to to serve to
service order another system etc there
are data however that we can finally
lose the only thing you lose there is
compass processing time recomputing it
okay this also ties a lot of course the
immutable states and things like event
logging outlook is later out of the
torpid also defines quite interesting I
think their ideal system you should take
that with a grain of salt of course but
I think they're onto something here
where they define an ideal system to be
architected in three different layers
first you have the essential state
therefore the foundation of the system
and that should that's completely
self-contained it doesn't depend on
anything
okay that's where we like for example
our input state the state to be simply
can't lose then you have the essential
logic that sort of the heart of the
system often called the business logic
that depends on the essential state but
nothing else and then and then and then
finally we have what they call
accidental state and control this is our
the least important part of the system
less or depends them both on both of
these the interesting thing is the
changes here can never affect either the
essential logic or the essential state
so architecting this way you have you
have a good foundation for managing
state in a safe way and so what I think
what this sort of describes where I'm
getting at here is that what what I call
on e on layered state management a lot
of people call in this community I think
all is the error kernel factory directly
there are a couple of good good links
here and the first of course Joe's paper
here but also it just rounders and wrote
a great post about this in more depth
but but the interesting thing here is
that instead of having you know the
states scattered across the whole
application you define what's the error
kernels where you sort of the core where
you put your essential states and the
state that you simply can't lose and the
interesting thing is that the kernel
never compute does any dangerous
operation by itself it's always served
delegates to an outer layer to perform
dangerous operations this means that
when the kernel is hit with a request
can always assume correctness it's
always been validated it's already the
dangerous stuff is already being done in
another thread or on another machine
perhaps even and those all be safe and
to apply new state or to apply the
operation to the inner most of this
error kernel so let's look at an example
here
the legend again is you have a client
you have objective state that needs
critical protection etc so now
instead of having to state scatter
across the whole application we put that
in what we call the error kernel here
and then we have sort of layers where is
our delegate dangerous work and the
interesting thing is that for each one
of these each one of these are layers
you have components that all around in
there in their own thread so you have
served in a stirring this boundary which
between all of these it's also extremely
important to prevent from cascading
errors in casting and cascading failures
okay so let's now say that the client
comes in here and it does a request and
and and and something then blows up in
the thick in this intersect is second
layer the interesting things that assume
that that failure will not be reified as
a message it was sent out to whoever
subscribed it usually the guy that
created it because that's the components
are created because that sort of in
charge of managing the lifecycle but it
can be others as well the interesting
that that component now can serve you
know manage failure by restoring the
component or you know resuming it or
perhaps restarting it on another machine
or something like that this gives us
system the store can very much sell feel
and the interesting thing is that this I
believe this is very similar to her
nature have evolved in terms of the meat
of the mierqis where is your delegate
work dangerous work to subordinates and
Michael often died but in this case you
know the the the dominant female
represents to the error kernel is still
safe to continue to function and create
you know new new actors or new
components or new babies in the in the
meerkats example and if you remember
this mr. deserve this is a diagram from
dealing in secure insecurity we have the
individual being protected by layers all
the way up you know this is exactly the
way we are trying to model things here
that you have lever layers of defense
for
detecting you from dying okay so far I
find that quite interesting so then are
we done now can being going to be
recessed you early I guess but no not
really though because we cannot keep
putting all the eggs in the same basket
so the problem is that is not it's it's
not sufficient yeah do you remember the
top lessons from from from service
elites and social and biological system
that we need to maintain the diversity
redundancy we need to have an
interconnected network structure we need
UPS rd central its size decentralized an
autonomous agent the same thing applies
to computer systems because you know you
can never run a resilient system on a
single machine doesn't matter it is
beautiful use there a kernel pattern etc
it's not a single box it's not resilient
someone can go in you know where this
with a sledgehammer just kept the cut
the wires you know connecting to the
client etc resilience really requires
you to run at least you I'm in three
hundreds depending on your own
requirement machines okay which means
that we need to spread our application
out of multiple nodes and that
completely changes the game no we all
know that network is reliable right well
not really and the network you know it's
work you have you you just enter so this
world this ocean is ocean of complete
non determinism you might be may have a
bean orchid architected your single
application a single node in the most
beautiful way even using strong
consistency it's tough but as soon as
you enter the network you know you're
jumping out of that peeking out of that
little box of beauty I mean everything
that that's what we take for granted
it's lost
no because messages that can be in a
delayed reorder dropped randomly
etcetera that's our TCP works you know
and failure detection is like at noir
black art
it's a science you know it's it's it's
it's a guessing game you can't be sure
if a node is actually up and just being
dead slow if the job are probably going
DC we do something like that or if it's
down it will never ever come up again so
you need to take an educated guess based
on Uhura stakes thresholds etc so it's
it I mean you know this problems of
course not necessary if you're running a
single in in the in a single node so
what is the path then towards reserve
resilient distributed systems yeah
that's the whole topic by itself for
like probably a week a week class or
something like that but the some of the
things that I that I found useful we'll
talk about just briefly is that and I
will dive into a lot of these serve and
they're in the remainder of the talk is
that we need to embrace the network
don't try to hide it a synchronicity
location transparency is important the
isolation is as important you know as on
a single machine I believe through your
computer your components running in
process autonomous micro services is
something that can help I mean we can
sir we can surf on the market services
trendy not just you know drink the
kool-aid but actually use that in order
to build systems that that are
distributed in the right way I believe
there's a lot of people doing micro
service is wrong but there's this an
opportunity to build distributed systems
right there resilient protocols is of
course extremely important building
self-healing systems you need things
like decentralized architecture mean
gossip protocols have helped me a lot
there I mean doing failure detection and
stuff like that and data resiliency we
need to start entering eventual and
causal consistency things lucky event
logging can help its flow control etc
but starting with mark with micro
services say I believe that these micro
services as I said there's a lot of
wrong ways to do marker service and just
having some framework to serve that that
scaffolding framework you just easily
let you like spit out the single micro
service a lot of them do you know they
can they ignore all the hard part
because this with our micro service
you're actually suppose
to enter the world of distributed
systems and that's hard that's really
hard it's nothing you can just have a
scaffolding framework justice to spit
out you drew this think through what
what you're doing here but it's also an
opportunity since is the world you know
moving from monolithic to start thinking
in in distributed systems it's an
opportunity for us that you know that
live and breathe distributed systems to
show them the way serve and lead them in
on the right path towards building that
correctly some of these core traits of a
micro services
it said autonomy I think is one of the
biggest ones isolation is of course and
you know through very through
virtualization and think we actually not
allowed to have urge for isolation all
the way down to the hardware which is
which is also a good thing you see
docker containers or whatever mobility
is also sort of a key a key a key aspect
to this I believe micro services need to
be so a single unit that can moved
around it can be replicated as you know
as one thing and and a lot of people you
know they lock into them to the micro in
within the micro services but it's
really in an unfortunate term I believe
micro service is the terrible chosen
name because it's really nothing to do
with micro macro implies size it's
nothing to do with size I think it's
about scope of responsibilities and NS I
mean we most people have been around the
block a few times note the single
responsibility it's a good thing that's
how these it at the UNIX philosophy
that's how we we were sort of taught to
build systems so think about that think
about scope responsibilities and finally
exclusive state that's extremely
important I believe the first I'm going
to have to have it be able to move
around at the single as a single unit
but even more to fail in isolation and
and in restored in isolation etc
anything then you need to make sure that
you have that you own your state
exclusively not that it sitting you know
and elsewhere wherever there's really
hard to maintain that data integrity
needed as you scale your system etc
okay and and and sort of looking at how
to apply promise there here I can just
give you one one glimpse this is more
burgers by the way you know what does
promise theory then mean for autonomous
microservices yeah the interesting thing
is that an autonomous service looking at
that for is from from from the promise
theory standpoint can only promise its
own behavior never someone else's
behavior that's not when you think about
it else if you can promise someone
someone else then it's coupled and then
it's not autonomous the interesting
thing I mean this is you should sort of
let that sink in I believe because I
think it has profound the implications
or how we think about system because you
know if the service can only promise its
own behavior then all the information
needed to resolve you know conflict to
repair under failure scenarios etc
that's available within the service
itself there's no need to go out and ask
others for anything you have all
knowledge that you need to do that so
that minimizes actually sometimes but
most of the time completely eliminates
the need for coordination and
communication with others so the same so
I think autonomy is really the key here
and promise there can be an interesting
lens I want to oversell it but it's an
interesting lens to look at we also need
to decompose the system in insert
consistency boundaries so what what is
the consistency boundaries any I I I
believe you know that it is the boundary
of the service that that that you can
have strongly consistent that can have
sir transactional semantics the
important thing is to try to minimize
that it's not just possible why yeah you
look at the model if then you minimized
it to you no not at all really you know
you have one single global consistency
and there's in desparate then your
server you over to run out of options to
scale so if you try to minimize the
scope of a bit of the view that needs to
be strongly consistent then you open up
for more possibilities of scaling
and also more more more syrup head room
for doing resilience of course you can
replicate be more easily etc I think
it's better to stay like to start with
no guarantees when you design your
system and then add just as much as you
need and try to minimize you the
transactional semantics of the data that
you that you need and then you add
behavior a lot of people do the other
way they start with the behavior and the
throw in everything that they want you
know nor thinking that strong
consistence is completely free and they
end up with way too large consistency
boundaries and and and yeah the camp can
come back to bite them that's a quite
high price patel and defines a quite
nice framework how to think about these
things in its data on the inside versus
data on the outside paper we talked
about inside data as our current local
presence that's the other state or
internal state okay that's the state
where we can actually make strongly
consistent we can have one you know
single view on time not having to you
know juggle different times etc outside
data is what I call blast from the past
that's like facts arriving from
somewhere else no facts arriving from
somewhere else are always from the past
they're always looking into the past
when when you're working with the facts
from the past it's also important
because you can only maintain strong
consistent within your component that
means that outside all that far off
messages are delayed you know whatever
so so you have to juggle these two
worlds between services is what he calls
hope for the future which is almost
poetic I think that's that's or your
command when you try to send any
position obligations you know they'll
talk about in promise here you ask
someone to do something you can never be
sure that he will do it you can ask
politely
okay so I've said again I will reset
this but I can just be emphasized again
with them the strong within the
consistency boundary you know we can
have strong consistency we just need to
minimize it as much as possible
things like bounded context seemed
appear in ddd can you help modeling
lists and this often goes hand in hand
with microservice design in actors
they're lying in archives but you know
between these boundaries it's a lot
harder because between these boundaries
it's a zoo really
it's non-deterministic and it should be
because it is the zoo that gives us
tools for availability and scalability I
believe it gives us more options but
it's extremely hard right
nothing's free unfortunately so to
manage this who are we certain these
systems that are decoupled and I believe
they need to be decoupled into in two
dimensions first in time that is what
gives us concurrency it gives a
concurrency through interleaving or by
running on multiple threads etc but this
it gives us like it makes tools that
breaks free of the Saudi strong coupling
that we have user link developers you
already know this of course that's what
you live and breathe but that for way
too many developers is not something
that feels normal to do rely on
asynchronous communication to get this
sir decoupling but it also needs to be
decoupled in space and that will gives
of distribution and mobility okay and
essential leave leads to resilience and
things like that I also believe I
learned the hard way that in we need to
embrace the network no we need to we
need to make the network first class in
the programming model ok we need to
embrace the constraints of distributed
computing embrace the constraints of
network programming don't try to hide it
like we've done that's the neatest way
too many times in the past you know the
fallacies of RPC Stephan ask you can
tell you all about that egb is CORBA
decom etcetera I mean we learn the hard
way that that creates leaky abstraction
that leaks so much that they become
almost useless because they hide the
hard things and they hide also the
opportunities for managing failure
that's that's one of the problems right
and that we that the network doesn't
exist I think they are they should do
the other we should embrace the network
and and live and breathe it you know it
breaks the constraints because that
gives us more Headroom for more knobs to
turn when it comes to building resilient
systems and the actor model does it
right because it makes distribution
first class which is the key in my
opinion after sorry great for a lot of
things in a minute but concurrency etc
like but it but I think the key thing is
that it doesn't try to fake that is
running on network is it takes the other
way around you know this the Waldo pay
for the no.2 distributed computing it
really tries to to to tackle it head-on
instead of try to fake it and location
transparency concept that I've found
extremely useful here that it that gives
us one communication abstraction across
all dimensions of scale so if we in
practice gives at one programming map
model with unified semantics regardless
on which level you're attacking the
problem okay so so the instead of czar
relying on different tools and different
semantics preferring for each for each
level for example if you run on a single
core some people might reach for
callbacks you know doing interleaving on
a single core if you have multi core you
some people then go misuse threads and
locks you know or whatever MPI or
something like that and if you have a
cross machines yeah then you bring in
some message queue or something message
oriented middleware or
more PC or something like that so you
have different tools for different
levels the problem here the knee lock
yourself or to the program to be locked
into it with certain topology which you
mean dynamic systems the special
particular advantage of the cloud
computing is just it's extremely
unfortunate because because it mean
cloud computing promise in elasticity
and then we need many other components
to be able to scale you know as the
system's is being used from single core
to multi-core to multi-node etc and be
moved around so we really need you know
abstractions that allows this gives us
to say
way of thinking with the same semantics
apart from latency perhaps across you
know from core to sake to CPU to
container to serve a Dirac to data
center to global etc and I believe
message passing asynchronous message
passing asynchronous communication is
really the key here because that allows
for that it gives us one programming law
that we can use regardless we haven't
locked ourselves in and this is what I
believe is its or the essence of a
location transparency we also need to
serve focus over still resilient
protocols and and and what I mean by
that is the app depend on asynchronous
communication eventual consistency
protocols are tolerant to message loss
message reordering and message
application and one thing that sort of
come up the last years the exact you
look at Helen that I came up with
acronym this athlete to doto this is
also framework to think about when you
design protocols serve Frankie you know
variation of you know acid that serves
you know strong consistency from from
the database world but with the change
that a stands for associative
associative mean that it batch
insensitive is grouping insensitive okay
commutative means that is order
insensitive order doesn't matter you
know the idempotent it means that it's
application insensitive you can
duplicate things etcetera doesn't matter
and dia probably just distributed or
just to make them the acronym work the
important thing is we should not strive
for guarantee delivery because that's a
hoax and transactional semantics okay
another another tool that I found useful
that we use in our car you know
re-architect race is this interesting
case on race or the dynamo serve idea or
manova know of a node ring this gives us
a possibility to build
completely decentralized architecture
that are masterless so peer to peer
based that where you don't have a single
point of failure and no single point of
bottleneck the interesting here is that
using than gossip protocols search is
also inspired by by nature here you were
your use of epidemic gossiping
you serve being certain that try to
mimic you know how viruses spread
essentially in among humans etc and this
industry of gossiping can have like Oh
Casa dating the membership data in a
metadata a lot of people use like CR DTS
nowadays you know to actually have had
the business related data sir spread
across the network etc we see which is
quite interesting it also gives us a
structure way to do failure detection
that's the whole topic by itself there
are many ways to looking at it but but I
really believe this is the core
principle that you need to have a part
of it it's also very important to
understand I've been being sort of going
back to this before that strong
consistency is really the wrong default
it's just too brittle I mean how many
people here have used AXA and when it
coming back to bite you in there yeah
it's so it's really really hard to make
that work facial because could try to
shoehorn the world into an illusion
that's just wrong no it's not how the
world works the world the world is not
strongly consistent is something so
something we compute we find computer
scientists have made up to try to make
things simpler and in the simple case
you know it works but as soon as you try
to tackle hard problems usually as falls
apart and you know Pat hell and one says
that two-phase commit is the anti
availability protocol and I believe that
we have to rely on eventual consistency
unless your consistency is sort of a
probably too broad category to be useful
but but the solution is often to be
found
somewhere in there you know there's
nothing to be surprised to be cuz it's
really how the world works
it's we humans act you know he's using
eventual consistency all the time so we
shouldn't fight reality we should
embrace it we embrace the constraints
the things will be easier cause of
consistency for example is it's in my
opinion often what good enough right
it's what people
in català t is how we pee havoc how we
people interact with each other all the
time
so caustic insistence is actually
probably good enough that you can do
quite a lot good when it comes to scale
and availability but some people might
think but I really need transactions I
just can't see your way out of the
problem if I well yeah I'll give you a
quote Pat hell and again is this like in
general application developers simply do
not implement large scalable
applications it's assuming distributed
transactions so so what should we do
then if we have to have sort of
transactional semantics or so yeah Grace
Hopper once said it's easier to ask for
forgiveness little bit to get permission
so what do we do when we don't when we
can't coordinate something with someone
in real life we can't be certain about
something we usually take an educated
guess that is that some sort of property
will hold and if we're wrong we
apologize you know and we hopefully do
some sort of compensating action once
we've asked forgiveness yeah flowers to
the wife or something like that you know
and this is very much matches reality
matches how the world works all around
us I mean other examples you know
Airlines they try to usually over booked
flights on purpose and they try to bribe
themselves out of the problem by seeing
vouchers etc this also you know taking
it back the whole plane will not fill up
apologize and then issue compensating
action same thing with ATMs they if they
can't reach the mainframe they still
allow you to deduct money with the money
making money so the bank is making money
from that and if you if it turned out
you didn't have the money in your
account you will even once the
connection is restored and we will
deduct it to negative balance and then
you know if and if necessary they will
take legal actions afterwards and then
it's also apologized probably not but at
least take compensating actions so a
patel and also said that the sort of the
subset this audit serve the truth is a
log database
it's a cache of the subsets of the log
you know disk space used to be very
expensive but today and these are
certain that's the reason by a sequel
databases use in place update
destructive ID updates or REO overriding
in history that was there but today disk
space is extremely cheapest there's
really no reason to use in place
updating along there's no reason to not
keep all history around forever
I believe so why work with the cache of
a subset when you work with the real
thing and I really believe that we don't
need update and delete any longer we
should just you know create facts as
they arrived into the system is how we
derive them from other facts or read at
any point and something that works
really really well
when it comes to this is event logging
you know working with facts working with
immutable values store facts in Kosovo
order the order that they have been
created in an event log an event
sourcing is starting to be popularized
last year some it's a great pattern on
top of event logging because you know
the log is serve a database of the past
it allows time travel the time is a very
useful index you know so you can
actually go back in time and in replay
and think that it opens up things like
replay um failure if one node crashes
you can just bring it up replay from
where it was bring it up just to speed
again you can also use this sort of
replay to have things like you know
bullet proof auditing bullet proof
debugging this replay and see what
happens you know and and and for
replication for active and passive
replication you get any number of
subscribers to this event log doing many
different things event logging is also
extremely performant I mean uses the
single writer principle having a single
component just writing sequentially to
disk very much mapping how modern
hardware looks and works removing in the
contention contention is the biggest
scalability killer really trying to
remove something like that is extremely
important
it also gives us the possibility to have
to have what is called a memory image
that you work with data in memory and
you know avoiding this deserve classic
object-oriented relational impedance
mismatch since since you can work with
data memory backed by the event log on
disk you you don't need to map anything
the data is fully persisted is replayed
you know instantly we often use the
using some sort of snapshot in-between
because you can't replay I from day one
if you want to know them the technical
way so we'll probably do this but the
interesting thing is you can work with
the data in the optical format in the
object without having to worry about any
mapping or anything like that and a lot
of people you see QRS on top of event
sourcing as a way of separating the
right from the reads you know the read
side on the right side often very
different resilience characteristics
scalability characteristics and being
able to scale them and provide
availability you know independent of
each other is a really good thing it's
also it gives us the way you know from
the resizes like many types of read side
to consume subscribe on on on the source
of truth being the event log in many
different formats one for example goes
into elastic search were for for
querying one goes in the sequel database
for reporting and you do you do most of
the queries using Cassandra for example
it gives you a lot of different options
for both scale and and and resilience
finally you know I think it's very
important to apply back pressure all the
way through because you know you have a
fast producer you can easily overwhelm a
slow consumer and and and and and and
take him down I mean if you can't keep
up I mean even memory might go up or he
might starve other processors or
something that's extremely important
especially today you know with streaming
being sort of a core trait in a lot of
applications to have a way for the for
the slow consumer to signal up the chain
how fast the producer can go so you have
a steady flow in the system so a steady
state steady state you know in terms of
of streaming and it's really important
that everyone participates else will go
something like this that's clearly a
service system that has a need for back
pressure poor fisherman's and this is
also the reason for standardization
efforts around this and we add life and
we created the standard called reactive
streams
that's only currently essentially not
only there are implementations in some
of the languages may be but it may live
for Java it's a simple way to serve an
SPI for different sort of libraries to
participate underneath how data flows
it's also a reactive socket
implementation recta socket or dial for
example that allows you to do that
across the network cetera so I've
covered a lot 35 seconds left according
to my account but just to sum things up
I think the important things to remember
is that complex system always run as
broken systems okay something in the
complex system which most software
systems are it's always failing
somewhere ok even if you haven't
realized it yet and the only way to deal
with that is not try to prevent it is to
embrace it to make it Power Core part of
the essence of your application and
resilience is really by design how you
build systems from ground up so without
resilience nothing else matters you
really I have a bunch of reference areas
are interested if you're lucky you get
academic papers and reading material
I'll post the slides afterwards
so go off and read it thank you that's
all I had
we can take two questions folks kind of
set up I can't help it nothing else
matters we can take em asynchronously I
have a question sure told me that you
need to design your system to embrace
the failures right but what is a failure
a failure is something unexpected so
shockingly designed to handle unexpected
how could detect it designed to handle
the UM the unexpected yeah that's a good
that's a good thing but it's of course
if we're hard to think through all the
failures scenarios right but but I think
looking at failures as messages mean
that at least is something like Scala
they are typed you know they have
semantic information so so so I see I
mean try to think through the failure
cases and give them names give them
semantics make sure that all the context
needed so it's part of the message so
whoever is on the other side receiving
side knows what to do then actually the
way to finding my minding all the
failures that's sort of a more of a
testing problem I believe there are like
think like chaos monkey and stuff you
know we have a lot of tools in archive
for distributed testing you can you can
kick off about your nose you have a
testing what we call conductor that can
conduct the tests and that tries to you
know if possible round things on a
single thread to make things a little
bit more deterministic if that's what
you want or just you know try to like
introduce randomness to try to find
failures if that's what you want so you
test the whole spectrum
let me Netflix that's a bunch of tools
for that for example you know the chaos
the simian army or I think it's called
so let's all start with trying to think
through the test cases but then then
also beat the crap out of the system to
make sure I find all the cases which
will never do by the way it will always
be something that you never thought
about right so you need to be a
that deals with the unexpected as well
whatever that might be any other
questions I'll be around here for mentor
today so please don't hesitate to come
up and give me a redness or of both
ramps or praise I'll appreciate it</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>