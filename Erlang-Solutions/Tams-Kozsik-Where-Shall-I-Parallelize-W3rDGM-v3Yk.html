<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Tamás Kozsik - Where Shall I Parallelize? | Coder Coacher - Coaching Coders</title><meta content="Tamás Kozsik - Where Shall I Parallelize? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Tamás Kozsik - Where Shall I Parallelize?</b></h2><h5 class="post__date">2014-08-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/W3rDGM-v3Yk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you for choosing this session and
thank you for Simon to introduce me so
as you see seven people are working
together on this project to our side and
referring back to the invited talk
yesterday three of them are women
actually it's pity that they could not
come today so it's my task now to to
present the results so what is our
motivation probably everybody agrees
with me that we are expecting megacorp
computers in the near future not very
near future but in near future medical
computers which are highly heterogeneous
that may contain CPUs GPUs specialized
computing elements or general purpose
computing elements and we would like to
write software for these machines and
this this software should be optimized
both for performance and for energy
consumption it's not very easy to write
such programs if you don't have the
right constructs to structure our
programs so if you want to think in
parallel if you want to really write
large-scale applications we need the
appropriate tools for that for instance
we need high level programming
constructs we don't need to worry about
deadlocks and other communication
problems it should be somehow part of
the system part of the design to
eliminate such discrepancies is it
turned off the communication facilities
should be somehow taken away from the
hand of the programmer and should be
left to be implemented by by by the
system by the runtime system and finally
we have to be able to engineer the
performance characteristics of our
applications so the performance should
be considered part of the design from
from early on
and it's not only applies on new
software but they have to restructure
existing software legacy software as
well so we need some tools to to help us
in these tasks so at my toe claw
introduce you a tool which is able to
find pearl I zabal code in some cloud
days he is able to help the programmer
to make the right decisions on how to
turn his mostly sequential code into
mostly parallel and for that it allows
the programmer to reshape the program so
that the parallelization can be
introduced to the salsa I think this
this kind of software this kind of tool
should be very useful for many of us all
the work has been carried out in the
paraphrase project parallel patterns for
adaptive Virginia's multi-core systems
which is a fp7 project running from 2011
and it's going to terminate this year so
if you are really interested in in this
topic then you could check the results
of this of this project but while even
now you can visit our website or or
tweet us today and yesterday you have
probably heard talks from our project
void check from agh I was giving a talk
yesterday and Chris Brown from Santa
news I think he had the best talk in
this room just before lunch so what are
the main ideas of the paraphrase project
the project aims that improve program
ability of heterogeneous / architectures
by allowing us to express parallelism in
a structured way so we can use
high-level parallel patterns to express
how the polarization of the application
should be
carried out patterns like map reuse or
task forms or pipelines divide and
conquer dissipate general patterns there
are more domain specific patterns as
well like orbit or stencil and once we
express the parallel structure of
applications using these high-level
patterns then we can use the runtime
system to map the components of the
system onto the existing hardware taking
care of the optimal use of resources and
even remap the components of the
application if the hardware resources
are changing and the periphery is
project addresses to language
environment c++ on Erlang but guess what
I'm going to talk about along this time
so the the patterns that that are
familiar for for many of us are like the
farm the pipeline MapReduce divide and
conquer I will mostly talk about talk
about the farm today and a little bit
about the pipeline these are the two
patterns that we currently can address
with our tool so what is the approach of
the paraphrase project well in
paraphrase we we we say that if you want
to paralyze an application we first have
to identify the components that can be
run in parallel and these components
should be fairly independent from each
other they should not interfere with
each with each other if we run them in
parallel so they should have some
hygienic behavior and when we identified
those components then we can introduce
the patterns for describing the parallel
behavior of the application so we
structure the components in the parallel
program
by turning the patterns recognize
patterns into into some basic
implementation we have a skeleton
library that allows us to construct
patterns and of course in this previous
people take performance and energy
consumption into account as well once we
have introduced sample ization and we
have done with some profiling than we
have we might have find out that that we
still need to restructure application so
we need tools to do the world the
transformation the program
transformation work during the
introduction of the skeletons into the
code and also during the restructuring
if it is necessary so we propose to use
the refactoring tool for this purpose i
mentioned that Chris had talked just
before lunch he's not here probably he's
drinking his well-deserved beer
somewhere let me just tell you in few
words what he was talking about so he
said that there is a skel library for a
long gun also for C++ but Skylar before
Erlang allows us to describe parallel
patterns with some domain-specific
language i will show you a few examples
on that that can be applied on some
inputs and produce some output and this
kind of patterns can be mapped onto
available hardware resources both cpus
and gpus all this can be carried out
using your factoring tool Wrangler Simon
gave a talk yesterday about how to use
regular for affection airline programs
and I will show you a few examples
during this talk as well
so for instance if you want to have a
pipeline in your application then you
specify some something like this so you
say that I have the inputs and I would
like to apply a pipe on these stages of
course this should be done only when I
have lots of inputs so the the list of
the input is flowing in the system and
the list of output is flowing out of the
system similarly I can very easily
express a form i have some input i have
some inputs and i apply the same worker
activity a couple of times and again i
split the long list of my inputs and
allow the workers to produce the outputs
so in this in this case I need a process
that splits the input into amount of
workers and another process that
collects the outputs and and returns the
value the list value produced by by this
construct but all these details are
hidden by the libraries I don't have to
worry about this this low-level process
creation and communication issues and
the whole thing is completely completely
compositional so you can define more
complex patterns using these simpler
ones for instance you can describe an
ant colony optimization algorithm using
feedback skeleton a farm skeleton and
the pipe skeleton so what I do here I
describe this computation with this
complex structure so it's a feedback
that takes a pie
the first stage of the pipe is a form
inside the form I'm doing this fine
solution function on the inputs and in
the second stage of the pipe I do the
pig best function this seek here is a
special skeleton expressing components
so this this dysfunction is turned into
a component using this scale this is a
sick skeleton now let's hear a simple
example for instance matrix
multiplication you have a dot product
taking a row in the column and then in
the multiplication function you take a
matrix in as a list of roads and another
matrix is a list of columns and you
compute the dot product of all the roads
and all the columns it would be nice to
identify how this can be paralyzed
automatically so our goal is to develop
a tool that is able to do this pattern
identification so the tool should be
able to find that yes this is a place in
the code that you can introduce the
skeleton to describe the structure of
the polarization and if you have many
such places in your program then the
tool is able to choose the best ones to
introduce pearl ilysm of course in the
large scale program you have you will
have millions of pattern candidates but
only a few of them is verse to actually
turn into a parallel pattern so our tool
will be able to rank and and suggest the
best candidates and as well we can do
some shaping of the code so that the
introduction of the skeletons becomes
easier for instance if you take this
multiplication function
we can introduce a form which allows us
to compute each row of the resultant
matrix in a separate worker so this is a
the code is actually quite similar it
didn't change a lot so the main
computation is done here so this is how
i compute a row in the output and this
is turn now into a function that takes a
row from the left matrix and produces an
output row and I will pass this function
to each of the workers in the form in
this example I have 16 workers of course
you have to tune this value based on the
available hardware resources so when you
design your application you express the
structure the paralyzed nation of that
you want to use but you also need to set
the constants properly you have to
somehow work with the available
resources and and split the resources
among the different components so I
would like to show you how this works in
practice so let's party
you
he's gone
the mouse is doing really strange things
with me oh do you know how to make this
bigger can you see it no I can't it
no oh my gooood ah that's bad
how to do that here oops yep oh that's
fine all this better oh cool
okay sorry for that I'm VI person so
emacs is in a kind of dark magic for me
so our tool is called party party party
parallel refactoring tool for a lot and
I can turn this on and as you see new
menu item appears here party menu item
oh this this is not the font of this is
not change unfortunately but I will tell
you what you can see there if I can say
so for instance I can do some pattern
discovery it takes a few minutes I have
a save me kind of menu item which allows
me to view the previously executed the
previously obtained result so if you
don't mind I will and use this menu item
rather than running the search just at
the moment if you're interested in how
this works just come to me and I'll show
you so in this case a browser will pop
up I need to change it and this browser
will show me the possibilities that my
tool has found in the code for instance
it proposes me to introduce a form in
this file in the matrix not it's one
variant of the matrix multiplication if
I introduce the form with 20 workers
then my tool thinks that I will achieve
a speed up a very good speed up so this
is recommended transformation by the two
of course I will have better than
candidates which are not really good
ones not very good candidates they are
not recommended like this one if I do a
introduce farm transformation here then
with six workers I can achieve 2.4 speed
up which is not very good so suppose I I
want to see this one this is this little
bit more complex this is a former farms
so I have to introduce two forms in this
example and on the 24 course this might
give me almost ate almost 19 speed up
see if I click on this one I can see
that there is a list comprehension which
I can turn into a form and there is a
call to the lists map function which I
can also turn into a farm it should be
highlighted where this thing is here yep
wait
I'm good to have a wrangle expert around
so this was the original code and the
shaping would turn this carried into
this comprehension its equivalent
actually but what is more appropriate
for introduction on the phone okay so I
like this so you type bang Kieu oh yeah
q yes I mean yes ok so my code has been
changed a little bit now this is a list
comprehension where I can introduce a
form but I have to select it
I need to use a form se22 workers oh
tell workers yes I'm not going to
preview it this time just say commit so
now you have the farm introduced and
then again you can do something with
this inner this comprehension in this
case you cannot introduce scale forum
directory because the head of this list
comprehension is not exactly in the
shape that is required by the
transformation here I need a function
call with a single argument so this is
not not really the case here i have a
function here with two arguments so i
have to shave this little bit again
party refactor i have to fix the head of
this list comprehension commit
of course the code is not as nice as
well as before but still semantically
excellent the original one but now i can
introduce a form here so i say from
introduction to workers yes commit yes
and now I have the other forms bar so
this is how you you work with party
how much time do I have it's fine so
what are our expectations against our
tools well this will of course change
the way we think about parallelism or at
least our tool is able to completely
redesign our software automatically or
at least show all possible places where
we can introduce parallelism into our
code we can predict speed up exactly and
the tool does everything by itself you
don't need any interaction with the tool
safe completely safe and completely
automatic of course these are completely
false expectations none of them is true
you should not expect such behavior from
a tool what can we do we can find many
places that we can introduce parallelism
we can predict speed up more or less
precisely not very precisely the level
of precision depends on the depth of the
analysis with reform and the precision
of the cost model that we use the more
precise cost model to use the more
precise predictions for the speed ups
are but if you use a very complicated
customer other than the tool becomes
very slow and of course you don't want
to use it anymore so there should be a
trade-off between applicability and
precision the tool is very good if you
have a you're smart programmer and know
how to use it but it won't work by
itself sometimes it needs input from the
programmer sometimes needs interaction
with the programmer but all in all it
cannot for it can allow you paralyze
your program in a very simple way so you
don't have to think too much you don't
have to read code too much you you get
some easy fertilization not much effort
much game
so that's what we try to offer to you so
the key idea behind our tool is that we
can predict speed up by measuring the
sequential execution time of certain
components in the program we just
generate some random input data measure
the execution time and try to estimate
the parallel execution time with a cosmo
law and if this estimation is good
enough then we can predict the speed up
quite precisely so this is the big
picture of the tool we have lots of long
coat here at the moment we are working
on integrating opencl code into the tool
Chris talked about open CL plus Allen
code refactor together in to use
skeletons that are really heterogeneous
we don't do that at the moment we just
have all anchored at the moment so we do
some static analysis on this airline
code and we try to cost the possible
pattern candidates the static analysis
will find us some pattern candidates
that we can benchmark and applying and
by applying a cost model they can't come
up with some speed up predictions so we
ranked the best candidates and present
it to the user resent them to the user
and the user can apply refactorings to
introduce the required skeletons into
the code so this this first phase this
pattern can't day discovery is is no
magic actually it just goes through the
whole program and tries to identify
certain syntactic structures and also
investigate the semantic properties of
the code at those places for instance it
will fire on on these comprehensions or
it will analyze recursive function
definitions of course you can only apply
a transformation if the preconditions of
that
transformations are matte so we have to
analyze the site conditions of the
transformations as well and what makes
the two really useful in practice we
need to apply some heuristics to improve
the suggestions so for instance we can
or two can identify multiple ways to
introduce skeletons in this code it will
measure some certain components in this
code fragment and it will of course
identify the best possible candidate for
realization so how does the analysis
proceeds we have different kinds of
analysis a combined together since inner
line we can call functions dynamically
we need a good dynamic analysis which is
supported by module scope analysis and
steady cool analysis and and some data
flow analysis and you also need some
type analysis I will tell you later
right but but mother you can find out
you need to identify operations that
work on lists for instance so we need to
find out the list values in our code so
we need to infer tight for certain
expressions and you also need to do some
side effect analysis because the site
conditions of the veterans are often
based on the side effects the possible
side effects of certain expressions so
how can you do these kind of analysis we
have a tool for that that's this long
story that's the stool has been created
like seven years ago it's good for
refactoring it's good for static code
analysis and transformations has lots of
nice features it constructs a program
graph it's not just an AST not justice
in abstract syntax tree but it
constructs more informaton program graph
semantics
graph from from the source code stores
it persistently in a database and you
can use this semantic program graph to
collect information about the code we
can find dependency among program
entities we can identify bugs and track
them down and investigate them we can
also share information among team
members and we can also refactor the
code using this tool I'm not going to
details about this tool just skipping
this slides because I need to hurry a
bit so the pattern candidate discovery
uses the infrastructure provided by the
factor on at the moment we can identify
list operations like these
comprehensions that's target number one
a certain library cause like I show you
what this map is a good target and you
also try to identify map like recursive
functions so we analyzed go c function
definitions and try to try to decide
whether they they operate in a similar
way to to the list map function at the
moment we are able to propose candidates
for task forms and pipelines I'll skip
it a metal I function is something it's
a function it's a recursive function
okay recursive function now I need some
core graph to decide whether a function
is occurs inside the kind of analysis to
decide that there are functions you
cursive it takes a parameter P which
must be a list ok I need some type
analysis to decide whether parameters of
type list and then I need a control flow
graph to investigate the different
execution paths in this function
definition and all the recursive
execution paths by sette must satisfy
certain conditions like they should
return a list are there the head of this
return list should not depend on the
complete list coming into the function
only only the head at that list and yeah
this is a dependency analysis
yeah on the tail of the resulting list
should be the result of the recursive
call on the tail of the input and other
parameters of the recursive call should
not be changed medical recursively the
function again and for the non recursive
execution paths we require the the the
empty list and the function should
return the empty list so this is a
characterization of map like functions
so if we can using our analysis analysis
we can identify these nepeta functions
we can turn them again into a map and
then into a task form one important
concept here is the concept of component
the component is something that is done
by a stage of a pipeline or done by a
worker of a task farm they should be
quite independent from each other so
there should be some side effect
analysis that tells us that ok these
components are possible to run in
parallel there are many sources of side
effects in our line as we know message
passing global variables in C code but
even exceptions can cause impurity
costas made some experiments on how much
percent of typical airline code is pure
it was below ten percent so it's not not
much so we don't want to just deal with
pure definitions they will work with
hygienic components rather so hygienic
components can be characterized by the
resources they use and how they use
those resources so if you have resources
in our source code like ETS tables then
we can decide whether a component oops
whether the component alters this
resource just reads this resource or
does
read or write this resource at all and
we can identify component sets which
which behave well together there is a
simple rule if a component c1 alters the
resource are then another component in
the same component set should not use
read or write this resource and if
component set is constructed of
components with this property then we
can run them in parallel so we can use
them in the body of the skeleton so
these are the analysis that we do so
once we have the this analysis we can do
the benchmarking and then apply a cost
model for benchmarking we split up the
candidates into small fragments and
measure the execution time of those
small fragments on randomly generated
input so we need to compute the free
variables which will be the inputs to
these to these expressions the assemble
new module of these small expressions we
can can instrument it with with the time
measuring functions all this can be done
very easily using the infrastructure
provided by the factory so it's it's
really fun to use effector fault for
these purposes and this is not actually
at one time so we generate these things
while our tool is running by party is
running and then we load this module
generate some random input and profile
the data and make some statistics and
this is how we benchmark the software so
this random input might be really scary
for the first moment it's not always
meaningful of course but if you want to
do some automatic timing profiling then
there is no other way but but generate
some random input so we try to find out
the type of our free variables and use
quick check to generate random data
based on the types but for that of
course we need some type in
which is good enough which which is not
the the success type being provided by
by by typer for instance because typer
is happy to provide any as a type for
everything so we need more conservative
typing at the moment we are using type
of it with specs it works for many cases
but we have to work on on another
approach better type inference algorithm
for this purpose so once we are through
this you can apply the custom model we
have formula that we can use to compute
the estimation for the panel execution
time based on the sequential execution
time but as you see there are some
constants in this formula that need to
be calibrated to the hardware that we
are going to use to run our application
so that's why we have the calibration
phase on the diagram but once we are
through this application of the cost
model then we can present the possible
candidates to our users through the user
interface and you have seen this pattern
candidate browser after ranking the
pattern candidates it provides a
web-based user interface now at the
moment we are working on battery
integration with the max so I i had the
button on the interface to click under
vectoring start automatically but that
button does not work at the moment so
wow this is need to be implemented the
good point in the pattern Kennedy
browser is a little first services for
other software components in the system
it allows us to to export data in
different formats it allows us to
persist data that it produced and that
it also allows multiple users to use the
same code base and the same results of
the pattern candidate discovery as you
have seen we have to apply some shaping
transformations as well before actually
doing the the map or farm introduction
or type in introduction these shipping
transformations might be quite tricky
because we have to consider many
syntactic forms and transform them into
the some canonical form before using the
intro scale refactorings so future work
lots of future work I think we have more
future work than what we have done so
far so its future work is getting always
bigger and bigger at the moment we try
to learn from from bigger examples I
think this is the most important because
we have already used small examples
contrived examples the test or two of it
but now we need big number crunching
Erlang applications if you have such an
application just please send it send it
to us it's a conclusion yes a good logo
yeah Kevin came up with this party name
but we need a good party logo as well
yeah so the conclusion we have shown you
how to use party periphery is the
factoring to for a long beautiful name
without logo that integrates the best of
regular and refactor it can find us
realizable code not all of them but some
of them some interesting ones it can
even predict the speed up if we turn
these code fragments into perla it kind
of for refactoring that facilitate the
introduction of these perilous skeletons
but it always expects the programmer to
be partner in this activity that's all
thank you
so questions I had one and it was about
the profiling do good could things be
dependent on the size of data for
example when you predict that you get a
speed-up of 20 I was thinking that my
team might depend on the size of the
matrix how many how many workers you
might want to have for example is that
is that something you've taken into
account yes but not very very well at
the moment we we try to work with with
some fixed length like 1000 for
everything so that there is a constant
but we need to develop better
measurement approach which which
experiments with different constants
with different sizes and tries to make
the statistics and decide which
measurements are relevant or which are
just you know kind of bad values coming
out from the measurement tools so this
is a weak point at the moment of our
benchmarking and we need to improve that
that's that's very important because the
possible values that can flow into a
function can affect very much around the
sequential execution time and if you
measure like 20 and 120 and 5020 you
just cannot compute the average of these
values because it makes no sense so you
need you need more you need better
statistical methods to to to get the
right information out of these
measurements you need to work on that
yeah interest rate any other questions
doing doing these optimizations it makes
my program very specialized for the
platform it's running on do you have any
thoughts of how you could do it more
general so that you maybe get different
constants for different systems so that
my program is still runnable on many
computers so this is this is not Vader
the calibration part of the cost model
so if you want to calibrate your
application for a given hard that
platform then you have to run this
calibration module on that hardware and
measure for instance how much time it
takes to start to spawn a new Alan
process on that platform how much time
it takes to copy from heat to heap so if
you run your your system on your desktop
machine then of course you should not
use the calibration data that was
collected on your machine you have to
you have to run the calibration on the
target machine and then use the data for
the predictions obtained from those
calibration I hope this answers your
question okay good so let's say thank
you again to tomash
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>