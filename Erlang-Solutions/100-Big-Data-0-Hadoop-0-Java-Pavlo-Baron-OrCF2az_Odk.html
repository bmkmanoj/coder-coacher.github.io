<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>100% Big Data. 0% Hadoop. 0% Java - Pavlo Baron | Coder Coacher - Coaching Coders</title><meta content="100% Big Data. 0% Hadoop. 0% Java - Pavlo Baron - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>100% Big Data. 0% Hadoop. 0% Java - Pavlo Baron</b></h2><h5 class="post__date">2014-05-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/OrCF2az_Odk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">uh well thanks for coming I mean I
didn't expect that
people I didn't even expect that this
will be this big room anyway the
interesting part is the guy with the
camera told me i should point this
screen when i have to point in something
most of the people are on this side
going to be fun okay so one hundred
percent big data 0% hadoop 0% java I'm
Pablo baron from the company code
centric AG do we have people from
Germany in the audience nobody i'm all
alone here okay well basically in
Germany so I'm quite a no-name so I need
to introduce to briefly introduce myself
I wrote a couple of German books and I
assume that nobody have has read them
here in this audience but well overall
up but like I've sell salt like 300 400
copies of them or follow them so it's
okay it's just a hobby well actually
it's i'm using writing books for digging
into things and understanding them
learning them a lot so i spent like two
and a half years writing a german erling
book most of the time it was learning
scratching my head so um well some
people say I'm but I hate Java it's
probably I'm probably known for that
well I don't hate Java and kind of not
really liking this enterprise Java thing
and some people also maybe same people
say I'm grumpy according to my tweets
well the reason for this is I'm in the
middle of my midlife crisis so forgive
me it will pass at some point so the
current book is out there is this orange
one the big data for IT decision makers
and it's an attempt to describe to those
people who actually spend money or have
budgets to describe the whole area and
to make them understand that it's not
all about one single too
but it's more about analytical
approaches it's more about mathematics
and stuff like that different tools
needed to be taken into consideration
does anybody know what big data is here
in this audience oh one guy knows it you
know this what is that how would you say
okay cool our congratulations to know
more than me I've kind of try to
understand this area for a couple of
years well what I've I'll be introducing
here is well an experiment it's not a
production system it's an experiment to
test Erlang in it also has different
things in it and well here's the story
of this all you know this book anybody
from Russia here it's pretty thick and
okay cool we should have a chat
afterwards it's pretty thick and for
more most of the people who had to learn
this also pretty boring anyway I was
sitting in a well in a one-day talk for
a tea decision makers about big data and
blah blah and fubar and whatever and
somebody from the calc company called
intensity they did some some interesting
stuff it looks pretty nice so what would
they actually do this talk social media
in order to find out if somebody is
ranting about the product and then they
just point the company at this problem
so the company can react on this and
they have told that they have like
patents in machine learning and stuff
like that many different things so it
was like Houdini magic you know hoodie
smokes and fire
and I'm sitting there a little bit
skeptic I mean I'm I have more general
knowledge in many things for now over 20
years I'm in this industry kind of
expertise in some of them while
mathematics is not is not really the
expertise of mine but i'm learning hard
so I'm just I'm skeptic i'm typically
step skeptic about things like that and
what i have spoken about looked like a
bunch of cues and pipes and filters and
well some some data being pipeline from
a to beat from to be from b to c then
notifications to somebody it looks like
some some natural language processing
which had did as a hobby a while back
playing around with things well of
course it looks something like some math
and well basically you can you can cover
this with the topic of machine learning
such as thought i'm at this conference
or actually in this place have two
nights in the hotel and my biggest
problem when I'm traveling I can't sleep
in hotels I don't know why but I use
this time to learn new things and then
next day when when I'm going to the
customer I'm sleeping there it's not
very good for business as you can
imagine well anyway I have a half couple
of nights here so let's let's let's do
something I can I can probably think of
something like that so let's see this
piece works
I hope so
so it takes a little time it's an
automated applescript automated
demonstration here just let me wait
because applescript gets confused when i
click around here before things start
actually i can zoom in
okay here we go this is very interesting
what is happening that I can just point
it this windows so um what they did at
this company they I mean they just suck
from data sift stream and analyze this
data well it's pretty expensive when you
want to experiment for this so you would
probably go for the firehouse of Twitter
which is I will explain how good it how
could how bad it is so I've actually
cheated for this demonstration its start
locally so I don't want to rely on on
anything on AP ison whatever because
Twitter does some limitations there
here's the never-ending stream of very
many well tweets this is also something
which does basic filtering I will
explain some concepts here this is the
notification window so this links would
go to the so called Twitter team because
many companies have established
something called Twitter team and this
Twitter team is responsible for well if
somebody writes a tweet about something
they will look at it and say on say come
on maybe you need help or something and
that this one the last one it's just a
MapReduce in parallel to this I've
thought this already in the react store
and it's it's just a small part of very
many tweets being filtered out with with
the essence here getting down to
negative 81 and positive 109 59 of them
so let's just let it run for a while and
get back to the presentation oh yeah
well a little gimmick that I did
afterwards is just whenever I have a
location information I just let make
this green and red dot jump here on the
map it's cool right or you can basically
impress people with this but not the
geeks not the audience here you can
impress you can impress managers with
this so this is so this is Houdini magic
easily so okay so I basically have two
use cases
let's look at how I can get the data in
what you consume from from the stream of
messages where people as I say here
where they say things before they think
about these things also i do on twitter
so this explains this grumpy pot so just
drink this big data warm straight from
the fire house of twitter which is
absolutely limited and you have two
basic use cases one is you need
immediate notification when somebody is
ranting about the product or a company
you would want to react immediately on
it you don't have time to do it once a
day or something because probably the
person who's rented it's typical for
social networks he or she has just
forgotten about this next day when you
come back to it so you need to react on
this I've learned from from some
customers that they have been real huge
problems when when somebody is renting
about the product and the whole
revolution starts so people start
burning this product so this things
happened so you want to be fast there
and the batch part of it is what will
you do some well this this are collect
information and then run some statistics
on this on this whole stuff in order to
understand how a product would perform
maybe make some predictions for the next
month maybe just kick this product if it
doesn't perform according to social
media so here are the bubbles because we
always need an architecture picture so
it's pretty simple fees come in get cute
get filtered this is a very important
part I will I will emphasize this later
get filtered then I fork fork 3 q's
again for alerting where somebody would
react this is what you saw in the right
top window it gets cute former life so I
don't have a date data
iOS will actually I just cut off some
information from the tweets formalize
them store and then I can do my batch
through q I will explain this part as
well because of Technology I use that
then I just run MapReduce jobs and do
some sentiment analysis aggregate the
results and can report and somebody will
react on this as well pretty simple no
real Houdini magic so what is the tech
here both two languages Python in
darling well it's not only Erling it's
also Python so twee p is for for the
twitter firehouse and i also
experimented with some crawlers and
stuff but it's not in the demo here so
queuing is done with rabbitmq through
topeka rabbitmq is also system written
in Erling so we are in there at the
erling conference also fits kind of we
will explain it in a little so react
through protocol buffs normal MapReduce
with a modified version of this code
this is probably something where I spent
most of my time during this couple of
nights playing with this you know this
con ever heard of disco okay ever
compared disco with Hadoop nobody okay
we will talk about this briefly so
whether this this jumping dot is just
web stomp plug-in on rabbit chair vector
map and stuff like that oh yeah I've
also implemented a a corpus for those
from you who know about natural language
processing what is the corpus I will
also explain this briefly in a little
just a little so what is the math
mathematical part of it it's also pretty
boring for those who are into
mathematics analytics are done with NLP
through NLT k and l TK is the library
for natural language processing well
it's Python well it's kind of Fortran
and C underneath but it has a Python API
let's look pythonic algorithmic training
is an l TK trainers it's not very
interesting for the earning community
algorithms nave bias it's absolute
sufficient because of the nature of
tweets and how people tweet where well
how you build the sentence doesn't make
a lot of sense all the time or most of
the time so it's absolutely okay to do
nae of bias on it decision tree for some
well for just for here are critical
decision here trigrams for language
recognition and so on and so forth we
will go through it a little I'll also
filter so this is probably the very
important part because what I experience
with Big Data projects and I'm doing
this Big Data projects trying to avoid
making myself an evil person but well we
know about recent developments in this
area I don't have to mention them but
anyway so people most of the people are
right now just collecting data
everything which comes in everything
they can buy the just collecting it they
almost do nothing with it and from my
point of view what I've learnt and I'm
not the expert in statistics and stuff
but still when you want your
mathematical or math based analysis
which is given it has to be math based
when you want it to be a real good you
have to clean your data you have to
filter every garbage coming in you
surely need something like a explore
exploratory analytics but you can do it
on samples you can just write like two
three days store them to the data store
or wherever you want them to have and
then you would try to find buttons and
stuff like that I'm not into collecting
everything flying in so I'm more into
filtering upfront and ensuring that the
algorithms don't have garbage to compute
on so simple name and tanta blood
filtering is also down here with with
some own coopera i will also explain
this sentiment analysis is based on
public and owned cooperative will also
be explained and i also filter trolls
because
because of the nature of Twitter fire
hose did anybody if you do any work on
the social social media streams or
something you know about okay happy with
this it gets less and less everyday
right what you get out there well it has
a reason because they want to sell this
data actually and want to avoid foreign
clients because they can otherwise sell
sell ads through their own clients and
stuff like that well I can understand
this development well about some numbers
it's not successfully it's just the
numbers numbers are sexy so yeah I'm
also not into these numbers porn for
what I did here it was sufficient to run
this on this machine and you don't need
huge clusters for this huge Hadoop
clusters where you just well used maybe
two percent of the whole machinery per
machine because you don't know what you
do there so some numbers here it's very
important to impress people with numbers
managers are very easily impressed by
numbers when you say I can process like
terabytes of data per second and I don't
even have to store this data everybody's
immediately impressed geeks who are at
this conference will ask or probably
when they do stream processing I love
this this stream processing arm
benchmarks because they compare each
other or each other with each other by
saying hey I can process 10 millions of
events per second yes well theoretically
but as soon as you have some logic there
and Sunnis to start compute as students
to start running mathematical algorithm
algorithms on this which are more
complex than just building sums it gets
real nasty so it from my point of view
this this benchmarks are not very
well don't say a lot but still we can
impress people with numbers so here's
some numbers on this MBA not very
impressive but still you get round about
10,000 chaotic text messages from the
feed from the fires of a fire hose I can
easily process them because I'm doing
queuing I mean when you queue and you
have kind of memory so you can fill up
your cues I store around about 8,000
messages per minute here in a react with
n of three with three notes here on with
on this one machine analytics are done
well the basic analytics filtering and
then just the positive negative
aggregation and stuff like that is done
well around about 7,000 messages per
minute in this team or you see round
about one and a half million tweets
thought and this machine in one file I
don't suck from from the firehose
because it wouldn't get it wouldn't give
you this performance there or it was
living it would limit you out actually
at some point so I've just stored them
and I'm processing than in the demo it
runs in about the stream processing in
about seven minutes and this map
produced was just easy on several
thousand stored events ian stewart
messages so what is more important is
I've actually learned a lot in a couple
of nights so when you when you go for
social media streams however they call
them you will get these people there you
know about the believers does anybody do
then I have fans of Justin Bieber he
endures in this room who yeah I'm also
into progressive rock man so it's cool
whatever progress if it is anyway um I
was fluted is this the word bread like
bye-bye I just had the feeling that
almost everything is a believer on
Twitter so I roughly did it I could I
did a rough calculation
that just found out that it's about
sixty percent of what I get from the
sample stream and what is the sample
stream on Twitter you get a 1 second
sample which is it maximum one percent
of all tweets all over the world and
this sample is equal for anybody who
will access this stream or sat from the
screen stream in this second so
everybody is equal that and you get run
about sixty percent of garbage it's real
garbage its I mean well it's not useful
almost the whole rest of it are trolls
and people that are not serious people
like me tweeting sometimes I'm serious
so I ended up implementing something
that it that was real nasty I have it
out on github as well it's called WP
coppers so what I did is I just I've got
myself a Wikipedia dump and Wikipedia is
well we can argue about the quality of
categorization on wiki Wikipedia because
well it's crowd-sourced right so where
people have no real direct moderation
control there they can put any category
on any article basically but anyway it
gives you categories did anybody if you
do any natural language processing or
heard about it read about it okay well I
mean you don't need to be expert these
days to exit actually to actually be
able to start with this so what does the
corpus corpus is a a collection of tact
or classify it something so it can be
text most of the time it's texts and
when you when you wanted to classify a
negative and positive well sentiment for
example you can go with the corpus which
is protect or pre classified where left
is well thousand documents are negative
thousand documental positives so you can
train your algorithms on this and
afterwards you can just send your text
through this algorithm sent it will try
to find out if it's more negative for
it's more poisonous positive and so on
and so forth without digging deep into
it I've implemented a a corpus
well it's an active corpus so it's not
only text which is text so I have a
small database well it's not written
nothing it's by tables it's good for
indexing things our spy chthonic with a
lot of C code so anyway what this corpus
does is pretty simple I just can combine
several categories of with Wikipedia
articles into one class or one anti
class for example then I can do binary
classification say it's left or it's
right yeah for those of you who are
interested can look it up on github
let's look at filtering filtering is
pretty complex thing generally I would
never underestimate filtering you know
about this guy dhh anybody doing Ruby
here okay well he's an awesome awesome
hacker he's real cool but uh his name
his readable name is dhh we all know
probably those who are into it no who is
dhh right aah how would computer know
about this it's not a real name it's
like something it's just three
characters here so it's pretty pretty
complex to filter based on on real names
from Bayes filter the Twitter stream or
things like that observe profile buyers
in this community this guy should be
well-known you know James colleague real
awesome hack a deep low level but look
at the profile bio i think is he has he
still has this one so well i would
filter well very negative stuff this one
will just fall through right and when
this guy with his three or four thousand
followers rants about the product this
can have influenced not an easy problem
v here you go i owe you an explanation
on this one well it's pretty easy when
we met in san francisco year back and
six months
afterwards your tweets were marked with
San Francisco for you just went back to
Israel and I mean and you cannot rely on
location well you can't even rely on
location set set by people themselves
because my location I just say this or
something different now this is the
location string there where is that
where is that language recognition wow
that's not an easy problem Google is the
best has the best well publicly
available language recognition
technology around but you can also fool
Google's engine into chaos like when you
when you use lead it will just recognize
it as German yes well because because of
based on my IP address it doesn't have
any chance anymore it will just say okay
he's from Germany so that's let's assume
it's German so what work pretty well was
i used spanish i used an l TK all the
time so it has a couple of copper copper
that you can use in order to recognize
language so it's it's it's done with
trigrams trigrams are like three letters
are together so you can measure it you
can also do an AF bias on it on whenever
you like and you can do well poor guys
language recognition with this so
Spanish worked like a magnet for
everything except German and English for
every single language and I also only
one wanted to know about English and
German rents so it was ok somebody told
me that that spanish and arab ian has
some some common roots i cannot say if
it's true but probably this explains
this in a way so I mean it's well
Unicode and stuff ok
this coil let's let's get back to our
language is more important for this
conference so what I wanted to do was I
wanted to store my stuff I wanted to
store all the messages in a react store
because i'm a real react fan i'm doing a
lot of work with react and so there is
one problem when you have a data store
and you want to run MapReduce well with
the tool like a duper disco this problem
is called data locality when you don't
run your mappers well well parts of
reduces however you have your topology
that when you don't run mappers on the
same notes in the same machines where
the data is actually stored on
physically you will have to move the
data around and this will take a lot of
time and I'm not the fan and losing of
losing time even if you can effort this
so my idea was to teach disco to sit
directly on react nodes and two suck
directly from the machine where this one
disca node is running on so the mapper
would just wouldn't have to to rely on
the data lying on some different nodes
we just get it from the note it's on oh
well that was a pain in the ass to be
honest it wasn't that easy this guy's a
pretty cool system you should go through
the code it's built very well and it
combines Erling and python and T&amp;amp;T see
that it's done by by good programmers
well my problem was I want I didn't want
only to extend it I had to modify the
kernel of it the very kernel of it in
order to run our line code as ASCII
mother or scheme they call it the skin
and then to accept they have this GD FS
as the underlying data file system or a
pseudo file system so i wanted react to
do this job well those of you who have
been digging real code will know that
well yet basically you can ask react as
a store as a whole
give me data so it will flood you with
data then well it's not accessing by key
so it will flood you when you're not
fast enough it will penalize you it will
it will stop transferring at some point
when you're not fast enough but anyway
this is not the problem the problem is I
wanted to read from one node I'm on this
note I didn't want them than to agree on
something I didn't want to go through
coordinator because data would flow from
node to know before I even get it in the
disco node so the basic idea was to go
low level asked Scott fritsche for for
help and he pointed me at some functions
I could use so I'm sucking straight from
from V nodes so when you have n of three
you can assume that there are well at
least three copies of the same key
somewhere in the store so I also
experimented with some probabilistic
approaches that I didn't come very far
but well actually when when it's
sunshine scenario you can just divide
the results by three but it's not that
easy in the production system would
never be easy like that so some more
work needs to be done there and what is
more important you want to be very fast
there so i started going with with
discos approach to this when data gets
delivered to you would go with a with a
unix pipe there and will pipe the data
through it's not fast enough so i used
RabbitMQ and I'm just filling up react
writes our really notes deliver data
straight to rabbit q and i will just
consumed from it in the loosely coupled
way then north is it has not nothing to
do with our line but it is a very
well-known and smart guy brought me to
this idea actually I kind of could think
of it of my on my own but well didn't
have that much time during this hack oh
well
mixing languages in one project I like
Python I seriously like Python for well
python is a foundation for very many of
very many scientific libraries and stuff
like that but when you know when you're
doing a project within let's say 20
hours and you have to quickly switch
from one language to the other they have
almost nothing in common right so I just
forgot punctuation in darling all the
time and on the other on the other hand
what the feature that I really like
about Erling is the pattern matching you
can put a match everything in the
Erlanger this is probably the only
language where you can pattern match
everything you can putt and match
function head so you can pattern match
our messages you can put an edge match
everything it's pretty cool but I don't
have to explain this to this community
well embedding pattern in darling would
be a real pain in the ass but let's keep
this one let's get back to sentiment
analysis does everybody know what
sentiment analysis is cool awesome I had
to learn how to do it right it's in my
case it's about strong sentiment
analysis but look at this tweet
I mean we are human are we able to say
this is positive for its negative ha
well when you when you and the Machine
and you would try to count this features
here you will probably end up with zero
like it can be positive it can be
negative I'm not sure well you can also
say call this for some people something
negative oh my god is something positive
whatever it's hard it's a real hard job
to first of all to classify human text
and then to classify something which is
absolutely chaotic and this descendants
building there is like well I mean with
tweet we probably should shoot invest
more time into into building correct
sentences and twitter as well but I
think it's not the right platform for
that so i ended up for strong sentiment
analysis or for classification of
negative and positive text i ended up
creating another coopera well it was one
corpus and another experiment you know
these two guys well lynus of course he's
the one who's changed the world but when
you want to go for a negative text you
would just pick any obvious rents in any
of the forums he's communicating through
seriously I mean this is negative I mean
he's an absolutely smart guy who has
managed to change the world in a way but
still from the perspective of the text
it's negative like you are mr own man
and then you have the NEX planation so
probably you would drop the explanation
go with a with some part of it I just
said it's negative you do you know the
other one any Python guys here around
this is probably not the most popular
person in the earlier community his name
is that Shaw that is a well from from my
point of view as a great hacker but he's
kind of
out and very he has a strong opinion so
when you read something like programmers
need to learn statistics or I will kill
them all I can't really disagree with
well I understand the meaning of this
sentence but I can't really disagree but
you can absolutely say it's negative so
the whole text which comes afterwards is
also negative so just I just picked them
all all of the wealth from from some
blocks and stuff just a couple of
articles and had like hundreds of them
and said this is negative so I had a
stronger negative classification ability
there frequently asked questions before
you ask questions i will ask these
questions myself why am I doing this
well I want I want I'm learning all the
time most of the time I'm learning to be
honest and I wanted to go deep this is
also why i started doing erling back in
two thousand five or experimenting with
him i'm not really doing any serious
early based implementation some more
general generally into technologies and
things like that I'm probably known by
some of you by starting the project
called react Mongo ever heard of it was
an attempt to sell to Rio to Mongo
clients sell react as the Mongo database
so digging into mongos wild protocol and
experimenting with this we did it's
together with kresson until we ran into
some problems that it's outside of the
topic here so it's very interesting to
combine computer science with math
however lang whatever language you use
them why not just use to do this is the
most interesting question here yes well
I didn't I really didn't want to run
this one on the JVM I just wanted to see
something different my first language
was it was assembly back in in the 90s
and well the JVM came along and I did
some java work for business as well I
absolutely admit this I was still doing
this and I have this to use cases I have
this MapReduce stuff and I have this
immediate notification thinking where I
absolutely
no from my own experience I did some
work with the dupes and well more or
less serious work it will probably never
get there to be a real time near real
time I mean real time is a different
term for computer scientist and from for
marketing people but still it's not
there to do this work it's a batch
processor basically so why didn't didn't
I want to run this on the JVM it's
pretty easy well the JVM is growing in
terms of big data and stuff like that
all this I mean along the Hadoop
ecosystem has around about 160 project
around projects around every now and
then a new one is popping up those of
you who did Java will probably know this
one no maven this is real big date on
your machine and well yes I want to find
alternatives to the ecosystem I wouldn't
go deeper in with this one you probably
know this game yeah why queuing all the
others can do gazillions of messages per
second like trillions messages per
second and stuff like that without
queuing well by the by the end of the
day it's either cuse or ring buffer so
whatever structures you use you will
blow up your memories I mean it's that
it's a limited number of data structures
that you can use that and I'm what you
need to know is what it's not it's not a
new thing but whenever you floote your
data store with data you probably want
is separated from the data delivery with
a queue it's a good idea is seriously
good idea even with react as well why
erling in Python well disco uses both
RabbitMQ I'm a big fan of rabbit it's
written in early and react it's written
in Erlang and see and so this explains
this languages I just wanted to keep it
small so it's just two of them and well
yes python is very popular among
scientists probably more popular
than Java so I think that everybody
who's doing this this well analytical
work should actually go with Python and
are and things like that before even
trying to implement it in Java well yes
isn't pythons slow yes at some points
its low it can be where you can use pie
pie and go with C Python whatever but
for my numbers it was sufficient it's
not important to this conference mba is
pouring how about web scale we know
about web scale let's make it web-scale
well actually I'm operating on web data
right so Twitter doesn't give me more
but I can go with data safe talk nib who
are delivering biggest dreams like ten
percent of everything I can suck from it
and is it's real it's a lot of
information coming in so let's let's
just look at scalability points it's
rabbit I can scale with rabbit I can
scale my q second scale through
exchanges and stuff like that I can
start scale storage with react and I can
swear it works yeah I'm almost done and
I can also scale with disco in this case
well it's still an experiment so disco
notes are running on react notes it's
sooner from react point of view it's not
probably not the best solution so I can
also scale with feeds and streams and
whatever comes in so yes web scale
what's in the future what I have
considered I didn't I didn't come far
enough I wanted to do two things
implementing p Clayton angel in Python
it's not interesting but contributing to
disco it's a little bit hard from the
time perspective right now contributing
to disco just merging what I did with
what they are doing seems to be
interesting for these guys as well so
let's just finish this one what is the
big data because I'm all the time big
data you when you do a big data project
whatever however small it is you have to
answer to three questions what what I
want to do what I what is it what I want
to know then you will find out the
analytical model for this in order to
answer these questions and then you will
decide what tools this are
and it's not only one to want to do
whatever the next very interesting thing
is this perspective of filtering don't
let garbage come into your data stores
don't expect this huge data amounts and
this is the big dismiss interpretation
of this big in this nonsense term namely
don't let garbage come in because
garbage in garbage out I mean the rule
is very old it's older than my
grandfather so don't let this garbage
come in just concentrate on building
quality models around quality data and
ensure that the data which is stored for
analytics is clean enough for explore
exploratory analytics you would have
liked chaotic samples but you will try
to find out some some patterns and then
you will know what you have to clean out
those who might know who are collecting
everything they don't analyze this they
have never did this seriously and this
is the main thing and experiments like
this can can even bring you further in
this area whatever tools this are we
should be open for tools and this is
basically if with this presentation
thank you very much thanks Buffalo</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>