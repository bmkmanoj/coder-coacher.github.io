<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Container Orchestration and Software Defined Network: A Field Report by Sargun Dhillon | Coder Coacher - Coaching Coders</title><meta content="Container Orchestration and Software Defined Network: A Field Report by Sargun Dhillon - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Container Orchestration and Software Defined Network: A Field Report by Sargun Dhillon</b></h2><h5 class="post__date">2016-09-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Ixk68ioyL8Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so yet today when we talk about
container orchestration and our
experiences with it at Mesa sphere but
first let me talk a little bit about my
background um so when I started my
career I used to be a sysadmin I used to
be responsible for setting up data
centers and over time I transitioned
into network engineering a transition
into setting up switches routers very
traditional um but that in particularly
interests me so I switched over to
software engineering and what I realized
was that we have yet to apply the
techniques that software engineers have
the tools that software engineers have
to do networking in system
administration and my mission is to
allow sis admin's in network admins to
be able to leverage the acumen it's been
developed in distributed systems and to
have a proper approach to to this versus
a lot of hand waving in addition to that
one of the things that that is a
challenge that every system in suffers
is as they evolve their infrastructure
they always have to build orchestration
systems to automate it at Mesa sphere
ideally I want to build the container
orchestration system that I can take
anywhere and use in the future so a
little bit of an agenda of today's talk
I want to talk about a brief history of
how we got here how we got here as an
industry and in that why infrastructure
looks the way that it does how we're
trying to make this better atmosphere in
some systems that we've built a Mesa
sphere to enable us to ship this
technology so with this still talk about
a brief history of networks in the data
center but we can't talk about
networking in the data center without
organizations so I want to start in 2007
about 10 years ago in data centers in
the way that software was run was
dramatically different than it is today
in 2007 the term DevOps was not heard of
and with his clear differentiation of
responsibilities we had QA weird ops and
dev and these organizations had an
adversarial relationship and the purpose
of this was to ensure stability but it
meant that organizations were incredibly
slow moving and software that was
developed in 2007 was also dramatically
different microservices weren't really a
thing people were shopping together
psoas but you would strap together so
about having your favorite Enterprise
Service bus um also networking was
dramatically different networks with
these giant layer two domains and the
dis resulted in
significant overhead you typically
wasted fifty percent your network
capacity for redundancy and all of your
components were provided via these big
pieces of hardware that there were total
black boxes so your load balancers in
Hardware you had firewalls and hardware
and one of the reasons of this was most
people around their own data centers
whether they they bought the hardwood
themselves or outsource it to someone
like a rackspace people weren't able to
take advantage of economies of scale and
given that my talk is largely scope to
do SAS companies in internet companies
most of them had statically partition
systems you chopped up a system at the
beginning when you installed it it did a
few things and it did them very very
well but SAS was continuing to grow at
an incredible rate and amongst ask
companies there became a race to ship
faster in the only way that we were able
to keep software alive was by feeding it
with sis admin's we kept the machines
alive by feeding the mudblood and this
obviously wasn't working so in 2008 the
the industry started to move and the
term DevOps was was coined and a year
later the first DevOps day happened and
that the trim took off I mean develops
is the application of developer tools to
operations in in this was also because
organization started to adopt the cloud
and you have fewer experts in in systems
you have to have fewer experts in
hardware but there was also this this
notion we need to reduce the number of
operators and the only way to do this
was producing software also software
began to change in 2008 tools like
puppet and chef to automate operations
became popular even though they had
existed for a number of years we also
saw this on the dev side where we had
tools like Jenkins in Capistrano where
we had we enable developers to go ahead
and deploy software to production
without having to consult ops we also
saw the the many pieces of software like
Hadoop come about and the no sequels
come about that that tended to push
hardware much much further but
unfortunately we we still had statically
partition machines and networking was
largely owned by a separate group in the
company and they still had someone for
an adversarial relationship but in 2011
a lot of this changes
and this changes because of this
technology called Sdn software-defined
networking or an FV network function
virtualization it's the idea of taking a
piece of hardware or some function that
would typically be implemented in a
piece of hardware and implementing in a
piece of software in the reason if this
is that virtualization starts to make
massive inroads in the enterprise and
VMS become one of the default ways to
deploy things because to the society of
the private cloud and also the the
public cloud starts to become reasonable
in 2011 it changed from if you were
buying your own hardware you were an
auto start up versus deploying on ec2
not only this but software development
changed we started to see these things
called microservices come about and and
people were still kind of figuring out
what they were looking like but but
there was an obvious need that we needed
better networking to make these work
because they had more reliance on the
network and in 2013 this all comes to a
head dynamic partitioning starts to make
inroads in the SAS industry even though
several large companies were doing this
prior it finally became accessible to
these smaller organizations and this is
largely because these microservices
counts explode if you if you look at
like LinkedIn and Twitter they talked
about how they had hundreds of services
running in production and also like
Google releases their own mega paper
Apache Aurora the scheduler twitter is
open sourced and we see the Apache mesos
project get a lot of commercial backing
we also see containerisation technology
finally come to a head we see docker
becoming released in its an instant hit
we also see DevOps from the other side
we see site reliability engineering
which was taking software engineers and
having them do ops so finally we were
able to change things so everything was
changing but why fundamentally was
everything changing it was changing
because the business value and what that
means at the end of the day is money the
benefits of doing all this were
reduction cost of goods sold we're able
to have fewer engineers we are able to
have fewer engineers with more servers
and more capabilities and not only did
this mean a reduction of costs of goods
sold it meant that we had a better
availability and we will
features faster to production because
with fewer engineers we had less
complexity and we had less coordination
to do within these organizations but
fundamentally this all came at a cost
and this cost was complexity so in the
old world you had something like this
where you had a client that sat on a
given node you had a load balancer at a
given fixed IP and port you had servers
and they'd all be running a given
service on the same port in this was a
large in static environment you never
change his configuration unless you were
growing your infrastructure but in the
new world we were like well my app
instances might move around so we need
this the side card that that is able to
tell me where they are but my client app
has this notion that it has this fixed
load balancer I don't want to change
this so now we need to add some kind of
proxy to go ahead and perform the
behavior that my load balancers used to
and these need to rendezvous somewhere
so I need a centralized registry in this
is a lot of complexity if we dive deeper
into one of these individual containers
we start to see things like iptables
gene at to become required and we start
to see all these these sidecars they add
a lot of complexity and suddenly
engineers have to learn all these terms
a VX plan for overlays they have to
understand what like raft is for a TD
and this is really complicated so it's
time for something new and that's where
bcos came about so the idea of D cos
it's a data center operating system that
is meant to include everything you need
to advance from 2007 to today it
includes networking security stateful
applications and in orchestrates our
data center for you and the idea is that
you you're able to do this in your own
data center and if you'd like you can
treat it as a total black box you don't
have to understand what's what's
happening under the hood but back to our
story our story starts in November 2015
when would Mesa sphere first started to
build out their network team met that
time our network features were pretty
limited all we had was service discovery
in in we again had this problem where
are my containers running and we can't
just have them on static ports and the
reason why is because you might have
multiple containers that have the same
function scheduled on the same host and
therefore these these poor
have to be chosen dynamically whereas in
the old world every container had an
individual IP so we have to let me sis
are scheduled or choose airports so
fundamentally how do you find these
tasks you have to have some kind of
directory and the common directory for
the internet is DNS so we built this
thing called mrs. DNS and the way that
makes this DNS worked was that you had
your missus master that had all of your
state information and mesas DNS
constantly pulled this master and this
is a master that had updates every 30
seconds every minute and then all of
your tasks were able to go ahead and
query this information from asos DNS
this mostly worked but it had some
problems so it was based on DNS SRV
based service discovery and for those
who don't know SRV records are these
these things that contain information
about a hostname ports weights
priorities etc in our thought was that
everybody has DNS it fundamentally it's
one of those building blocks and
applications in the internet and even G
Lib C has a bug open to go ahead and
support these SRV records and everyone
has G lipsy but it turns out this bug
was opened in 2005 and nobody really
supported this so we needed a solution
that actually worked given this we
performed in lieu de loop we wanted to
figure out what the rest of the industry
was doing we wanted to come up with some
ideas of her own and then act on them so
we looked at what the rest of the
industry was doing about a year ago and
we had these advanced companies that
were rolling their own service discovery
solutions on top of things at console
and that's ed we had people who were
taking things like super and taking
client-side stacks like finagle in in
pairing them but we still saw a massive
number of organizations with these
existing static service discovery
solutions like Amazon lb or hardware
load balancers and they were really
happy but fundamentally we realized that
service discoveries an afterthought
nobody wants to do service discovery
nobody wants the networking it's just
something that you have to do with these
micro services we also wanted to look at
people's assumptions people assume
things like reliable DNS people assume
things like IP per application instance
as they're developing their applications
but what we were wrong about is it that
only some people
care about performance and only some
people care about security in the the
biggest surprise to us was that nobody
wants to actually change their
application to go ahead and move on to
new infrastructure the idea of changing
the application code to adapt
infrastructure is somehow really scares
a lot of the developers that we talked
to and still yet no one wants to talk to
their network engineer network
engineering has remained this awkward
position in organizations in this
awkward department in organizations
where it's there's the adversarial
relationship so with that we came up
with some core networking tenants in DC
OS and our core tenants were that DCOs
must be agnostic the environment that
it's deployed on it must be able to
round asier GC AWS any cloud in the
world and we should be able to have
application developers run their
software on our platform without having
to adapt to our platform in order to do
this our platform must provide existing
services so things like hardware load
balancers or things that mimic hardware
load balancers at least in the biggest
aspect of this is that we don't want to
have to change an organization for them
to adopt a cos is then it'll never
happen so with that we decided to go
ahead and build some things and the way
that the D cos architecture works is
that we had a bunch of poly vault
microservices so we have the JVM C++
Python go etc so I'll deploy it on on
boxes throughout the data center but but
what did we end up building we ended up
building a service discovery system load
balancing and a control plane to go
ahead and glue this all together in with
this we were able to introduce several
new Erlang microservices or services to
the dcs architecture in it i'm going to
go and talk about some of these services
so the first one is is our networking
control plane nav start and the purpose
of the networking control plane is to go
ahead and run on every node and to
interface with their state score lash-up
which i'll be talking about a little bit
later and to go ahead and share state
information like routing tables like
service discovery records and push these
to the relevant nodes in the relevant
systems and subsystems so things that
the colonel
things like my toes etc and i'll be
talking about it a lot but fundamentally
what it is is it's a building block it's
a building block to go ahead and build
the rest of our service discovery on
it's a building block to build the rest
of our networking on the the next system
that we built was our DNS story um and
we have this disdaining called Spartan
and it again runs on on every node
inside the data center so previously in
order to make DNS highly available
people did things like this where they
had a hardware load balancer that was
running an active passive or they were
using any cast and they had some dns
servers behind this in this
infrastructure work really well for
these people but it required a had them
make the assumption that their
infrastructure was a hundred percent
reliable or it allowed them to make that
because they had so many levels of
redundancy but without this the way that
normal DNS works is that you have a user
with the DNS client and in a resolve
column for some sort of reference if the
DNS servers and typically what happens
is that your DNS client sends a request
to your first DMS server and you get a
reply and this is great but but the
failure case for DNS is pretty awful so
in the not so ideal case you send a
request your DNS server and you have to
wait at least one second for a reply
because with UDP we don't necessarily
get a knack we don't get an immediate
knack and then there's not persistent
connections here and the DNS standard
advises to think in seconds peace when
it was built that the swim intense so
then we send it to our next DNS server
and we wait at least a second and then
we finally get this time out but but
multi second time outs really don't make
sense in the modern world if you're
doing things like Ruby or know Jas or
Python in your front end you're single
threaded and if you're waiting for all
of your front ends to to wait on DNS as
your DNS infrastructure is healing you
can take out an entire application very
very easily so what Spartan does Spartan
dual dispatches these DNS requests to
multiple back-end servers and it allows
the first server to respond and goes
ahead and forwards a request back to the
user and it sees the second server
respond and it stores that information
about availability and this allows
Spartan to control timeouts
so we can do sub-second timeouts the
other thing that it allows us to do is
edge DNS so I mentioned navistar earlier
and what Napster allows us to do is it
allows us to take third-party components
so things like Active Directory DNS Mesa
SDNS perhaps in individuals independent
internal dns and it allows us to pump
that into Spartan on every node and this
means that DNS is it's it's highly
available because you every node is
independently running their own DNS
server and it also allows us to lower
average latency because you never have
to go off node to get this data and we
can control DNS in a way that you
wouldn't be able to with good things
like GMC the next system that we built
was a minute manner or a load balancer
and in order to talk about this we have
to talk about how the actual connection
process works so if you have a client
that the client calls into this is
caller and in the cisco lair it calls
down to the tcp stack and that does all
of its magic but there's this thing
underneath the tcp staff called
netfilter and some of you may have heard
of it enables tools like IP tables and
if tables etc this is all in kernel land
and this is where minute man lives
minute man goes ahead and interfaces
with netfilter and their state store to
go ahead and allow you to connect back
to servers transparently without having
to reason about the fact that you're
connecting through a load balancer but
let's dive in to a little bit more
detail about how this works so again we
have our state store wash up that tells
us that there's a VIP that exists the
virtual IP that exists with the given IP
port and a set of back ends and
minuteman goes ahead and whispers this
data to the colonel to program in these
exceptional flows and when the user
first connects to this given application
the colonel punts that connection over
to minuteman and we can go ahead and
write a mapping to the back end that we
want for that connection and then this
connection goes through the kernel for
the rest of its life time so that the
benefits of minuteman are that it gives
the appearance of a fixed load balancer
and it's fully distributed again because
it runs on
every independent node and we were able
to take advantage of the Colonel's data
plane and in the fact that it's written
in Erlang is it's really nice because
the the latency guarantees that were
able to provide for time to first byte
can be tightly bounded since every one
of these connections is an individual
process but these systems aren't
particularly interesting by themselves
we're to talk about how we we tie this
all together and I think that this is
the real innovation in our system so
there's a bunch of global state in the
system that I talked about so these load
balancer task mappings that we have in a
minute man we have these DNS zones with
with independent records we have these
these routing tables and we have
implicit Information Act reach ability
is a node up is a node faltering etc and
this is a fundamental problem when you
have a lot of computers because you have
constant churn amongst all these
computers virtual IPS might be going up
and down tasks might be starting and
stopping and you're trying to figure out
the availability for your your neighbors
and sometimes these computers break and
sometimes a lot of these break but
sometimes you don't know if they're
broken or not they're in this kind of
weird state and fundamentally this is a
signaling problem it's a problem of how
do you go ahead and message to all the
nodes that require this information what
the state of the network is what the
state of all the nodes are and the the
typical answer to this is use zookeeper
because it's it's something that's been
around for ten years it works Hadoop
uses it yeah it's a reliable system but
at Mesa sphere we we know about
zookeeper going back to our
microservices architecture here
zookeepers is kind of at the center of
our architecture we know how it fails
and we know how it works in it works
pretty well usually but but when you
haven't things like network partitions
occur it fails in in dramatic ways in
you really don't want this when you're
on a non-prime environment and you have
no assisted man or you have no software
engineer to go ahead and fix this so we
said well how else can we do this and
the knave answer is what we have in
industrial today which is everyone just
kind of connects that
one in the OTP team is working on this
but we needed a solution about a year
ago in the problem with this is that it
generates a massive amount of
information and every computer would
just be sending out TCP packets all day
long and you wouldn't actually be able
to get anything done unless every
computer was down little supercomputer
so we thought we also solved this and
without we looked at academia in it
turns out the academia has spent 10 plus
years on figuring out how to do things
like failure detection on how to do
things like building efficient overlays
and with this we came up with our
control plane lascia and we said well
how do we scale this naive approach how
do we scale this negative approach away
from a complete graph it really is that
we don't need a complete graph in fact
we just need a sparse connected graph
but how do you go from having these
discrete nodes that are all over the
place having this disconnected graph and
how do you do this in an efficient
manner so we look to this protocol
called a hyper view and hyper view is
this protocol that allows you to have a
fixed active view to a given set of
nodes so this is a constant number in
the examples here I'm going to be using
a three in production we use seven
because in the paper they talk about
some these two Nobles and we've toonder
our system to about 10,000 nodes so at
boot time you have a little bit of
information you have these contact nodes
these leaders inside of the network and
what nme leaders I don't mean leaders in
the sense they're actually orchestrating
very much they're just knows that are
always going to be available at a given
address and they they only need to be up
at boot time so when a given agent comes
up it can go ahead and connect to these
nodes and since they haven't violated
the size of their active views they are
perfectly fine accepting these
connections and we can build up the
network but if more connections or more
nodes connect to them they have to shed
some of their previous connections and
they have to shrink their active view in
order to maintain that K and they can go
ahead and ask nodes to
connect to other nodes in the network by
forwarding these drawing requests and
shedding this load from the decor of the
network and with this were able to build
up this graph and these messages are
forwarded throughout the network until
we finally get a connected graph the
connected graph but it's an incomplete
graph which allows us to have low
replication but it allows us to have
redundant paths in the network but this
isn't particularly interesting this
isn't particularly interesting unless it
responds to failure because we have this
problem of reach ability information we
have this problem do we note a note is
up or not and if every node still had a
pessimistically health check every other
node we would have massive overhead
still so with this we we came up with
the idea of constant adaptive health
checks and what of this was borrowed
from the swim work and in a gossip style
failure detector so let's say that you
have four nodes ABC and D in this case
and a fails now if every node is held
checking every other node every 200
milliseconds let's say or everyone if
it's situations disease every 200
milliseconds you're still going to
generate a quite a bit of information
and you're still going to require these
these tight timer loops and in there's a
lot of negative side effects because
we're running along other processes and
those other processes might be massive
jvms they might be Hadoop they might
take up the entire machine so we can't
have constant health checks that are
very very tight and interval so instead
we said well why not ensure that every
machine is health check every so often
but given that it has enough adjacencies
we can rely on the the majority vote to
decide whether or notice down or not so
when a node fails or when we think a
node fails let's say that B has observed
a is failed it goes ahead and messages
to c and d and asks have you seen it
fail as well and if those nodes have
decided that that notice failed they go
ahead and they disconnect from it and
they route around it and the hyper view
protocol runs again and you go ahead and
you build up your graph but how do we do
routing on this in the example earlier I
talked about two nodes sending messages
to each other
that weren't connected to one another we
aren't making connections on demand bees
again that would require a ton of
overhead and TCP really doesn't do well
with lots of making and breaking so
fundamentally if you have a graph if you
up the entire network you're able to go
ahead and do routing across it but
unfortunately not every node has this
entire view we have to build it up the
only thing a node knows about is its
local nodes that the note that it's
immediately connected to but you can go
ahead and build up this adjacency list
you can go ahead and say for every given
origin what are the the destination
nodes that it's attached to and what we
do is we go ahead and we gossip these
view changes so when when there's a make
or break or a health check failure we go
ahead and randomly gossip this
throughout the network and wii version
these adjacencies these adjacency lists
to go ahead and know whether we've
gotten old message or whether this is a
natural a new active view and with this
every node can build up an internal
state that models the entire network
eventually and once we have this all we
need to do is run Dijkstra across it and
we're able to build up a minimum
spanning tree over the network so so
once you have this this this graph and
once you are routing in failure
detection um it actually turns out that
it's pretty easy to go ahead and build
the database on top of it and this is
where we are able to sort of things are
cast mappings and we use these things
called C or DTS into your duties have
actually been really really popular in
the early community but for those who
don't know their these data structures
that allow you to make simultaneous
changes across multiple systems and runs
all messages qsr from the network you
can merge the state and get a valid
state that converges at the end so in
our case we use the crdt kv store to go
ahead and launch tasks on multiple nodes
write it to our local kV store and then
gossip the herb messages throughout the
spanning tree and then when this data
converges everyone has a global view of
all of the tasks that are running inside
of the data center so I want to show you
guys the demo but unfortunately why if I
was flaky so I scripted some of this but
um in this demo we have three nodes
running rolling
fubar and bass and these nodes earn a
full mesh in wash up kv we have this
nice little API that says for this given
key airline users what's the value um
and I wanted to go ahead and break apart
these notes and make it so that we don't
have this mesh anymore and make the
topology look something like this so bar
and bars are not directly connected now
on bar if we go ahead and we request an
op to that that key and we say let's
take a value and increment it by 5 that
value actually goes ahead and converges
on all the nodes to 25 but let's go
ahead and make this this even a worse
get worse scenario let's go ahead and
partition all the nodes away from each
other by by changing the cookie so now
all of these nodes are independent
islands and if we go ahead we ask them
to increment by different numbers we see
divergence this data because they aren't
able to go ahead and message each other
and if we go ahead and weary bridge this
we see convergence across all of these
values so so lash-up kv is a database
that has quite a few data types and we
were able to leverage existing crdt
libraries to go ahead and do this but
fundamentally this is this is an
interesting system but does it actually
provide business value is it is it any
better than zookeeper is it any better
than what's out there already um so
prior to the last ship we did this test
where we use minuteman our load balancer
and we sent several hundred requests per
second through it and we wanted to look
at what happened in failure so we failed
ten percent of the nodes in the network
and we wanted to see what what happens
to do put and what happens with latency
and we found that throughput was heavily
degraded for about 90 seconds and
average latency went up to one second
which was the the retry interval for for
PCP but once we instituted lash-up we
saw the same test and throughput had no
affair and there was no effect on
latency when when we did this because we
were able to detect failure before the
next TCP connection occurred so proj
clash up it's a novel distributed
systems SDK that's enabled us to ship
these systems in our network in our
product it provides several services
today it provides global membership it
provides multicast delivery using that
spanning tree and it provides a strongly
eventually consistent data storage in
its actually powering real systems that
we're shipping on Prem today and it's an
open source project so anyone can use it
if they want to it's made as a library
so you can embed it inside of your own
system um but I want to talk about
erling now and I Connolly get this
question wireline go TP why not go and
go has made incredible inroads in the
container community in in the
orchestration community um and in fact
wewe try to use golang we we the first
version of Minute Man or load balancer
was actually written go so we thought
well why not stand on the shoulders of
giants why not leverage what's already
out there rather than having to reinvent
the wheel isn't much of what we're doing
is it's it's already been done
fundamentally we were building systems
over and over again we were building
things like RPC over and over again we
were building a failure detection over
again we didn't want to do this so we
said well what's a good language with
the healthy set of distributed systems
and networking libraries we said well
what's one that has an ecosystem and
once one that has an ecosystem that's
been battle tested for a number of years
because when it's 3am and your system
fails there's stem fails on someone
else's data center who do you want to
pick up the phone and the answer is is
you don't want anyone picking up the
phone you want your software to
automatically deal with failures and you
want your software to automatically deal
with the exceptional cases because
oftentimes upgrading our software inside
of our users data centers is harder than
upgrading software on the Mars rover
there's a story that the first version
of the software curiosity had some bug
in it and in 24 hours they were able to
upgrade it but when we're dealing with
these incredibly conservative
organizations that are deploying the
software and premise we have to rely on
our software self-healing in the the
period between a bug being detected in
us actually being able to resolve it and
ship a new version so with this what
components of Erlang were we actually
able to use that we're battle-tested and
provide
these benefits so that one of the first
things that we needed was a durable
store we need to be able to go ahead and
write data to disk and again and go we
have to go ahead and use some
third-party library but the fact that we
have anisha already built in although
sometimes it does get a bad rapids it's
an incredibly useful library that we can
rely on and it's been battle tested it
to the 20 years old and it's older than
go itself it's older than most of the
other languages in our stack um and the
next thing that we needed was a crdt
library um in crd teas are these
incredibly finicky data structures
they're really hard to implement and
people have spent their entire careers
trying to make them and invent new ones
and we actually couldn't find another
crdt implementation that was used in
production that was open source in any
other language than the knurling and
this was due to a bar shows
implementation in in react AV and they
done an extensive testing on it they've
done an extensive property testing on it
and the fact that other users have
actually deployed this on production in
rely on it for their critical
infrastructure was was really valuable
to us as a signal um and the next thing
that we needed was a secure distribution
channel because some of our users
actually cared about security on the
network because they they were running
on these untrusted clouds so again we
were able to go ahead and do things like
leverage distributor Lange's own ssl and
we knew that people were using this and
we knew that we can rely on and switch
it on as a configuration flag as opposed
to happen to roll our own encryption if
you look at other service discovery
solutions and other networking
encryption solutions have been
implemented and say surf they have to
roll their own encryption and we all
know that's incredibly dangerous um so
moving away from from wash up moving to
Spartan Spartan needed a DNS server so
we were looking at third party DNS
servers and we were looking at saying
well what if we go ahead and we adapt
something DNS mask or bind and this
turns out to be really hard because
they're not written in a modular way but
the airline community again provided us
a great dns server we found that DNS
simple a company whose businesses
serving DNS had open towards their dns
server and they were using this in
production and relatively large scale
more skill than any individual node
would ever need and Minuteman also
needed a kernel API library using this
thing called net link in that link is a
protocol you talk to the Linux kernel
with in order to do things like
programming routes programming net
Fulcher rules etc and we found that
again another company travel ping had
open sourced a library they'd open
source library under a liberal license
and they'd open source library that
hadn't battle-tested on other sites and
being able to leverage this without
having to do things enroller own
protocol or worried about the GPL or
worried about a community that was
putting out libraries that weren't
necessarily is in production was really
valuable um and then the last thing that
we we leveraged from the community was a
graph library in we leverage what's both
underling called digraph and it's it's a
simple graphing API or a graph
manipulation API has things like Dykstra
built into it has a quite a few nice
algorithm both into it but it didn't
work for us and it didn't work for us
not because it wasn't able to provide
the right features but it wasn't able to
work with us because it was too slow for
our use cases and it was a little bit
heavy for our use cases we need these
center-based trees so we went ahead and
we built our own library and this is
where we're testing became really
valuable and in what Erlin gives you and
testing so we were able to verify the
our own routing implementation against
digraph the way that we did this is
using property-based checking with with
proper so we were able to automatically
generate the command sets of what could
happen inside of this network and we
were able to verify equality across both
our implementation and the
implementation that we built stop
digraph we're going to do this tens of
thousands of times something that you
couldn't reasonably do with you know
testing something that you couldn't
recently come up with as a human and in
the other thing that we did for testing
was common test so common tests makes
integration testing wild lazy and on
every second we run quite a few common
tests on on wash up we spin up many many
virtual nodes in order
alt case on every check and we spent 25
because it's Rueter CI infrastructure
supports an able to torture test our
infrastructure will but a partition our
infrastructure were able to call the
disk errors we're able to crash nodes
and see how the system responds we're
able to verify that the invariants that
we stated still hold in the benefits of
this aren't that we have this
infrastructure the benefits are that
this is built into Erlang and this built
into our community and culture these
with 500 lines of tests with 500 lines
of integration tests we're able to get
eighty percent code coverage and we're
able to add more code in largely this
this code coverage metric still holds so
the takeaways out i want to give here
are that the container ecosystem is
still in its early stages i think we're
still figuring out what we need to build
but the Erlang is is suitable for
building modern reliable distributed
systems i think that a lot of
organizations haven't looked at this
because we constantly talk about how the
yearling ecosystem is is isn't really
ready for for everyone to use yet and we
have this discussion of you know
packaging is hard but it turns out that
there's all these solutions that are out
there that are battle-tested that are
used by real companies in with that
thank you questions
flapping um so yeah the there there are
several cases that flapping can occur on
but we have dampening in the protocol um
so the dis flopping where a node is
actually fundamentally failing um and
that resolves itself by having back off
and then the other thing is that we have
a defensible protocol so if if a node is
overwhelming us we can tell it to go
away
so um we don't have any interest right
now and that mostly because none of our
our systems require that but the wash-up
is an sdk so plugging in your own crdt
implementation wouldn't be particularly
hard especially if you implemented as a
react dt behavior
oh do to end you know i'll go ahead and
share this on after the talk anyone else
great thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>