<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Heinz Gies - Building a Cloud with Erlang and SmartOS - How Hard Could it Possibly Be? | Coder Coacher - Coaching Coders</title><meta content="Heinz Gies - Building a Cloud with Erlang and SmartOS - How Hard Could it Possibly Be? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Heinz Gies - Building a Cloud with Erlang and SmartOS - How Hard Could it Possibly Be?</b></h2><h5 class="post__date">2014-07-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lKPJThtCZdk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">and so today I want to talk a little bit
about building a cloud which are
Alliance mattress and I mean how hard
could it be
Amazon did it Google did it probably not
were smarter SM or Lang but about the
cloud so how hard could it be a little
spoiler ahead of time it can be quite
hard so it sounds easy let's build a
cloud it's just one word it's fluffy and
nice but it's not um three words to me
I'm writing project file which is a
cloud orchestration software force
matters in Erlang there is my Twitter
there's github all the work I do is open
source so you can look at it and on IRC
I am findable as license or even so I
don't respond unless you put my name in
there because I don't pay attention all
that often
it'll disclaimer ahead of time some of
this stuff is time travel we go through
the last two years I worked on it so
when I say something didn't work then it
does not necessarily mean it doesn't
work now and it's my experience it's not
the ultimate truth I might have been
doubly wrong so I think something didn't
work but it was actually working and I
was just doubly mistaken and I will say
something about stuff like closure
script or Jason and I don't want to
start a flame war or shame a technology
it's just my experience about applying
this technology to my problems and last
but not least no dogs were harmed here
it's all enemy's animal friendly
introduction a few words what is five oh
five words cloud orchestration that
means you can run a cloud was five four
you can have multiple hypervisors and
create VMs destroy VMs it works for KVM
it works for zones and Solaris it's
built on smarter s that means it comes
with a lot of nifty stuff ZFS the file
system to use today DTrace which is a
better version of system tap and there's
crossbow which is network virtualization
and you have zones which is what they
made out of bsd jails where then became
Linux containers and it's written in
Erlang and I don't go into the details
well this is great because you all know
that
so let's start with the first thing that
went horribly wrong and that is the fail
of chloral script no shame here and so
it holds started as a little application
in the global zone which is like the
hypervisor for some address and it was
written in clear script and I've helped
a little API over HTTP and Jason and if
looook would be here he would say stop
using Jason and I did in the end but
that's how it all started the reasons
for this were pretty simple there was a
client for the API it was the official
giant client the people building no TRAI
and yeah actually no js' and they're a
building smart OS - and there was a
client for the API so I just figured
they use it for their cloud I just copy
it and it was just one hypervisor anyway
it was my private server standing in a
barn and I'm not lying it is a barn a
little outside of Berlin where's the
fibre running into it and probably some
copper wires for power and and there was
no trace in the global zone so Clara
scoop kind of looked good to me since I
didn't want it to write JavaScript and I
like closure and I want to track loader
script so how hard could it be
I tossed in some little closure script
and it kind of worked but I had no idea
at this time what project fiber would
become that's actually more than my
hobby project for the server and the
barn this whole thing had a few slight
problems while the idea was there is
everything in the global zone already
since giant uses no trace it's all right
smart OS so they will have all the
libraries and they will have all the
dependencies and the stuff you need that
turned out to be not true there were
some libraries other libraries were
missing and then there were version
conflicts between libraries in the
global zone and libraries in the zone so
you ended up having to ship all your
libraries or most of the libraries and
partially even the compiled binaries for
libraries interfacing with the system so
that really was not that much fun and
not that easy as I expected
and another thing is it was really hard
to do back at this time which is the
main reason why I put the disclaimer in
that it has changed back then there were
no source maps for clear script so your
closure script application crashed and
not the Erlin kind of crash the bad kind
of crash and you got a stack trace of
about 2,000 lines of no trace code which
you then could try to map to the
compiled no dress code which you then
could try to map to your closure script
code which takes a while to do and it is
horrible I think they have sauce nips
now I haven't tried it so this point
might not be valid anymore um and then
the concept of smarter s is to keep the
global zone the hypervisor layer as
clean as possible not to clutter it up
with a lot of software and a lot of
applications and this approach meant
that everything was in the global zone
so you had the old authentication
everything in one big application was a
hell to maintain so going through this
weeks of misery and there are a few
things I learned and the first thing I
hope I learned I probably still make the
mistake every now and then try to plan
before you act so I looked at it say hey
there's no chance kernel script perfect
let's do it and it didn't turn out that
well I could have checked if the
libraries were there I wanted I could
have checked if the versions like on
compatible between the zones at the
global zone and but I didn't I just
blindly rushed into it because on the
first look and looked good I didn't plan
ahead I had also had no idea what it
became but now it's like running
hundreds of VM somewhere but this
wouldn't work I learnt that rewriting is
no shame I kind of always had the
opinion that if I rewrite my code I have
done something very wrong because after
all I wrote in the first place it
shouldn't have to rewrite it I could
just fix it and so rewriting is no shame
sometimes the best option is to just say
ok I ran
to a dead end here I failed miserably
you don't have to tell anyone else that
just yourself and I just scrap it and
start from scratch
and one of the other things is what
seems easy in the beginning like no
tress in the global zone is not always
simple or right in the end
so I think that's just saying that easy
doesn't equal this no easy doesn't equal
smart something like that so basically
just because it looks easy doesn't mean
it's good or simple or smart going on
with next cute doc is the fail of a
single host because after how horrible
it went I figured something has to
change and what changed was I try to
abstract over it because there's already
code I didn't quite got the rewriting
part at this point and so there was this
chloro script application and now on top
of it I built a little web server
written in cowboy and this web server
was taking the API requests you could
configure multiple endpoints and it was
routing the IPA requests to two or three
hypervisors and which I didn't have but
at this point people were saying hey I
like what you did can you make this work
was 2 hypervisors or 3 hyper right so
for hypervisors it was a big improvement
was running in a zone so it wasn't
running in the global zone anymore the
hole not cluttering the global zone part
kind of got better at this point and
this was a big big big step forward but
it was quite it the reasons are simple
there was a need for an abstraction it
was one way to big application and if a
person using it wanted to run 2
hypervisors they had to manually point
their client to one hypervisor and then
to the other hypervisor and that just
wasn't practical and as people are they
don't like consults well probably you
all do but trust me the majority of
computer users want something nice and
clicky and probably was cat picture
much more than a nice console which was
just faster to do so as I am a slave to
the masses I put on a web console there
too which kind of looked horrible since
I designed as well as the slides and and
I wanted to work with Erlang it kind of
took the same route as I wanted to work
with closure
script aside of that airline actually
worked for this and I'm still working
with Erlang I didn't scrap your line and
so my enthusiasm enthusiasm at this
point got the better of myself and I
wanted to put something on top of it
because it's nice I just read the book
OTP in action which is a very good book
when you begin to write our line oh so I
think M and yes as you can imagine
because this talk is about how horribly
wrong things go there where Sam you're
supposed to say problems now and
problems and there was still HTTP going
on between first the client and the
wiggled Erlang application and down to
the Kuro script application and HTTP is
nice but it's not always suitable and it
introduced a single point of failure
well before when you have 2 hypervisors
each excuse me each one was running a
own clear script application when 1
hypervisor failed the other one was not
affected so you could go on on your
business with the hypervisor still
running
now when the wriggle application there
early application failed you suddenly
lost connection to both hypervisors and
as we know in distributed systems single
points of failure are not ideal
they kind of come with problems and and
it did not simplify the code one of the
ideas of putting something on top of it
was to make it simpler and make it more
modular but instead it just added more
complexity because with this approach
there was no way to eliminate logic out
of the closure script application since
all the layer was doing is a shiny API
with kept pictures
and routing to the hosts those still had
to do everything including the
authentication and trust me if you have
five hypervisors and have to put in the
usernames and passwords for every one on
each of the hypervisors it starts
getting a mess after a time because it's
really really not funny so what did I
took away or try to take away after the
second episode of disaster in the
project 5 Poland HTP is no silver bullet
and everyone uses us today but sometimes
it's better to just go to something like
TCP UDP or protocol which does not come
with all additional constraints and all
the overhead when you don't need it
there are good reasons for HTTP but
blindly using it is probably not the
best idea and the second thing is to
split out actually applications when we
write code we talk about modularity and
splitting problems into different
modules and airline and then probably
different applications in Erlang but you
can go a step further and actually go
and split out your application in
multiple applications in the sense of
the operating system each with a special
task and and a turn of that handling the
authentication at the leaves of the call
tree was a pretty bad idea because I had
to have the whole logic of
authentication permissions through all
the calls because it came in here it has
to check something and those down had to
check something and it went down and he
had to check something and that that
wasn't very efficient and it wasn't very
smart either because you had all the
data at the leaves and then this usually
we say that we want in a big system the
leaves to do the most work for this
special case it was a bad idea
pushing some of the work upstream to a
higher layer was actually working a lot
better then doing all the work on the
global zones because we want to keep
them clean so with all this nicely
learned and some experience taken from
to it from it
the next thing that went wrong is
distribution the
probably one of the hardest problem in
computer science but with my can-do
attitude I figured how can it be
I mean Bachelor desert was react and
even MongoDB does it and every other
database claims they do it and probably
Google does it and Amazon does it if
Amazon can do it I can do it sure um so
in the process of this the whole thing
split out further the whole
authentication that was handled in the
leaves until then now went into an own
application called snarl all the logic
about deploying hypervisors about
managing memory managing resources IP
addresses all this kind of business
logic kind of stuff went into sniffle
and I finally took my own advice at
heart and rewrote the whole stuff
running in the global zone and and I
scraped the closure script stuff and
introduced a little Erlang application
there was running in the global zone and
really only doing what was needed
because our authentication of logic was
now handled layer up the reasons for
this decisions were pretty simple and
one thing I didn't realize before is
that Erlang applications or releases are
wonderfully self-contained I could
compile a release in his own and it
would ship all the libraries all the
binaries all it needed in one little
file one little compressed target set
file but still one file and I could put
it in the global zone extract and it
worked there are no problem with global
libraries missing library path and all
this kind of horrible thing I had to
fight with chloral script or no trace at
this point it was wonderful and a
distributed system was supposed to
protect against a single point of
failure if you're right management the
smile is distributed over multiple hosts
the theory is that if one fails the
other still works so you're not out of
luck and then instead of having one
monolithic huge
application running in the Google zone
they went now a lot of little
applications doing exactly one thing the
right management the authentication the
management of the systems running in the
global zone and doing an API each of
them distinct from each other no
interference no shared problems they
actually it looked really good at this
time until there was a thank you it
worked
come on there was a problem with a
remote - and synchronization is really
hard so it seemed like it just put a
little distributed on it and it works
not really and so the first thing I
tried was G proc and I don't want to say
G pork is bad because I really like it
but it has a problem with leader
election in the case of running
distributed over multiple nodes because
you can get in a deadlock and that gets
ugly and that breaks everything there's
a nice article on that which I didn't
wrote but which pretty much reflects the
experience I had there is a little one
here which you can't click now but if
the slides are uploaded there is a link
at the end and if you're interested with
the articles about the details on it so
G port didn't worked so I wrote a little
wrapper around G proc and I feel really
proud and smart because I just solved by
the Frog problem until I figured out
that introducing a Chrome server
introduces is singapura failure so I
made the whole circle of building a nice
system realizing interesting a point of
failure making it distributed noticing
is that a problem
introducing a single point of failure to
fix the problem which wasn't the goal
and another thing that turned out to be
problematic is if you're running three
services on six hosts each and have to
configure all the endpoints manually it
starts to be really annoying and it
starts to be doubly annoying if you
don't use configuration management or
anything but do it manually because
you're developing it
and have to write all the application
files and then you miss type and IP and
trust me you will and then something
breaks and you have no idea why until
you realize that instead of 12 you wrote
21 and there's no fun so what did I take
away from this and what I hope what do I
hope you guys take away from this
distributed systems are heart and
probably all of you know that and I knew
it at the time
but my experience is they are always a
little harder than you actually think
they are so it's like time travel
sneakiness and managing configuration is
annoying especially if you have multiple
notes because the number of
configurations you have to do is like
growing exponentially that's kind of
annoying and hard to do and I learned
that there are really really really
great libraries for distribution in
early I can't say if they are not in
other languages but I know in Erlang
they are really good there is G Pro
which has problems multiple nodes but
it's still pretty good and then there is
one library which has like become my
all-time favorite and I want to thank
Petro for it which is react or if you're
writing eventual consistent library that
application that is going to be
distributed do yourself a failure a
failure failure and do yourself a favor
and not a failure and spend the five
minutes to look up react or it will save
you days of work and months of problems
it's wonderful and it's open source and
it's what react built on it is what
five-foot boot on and it really nice so
we had this topic before in Lewis talk
the failure of storing Jason and it is
not as obvious as Jason as bad because
Jason is not necessarily bad but what I
did was all the data that got into FIFO
came in one way or another in a JSON
format
so the front end sent Jason all the
stuff on the hypervisor since it was
from Joyent
which are the note reyes guys came and
Jason so had Jason at both ends I
figured why not just use Jason
everywhere store the data and Jason and
there was JSX which is great for
serializing and deserializing J's it's
written in Italian Erlang no niffs no
nothing yeah why not also everyone uses
Jason must be good you laugh I love
today too but back then I was young and
naive I had like five hairs more than I
do today and it seemed obvious everyone
uses Jase that's wonderful it's a
solution
it's God's and and except it's not the I
made the choice based on popularity and
not common sense I didn't take a moment
to sit back and think about it and and
this point is not based on Jason so if
you take one thing away from it from the
talk today other than I am a horrible
programmer and please let it be don't
base choices on popularity think for
yourself because a million fleas eat

um and you don't probably I hope and so
that was the biggest problem all the
biggest reason for a problem then there
the pattern matching and Erlang is a
wonderful feature if you stuff all your
data and Jason you kind of toss it out
of the window because we can't really
pattern match against adjacent data
structure no matter how you form it and
it is lists in tuples and lists and
tuples and lists and tuples and listens
to those and with any kind of keys you
don't know any order you don't know so
you toss a parametric one of my favorite
things no lying aside of all the other
favorite thing in there like out of the
window and there was no good library at
this point or probably I should say I
did not find any good library that was
there to menu plate racing so you ended
up with key find halide key replays
and recursive calls on those kind of
things and it made really horrible ugly
coat compared to a simple pet on
maternal record and Jason is very big
and verbose and Lois said this much
better than I did so I won't repeat any
too much on it but it's big laughs and
it was hard to represent Jason Erlang
because back then there were no Maps
there was j6 who put tuples into lists
unless it was an empty object and it put
an empty tuple in a list and then as the
other thing you which use struct and
then a tuple of lists and the other
thing which used another different way
to represent it so it was really hard to
map the data between Erlang and Jason
and going into a distributed system and
that needed to be a way to synchronize
data if it got out of sync so in react
or databases you know the reach repair
where you take two daters and merge them
back together there are state books
which is a pretty sweet library which
kind of record everything you ever did
to an object or data and lets you replay
it and merge it this way
but has serious limitations and one of
them is the data keeps growing and
growing unless you time it out um so
with Jason and data without typing or
without any kind of constraints it was
really really ugly to do so what did I
take away from this what I take away is
that modeling your data around the front
end or the edges of your application is
probably a bad idea you end up doing
most of the work on the data in the
center so I found it a lot smarter by
now to do the opposite of what I did and
just do conversion to the front end
types at the edges convert a record to a
Jason when you ship it out or when you
read it in and that works very well
Jason is no silver bullet
which kind of you might have guessed by
now because how much I hate it and I
think it has a lot of the same problems
that XML hat I don't mean a lot of
brackets I mean that people are using it
for everything just because and not
because there was a reason for it and at
least for me there was kind of a one
thing that destroyed XML the most and
raised is on the best path to follow in
this M C R DT which are concurrent
replicated data types wonderful if you
haven't read up on them there is a link
at the end here because I don't think I
have the time to explain them entirely
but I only have 45 minutes and not 45
days and they are a very nice
alternative put them in a record and you
can merge them and you have types and
it's really really really a lot lot
better than just storing some kind of
data some kind of Jason anywhere so this
is not entirely fixed by now so I'm
still having some Jason data which I
didn't manage to merge out and kill
which I'm very ashamed of please don't
toss the tomatoes yet and so finally one
big big problem is the fail of cap and
no I did not beat the cap theory I don't
think I will until I fix my time machine
and can do a fourth and back and just
send packages in time and so cap means
pretty much that you can't have
consistency availability and petition
tolerance at the same time you have to
pick two including petition tolerance
and one of the reasons why I ended up
thinking about the stuff is because
react or is great react or is eventual
consistent which means you give up some
consistency to get availability and
that's very tempting because when you
think about it most of the time at least
for a cloud
I think availability is more important
than consistency that you can create the
VM in the cloud and he can create the VM
in the cloud at the same time as more
important than you seeing his VM at the
same moment
usually you just want your VM and it is
wonderful to have the ability to trade
off some consistency for availability
except when it's not because you start
off thinking everything is eventually
consistent now my life is solved
everything is good I am in heaven
there's no more problem to be had
because it's eventual consistent so
eventually it will be consistent and
it's available so I have the best thing
ever and there are no problems anymore
and then you realize that eventually
figuring out that you gave out the same
IP twice kind of sucks because then
certainly the computers you created the
VMS you created will crash and get IP
conflict and everything blows up in your
face and you would certainly want to
avoid that because it's not good same
applies for things like memory and
hypervisors you don't want to eventually
give the guy his memory you want to give
the guy his memory for sure and the
biggest problem was cap is that probably
no one will solve this problem anytime
soon and there's a nice checklist here
labeled with a3 which is from threat the
guy who wrote on you some airline for
greater good if you ever think hey I
think I solved the cap theorem go
through this list make the appropriate
crosses and figure out why you didn't
and so what did I take away from this
and this is a bit more technical and the
first thing I figured out or I learned
is that the more control you have over
your data
the further you can push the eventual
interventional consistency if you know
what your data represents and how it
behaves how it affects the other systems
you can make much better trade-offs and
much more informed trade-offs than just
storing some kind of data and the first
thing I was thinking is let's put a lock
somewhere so
that if he creates a VM you can't and I
was tempted to do that until I realized
that I would have introduced a new
single point of failure and kind of
built the eventual consistent eventual
available system which is nothing but
partition tolerant don't give any other
big advantages and then thinking of it
more about it because I kind of wasn't
satisfied with having a system which
doesn't work either way and I realized
that if you do some kind of logging and
you know how the data works you can't
cheat a little for example in the case
of hypervisor memory and you only care
about the memory on the same hypervisor
if you are actually doing something and
if you can't reach the hypervisor there
is no point of calling it a single point
of failure because yes you can't create
the lock if you can't reach the
hypervisor but you couldn't create a VM
there in the first place so not being
able to lock a hypervisor you can't
reach is the trait of you can make based
on the information you have about the
system
mmm so the lock on memory of the
hypervisors now is on the hypervisor
on the code running on hypervisor so if
he creates a VM on a hypervisor he grabs
a lock on the hypervisor if you try to
do the same it will tell you know this
hypervisor I was busy if you can't reach
the hypervisor then it's kind of busy
too and if he's done he's done and you
can work on every other hypervisor in
the meantime so it kind of introduced a
single point of failure but the point
the impact of the failure is about as
big as a failure so it's not making
things worse and peace are the second
thing they are more complicated because
you can't really pin a IP to a physical
entity and so the idea I had here and
which is again about lock location is
that if you take your IP range or you
know a parental status at the end there
are numbers in between so you know how
the data works and you know that you can
take out only one of them once and not
twice so you have seven systems in your
this root system and you say okay I
divide my peer
to seven ranges and each hypervisor gets
their own range you sacrifice a little
availability because if all but one IP
is in use and you only have the one left
then you depend on accessing actually
this one hypervisor that has a claim on
it but if and in the most cases that is
true you have a lot of free IP addresses
this impact on it is actually minimal so
you sacrifice a little availability to
get a little more consistency at this
point but you don't toss it out of the
window entirely okay I have no idea how
I'm at the time but I'm about finished
and which means do you guys have any
questions I have a question regarding
Jason so you're suggesting Maps right if
I get that right you were proposing
binary data format for a link to use and
serialize it to Jason if somebody needs
that but in general what would you
replace Jason with not that I believe
it's the best one but I didn't catch
what option was well the alternative
what I was trying to say and I probably
phrase that badly is that using Jason at
the edges to communicate with a web
browser is one thing but inside your
application representing the data in
some kind of Erlang that maps to a jason
directly which was probably lists of two
bolts has a lot of disadvantages I ended
up putting records everywhere because I
conversion them I can have the fixed
fields I have checking against
misspelled names and trust me I'm very
good at misspelling stuff and so if I
had to design a system like this again I
would internally use records everywhere
or perhaps Maps today but I haven't
tried them yet because there is no r7
yeah with persistence would you use that
what you're describing as well yes okay
just term to binary works wonderfully
and you can put it somewhere and then
binary retirement you get it back
because that's what I used with Jason
the end too just in a kind of horrible
representation instead of a nice record
oh now I'm scared
it's all right cause it very simple
quick I mean I know what darling is and
I know what closures good I know I have
a clue what smart os's
I've never heard so what is it okay in
the good old days when there was Sun
Microsystems
which was a kind of acceptable company
which charged way too much for servers
and they developed a operating system
called Solaris which is Unix but not
Linux and then the evil Oracle came
along and they killed Solaris no not
only the layer is actually entire Sun
but the brave knights of Sun were so
smart to open-source Solaris before they
were bored there was no taking back from
Oracle and there are now multiple Forks
of Solaris there's Omni OS there's a
luminous and one is smarter smarter s is
specialized on cloud computing it's a
little hypervisor like 300 megabytes
installation and everything runs in a
virtual machine or zone that's not X no
you have a USB key or you have a yeah
yeah I can show you it writes the data
on the disk but the entire operating
system is either on a CD or on a USB key
or on a pixie boot if you have more than
one hypervisor that's very nice but yeah
and no it has nothing to do with Erlang
on Sam I have one question Hines
it's quill quite obvious that you're
eating your own dog food yes to control
your servers in the barn outside Berlin
not only by now there are actually
bigger installation there's a bit who
else is using this and there is Lou
Sarah which is a financial cloud
infrastructure company they are like
Amazon for financial which means
expensive and fancy
and now it's very fast and very
performant and very expensive and they
also pay for me to work on Pfeiffer
because they depend on it it's a nice
thing and there is the University I
think it's Melbourne somewhere I please
don't quote me on it um in Australia who
use it for the IPD i-80 department and
they're having literally hundreds of
zones managed by it and there's an other
university of which I don't remember the
name in the u.s. it's some kind of
Christian University and they are using
it for the media department so there are
actually real life use cases outside of
my barn everything has to leave the barn
eventually it's a very nice barn and she
do have you contacted giant about this
yes I actually the first thing I did
before I started FIFA was talking to
giant because I really respect the guys
at Giant and I think they do a great job
for smarter s and they have a I don't
want to call a competing product but
they have a cloud orchestration product
and the first thing I did before I
started this was ask them if they are ok
with it and I got a very nice reply and
a t-shirt saying we love the idea please
go ahead we all profit from all people
using smart ass and another question did
you look at OpenStack in the beginning
and supporting smart OS for OpenStack
its natural question for me if you're
building a cloud management application
yes and and the answer is I believe
firmly in to doing one thing well
instead of doing a lot of things kind of
well and I am pretty sure that the code
needed to get smartest because the
concept of smart is was mostly zones and
data centers all kind of stuff is kind
of different from OpenStack or cloud
stack or all the other cloud software
and isn't worth it you would get a kind
of working thing that also does smart OS
but I am pretty sure that neither
redhead nor anyone is doing this
applications
really interested in supporting smartest
because that would mean that they are
competing with their own product right
whether Linux and it would never work as
well as application tailored to house
Mario's desktop so yes here's a sort
owns several times yes what's that so um
there are like multiple types of
virtualization the most common one is
hardware virtualization where your
operating system pretends there is
hardware and then on this pretend
Hardware runs another operating system
which you then run your applications
that was Amazon does that's what Google
I think did until they had docker I'm
not entirely sure I am pretty sure
that's what OpenStack does with KVM and
the zones are an alternative to this
they are derived from BSD jails which is
a form you take your kernel which is
like big thing and you carve out a space
in this kernel with special permissions
that still has access to a lot of parts
like the hardware and Cancer Network
packages but it is constrained so it's
like a virtual machine but not it's
running at the same speed as your
operating system
but you have your own permissions you
have your own resources in Solaris you
have your own network stacks all the TCP
stuff is handled separately and that's
an alternative to pretty much KVM exam
which runs a lot faster since you take
out a layer of virtualization don't
answer the question yes yes
have you looked into core OS and no I
think it might be able to solve some of
the consistency problems for you like is
pretty much smarter as ported to Linux
yeah and on top to use like a key value
storage are using raft like an
alternative to paxos where you should
get a lot of problems removed from your
consistency availability your problems
and you get nice structured containers I
think they also use docker there yeah
it's pretty much smarter s plus Linux
but consistency problem is in kind of a
different layer also I like Solaris a
lot better than Linux which is hey it's
my choice don't stall me for it you can
use your Linux Solaris no more questions
Hines thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>