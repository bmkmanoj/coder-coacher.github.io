<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Beyond Lists: High Performance Data Structures - Phil Trelford | Coder Coacher - Coaching Coders</title><meta content="Beyond Lists: High Performance Data Structures - Phil Trelford - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Beyond Lists: High Performance Data Structures - Phil Trelford</b></h2><h5 class="post__date">2015-11-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/hx2vOwbB-X0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so this is the functional track i
believe and the finance track why was
quite curious about was to get a raise
of hands of those people who are working
in finance now so that's not me okay and
who have ever worked in finance that's
ok so we've pretty much got everybody
covered now and I'm going to be talking
about across multiple languages so
hopefully that's that's good news for
you how many people here have used a
functional language before that's pretty
much everybody which is great this is a
this is a great conference anybody not
used to functional language no so one
cool today's your lucky day because I'm
not going to do much functional today so
that's great um so okay I think I've got
got a good idea of you guys now my name
is Phil I work for a company called
Simcoe which are based in Denmark have
offices in London we're hiring that's
all those inevitable things you have to
say when you can't hear we're hiring for
the Denmark office so hopefully by the
end of this hamper you off too much
you'll come and talk to me in and say I
want to work with you my background I've
worked in finance for about seven years
but I'm from video games which seems to
be quite common now people want people
who are cheap and work long hours and
that I fitted the bill really well
they're also people with some idea
around performance and this talk is has
come about from really a series of rants
with Andrew McCloskey about things that
I've seen go wrong and things that could
go better and trying to distill that all
together so let's crack in going to
start with horrible diagram data driven
applications now we've gone
here are kind of long tale of pretty
much loads of people around the world
doing web applications with lamp or we
could replace this with Ruby and they
have a database and some templating and
they they put that together and they
have some sort of database here and the
database has all the data structure work
for them so they don't have to know
anything about that so it's probably a
good thing and it just kind of works for
them and then this is this is kind of
what we see in finance and and kind of
line a business enterprise
line-of-business applications is we have
our database but then we've got some
layers in between it and in effect some
why I've seen most frequently in finance
is it costs so much to have a server by
the time we've gone through all the red
tape it costs you know nearly a hundred
thousand pounds just to get through the
red tape to buy a 1,000 pound server
that we don't want to have lots of
servers all you want to do is have some
way of distributing the code and the
clients machine turns out to be a really
good place to to all the compute so in
effect what we're doing and you see us
alone application since we're driving
the processing to the client right and
in effect the climb is starting to do
database like things and we're getting
more and more data to the client right
this is a great way of doing it though
because the clients have lots of CPU
power and instead of having lots of
expensive service we just push it over
there which leads me to the next one so
we you may have heard any sufficiently
complex application probably has a
half-baked flaky version of Common Lisp
bill into it and then the Erlang version
which is any distributed complex
distributed application has a half-baked
version of Erlang in it there's there's
another one which is green cards every
sufficiently complex act has a
half-baked database implementation and
that's where i'm staying from for this
talk so in effect our performance of our
application we need to do database like
things in our apps whether it be r2
server or the client and the reason for
that is this this is the timings for
different actions on a computer and if
we take the right side column because
it's a bit more easy to reason about CPU
cycle one second and if we look at the
stuff in the cash when we keep it in the
memory cache which going up close to a
minute but as soon as we miss the cash
six minutes 11 second six minutes so
that that's going to hurt right when we
hear disk it's two to six days that's
really really bad right and now we're in
two months if we hit a slower disk mum's
right and then going over the network
for years comparatively to one second so
clearly if we want to go fast we want to
be in memory and this is what's driving
us to have our database like operations
in a high performance systems in memory
rather than after database unfortunately
most of the systems I see don't have the
data structures that you expect to have
if you were implementing your database
you're still using very rudimentary data
structures no that's basically what I'd
like to talk about and there is a reason
for it most of my career is have been
about making things faster but making
things faster is actually what the
customer wants when you ask a trader
what you want does he want it to look
prettier no he wants to run for
cluster and pretty much anybody buying
anything on the internet would rather it
moved quicker although we spend a lot of
time doing CSS stylesheet changes so our
performances feature so we should write
everything in C++ clearly right
that's the best way to do it so I'm
going to give you a quick example when I
first started in finance somebody had
done an interview an investment bank and
they've been asked a problem about left
truncated primes which Prime's you
remove one value from the left and it
should still be Prime right so you need
to generate these truncated crimes and
this is the final version of speed
between C++ on the left C sharp and F
sharp so they're sharp being a more
functional one they're all basically the
same what this picture doesn't tell you
is the earlier part of the story which
was when I first wrote the F sharp
version i asked the C++ guy to share his
version the F sharp version was twice as
fast as a C++ version now he did not
believe this could C++ is fast then I
explained it dotnet code compiles just
in time so is actually compiled code
it's not interpreted but why was that
faster well actually the dotnet
collections the.net resize array is
about twenty percent faster than a c++
standard vector the next thing which is
already significant was the F sharp
version just happened to use 32-bit
integers because that was sufficient the
C++ one used 64-bit the guy spent two
weeks trying to reach the same speed as
the F sharp version in the end I had to
just tell him and then let it all panned
out but I guess one of the early points
before i drive into showing you things
is one of the most common things when
dealing with forming
is that people go all I'm using X which
must be really fast and why what is it
fast well if you compared it with and
actually get the F sharp code which
shouldn't be faster was twice as fast if
you don't compare you won't know and
that leads onto another quick slide
beware of these prefixes and plays fixes
okay so I'll just let you soak that in
some of these we're going to explain
this one we're going to do first quick
is normally a good one fast I generally
think isn't fast be really wary a fast
and simple that's usually the last thing
they are so so look at a mutable list so
we're in functional land initially we're
talking about going beyond less and I'll
move you on to more interesting things
later we have our immutable list there's
definition in a camel and these are
quite nice things they are mutable we
can share them around and they're laid
out in such a way when we have a mutable
linked list we mutate the pointer here
we just point back right so the cost is
no worse when we're adding then a linked
list of hand and we don't have the
mutation property so that's all good so
as an example though let's move on
beyond addition I don't know much about
Haskell well I know it's pure and I've
got a book called learn your Haskell for
great good and I found this thing I
don't know is Tony in no I've seen quick
saw in the book as I ice is cool I
wonder if it's quick
so I'm going to I'm going to go and find
that out so I'm going to do some code
samples with F sharp and the reason i'm
going to do with F harp is because I
know it and the other reason is there's
this really nice function called time
which lets me in the interactive window
find out how long things take which is
kind of useful when you're trying to
perform its code so we're going to have
it i'm going to set the hash time and
every time i do an operation now it's
going to tell me how long it took so
that that value is quite quick right so
what I want to do I'll make a big list
of numbers and i'll write out that same
sort function and oh dear
ok so we've already into cheering
completeness problems at this point so I
know that's not going to work why don't
we will just give you a little hand this
time so I'm resetting that that wasn't
going to complete if I give it a pre
sorted list then maybe we'll do okay
right
that's pretty cool so it can actually
saw a pre sorted list of a million in
just over a second so that's pretty
happy but I wonder what the actual
quicksort algorithm does where we
actually where we do a sort in place
that's the kind of important thing about
quicksort so that's under a hundred
milliseconds it's more than order of
magnitude faster and that's actually
sort of the one that's the other way
around so clearly our immutable data
structures are really cool but in
certain circumstances it's not going so
well if we have a look at the standard
library so that's a third of the speed
so that's done a saw on in point 3 of a
second and actually if we just convert
to an array and back again convert to
convert list to an array sort it in
place go back to a list it's still three
times faster than the sorting of a
sorted list right using that mechanism
so something clearly this immutable days
structure is nice but it doesn't seem to
scale so well and our rays do seem to be
doing quite well so can I spend a bit of
time on this
so well it's short and saw but it's not
quick I think this is a quote from
friend of mine John Harrop I think we
might be getting to puritanical about
purity when it comes to speed the purity
is really nice you know when speeds not
important but maybe you know we would
like our things to actually end at some
point to actually complete so next thing
I'm going to look at is laziness another
property that we see in pure functional
programming languages and also in our
standard languages so if you're using
JetBrains resharper product and you've
got a full loop it will tell you I see
you have a for loop that why don't I
turn that into a link expression wide so
that into a high order function for you
because that'll be cool so that's nice
and it becomes declarative unfortunately
it also typically can end up being 15
times slower or more so it is prettier
so um some guys in Greece team called
Nessus have a link optimizer take the
declarative high order functions and
turn them into imperative statements on
the fly for you and you can get speed up
so that's 15 times so if we start a bomb
we have summer squares five seconds with
a standard link using it being unrolled
two falls it's less than a second so
very big improvements from not doing
Claire ative but the thing I kind of
like about this is that we can you write
it declaratively and the compiler works
that out for you it turns into a for
loop so we can still do our nice code
and we can move forward another library
they've got is streams so anybody using
Java or scholar so Java rate has this
these streams library and actually is
pretty cool it's
the link library pulls data streams push
and in the number of scenarios streams
are significantly faster than link so
we're kind of jealous of that you've
come late to the party in Java and
you've got faster systems so again the
nestles guys have a paper clash of the
lambdas and a library and we have a look
here this is standard sequence and this
is the optimized sequence using an
effective stream how you can see the
time is significantly lower so this is
this is all good so while there was some
while I was tweeting about how great
this was there's another push mechanism
called reactive extensions and so how
does that compare somebody said our
numbers are hard to be and we've already
talked about not checking other versions
so I had a quick check so the reactive
extensions doing some squares was nearly
three seconds right to do a certain
number of summer squares reactive
extensions use something called an i
observable interface this was first in
f-sharp in about two thousand and six so
I had to look at the original
implementation from F sharp this is from
2010 onwards and I was here the naive
f-sharp implementation is six times
faster than that one so it's not that
hard to be and if we look over here at
the Nestle streams version it's point
one of a second oops so about 20 times
faster so nice thing about this is
obviously strings could be fast but also
I'm just trying to reinforce the point
that if you don't check against another
implementation you might end up with egg
on your face when you say your things
really fast and a little bit of Star
Trek for that but the thing I keep
seeing again in the game with
performance is not testing against
multiple implementations setting out to
confirm your bias and not even bothering
to instrument and profile your code well
I'm sure all of you do that ok so we've
saved this there's some problems with
with our lists let's have a look at
lookups there are our dictionary so this
is a from an article by yanqui and he's
looking at the time it takes to add
million items followed by the amount of
time takes to traverse a million items
now our rays are really good at resize
arrays are really good at this so this
is the benchmark 1 times game 1 times
this hi this is on.net but you would get
a similar similar thing it's just an
array Java C++ but good question Thanks
now here we've got the f-sharp map which
is Navy l tree basically you'll get the
same speed again the AVL tree is an
immutable map is 244 times slower and
insertion which isn't too surprising
yeah the dictionary which is a hash
table that's actually quite reasonable
and then look up why's the AVL trees
actually not too bad but the insertions
really expensive and the dictionary is
doing better so what we can see here
is if we want to go fast all we need to
do is turn on our move all collections
right now this this this there's a lot
of functional people in the room I think
for me as I say I like to have my
collections immutable by default but a
lot of the time I'm actually holding my
mute my state inside an agent right so
nobody else can see it it's completely
safe and in that scenario using mutable
collections and getting orders of
magnitude performance improvements is
pretty sensible right so
but I've said that about a race well
want to do now is completely disprove
everything I said again so we're going
to say our value out to ten million i'm
going to create an array 10 million
items that's taken just under a second
and i'm going to remove from the back
and let's take in just over a second
that's really good that's 10 million
items in 10 million items out i'm going
to create a new one and this time i'm
going to remove at the front now I've
seen this in production systems people
have come to me and said the things just
hung right and you like but I can't work
it out you know and typically on Java
and C sharp they have things called list
which were actually arrays so people
don't even know what they dealing with
so let's try this out anyway so I'm
going to remove from the front on 10
million and as I'm not going to hang
around with this for long I've never
actually got to the end of this one I
think I'd probably have to leave a
computer on for a year or so so what
this is doing is every time we removed
from the array we pull all of the items
back one at a time right this is not a
good thing now pushing with the back was
really really easy so let's stop that
because that's just taking too long the
other problem we've got is quite often
in trading stories in law of scenarios
we need to insert into the middle right
so what I'm going to do is set up a
scenario where I create 10 million items
calls
and I've managed to I'm just do that
again insert a hundred items into my
telling 10 million item list and it's
just taking under a second to insert a
hundred items so that's not going to
work either that's it's as bad as a
removal problem so the next thing I
might go well what about a linked list
because it's quite easy to remove
something from the chain i have to copy
right so let's try and add 10 million
items
into a linked list
I get that doesn't even finish so what
we've got here is we've got something
that's really good at adding to the end
again with the array it's very good at
traversing but absolutely awful for
random insertion and removal and the
linked list is dead because I can't even
get 10,000 items into it before you guys
get bored so that that's a dead one as
well so we'll come back to those so at
the moment they're looking like dead
ducks right but maybe there's something
we can do with them later that's that's
where we're going to get
so the next thing I wanted to show you
is we've got a dictionary we looked at
arrays got a dictionary now one of the
interesting things I found in.net is a
hybrid dictionary and the hybrid
dictionary has a list and a hash table
and this is kind of cute because
traversing small amounts of data seems
actually quite fast so this green line
is the time it takes for their when it's
traversing a linked list so for small n
insertion and traversal is fine and as
we go up it ends up being rubbish but
actually a lot of the things we have a
small dictionaries and so traversal is
easier so just quickly wanted to show
you that because it is linked orbit
rindy
so I've got a bunch of key value pairs
oops
well sorry the hardest part of
presenting please let me know switching
between powerpoint and and the desktops
really painful okay sorry let me show
you that again so i want it i'm going to
set up a scenario where i look up up to
50 items in a collection i'm going to
compare that against doing in a
dictionary against the hash table so
let's just run that a few times so
lookups about 30 milliseconds create
dictionary and we'll do the same look up
ok so the brute force look up over 50
items just going across an array is
about six times faster than doing the
hash table alright so what we're getting
here is we're getting data structures
are really cool the dictionary is much
faster than the AVL tree but actually
for small n these arrays seem to be
incredibly fast right the processor
seems to love going in straight lines
right now we could use this and that's
where we're driving towards but actually
if we go if we remember back to the
speed of the CPU the time the amount of
time it takes when we go out of the cash
is about six minutes compared to one
second when we're on the processor or in
in cash right so it kind of makes sense
if we keep everything local and we're in
cash it's going to be really fast and
that's kind of where we want to be
driving we don't want to have lots of
data spread out across the system where
you know six minutes against one second
I know which I want right so let's go
back in
and what that what's that an example of
that is in databases so one of the
databases heavily used for time series
data in finances kdb and that uses a
column store if we use classical kind of
relational store with rose every time we
want to check each day we go go all the
way across so where we're missing cash
values right if we store all of the
dates and we need to compare the dates
are all in a line our cache affinity is
beautiful we go significantly faster and
we can do qaidi bees in memory we're in
memory because we want to go fast this
is all really important I actually wrote
a database for Tesco com back in the
turn of the com boom and they had a
database it was taking up to about 15
seconds to get the round trip from the
database because the day basis so
heavily loaded I wrote a column store
database and it was read for the
read-only data and we managed to gather
round trip down to around a millisecond
right so this really does work so using
columnstore values okay data structures
if we look at our example of insertion
and removal if you have a text editor
and you've got your million lines of C
sharp code or Java kallik and you press
a button it will try and insert into an
array right and that you're waiting for
two hours for it to do that insertion
one of the common data structures for
this is a rope and hang by the rape and
the idea there is instead of moving
everything across we create a tree we
say this half a million is one side of
the tree and the other half millions the
other and we can insert a new character
see between the two points right so
instead of moving half million points
over from our million we just create a
simple tree which has our new value and
the left side of the large string the
right side and eventually with the the
Rope if it gets too complex we just
rewrite out the whole string but it
means that we've basically got almost
instant insertion inside say a million
items right so this is insertion time
this is the rope we like this one this
is the green one and the red one is
stringbuilder and that's a standard
string so this is quite nice typically
we don't write a lot of word processors
in finance so we're not going to spend
too long on this one next one I want to
show you is an unrolled linked list
anybody seen one of these before got a
few nodding heads so we've said that the
array long arrays are really bad link
lists are really bad what if we put them
together put some really bad things
together would we get something good and
usually not but in this case you do so
the problem with linked lists is that
you have a link and the item and that's
quite heavy right so what you do with a
unrolled linked list is you have a link
and a bunch of items right and what we
can do then is that bunch of items
that's all very local it's an array okay
so we've got great cache affinity we're
going to be in memory once once we've
traversed to it and then the fun bit
comes when when we do an insertion let's
say the that link is full we've got 40
items in it and we insert one all we
need to do is we don't need to move a
million items Doug all we need is we
split that node in half and add a new
chain
right so that means that you can
literally insert into a million items
again with virtually no cost now once
you've done one split the next time that
you insert it's already split so the
insertion is free and what it turns out
is it probably about ninety-nine percent
of the time depending on how big your
each of the buffers are you've got no
allocation whatsoever when you insert a
no-call minimal copying only the size of
the range which is hugely fast I'm going
to give you a quick example in code in a
minute but I was able to i was working
on earth on a system for a front office
system and we were taking about one
hundred percent cpu to deal with a
hundred trades per second i replaced it
with the unrolled linked list and we
went to 10,000 trades per second on 0%
cpu right it didn't actually measure on
task manager because it was less than
0.3% CPU so I was kind of freaked out
for a while because you know you don't
normally make that 20 and then I I put
some delays in it and realized that
there was like a fresh hold where it
would notice that it was cpu going but
this is kind of cool so this is kind of
database like and a lovely thing here is
if you need to do traversal it's all
laid out nicely for you so if I need to
slice out 50 items to display in a list
halfway through half a million it's all
they died out reasonably nice for me the
only downside with this is that when I
traverse I have to compare the last node
of each one so if I start to get into
the hundreds of millions then that
traversal costs are going to cost more
so maybe you want something a bit better
but let me just show you that data
structure because it's nice
have you audio cable programmers here
one brilliant f show lots of hands
that's great so this song will be in
f-sharp but the codes actually just copy
and pasted from a camel so if i go back
to that sample where we're doing the
insertions and instead of using an array
i used an unrolled linked list oops
so I will just get my session going okay
so we were about nearly a second to
those in sessions on the array just a
hundred by and we're around 30
milliseconds with the unrolled linked
list so basically it feels like we're
almost at the panacea point right this
is we're feeling quite happy and for
most practical purposes this would be
enough the unrolled linked list
implementation is fairly trivial so 200
lines of oh camel nail it I'll just show
you the it's not much different from a
linked list you have a node and instead
of having an item in the node you have
items right pretty pretty easy so this
is a really nice easy switch to get
incredibly good performance games and
then I'm as some additional
optimizations we store the first and
last items so that we can quickly insert
exactly the key gets good kosher the
question was is the key to this breaking
up the pieces so they're in the cache
yes a huge part of it is what so we we
avoid all a huge copying right when we
do copy it's only in a very small
fragment when we do traverse or read
it's all in cash right now typically
what you would do is set your page size
your items array to fit neatly within a
page size in memory so you'll see pues
loading in a page right and so basically
you take one cache miss potentially and
then from there on it's all happy cash
and we're all in the one second area
instead of a six-minute area so it is
really beautiful for that so we've got
this lovely affinity by using an array
the breaking of them when we do have to
insert and we've already spill is still
quite lightweight operation
so next
the next type is a B+ tree and actually
so you're probably going well this this
list thing is a bit sucky because you
know we have to go from one end to
another even though it's actually
relatively fast because we're in the
cash what we really want to do we want
to get to the end of like a hundred
million items is we want a tree we just
want to go down a tree so all of your
standard databases are a call sybase
sequel server you know you name it user
B plus tree right and a lot of in-memory
databases CouchDB use V Plus tree now
this is actually only a very small
change over the unrolling this I was
building up to it so what we do is
slightly different to a b-tree standard
be tree in that we actually hold all the
values in the nodes so I'm showing you a
b-tree here move on to the b+ tree but
this splitting behavior that we had any
unrolled linked list which is our kind
of key point holy everything in a cache
our be trees do that and again the
implementation isn't that hard people in
the 90s people treat try to use tea
trees when caches were smaller but be
trees have been found to be faster with
modern hardware so or B plus trees so
don't just ignore that you can or the
tea tree thing and go straight to the V
tree but yet basically you construct a a
tree you when when you fill a an area
you split and you push the values back
up and that's all there is to it right
and if if that's filled you split back
up so it's a very small adaptation over
the unrolled linked list okay so if you
want to go fast you want to be movable
right and you want to be you want to be
able to get affinity or memory and you
want to be able to
scale to huge numbers and these these
data structures are basically all
databases achieve that with disk
sometimes with memory and you can have
those of your own programs and we've
solved everything we've solved our our
database problem so the actual data
structured one is a B+ tree this is a
found this along the way this is
probably a bit gushy but one of the most
beautiful and useful inventions that
computer science and nobody's using what
everybody is using them because you're
using in a database but you're not using
them in your applications if you do
you're going to go really fast so I
think I'm about out of time that's guy
out of time so i quickly sum up I've
gone on and on about speed and mews
ability please don't don't get me wrong
prefer safe and simple defaults prefer
immutability right because most of you
know paretto is rule most of your code
is not performance critical but what it
is when you've profiled your code and
it's going really badly or you know
you've got millions of items to traverse
switch so profile mutable arrays are
fast build your data structures from
arrays and be pragmatic so that's pretty
much all I've got time for there's on my
github there is a implementation of
unrolled in o camel which you can copy
and paste in select sharp there's
actually an implementation in Scala
already I think it's quite common data
structure usage there and I will be
publishing my b 3 b plus tree shortly in
the same place there's my twitter and
blog any questions one question in the
back
right sorry
you
yep cool yes so the question was on how
do you go about profiling girl I keep
saying you should profile so I'm on the
windows stack and I think it's been a
similar for jvm I use tools like your
kit which have on the JVM as well the
bill in Visual Studio 1 i've used any
profile i can get my hands on because
often you get slightly different neurons
results that gives me a general feeling
but i don't trust anything ever so i
will then potentially once i found a hot
spot I will do the act of viewing
something usually changes it slightly so
i will put in some instrumentation
directly in the code to make sure that
it is doing that time in the real world
scenario and then from there what i will
do is pull out the section of code that
is dodgy and i'll run it inside a ripple
and I'll time it in different scenarios
and I'll try different implementations
until I get where I want to go so at
that final point I will do the rapa like
i did in the samples and for me that's
quite important York here is pretty much
my favorite profiler for.net but it's
also available for the JVM cool i think
i've been told i'm done thank you very
much and
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>