<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Luke Marsden - The Sock Shop: Microservices from dev to prod with Docker and Kubernetes | Coder Coacher - Coaching Coders</title><meta content="Luke Marsden - The Sock Shop: Microservices from dev to prod with Docker and Kubernetes - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Luke Marsden - The Sock Shop: Microservices from dev to prod with Docker and Kubernetes</b></h2><h5 class="post__date">2016-11-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zzSElP8pQUA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi folks it's really nice to be here yes
so today I'm going to talk about docker
and kubernetes I'm also going to talk a
little bit about Sox the reason for that
is that we've built an application
called the Sox shop the reason that we
did that was that so the company I work
for we've works is based in the
container ecosystem so we built around
docker as an emerging phenomenon and
there are lots of lots of other vendors
in this space and there are lots of
vendor demos lots of people show off
their their technology and in various
ways but well there's lots of talk about
micro services there are no actual micro
services demos all of the demo
applications that you see with for like
fig which turned into docker compose or
or kubernetes typically these silly
little Noddy things like has anyone seen
the the fig counter that just increments
a number in a Redis database it's like
you hit reload and it increments the
number end times it's it's not really a
realistic example and similarly the the
kubernetes a canonical example for the
kubernetes application is a guestbook
that's just a PHP guest book written in
Redis sorry written to connect to a
Redis database and and so we we wanted
to to come up with something a little
bit more realistic so we built this this
sample microservices application called
the sock shop and so this is it it's not
much to look at we're not really from 10
people we do have good some good front
end people but they didn't work on this
and but if it's a working ecommerce
application for selling socks and and
that's fine
it's kind of a good realistic use case
it's not much to look at but it's it's
much more interesting in the backend
so today I'm going to talk a little bit
about the goals for this application and
we can look at the application and poke
it a bit deploy it to a few different
places and and talk a little bit about
microservices docker kubernetes and then
at the end I've got a little section on
some of the internals of one of the
tools that I'm going to show you called
weave net so when we were building the
when we were building the sock shop
there were a number of goals I mean we
wanted to demonstrate micro-services
best practices and in fact we ended up
demonstrating micro-services best
practice and also some micro-services
mistakes so it was a pretty interesting
learning experience so so for example we
we learned we learned about when
coupling is necessary so presumably the
folks here are familiar with the concept
of micro services some nods yeah okay so
so we learnt about some of the cases
where we're coupling was necessary
obviously it's nice if all your micro
services can be as independent from each
other as possible so you can have
different teams working on different
ones but but when you're adding or
removing whole micro services or
changing this structure of the
application there's obviously some
inherent dependencies formed because the
things that need to point to the new
shape of things need to change as well
so we had some issues where we forgot
about that we made added added a micro
service and deleted two of them and and
and and we we didn't deal with version
dependencies very well so so it was an
interesting sort of real-world
experience of sort of try to practice
what we preach another goal was to be
cross-platform so this is sort of in a
sense perhaps slightly unrealistic for a
typical user but we figured out how to
deploy the SoCs shop to docker docker
compose docker swarm kubernetes DCOs
mesosphere marathon
which are kind of the same thing
kubernetes ECS and i think we've got
about 13 different integrations and that
was also really interesting because we
got to learn about some of the
differences between those different
platforms and we sort of settled on this
fairly standard way of building the
application such that all of the
container images that make up the
different micro-services use the same
images and they all assume the existence
of dns for service discovery for example
and and then it's up to the platform to
provide those the basic services so that
things can be brought up things can be
scaled things can find each other using
dns so yeah I would rate us pretty well
on on the cross-platform aspect we've
got pretty broad coverage but support
for some of the orchestrators is pretty
experimental still so it's kind of
interesting if you look at the the
mezzos and marathon example that it's
with mezzos and marathon you're still
left to sort of at least when I last
played with it you you're given quite a
lot of pieces and you're expected to
assemble the car yourself if you know
what I mean so so we didn't have sort of
out of the box container networking we
didn't have out of the box a service
discovery when when I when I tried that
and so we had to add some bits to get
that working we also wanted to
demonstrate the benefits of continuous
integration and deployment so we
obviously wanted developers working on
the Sox shop to be able to deploy
changes easily to individual micro
services and to have that automated at
least into a staging environment so that
whenever a change gets made that that
deployment happens quickly that's
definitely a work in progress that
there's work with we're still developing
integration tests and things that
allow that CI system to be more
realistic because you obviously want to
gate a deployment on it on a failed test
we wanted to sort of demonstrate oh and
the other thing about about continuous
integration and continuous delivery is
that when we were deploying to Cuba
Nettie's we found some gaps in sort of
plugging the output of the CI system
into the input of Cuba Nettie's so there
was it wasn't immediately obvious how to
match up which versions of the code
match on to which versions of the docker
images and to be able to control the
deployment of those in the same way and
that actually led to us developing a a
tool that we call flux which we switch
in fact flux was developed so the Sox
shop is microservices sample app but we
also run a production deployment of
we've cloud which is one of the tools
I'll show you and and we've cloud is run
on kubernetes on AWS in production and
it was during the development of that
that we really found this pain point
with with continuous delivery and so we
developed flux as a tool to to help with
that and it's it's interesting as a
developer tools company to be dogfooding
everything we do and making sure that if
we come across pain points in our own
application development then we can
sometimes turn those into into open
source projects and services ok so we
also wanted to demonstrate how DevOps
and micro services complement each other
and that was definitely true we were
able to work in smaller groups we were
able to fit the developer could fit a
micro service in his or her head quite
easily and indeed when you're not
changing the structural aspects you
could independently upgrade and deploy
them but the main thing was that we
wanted to provide this real life
a testable application for various
orchestration platforms and and this is
important to us because we're trying to
build tools that are useful to
developers who are doing this stuff and
it allowed us to really show show it
show it working for real so this is the
application or at least when I first
loaded up the application and took a
look at the readme this is what I
thought the application was now there
are various different components they
talk to each other in in a fairly
logical way so for example we have the
UI which talks to various different API
is everything's rest and at the bottom
you can see all of the different
languages that are in the various
different Sox shop repos and so one of
the things that we wanted to do was
develop different some of these services
in different languages and we succeeded
so some of them are written in spring
some of them are written in go some of
them are written in node and there's a
whirring amount of shell so what he did
noticed though was when I pulled up this
this diagram in the readme at the
diagram I thought it was being pretty
useful but it says that there's an elk
stack and when I looked around in the
docker images I couldn't find an elk
stack so I was like I wish there was a
better way of figuring out what was
actually running in my app so that's the
first demo I'm going to show you I'm
going to show you a tool called scope
that we've that we've developed which
can show you what's running in your
application in what's sort of like a
live architecture diagram so it avoids
this problem of like oh I don't have an
elk stack so let me just try that
okay
so I've got a docker compose file here
and so you can see all of the different
services in the application so you can
see we've got this front-end we've got
an edge root or a catalog and so on and
so on as far as really long so it's
difficult to sort of get a sense of how
the application fits together just by by
looking at this file but what I did
earlier was I ran docker compose up - D
I'll let you take my word for that it
takes a little while for all the
different services to spin up on this
tiny little laptop but I can I can now
do docker PS and I can see that I've got
all these different pieces up and
running and again it's still kind of
difficult to see how everything fits
together just from this long list so the
next thing I was the next thing I did
was I went to weave cloud
so we've cloud is a hosted version of
some of our different tools you can also
run them on your own if you want to and
the one I'm going to show you right now
is called scope and I can just run scope
launch and that specifies a service
token and that service token sort of
ties this darker instance to this
account or instance in in weave cloud
and so you can have multiple instances
and so you can organize yourself in a
reasonable way there so I can see that
let me just pull that up
so I can see that the probe connected
this little blue dot mobi is the name of
my doc of the M because I'm running
doctor for Mac I can click and view the
instance and then I can see all the
different components show up as
containers and so this this is slightly
more useful than just a straight list
you can click on one and see what it's
doing you can even get a shell inside it
if you want to holds up oh no I should
have click that button and find out
what's running just the app on port 80
and so on and but what what's more
useful is is actually being able to see
this application to join up and see the
structure of the application so I'll
load up the app so running locally on my
laptop and let's buy some socks
who wants who wants which socks colorful
ones yeah all right
colorful ones are very popular pretty
much every time I do this demo people
want the colorful ones okay so I've
added the socks to the to the cart I got
three items in the cart I proceed to
checkout okay so that's that's enough so
what we should see here is in a second
we should see that some of those
different components starts joining up
and sometimes they do
I'll show you a stress test as well and
when we deploy this in production and we
we might get get more like seeing that
happening okay so next so let's just
talk about what what just happened so
I'll take you through so this is what
scope is supposed to look like when it
joins up and actually to generate this
picture I ran a load test on the
application so it caused all the
different pieces to talk to each other
and scope was able to detect the network
connections between them the scope probe
actually introspects what's happening in
the kernel it it scrapes the output of
/proc at the moment we're working on an
e BPF implementation that's going to be
much more efficient than than scraping
proc but basically it's able to figure
out even when container is running
across or containers are running across
more than one host it's able to show you
all the connections between them in
there in a live sort of fashion so so
what what happened when I put those
colorful socks in my basket was that
requests were coming into the front end
then they were going to the catalog
service to list the items in the catalog
I added things into my cart I went into
the cart service with the cart database
then I connected to the login service
where I would have done which connected
the account service which connected to
the orders service so you can see it's
very micro services e we've we've split
it up into as many different pieces as
we as we could let me just switch
this view sorry
so of course each service is small
simple and self-contained each service
can be maintained by a separate team and
upgraded and deployed independently of
the others each service has its own each
service that has state obviously needs
to have its own independent database so
that those database schema upgrades
don't need to be synchronized across
different teams and so we're trying to
decouple things as much as you possibly
can
and of course different teams can use
whatever language they want okay so
let's take the app that I've got up and
running on my laptop and deploy it to
production so in order to do that I'm
going to spin up a cuba Nettie's cluster
I'm going to use a tool that we got
involved in helping out working on
called cube admin and I'm going to
install we've net as part of that
application as part of that deployment
we've net is a container network it's
one of the tools that we develop and it
allows containers on different houses to
find each other and talk to each other
and it can be installed as a pod network
as part of the setup of kubernetes so
who here has heard of cube Nettie's okay
so most people for those who haven't
it's who here has heard of docker okay
everyone's heard of docker cool so what
I just showed wasn't completely baffling
hopefully so so kubernetes is just very
quickly a container Orchestrator that
builds on top of docker so dr is just to
contain a runtime that will sit on a
single host typically although they are
now adding orchestration to the docker
product as well but back when docker was
just single host cuba Nettie's started
as a project from google to manage
containers across a fleet of machines a
set of machines and and so you create
well I'll show you rather than just
talking about it okay so
so in order to that's visible right okay
great
so in order to spin up a Cuban eTI's
cluster I'm going to get some computers
actually just going to be following a
guide that we wrote on the Cuban
Nettie's docks so before we started
working on this yeah so before we
started working on cou Badman which is
this tool that now ships with kubernetes
the kubernetes was notoriously difficult
to install I see some nods some people
have tried installing kubernetes clearly
and they've they felt the pain I tried
it once it took me about three days and
I ended up debugging anyway there was
the version of the Kubler was secretly
different even though coop although coop
cuddle versions stuff was telling me it
was running one version but the couplet
was running a different version because
there's encore OS but anyway that's a
whole nother story but but cube admin
makes it insanely easy to install
kubernetes at least that's the goal and
it just requires some computers running
Linux which is a nice sort of baseline
everyone knows how to get computers
running Linux and everyone everyone
probably has their own way of wanting to
get computers running Linux depending on
their environment so some people might
want to use Tara forms and people who
might want to like boot up raspberry
pies other people want to like use
vSphere in their own data center or
whatever so so today I'm going to use
digitalocean and I spun up three VMs
earlier and here they are I promise I
haven't done anything to them apart from
turn them on so these are completely
fresh
so I'm going to just log into each of
the VMs in turn
I'm going to do this trick so I can type
the same thing into all the the VMS so
these are just a bunch of 1604 VMS so i
can start by installing the cuba
Nettie's packages okay that's just an
apt repo which is nice and simple
when take a look
and so um yeah we just move on to the
next step
and so the structure of Cuba Nettie's is
that it has a set of machines that are
masters in this example I'm going to use
a single master and then a set of
machines that are nodes and the nodes
are where the actual workloads run
typically so the containers that you
deploy to the cluster will run on the
nodes the the master runs an API server
scheduler controller manager at CD
cluster database and various other bits
okay so I'm gonna go out of synchronized
mode now because I'm going to different
things to different machines so the
first thing I'm going to run is this new
cube admin command but as I mentioned we
got involved in in helping out on we're
gonna run cube admin in it and so what's
that well that's done it's generated a
random token that acts as a bearer token
or a shared secret between the different
machines and that allows the different
machines to authenticate to each other
securely so it's then setting up public
key infrastructure so it's generating
certificates and it's then waiting for
the control plane to become become ready
and what that's doing under the hood
that started up the cubelet the cubelet
is the of the beating heart of
kubernetes on each of the machines it
runs it's responsible for actually
running the containers and as that
control plane becomes ready what that
means is that the API server the cubelet
has started up the API server using
static pods which statically configured
on that master because this is a
bootstrapping problem we need to get the
thing up and running and then and then
it spits out this command which you can
go and run on other machines and so cube
admin join what that's going to do is
it's going to say okay I'm being told a
token and the address of a master armed
with that information I can go and reach
out to the master and I can use
JWT which is a cryptographic protocol
for exchanging signed and encrypted
information between peers and say hey
without actually sending the secret
which is the second part here over the
wire it does crypto to establish trust
between the different machines and then
using that trusted connection it sends
it does a TLS bootstrapping handshake so
we'll see that now I'll just run this
and it's really really quick it's just
doing that little transaction it didn't
need to download anything on the nodes
because the couplet was already running
there and and what that did was it asked
the the master hey I'm a new node I I
know this I know this token I can prove
it to you even without telling you the
token using crypto and and I'd like to
join your cluster please and the master
in in a cube admin setup by default is
configured to automatically accept any
certificate signing request that come
from new nodes there would be an
alternative mode here where an admin
would have to say look at a list of
nodes that have requested to join and be
like yes that one's okay I can match
that up somehow out of bandwidth that
machine over there so I'm definitely
secure okay so I can now use cube cuddle
on the master and I can do cube cuddle
get nodes and I can see that I've got
three code mesh nodes up and running
ready to run workloads so mmm my cluster
isn't quite ready yet what I now need to
do is install a pod Network and as I
mentioned here it is just I think I was
looking for so a dime as I mentioned
we've net is one of those available pod
networks
one of the nice things about weave net
is that users gossip and Ciardi T's to
avoid requiring a central store and
actually just late last night I was
recording a demo of federated kubernetes
that uses a single weave net across
multiple clouds which I won't show now
because I probably won't have time
although if we do have time I can show
you if you're interested but but so the
federated kubernetes really really needs
to not have a single datastore because
you don't want your network to be
beholden to a net CD cluster that's
running like in one specific cloud or in
one specific data center so anyway
without further ado let's go and install
that that network and one of the cool
things about kubernetes now is that you
can install a CNI network with a single
command and that deploys the CNI network
across all the nodes as a daemon set and
in kubernetes that daemon set is just a
pod description of pods are sets of
containers and so a daemon set is a set
of containers that are just told to run
on all the computers so this is useful
for like system services that need to
run on all the machines and we've also
got a daemon set for scope which I'll
show you in a minute so so in this way
we're able to to set up a weave network
and if we let me just find this so if we
now run cube cut' will get pods or
namespaces the way that you tell that
your network is up and running is when
your cube dns pod goes to running
because dns depends on the network so
okay so we've got a kubernetes cluster
up and running it was actually very
little typing even though I talked a lot
so that's an improvement on where it was
before and now we can try deploying the
sock shop so actually as part of this
we've got
some configuration for the sock shop in
this tutorial and this is all on the
official kubernetes Doc's by the way so
you can try it at home so I'm going to
start by creating a namespace name
spaces in kubernetes are like different
workspaces they can be different
security contexts and basically they're
like environments in which sets of other
API objects exist and now we can apply
to that namespace this manifest file
which well that's applying I can show
you and so this is very similar to the
docker compose file we saw earlier it's
really just a list of all all the bits
and hopefully we've got okay
okay
so we should be able to do cube cuddle
get pods - end sock shock and we can see
that some of those containers are so
starting up that just means they're
downloading the docker images probably
from the docker hub and very shortly we
should see those go to running I'm just
gonna check oh yeah it is a node port
okay I don't know why that didn't show
up in the config but because this
cluster is just running on digitalocean
on machines running Linux it doesn't
have any cloud provider integrations
configured kubernetes does support cloud
provider integrations so you can do
things like automatically provision EBS
volumes on AWS for stateful services
which is pretty cool they can then
follow the container around like
databases because database is like
having their data you can also
automatically provision load balancers
using cuba Nettie's and various other
bits and pieces but we're not going to
do any of that fancy stuff today we're
just going to use what's called node
port which is like an alternative to a
load balancer node port just says hey
give me a port on all the machines and
root that port on all the machines to a
specific service and so if we don't
specify what no port we want then
kubernetes just randomly allocates one
for each service in the in the high
range of port numbers between 30,000 and
33,000 I think okay so let's see shop
might now be up and running okay it is
so this is the moment of truth
so that's the port I want I can pick any
one of these machines and go to the IP
address and huzzah we have our socks
chopped up and running
Oh hopefully we don't have any socks
yeah
sometimes it takes a minute well that's
running well that's starting there we go
got our socks excellent so while that's
starting up we can also deploy we've
scope which is listed here in the in the
list of add-ons which is the same UI I
showed you earlier and so using using
this command here I can also deploy a
scope on my kubernetes cluster just like
I deployed it locally on my laptop when
I showed you the laptop demo and the
token I need is in we've cloud which is
here so I'm going to switch to a
different instance and we've cloud which
is also a bit like a workspace and
switch to the Kuban eTI's demo instance
and I haven't plugged anything in yet
here so plug his service tokens in plug
that service token in and that's created
another demon set so again the weaves go
probe is going to run across all the
machines it's gonna figure out what
containers are running here it's also
got integration with with kubernetes api
so it can show things like pods replica
sets etc and any moment now we'll see
the probes show up they take a little
time because it's downloading the docker
images for weave scope as well as we
speak so let's just give that a minute
okay our first machine has shown up I'm
expecting three of them to show up so
probably get a random distribution
okay that's probably enough to get
started it should okay cool so already
the promised joining up that I that I
failed to achieve in the laptop demo has
already started happening here so we can
see already that the front end is is
talking to the cart and the catalog and
the catalog is talking to the catalog
database and the cart is talking to the
cart database and that's all good we
don't have everything fully joined up in
this application yet and that's because
we haven't actually pushed any traffic
through the application yet so I should
be able to run a quick load test if I
can remember where I put it
this is a Python program so I need to do
something with virtually and and I don't
have it in my history so I'm gonna have
to figure out how to run it again sorry
about this so let me just look on the
microservices demo repo
so there are some instructions in here
for for running a load test there we go
and if I recall correctly I can
run a load test against the out there
just while that warms up we can also go
through and buy some socks colorful ones
anyone else for any other type of socks
which one holy yeah I like the holy ones
though they are $99 I'm pretty sure I
don't have that much for my credit cards
so I'm gonna have to say and seriously
the there is a limit built into the
amount that you can buy in any one
transaction
okay so I've logged in as a user I'll
try the holy socks in a minute but but
here I'm just gonna get the colorful
ones proceed to the checkout and let's
go and see yeah okay so we can see that
the front end is now connected to the
user service when I logged in so we get
this sort of live display of what's
going on and and that's kind of nice
okay so I think that's everything I
wanted to show in the in the kubernetes
app in the kubernetes demo so just to
recap we installed kubernetes from
scratch on some machines on digital
ocean we then deployed the same socks
shop application that we've built as a
set of micro services we then deployed
we've scope as part of installing we've
Cuba Nettie's we installed we've net
which allows the containers to even talk
to each other then we installed we've
scope which was able to push information
about which containers they were and
which ones we're talking to each other
into this we've we've cloud application
so so that's that demo
so a little bit more content I can find
the right button
yes Oh so to recap we started out with
docker for Mac we used a compose file
there docker compose for anyone who
doesn't know is fairly simple tool which
allows you to define in a nice friendly
amel format here are the things that
make up my services and where things are
containers with images image names that
get pulled down and define the
connections between them and then we
used weave scope plugged into weave
cloud to push the information about
those containers up to that UI I showed
you then in kubernetes we spun up a
kubernetes from spin cluster from
scratch using that cube admin tool that
as I mentioned myself and like some of
my colleagues that weave works worked on
with the kubernetes community then we
spun up the sock shop using the Kuban
Nettie's manifest which is kind of like
a an equivalent to the docker compose
that we saw earlier that we deployed
we've net using a daemon set and then we
also deployed we've scoped probes using
a daemon set and plug those into weave
cloud as well so I'm going to talk a
little bit about we've met because
developing weave net was kind of
interesting the it's a pod Network what
that means in its described as a pod
networking Cuba Nettie's because
kubernetes has sets of containers that
are pods that want to be able to talk to
each other and the idea is that it gives
each each pod or each container its own
IP address on an overlay network so it
forms an overlay Network between the
hosts using gossip and Ciardi T's to to
share information between between the
nodes and then it does I Pam so IP
address management so allocates IP a
allocates the set of IP addresses to
each machine and it can dynamically
reconfigure which I which IP ranges
exist on each machine and then out of
those IP ranges it can automatically
allocate IPs for containers that come
along and kubernetes plugs into it by
what's called CNI which is the container
network interface which is a standard
way of plugging in these network
provider
into into kubernetes um and I want to
take a brief digression to to talk a
little bit about how we've networks
under the hood so we factored out under
the bonnet I should say so it factored
week so we factored out a lot of the
more interesting gossip and see rdt
logic in weave net into a separate
golang library that we call weave mesh
and so if anyone wants to play with
gossips and see oddities and build their
own distributed system that uses them
then you can just pick up weave mesh and
and use it as a go long library and
vendor it into your project as you
normally do so yeah this is a library
that's used by net and and also weave
DNS and there's some kind of interesting
computer science in it and this this
sort of audience may already know this
so I apologize if if I'm repeating
things that you already know but so
Alexis our CEO likes to describe weave
net as being invincible like you can
drive a truck over it and it isn't
working and I pretty much agree with
that because with with most of the
Container networking options out there
they rely on a centralized data store
and that centralized data store is
something like fcd and SCD users raft
and raft favors it favors CP in the cap
theorem so it's consistent and partition
tolerant and that means that sacrifices
availability in the face of network
partitions right so networks have
network partitions all the time you want
your network to carry on working if you
have a network partition normal networks
do things like bgp which build which are
like how the internet works are
available and partition tolerant for
exactly that reason the internet would
not scale if there was a big centralized
database of all the IP addresses
somewhere so we kind of feel righteously
indignant
or whatever about the the fact that this
is actually the right architectural
model to use both for IP address
allocation as well as things like
service discovery and so how that works
with weave with weave mesh is that you
might have a set of machines like this
so so let's assume these are processes
that are running on different machines
that each of the red boxes and so the
goal here is is that we we get all the
machines to agree on what the number is
so let's assume that there's one sort of
value that we're trying to get everyone
to eventually agree on and so gossip is
this approach to communication in a
distributed system which favors eventual
consistency as you as you know the
network is not reliable and the basic
idea here is that even if there's a
partition between the top left and the
top right nodes in in this network and
note that this is a partial partition
it's not a complete network partition
then by gossiping with each other about
what what they know then you the guy in
the top right will eventually be able to
learn about the value that was given to
the node in that in the top left and so
that all seems pretty trivial that's
there would be a simple algorithm to
implement like I learn a value tell my
peers but obviously it's not that simple
that only describes the communication
model which isn't enough because if
someone updates the top left with value
one and the top right with value two and
then they those those values meet in the
middle then the question is which one is
right if you're favoring this eventually
consistent model then you can't assume
that you've achieved quorum on any value
that you think you're going to agree on
ahead of committing it to a node you
just have to go ahead and commit it and
then hope that it will propagate and so
you have to resolve conflicts you always
you need data structures and algorithms
that can always figure out how to
resolve a conflict and so as you can see
the message may need to be gossiped many
hops and
it's not clear which one will win and
what's more you you're gonna deal with
you're gonna have to deal with a dynamic
Network which is experiencing partial
failure constantly like the Internet and
so the network is coming and going and
messages will inevitably end up out of
order or be repeated or be delayed so
see our DTS are a solution to this
problem and the solution to the problem
is to be clever about the data structure
that you're gossiping and basically so
that you can when you get updates they
can always be merged irrespective of how
and when they arrive and whichever order
the updates arrive in everyone always
comes to the same idea about what the
state of the system is eventually and so
C R D T stands for a conflict-free
replicated data type and you define a
data structure appropriate for your app
and you define this merge operation so
where you see the circle with a plus in
it I'm going to pronounce that merge and
merge is associative which means that
you can do B then C first and then merge
a later or vice versa it's commutative
which means that a merge B is the same
as B merge a is idempotent which means
that you can do it twice and it doesn't
change and so at least to me sort of
intuitively these requirements on on the
data structure and the merge function in
particular makes sense because if you
have this merge operation then messages
can flow around the network in any order
they can get missed they can get
reordered they can get delivered 3,000
times and your system will still
converge on the same idea of what the
current state is and so this is really
valuable if you build systems like we've
met that do IP address management that
do service discovery that that figure
out how to route a message around in a
network it's really useful to be able to
do this rather than depending on on a
central data store and by the way this
is how Google Docs works so if you've
ever made some changes while you're
offline and then someone else has made
some changes to a doc and everything
just seems to work it's because Google
Docs is implemented in terms of C
oddities
so some examples of CRD teas so I talked
in general about the requirements for
the data structure in the merge
operation but some concrete examples are
an add only set so an add only set is
pretty trivial although arguably not
that useful depending on the application
because the merge operation is just
Union so if you are holding on to some
local state and you get a new message
saying here's the update then you can
just like Union the two sets together
and you'll satisfy these these three
requirements you can you can also have a
latest value in singleton which is
useful if you if you just want to store
one thing we did a prototype actually of
cube admin which unfortunately didn't
make it that was going to use CRE teasin
and mesh which in which the the clusters
see a cert the one that sets up the
trust between the it allows the nodes
that are joining the master to trust
that the master is who they claim to be
because they've had the the CA cert sort
of given them given to them somehow we
were going to gossiped the sea-ice over
a secure Channel and in that case the CA
so it would be an example of a latest
value in singleton because you can just
attach a timestamp to it and then if you
hear about a newer CA cert then you can
just replace the one that you've got so
you can you can satisfy those
requirements if you want to implement a
set with deletion ie a set that you can
add items to and remove items from then
that's a little bit trickier but you can
give every element an ID sort of like a
UUID and then maintain a separate add
only set of deleted items using an add
only set so you can implement these more
complex CRE T's in terms of the simpler
ones and there are lots more so that the
link there is is to an interesting
experiment using defining CR DTS on
arbitrary JSON documents
so I'm almost out of time I'll push on
through the rest of these slides so if
you're interested in implementing
something in using weave mesh then in
general the form of an update from a
peer is like a merge be become see where
a is the update the update could have
been delivered twice or come in any
order a B is the current state stored in
memory or on disk on that process and
then you just need to define these three
golang interface methods so merge
received merged lter and merge complete
they all update the local state to see
but they differ in that merge complete
return see merge received two returns a
and merge Delta returns the Delta from B
to C which notably isn't just the update
a because the definition of merge might
say something like throw away an update
to one part of the data structure if the
incoming update is out-of-date so merge
Delta was the only one I really had
trouble getting my head around but
that's that's how it works it's it's not
really that complicated and so anyway
when applied to weave net which is one
of the tools I showed you in kubernetes
like I say it doesn't need a centralized
store it carries on working during
network partitions on both sides so you
can do IP address allocation on both
sides of a network partition and then
when you heal you carry on working and
like I say it's particularly interested
in particularly interesting in federated
clusters so I'll leave it there there
are some URLs if you want to try the
stuff yourself and thank you very much
we have time for we could do one
question no questions
oh yeah a question about the security so
you it's you know you've got the
certificate kind of infrastructure there
and that's great for kind of creating
TLS collecting connections what have you
good solution for securing UDP traffic
between different components yeah so yes
so the the good question so that the
security that there are sort of two
different aspects to the security the
first one I showed you as you mentioned
was the TLS certificate dance between
the different kubernetes components but
if you have UDP traffic then you can
just run it over we've met because we've
net operates at layer two it emulates a
switch so it's pretty easy to comprehend
it's an overlay Network because it runs
layer to overlay of three so so that
means you can run anything that you run
on your layer 2 network over we've net
and so one of so you can run unit so you
can run UDP over we've net that works
great you can also run multicast over
we've now which is interesting we have
some customers in finance who are doing
that for like stock trading and that for
example means that you can use multicast
on AWS which wasn't possible before it's
kind of interesting and not just one
last thing
we've net also has encryption built into
it so you can give all of your peers a
shared secret and they'll encrypt all
the traffic so you can do encrypted UDP
between containers okay let's thank the
speaker again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>