<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Fixing Erlang’s Distribution Protocol - Peer Stritzinger - EUC17 | Coder Coacher - Coaching Coders</title><meta content="Fixing Erlang’s Distribution Protocol - Peer Stritzinger - EUC17 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Fixing Erlang’s Distribution Protocol - Peer Stritzinger - EUC17</b></h2><h5 class="post__date">2017-07-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/CVpcrYH18NE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">test oh this works okay hello welcome in
Stockholm I'm glad to be here again and
this time talking about fixing Alan's
distribution so why do we want to fix
the things so the whole thing is why did
I start with air long actually so this
let's start by their old Romans I was
building this device and it's a flash
device for automotive system like a
large embedded device which is like not
important for the following but the
predecessor device had lots of channels
like lots of parallel concurrent chance
when every customer wanted a different
number of channels so we thought we'd
build a new version like this have like
networked device which behaves like one
big device and back then in 2007 I heard
about a language that had built-in
distribution and so I tried it out and
that's always clear that's how I got
here in the beginning and so I hear this
story from many people that they're
basically they hear about the
distributed the transparent distribution
of air lung and that attracts them the
first time to the language so nowadays
is also fault around scalability but the
distribution is one story that you keep
hearing but then when you actually use
it in large scale you see that there are
some limitations and then you need to
work around the limitations or do
something about it and that's the rest
of the talk
so the first time when we saw the
limitations is when I did the port to
the hard real-time operating system for
small embedded systems because for the
application area which was industrial
manufacturing like conveyor belts for
like manufacturing plants which were
which were supposed to be controlled by
a lot of these nodes talking to each
other
more or less reliably so you be needed
basically a locality a reliable look
local communication we need less
reliable communication like over longer
distances and for this well it's I have
a video so at least something is moving
the rest of the talk is more dry so
that's what we actually controlling
there there's 15 LM notes controlling an
8 meter I 8 meter stretch of
manufacturing transport system so this
is all run by along everything
distributed so for this we need 15 nodes
because you want to have local i/o and
safe a lot of like wires going running
through around the manufacturing plant
because this is a major cost factor the
wires cost money and putting them there
cost even more money so you want to have
distributed system if you want to
improve something and have local wires
to the just to the sensors and actuators
and it's another picture of the system
so this was a this was a research system
which was shown on the cbiit and that
was the exhibition of the seebut but the
final product actually should like run a
real factory and real factories came get
pretty large and we estimated that we
need like on one factory line which was
our unit of like operation we need up to
1,000 nodes so most of you probably know
that somewhere between these 50 notes
they were working and the thousand nodes
we were wanting alan distribution breaks
so i'm not saying when because there's
different numbers there's been an old
number which were was 70 nodes and then
i we heard about 200 nodes but these
were like 200 large nodes like servers
but we have like tiny notes left 20
megahertz so there are like an old
server very old server what much memory
and so we were supposing that it will
break earlier first so we did not build
a network and see when it breaks we
wanted to have the solution before so
how can we actually stay this airline
solution or we're in the sorry error
distribution and
and scale up there was one thing that
was already presented here this
conference like in the past a result of
research thing which was called SDL
unscalable distributable aron
distribution alan we check it out i
talked about it already it didn't work
for us because it's mainly a solution of
the namespace the global namespace which
gives you basically several sub
namespaces but that was five of my
followed enough force because we need to
actually talk to across the whole
network of the thousand nodes and have
local communication but we also need
have a few communication going a long
way like collecting metrics and
controlling the whole system getting it
up and getting down so that didn't work
for us there's a thing called hidden
notes I have one slide for that to
explain it for those who don't know it
the thing is the day-long distribution
wants to have a fully connected network
so if you have n nodes you get order of
n square links in the C Network these
feelings and the reason it actually want
to do this is actually the global
registry so there is high-level
components of a land distribution who
wants to needs actually a fully
connected network to make it work and
there's a way basically when this one is
component runs which is the global
registry is the major basically bad guy
here lecture makes sure that you get a
fully connected network so if only if
you connect a few nodes it basically
gets the list of nodes of all the nodes
connects them and then connects them all
together and there's a way basically to
hide it from from from global and that's
hidden nodes that's why they called
hidden nodes probably because they're
hidden from the list of nodes that
global cares about the global registry
the global name registry so you hide it
and then you can do your own
unfortunately you also on your own
because then you basically just get the
connections that you really make you
make a connection to a neighboring node
and this neighboring node but if you
don't want to talk to the nodes over
there
then you're known you have to basically
on the application level make sure that
the information somehow trickles through
your network and everybody has to do
this again and it's like it's a solution
but it's not so nice so basically that's
what we're running on this 15 note
system we have them as hidden notes and
we have application level knowledge of
our whole topology which is in there in
the demo case also not changing and
that's how we provided everything on the
application level one solution that is
very often used is basically they you
dip telling solute Airlink distributions
so you don't use it anymore or use it
only for a little thing the local thing
and follow the rest for the scalable
thing you use your own TCP connections
run your own protocol have your own data
dissemination layer which is usually
tuned to your application the sad thing
about this is that everybody has a
library they're like this everybody has
a scalable system has some library that
actually solves the problem outside of
the Erlang distribution but then we're
not actually using the disability alone
which in my case was the reason I
actually went along initially I mean
have more reasons to say but it was the
initial thing and especially on embedded
system attacks are actually quite neat
if you if you have your distribution the
data distribution thing built into the
core system because everything you built
on top of it needs more resources you
like you need to serialize the terms
implement protocols it's all extra stuff
and the distribution always comes with
say LM VM so why not use it when you are
like little constricted and thing and
that's why basically we come to the last
point why not actually fix the problems
in your own distribution
yeah I just put this slide in for hidden
notes for people who don't know how to
use them that's basically how do using
it you make a hidden note you started
with a special option and you basically
can do the function that lists the lists
on your notes has options and you can
better say tell me all my hidden
neighbors all their real connected notes
I'm there and tell me about all the
notes of my fully connected network so
there's basically two parts if you're
fully connected Network your local
cluster basically and hidden notes are
just hanging off other notes but you
can't find out anything about the
topology like how do I get from this
node to that hidden node over there that
that's there you're on your own so
fixing a long distribution if we fix
that we actually need to find out what's
the problem why does it why does it not
work for everybody
the fully connected Network I already
mentioned that doesn't scale because of
like number of connections closed with n
square and then if you want to have some
keepalive traffic the keep on a perfect
at the at the final point basically they
keep alive signals are all your node
processors at some point because it gets
to keep alive if you have a node system
cells know this would get keepalive
messages from 1,000 other nodes and if
you lose four of those then the node
gets disconnected and then it reconnects
and then you get error messages and it's
like not nice there's another problem
that all the all the messages you send
over to another node no matter from
which process to which process go
through one TCP link and if you send a
huge message like you have like big air
long term and you want to send it over
to the other side then it goes on to
this peak connection and everybody else
has to wait with their messages until
the big messages went through this
effect is called head-of-line blocking
because it's the message at the head of
the line which basically blocks
everybody and takes forever like the
post office somebody the post office
needs to solve a lot of very complicated
problems
and everybody else so just wants to drop
the letter have to wait especially also
the keepalive messages which then if you
send a really huge message over then you
actually can drop keepalive messages or
delay them so far that you actually get
errors so this is one thing a lot of
people basically had to solve then there
are some possible concurrency issues on
the higher levels like for example if
you use our PC if you want to use that
and don't recommend for it to actually
do some scalable things we will find out
that all their RPC calls to one node go
through one process so I guess a
bottleneck there of course that can be
fixed and that's higher level and we
won't take care about the higher level
like how we fix the higher level we
really want to fix the lower level
because the higher level is actually
easier to fix if the lower level is a
has some different properties since we
ported airline to a hard real-time
operating system will be a kind of
running hard real-time operations it
would be pretty neat if you actually
could do hard real-time Network
connections so we could use protocols
that supply hard real-time to us between
our nodes and then have a distributed
hard real-time application because that
would make our possibilities much larger
so currently we are using software ALM
soft real-time and kind of crossing
fingers and actually works quite well
but we could do much more like speedier
applications like a robot arm like if
you want to hard real-time is in in my
fracturing for example is always used if
you need to synchronize depth several
access several motors that need to run
in sync and have a very detailed
schedule to observe because if then one
gets out of line then the robot makes
moves that you didn't plan for
and then basically its outline can
intersect each itself at some other
point which means it destroys all feels
really because hits itself or it hits
floor hits somebody else whatever
then there's also the issue security it
would be pre knew that if you could have
like secure links between Ellen notes
and fortunately the OTP team is already
working on that as I heard because there
is actually a project going on for a
while and inside the OTP team and that's
what I know that they are doing it
looking at heterogeneous networks so
that you can actually have different
types of links between two nodes and use
the different types of Link's for
different kinds of messages or I think
in their case you have basically the
link between some nodes is maybe
encrypted because it's like cross data
center and the link between other nodes
is not not encrypted because you want
the performance inside you data center
but for our application world would be
also need if you could actually have a
heterogeneous links between two nodes
between the same nodes basically one
node for normal messages and one link
for hard real-time messages or one link
for yeah it doesn't make sense to make
secure secure and non-secure messages
because then you probably everybody
finds a big daughter so yeah bad example
there is a there's a project going on in
the OTP team to distribute global add to
not a disability yeah yeah actually
distribute to scale it up to replace it
by something that scales better a
distributed hash table for the naming
thing so global registry is basically a
global registry global meaning
global between all the nodes in a
network where you can actually register
process with a name or with some
metadata and then you can send a message
or you get the process ID for this
process that can be somewhere else on
the network on a different note and so I
heard that they're working on a
distributed hash table please correct me
if I say anything about like what Bill
treat him does because I just hearing
from the outside
I also heard some at some point that
wasn't announced today there
plans to actually manage the links
because currently once two nodes are
connected with a link the link is just
kept up it stays forever you can shut it
down manually kind of but it's like by
itself never goes down even between
hidden nodes and often you have
basically some messages between all of
the notes during the startup system or
have us a rare message in a special case
but then frequent messages only between
some notes so you could actually shut
down all the links that you're not using
and there's something about like dynamic
link management that the distribution
link goes down when there there's
nothing going over it which then saves
all the keepalive messages for a link
that's never used every solution for
Erlang distribution usually involves
also EPMD they along port mapper daemon
which is used to find the tcp port where
they learn distribution systems on a for
for a special node because you can have
more than one l and node on our system
so you actually need to know like which
LM node on this system listens on which
this Peapod and that's the the the use
for the alum port mapper daemon which
provides this registry of name no names
tool to the port names so for example if
you want to have like like different
protocols between some nodes then it can
be should maybe know about that and tell
the other node yeah if you want to talk
to this node actually you should use SSL
and maybe it even can like help us with
the management of the certificates for
the embedded system I also needed a
solution for a PMD because we don't have
actually external processes and EPM P
likes to run in the axial process so
back then I implemented EPM every
infirmity PMD in pol arm which I'm happy
that is it being adopted by the OTP team
by now
as a potential future solution for a PMD
because it's much easier to extend if
it's in the air long code and it's a
pretty obvious application for Ellen
code like writing a server to talk to
and whatever so normally we would use
the along for this if you would need to
build something like this and yeah so
this is there already and much more
extensible than the C code especially
after he looked at the C code which is
kind of like collected a little bit of
Kraft over the years maybe there is
already support to plug in another
distribution protocol so you can
actually run your own I'm not going into
the details because that forgot to talk
us about like what but it's actually
there it's not not that well-documented
so it's kind of bit a little bit hard to
actually get it working but you could in
theory have SSL between ela nodes as the
distribution link and there's an example
in the OTP tree how to do that there's
some documentation also but you it's
like not like a user manual it's more
reference model you need to know what
you're doing so you can you can there's
a command line option where you can plug
in an another protocol distribution
module into the Allen thing in the and
this module needs to basically implement
this behavior which is mainly the
management behavior for the link and at
some point actually get the data over
from one link to the other you need a
port driver into the LLVM which normally
is the internet landed the network port
driver is used for the distribution but
you could basically do your own port
driver implement another protocol or
whatever encrypted one encrypted
whatever you want and then plug it in
but that's working today
so this area might need a little bit
like making it easier maybe for people
to plug in things because you don't
heard very often that people actually
plug in their own distribution protocol
and there might be a reason for that
so since I want to fix it I had a look
at the at the source code in in the
Allen runtime so actually find out how
does it actually work how how do we get
these messages from transparently from
one process and one node to the to
another processor our node so what I
found is that when you send the message
from a process that in the context of
the same process it's actually
sterilized
and it's basically doing terms binary so
this is simplification it's doing it's
doing the serial format for a long terms
that C realises the term it puts a
header in front which is also which is
usually just a serialize couple and then
it sends it off to the driver and the
driver is this poor driver I talked
about which then has a TCP connection to
the driver on the other end so this is
the other node and as far as I could
tell I'm not 100% sure but 95
interestingly the binary to term for the
whole term is actually done in the in
the in the context of the driver like
like centralized and when we have easier
lies the thing actually sent to the
processes so I would have expected that
this would be actually happen in the
processes also because then could like
run on on all the course so there is
there's a point of may be possible
optimization but maybe somebody tells me
yeah we tried that and it didn't work
could be hmm it works like that okay
then I read their source code wrong okay
I will fix the slide for the PDF thank
you
so let's let's have a show it look like
like what can you actually what can
everybody see what what during this
version is doing and there there are two
flags which you can send your in
compiled you can either edit the test or
see module in ERPs emulator now in UTS
simulator yes
or hello or you can you can like set it
during the compiler on options and that
sets basically that gives you visibility
and what actually is sent over the link
so prints out text when debug messages
when whenever something is going over
the distribution and I want to show you
what's actually going on there because I
like to have demos and if you're talking
about something you plan to do it's
actually how to do the demo
so such a different resolution again
Simone let's let my two windows
so what I prepared already is like two
distributed notes on running on this
laptop both compiled with this options
so the one is the node fool and the
other one is the notes bar as you could
probably imagine and they are connected
on ready if I do notes on fool you see
it knows about ones about power so
everything is in place and what I would
like to do is to send something from one
shell to the other shell and then let's
see what happens in there in the
distribution layer so to make that
easier I register name here whatever
test yeah I can for a moment make this a
little bit smaller than that's maybe too
small so the okay
that will storm around
no no a registered fubar ah yeah okay I
registered already when let's write it
out so it's named fubar so this this
Charlie's name football except now it
isn't because I crashed it okay let's
register it again no yeah
now we are there okay sorry about that
so now this shell has registered the
name fubar and what we do here is we
send to fubar add the note or add we
nose and let's just send a number like
55 no 42 of course and that's what we
get basically so you see that the first
they'd see CTL thing that's the tuple I
mentioned so that's the header of the of
the message so you get the sender the
sender end there and in the target which
is fubar and the message is 42 and the
the binary block here is basically the
long thing is what actually gets sent
over the wire and so as you can see the
same thing is received on the other end
and then it gets decoded and if I do
flush here on the shell I actually
should see my 42 so let's see what's in
our mailbox so I got 42 one other
experiment we could do is you could send
a nuts on so you can see now in the
message you can see the autumn text here
and what happens if I send the same
Optima ghin oh I get a different message
because there's a little optimization
there that if you send an autumn of a
distribution there is on each end of the
distribution there's an autumn table and
atom table once you send it once it's in
the autumn
and then it only sends index into the
autumn tables a dozen head sent all the
atoms again which would be a waste so
that's the reason you get a different
message that was already on off the demo
because I need to get on with it
otherwise I don't have time for my
suggestions so we started a little bit
later I get some extra let's make a deal
so there was a demo so you know
today
better how could we avoid having a fully
connected Network one way we could do
that actually did I yeah okay one way we
could do that is basically not seven
fully connected Network just don't have
all the connections like connect a few
of the nodes but not all but make sure
that basically you have a path through
the network but if you if you have a
path through the network of the nodes
then actually need to to route messages
you need to route the messages from one
node over several hops of other nodes to
the final node so for that we can
actually then decide how much TCP
connections we want depending on our
network topology maybe like map it to
the network topology or think about some
virtual topology or whatever you can do
lots of things when you can do message
routing the dynamic connection
management can help some applications
but only some and you can you can
combine if this message routing so you
basically if you have a route if you've
message routing like across your whole
network and you have like a
initialization message on the beginning
of your application is when you start
everything up then you could like to a
direct route more and then when when the
dynamic the link is basically taken down
because there's no messages going on
then it saves also a lot of links
between the nodes
but effectively what you need to do
what's not in the implementation at the
moment you need to forward messages that
you received over the distribution to
another distribution mode it should not
be those so hard but there are a little
bit actually a missing slides now sorry
about that
did I skip a slide
oh yeah no so their upcoming so let's
talk about the problems how do we
forward messages usually the way it's
done is already like shown to us if you
if you look at like an tcp/ip router or
an IP router so you get packets in you
look at the address where you want to go
if you have a table you look up in the
table and then you send it out by
another link we could do the same for a
long distribution so assuming you have a
table in every node which tells us where
which which is appealing basically which
distribution link every other node is
then we can basically look up in a table
and forward the message and of course
the same at the initial message send the
initial message and also go through this
table because it's like in the beginning
if you would have such a table it would
need to be like built into a RTS in a
low level it needs to be accessible from
the low level you want quick lookup for
the messages but you also want to like
is to be able to fill the routing tables
from the Erlang label because like the
way there it's configured which should
be accessible from the L example because
everybody wants something different
probably here in the routing table so I
was thinking about so but this is not
determined I was thinking about maybe we
could have you see our TS tables here
like especially RTS table which we use
for message lookup
sounds like possible use but that's
still open just a suggestion and they
also could use such a table for our hits
or ignores links such as so we can
actually see for these messages
don't use the main link use a pod return
link or for these messages use the
security secure link or for like for
example for small mess such as user
different like embedded link between
nodes could also make decisions on
message size possibly how would we
this message table at this routing table
one possibility is to do static routing
so it just configured it and like I put
up one example from for static routing
so we don't want a fully connected
Network so what's the next more easy
less less connected solution that would
be a so called hypercube so this bill
hypercube is basically extension of like
point line square cube tesseract the
four-dimensional and then go on and on
and on so basically always duplicate the
thing and you can in a hypercube of
order n you can have 2 to the power M
nodes which is plenty pretty soon and
the routing can be done basically by
looking at if you address the nodes like
this that you say basically that they
lower the upper level nodes have their
last bit with set 1 and then or level
have it 0 and so for each dimension you
have 1 bit and if you want to go from
here to there you know you have to flip
all the bits so every time you cross
such a line you flip one bit so we need
to flip all three bits if you want to go
from here to there if you want to go
from here to there we know I mean
there's only one bit difference so we
only need to flip this bit so we go over
this line that's the shortest path so
it's a very easy to make decisions how
to get from known from one node to the
other if you number them like this
that's just one suggestion which you can
make you can make a tree you can make
whatever your application demands but
what we also would would like to do here
is to have like networks like this
that's actually out the network in the
manufacturing use case looks like this
except like a very long stretch of 1,000
nodes which like mesh things with
shortcuts from here to there which you
could put in for to improve performance
and how do you actually configure this
this is kind of messy at first you have
to why all the thousand nodes and then
you have to write it down and then you
type it in a table and if you make a
mistake it doesn't work and then you can
it's very hard to debug so
there's a wave which is there since a
while and to actually discover the
topology of such a network which are
called routing protocols so this is a
higher level protocol which we can
implement an airline for example and
there have been some increment in the
alarm which discovers the topology and
distributes the important information of
the topology to every node so every node
can basically fill their routing table
with this topology information and the
way you should then today use writing
portals work is you you actually have to
hold rough topology in every node every
node knows the whole ecology of the
whole graph and you run Dijkstra
algorithm on it and find shortest paths
to every other node and that's what you
basically put in your routing table so
you actually get shortest path routing
in arbitrary networks as long as they're
connected of course like I rush through
this you can read it up afterwards
the routing protocols used nowadays are
all called links type protocols they
basically send like a certain number of
pick a certain type of packet to all the
neighbor nodes to all the nodes they
discover on their own in their network
said ok clarified okay and in each of
these nodes basically it's information
about like the other links and so you
just say I don't want to go into that
because ten minutes so this is a very
efficient way to distribute to discover
and distribute the whole network
topology of an arbitrary network and
then we can fill out a routing table and
that would actually be the power
manufacturing use cavity we actually
want to use something like this because
one of the major things the customer
wants is also configurability
because the configuration kind of sucks
for these large networks so it needs to
discover itself and it needs to repair
itself so this is done regularly so
whenever you one node finds to the
neighboring
goes down it does basically distribute
this information again and the graphic
at sixth and the routing to advocate
sixth and so pretty soon it's pretty
quickly converging that's one of the
major advances of the link state
protocols there have been other
protocols in the past which had two main
the main disadvantage that they don't
converge first so pretty pretty soon you
basically have new routes that's a few
variants that are used the best one is
ice ice and there's also OSPF because
the ietf isis from is from OSI like the
ease of people and ITF who does the
internet protocols want to deaf Thrones
or they implement that invented OSPF
which is similar but different and like
a few years behind behind ice ice which
is like which is only their disadvantage
that has like a weird name now but it's
like older than other eyes eyes so yeah
okay I talked about routing messages as
there would be no problems with that
that's the slides I wanted to have
before router messages have a few like
problems they can get out of order
because when their routing table changes
while after one message went through the
through the graph the next message might
take another route which is faster like
I plug in a shortcut and then like
messages overtake each other kind of
yeah okay they get out of order they can
get lost if I'm so before if I have two
nodes and I want it's appealing between
the nodes and the two nodes are alive
which we are constantly watched
basically if they're alive if I send a
message over this TCP link and I don't
get an arrow I know the other end
basically eventually gets the message
but if I have routing then the message
in transit is on on some other nodes I
don't know anything about it and if this
node dies my message is gone while then
my messages on the node so we can lose
messages now and at least for temporary
times messages also can go in circles
especially when basically the routing
table changes then you get one topology
while the message is in transit and then
the topology change then it goes back
and you can't get temporary circles and
you don't want to have that if that's a
real problem that depends on the routing
protocol but you might want to have
fixed whatnot to keep these messages
forever maybe then on the other hand in
the LLVM you have a few invariants we
are which everybody relies on so all the
messages between two processors no
matter if they're on the same neuron on
different nodes are to be received in
there are two basically people to be put
in the mailbox in order they're sent not
not between unrelated processes rusty
five process a and B in a sense
message one and then message two I
expect if I receive trust any message to
get first one and then two and not the
other way round if it's on rarity
processes we don't need to care about
that because they're already reordered
in all kinds of weird things and there's
basically theoretically impossible to
actually have an ordering of another one
SMP system at least we have an
additional lesser-known thing which is
actually only true for new hour-long
systems I forgot which version it was
it's one of our I probably nobody has a
has a version of a long-running in in
production which which for which this is
not true so if you do node monitoring in
monitoring your neighbor node or the
connected node and then you basically if
you monitor the node you get node up and
know down messages so you get basically
information when your note comes up and
when it goes wrong and it's guaranteed
that all messages from this node or
between the node up and note down so
there's not one stray message before the
first note down or the a few left over
messages after the first before the
first node up and a few stray messages
after the last note down so this is also
something we should actually
keep in the semantics so how do we do
this we have the requirements we need to
reorder the messages because they can
get out of order but we need them in
order for a pair of process so we need
to reorder the messages between two
processes we need to detect when we lose
messages because then we need to do
something because you're not supposed to
lose messages if there's no note down I
mean if the note is down the other
notice down I don't expect them their
messages to be there because the note is
done but if the message to trust gets
lost I need to do something different
and we probably want to drop the
messages that go in circles or have a
routing protocol that can't wherever
where this is avoided so the last thing
is pretty easy you have like a hop count
you have additional content a message
and on every hope you increment it and
if it goes beyond what you D comment it
and if it goes below zero you just throw
away their ordering requires like
actually knowledge about the sequence
the messages are sent and this is
usually done with sequence numbers
that's how TCP does it for example for
the IP messages so what we would need is
a separate counter for every pair of
processors who actually communicate and
since the the process is actually
serialize and deserialize as I just
learned this is done in process context
we could actually keep the table of all
their of all the other processes we
communicate from one process in this
process so we need a table of contents
which basically increment for every
message and then on the rest on the
reception we actually check if they come
in in order and if they don't if it
basically a message comes business like
there's a gap I keep the next message
for a while and wait for the message
that it goes in the gap and then I get
the message first in the gap and then
the other one and that's also how you
detect that the message was lost you get
a new message versus like you expect
message nine but you get ten and then
you wait you a cue eight and I never
rise so you timeout and then you know
you lost a message if you get like all
the messages after you're already
detected
drop basically and you moved on with
your with your life basically and then
the old message terminus again I'm late
but I'm here then you drop it of course
because then you can't like insert into
the message stream so what do we do is
the message loss I mean every ordering
is a pain let me take some computation
but can be done but what do we do with
message loss because it's unexpected the
rule this with a note down and note ups
is basically a workaround where we can
have message loss and be backward
compatible so every time we lose a
message it trigger no down load up that
won't scale if you will use lots
messages so we still this is still only
a solution for a quite reliable network
which would which is the case in our use
case so because here I insert a note
down load up all the messages that the
note sent basically after the link is
gone so I pull the block between two
notes and this loads goes on sending
messages so dunno the other one gets a
note down all these messages are also
lost and then I get a note up and then I
know it to get on his life so this
probably should work with everywhere is
written distributed application that
expects this behavior we could actually
optionally have a different semantics
like configurable that we actually have
a special message that like yeah by the
way you didn't get the three last
messages so you lost a few and then you
can deal with it in the process that
would be an optional extension to that
so I think a little rush now what would
also be nice so if you have all these
things and we want to have a backward
compatible way but we also want to do a
new file musings where you actually
don't care about for example message
ordering so you for example if you have
like brick request/response things and
you don't care about the order of the
requests arriving in order and you have
multiple requests and fly and and there
is a request as a referent reference in
it and the response message expect the
reference and then you might not care
about the one ring of
whole thing and so it would be nice if
you had a few options to that that we
can actually make use of this losing
semantics like that could be option
during sending in the send call or that
could be an option that's set for the
process short thing about head of line
blocking head of line blocking can be
fixed one way of fixing it is to if you
have a large term it sends slices of
message messages and having the sequence
numbers in already is half of the
solution because now I know I have to
sequence them in every slice of my
offering message so I know which which
belong together so all I need in
addition is another little number which
basically tells me which is which part
of the message it is like so in which
order I need to reassemble it basically
so when you just one more level of
messages and then we can have some
scheduling that we send a little chance
not like all in order
but like pick one of this and this and
this so send them out of order from for
this different problem so optimizations
I skip very important this is all paid
by light cones or the reason I'm up here
is that we have actually budget from a
new project from the right context line
I need to mention that so I eat this 30
seconds which is about edge computing
hybrid quality protocols are used there
see oddities it's a very interesting
research project for the project for you
to edge networks which are basically
what which we are which we have and in
the framework of this of this project we
want to implement the thing and there is
one talk in the same room went for about
the project so I don't need to say
anything about it and that's my last
slide
if you can wait for coffee just a few
more minutes we could have a couple
questions takers why not just ditch TCP
I I never said we want only TCP so lack
of time I would have said basically when
we can actually lose messages and they
are small we could just put my message
in a UDP packet and just send it and the
long messages we keep on TCP and route
them to the network so all kinds of
mixes are possible and the main the main
plan is to have everything as pluggable
as possible so you can like build this
yourself on top of it so it's your
choice what actually protocol you what
about security so if you use LSB anyone
can potentially get a node in your
network so any intruder could say I play
this this for note and then you route
you messages so you cannot have a kind
of point-to-point security on those last
minutes so how are you going to solve
that in a factory use case not because
it's like make everything in clear tech
because it's like that's how it's done
in manufacturing nowadays but if tonight
be the month not to do it like that
then it's a good person yeah um I think
I don't have a quick answer to that okay
but if it's the important question yeah
like how do we have a network actually
you you get a transitive security thing
so if you have certificates you need to
manage your certificates and they can
actually use them between the nodes
maybe
so an hour line implementation TCP
protocol might be handing this might be
or might be also too slow I don't know
I'm open to that I mean we have one now
which is tested yeah
or actually reusing ideas from TCP on
the error message level one level of
basically of course if if you have we
could route if a paper route in every
node so as which or whatever you could
actually use this to actually round
through but then you still have your
scalability thing that you need lots of
connections on every node yeah
one possibility
I suggest we talk to speaker recovery
and let's thank you don't forget to
display feedback
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>