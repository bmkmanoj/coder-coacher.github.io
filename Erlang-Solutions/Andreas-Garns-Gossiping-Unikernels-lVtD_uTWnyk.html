<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Andreas Garnæs - Gossiping Unikernels | Coder Coacher - Coaching Coders</title><meta content="Andreas Garnæs - Gossiping Unikernels - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Andreas Garnæs - Gossiping Unikernels</b></h2><h5 class="post__date">2016-11-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lVtD_uTWnyk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">essentially this is about two ideas that
I currently find really exciting on the
one hand unicorn oohs and on the other
hand micro-services and as you'll see
there's going to be a gossiping protocol
that's the enable of combining these two
approaches and the reason I'm really
into unicron's right now is the security
and performance benefits that they can
offer compared to the traditional model
of writing applications so don't worry
if you don't know much about unit
kernels or micro services I'm going to
start out by giving a brief introduction
to both before we dive into the details
of of writing micro services using
unique kernel technology so very briefly
about myself my name is Andreas I am on
social media and github and I currently
lead a team of engineers out of
Copenhagen you might know send us for
customer support software alright so to
talk about micro services I think it's
good to contrast with the classic
approach of having a monolith and and
I'm going to try to scribe my journey
into micro services so around five years
ago I joined an internet startup as the
third bagging engineer they had a
classic REST API and the monolith was
written by this quite brilliant engineer
and being a monolith all the
functionality was in a single process as
illustrated by these colored dots and
when you wanted more capacity for a
single component you would run more of
the same process right and if one piece
of functionality let's say the pink
depended on the orange then everything
was just a function call away it's it's
pretty simple on the other hand the
boundaries between the components were
maybe not super well defined it was easy
to reach in and ask for the internal
state of another component since they
were running in the same process and and
that led some some challenges down the
line the company became a lot more
successful the engineering team grew
from just being a few number of back-end
developers to being a lot more many
teams working on the same code base and
this whole process of scaling up the
engineering proved to be quite
challenging using this structure I think
many companies follow this approach of
trying to having autonomous teams that
can deliver features independently
without having dependencies on other
teams I think that's like a gold
standard for many for many companies and
it can work well but in a monolithic
architecture it's very easy to be bogged
down with coordinating with other teams
if you have a deployed cadence for the
one application that might get in the
way and all these processes have to be
some kind of homogenous across teams and
it can be a problem the failure modes
are very simple though you can provide
transactional guarantees with in the
monitor so that's really the nice
pattern so in 2014 I moved to London
actually and worked for a company called
halo you may know them either get a cap
app and it was very very different quite
a culture shock to me actually they were
already quite far in moving towards
micro services so instead of running all
the processes in a in a single process
or the order functionality in a single
process they would run each a separate
services as separate processes
and when you deployed things it would be
a matter of saying oh I have this orange
component please run X replicas on this
set of machines rather than they're
scaling up the number of Rosie's on on
single boxes so it was very different in
many ways and in the beginning I was
very frustrated with the way that if my
component let's say an orange depend on
the green then suddenly it was an RPC
call to access that functionality and
that means much more complex failure
modes or you know all the fallacies
about the networks hiding out so on so
forth there was also no notion of
transactionality so suddenly you would
have to handle being in these in-between
States or at least explicitly structure
your applications you wouldn't run into
your data being in in weird States but
after climbing this learning curve it
worked amazingly well on a very large
team of engineers suddenly the engineers
the the teams could really be
independent they would own a set of
these services that they would both
develop deploy and operate so you would
be responsible for the entire and these
services across the entire spectrum and
if I wanted if my team wanted to deploy
some new functionality we could come up
with an ID on on Monday and have it in
production and operated ourselves by the
end of the week so it really led to a
lot of innovation within the company and
a lot of autonomy ownership within the
teams so obviously this is just you know
one anecdote but I think it resonates
really well with what other companies
are telling about their experiences
recently uber came out and said that
micro services had been key to scaling
up their engineering team and I think
they have more than any
really seen you know massive growth
issues it's getting a big engineering
team to make this very concrete this is
what a classic API might look like
microservices style so you will have
some kind of gateway that bridges
between the outside world the internet
and the internal world inside the micro
service cluster accepting HTTP requests
and mapping them somehow to an RPC call
to the micro service that should
responsible should be responsible for
handling this request and that micro
service might in turn depend on other
mic reservas internally and make further
RPC calls and the responses as that is
then finally proxy back to the corner in
the end so this API can dynamically be
extended by deploying numeric micro
services and updating the mappings in
the API gateway so this really allows
for a very malleable API and obviously
micro services can go away again and you
can really have a dynamic API and what I
wanted to do my goal like a year back
was to investigate how how can we
achieve something like this using
unicorns instead and to understand why
unique her nails are peeling let's take
a look at how a micro service is
typically deployed in the cloud so the
stack looks something like this at the
very top we have the application it
might be very simple a couple of hundred
lines to a thousand lines of code easy
to understand easy to refactor or even
rewrite it's it's fairly is fairly
simple so it's it's running inside some
kind of container probably docker to
provide isolation from other micro
services running on the same machine
the container is running on top of some
kind of operating system let's say Linux
which is providing multi-process
functionality it's providing multi-user
functionality and obviously it's a
stable hardware interface so our
application doesn't really care about
which disk it's running on or which
network card it's it's interacting with
then we have the hypervisor sin so you
from the cloud providers perspective you
run multiple operating systems on the
same hardware which makes it much more
cost-effective and then finally at the
very bottom we have the hardware so we
started with something that was very
simple right or a small micro service
and we ended up with this very deeply
layered stack which is making things a
little bit more difficult to understand
perhaps so the idea of unicron's is how
can we strip away the unnecessary layers
and instead of taking the traditional
approach of computer science with layers
layers layers really you know go back to
do it from scratch so the stack for a
Unocal instead looks like this so now
your application is running directly on
top of the hypervisor and the question
question is then well how does this work
so the first responsibility of the
operating system which is crucial as
this stable Hardware interface but
actually now we're all running in the
cloud there's not like a great diversity
of hardware we're all running on this
virtualized hardware which is totally
homogeneous so there's no need to have
ten different device drivers in your
operating system we can just write it up
against this virtualized Hardware
there's only one type of and then that
requirement goes away
the second is previously we're running
multiple processes on the operating
system but now instead we can just scale
out by running multiple applications on
top of the same hyper version instead
obviously we still need to access the
underlying hardware and instead of
having this operating system wins act
with the system cost to read the disk or
write to a network card
it simply libraries now so libraries I
included explicitly in the application
as needed just as you would require
something for serializing json or
something so what we gain from this in
terms of security is a much smaller
attack surface we've literally gone rid
of millions of lines of unsafe code
written in C and we can replace it with
code that can be written in safe
languages like camo haskell and so on
there's no unused device drivers or
other kinds of libraries included in the
application unless it's explicitly
required so you won't have something
lying around that you worsen you weren't
aware of that can suddenly be used to
exploit a security hole in your
application and finally if somebody were
to breach your application there's no
tools to aid the attacker at all there's
no bash oh there's no you know you can't
LS things
there's no SSH or whatever to further
exploit your application in terms of
complexity well it is a lot simpler and
just to give one example we can look at
how things are being scheduled so on the
traditional stack we can have up to
three layers of schedulers so in your
application runtime you have a scheduler
for green threads on to processes in
your operating system your scheduling
policies on to virtual CPUs and then in
the hypervisor your scheduling virtual
CPUs onto CPUs
and this three-layered scheduling can
actually have quite complicated
interactions that can be hard to
understand later
so in short we've replaced this
general-purpose multi-user multi-process
OS with the minimal possible solution
another way to look at this is how the
address space looks like for a silikal
UNIX process running this micro service
and the corresponding layer for eunuch
kernel so you have this strict
separation between kernel space and user
space in a UNIX process and crossing the
boundaries between the two is costly
it's just a context switching so every
time you access the network disks on
then you're actually paying a price
again to reiterate the kernel includes
all the functionality that the
application might possibly need but not
what it actually but it doesn't know
what it really needs because they are
compiled separately and you can't know
when you're compiling your kernel unless
you have recompiling it for every
application what you actually need so by
comparison in the unit kernel world you
only have a single address space where
everything is running and there's no
distinction between kernel land and user
lands so you're not paying the price of
making system costs you're just making
regular library function calls it only
includes what's what's required by the
application so for example if you're
writing at the NS server that's not
writing disk then you don't have
anything for touching the disk at all
in terms of performance this means that
no context switching it's trivial to
achieve zero copy IO that is normally
when you're accessing the disk then
you're copying into kernel buffers and
then kernel buffers to user land buffers
but when there's no such distinction
then it's trivial to achieve finally you
achieve whole program optimization
because since you're the the operating
system functionality is just a library
you can now inline code from the from
those libraries into your application
and optimize across the entire stack
rather than when you have them compiled
separately finally the only criminals
because they only include but what they
require they're very small we're talking
kilobytes to megabytes for an entire
send image and they boot in milliseconds
to be instead of booting in the child
rating system and then running your
application on time so so far I've
talked about unique kernels on a very
general level and for the rest of the
talk I'm going to be talking focusing
specifically on Mirage which is a unique
kernel written in oak ammo it's one of
the most mature and oldest unicorns and
just to give you a flavor of what it
looks like this is a hello world
application so as you can see it has
this main module which is the entry
point of the unit kernel and it has
these this argument this console which
is of the interface console in capital
letters so it basically means at
compilation time it will inject a
console a console of this signature and
it will either be for running on UNIX or
running on Zen depending on how you've
configured it so basically your source
code is is written once and then at
compile time you decide
this be a executable binary as the
output or should be a send image and
there's actually further targets coming
to rationale this support for kayvyun
KVM coming soon so there's gonna be a
third target and just to make it there
create these are the actual commands in
the command line for running on on unix
and you might ask why would you even
have the unix target and that's for
development you write it you run it in
on your local machine tested and so on
so forth and then finally it at the end
you make a sent image and then you can
run that in production so now you have a
basic understanding of of micro services
and and unit kernels and the question is
then how could we what do we need to
replace these micro services with the
unit kernels and there are four
requirements for such a platform you
might say so obviously we need some kind
of a PC functionality so they can coach
other internally in the micro service
cluster but to do that we also need to
know what what services are out there
and where are they so that's what's
called service discovery which is
basically like what are the other
members in my cluster and what
functionality do they provide finally we
need to have some kind of deployment
solution if we want to say run X applica
replicas of this service on a cluster
that that still needs to be built and
once we're running this entire Microsoft
cluster we need to understand how is it
performing house is running some kind of
having insights into how your cluster is
performing is essential of actually
running this introduction so that's
these are each massive topics I'm gonna
consider the a PC one solved we already
have a PC libraries more than plenty and
focus on the service discovery as
the first step towards this goal once we
have service discovery we can actually
we can still deploy things although
manually into the cloud and we might not
have have insights with monitoring but
at least we can have a proof-of-concept
that you know we can make in
micro-service architecture that works if
we have services gallery and RPC so for
the manor of the talk I'm going to focus
on on services gourry
okay it doesn't I have a picture it
doesn't like it apparently the picture
shows it's it's from the rooftops of
Marrakech where the first mirage
hackathon was held this spring and I was
fortunate fortunate enough to be able to
attend and be able to hang alongside
some of the Mirage core contributors on
on actually making this solution so
we're just gonna skip that picture
service discovery so we want to have
this notion of who else is in the
cluster right now and where are they
and the most straightforward solution
would be to just introduce a centralized
component it might be a message bus like
RabbitMQ and that would solve all our
troubles we'll just communicate via that
but I would argue you know we're trying
to move towards unit kernels why
introduce centralized infrastructure
that needs to be supported separately
and instead we're going to focus on
peer-to-peer solutions that is or the
services are talking directly with each
other so the naive approach to this
problem is for each of these services to
ping or the other ones and ask you alive
and if you get a response back they're
still alive and otherwise their problem
we did so that works pretty well but it
doesn't scale up this problem is it's
generally called or this type types of
protocols are called distributed
membership protocols and they should be
evaluated against four criteria
completeness that is if a node is down
then eventually an on faulty node should
find out speed is how quickly they found
out that you find out that the other
node is dead network load is how many
messages or packets were sending across
the network and the accuracy is the
number of false positives how often do
we believe another node is dead when in
fact it's not so coming back to this
naive approach of just
every so often pinging another node and
see if they respond it actually works
pretty well across there are three out
of the four criteria but network load
that one's really bad because the number
of messages is quadratic in the number
of members in the cluster so if you have
a thousand nose and they pin each other
every 100 milliseconds then you have a 1
million packets across the network every
100 milliseconds so it doesn't scale of
everyone so we need to find something
better some way to lower the the network
load while trying to retain all the
other nice properties and I looked into
some of the existing existing solutions
outside the unicorn world
and in the literature and I found this
protocol called swim so swim is stands
for scalable weekly consistent infection
style process group membership for also
quite a mouthful basically it's a
peer-to-peer protocol over UDP with
randomized hot beatings or instead of
hot being everybody the notes choose a
random member to ping every interval
with some gossiping on top and I'm gonna
get into the details of that there's a
configurable ping interval how often do
you ask other members of their live and
it has three types of messages ping ACK
and ping rec that I'm gonna dive into in
a little bit and the basic idea is that
we can trade off slightly lower
detection speed for much lower message
load so that is it's gonna take slightly
longer to find out that it another note
is down but we're gonna use a lot less
packets Network packets doing so it's
liner in the number of members in the
cluster only so to understand the
protocol I'm going to show like three
interactions that display how these
three messages work in practice
so the first interaction is pretty
simple a ping see the message has a
unique ID for a it has like a sequence
number so it knows when it gets X back
what is the the responder aking and
let's say that C is live in it sends a
nagging now a still considers C alive
what you see to the top-right is
basically the time ticking down for that
particular interval so it expects
response within that time so that's the
the first interaction fairly simple Sofa
King ACK the second interaction we start
over with the time a ping C but now
after certain amount of time a says hey
I would have expected a reply by now but
I haven't doe note that the entire
interval time hasn't hasn't gone yet so
it asks B for help and says hey could
you ping C for me please and be helping
C and she replies this time and a now
again considers C alive so the basic
idea here is that if there's some kind
of trouble on the network on the path
between a and C then we take an indirect
route and the number of helpers that a
solicits to doing the so is also
configurable as part of the protocol so
the final interaction a ping see again
we start you over with the protocol time
we get the timeout again we ask B for
help but we still don't get a reply so
now at this point we consider C dead or
a consider C dead and now we get into
the gossiping part of the protocol
because each node maintains a list of
the most recent events that happened in
the cluster so every time no dyes or
you first for the first time receiving
it came from another node you consider
them alive that state is kept in each
node and they add that to the messages
when they talk to the other nodes so now
for the next when the next period starts
of the protocol a ping see a pings B and
now additionally says oh by the way I
think C is dead and now B will update
its own State
knowing that C is dead and propagate
that further so now that's why it's
called infection style B is now infected
with the information that C is dead and
will propagate that further to other
members of the cluster so this is the
pod that gives really nice fairly nice
guarantees with respect to how quickly
other members learn that and notice come
alive or and notice has died
so what I've covered here is really the
vanilla version of the protocol and
there's a number of the extensions that
in the disregard but it might be nice
you might be sitting or what about this
use case at that use case how does it
handle that so I just want to mention
three so the first is you can increase
accuracy by instead of immediately as
fuming and no dead mocking it as a
suspicion and then you can later learn
that and the note was actually alive so
that increased the that decreases the
rate of false positives
secondly in the vanilla protocol when
you join a cluster you just ping and
member and then you're a member of the
protocol but it actually takes time for
you to build up the entire state of who
else is there so a natural extension is
to get a four sync when you join a
cluster and the final one is some kind
of metadata so right now we can't
distinguish between the notes that are
part of the cluster what kind of
functionality do they provide and that's
actually essential for our to service
discovery mechanism so when you join a
cluster you say oh and by the way I
provide the logon service or the get a
cap service or whatever not none of
these extensions really change the
fundamentals of the protocol so just so
you're whether it's them so now I hope
you have a grasp of what the protocol
works like and we're going to look a
little bit at how it's implemented and
some learnings from doing that so there
are these are the messages the types of
the messages being interchanged on the
network so an address is an IP and in a
port there are three message types ping
req ping act in ping req where ping reg
has additional inertia of food to ping
the state is either dead or alive and
then a message is finally a sequence
number which uniquely identifies the
message a message type and a list of
gossip saying this this notice is dead
or alive
and if we look at how the notes
individually handle such a message
coming in we can think a little bit
about immutability impurity and side
effects now okay amo is a functional
language it promotes immutability but it
doesn't force your hand you can you to
its data what you want you can have all
the side effects you want right to the
network right to disk do time outs so
there's really a matter of choice in how
to implement this and whether you want
to go sure or not and I want to explore
a little bit what this would look like
if you want to make something that's
actually pure in terms of side-effect
free and not mutating data and what are
the implications so our starting point
is the typical imperative solution when
you handle a message there's the state
of the note you get a message and then
you just return unit because you're
mutating data you're writing the records
to the network it's not you can't really
tell from this type signature that all
this stuff is happening so let's say we
want to get rid of the mutability part
we want to make it such that the data is
mutable well now instead of returning
unit we return the new state of the node
so we've gotten rid of we now have a
mutable state but we're still writing to
the network and we're still setting
timers we need to figure out if if other
nodes haven't responded in time so how
could we approach this problem of for
example getting rid of writing to the
network well now instead of just
returning a state we also return a list
of actions that we would like the caller
to take and the actions are place and a
message to this address and here's the
message so that's the send message you
see up here so now we're no longer
touching the network we're asking the
caller to do that for us but we're still
setting timers we're still not the the
timeouts are not part of this model and
the final version of trying to handle
this purely looks like this so now we
have an opaque timer type and the
actions that we returned from our handle
event function is now it can either be
please send a message or it can be
please set a timer and the events we
receive and not only not only messages
but also something timed out and it's a
it's this particular timer that you
asked me to to handle so at this point
where it's it's totally pure it's it's
mutable its side-effect free and I think
you know you can argue in terms of
readability the state that the state
transitions are really explicit in the
program but I think that's all a matter
of taste
where it really becomes a net benefit
that you can really argue about is how
you can use this pure call in different
contexts so for example you might have
you might wrap the pure call in
something that does synchronous i/o it's
straightforward it might interact well
with your program that's already using
synchronous i/o but you can also wrap it
using asynchronous i/o or you can do
mock you can mock the network and mock
the time for testing or you can have an
effect for raba
which is suitable for mirages so that I
think that's really a benefit that you
can't argue about in the same way the
readability and you know should you
distinguish between a separate i/o and
core logic
so the effect for rabbits in cements to
pure coal the pure course ends the
actions back and it's a responsibility
of the rabbit through actually
interacted with the network and set
timers the pure Co has a little bit
complicated interface these are mostly
types you've seen before so you can ask
ask the pure Co about what are the
members of the cluster please that
failure detection please handle an event
and looks really complicated but when we
rabbit in an effect forever the
interface is actually really trivial and
this is what it looks like for Mirage so
you can start you can stop it you can
join a cluster you can ask for the
members so we have this distributed
probabilistic algorithm lying at the
core of our micro service architecture
and it's really essential that it works
and by nature it's quite tricky to get
confidence in the solution the first
approach will probably be unit testing I
started like this I wrote some scenarios
down I saw that it they acted as as I
expected and it worked fairly well I
think the program was already the design
was already set up for success and in
terms of it was easy to mock Network in
time so the tests were fast and easy to
write and so on but it only goes so far
let's take an example so there's an
initial state where we have a being part
of the cluster it's tied up to a mock
Network and then we have this event in
our test scenario where B joints a and
then we wait for second allowing them to
gossip a little bit and then C joins a
and we allow them to gossip a little bit
and then we let a fail by connect
disconnecting a from the mock net
work and we let them gossip again and
then at this point we know how the
protocol works so after these steps we
should verify that B knows C is live and
C knows be alive and to reach me know
that if we know how the protocol works
right but writing down all these
scenarios and testing them each
individually only goes so far even if I
did a hundred scenarios the it's it's
minuscule compared to the number of
states the cluster could really be in
when you look at a large number of nodes
so is there a different approach to
solving this problem of gaining
confidence in the solution and the basic
idea is if we can for each of these
steps like join da wait one second can
have a model of the world and idealized
what a model of the world is a much
simplified model of the work a world
then we can instead of manually writing
down test cases let the computer
generate test scenarios for us so as a
very simple example let's let the model
of the world be the set of nodes that
are currently alive and in the initial
state a is alive so for each of these
events we need to figure out how to
update the model so when B joins a B
should become part of the set of alive
nodes so we simply added to the model
and at the same time we update our we
run the code against the mock network
and so on then when C joins any again
now C is part of their live note said
and finally when a fails we remove it
from their live notes set and instead of
manually now verifying that the world is
in the state we expect we can use the
model of the world to verify that the
world is in
that status so the model says that B and
C should be alive so B should consider C
alive and C should consider be alive and
so an overview code wise of this looks
something like this we have a number of
events in scenario it's a list of events
we have the state which is our model of
the world and a list of our pure logic
and if we can write a step function that
takes this state and an event and gets
us a new state that means we can execute
a scenario by simply executing the steps
one by one and if we can write a
validate function that looks at the
state and compares our model of the
world with an actual world then we can
basically let the computer write this
any number of test scenarios and
validate that the algorithm works as
expected so this also works for
different models this model was quite
trivial it was just the set of a live
notes but we could also have the model
be a graph where the latency is between
the notes and then suddenly we can start
verifying that it handles network
latency correctly or packet loss or
something else obviously the more
complex your model becomes the less you
then more you need to ensure that
there's not a Fault in your model but
actually in in the code
so at this point we can actually build
the architecture I showed earlier with
the REST API
build microservice style we can have a
we have a PC so we assume we have a PC
to call between the nodes we have our
service discovery algorithm our classic
algorithm for determining who else is in
the cluster and what functionality did
they provide we can deploy although in a
manual fashion for now that's work to be
done how to deploy únicos in a smart
fashion and monitoring is for now left
as an exercise or undone work so it
needs to be done but I hope I've given
you a taste of first of all how micro
services can be interesting for scaling
up in engineering team how unique
earners are not only simba simpler
literally but also conceptually and
provide gains in terms of speed and
security and how this all fits together
and a little bit about the road forward
so if any of you is interested in
working on this you know reach out to me
the code is on github and otherwise
thanks very much for listening
so we have about three minutes for
questions so let's see some hands
hi so there's a product from the Hoshi
Corp called surf which does implement
swim so it's just wondering in your
testing where you're basically proofing
in equivalence between your
implementation and your model did you
consider trying to prove that same
equivalence between your implementation
and surf from hash code that's so you're
totally correct surf does implement the
same algorithm and the reason it's not
your tears basically it's not you kind
of compatible I haven't tried running
this against what they've done they have
written serve in a you know direct style
impure imperative so I think it would be
a lot harder to go and do the same kind
of verification maybe you could
restructure the program and then you
could run this same use the same
approach to verifying their stuff but I
think it would be a lot harder hi I had
a question about security is that an
issue in this sort of architecture and
if so what how do you deal with it and
if not why not
for Juna Kronos for unicast
architectures that you're proposing yeah
so I would argue that security is
improved compared to the traditional
style of writing applications so it's
basically the the benefits are a lot
less third party dependencies which
means a lot less code which with the
potential exploits it's also a matter of
if and if your application is exploited
then there are really no tools to eight
the attacker in in going further there's
there's no bash there's no I suppose I
was think here's a higher level if I
managed to put in a malignant agent in
there who is broadcasting to everybody
look I can provide you with this how do
you ensure that your
you're actually that the the what a
service says it's going to do is
actually what it's going to do so you're
going to swim in terms of a
microservices architecture right I if I
insert a okay so once you're inside if
you do manage to get them like a
malicious actor inside the the cluster
then I think in general yes you can do
bad stuff obviously you shouldn't be
able to your microservices should verify
that the requester only has the only
gets permission to do what the caller
has permissions to do so if you have
some kind of authentication system and
you should then you should authorize the
action they want to take against that
okay so I guess you're assuming security
guarantees from your cloud provider and
from from mirage and so on that will if
I understand the question correctly this
basically this is application level
security not something that's explicitly
provided by by mirages right or unicorn
Allegiant okay and we're out of time
so yeah let's thank the speaker again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>