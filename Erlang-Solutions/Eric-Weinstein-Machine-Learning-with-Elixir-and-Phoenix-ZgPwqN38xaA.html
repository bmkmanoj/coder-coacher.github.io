<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Eric Weinstein | Machine Learning with Elixir and Phoenix | Coder Coacher - Coaching Coders</title><meta content="Eric Weinstein | Machine Learning with Elixir and Phoenix - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Eric Weinstein | Machine Learning with Elixir and Phoenix</b></h2><h5 class="post__date">2017-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZgPwqN38xaA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you so much for coming by the way
you know I know you guys have a choice
and talks so thank you for choosing to
spend your time here thank you also too
it looks or count for you thank you to
our sponsors in the venue like I said
I'm really excited to be able to give
this talk which is called machine
learning with elixir and Phoenix and
this talk is dedicated to my younger
brother who passed away unexpectedly
last summer part 0 this is a computer
talk which means I have to start with
zero so hello my name is Eric I tend to
speak very quickly especially what I'm
excited and you know talking about it
looks you're talking about machine
learning is very exciting so I'll try to
slow it down especially since I know
many of you are not native English
speakers but if you catch me going way
too fast
having a hard time keeping up just some
kind of signal something some kind of
like penalty out of yeah exactly think
now would be great just to get me to
calm down and and slow down to a human
pace which would be great I'm going to
talk for about 35 or 40 minutes if I
come in on the lower end of that we'll
have time for some questions if I end up
using all the 40 minutes come find me
after the show we'll we'll chat happy to
answer any questions that you all might
have Nathan actually gave an excellent
talk in this room just before the break
and I really liked what he said he said
I'm happy to answer any questions but
not long comment sort of disguised as
questions and I think the the same thing
applied cool also today's Star Wars day
so I was obligated to include this joke
may the force be with you so yeah like I
said my name is Eric Weinstein I'm a
senior software development lead slash
engineering manager at Hulu as well as a
master's student at Georgia Tech in the
online masters of science and computer
science
I recently actually this semester took a
course called machine learning for
training which was the
impetus sort of like inspiration for
this talk most of that course is in
Python so we've taken that some
translation work and done you know
working elixir to see if it could be
done like I said the common wisdom is
that elixir or Erlang or beam are not
well suited to extensive number
crunching and we'll see if we can prove
that to be false you can find me on
github you can find me online on my
website Twitter etc in this human map
that I felt obligated to make I write a
lot of Ruby Python and JavaScript and
some go at work as well as it looks your
enclosure for my own personal projects
I've been writing closure for about four
years and it looks ER for about one I'm
also a relatively new contributor to the
language interest so if any of you are
interested in dependently type two
programming languages or in Haskell or
Idris please PLEASE combine me I like to
talk about that stuff
I also wrote this book a bit ago Ruby
wizardry is a book that teaches Ruby to
eight to twelve year old kids
Ruby's like your licks are right
somebody somebody told me that so if
you're interested in that please please
do come find me and there's a 30%
discount for the duration of the
conference with euro Ruby 30 from the no
starch website so thanks also to to no
starch for that this is not a long talk
if you're watching the little sort of
loading bar at the bottom we're already
20% done which is great it's 20% of the
slides not 20% of the time but I do
think it's helpful to have an overview
of what we'll be talking about so we'll
talk briefly about machine learning
generally supervised learning in
particular neural networks in very
particular I suppose and we'll be using
a bit of Python sort of cheating a
little bit kind of setting up the data
and the infrastructure and ecosystem for
elixir and Phoenix to take over it I'll
explain more about that in a minute and
we'll be using some publicly available
financial data and as well as it elixir
neural network and Phoenix
so part one machine learning what is it
actually show of hands how many of you
feel very comfortable with machine
learning okay good
how many of you are like I have no idea
like I've heard about it I know no sense
of how to do it what it okay cool good
so I was right to call this intermediate
that seemed pretty everyone else I
imagined it somewhere in the middle
right excellent so in a word I would say
that machine learning is generalization
right the idea that you can take some
set of knowledge and apply it in one
domain and apply it to another one and
the idea here is to help a program sort
of assemble rules for dealing with data
so that that machine can then act
independently
you know without being explicitly
programmed on new data and sort of I
guess what do I mean by that so imagine
you want to perform some kind of pattern
recognition right you want to see if a
machine can tell you if something is a
picture of a car or you want to see you
know given a whole bunch of information
about housing data all across some
country what might the price of a house
be in a part of the country where
there's very sparse or no data or maybe
you want to say hey like weird stuff has
been happening in my application I'm not
really sure what's causing it or what
the deal is but I would like to run a
program that can tell me I'm not sure
what to call this but here are the
patterns here are the clusters of events
and you the human can take a look and
interpret this for me these are all sort
of examples of of machine learning and
things that machine learning can do for
us is this speed okay volume okay great
cool so supervised learning be first two
examples a game of the car and the
housing data are examples of supervised
learning which is essentially learning
from some labeled data you have some set
of inputs that someone some human being
likely had said this is what they are
and we then want to construct a program
that will allow us to make predictions
about the unlabeled data
some test data that we don't really know
what it is and that's what we want to
actually perform machine learning work
on and this generally falls into two
categories classification where you have
something like you know is this a car
and regression something like given all
of these dollar amounts for houses what
does the dollar amount I should expect
for this house so for the car example
you know if we're going to have a human
version of it now I might take you on
Barcelona and say that's a car that's
the car that's the car that's not a car
and then we go to Boston or Oslo or the
moon and I say okay is that a car and if
you can successfully say this is a car
that's not a car with some and as
successfully I suppose corresponds to
some acceptable error then we say that
we've generalized appropriately right
we've succeeded in machine learning and
the same goes with the housing data
given you know we've seen some certain
certain houses that are bungalows or
duplexes maybe they're close to good
schools maybe they're in good parts of
town or bad parts of town maybe they
have more fewer rooms these have led us
to believe or sort of have beliefs about
the dollar amount that the house should
cost can we then generalize that
knowledge and use it in other domains to
say okay this four-bedroom house in
Detroit this is what it should cost
given what I know about other houses and
the label data are the sort of things
that you know about the data that you
are going to train on so you sort of
train your machine learning model on the
label data and then you test it on the
appropriately named testing data and
I'll come back to this but one of the
cardinal sins of machine learning is you
do not get to train on the testing data
some shops will tell you that this is
okay
for example if you constantly get new
streams of testing data like you have a
real-time system and you know over time
you accumulate more and more and more
testing data you can kind of take the
old test data they get into the training
data get even better and then keep the
new data aside for testing and there are
sort of exceptions there but generally
speaking you're not allowed to train on
the testing data it's cheating you know
it's sort of like you have the road
you've memorized the the answers rather
than sort of synthesized any kind of
knowledge so our data in this case
come from yacht and finance though there
are several good sources quantal qu a
and DL is another good one and these
data are from the S&amp;amp;P 500 from 2015 and
2016 which are a set of stocks in the US
stock market it's not truly you'll see
in the in the URL it's not truly the S&amp;amp;P
500 but rather s py which is an index
that tracks the S&amp;amp;P 500 so in this case
and it will talk in more detail about
indices and things like that in the next
section when we get to finance or or
finance as folks who are very interested
in financial sometimes call it so the
idea here is to train on the 2015 data
and then test our assumptions are model
on the 2016 data I've selected them
because they're the most recent but as
we'll see in a bit there are some other
interesting qualities of these data sets
that I thought made them good candidates
for for this experiment you'll realize
though it may occur to you that there
going to be some years in the stock
market that are not necessarily good for
training again if the idea is to
generalize if you pick a year or sort of
a duration where things are really weird
you know we're abnormal in a larger
landscape of the financial market maybe
that's not a good thing to sort of learn
about so for example huge 50 or 2008
during the the global financial crisis
and recession that may not be a good
year to generalize from your machine may
decide that every year is going to have
a giant collapse sometime in the middle
of the year and that's not something
that we would want to bake into all of
our models or have as an assumption in
our models so those kinds of rare events
or things to think about generally
speaking when you will talk more of it
about this when you have a model that
sort of believes the data too much when
it sort of starts to model all the
quirks and idiosyncrasies of the of the
training data rather than sort of like
broad signals that are generalizable
that's said to be overfitting so when
you over fit you are kind of adhering
very very closely hewing very closely to
the data in the test in the training
data and you're not going to generalize
well to the test and you'll see that
when you look at the error that you have
in your training set as opposed to your
test set and if you're curious the
reason we have three features we'll talk
about them soon we have very relatively
few instances only 252 so we want to try
to reduce the number of features that
we've got it'll talk more about why we
do that later and there's 250 too simply
because there are 252 trading days per
year so those three features I mentioned
in order to do supervised learning you
need to have some features some input
values and some labels some output
values these technical indicators
volunteer bands simple moving average
relative strength index I'll explain
more in a minute but these are the three
signals that the neural network is going
to look at to determine what it thinks
the price so the return is going to be
and given these inputs this is actually
going to be our output 20-day return so
the network is going to try to predict
what the return on the portfolio will be
20 days from now so if you think about
the earlier discussion of classification
and regression this is a regression
problem we're looking at a real value
sort of continuous output that we're
going to try to predict you could
consider also a discrete problem sort of
a classification problem maybe you want
to have your neural network say actually
I'm not going to try to predict 20 date
return I'm going to try to predict just
buy or sell that's what I'm going to do
I'm going to add to return one value
provide one value for sell and then you
have a classification problem and neural
networks can handle either one very well
helps if I open the water bottle
so neural networks neural networks are a
machine learning tool that modeled after
biological brains and the idea is to
have many neurons functions or objects
in the case of the code with dendrites
to sort of those little inward moving
branches on real neurons which you can
think of as vectors of signals in ways
in the program and an axon that sort of
long branch coming out the end that
connects to the next neuron and this is
the output now in some neural networks
this is thresholded in some it's not its
threshold er then you had a fire or you
don't and that's that corresponds more
to a classification problem if you don't
threshold you can treat it more as a
regression problem you have a continuous
real value to output that you want to be
the sort of prediction or the output
from from your network so I selected
neural networks partially because they
can model interactions among inputs they
have a lot of pros you know they're
relatively fast to query they can model
any continuous function as long as they
have two layers but part of the reason
I've selected them was as mentioned
earlier in the talk they are
computationally expensive and the idea
here is that sort of you know Erlang or
elixir or beam are not well-equipped for
these kind of computationally expensive
tasks so I wanted to pick something that
was particularly difficult for for the
machine to handle there are other models
that you can use for machine learning
such as decision trees things like that
that are not necessarily quite as good
for things like this for example they
can't model interactions among inputs
but as you'll hear in machine learning
there are no silver bullets and there is
no free lunch the idea being that there
are machine learning models that are
good for some things and others that are
other things lots of knobs you can turn
things you can do but for any given well
behaved model and data set there's going
to be some data set where your model is
going to do no better than just random
selections so there are constant neural
networks they are notoriously finicky
they have a lot of tuning that can be
done in terms of very hyper parameters
sort of learning rates and things like
that they can be very fussy and it can
over fit very easily they are also
expensive to train as I mentioned
they're computationally expensive it
takes a while you know I got to the
point where it's taking hours with
particularly learning rate or error to
to train this network so I kind of
dialed it back to try to get training to
an easier more manageable pace there are
also black boxes and what we mean by
that is the neural network that is sort
of like not hoping for you to examine
and even if you did kind of crack open
the network and take a look at all the
weights of the various neurons inside it
wouldn't mean anything to you there's no
sort of explanatory power there is a
decision tree where if you kind of look
at how a decision tree is mapped out you
say okay the tree decided that this was
the most important attribute to split on
and it made this decision and then this
is the one that provides the most amount
of information after that it's split
here and you can sort of trace the path
of the machine's thinking by examining
the decision tree not the case the
there´ll networks say our mysteries so
if all that was a little bit vague
hopefully this visualization will help a
little bit now this is not the actual
neural network for this data set or for
this discussion although it's actually
pretty close we do have three inputs
which would correspond to our three
signals there's a hidden layer here
there's only one and there are two
outputs and if there were a single
output this would be very close to the
network that we've got or if we had
chosen to do by ourselves as opposed to
trying to predict the return again we
would have a closer we would keep more
closely to this this visualization now
the issue with overfitting like I said
is when you sort of model the data too
much and you believe it and you sort of
extrapolate the nooks and crannies and
weirdnesses of your training set onto
your test set there are ways to address
this there are things you can do such as
regularization there are ways you can
change the activation function that you
use and we'll talk about that in a
second that's not really a problem for
us this is a relatively simple shallow
network but if you had a very
complicated network topology if you had
many many many neurons or many layers it
would be tough to
avoid overfitting and so some of the
things that you could do would be sort
of like you know avoid these like very
large grains that you get a very very
small grades that you get as you descend
through the layers or I guess modifying
your activation function so let's talk a
bit about this this activation function
and the way that data sort of moved
through the layers because I think
that's key to understanding how neural
networks work so during training the
network uses this these layers of
neurons and assigns them weights so the
idea is you have you initially
initialize two very small random numbers
and as training progresses you sort of
feed data through the network it passes
all the way to the end and we get an
output and we say okay here's what we
were expecting to get in our test data
these are our labels that we had before
and here's what we got and then the
network will say okay this is initially
pretty far off and so the next step is
to propagate backwards and it's that
propagation step effectively sort of
moves the error signal back through the
network and assigns to each neuron a new
weight based on how far off it was from
the original prediction and you do this
through this kind of idea of gradient
descent where if you think of the the
error you want there's a global minimum
and you're trying to kind of step down
slowly or sometimes faster down to the
bottom of this error you want to kind of
use the derivative of your activation
function the function that's used to
determine if your network or your neuron
fires or not to control how the weights
are adjusted over time so that learning
rate I mentioned is one thing that
controls that sort of gradient descent a
very high learning rate means you learn
faster but it means you may kind of trip
and skip over that minimum and kind of
go up the other side a slower learning
rate is it makes you more likely to
achieve that error minimum but you will
learn more slowly and so essentially
what happens for all these training a
box is you kind of feed forward through
the network you look at how you did
propagate the error signal backwards to
adjust all your weights and you do it
again can you do this over and over and
over and over until you hit some
threshold that you've determined ahead
of time and said good enough this is you
know this ninety-five percent of the
time
you know we we've identified cars or you
know 80 percent of the time we've
identified you know what the more or
less correct price of this house is
things like that so again this is
another thing that you can tune is this
this acceptable error that you're you're
going for so the training rules here
we've decided we're going to buy when we
think the 20 day return is positive
we're going to sell when we believe it's
going to be negative we're going to do
nothing if it's going to be zero or if
it's very close to it and I said an
arbitrary threshold estate and this is
too close
we're really not going to make an
investment decision based on this signal
let's just close our position and do
nothing and so do nothing is defined as
if we're not in the market don't take a
position or if we're already long or a
short it closed up this speed okay cool
part to Sundance this is the obligatory
warning slash caveat slash I don't get
in trouble if you lose money so I am NOT
a financial professional I don't have
any certifications not economists I
don't do this for work for work I sit at
a computer and type things and break the
computer and curse allotment eventually
thinks you fixed somehow because
computers are magic but the idea here is
that I'm not making any guarantee
explicit implicit etc etc that this is
reproducible that is going to be
complete or correct that you can go and
throw this at the market and that you're
going to become fabulously wealthy if
you if you repeat these experiments with
real money you can and probably will
lose money at some point and that's true
if you're picking stocks by hand if
you're buying index funds if you're
doing fantasy of machine learning stuff
you will eventually lose money so that's
that's that
so for the finance side of things
there's a little bit of jargon to get
past so like I mentioned the S&amp;amp;P 500 is
a collection of 500 stocks
it's an American index the actual
instrument that we're following is sqy
so that's that index that actually
tracks along the behavior the
performance of the S&amp;amp;P 500 adjusted
close so this is the price at the end of
the day 4:00 p.m. Eastern Time in the
United States when the stock market
closes and whatever that price is that's
the close for the day
now the adjusted close is very slightly
different and I'll explain it in terms
of this next one the stock split
companies can sometimes say my stock is
too expensive or for some reason I've
decided I'm going to convert the number
of the number of shares that I have
outstanding without diluting or adding
new ones so the idea might be company a
has a thousand shares outstanding but
the stock has you know climbing climbed
and now cost $100 a share so their
market capitalization is $100,000 but
they might decide what I'm going to do
to make this more affordable for people
to buy shares in an age of people you
know try to buy you know round lots of
100 shares say what I'm going to do is
say for everyone who has one share that
cost $100 those people now have two
shares that cost $50 each which is great
no one gets diluted everyone has the
same amount of money that they had
before but if you in maybe this happens
in 2012 you in 2017 look back at the
data and say oh man something really bad
happened on that day because their stock
price fell in half in like one day you
know how did they lose 50 percent of
their value they performed a split so
the adjusted closed accounts for things
like stock splits that would make the
data hard to manage otherwise so that's
just a closing and those are stock
splits and the last one is look at bias
so look ahead bias this is the sort of
second I guess cardinal sin of machine
learning though it is unique to time
series data so for looking at it
the idea this bias is that you have some
bias that's introduced when you're using
data that you would not have had when
you're running your simulation so you
can't for example let's say you have
2014 and 2015
you can't train on 2015 and then test on
2014 right you can't take some data that
was not available at the time and then
sort of go back and have that you know
sort of that future knowledge baked into
your test you get results that are sort
of uh near a tional e exhibiting there
any of these great results ok cool I can
predict the future and as you sort of
make the future into your test already
so for time series data you have to be
very careful to avoid this you cannot
make any future knowledge into into your
model so let's talk a little bit more
about these indicators so I mentioned we
have three of them simple moving average
Bollinger Bands and RSI the Bollinger
Bands actually has that little
registered trademark because John
Bollinger trademarked us I think in the
1980s which has it's interesting when
you find out what they are because
they're it's astounding what you can
trademark and so the simple moving
average is simply an arithmetic moving
average over some window so if you have
this kind of you know jagged walk of a
stock the simple moving average is this
sort of smoothed out line that follows
the stock betrayal dit by n number of
days so if you have this kind of 20 day
window you're going to trail behind that
jagged you know random walk but it can
be smoothed out over that and what we
actually care about is the ratio of the
price to the simple moving average in a
sense kind of looking at opportunities
for mean regression if that makes sense
rather than the stock prices or the SMA
itself the Bollinger Bands are a similar
idea these are standard deviations above
and below the simple moving average so
if you have this smoothed out curve
that's the simple moving average the
Bollinger Bands sort of are on each side
of it following it along kind of like
you know like a river with a line down
the middle the idea of Bollinger Bands
is
kind of want to watch for events where
the price of the stock kind of punches
above that upper band or falls below
that lower band and the idea here is
again sort of a mean regression strategy
the idea is if you think it you know if
it's punched above that upper band it's
going to come back down at some point if
it's fallen below that lower band maybe
there was a poor earnings report maybe
it was you know who knows what actually
caused this it's going to come back up
toward the mean eventually and that's an
opportunity for you to buy because the
idea is you buy below the band and then
it will eventually come back up and RSI
is a momentum indicator that sort of
measures the speed and change of price
movements and it ranges from zero to
hundred now the tricky thing here is
that these indicators on different
scales right your your simple moving
average ratio maybe ranges you know
you're sort of interested in sort of
like a point eight so at one point to
sort of range Bollinger Bands maybe
something similar but the RSI is going a
much larger scale and the problem with
neural networks is if you have a signal
that is much larger than the others it
is going to unduly influence the network
and the network is going to start to
believe that the RSI is way way way more
important than the other two which is
not necessarily true so we do have to
normalize all of these to the same
domain so they sort of haven't none of
them has an unfair influence over the
way in the network X decisions although
historically RSI and you know the idea
is you're sort of overbought if you're
above 70 you should think about selling
and undersold if you're below 30 I think
you should think about buying and I can
scale down to the domain I mentioned
before if all of that makes sense so we
have our indicators we know roughly what
their scale should be we have all the
requisite machine learning and financial
know-how to start working on this it's
on two part three the Phoenix
application
so now that we understand all these
things and we know how to write it Luxor
and we know a bit about finance we can
start predicting things with our Phoenix
app I imagine I'm just going to do this
anyway show of hands how many of you are
not familiar with Phoenix ok don't do it
don't be shy if you're really not that's
ok close I'm not at all surprised
there's folks who are not familiar and I
think that it's good to be aware of that
so cool we'll talk about we'll talk
about Phoenix I just didn't want to like
talk about being like literally no hands
go up and like you know I'm not going to
tell you stuff that you already know but
that's good so Phoenix Phoenix is a web
application framework a model after
reviewing rails are inspired by it in
many ways that is written in elixir and
is used for all kinds of fantastic
things in this case for predicting stock
prices in this case we're using elixir
1.4 and Phoenix one point two point two
which I think are the most recent but
maybe next two most recent if they're
not the most recent will also be using
d3 which is a JavaScript library for
charting things and drawing pretty mind
graphs and things like that
as well as CSV files the CSV files are
sort of what the d3 librarians going to
pull in to generate these charts so I
apologize that this is a little bit hard
to read but I will tweet out a link to
the slide later today in the talk
abstract and in my original plan I was
not going to use a homegrown they're all
Network for the for the code but over
time and this happens to all of us I
discovered that someone else had done a
much better job of it and I was going to
do so I'll use that so I did want to
show you the some of the neural network
code that I did right you can if you're
in the front couple of rows you might be
able to see this you have this function
here sign apps that kind of creates a
matrix of like randomly initialized
values very small and sometimes we
mentioned that sign APS's are sort of
for the neurons are initialized to small
small random values and then we have
this training method that basically goes
through and says okay I'm going to take
some input which appears just a matrix
of zeros and ones the output we expect
is 0 0 1 1
and we say okay we set up an agent to
store Satan and we tell the agent okay
tell me what the state is we get the
state store that in their signups we
then map the sigmoid function which is
our activation function it's kind of
smooth and kind of S shape we map that
over though the input layer we take a
look at the errors okay how did we do
subtracting the result from the output
and when we determine how much we were
off by we then take that error and
multiply it five the first layer with
the derivative of the sigmoid function
mapped over it again the derivative is
sort of that back propagation step where
we're kind of trying to figure out the
steepness of the curve down to that
minimum error and we go ahead and we
update the synapse you can't really see
it but there's a couple of matrix
transpositions a little bit of
arithmetic and then we show that back
into the sign out state and in this case
we end up doing this 60,000 times and
again it's hard to read but if you if
you can read in the front view rows here
you'll see the values are like point
zero nine point zero zero nine I think
or actually can read on the screen why
not
and then actually I can't comes too
small and then very close to one point
nine seven and point nine end I think
three five and then as you walk down
these kind of signature at ten thousand
iteration increments you can see that
the first two values is the output layer
zero zero one one the first to steadily
approach zero and the last to steadily
approach one so the this is about ninety
lines epic lick sir it's almost all of
the code that's necessary to kind of
have like a sort of tiny roll Network
and it's already learning which is
really cool but like I said I looked on
hex and there were better options so the
neural net and I get zero underscore net
package on hex is what's used in this
project and that's what I'll show you in
a second if you're curious I'll put this
on the in the slides as well I may put
up a gist in the slides there's my
website there's a blog post that has
sort of a translation of
some Python code and a closure that's
very similar to this I give you a post
as well for a pretty elixir code so I I
occasionally do live demos I've done
them before but having into more and
more conferences and having become more
and more paranoid
things like Wi-Fi or audio-visual stuff
or programs crashing even though I guess
I'm supposed to let them fail now I'm
still getting used to like Serling or
just a difficulty of getting out of
keynote which I've struggled with my
entire adult life for some reason I'm
not going to select that on you while I
start over for 10 minutes so left to
make do with with some screenshots but I
think that'll be ok so again I apologize
for the small size but this is what
training looks like very similar we saw
before if you can read these first roads
there's you know Bollinger Band there's
a value of RSI there's a value simple
moving averages of value and we continue
to move down from there there's about
like I said 200 and there's actually
about 230 values here because the
Bollinger Band if the window is 20 days
which it is in this case and the same
for the simple moving average it'll take
20 days for you to actually get Nina the
first 20 days of the year will be kind
of like not a number things like that as
mentioned in order to get all this code
shaped the right way to put into the
neural network I had to do some pretty
extensive Python magic so apologies for
having to cheat a little bit there and
the cool thing though at the top you can
see is processing by elixir confident
electric on for you that face controls
the Phoenix application and it's a get
on the route route so early on I could
just hit a route and it would train in
real time which is amazing to me it only
took a few seconds but as I tuned the
error way down and learning rate a
little bit down to avoid skipping off
the bottom of the error curve it became
impossible to train in real times you
have to sort of train offline and then
look at your tests in the in the
application but it was cool to be able
to train in real time for a little bit
so here are some of the charts from the
from the UI one interesting thing here
to me so on the on the left here we have
the S&amp;amp;P 500 in 2015 and the S&amp;amp;P 500 on
the right is from 2016 these years are
consecutive but they don't really look
that much like each other so you see the
S&amp;amp;P 500 on the left kind of starts off a
little bit rocky goes up kind of move
sideways for a while because it's steep
drop at the end of August beginning of
September bounces once falls down again
in October comes back up and continues
across and interestingly enough it's
tough to see because of the the
y-intercept there the blue line overlaps
with it but we don't actually land up at
the end of the year we're actually very
very slightly down for you basically the
entire market went sideways so from
January 1 to December 31
whereas for 2016 we start what like a
spy starts at around 195 maybe a little
bit above that let's say 200 and ends at
around 220 I had that kind of like dip
at the beginning and then a little bit
jagged but mostly up and to the right we
actually end up about what up 10 percent
for the year 2016
so like I said earlier I I picked these
because they're recent but it's not just
because the reason is because they are
very different and I wanted to see if
this had an impact on sort of
overfitting if I had a very different
year you know before that I trained on
as opposed to tested on over the result
view and whether this dissimilarity
would sort of avoid overfitting
so this is our portfolio value for the
out-of-sample data set or this is the
test
so the 20-day return is positive again
the Machine wants to go long and take a
position with a 20-day return is
negative it says nope I'm going to short
the market and if it's zero or very
close that says I don't know what to do
so I'm going to get out and that's no
position and you can actually see a
couple know position moments those flat
lines where the changes gets out of the
market entirely and so I'm good where I
am which is very interesting to me I
actually don't know why it's doing that
like I said it's your black boxes so
nobody knows and the universe here is s
py so the standard imports 500 but the
index tracking it the positions the
machine can take are long 500 short 500
or nothing and we're going to start with
a hundred thousand US dollars so that's
why we have the value of the portfolio
here on the side we doubted hundred
thousand dollars where we start and we
actually had up at one hundred and
sixteen thousand so how do we do
actually not bad so NS in 2015 SP y was
very slightly negative we got a negative
point seven three return the Machine got
about a three percent return which is
not bad you know we beat the benchmark
what's very interesting to me is that in
2016 even though the market returned
almost 10% the Machine managed to get
16% even on two years that did not
really look like each other you know
that's that's me is pretty good now it's
not great in the context of like how
well could we have done right so if we
look back at that chart so this is sort
of you sort of see the fall down the
bounce up a couple bounces and then we
kind of go up into the right if you look
at 2016 the Machine sort of like follows
that trend downward for a little bit and
then it takes the upward turn and it
does actually look like that spike
downward it actually looks like it's
shorts on that spike downward which is
great that's exactly what it should be
doing and then it kind of moves sideways
for a bit and then for the last couple
months of the year just kind of like it
looks like it buys in holes in basement
good now the best thing we could have
done would have been to short
immediately in January or close to it
and stay short probably until that peak
in like earlier mid-april and you could
do some some shorting try to avoid that
spike in the middle and then you just go
long and you just sort of fall to mark
it up maybe maybe avoid that dip on the
right and the best we probably could
have done is about a 31 or 32 percent
return so even though the market got us
10% commission you got a 16 percent we
could have gotten as good as 30 37
percent so things that we could change
we do have relatively simple set of
technical indicators really just
variations on the price of the price
momentum and the investment theory is
really that eventually we're going to
regress to the mean right so a richer
set of indicators could potentially help
us although more indicators would mean
that we have a lot we're going to
require a lot more data there's this
notion in machine learning of this kind
of curse of dimensionality the more
indicators that you have the more
features that you're trying to use to
describe what's happening the more data
you're going to need in fact it's much
much much more data it's you know for
example you know if you if you have 10
more indicators you're going to need to
know 100 sorry what is it you're going
to need 10 squared yes exactly so it is
exponential in the amount of data that
you're going to need so it's really
tough if you want to have you know 30
indicators you're going to need not
you're not going to need 30 times in
mâche you're going to be much much more
but we could do that we could design a
very complicated financial engine that
not only takes into account it's called
technical analysis this idea of using
older you know past prices to predict
future prices we could use fundamental
analysis you know looking at various
attributes like price to earnings ratio
or beta or other attributes of the stock
market capitalization things like that
we could look at macroeconomic trends we
could plug in to Twitter and see what
people are saying about various
companies things like that in order of
the market in general in an attempt to
have more information about what people
will do and have a better return so
those are things that we can do we can
even change the model we don't have to
use a neural network we could use
decision trees we could use
random forests we could use you know
ensemble methods like a whole collection
of neural networks and gets very
complicated very quickly but there's a
tremendous amount that we can do we in
fact don't even have to do supervised
learning there are other forms of
learning such as reinforcement learning
where you don't sort of learn Apollo you
learn a policy and actually dr. Tucker
bolts who teaches machine learning for
training and David Byrd at Georgia Tech
recently gave a talk at quant Khan in
New York where they very successfully
demonstrated a key learning trader that
did achieve something like 30 percent
return over the out-of-sample window so
there's a lot that can be done cool
we're almost done so what did we learn
well a little bit about machine learning
neural networks and Finance we saw we
didn't have to use neural networks but
they're cool and kind of exercise
Durling and elixir and show that it
wasn't a problem for us in terms of
number crunching we talked a little
about other machine learning models we
saw all this is super doable and
honestly the takeaway think that you
should sort of like if you don't take
away anything else from this talk I
think the thing that's important is that
library support is what we really need
you know like I said a lot of the
scaffolding on this talk is in Python
it's sort of got things into the shape
they need it to be the more library
support we have things that are like
numpy like Sipe I like pandas the richer
ecosystem we can have for doing kind of
machine learning type stuff in Erlang or
in elixir on the beam cool so be the
change that you want to see in the
community I know I'm stealing from
Gandhi a little bit here but if you do
want to be able to do stuff like this
purely an elixir library support is what
we need so contribute to existing
libraries open source things work on
projects share your work and make this
as fantastic as you can this code is a
little bit of work in progress the
semesters just about done so sometime
next week this will be up on github I
will tweet out a link to the slides
today but a link to the code will be
coming out probably in the next week or
so in the meantime if you are interested
in this kind of stuff quant software g8x
edu you can get a look at how all of the
work I've talked about it's been
implemented in Python some interesting
information about the course
I've been taking and about dr. bollocks
and folks like that so if you are
interested in algorithmic trading or
machine learning that's the place to go
and with that thanks so much for having
me
thank you for choosing to spend your
time here unfortunately I guess we are
out of time for questions but please do
come find me afterwards I'll be around
thanks so much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>