<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Tech Mesh 2012 - Go Do: solving Real Problems correctly with Go - Peter Bourgon | Coder Coacher - Coaching Coders</title><meta content="Tech Mesh 2012 - Go Do: solving Real Problems correctly with Go - Peter Bourgon - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Tech Mesh 2012 - Go Do: solving Real Problems correctly with Go - Peter Bourgon</b></h2><h5 class="post__date">2013-08-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pN4POgfTcDc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Peter I work at soundcloud on
search and discovery and exploration
features like this and I'm going to talk
a bit today about the go programming
language and how we use it in soundcloud
so I think this is like the gaming and
social media track but it's going to be
a bit of a mix I guess with the
programming language track as well but
before I talk about any of that I want
to kind of take a step back and talk
about software engineering some curious
is anybody here considered themselves
like a software engineer first and
foremost a little bit maybe I certainly
do and so forgive me I'm going to start
with the definition to lend my talk the
illusion of credibility if we can get it
going haha so software engineering
according to the ATM is concerned with
developing and maintaining software
systems that behave reliably and
efficiently are affordable to do this is
super boring all i care about are these
first two words here developing and
maintaining this is how i view software
engineering personally not as like a
goal or as a thing that you can maximize
but rather as a process so software
engineering as a process you're always
starting with something maybe nothing
you're getting some specs or some
requirements and you're building
something whether it's the initial
version or version to a version 3 i look
at the system as it exists today and
compare it against how it should exist
in if you in the future and not only
this process for a software engineering
but also kind of internally this is how
I judge myself how I measure myself the
better i am at what I do the more
frictionless I can make this process at
soundcloud at least this is how almost
all of our features go almost all of our
development goes we have somebody who's
in charge of something and they say
wouldn't it be cool if it always starts
this way and my job is to say yes it
would and I'll do that for you and then
I go back to my desk and I think okay
what did I just get myself into so when
I'm thinking in these terms and I'm
going from 0
implementation or version 1 the version
2 of course I use tools and so that
brings us to go why am I talking about
go it's been my experience that go is a
really excellent tool for the process of
software engineering in my experience it
provides a small set of carefully
considered primitives that are
orthogonal to each other and can be
easily combined to develop solutions to
a large class of problems those
solutions tend to be decomposable
testable and maintainable and I hope to
do a bit of advocacy here and maybe
convince some of you of this but in
order to do that in order to show you
some examples we have to get a baseline
understanding of the language so just
quick show of hands does anyone seen
who's heard of go anybody yeah I keep
your hands up if you programmed any go
at all and something significant okay
all right so we're going to do a quick
run-through of the language just enough
information to be able to understand the
examples so facts about go this is just
you can put it in your like language
matrix so you understand like where it
sits with relation to other languages go
is statically typed compiled fast
compiles will see that produces native
binaries on linux mac windows and a
bunch of architectures it's garbage
collected it looks a bit like see it's
got a big standard library and it's got
among other things baked in concurrency
which is my favorite feature okay so
let's go right to syntax here's a pretty
simple go program first line package
main every source file is a member of a
package binaries are packaged main
libraries are packaged something else
we've been import statements just like
in any dynamic language I guess and then
a main function it's the entry point of
the program here we're defining to
string variables this first one is
explicitly typed in that we save RS one
is a string and it has a value of this
Icelandic name that I won't try to
pronounce and then this is exactly the
same thing it's still statically typed
but it's implicitly statically typed so
s2 is getting the type from the string
literal it's also a string so the last
line is a print
statement just like sea and we run this
and in the background we've taken this
text compiled it run it and then
forwarded the response back to the web
browser here and we get what we expect
okay cool simple syntax a couple
features really quick types so in go the
word type is a keyword use it to define
new types so like here's a structure
it's a thing it's got a name which is a
string and a value which is an int
notice the declaration is reversed I
think that has a special name maybe it
doesn't similarly to defining new
structure types you can create what's
called a type alias so Celsius and
Fahrenheit are both aliases of float32
that means they're kind of built on top
of float 32 s but they are not float 32
s so you can construct them in this way
you can say this is a Celsius value this
is a Fahrenheit value but you can't
compare them if you try to compare them
you'll get a compiler error because the
types are mismatched you want to do this
you can cast them this and then this
should work yeah okay so that's types
hand in hand with types of interfaces
interfaces are like abstract classes and
other languages for example if we had a
type runner interface that is a
collection of behaviors in this case
only one behavior and it says if you
have anything that has a function that
takes an integer and returns an error
and it's called run then by definition
that thing is a runner and you can use
it in place of a runner in your program
so a concrete type would implement this
interface if we have something like a
run bot nine thousand with some stuff in
it we can define a run function on it
taking a distance int's returning an
error and of course run bot nine
thousand cannot possibly fail so it just
returns an ill air and now the run bot
nine thousand is a runner and can be
used as a runner crucial point there's
no explicit declaration of intent you
never have to say implement a runner or
anything like this it just is and the
compiler builds this kind of tree during
its compile
okay so interfaces are first class
objects you pass them around many
standard library functions operate
exclusively on interfaces so for example
we can build such a function here race
takes a distance and then a basically an
array of runners that's very attic very
otic type syntax so we just range over
the runners it's like a four loop for
each one we're going to call the run
method if the air is nail if not if the
run succeeded then hooray it finished
otherwise they didn't finish and then we
print out why print out the air and then
here's our main function we run a race
of 50 meters I guess between a developer
with a certain clumsiness index a little
baby and our run bot and we see what
happens the developer finished array
babies don't run obviously and the run
Bob finished of course we run this a few
more times maybe the developer will trip
over his shoelaces eventually yeah okay
so that's the basic idea interfaces
defined behavior types implement that
behavior okay now to my favorite future
the languages go routines this is how go
handles concurrency they're essentially
co routines from communicating
sequential processes they're very
lightweight threads are multiplexed on
to one or more operating system threads
they're very cheap you can launch any
function call on a new girl routine with
a go keyword so it begins executing
concurrently in the background note it's
not necessarily in parallel you don't
get handles or any explicit goroutine
management because communication between
go routines is idiomatically
accomplished with channels which are
types synchronized and optionally
buffered pipes for data you can think of
a channel as basically an eye a unix
pipe except with a type attached to it
channels are first class objects you can
pass them around like anything else and
you can have a channel of channels and
thereby get like a lambda calculus or
whatever you want ok so how do these
work in conjunction let's take the kind
of canonical example you have a producer
and a consumer so here's our main
function we're going to make a channel
vente jerz make is like an allocation
primitive it does some allocation and
initialization for some types
we're going to go a produce function and
then synchronously call the consume
function produce takes the channel of
integers it puts one two three onto it
that's what this little syntax is it's
like put this value on to the channel
and then it closes a channel which is
like a signal to all the consumers
you're done you can stop listening and
the consumer uses a range over the
channel range is a special thing when it
receive the channel it's going to yield
every value that comes on to the channel
until the channels clothes and then the
loop exits basically so we yield all the
values and just print them so when i run
this I hope you just see one two three
yeah okay obviously duh I any takers
what happens if I do that any any
guesses does the output change okay
let's see run no output consistently no
output haha so exactly we got this main
thread of execution we create the
channel great we launched a girl routine
to produce great we launched a core team
to consume great and then we ran out of
main and when you run out of main the
runtime environment shuts down and in
this case it shut down before allocating
any CPU time to either the go routines
we just launched so they get shut down
immediately as well if we want whoops if
we want to fix this we can do one of
these and in order to do that we need to
do this okay and now if I do it one two
three okay so this is how you can
conceptualize go routines and channels
that's basically all we need to
understand the examples types and
interfaces the routines and channels
it's like peanut butter and jelly or I
guess here it would be like beans and
toast okay so back to this idea process
software engineering is process I don't
know about you but when i get these
specs from my product owner or whatever
i go back to my desk and I look at it
and I say I'm in over my head probably
what should I do I'm going to first I'm
going to build the simplest possible
correct solution to the problem
so you don't have to buttress it with
caveats and it doesn't work on this day
it doesn't work in this use case so I
build a simple as possible thing try it
out and then iterate all right so make
it better make it faster make it smarter
make it do better things so keep this
idea in minds and i'm going to show you
this first example where we're going to
do kind of like a scatter gather so
you're going to collect data from
multiple backends aggregated into a
single like response object and then
propagate that up to your requester
think about how you might do this in
your own language of choice I don't know
what that might be okay I must say I've
actually taken this example from another
really great talk by a guy it's called
Sameer at Google afterwards you'll see
the link to the slides if you're at all
intrigued by this check this talk out
it's really good okay so we need to
model a concept of a backend which is
something that can take a query and kind
of return results so we can model that
and go as an interface a back-end is
anything which has a query method that
takes a query string and returns a
string think of it as like search
results or something like this so that's
the behavior we want we then define a
couple of concrete types which implement
this behavior like let's say we have a
my back end which is only a string type
alias we define a method on that which
sleeps up to 100 milliseconds and then
returns a string which is just the name
of the back end / the query you gave it
so you can imagine this is like the
results and this is somehow work
similarly sound crowd soundcloud is
somehow always full of Skrillex so let's
say we have a Skrillex he's an empty
struct that also has a query method he's
going to do the same thing and he's just
always going to say well blah blah okay
straightforward so what's the most naive
possible way to have a set of these guys
send a query to them all collect results
and return it well I guess you just do a
for loop right and you just do it
synchronously so let's build that
function query all takes one query
multiple back ends and returns and
basically an array of responses so how
do we do this we build the array we do a
for loop over the back ends we run the
query append the results and
return the group a super simple super
dumb super slow I'd probably get fired
if I did this all the time but whatever
version 1 so in the main function
defined three back-end server once over
two and somehow Skrillex record the time
we start send the query out put the
results and record how long it took so
if you can imagine every back and is
going to take up to 100 milliseconds are
going to take on average 53 backends
average 150 milliseconds let's see 127
to 3985 not too bad so key points here
it's always an order server once over to
then Skrillex and it can be as bad as
300 milliseconds I guess ok so there's
iteration 1 and it's correct and it
works but it's slow so what's iteration
2 what's the simplest possible way to
make this faster you actually maybe do
the scatter gather even my product
manager can understand that you don't
need to wait for all of them in sequence
you can just wait for the longest one
and that should be enough time so think
about how you would go from this naive
version to like what I've just described
in your own language of choice probably
you need some kind of framework probably
in Ruby you're doing an event machine
thing and go it's really simple so let
me do that let's fire the queries
concurrently we're going to have the
same query all method the same method
definition but we're going to do things
differently inside we're going to have
this scatter phase the query phase and
the way we're going to model this is by
building a channel a channel of strings
or channel results with a buffer depth
exactly equal to the number of backends
that we're going to fire fire against
then for it all of those backends we're
going to go a closure an anonymous
function that calls the query and then
puts the result into the channel so
there's the scatter face and then the
gather phase is almost identical we
build this array of results for every
back-end that we fire to go routine for
we're going to drain the channel so here
were draining a value from the channel
and appending it directly into the
result slice and then we return that
just like we did before so know that the
method definition didn't change and
you'll see the way we call it isn't
going to change all we did was change
the implementation this is what an
interface kind of gives gives to you so
I'm going to run this and I think if I
did everything right this should never
exceed 100 milliseconds right because
that's the longest the longest one can
possibly take and it should often be
quite low I think it should probably
average around 50 so this is cool we've
made like a really significant
improvement what we can do even better
still we're kind of at the limit the
theoretical limit of how fast this can
be given the current constraints but we
can even go a step further and say if we
need it to be faster if we need to bring
the long tail these query times in we
can replicate the back ends and so we
can have the same back end with the same
content replicated let's say across data
centers and then fire the query to all
of these replicas or maybe some
intelligently derived set of replicas
and then take the first response it
comes back and use that and therefore
bring the long tail of query times in
think about how you do that in your
language you'd have to figure out some
way to handle all the failure modes
you'd have to probably clean up all
these bad values somehow a lot of
synchronization I think no matter how
you cut it but and go we can lean on
these primitives we can lean on the fact
that the channel is synchronized and
that go routines are very lightweight so
what we can do is build this type called
replicas replicas is an array of
backends in theory they should all have
the same content and then on this new
type we've defined we can implement this
query method that satisfies the
queryable interface we defined and what
it's going to do it has again the same
interface takes a string returns a
string internally it's going to do just
like the query all method does going to
build a channel we're going to feed
query results into it but instead of
aggregating them we're just going to
return the first one we're able to drain
from the channel so what happens here
we're launching all these girl routines
one of them is going to win it's going
to push the first value in we're going
to return that immediately but all the
other girl routines are still running
they're all still doing their work
they're pushing their values into the
channel and then exiting once the last
ones done all the handles on the sea
channel are going to be released and
then the sea channels going to get
garbage collected and this is fine this
is fine we're burning some cpu time on
these replicas but that's okay we
decided it was worth the cost to bring
the long tail in so then to query
replicas we have to build the replica
set so you can imagine replicas my back
end we have food 1 through 2 33 we have
another set of replicas for bar bar one
bar two or three of our four of our five
you can imagine and then frightening Lee
we have five Skrillex's all in a row and
we can see the rest of the function is
exactly the same query all we didn't
change that method at all because the
replica set is still a queryable thing
so we run this and hopefully on average
these are pretty much faster too yep yep
there's a 70 okay doing good three
iterations five minutes my product
manager is pretty happy think about how
you'd have to do this in your own
language and how maybe how much time you
need to allocate to go through these
iterations one thing I really love about
go is that the primitives composed so
well that you don't need to spend a lot
of time building an infrastructure you
can just or using abstractions or things
like this you can go directly to the
core primitives and get exactly the
behavior you want it's pretty cool okay
so this is like one smallish problem but
you can imagine and at least for me this
happens all the time I'm tasked with
building features that are composed of
many of these smallish problems often
times the behavior that's required can
be described very easily in a very
straightforward way it might be get a
piece of data from this API enrich it
via this database transform it in this
way by these set of business rules that
I'm going to give to you and then store
the result in either this database or
this data store depending on blah blah
blah a lot of feature requests break
down
for me at least into this sort of
prescriptive set of rules and I view it
as sort of my task as a software
engineer to transform this and as good
and frictionless way a pot as possible
to a working implementation so for me a
lot of things break down into into this
pattern this idea of pipeline data
processing you're given something you do
work XYZ and then you finish somewhere
else and I guess the canonical example
of this would be like an extract
transform load sort of workflow so in
this example will be subscribing to like
an event publisher to consider just a
stream of messages somehow will convert
the messages to enrich data model so
like pack some other stuff in there and
then we'll feed him into a data store
this comes up kind of a lot for me maybe
for you too I don't know so how do we
model this let's treat each of these
distinct stages as a function so let's
start at the listening function here are
listen function simulates an infinite
stream of messages pushing them down an
output channel so we have this funk
listen which we have to pass a channel
of message whatever that is and we do an
infinite loop we wait up to 250
milliseconds and then sixty percent of
the time we're going to write foo forty
percent of the time we write bar
continue okay straightforward so let's
now have an enriched stage which is
going to read a single message from an
input channel process it and then push
the result down the Alpha channel so
takes two channels enters another
infinite loop read the message in put
some nice little stars around it you can
imagine this is actually doing work
let's say and then push the enriched
message now out the Alpha Channel and I
mean that's literally it this is
production Greg code with no explicit
synchronization no condition variables
no time two weights everything falls out
of this goroutine channel model it's
already synchronized for you and as
we'll see it's already
super scalable okay last stage is
storage so etl load well model this is a
function to will take only an input
channel because there's nowhere else to
go afterwards another infinite loop we
receive every message off the channel
and then we're going to just store it to
the screen I guess you can imagine this
is going to a my sequel database or
something okay so these are our stages
now we just have to wire them together
so in our main function we're going to
build an infrastructure of channels of
pipes one between the listener and the
enricher sore to the enricher and one
between the enricher and the stores or
to the store and then we launch the
actors we launch the things doing the
work on these channels and then we'll
wait a second and see what happens so I
hope you'll see it works as expected
yeah sure and again maybe it's slightly
different right cool all right so what
are we done here we've we've modeled
this very simple business domain set of
rules in a very simple implementation
that maps directly to what you kind of
perceive the necessary work needs to be
and for me this is so important I don't
like to spend my brain cycles thinking
in terms of like the 40 layers of
abstraction I had to use because my
language doesn't natively support
concurrency you know I like to think
about the business rules that I need to
implement and making the path from an
idea in my product managers head an idea
and my customers head to reality like as
frictionless as possible and as quick as
possible using channels to pass
ownership of the message between stages
in this way makes this program naturally
concurrent it also cleanly I think
separates the business logic from the
transport semantics so you have a total
separation of concerns not only across
business rules but also across
implementation schemas note that because
the channels are unbuffered you get
automatic back pressure which in my
experience is what you want that means
you won't ever take on more work than
you can actually handle based on your
external resources so in my experience
is better to push that failure mode out
and not accept more than you can resolve
so that's cool that's what you get
automatically so implementation one
great I roll it out and suddenly let's
say my CTO says oh this is great but
what are all these bars doing here I
didn't expect to see any bars I don't
want to see any bars so okay how would
we solve this normally maybe we would
put like a little if bar then do
something weird in the listen stage and
maybe but let's stick with this model
and let's have a filter stage so a
filter again takes an input output
channel reads a message if the message
is the bar then drop it so this is the
direct translation of a business rule to
a stage and we can just plug it in to
our infrastructure and we don't like
lose performance for this as we'll see
it maps directly to the concept of what
we're directly trying to build without
any abstraction and of course it's safe
and easy to abort a pipeline if you
think about the model of actors doing
work and pipes used to transport the
work so we can just drop this message on
the floor if we need to and it's really
a safe and no problem so to wire it up
we just add a new channel we add a new
actor and I hope we won't see any bars
sure cool easy there's no complex
abstraction to get lost in you can look
at this function read it from top to
bottom and understand immediately what
it does and how it works and go the code
does what it says on the page and i find
this super super valuable similarly
scaling the actors for a stage increases
the concurrency of the program so far
enrichment stage wasn't just sticking
two strings on the end of a string if it
was actually doing work maybe that would
become the bottleneck in this and one
way to solve that bottleneck problem is
to have concurrent let's say look up
actors running at once imagine doing
this with your language of choice how
would you have to do this you would have
to synchronize somehow the handoff of a
message to an actor and then synchronize
putting that back into a shared pipeline
to the filter stage or something like
this
or sorry to the store stage you'd have
to maybe build a thread pool or like
multiplex jobs onto onto workers and
then demultiplex back and blah blah blah
but in in in this in if you use these
these go primitives literally all you
have to do is spawned more go routines
doing the work you want reading from the
same channel because they're
synchronized and writing to the same
channel because it's synchronized and
you can in this way get increased
concurrency on very specific points
channel operations are a synchronization
point across girl routine so multiple
girl routines can safely read from a
right to the same channel each message
will go to exactly one receiver so I'm
going to hit run but you're not going to
really notice a difference because we
just are sticking strings on there but
you get the point I hope okay so that's
cool but now let's do another conceptual
change here let's say what if and so the
source of our data isn't a message key
but what if we want to change kind of
the paradigm of the service and say it's
an HTTP server and that every message is
not a vent but an HTTP request we can do
this we can change our message type to
hold the relevant information let's say
we have a piece of data that comes an
extract from the forum values and then
what we also need is a signal channel to
signal our HTTP request handler that
we're done with the pipeline processing
but if we do this if we redefine the
message structure we can we can we can
modify the pipeline to work on HTTP
requests so we have to change a listen
the listener should now start an HTTP
server rather than generate messages
that's relatively easy to do we define
this handler function H which takes a
response writer that's where we're going
to write output to and then the request
that comes in in the handler function we
build this message from the form value
and then we allocate a signal channel
and then we push that message into the
pipeline then we're going to block here
and we're wait for a dumb signal if we
didn't have a success and we're going to
write aborted and the
data otherwise we're going to write okay
so that's a handler we need to wire the
handler up to a route incoming and then
in the listening function we're going to
block forever on this listen and serves
this is the HTTP server okay that's all
we need to do there but we need to do
one other thing whenever our pipeline
completes whether it's an abort or a
success we need to signal the handler to
write a response to the client and shut
down the connection so in our filter
stage if we drop bar on the floor then
we need to tell the done channel that we
had a failure in the store stage if it
got all the way there we had a success
so we signal success okay otherwise
everything is identical we're passing
around pointers to messages rather than
messages because in theory you would
like change the content of this context
would maybe be a lot bigger but I'm
going to run this now rather than
sleeping for a second we're blocking
forever then I hope okay 8080 incoming
data a foo cool foo food to food three
the dreaded bar not there I'm boarded
cool bar to feature request yeah so the
cool thing here is we didn't change
anything because conceptually you don't
need to change anything the way you can
describe what this program does whether
it's this events are coming from an HTTP
server or coming from a message plus
like it doesn't change the business
rules and indeed we haven't changed our
business rules we just changed the
functional component that's different
this is really cool and for me this is
an amazing like enabling capability so
in a recap for me go helps the process
of software engineering to be a lot more
pleasant it gives you simple orthogonal
primitives that combine well it makes
code readable and maintainable and as a
result of all this they say that go code
is code that grows with grace and I tend
to agree so I hope I've given you a
taste of that
that's it thanks a lot questions anybody
we've we're a little bit ahead of time
so feel free to ask more than you
thought right so in terms of all like
coroutines it looks fairly similar to
the occur in Scarlett's of the occur
framework and access framework and skull
is the actual well okay with some
changes which i don't know of but with
with the terms of redirection to the
channel is that a language construct or
is it a some sort of a function I mean
the question is can you define the
functions like that acting similar way
with a similar sort of you know is there
a like a restrictive characters or is a
language construct or what like I'm not
totally sure what you're asking okay so
for example in Scala can define any
function any function name is the
similar for go you can define any
function name yeah for example redirect
you had in redirecting stream we direct
to the channel is a you know is a
function with like you know funny name I
was just wondering if that's the
language construct and go is redirection
20 the arrow or language construct you
get operator overloading you mean things
like this no there's explicitly no
operator overloading is it operation ok
yeah does that answer the question ok I
could expand on that a bit and say
that's actually by design the the go
calculus that they've landed on the idea
that operator overloading hurts you more
than it helps you so this part of the go
philosophy so what about debugging this
I mean concurrency is always nice and
this looks really impressive but what if
it goes wrong what kind of tool sets do
we have to find out what went wrong what
if it goes wrong ok let's see if I can
do maybe not ok so debugging in general
there's gdb support so you can load up a
go program in gdb but that's often not
like the thing you really care about
with concurrency so let's go back to
this producer consumer thing
yeah here we are and so what's what's
like the most common thing when you have
a concurrent program like the most
common bug would be what deadlock
probably right a common bug so how can
we induce deadlock here if I produce see
and then consume see without launching
one in the background then this guy is
going to try to execute but he's never
going to be able to push this value
because there's never going to be a
receiver right so in theory this wood
block forever if I ran this as it exists
here so let's see what happens oh well
yeah that happens first of all can I try
that so did go runtime gives you
deadlock detection and when it detects
this it gives you kind of a stack dump
which maybe you can't see so well in
this tiny little window but if this were
a real file you would see exactly where
each go routine this is like the runtime
environment but we only have one girl
routine and here it is main doubt main
line 10 so i don't have line numbers but
I home two three four okay maybe it
doesn't translate but in general you get
in the runtime it's kind of
sophisticated enough to give you
detection of a large class of
synchronization problems so this is cool
but even like taking a step back if you
if you model your problem in terms of
like go routines and channels a lot of
the things you normally have to care
about you'd simply no longer have to
care about taking a key from some
earlier talks in the in the bigger room
you certainly only very rarely have to
do locking at all because the channels
are synchronized sometimes you use a
weight group but I mean that's really
the extent of the primitives that you
dive into so I've been programming go
professionally for a year and kind of
casually for well since it was
introduced three years ago and I cannot
say I've ever used a debugger and I've
done some pretty big stuff so that's
cool too in a way in my canoe
I work in a team of about four or five
but at soundcloud we have very fluid
teams and this changes a lot bigger and
smaller and go is a prevalent language
but we also do scala we also do Java a
few other things but we're kind of like
a service we're trying to be a service
oriented service service oriented
architecture sort of company and in my
experience goes like the perfect
language for this type of service so I'm
trying to convince other people of that
as well in the company there are several
including several that have been built
kind of for the ground from the ground
up but for my money the best you can do
is sublime text 2 with a code Intel type
plugin called go sublime maybe I can
just show you it's really cool i'll try
not to load up any terribly production
grade code dangers of a live live demo
okay so blah blah blah but you get this
really nice completion and then you get
dropped down and then you get this and
blah blah and you get build support
undefined key okay yeah all right let's
build no errors automatically runs a
test tests okay blah blah blah pretty
cool and the go language is lightweight
enough that like this is possible and it
like doesn't require a ton of storing
par state or anything in the IDE to
question the first one is about to
concurrency model GU is using CSP um
rendezvous fo for channel mean it's a
real CSP or modified one it's certainly
inspired by the CSP model but I can't
say like is there a CSP spec that you
can either bye-bye or fail at like I'm
not sure about this actually there is
one but it's but world and stuff like
that okay so i would say it is not a
strict proper CSP implement
it's more like inspiration and you
didn't miss the 2n synchronous channel
and types of the actual model or you
approach it with the concept of buffer
buffer channels but see how how to
answer this I wouldn't say that I miss
it because go is kind of first and
foremost a productive rather than a
theoretical language and in the in that
context in the context of like
pragmatism asynchronous channels like
they enable this this huge class of
really interesting models that you can
build but when that model like
interfaces with silicon and memory and
stuff and resources you you need to care
about things that you didn't need to
care about at the model level and so
asynchronous channels alike they'd hit
to support them properly I'm kind of
speculating here would require an
enormous increase in the complexity of
the language and go generally when faced
with a decision and in these terms will
go with the simpler solution even if it
means leaving features out so I'm not
sure this is why there are no
asynchronous channels but I can tell you
this is why there is no generics and go
yet a number of other things no
exceptions as well so thank you
partially perhaps already my previous
question but how are the coat and go
routines and the channels implemented or
is there anything we need to worry about
in the implementation like bottlenecks
or so when you spawn a new girl routine
it takes up like four kilobytes of
memory so that's that's your overhead
you can get to about fifty hundred
thousand in a program without a sweat
some of them you do it intelligently you
can do about a million so it's no
problem to do like n go routines per
request for example this is not a
problem I'm unfortunately not super
familiar with how channels are
implemented but if you had concrete
questions you're concerned about I could
maybe answer those ok later thank you
yep excellent thank you as I say if you
could just write the session on your way
out it's greatly appreciated and thank
you very much for your time thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>