<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Dmitry Ivanov &amp; Nami Naserazad - Practical Demystification of CRDT (Lambda Days 2016) | Coder Coacher - Coaching Coders</title><meta content="Dmitry Ivanov &amp; Nami Naserazad - Practical Demystification of CRDT (Lambda Days 2016) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Dmitry Ivanov &amp; Nami Naserazad - Practical Demystification of CRDT (Lambda Days 2016)</b></h2><h5 class="post__date">2016-03-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/PQzNW8uQ_Y4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you everybody thank you for
this huge numbers
in this stop we are going to
practical demystification of CR DT I'm
Nami his Dimitri and DDA who had great
contribution but couldn't join us so
first disclaimer is that we are not hard
academic guys hardcore Academy cars we
are not that much expert in the Swiss
system we won't just use some
achievement from the academic in our to
solve a real-world problems we are full
stack developers so we are do many
things we are doing back and front end
infrastructure while I'm talking to you
I'm also on call from my back-end
service so if it's something goes on I
have to react fast and we are working in
TomTom and we are working on a system
called nav cloud sister floud which is a
stew cloud based storage service to let
users synchronize their navigation
information some time has a lot of
clients in the market a lot of devices a
lot of automotive have contract with
TomTom so most of them are gradually
will integrate with nav cloud and
already many of them had so TomTom so
nav class returned a lot of requests a
flow should be scalable and available
and because location-based information
and information is not one of the most
sensitive information enough cloud
should be really secure and also should
comply with the legal requirements and
also enough that once wanted to be used
in a third-party application and TomTom
application as well so we should not
degrade their performance that we have
to be reactive and respond quite fast we
try to use the technology that matches
our requirements very well so in the
server we use a scholar as a core
language and also spray a knock on top
of that using RabbitMQ for push
notification reoccur out storage and we
deploy in Amazon and also to facilitate
integration with nav cloud we implement
different SDKs in a different
abstraction level with a different
different technology Android Java C++
etc such many synchronization system and
also knife not have specific
characteristics especially the last
cloud which is used in navigation
devices when most of them have SIM card
built-in and this SIM card will be paid
by the comic-con company by TomTom or by
automotive company so they have very low
bandwidth and although also when you're
driving you most of the time you are in
the places that you don't have internet
because for example you go to the farm
doesn't have any coverage you're going
to the tuner you're parking in a parking
so you don't have in
so the characteristic is that the
connection is unstable as I said man
with his limited and user Shh
doesn't want to wait until he'd get the
Internet and apply updates on his
information it wasn't seamlessly just
changed things and of course because the
duration of this connection is big you
may change concurrently and these
changes may be in conflicting state and
of course or there is not guaranteed if
I change something now it may reach
sever an hour later okay and some of
some other changes can happen meanwhile
and of course user cannot accept the
data it's gonna be lost and this is
against the legal requirement and of
course data should be conversion to the
value that user must probably expect so
how to deal with that you can first lock
write a lot of logic trying to cover all
the corner cases a lot of code effort to
handle everything I doubt that is even
possible but if it's possible it brings
you a very maintainable code and as
leanness turbot said the good developer
always focus on a data structure they
want to solve the problem at the data
structure level so they want to gain
benefits out of the box this is the
reason that we went for CR DT so we said
CFS we wanted to try CR DT as I said CRT
is a data type the data structure and it
has its own it's a family a little bit
and because if an is a range of data
data structures and it has its own
algebra and also it's replicated so it's
meant to be distributed so at any time
any instance of CRT can have multiple
replicas which these replicas can be out
of sync and can be out of same is one
thing and they can be even in a
conflicting state most of you work with
these source control tools like get
sometimes get solves this conflicts for
you using something like recursive
strategy but sometimes it can not and
you have to interfere the user should
have should interview but C at least is
no no user interfere I know what I have
to do how does it do that the main
ingredients of this lot of benefits is
something called merge merge is a part
of the C R DT algebra what is merge
merge is a binary operation on too
Ciardi T's having
these characteristics so merge must be
committed if must be associative and
must be ight important and it's really
clear what are those are so YC ret
should have this characteristic what
does it bring for us apparently these
characteristics characteristics matches
really well with the distributed nature
in distributed systems we get all there
is not guaranteed so you may send event
I may send even to you but a couple of
even to you but there is no guarantee
that in which order you receive those
imagine that I'm server I receive your
event and I have a local stead I just
merged to the local estate merge to the
local estate merge the local estate but
my merge is committed and associative so
no matter in which order that I receive
those they all will converge to the same
value so apparently really good for the
distributed system another thing is that
in these service systems even can be
delivered more than once so I send you
an event you send me back an ack-ack may
be lost I thought that you haven't
received it I resent it to you but you
you received it twice but again you just
merge it you just merge it to the
current estate current state and you get
it multiple time but because merge is
idempotent doesn't matter it reaches a
same value and what it doesn't what does
it bring in practice is that you can
change things locally you don't need any
on-demand
remotes synchronization you can change
things you can change things locally and
they will reach server at some point and
local changes be able to apply changes
in our fly mode actually brings a great
user experience because user cannot
doesn't need to wait until it gets the
internet I said I explained some couple
of very easy examples about CRT team the
first is G counter do counter is all
these growing counters at the counter
that always grows for example you have a
website you want to count the number of
the heat on your website and probably
your website is really successful and
you cannot count it in just win what one
single machine so you want to distribute
it Li count addition is not a very CR DT
compliant operation because imagine I
have different three machines and each
of them can receive their request
towns and if I have numbers in each of
them and just increase them I cannot
merge them because addition is not item
potent if I send event and it receives
twice it counted wrongly so I have to
think about the data structure that
suits well so we define an array which
has elements corresponding to each
machine so I have three machine here ABC
and it so I have array of three elements
is exactly vector o'clock so whenever I
receive a request for count is just
increased their corresponding elements
so I am always incremented the first
element and it's not intervals they talk
to each other because gossiped with each
other to propagate to broadcast this
information to reach their state to the
total estate and upon gossiping for
example series if the array from B and a
it just merged to its own array how does
it merge it just picked the maximum of
the corresponding element so here for
example if C receives from B and a the
result will be 6 3 9 because the maximum
of each element will be deists and what
will be the total value is some of them
so in this way I count a distributed
count and it's gonna work and I never
count twice it never lies to me maybe
show something behind but eventually
will consistent to the true to the
correct value why does it work because I
use max in the merging and Max is the
RTD compliant max is associative
commutative and height important and
this is why it works
another example even is a simpler
example is G set G set is all the always
growing set you can just add element to
the set adding element to set is
actually Union Union Union of a set of
one element to another Union but Union
unlike add is ease compliance and Ciardi
to compliant so I don't need to change
my data structure I just have different
set in different machine whenever they
receive a value they just change the
local state i said local update is the
great benefit of nafla of absurdities so
so whenever the gossiping to each other
they just Union them and of course Union
is CV RTD compliant because Union is an
associative commutative inaudible
okay how this data structure will will
help us enough cloud affluence different
use cases one of them is that
synchronizing the favorite location so
you may go somewhere you like it you
mark it as a favorite and regardless
which device that you use or whether you
have a connection or not you want this
to propagate it seamlessly and you want
to have a list of the favorites
regardless where you set them favorite
has a different attributes like name
longitude latitude address etc etcetera
naive approach is that just last right
wins whatever server receives is just
right into the database so this
obviously is not gonna work because
imagine I I'm offline and I send the
data for example I'm in the parking I
don't have internet I want to mark his
parking because a nice parking and it's
cheap as a favorite location but I don't
have an internet so I click there and
imagine that an hour later it will reach
the server but in meanwhile I also may
apply some other changes so it will
override my most newer my newer changes
and also you can solve this by attaching
timestamp but which timestamp there is
no reliable clock clock of your device
clock the clock of your a server you
never know although as limit you're
gonna explain you we are going to use
timestamp but we are going to use a
simpler version and a little bit
tweaking around that so the result of
that is letting update will win so you
may have stale update will win the newer
so let's try see our DT because see
oddity apparently is a good match for
this environment
you already saw this slide this is the
correct nature of naff cloud on a stable
connection fine CRT said that I don't
need on-demand removes synchronization I
can't just change things locally lobe at
low bandwidth we extended the algebra of
C our duty to support another operation
calls difficulties so what does that
mean it means that whenever I want to
send us up there to the server instead
of sending the entire CR DT I just sense
the difference between this local state
and the last state that I have seen from
the server
so I optimize the bandwidth seamless
atif you this is by nature conquering
changes of course you can have a calm
flick ting changes but Ciardi design
theory says that I know how to solve it
no guarantee on update order we don't
care see oddities associative and
commutative data lost we never override
we always merge so we're not going to
lose data and data convergence to the
expected value okay why because we use
this data structure everywhere we use
this data structure and client we use
this data instruction in server and even
we use this data structure in the
database so no matter which technology
that we use we have C or D T sets or C
or D T whatever in the client in the
server in the database and all of them
does all of them do them merging things
and merge logic is consistent everywhere
for example we are using react as our
data store
react has a very nice feature which
attaching a vector clock to an entry
that you enter is a key value base
database so whenever you read you write
something a react
attach a vector clock it's a lot some
kind of vary a little bit different from
the pure vector clock concepts and kind
of versioning things buts the quite
close
so it's attached a vector clock to that
whenever you read that value you also
read the vector clock when you want
right back you have to provide the last
vector clock that you have seen if the
vector clock that you provide is
actually the most up-to-date at wanna
and it's exactly the same with the one
in the database your right will override
the previous one but if your vector
clock if my meanwhile that you are
reading someone else changed something
in the database the vector clock of that
entry will will be changed so when you
write back your your right will be
considered as a stain right and in this
case if you configure react react will
keep both version for you and this is
your application responsibility to up on
up and read resolve those conflicts but
for us we don't care it creates sibling
for us awesome what we store in the
database its see our duties we read the
CR duties and we just merge them two
lines of code no logic and we know that
this merge will converge converge with
all the clients and all the all the
other other I dunno devices iPhone iPad
iPhone everything so this is actually
a little bit of theory and now Dimitri
is going to talk about the details of
the how we implement and we actually
extend the concept of the CR DD to match
our needs cool
thanks mommy so yeah sort of salt to
sear the key concept we decided okay we
need to do our homework so we wanted to
try to model favorites as acidity set
and now we actually needed to see what
are the existing implementations of CDT
SATs and pick the one that fits our
needs so we already seen the the G set
concept but it only allows additions not
removals for favorite locations well
it's not the case we have to support
updating and and removing of the
elements so we looked a little bit
further we looked at the to face set so
what is to face set to face set stores
information about addition operations
and removal operations so removal is
supported and it can be implemented
using basically two just two G sets in
first G set we have we store our
addition operations and then in the
second one removal operations really
simple right so this is how it will look
like in the example so we have two nodes
main B both have the addition and
removal sets so how do we do luke how do
we get the total value of the of the set
well I guess it's pretty intuitive we
just need to count the diff between the
add set and remove set and these will be
the elements which are not deleted yet
and how do we calculate the merge so how
do we merge two sets together well we
just need to take a union union of add
set and a union of remove set and we
construct the new value here is exactly
what we do in here so this is the result
of the merge and of the look up I would
argue is pretty simple right and here's
like a small implementation in Scala we
have the code for all the common here
that is published we will give you a
link later
although it didn't work for us for two
reasons so one reason is that once the
element has been removed from a
two-phase set
well it's removed forever so we cannot
riad it back the second thing is a
little bit more even arguable the
elements are inherently mutable so no
updates as possible of course with the
miscibility you can still model updates
by just removing element and then adding
again the change its value although it
really easily brings much more toned
stones or removed elements to the set so
the the remove set grows really really
fast especially on the hot elements that
are updated too fast which we wanted to
avoid so there are multiple there are at
least few sets that trying to tackle
problems of to face set the first one is
last right wins element set so yeah last
right wins doesn't sound really
promising I would argue so it also
stores an addition and removal
operations again can be modeled as G set
but as is common in distributed systems
practice so if you want to get some
additional features for example you you
have this spatial trade-off you have to
introduce some sort of additional
metadata like we do with Thompson's
so in the case of last trade winds it's
actually timestamp which is associated
with every remove or or addition
operations and yeah each element has a
timestamp in that case actually we can
read element to the set which has been
removed by just provide by just creating
an addition operation with the higher
time stamp than the one that is stored
in the remove set so here's an example
again two machines we have these pairs
the the first element in the pair is
actually a timestamp just a long value
and and the value itself so how do we
calculate the lookup for the set well we
just need to analyze again the add set
for the elements and the timestamps and
check for if the element has a
corresponding state and the remove set
with the timestamp higher and if it has
10 well it's considered as we moved on
won't show up in the look up and from
merging the merging is exactly the same
we just need to take the union of ad set
and remove set this is what we're doing
here so so and based on the merge result
we get this lookup pretty easy and
that's how you can basically implement
that the basic operation lookup and
lurched so as you see merges is pretty
much the same for these sets it didn't
work for us door again the main reason
is still the elements I immutable which
means that the remove set will grow
really fast again so it solved one
problem of the to face set with reading
elements doesn't sort of stilly the
other one so the next one is all set so
all set stands for observed and remove
set so again it stores addition
operations and remove operations can be
stored separately into G sets again
so in the case of all set it actually
uses the sort of provides additional
causality for additions and for removals
so when you add element to the or set
you you provide the unique tag which is
associated with a particular addition
operation if you want to remove set
remove element from the were set you
have to find older older pairs in the in
the add set in the G set take all these
tags and put these tags to the to the
remove set basically and of course it
supports reading elements you just
create a new addition operation with new
unique tag which is not yet in the
remove set so based on that we can we
can imagine how the lookup function will
look like for or set yes we basically
need to again traverse the add at set
and find those elements that have tags
which are not yet present in the remove
set and basically that's what we're
doing here
so the merge works surprise-surprise
exactly the same we just take a union of
add set and remove set
that's basically on mesh the look up
yeah that's how we calculated look up in
here so we have us a code sample for the
lookup operation basically traversing
the ad set and then finding the
corresponding elements and the remove
set yeah and merge is is exactly the
same again it has the same problem or
yeah for us let's do the problem as a
lww n to face the immutable elements
well the elements elem usable right so
then we started thinking okay can we
enhance a little bit for our needs
the the existing sets so we said okay
can we can we introduce our own set our
set yes okay and incidentally we called
it actually our set as updated observed
updated and remove set so yeah we use
the same technique kind of by providing
additional metadata that was basically
helping to solve our needs so first of
all we said okay we want to be able to
mutate so to update the elements we want
to identify the elements so we
introduced this identifier which is
associated with each element it's a
unique identifier we use your IDs the
second thing that we said okay we also
want to have time stamps to work the
same way as in last right winds set to
be able to react elements and to solve
the the the conflicting copies and
basically that's the the the principle
so we have sort of identity of the
element which is which is immutable
right so it sits there forever once the
element is generated it has this non
changed ID but the value is mutable so
we ended up with this structure so the
metadata that we added is basically idea
as a set time stamp and this funky
remove flag so what do we need at that
well we could have modeled that one as
as a two separate sets for additions and
removals so the problem we wanted to
save some space and we said okay if we
integrate introduced that discriminator
field for marking the
the element has removed or not removed
yeah it's actually works pretty well so
yeah and of course that can contain only
one element with particular ID so here's
an example again two machines so we have
these four four fields so the UUID
timestamp the value itself and optional
remove flag which if it's not set then
it's it's false so how do we calculate
the lookup for for our set so for
example on a machine
we just need to traverse the the
underline sets of our land set of all
elements and find those which are not
removed it's pretty easy right how do we
merge so the merge in that case is a
little bit more involved not that much
so if you need to merge the values from
two machines we have to well take all
the elements from from both underlying
sets then we group them by ID we get
these sub groups for each elements these
are like conflicting copies that has to
be has to be resolved so we need to
reduce across these groups how do we
reduce well we have a time stamp so we
can say okay we pick the winner based on
the time stamp if it's possible so
here's our merge result will be like
this so these are the winners and the
lookup will be only two elements one is
removed one pretty easy yeah and again
the the code sample how you can
implement that basically exactly what I
said about grouping okay so once we were
kinda determined we want to go that way
we have our model set we started
modeling the favorites API using the our
set
so exactly we have the set of attributes
that we want to synchronize which is
like a favorite data right like name
location whatever and we have these
three additional metadata fields which
are encapsulated by this favorite State
element these metadata is needed for
synchronization
so one may I ask what do we do if we
have equal time stamps so we as I said
in the merge we have these subgroups
where we reduce okay we have to equal x
times four to two elements so as Nami
said here the key has to guarantee to
has has a guarantee to converge so
whatever happens they have to converge
to do to a winner in that case and in
the reducing of the group so if time
stamp is the same we continue comparing
so the next one we we we checked the
remove flag and in in cities there is a
there is a term of bias at or delete
bias so you can depending on the
business needs you can say okay I prefer
the deletions or removal additions or
removals and etc if even the remove
slack is the same we have to compare all
the rest attributes even we have to have
a deterministic Lee deterministic
converged operations right so even if we
have to go to the to the real last
attribute we do the lexicographical
order comparison because it's
deterministic so once we introduce these
favorites C or D T's on all our layers
starting from the application client
application server databases Nami set
everywhere we have the same flow
basically everywhere on each layer we
have this merge operation which is
applied to the to the values that coming
from from from the other layers right so
the update comes from UI comes to the
client client merges to its local state
if something comes from the server then
this update can also blindly be merged
to the local state you don't have to
worry that much about the conflict once
you have your model implemented right
way so for example on the server yeah as
Nami was explaining the the react case
for example server is just sort of like
a proxy so server receives an update
from the client the deef it fetches the
data from the react resolve the conflict
which is not shown here and then it just
needs to merge these values the values
from a database and from the client
and yeah push to the database and return
the the the resolved values to the
client that's it pretty simple it's
pretty simple model to program because
well yeah basically you don't have to
worry that much about implementing all
these conflict resolution code and every
single component separately especially
if you have like in our case a zoo of
different platforms different clients
that have to adhere to the same things
so so far probably you you heard you
think like now yeah it's pretty pretty
good pretty awesome there are no any
problems we'll share with you why don't
we just start using charity everybody
right like for the the kind of
applications why do we need just a
normal set normal data structures well
there are considered considerations and
limitations that there's always a trick
right so the first I would say problem
well-known problem with charities is is
the growing Tom stones in he set so
every time we do delete an element you
produce this Tom stone which is stored
in the remove set and intuitively the
more you you perform updates on the on
the on this set on the you you create
more Tom stones right and potentially is
unbounded growth so we have for example
we observed once we just rolled out our
API we observe that one of the betta
user had only five non deleted favorite
so in UI he was seeing just a small
piece of information that was
synchronizing but if he was actually
testing quite hard the platform and he
created like three thousand deleted
elements which resulted in unzipped JSON
like one megabytes wow that's crazy and
imagine that it comes and goes by the
the the wire so yeah we can argue okay
we want to be able to prune the deleted
elements in the end they don't bring
this that much value to us the the
question is when so we can say that okay
the requirement probably should be that
all the clients has to observe that
deleted element otherwise you
might be resurrected so imagine that the
client was offline we just pruned from a
server
it goes back online it sees that server
doesn't have that value tries to reach
back server doesn't know that that
element was removed it that is back not
really good so we started thinking okay
how can we solve that
well first we thought okay maybe we can
introduce some sort of client awareness
so each user has a set of devices
associated with that with that account
we can say ok once we have the
registration of these clients and once
we magically have be able to determine
the last synchronization time of the
client we can say ok if they're all the
clients has synchronized as observed
that delete the favorite we can prune it
it has some problems though the the
first thing is that well the tracking
the last synchronization time is pretty
tricky it proved to be tricky and the
second thing is that yeah it's it's
depending on the on the time basically
and we know what what happens for the
time right so the the the the next thing
we started looking at was the
introducing some sort of time to leave
for for Tom stones so time to leave yeah
just a period of time after which the
deleted that the tom stone can be
removed safely the trick with that is
that all clients and the server has to
apply the same time to live rule and
again it depends of course on the timing
so there can be periods of time of some
sort of divergences and of course you
have to manage properly these TTL rules
the next thing we we were tackling on
was optimizing optimizing the bandwidth
it's really important for our platform
as Nami set so the classical way to to
work with the the our CDT kind of data
structures is that sending all the
states that's why actually they are
called state-based Sur duties so we
wanted to optimize that we wanted to say
only def on any updates so in the
example I show in the slides actually
the client has a set of elements server
also has a set of elements one to be has
been modified that's why
has this funky double-quote client
modifies also on in the local state to
elements and it sends it actually to the
server it can send only updated ones
because well see is not changed its I
think it's intuitive before in the
initial implementation the server would
actually do what so it will merge the
values and then it will respond to the
client
now rest api with the full merge set
which is not pretty effective if you
have for example really big set with
lots of tombstones for example and such
the one thing that we need to do to
notice here is that server responds with
the b which was on the server before so
actually the update for b from the
client has lost so we introduced this
thing called scope thief so in the case
of scope thief actually server responds
with some values only in the case that
these values actually though were the
vinny winning ones and server assumes
that the client hasn't seen them so if
all updates from the client have one it
will be the empty set in the response
but client doesn't really care it just
received something from a server it
merges to a local state the response
from a server that's it so let's talk
about the time yeah there is problem
with time well there is no such thing as
reliable time right and that's kind of a
problem especially if you if you if you
have time stamps as the additional
metadata for conflict Rizzoli so I like
this quote actually from Janos bionaire
in one of his presentation he was
arguing that actually tracking the time
when we tracked the time we are not
interested in the time itself what we
really need to do at least and what we
really need in the distributed systems
is the ordering of the events so we need
to understand that what happened after
what some sort of like happens before
relationship in a sec so in that case
yet the most important thing is
causality and ordering so we argue that
actually time can be just good enough
but what does it mean so let's let's
look at two cases of ordering one is
ordering within a scene
note sounds pretty simple right it's a
there is no distributed states just a
single note well it still can be tricky
so for example I guess most of you know
that if you're using a GVM API system
that current Milly's it's not monotonic
there is no guarantee that if you call
consecutively twice the system current
Millis the second value will be
guarantee ly higher than the first one
which is might be kind of tricky
you're even updating locally or your
your state of the same favorite so for
us what is important we use time stamp
is a logical clock and we need to have a
guarantee that it grows monotonically so
we use on the client for example these
+1 strategy so what client does when it
puts an update for the for the for the
element in the hour set so it needs to
retrace the time stamp beat like a local
provider of the time stamp so it can be
can be coming from a server depending on
the on the situation if it's possible to
fetch it from a server or not but when
it needs to guarantee that at least it
won't be lower than the time stamp which
is already in the set that's why in the
worst case we do this +1 which sounds a
bit why yeah but actually yeah we just
need to guarantee that this this this
operation will win locally on a single
node so things come things become even
worse when we talk about ordering
updates from different nodes that is
really a tricky topic so of course we
were kind of lucky some of our devices
are P&amp;amp;D so they have this GPS GPS clock
and if GPS clock is available then you
have a pretty precise timing the problem
is is that it's not always available so
in the worst case if we don't have this
kind of so so if we don't have GPS quote
clock at least we prefer to use the
server time over the client time it's
it's more say it's more stable if we
don't have even that one well ok at
least we fall back to this plus one
strategy to preserve the updates on the
local nodes
and here comes the edge case of course
if you have multiple clients modifying
the same element in the replicated set
and they don't have a reliable time by
somehow you might have edge cases it's
it's depending on the business
requirements that it accepts that or not
probably for financial transactions not
really so let's talk about another
problem so we already seen that picture
merge everywhere
awesome yeah we just have to use the
same function everywhere
so one merge to rule them all what's the
problem well the problem is that these
merge has to behave the same way so
given the same input it has to produce
the same results what if not well
divergence may lead to endless
synchronization loops which is pretty
bad for the client right of course it
won't it won't corrupt the data on the
server but the client won't be usable
the particular client because it will be
always merging producing the same with
the different values and then pushing it
back to the server and back and forth
back and forth we have some mechanism to
to actually protect us from the clients
the the the the robe of clients like
rate limiting etc but still it might be
an issue okay so so what what's the
point actually what we want to show we
want to show that well sometimes the
Accademia might be not that scary I know
that's now we're at lambda days most of
you actually like have a pretty decent
academic background I'm pretty sure but
still like for our mirror pragmatic
programmers yeah sometimes when we
started looking for example at the CR DT
so we'll open the Wikipedia right and
then you read that what is your duty
it's a it's a bounded semi lattice with
join operation okay what does it mean
and then there lots of formulas and etc
so you have to spend some time on
deciphering that stuff but the point is
that it's it's worth it sometimes and
some of these solutions are pretty neat
and it proved in our case be much better
than some sort of homegrown intuitively
some homegrown
algorithm that might not work in all the
cases of course there are still
limitations as we showed and you have to
understand the real usage of your system
and constantly monitor and see if it
still fits your requirements or not and
improving if it's needed so speaking
about the code so we published the two
small repositories with the samples that
we showed for different CDT sets
including the our set the code is pretty
small actually there are set
implementation in Scala is like 80 lines
of code well it's not because it's skull
only it's it's just because it's quite
simple and there is also a Java Java
Java 8 based implementation if you
interested in so here's our homework for
curious minds so if you're interested in
some additional information on the topic
so the first talk actually was the one
that inspired us to try out C or D T by
Noah well I really recommend that talk
also Chris Michael John formerly from
Barcia he maintains a really really nice
reading list about CEO duties
the third one is a paper from the
original authors of CDT that coins that
term CDT and strong eventual consistency
and these are two links a bit more from
the semi practical side so the last also
worked from work by my crease Michael
John is a language based on Erlang on
top of Erlang that has here DTS as the
sort of first-class citizens it's really
really interesting stuff going on there
and also the swarms yes this is like a
sort of a framework that you makes this
makes use of EITS
for synchronization and in in that link
actually there is an example how that
you can build the offline radio web
application okay yeah thank you very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>