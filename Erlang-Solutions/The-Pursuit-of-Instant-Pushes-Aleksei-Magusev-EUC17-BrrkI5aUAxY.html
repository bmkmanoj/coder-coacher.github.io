<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Pursuit of Instant Pushes - Aleksei Magusev - EUC17 | Coder Coacher - Coaching Coders</title><meta content="The Pursuit of Instant Pushes - Aleksei Magusev - EUC17 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Pursuit of Instant Pushes - Aleksei Magusev - EUC17</b></h2><h5 class="post__date">2017-07-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BrrkI5aUAxY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay thank you everyone for coming to my
talk and I hope you enjoyed it so this
will be talked about push notification
systems and the components components of
the system actually not many systems but
what we had before and what we have
right now my name is Alex I'm aggressive
I'm working for for the football company
previously previous name on our SKU code
like football ethics you may know and my
handle on internet is Lexmark but before
we go in my main goal besides building
push notification systems is of course
take over a league here and then make
m/l style syntax but I fail horribly as
you see but at least I can put style in
Alex here and this link actual style
guides that we follow trying to follow
right now and also you may know me by
this wonderful warning I guess all the
whistle developers know how wonderful it
is and especially when it comes from
dependencies but yes it's part of our
life
it's alright you can blame me yes that's
alright
sometimes I'm adding features to Alex
here this is some that I like the most
but what I will talk about this is about
push system in further football
application for mobile devices and this
screenshots show what this speech
actually looks like for end-user so you
can subscribe for push notification
events like my start goal all life
events that may happen in game and then
you receive this notification and when
you open you have this rich format which
show you line up for recently played gay
this Saturday probably you who like
football nowadays and this football
saying football I mean not American TV
show but football that TV show in Europe
some facts about this system which is
important to understand why we needed
new system that it has several platforms
we do billion notifications more than
this in the months and many million
users subscribe to events and also we
have issue because many million stories
in database but what makes this need for
new push notification system inaugural
only because all these push
notifications are very time-sensitive
who wants the goal notification one
minute after a goal in real life I guess
nobody because it's just junk it's
unnecessary from high perspective view
of a system basic matific push
notification system divided by two parts
you and this is basically divided also
by time you manage storage of
subscriptions in one moment when people
subscribe and subscribe from push
notifications and you manage or actually
push notifications when some event
happens and you you use storage as a
heart of this system and before going
forward how this subscription looks like
this over simplified version but two
shows what this store you have device
talking it's needed to identify who will
receive this notification and also you
have subject and this part important
because actually notifications can
overlap as you see all these
notifications have same token same
language all projects is the same except
subject we already know by using
this format that someone from Sweden who
speaks English wants to receive
notification for a team and tournament
but this one issue is this storage Inc
with this record that they overlap in a
matter that if this team plays in a
tournament and much happen so you will
receive two notifications which should
not be we must not to allow this why you
need two notifications very much and we
need somehow to resolve this overlaps
that's why this house steps when we send
notifications looks like it's just this
meta fire on a right side it receives
much event then we fetch all available
notifications for this event and this is
important that we need to receive and
fetch from database all possible events
because then only then when we have
everything on hands we can filter out
duplicate and push this forward of
course build translated messages this is
another step as you saw we have language
because people like their own language
to see on notifications easy to
understand like this is the feature but
you have an issue when you do this that
way this is very straightforward way
when you fetch everything together get
duplicate on a client site or worker
site and this is started to be an issue
for us if you store millions of
thousands thousands of millions
subscriptions and you fetch even two
million subscriptions it can take me
minutes to fetch these subscribers and
basically you stuck in this step you
don't even start thinking anticipations
to the user you wait minute just to get
what tokens want this notification and
this has several issues just all as I
said it's a
working you not receiving notification
at all while we fetching these
subscriptions and we have normalized
data and this is why it's law and
everything sequential after we fetched
the duplicated everything it still goes
step by step with translation with all
in enchantments of message the trivial
send and another issues was that you
can't really scale such system because
it was fun elliptical design and even if
you add one more it won't happen because
it lives inside one component and this
means that time came to rewrite and this
tractor is basically there right when
you see that you have so many efforts to
add new features probably it's time yeah
it took quite a long time for us because
if you imagine like one and a half year
for a new system it's a lot even if
someone will tell me like I worked on
something one and a half year like I
know it's two one yeah but this is what
it actually because for reasons and this
reasons we had only two person team yeah
you have two thousand you can't expect
do this faster and these two person
still did a lot of stuff in other
systems and components of our back-end
and of course we did a really good
storage research and prototyping how not
to end up in this system similar
situation in next few years and extra
problems we have no metrics at this
stage we had no matrix and this means
how you can improve something that you
can't measure that's why we also build a
system for matrix collection and at the
same time we migrated to Amazon Web
Services
and skillet took some time this same
representation but with some really
important events that happened during
this live right yeah and speaking about
storage researching system prototyping
it took quite a long time because we
wanted from the first issue with our old
system because users was quite angry
typical users and competitors was quite
happy so we should build something that
don't let us be in the same situation
and next years and we spend a lot of
time and this code that I try to keep
always in my mind when I thinking about
something big that you probably need to
spend more time on try out and our chase
is Cassandra and this was a bit of
surprise for me because it just I didn't
expect anything like what will be the
best but Cassandra fits wonderfully
because of these properties and all this
product is actually in use in our system
for example replication in together with
- no Bell consistency it's really really
important we enforce really strong
consistency when we write data when user
subscribe because it's important but
when we read data during push we can say
if any replicas return data it's alright
at least we deliver two really big
percentage of people and another really
important properties like streaming of
results that we fetch and data
compression one of the important really
probably key properties of Cassandra
that made us to choose it it was that
data when you write on Cassandra it
studied immutably and sequentially on a
disk basically when you write
for one partition K this is in this
example its topic subject everything
starts to be added on a disk and when
you eat millions of subscriptions in
very ideal situation to be just one disk
sick in reality of course it's not it
will be 40 maybe still better when you
read millions from relational database
and this is how we can store our
subscriptions from previous slides in a
cassandra level it means that this topic
subject it's a raw ok it means that all
data in this row will be stored
sequentially on a disk but also each
entry in this row has its own key and
this is will be topic will be device
token basically we store all subscribers
for one desired event in one long row on
a disk
it still has issue but because of you
see you can subscribe to the team and
Turk and tournament that's alright
because we resolve this in parallel with
these systems that manage these
subscriptions when person subscribed to
one of these we splice this equal this
place and when we understand that this
is actually one event and this happens
before pushing this push passing is
responsible for doing splicing it
basically understands when in this match
this user subscribe to these two kind of
topics we understand it's only one and
this happens before match and then push
boy doesn't know anything about any
topic except much it only fetches much
subscribers and it looks similar to
previous but works differently for
example this
what makes it so beautiful and
performant overall around run time
system there are not that many words I
can say is how beautiful it is I know
this is you can do the creation system
you can do reliable software it's just
incredibly wonderful it's my religion I
guess but yeah you know these properties
of a long runtime system you have live
debugging you can trace production
systems very good introspection all this
goes to the first point but of course
from new system we can stream our
subscriptions it means that when we have
already spliced subscriptions in our
database you can read this slice by
slice from a Cassandra and then we start
from probably not zero but just second
push these subscriptions to these
notifications to users and using a leak
here or Erland we can do this in
parallel or concurrently if we do this
building payload something you despise
this everything can go in parallel and
push gate start to be usable as you see
this push gate it's completely payload
agnostic it says this token should
receive this binary message and deliver
and this is all what it does and we can
reuse this in any other application and
of course more about money-wise
prodigious like we have less resources
to allocate like we need previously it
was many like a dozen of servers is 24
cores physical machines now we have
maybe eight core five or so that's you
it's more for redundancy than for
performance because there is no need for
such performance it's you quite good and
we focus on
other optimizations this is an example
how you can achieve this with Cassandra
and Sam's a driver you basically start
receiving my signal not messages chunks
of 5,000 subscribers from database and
then you can start a sync processing of
this and this is oversimplified but
still close to reality think how we
handle this right now
but it still has issues because even if
you can do everything in parallel very
fast but you can go faster than its
serial part so if you need to do an
optimize this sequential code and
profile to find where it actually slow
and we learn this through the many try
outs and other stuff how to optimize
share code we we learned that usual diet
coke and this is wonderful feature of DD
connection library that it pushes socket
on a color level and then you don't need
to copy all the binary stuff to parse
later you parse and already have this on
your color level and this is removes
pressure and memory allocation also
batch operations this was interesting
this car is it Cassandra has different
style of batch operations I will tell
this in details on the next day and
another interesting optimizations is
when you decode binary you in ideal case
you should maintain single match context
and use i/o lists and this last bullet
point was interesting that never do
paralyzation blindly because if you say
that 100 concurrent processes works
better than 15 it's not true especially
it depends
of course it depends what kind of
processes you run and we found that you
should monitor your run queue it means
how many processes the current moment
ready to be run on a course of your CPU
but they don't have slice of CPU so
basically you have high level of
concurrency but you waste waking time
this is single budge single partition by
separation this is what helps optimize
Cassandra writing in Cassandra each
iteration goes atomically but it's it
needs synchronization across replicas
and all this communication because when
you enforce consistency but if you use
unlocked batch and one important
property of it if you write one
partition K in this K in this case it's
serious it will be considered as only
one single right in Cassandra and
Cassandra will communicate
synchronization of this right on
replicas only once and this gives
noticeable optimization and this is real
graphs what we saw after we applied this
batching so now we have splicing that
even faster and we don't miss a moment
when someone probably cannot receive
notification who subscribed just a
couple of seconds before go happens or
something like that and the binary merge
context in optimization it's less known
but still very powerful and interesting
optimization there are few good points
that show how it was applied in real
projects and in simplified way it's when
you match binary you continue with rest
of the binary but you should enforce
some some
think how you do this you always should
pass the rest of the binary the first
argument for example and this guide
first line describes what you do and
also there is a compiler flag that says
what was optimized or where you have a
chance for optimization now its results
time what what our actually outcome
after all this what we went through in
reality it it works really nice because
previously it was 45 seconds and this is
only 45 seconds when you actually
receive all tokens and you start
duplicating them when you start actually
pushing and 40 seconds all our
competitors laughs on it but if you do
this if you finish pushing of push
notifications after 15 seconds and this
is actually the time when we already
know we have no more job to do Apple
knows about everything and replied okay
I got you're reckless
this is 16 seconds and this is nice
optimization I think this is what we he
recently like you have two and a half
million in 22 seconds and yes this is
what it works right now but you don't
think that this is still boot enough
because we target 2 million in 10
seconds or 1 million in 5 seconds it's
still doable I believe because I know
some places where we do on purpose
blocking code where it could be not
blocking but then there is a trade-off
because then we lose how how we can
measure this because when you're
blocking you can clearly see see that
this works in this amount of time but if
it's a think it was this product
but we will find what we can optimize
for example risk you can optimize single
single context much in context in HTTP
to parcel everything looks good but you
know absolutely correct systems like
unicorns and saying that I mean not that
they colorful or mighty I mean that they
live in our imagination and yeah we saw
this in practice you should always be
prepared for bad things you should
understand what's wrong and will be
wrong in your system and prepare for
disaster for example if you use likely
using distributed queue distributed
queue by design provides at most once
guarantee or at least once
there is no exactly - you should choose
and we choose at least once but then you
should consider how you to do with
duplicates and either this idempotent
handling where you don't care
apply this 15 times and still all right
or the duplication manually on a level
of worker another interesting thing we
found that the orderic it's always
happening in distributed systems you can
trust events orders that you see on a
level of any component of your city
delete can come before actual create of
a subscription so and how you handle
delete of subscriptions that not yet in
database but thankfully cassandra treats
all beliefs as absurds it's actually
insert that says this was delete and the
risk small trade of cassandra keeps your
delete for period of time because before
it garbage collects it and
this is few days days so if you don't
stop your system for a few days between
wrong order message it's alright and
this is some limitation you should
always know and understand and monotonic
time this is the way how we resolved all
our issues with rice because Cassandra
here this time and if create you come
after delete but it has lower timestamp
you just discard it because it's not
what it's currently in Cassandra level
thank you that was it
very quickest and efficient talk we have
plenty time for questions so can you
elaborate a little on what kind of
hardware you used for the actual pushing
so the limiting factor in the system
what kind of hardware pushing you mean
in the current system or or previous in
the current system so you're saying two
million in 20 seconds
like how many or how much power machine
wise I'm putting into that so I exclude
database because it's not power that
pushes but one push boy it's a single
machine we have two for redundancy
mostly and Q only one starts of
practicing this job and if it dies bad
luck for this notification but this push
boy it's eight core machine and we still
can't utilize all the run cues of this
machine and this is where I say that we
have many opportunities to optimize we
plant it made faster then when this pool
boy fetch though it's fetching in
streaming clay and fish infection at the
same time it's
to pushing this to push gate and we use
for poor gates - for Android and - for
iOS and - for Android it's four core and
for iOS it's eight core mostly because
HTTP - protocol quite question right now
with you as I said before has
optimization for parsing of H HVAC
format so it's I guess it's quite cheap
in comparison what you need to pay if
you use some paid service and give it
right it's don't provide any guarantees
it's low and this is the case nobody
won't even work with you even with some
azan we ask them maybe we can do this
but it has two problems just that we
still need to manage this deduplication
on our level and they only want to store
what they know and also another reason
they just don't want to do millions is
the small time slice hello oh I missed
the first two minutes so you may have
answered it already
but handing from the type of the subject
on topics of your push notification that
seems that a lot of the push
notifications are push only requiring no
engagement from the user yes okay so you
have not like in in some push
notification scenarios you want to have
you have maybe a campaign and you want
to re-engage the user after a certain
period of time or dependent this is not
something that you have and now we still
have this sub heating that does non
time-sensitive pushes for example
transfer use or we can we may ask
question of users like
would do you think about this much who
will be in or something like this and
it's not time sensitive and it goes on a
site it's not go through the same steps
like this if you use Cassandra and few
topics store it like this it's steamed
but we don't closely monitor this how
it's performant and everything but yeah
we have this and beauty of Cassandra
that in this pushes maybe we can higher
level of consistency when we read if you
want you probably not need it and we
don't do this but you can show - you do
- maybe concretize my question a little
more do you push on to Cassandra push
notifications that you want to push in
the future not immediately yes okay and
even if you worry maybe it will be
stable data
Cassandra has time to leave metadata you
can say this only needed for one week or
so and it's alright okay
there is a many background Java
processes that does a lot of interesting
stuff and they maintain this quite
nicely
all right can you elaborate on
monitoring you talk sure yes I wasn't
sure if I you have time to add this to
presentation plenty of time
yes yeah yeah so we build this from
scratch and we wasn't sure at the
beginning you always not sure what to do
and we didn't know what what to choose
and we started again with research and
revelation what we should choose this XO
meter and other tools but they quite say
V so we didn't like ideas and we didn't
use this we wanted something more like
study but not strategy because of format
and node.js it's a pain to brink on each
machine and we found these two good
solutions it's from it tells and in flux
data companies they provide universe of
tools and we used in flux because of one
requirement and this is interesting
what makes in flux unique that usually
when you store metric you store metric
under key and metric like number but in
in flux it's more each format you can
store field and this is what we do we
store time to send push notification and
extra metadata like much ID and then we
don't see overlap metrics because if you
don't throw this metadata it will be
aggregated and if two goes happen at the
same time you can distinguish you could
use tags but this is high cardinality
data and net time series data basis
after 1 million starts to be pain
horrible and slow and fumes resolve this
and yeah we use Alex here library small
libraries that sends metrics by UDP to
local Telegraph go listener and this go
listener using TCP sense to influx
storage and we use you can use replicas
if you want to store your metrics in
more redundant and safer way if it's
metrics of some important properties
such metrics you don't use any other
logging monitoring for metrics you use
mostly this and we plug in places where
we want we use F broth from our link
installation when we want to profile
small places like optimization of in
sequential code and for error reporting
we use roll bar nothing except this I
guess okay thank you I'm going to be
cheeky so I've got two questions and
firstly what other databases to do
evaluate and was there anyone coming
close to being as suitable as Cassandra
I was prepared for discussion yeah of
course I needed this because this
actually not that much I can say because
it was one a half year ago
everything changed like but yeah we try
the elastic search even if it's not
database of course then we need some
more like persistent storage but still
desaad any database that allow us to
fetch millions in any possible smaller
chunk of time then it's good for us then
we tried coach base when memcached
merged with coach DB is coach base I
guess but it was early stages when they
just about merged when they didn't have
even
and o ql language so it's completely
different right now but it was close but
mostly because if you use serious a lot
of memory you can put this into memory
but right now with Cassandra we don't
use any questions this comes from a disk
and it's and this as fast as you can
have network only for now and
elasticsearch coach base react it still
was different react
two years ago yeah this for it's right
because we had limited time and research
was decent we watched what data model
actually store it on a disk would allow
us all this cool yeah and we actually
tried actual databases not Mongo DB good
for my second question and I've noticed
over couple of the slides and I know
they mentioned it a couple of times as
well but out of all the parts that you
built
what parts and wrapping open sourced so
we we didn't open source part s of
components but we still open sourced
some tools that we use for example this
is Cassandra if you see this on a bottom
of the slide link on github it's
Cassandra driver which highly optimized
is binding single binary matching
context this streaming which we built on
top of the B connection to you to remove
unnecessary cutting everything that can
benefit reading we do this and our goal
to maintain this for next five years and
not saying forever and so you can start
using this you can contribute ask maybe
features so right now it's a complete
feature complete for us but we want to
be to make
get one all and then ask what you want
and we do this because we have high
interest is I started to like Cassandra
and all the Stockholm Syndrome yeah yeah
and another one it was message box so in
inside this system through the
components of the system for example
from push boy to push gate we use
message pack series Asian format we can
use just term to binary it's possible
but it's not that fast
noticeably fast but still message box
actually as fast as binary to term if
you parse because of single much context
with high personal spent like week just
reading assembly code of generated
message box to generate best heat em and
it's not on a slide but we build also
this library and open source for influx
reporting and it's doesn't care if you
report to local process or you can not
only use Telegraph but report directly
to influx DB very cool thank you thank
you any other questions yeah so thank
you for your talk I'm wondering why you
decided to write another Cassandra
driver because there are two as you
mentioned that we have tried them both
I've seen the problems with them but
what are your reasons for writing a new
one
yeah as you said there are issues I I
don't know if there are several drivers
i I know there is one Maria or something
and another it's equal we use sequel and
at the same time we was building Sandra
but we found a lot of problems with
seeker just oh all it was sometimes
some problems when Cassandra replies in
unexpected way for example when you have
timeout on it you have stuck trace from
the guts of the driver and this is not
the way we want to work this because
then we have try-catch everywhere and
this is not that wonderful another
reason it has a lot of unnecessary
coping a lot because processes past this
actual data from socket few times and as
I saw parsing not optimized for single
binary matching context and in reality
if you see this pull request in message
box single much context gave 40 percent
optimization and in Sandra it was 35 it
depends of course on the data you parse
but in our case for 5k subscriptions we
did from database before it was 70
milliseconds to parse because talking is
quite long garrison and now it's 40 and
if you do this from millions 5k in
millions you have many five case yeah we
have this had the same experience with
the error handling in CQ various if
you're just a comment we have used the
this Earl Cass which is using the data
stack C++ driver and it's hard to build
but one thing we're gaining from using
that is because it it is token aware so
it knows where the date that were the
master the data is so it really speeds
up a read so that is something that that
is good for a driver to have if you want
to have better reads or supposed to read
yeah this Drive will not utilize talking
aware policy of load balancing yet but
it was built bearing this in mind and
right now it used simple round-robin but
there is a place just we need just to
spend some time and implement this but
this is our goal we want to be as fast
as possible
squeezing impossible speed okay
great work
thank you in the other question alright
I think that's it thank you very much
thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>