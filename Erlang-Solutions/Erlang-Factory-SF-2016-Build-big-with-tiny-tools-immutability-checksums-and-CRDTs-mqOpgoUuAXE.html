<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory SF 2016 - Build big with tiny tools  immutability, checksums, and CRDTs | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory SF 2016 - Build big with tiny tools  immutability, checksums, and CRDTs - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang Factory SF 2016 - Build big with tiny tools  immutability, checksums, and CRDTs</b></h2><h5 class="post__date">2016-03-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/mqOpgoUuAXE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm Scott lasoo croce and with Basso
Japan and this this whole notion of
immutability and check songs and see our
DTS and and building some systems on top
so I've been with besho for five and a
half years I've been using her lying for
for quite a while I'm also the co-chair
of the ACM Erlang workshop that is part
of the ICF p the larger conference is
taking place in Nara Japan in September
this year and as a co-chair I strongly
encourage you to consider writing a
paper there are three different kinds of
papers and posters for for consideration
for the workshop and areas of her lying
elixir acha cloud Haskell and whatnot so
if you or someone you know is doing
something interesting for user user
experience reports or something a bit
more technical or research II feel free
to reach out to me via email or or by
Twitter so after that plug here's the
outline of what I hope to talk about a
very brief introduction to machi which
is the name of the product that is
embedding all of these primitives i'll
be talking a bit about a very short bit
about append only files versus right
once files because they're not exactly
the same immutability changes everything
Pat Helland early I don't know who said
it first but Pat Helland I guess is is a
little bit famous for saying that I'll
talk about chain replication and then
we'll make some music talking about an
allegory of how to manage chain
replication without
absent a system like react core which is
something that you might expect folks at
basho would use for for managing a
distributed system I'll talk about how
crd tease and check sums are used and
then development status of machi today
so it's a Japanese word means a village
or village or a town and this thing is
still under under under construction you
know they really sad that you know those
days are gone or we don't see that guy
but it's a distributed fault tolerant
right once blobstore with a slightly
different more file like API it can
operate in both strongly consistent and
eventually consistent mode at bass show
we have this great fondness for eventual
consistency stores where availability
comes first and eventually consistent
file it's like you know are you are you
nuts I mean people want consistency and
their file stores almost always and I
want to make a case that there are times
when it's not really necessary when
you're writing using a UNIX or Linux
system and you want to append only to a
file the colonel is responsible for
doing the ordering if you if you specify
the append option so we're talking about
sort of file API we're not talking about
the structure of the file system
underneath so nothing about sprite or or
ZFS where there's a conceptually there's
a append only log that is the basis for
something that looks very mutable from
the file system later from the from the
POSIX programmers point of view instead
something more like I dupa HDFS in
Hadoop the Google file system or Windows
Azure storage although the windows is
your case is more blob file store than
than anything else so file stores versus
blob stores I'm not sure if there's a
great example a great definition for for
the two I think of it as files if we
were used to thinking in unix
and if they are named and ordered
collections of bites and you can have
random access to any bite at any offset
blobstore behavior is a bit different in
that the client doesn't specify the name
or where you're going to sort that name
where you're going to store something
the the server instead gives you a nap
ache string some kind of name some kind
of opaque blob and you have to use that
same blog thingy not to be confused with
the blob you stored but this opaque
thing usually a string to fetch the data
back and Windows Azure storage does this
is a Twitter blobstore the google
blow-up store and other things so append
only files versus right once files
append only usually means that the
rights if they arrive in time are then
have a corresponding order by offset
inside the file for right once files if
you could assign a bite or white range
page of data and say this is your space
to write in and you could write in it
whenever the heck you want and so the
rights can happen in in any order so
that's what I mean by a write-once flat
system right ones file pardoning
relaying users you know no immutability
we know that's going to crash that's
very good the pad Helland from
salesforce com had this very informal
paper informally retin-a informal style
insider 2015 i recommend reading it
immutability changes everything which is
a great pun or you know oxymoron or what
you know whatever you want to think
about it if we wanted to model a
write-once register in Erlang say we
have this this right once register
record it's got a couple of elements
there's a boolean that says whether or
not the value is set and then a value is
either undefined or it's some value
application specific type and we
intentionally decide we're going to
crash if we try to try to set
the register that is already set so
that's why we have the guard here for
false we don't have a correspondent
clause for for true and then when we get
we have the the will return undefined or
an okay rapper tuple for the for the
value so why write once files because
time is hard and distributed systems
time of sucks even more and you know
even on the the human scale as we heard
yesterday from from Fred that time is
hard so will shift the problem to to
dealing with space instead where the
service will again assign the the opaque
name or handle and in watches case it's
semi-opaque it's possible we'll give you
a library function you could parse you
can parse parts of it and you'll get a
file name assigned and a byte offset for
for your right and then whenever the
system gets around to actually using
that space if it ever gets around to
using that space it can it can be
processed in any time order so part of
the API it's a little simplified here
but the client can specify a prefix
string is kind of a hint like I want to
use this as a as a stringy kind of
organization method you know the trunk
that you want to store the blob at you
own store the checks on the checksum
comes from the client we want and and
check some check something in a client
and as we'll see in the read chunk the
well we'll get to the reach hunk in a
second but if if the operation succeeds
you're giving the full file name the
prefix is a part but the server gave you
the full file name and it will also give
you the byte offset of where that where
the first bite of the chunk started or
will give you an error tuple that
doesn't fit on the slide for reading a
chunk you give the full file name offset
and a size and if that part of the file
has been written because these are all
right once registers at the plate level
then you'll get the chunk
and you get the checksum along with it
and if you read at an offset that is not
the original offset used for the right
the server behind the scenes will
calculate a new checksum verified based
on the offset in size that the client is
asking for here the read and and then
I'll verify it on the server side and
then send that check some back to you so
you can on the client side verify it
again if you wish and you should we know
in 2016 that hardware does evil things
to you so you should be checking these
checks ohms so unlike the quorum
replication style that a technique that
riac kb uses for storage i have elected
to use chain replication before managing
the replicas of the files inside of the
machi store not so many people are
necessarily familiar with chain
replication neil conway it said that you
know most a lot of practitioners have
never really heard it before but most
academics have i gave a talk at recon
last november 2015 if you go to this URL
and the slides will be available shortly
and i'll tweet about the slides also the
navigation is a difficult look for my
name and there's a pointer to the slides
in the video i talk a lot more about the
details of chain replication and humming
consensus that i can fit in time today
there are a bunch of really great papers
about chain replication that are quite
approachable I feel I recommend them
there are several research projects and
also commercial products that are using
chain replication today including machi
and here it is in one slide it's a
variation of primary secondary
replication but there's a strict order
in which updates happen whereas in
vanilla primary secondary there's
there's no defined order but this
ordering gives us some nice properties
client here at the top sends a write
request to the first element in the
chain we call it the head the head if it
were in a sort of a transactional
context it could make a commit or abort
decision and then
everyone down the line will just sort of
observe the the will observe the results
of the of the commit decision made by
the head but we're not using that in
this context but it's mentioned in the
original papers if the right request in
ma cheese case the stuff that we're
writing is the the filename and the
offset is unwritten it's writing
successfully then we'll send it down to
the middle and middle the middle if
there are more middles to the tail in
the right response will go back directly
to the client for using distributed
Erlang this this kind of triangular
style message passing it's very easy to
do another reason for for liking or line
for the reeds if we want sequential
consistency read we read from the tail
if we want laning risible we're gonna
have to check all of them ma cheese case
is a little bit easier in that these the
values are immutable so the the main
reason for doing a linearized will read
would be doing for doing a read repair
operation if if there was a partial if
you encountered a partial right where
the head was was written but a crash
happened in the middle the middle was
unwritten then you can do a read repair
and fix things but if you want a dirty
read you can read from the middle or the
or the middle server or the head server
if you want and then mark callahan had a
great way of kind of summarizing that
right to the front reach for the back
it's the mullet of replication so why do
you want to use this I argue there are
four good reasons it's arguably cheap in
that you require fewer replicas to
survive a number of failures for quorum
replication you need a minimum of 2 F
plus 1 chain replication only requires
f+ 1 it's easy easy for some quotes of
easy i've wrote a paper for the Erlang
workshop a while while ago that talked
about experience with a previous project
called have our EDD which also use chain
replication and talks about how I
I it wasn't quite as easy as the papers
made it out to point it to wasn't as
easy as the academic papers had said but
it's it's it's quite doable or lying i
think makes the job much easier i'm
really glad i didn't have to do it in
chocolate or see come along for coming
along for free is this anti entropy
effect that with quorum style
replication if a server dies or more
than one server dies Evan forbid you
don't have a good idea of what you don't
have a way of predicting what pieces of
data are unavailable that are gone that
that if those servers never return is
going to be lost forever with chain
replication you definitely know and that
is if there is a surviving chain member
in the in the chain then the answer is
you haven't lost any data yet and any
any missing data that you observe is
going to be as a result of a partial
right and therefore the system has made
no commitment that that data was was was
fully written in the first place the
fourth reason is kittens so that's cat
button why is managing chain replication
a problem if you script the chain order
if you if you do updates in a different
order then you violate your consistency
guarantees that's bad if you want your
system to be strongly consistent and the
state of the art is not ideal you can
have a single Oracle that can make these
management decisions and that's a single
point of failure so we want to have some
replicas and then you need to coordinate
the replicas so if you rub some
zookeeper on it then you've now changed
the availability of your entire system
at your system your systems availability
falls or descends to the availability of
your systems manager so you're not going
to use zookeeper or Etsy d or any of the
any of the distributed consensus
protocols to manage react kv for example
isn't it as a eventually consistent data
store we don't want to do the same thing
for machi
when it's running in a eventual
consistency mode react core because of
the power of two that is sort of built
into one of the fundamental assumptions
of react core was one of a few reasons
why react or wasn't suitable so now we
need to come up with an alternative way
in in an eventually consistent
environment for managing this stuff and
I got this strange inspiration from the
ITF the ITF at a number of meetings for
the working groups if the the chair
wants to hold a vote voting by paper
takes a long time if you just want to
have sort of a quick a quick poll of the
room raising hands is to political
because then you can see your competitor
over there is voting for a motion that
you think really sucks so they asked
people to hum and you listen to the
volume of the room to get a sense of
whether the people in the room are for
or against so what if we instead of
using the volume of the humming we're
hearing that we use the pitch instead
and we're going to get a little musical
then and once upon a time we have
distributed music composers and we want
to compose some music so everyone
follows strict orders strict rules for
composition so chord progression rhythm
instrumentation all of that stuff
everybody is going to be following the
same rules and these composers are going
to make individual decisions about what
kind of what the next measure of music
is going to be and we need rough
consensus on that we don't want people
writing different stuff into their
manuscripts everybody is working in the
same room and can hear everybody but
sometimes they're not working in the
same room sometimes one or more will go
down to a rehearsal room or they go off
to the coffee shop and they might come
back later they might come back a year
later or they may have left and will
never come back when we have to deal
with that also so for the composer's
workflow all of the
number all the measures in the music are
will be numbered and we're writing music
from beginning to end you know we're not
going to be writing the final coda first
we're going to do this one measure at a
time if we have blank measures in the
manuscripts you know composing is kind
of a messy business so blank and
incomplete measures will be removed by
the publisher we don't have to worry
about that this music is going to be
ranked for beauty and lyricism so we're
not going to be mixing happy birthday
with michael jackson &amp;amp; Herb Alpert and
the Tijuana brass that would be bad so
to get very concrete let's use just
plain chant Gregorian plainsong so it's
monophonic we don't have to worry about
bad chords it has very strict voice
leading rules so it kind of limits the
degrees of what a composer can do from
one measure to the next and as vocal
only we don't have to worry about pesky
musical instruments or percussion or
anything like that um oh and this
byzantine chant has nothing to do with
the byzantine generals problem just just
just saying so these composers they're
all acting independently they can hear
other composers that are in the same
room but they can't hear anyone these
these rooms are soundproofed or too far
away to hear and each composer has got a
private manuscript that they copy the
consensus results that there that
they're hearing in the room and they use
indelible ink so they can't change their
they're what they write afterwards like
no editing will also ignore little
anachronism you know things like music
measures didn't exist in the seventh you
know 6 7th century so here's how we're
going to compose a measure music we're
going to check to see who's in the room
and we'll also consult what was written
earlier because we want something that's
very very melodic and lyrical and we're
going to consult our planes plainchant
rules and then we're going to choose the
next note for a measure and we're going
to hum it and we'll listen to everybody
else humming and if everyone hums the
same pitch then that's great we we have
achieved rough consensus will write it
in our private manuscript we're done
if there is no unison then we have a
disagreement problem and the answer is
we ignore this measure number and we'll
go to annex will choose another measure
number a larger measure number and we go
back to the beginning and we'll do it
again so this is the bit where it said
earlier that if if measures are blank in
our manuscripts that the publisher will
ignore it and that's okay I mean this is
this is great you know there's probably
going to be unison fairly often again
the rules are pretty strict there's not
a whole lot of options that people could
choose but if there is disagreement or
an interruption someone could enter or
leave the room someone could go to sleep
take a nap I mean you know go comatose
in all of those cases the response is to
write a new measure of music for for all
of those things if someone has gone to
sleep in this in the same room and they
try to reuse an old measure number again
because our manuscripts are using
indelible ink if a measure has already
been written while they can't write in
they can't write in that measure music
and then we'll all scold them and tell
them how do you need to use a new new
measure number so you end up maybe with
maybe with music like this measures 22
to 26 perhaps and that's really cool so
now we'll refine the allegory a little
bit and what if nobody can hear you know
like Ludwig von Beethoven is is one of
our composers so we'll use two
manuscripts and the private manuscript
the one I mentioned here lower on the
lower part it's the same as allegory
that I just mentioned anyone can read
from this manuscript but only the owner
can write to it that was the original
rules we're going to introduce a new
manuscript it's the public manuscript
and we're going to write music in this
manuscript instead of humming so we're
going to use our eyes to listen quote
unquote anyone can read and write to
this manuscript so this one is
fundamentally different than the
original private this helps us deal with
slow composers or ones that have taken a
nap
but they're in the same room we can
actually access their their manuscript
then the next refinement is then you
know what if what if these are computed
computers instead of composers and you
know Swedish shelves or something I feel
like my eyes are blinded here you know
when i'm working on distributed systems
but how did that happen i can't i don't
have good visibility in in what's going
on so we'll try to make things a little
bit clearer so we'll consider these
measure numbers of music to be an epic
number and an epic is is a logical time
it's a it's a counter that should go
upward monotonically increasing where
the chain metadata is stable the chain
mounted a valid data includes things
like the membership who does the
administrator administrator say should
be eligible to run yeah in this in the
small cluster what is the chain order
and some other pieces of metadata and
instead of paper manuscripts and
indelible ink we're going to use a key
value store of right once registers from
now on i'll call this the projection
store and the projection store is a key
it's a 2-tuple it's the epic number and
then the an atom for the public or
private type of manuscript and the value
is a data structure and it's called the
projection and this projection stores
all of the chain metadata the chain
order and all that good stuff that we're
trying to safeguard the computers are
going to write to all of the public
projection stores to hum and if then
someone after writing then both the
writer and everyone else will do a read
and for a particular epic number of the
largest epic number that you eat that is
is readable if you see the same
projection from all the different copies
all the different projection stores and
each participant has their own
projection stored if you get the same
value this is equivalent to hearing a
unison pitch and at that point you have
to make a decision is this a safe
transition from what the
the configuration I was using before or
I am currently using pardon me to go
into this new projection is it safe is
it a good idea if the answer is yes then
I will write it to my public or pardon
me I will write it to my private
projection store which is writable only
by me and after I write that I then
start using it and that this is my new
configuration this is my new my new
thing going forward this sounds really
crazy but it actually works so four
different modes of operation the basic
difference is the minimum number of
participants to be able to to propose or
to write a projection into the store we
need a minimum number of participants
that is at least the corner majority
size in strong consistency land to
prevent split brain syndrome for
eventual consistency we can go down to a
chain of one and we could just have you
know just like in react we can have one
one node that is just sort of off by its
lonesome and clients can still talk to
it and still get service to the best of
that one clients ability and humming
consensus will allow us to do the same
thing so and i'll have a to try to
convince you why this why this isn't
totally nuts but when a partition
happens or a crash doesn't really matter
when it's restarted humming consensus is
sufficient to allow merging and repair
operations and file resyncing or anti
entropy whatever you want to call it
afterwards the the machi files again the
right ones registers and the the server
assignments the file names change each
time the epic number changes and so what
we end up with is an informal crdt like
always commutative associative
idempotent set of operations we can
always merge the files together and not
have any conflicts and that's what we're
looking for distributed systems really
ought to have a whiteboard so a photo
from a whiteboard hi in Tokyo epic 10 we
had a chain where the head was was a
the tale of C and this is this is
written in the public projection stores
so everybody's humming and we're humming
in agreement so it for the sake of
argument author a had written or server
a had written all of these records but
it was fast it was the quickest so it
was able to write the same record in all
three everybody is reading or pardon me
is it does the read their hearing
unanimous and so okay everybody uses
this uses this chain of length 3 then
and that's what happens during epic 10
and a is is separated from B and C B and
C have decided that a appears to have
failed we don't know for sure but we
can't talk to it so we'll assume it's
down and for the sake of argument server
be wins the race for the right ones
register at epic 11 and says I'm going
to propose a new chain configuration of
B and C where p is the head and this is
safe to to go from the chain of ABC down
to B and C according to our invariance
so should I use this it's safe it
appears to be a good idea because I
really do think a is down so i'll start
using it and see will say Oh epic 11 is
already written am I here in unison yes
I'm hearing unison swell i'll use that
to a if we're in strong consistency mode
can only talk to itself it's in a
minority and so it says it takes itself
out of service and says I can't do
anything and writes a projection saying
there's no service available and as long
as the network split exists it's fine no
one no one notices something different
no one no individual participant is
hearing discord and when the net split
is finally fixed now now we notice that
there's disagreement and the answer here
is okay fine we need to propose
something else and again the winner
whoever that happens to be at epic 12
manages to say well the change would be
being see like the original over here
and then a goes into a special repairing
mode at the tail of the chain and again
everyone reads from these public
projections and says yep that sounds
good
they write it to their private store and
start using that projection and it works
so in summary this projection store is
is itself a write-once register if you
hear unison music meaning that you're
reading identical values from the public
from the public store then you have to
consider the change if you like the
change you accept it you write it in
your private store and you start using
it if you don't like to change if it's
unsafe or you think no I I can still
talk to that server I think that's a bad
idea then you just propose a new change
in a new epoch and so you always have
the option of rejecting what someone
else is written and the answer whenever
network partition heels that's the same
case as if there was a race at the
beginning for writing conflicting values
in the public store we treat it the same
the treated the same way i will switch
to watching and see our duties there's
been a lot of talk about crd T's and the
basic rules are associated commutative
and community associativity an item
poems so I'll kind of skip over that I
already mentioned the informal use in
that these unique filename and offset
assignments create crdt like always
mirja Buhl's which is a nice property
but it's not formally coded in a library
like react dt which we use for use case
number two so we use the react DT
library using the map and a last right
win register and this is used for
spamming or broadcasting periodic
observations of who a particular server
believes is down I'm having
communication problems with so the key
is the observers name like a B or C in
the previous example and then the map
value is a list of servers believed to
be down so in that in the previews case
here during epic during epic 10 or epic
11 oops
ah which there is sorry so so B and C
we'll just we'll start spamming out this
crdt that's that both of them will say
I'm having problems talking to a and a
well it ends up spamming to itself but
the logic is the same that I'm having
problems talking to B and C so as gossip
happens and the CR DTS are always merged
merged together and if the resulting if
the result after the merge is different
then I'll spam that out again to help
propagate information and eventually
we'll find out interesting things like
is the network partition is the network
partition symmetric or asymmetric and
we'll build a directional graph of where
we believe the failures are and is the
is the partition apparently a one-way
thing or a two-way thing and based on
that the will remove the worst-affected
servers from any new chain that is that
is proposed in in a later time this is
called the fitness the fitness service
we also use checksums as a anti entropy
thing so like I mentioned in this day
and age we really should be aware of
mangled corrupted data so the client
specifies the checksum here we use the
checksum for several purposes one is for
verifying that the data is is is not
corrupted at the initial writing time
we're use it for kind of a parity scrub
like a rate of rays do for checking
checking for the sanity of data at an
individual replica layer and we also use
it for building a Merkel Merkel tree for
for faster a file comparison when a
server comes back online or is added for
the first time hopefully you know a bit
about Merkel tree and how its put
together the the good thing is that once
you have this Merkel tree and you can
very quickly make comparisons by walking
down the tree where you find differences
or equality
and you can sort through differences
quite quickly in you know new modern
high density servers the bad thing is
that you have to read all of the
original data in the first place to make
the tree and modern high density servers
this day in age it still takes a while
to perform on the i/o so instead of
using the original data block for the
leaf nodes will use a concatenation of
the checksums in our check some database
and use that as a proxy for the original
data and so instead of having to read
all the original data we have to read
all of the checksums but at least the
checksums are much smaller and Mark
Allen I'm not sure if he's in the room
but I know he's here yep there is he's
here in the hallway and he's been
writing all that code and I'm going to
skip over this he confessed her him
after the talk about how that goes so
this is a work in progress it's not
finished yet this is actually taken from
an apartment construction site near my
house they're apologizing for the mud in
the street and the noise during
construction today the humming consensus
it's fully implemented it's this is all
in Erlang by the way with the exception
of leveldb which is used for the the
checksum checksum status and the the
right once register state enforcement
but everything else is in pure rolling
it works well in a network partition
simulator I'll talk about that partition
simulator in a little bit property based
testing is so invaluable with a with or
without quick check I have very strong
opinions about the loveliness of quick
check but the the properties that I'll
talk about for a chain replication for
example and then using this to putting
them in the simulator and then codifying
the enforcement of the environments
invariance has found numerous bugs that
the real world would probably find
having said that we haven't actually run
in the real real world yet so a lot most
of the testing is I'll simulator based
it's a patchy version too
public license and it's available at
github under the bash Oh organization
and again it's called machi here is this
may be a little small for four people in
the back I'll zoom into this this is a
supervision tree from the from the appt
mon app that's built into the OTP
distribution and for a particular a
particular server internally called f1
we create a supervisor and a number of
worker processes underneath it so if we
zoom in a little bit let's see if we'll
ignore the lifecycle manager but the
point are not working oh I'm putting my
thumb over the ok right so we have a
fitness server I mention that a little
bit this is the thing that is is using
the crd T's and the up down or I believe
it's up I believe it's down status and
then it's responsible for a very very
dumb spam to all of the other members in
the chain and if it works great and if
it doesn't we don't care it's a sign
that very thing we didn't need to use
plum tree or anything like that because
these chains are going to be pretty
small a really long chain is like seven
or nine items and so spam the crdt and
those numbers there that size it it
doesn't really matter quite so much we
have the projection store this is the
right one store that I talked about for
the projections and humming consensus I
uses this there are processes that are
used for managing metadata inside of the
store and the interface to leveldb and
the checksum database internally we have
a file named manager for managing file
names space on disk there's the chain
manager this is the thing that's
actually executing humming consensus
that song humming consensus algorithm is
running inside of this guy this is the
actual server that's doing the file i/o
on itself and then down below I cut it
off our ranch processes for TSP
listeners and and workers terminating
protocol buffers is that is the API that
we use here a quick check is a
mistress but you know projective
production environments are also quite
harsh and I you know it's great to find
it's great to find errors in a simulator
before before customers find them and at
the moment we still have a luxury of not
having customers so anybody in the room
who hasn't done property based testing
of any kind of sort at all I mean you've
probably heard about it but have you
actually not used it yet that's a fair
number of people so I mean just as a
really basic outline any library or
function or app that you want to test
have some kind of invariance so figure
out what those are even choose one as a
starting point and this is your property
and then your next task I feel is to
write code to make that invariant and
check that enforcement make it
executable write a function that can
figure out whether the the invariant has
been violated and now you're flexible
you can plug it in to anything you want
you're your own testing framework unit
common test proper and quick check if
you want to use a tool that has a lot of
other infrastructure or other kind of
nice things to help out with your
testing but you don't have to use proper
a quick check to get started and you can
check these invariants at runtime I mean
you know Erlang programmers we sort of
use this all the time and you know other
beam languages for pattern matching that
if we are expecting only one results
then the heck with it we're just going
to pattern match on that one result in
anything else is an error and it crashes
that's great maybe you have to annotate
your code with some additional
assertions or probes that would catch
the failure at runtime maybe you have to
catch the the invariant failure after
the fact like you write everything to an
event log and you can use just an append
only file and write records to that and
post process them later however you want
to do that if you make the invariants
executable you make your job a lot
easier released it has in
every project that I worked on in
property based testing since i I've
learned about it from from the cubic
folks here's some of the invariants for
chain replication at least how it's done
machi style so machi uses chain
replication implementation that is more
like Corfu which is something that came
out of Microsoft Research a few years
ago and is different from the original
chain replication algorithm algorithms
that have been described in the
literature that I very briefly skipped
by earlier on the talk so we have machi
maintains this notion of servers that
are perfectly in sync or servers that
are out of sync or under some kind of
repair or anti entropy and we want to
keep these things separate because if we
don't keep them separate in strong
consistency mode we will violate
consistency constraints again for
consistency constraints we never Rio to
the instinct portion of the chain that's
just that's bad I can never happen a
server can go from nsync to down or to
repairing at any time that is safe
because things often repairing are not
used for a lot of operations if we go if
we want to move a server from repairing
from the repairing list to the instinct
list we had to have had a repair effort
the anti entropy for copying files
either in one direction or both
directions depending on the mode that
repair effort had to have started it had
to have run to completion it was okay
then it's all right to move from
repairing to in sync and when we do that
we have to do it only at the end of the
list again for for consistency sake have
a network simulator is also written in
Erlang and it has a very simple model we
have this list of two tuples a name from
from and to and if if a a and b is the
from and to then we can simulate a true
one way network partition so a message
is sent from A to B will fail but B to a
can work and if you do this using
Damocles within the Erlang world for
twiddling with the network interface to
block
packets sent in one direction we're
using TCP sooner or later you're going
to have the TCP window closed and you're
affecting messaging in both directions
where where as in in the the simulator
environment we can have true one-way
network partitions for arbitrarily long
periods of time or logical time and so
that's very different and exposes new
really cool failure scenarios when when
there's partial connectivity partial
visibility to read or write into the
projection stores and we can change this
list we can make it constant or we can
just ran the randomly randomly let it
change I think of it as shaking the snow
globe we really want to randomize things
that little snowflakes kind of follow
their place as the chain manager States
sort of change and are flying like snow
inside of the snow globe then we'll fix
the partition list and we'll wait for
stability do we do we have all of the
servers unanimous in which chain they
belong to and there may be more than one
chain again if we're in eventually
consistent mode the worst case everybody
is partitioned from everybody else so
everyone forms chains of one but they
remain stable and we fail if it's never
stable and then at the end of the run
will check in activity log to make
certain that all of those invariants
that I just talked about for chain
replication have not been violated and
the the that's the end of the sort of
the overview these things my cat thanks
you the the the Swedish elves thanks
thank you for your time the all of the
code is available like I said at github
for more information about the overall
design details about the chain manager
and humming consensus and the the
unfinished work for partitioning or
sharding horizontal scalability whatever
you want to call it is in the doc
directory so you can check out the repo
or look at it they're online and at that
point there's time for questions if
there are any thanks the question is do
the clients checked or so let's do this
it'll be faster I'll go and we'll get a
diagram the question was do do the
clients connect to all of the servers
when they want to do something up there
is and the answer is in the original
chain replication you're typically
dealing with the head and the tail but
machi is doing things in a corfu style
which actually means that the client all
of the chain replication logic is in the
client so the the servers are simpler as
a result because they're not actually
communicating directly to each other the
pattern is instead client sends to the
to the head if it gets an okay back then
it sends this the the write operation to
the middle and then back and then to the
tail and then back so there's more
network manages in that way for doing a
right but the client then has to connect
to all three it is a client and reads
from the projection stores so it so
humming consensus running independently
in each one of these bricks is kind of
servers pardon me this is a diagram that
taken from the hit a bar ADV so that's
why it's using the word brick sorry so
the public and private projection stores
as I had mentioned are being used by
humming consensus but they're also
accessible to the clients so the clients
have to start off with a hint of who you
know what are the possible participants
and then can bootstrap contact each of
the projections or stores on each of
those and then if one of them is
available get some more information
that's probably more up to date and then
continually refresh as it learns what
the crew what the current state of
the chain is now because it's hint on
disk maybe hours or days old but it can
eventually find the current configure
the current projection in the same way
that humming consensus discovers it with
with the server participants yeah
so the question was why why make this
choice of the the client driven logic
and why not choose the the the fewer
number of messages cases is that a fair
way to summarize and the answer is the
the original corfu research and a a
proof of concept that I've written for
besho internally and is also in the in
the repo by the way if you want to go
look at it there's a prototypes
directory you can look at the nasty code
written in a week and that corfu
implementation followed the original
microsoft research papers and they they
also had a research agenda kind of off
on the side they wanted to have the
servers really simple like put it in an
ASIC simple and so the complex logic of
the chain replication and dealing with
failures they wanted in the the smarter
client and I followed that pattern
sooner or later for efficiency reasons
we may move things to the original
pattern that you that communication
pattern that you see here but thats
future work one more question anyone Oh
same parent company I guess the the
original use case for this is to replace
the blobstore that react kb is currently
the function that react kv is currently
providing for the the s2 product the s3
protocol compatible server for big
objects what s3 does is it breaks it
breaks up the data into one megabyte
chunks and then writes those one
megabyte key value pairs in to react kv
and ma cheese eventual consistency mode
was to replace that blobstore
thank you very much for your time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>