<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Gary Rennie - The Road to 2 Million Websocket Connections in Phoenix (ElixirConfEU 2016) | Coder Coacher - Coaching Coders</title><meta content="Gary Rennie - The Road to 2 Million Websocket Connections in Phoenix (ElixirConfEU 2016) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Gary Rennie - The Road to 2 Million Websocket Connections in Phoenix (ElixirConfEU 2016)</b></h2><h5 class="post__date">2016-05-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/c6JcVwbOGXc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so there's kind of a spoiler in the
title here did apply there does scale
but will maybe get to that so the top
two called the root is 2 million
WebSocket connections with Phoenix it's
based on a blog post as anyone read the
blog post hanger show hands I read the
blog post in the last week
ok good ever mistake oh wait that one go
you go so yeah it so it's called the
road to 2 million WebSocket connections
with Phoenix I originally called it
benchmarking Phoenix channels but I was
told that doesn't get the sort of
impression on Hacker News that we wanted
so it sits nicely between between that
and 2 million reasons why you need
Phoenix in your life so this is me and
this is how I choose to represent myself
on the internet that's like a Jenga
tower in my mouth
I'm gathered on the Internet except from
Twitter ROS late to the party
so I'm the Goslar and I work at a
company called voice layer doing
push-to-talk stuff so format the talk
I'm gonna start with why we're doing
this they were going to how we're doing
this which there's like 5 slides of XML
but it does end ahem
yeah that guy loves it and then we'll go
into the results and then talk about you
know what's coming up in the future
maybe probably so why do this if you've
seen any elixir or Phoenix presentation
you've probably seen this
what's that blog post mentioned which is
1 million MS so 2011 and it's kind of a
talk about how in 2011 what's after able
to get 1 million connections on a single
machine and then they were able to
subsequently at 2 million lately and
that's great and it kind of as a
testament to how the Erlang VM works but
it doesn't really say much for Phoenix I
mean it shows it's technically possible
but but there was no real you know proof
of it there was plenty for HTTP so
there's like the Phoenix show down Chris
wrote a blog post and there's also the
frame mark benchmarks that come out you
should totally ignore because they've
done it wrong and the results are bad
but there was nothing for like
persisting connections so so we needed
some measurements for it really so what
makes benchmarking WebSockets different
wondering just like fire up Apache bench
and
do your thing cuz Apache men don't use
that use work baby using work it's
different so it's a different protocol
using the websocket protocol so the
connections have to stay open right you
can't just like if you use work then you
can open a connection and then it'll
close and give you the response and
amount of bytes or transmitted and then
you can go again
you got to hold on to the connections
and that kind of results in an increased
memory usage and then there's this weird
like hard connection so there's like a
port limit of about 64 over 65 K and
then 1,000 reserved
so it's 64,000 and you you can increase
this so if you imagine got like the
client IP and the client poor and then
server IP in a server port and that use
needs to be unique so that's why it's 64
K on one machine to get the same client
IP in port but on the server we don't
have the same problem because all the
incoming connections are different and
yeah so you can fix that but if you add
additional virtual IP addresses but in
this particular set of test we didn't
have that option so we didn't so memory
usage was our main other one so the
application would benchmarking or we did
benchmark rather was the chat
application that Chris put together that
showed you how chat worked and there's a
link there if you want to go and look at
it it's quite old now but we upgrade it
recently there was there was one
difference so I don't if you can read
that okay but basically there's a timer
send after that we ping a timer send
interval rather they would ping every
five seconds so this is like when you're
on the chat application you'll see a
ping coming from the server every so
often to let you know the you know her
message come in and to let you know
you're still active and whenever anyone
joins so this is like an after join that
gets handled it sends a message to
everyone to say that you know here I've
joined the channel but we don't want
that in this case because if you imagine
you can arrival rate like 1000 you've
got 10,000 existing connected users and
Kishore a great slide yesterday which
had like all these messages coming in
and then all the messages coming out and
I'm not as good as animations Keith but
I'm like an artist impression of what
that may look like if we left it on
and it's something like this so yeah so
we turn that off and here's what it
looks like if you don't if you're
looking like the Webber case you just
get this constant stream of incoming
users that all say foo so yeah so turn
that off so the way we benchmark this is
we used an application called Sun which
is an open source multi-protocol
distributed load testing tool which I
took that straight from the website so
that's a good description it's written
in our Erlang so that's good if you want
to look in the code you can see how it
works and a start development 2001 under
the name idx tsunami since version 1.5
actually supports a WebSockets so that's
good because that's what we needed and
that's one of the limitations with some
other tools it supports multiple
machines as well so you don't just have
like this one machine you can use to go
off and do requests so you go there and
it also produces nice charts and it's
got a web dashboard that you can use
which is really helpful you can look at
it once you're running the test and see
what's going on so here we get to the
XML so it's configured using XML you
have simply one XML file and it's got
several sections game can't quite me
back in so bear yeah so you've got
clients you got servers you got load you
got sessions and one of the machines
will have this config and we call that
the controller and all the other
machines that you use to run the tests
our clients and the controller powers
them so the clients configuration you've
got these little blocks with a client a
host name so in sum everything is
configured with the host name so that's
why you see like Phoenix 1 Phoenix 2 and
it can go up all the way to wherever you
want depending on how many clients
you've got you can allocate a weight as
well so in this example the middle one
has got a weight of 2 and the other two
have got a weight of 1 so that means
that 50% of the time machine twos gonna
get hit and the other 25% for each other
machine you've got max users as well and
you want to keep that below
Machin limit being the port limit or the
memory otherwise bad things happen and
it'll probably crash so make sure you
keep that below so if you got 60 K keep
it 60 K you'll find that after you first
run if it's too high because they'll
crash so you can also have multiple
virtual IP addresses I mentioned earlier
you can just specify them inside the
client block but we we didn't do in this
case because Rackspace set up the
machine for us and we didn't have access
to like the network adapters to add
additional ones and you can also do this
flag to use controller VM make sure you
set that to false otherwise you're
sharing a VM with the controller and you
don't do that especially if you
distribute across multiple machines so
the server is also configured in a
similar way you can specify the server
block and you've got again a host so it
uses hosts files for that or you can put
an IP address here as well actually if
you've just got the IP address of it at
the port and the type so there are
different types you can use you can use
TCP HTTP web socket and so on we
actually use TCP and I was making these
slides as like why why do we use TCP if
WebSockets available and I was getting
these insane results when I tested a
WebSocket was getting like eight million
concurrence and it wasn't saying it
wasn't holding onto the connections so
so we use TCP but I don't really
investigate why that was the case yet
and again you can do waiting to you as
well so the first machines go wait for
and seconds get away of one so be like
an 80/20 split load is how you get users
and connections opened to your server so
it's phased and you can say you know I
want one phase of like 10,000 users on
another phase or another 5,000 join so
you can simulate different levels of
load they have a duration as well so
phase will last a certain period of time
the total duration can be like just
under 50 days so I have no idea why you
want to run this for 50 days but that's
the upper cap and you can loop over them
as well if you want to run like the ten
thousand twice and the five thousand one
once you can certainly do that as well
and the way we did this is we just set
the duration really high and manually
terminated so when it got to like it
would even off and we don't you know we
just kill it then because we had no idea
of what we could really handle so we
didn't know what to set this to and the
arrival rate is just the number of
incoming connections per time period so
you'll see here I've set a thousand per
second so that's how that works and then
you got sessions which is probably the
most interesting one so sessions are how
the connections interact with the
application so in our example we open a
connection on the WebSocket then we send
a join message to join the lobby and
then we just wait forever or for a long
period of time again for the same reason
because we have no idea what we're what
numbers we're really looking for so we
just say so we open the connection and
we just waited until we killed it you
can use our line turns in here as well
so you can do this like we are double
percentage syntax and then call a
function so we use here TS user server
get unique ID and if you remember the
example I showed earlier you see that
each user had a number when it's
scrolling through and those numbers were
generated using this piece of code so it
shows like a sequential identifier and
you have different request types as well
so these are the WebSocket ones but if
you do an HTTP then you'd say that HTTP
and so on and you just specify the path
you can also different probabilities per
session so this is pretty interesting
where you can see like this has got a
hundred percent probability of being
executed but you can also say like or 20
percent my users I want to both join and
then send a message as well so we didn't
do it in this case again but this is how
you could simulate like a chat room
where some of your users are sending
messages but most of them are just set
their way it has this like web interface
so you can see here this is a Status
page which is called show you like the
number of running users connected users
the request rate as well and what's
interesting about the request weight
rate is that you set it to say 1,000 but
because you're generating this load and
you're probably general generating from
different
you can't really regulate it so it's
like as close to a thousand as it can do
based on how it's been performing and
you get the number of active nodes and
the current phase as well so if you
built like if you're using five some
clients then the active nodes will be
five and then you get these as well
these are the charts that are generated
that you may have seen periodically we
don't actually show many of these the
only one I think we do shows the bottom
left which says network traffic but you
can look at all the different metrics
here that it gathers based on your
connections throughput it's quite
interesting one as well the one that
you'll see the most is the brag one so
there's two lines here there's the one
on the top and the one on the bottom
yeah the reason I reason have to specify
this is because I would love to go by
color and say there's a green line in
the blue line which is technically true
but they swap so the top one is always
the number of users that have been
generated and the bottom one is always a
number of connected so in this case when
they go up pretty evenly which is good
that's not always the case so when we so
that's all the XML done by the way
that's the gone there'll be no more of
that when we first went to run this this
is the command to use some data config
the config file and then start so when
really came here with one server which
we had like 15 gigs around four cores
and Rackspace kindly give us three of
these to play with so we used two of
them as clients and one server and if
you're struggling to imagine what that
looks like it probably looks like this
so so we're at this point we were pretty
high you know we're like okay let's do
this thing let's run let's see what we
can we can generally let's do some load
you know what what's that can get like
two million connections we can probably
get like loads maybe and then this
happened and so again as I mentioned the
line on the top is the number of users
have been generated and the line at the
bottom that's capped at 1,000 is like
the number of connected and that's not
good because 1000 is less than two
million
so so what's going on here like you know
really what this this sucks this we
should stop now
there's this number that you need to
specify it's called the you women and it
was alluded to earlier and there's a
number of open file descriptors right
and what you want to do with this number
is you want to say it to something
that's like super high that you're never
gonna reach and then that way when you
run it like it doesn't matter so we did
that and set it to two million and you
want to make sure this is set as well
every time you restart the server so
sometimes we would run a test and then
we good we should probably turn it off
and on again to clear the state and then
we run the test and we'd see that 1k
again and be you limit when you start
again and it takes a while to do these
things as well so it's quite frustrating
anyway we ran it after this and we got
this more pleasing result and it's not
not amazing but you'll see here what's
good is the windings go up pretty
uniformly and they like come up as one
and you'll see here the blue ones on top
for its previous it was a green one and
it gets up to like just under 30 K and
then there's this drop but the good
thing about this drop is that both lines
drop together and that means this sum
has dropped the connections and not our
server sometimes you'll see this split
and that means that we've dropped them
so we're like 30 K we're now that's fine
but it's not not the sort of level we
were expecting and at the time Chris
Josie and I were on skype and like 10
after 10 minutes feels like hey I got an
idea try this branch so you've done this
optimization and the commit message here
says only rely on X tables inside local
5 months ago Joe's igloo it's not five
months ago now it's five months when I
do it you see here what's interesting is
one change and there's like 14 in
surgeons and six and nine deletions and
so the there's being way more code
deleted than inserted and what this
commit did is before we were tracking
like a hash dict of the subscriptions
and we are an axe table for the topics
and we just ditched the hash nicked and
just like managed everything inside this
one at stable which is our long-term
storage
so we've now just got this one place for
everything stored and that's pretty good
it got us like twice the performance and
you'll see here when I was talking about
the split there's like a split
that of a pointer it's there and that's
when it starts like dropping connections
and it drops them in such a way that it
like drops it for a long time and then
for some reason it creeps back up so it
recovers but then there's again a
massive spike down where they're not
terminated so it's a good improvements
like a two times improvement but it's
not again not near the level we were
looking at and that's when this came in
so observer is a tool that ships with
OTP and you'll definitely have it and
you should definitely use it you can
open it with observe that star and
what's really good about it is you can
open it remotely so you don't need to
like do this on the machine you're
running on and the way we found this is
we had this server that was running the
Phoenix application and we would open a
node locally no doc connect to it and
then observe it up star locally and we
saw this and we've ordered it by message
queue size here and you'll see there's a
timer server and the message few sizes
is hide it never goes down to zero and
as more connections come in the number
keeps getting higher and higher and that
was was another bottleneck I guess that
we found
thanks to observer so you know you've
got this tool here that is really useful
for finding it so that in in game this
next optimization there's actually two
commits but I've squashed him to one for
convenience and it says remove unneeded
heartbeat since cargo handlers timeouts
but the first thing we did was we were
using primer that said after and
timeless and after maintains like a
central timer server for your process
the register and it's a really expensive
operation so if you need to do something
after a period of time you can either
use it in like your gem server you can
specify timer at the end or you can use
process that send after I actually don't
think there was any use case I know of
that you should use time or send after
for if anyone husband won and tell me
but then we found out after doing this
change that cowboy actually maintains a
heartbeat anyway so what we were doing
is every 30 seconds we're sending a
message to the client saying you're
still alive and it said yes I'm still
alive
and cowboy handle that for us anyway to
see here again five insurgents 38
deletions just delete code and things
get better so there's a lesson that you
should definitely add and it'll look
more like this so this is a cool char it
goes up to so some generates 120,000
users and then it goes down a bit but
you'll see again is this clear spit
split around the 40k mark we ran this
test for ages as well this was running
for like 12 minutes maybe and then so it
goes up and it's great but they're still
at some point like 40,000 a difference
between 40,000 between the number of
generator and a number of connected but
this was the most load we could generate
with our two machines and you'll see you
right at the end of the line here
there's like it just goes from a hundred
thousand to zero and if you want to
replicate this just kill the server when
you've got a hundred thousand connected
connections and it'll just do that and
it just kills them all immediately so we
need more machines like this Podrick
capped with what we can generate so at
this point
Rackspace telling the government us this
amazing machine at at 128 gigs of RAM
and 40 cores which is a lot and we had
these like the two three clients that
they'd already given us and then we set
up some of our own machines as well the
four gigs of RAM and four cores which we
found was about enough memory to handle
60,000 connections and as I mentioned
earlier because we couldn't do
networking with the machines we already
had with virtual interfaces we decided
to just set up a machine for each 60,000
connections so this is what H top looks
like on a machine with 40 cores
it's pretty cool so I think it's 20
cores with hyper-threading and it's
probably worth noting I actually set one
of these machines up myself and
hyper-threading is disabled by default
and you're going to hate stop and it
shows 20 and you get really disappointed
and it should be for Ace and you can
enable at Colonel Flagg so if you try
this yourself and you only get 20 that's
why and you can change that and again
you're probably struggling to visualize
it so
so this giant machine here is obviously
the big one anyway so we ran it with
this so if you imagine got these eight
machines 60,000 connections each we can
generate about 400,000 maybe just so
over so this is like a dolphin chart
it's shaped like a dolphin and then
you'll see that like 50,000 again
there's a split and at the peak here so
we get like 300 30,000 connected users
which is a big number but there's like a
hundred thousand dropped connections
which just is not good enough and we
were quite disappointing about like the
number of disconnects you know it's
great having a high number to tweet
about and to boast about but we didn't
really when we were tweeting about this
we weren't like here we got 300,000
connected and 100,000 it didn't connect
so yeah so we need to fix that and we
thought well what if we swap it over
right what if it's maybe a hardware
limit maybe we'll take the big machine
and we'll put that as the server and
then we'll use one of the clients and we
did that we thought right let's see what
the big machine can do this is like for
acorns and stuff and the way I'm - it's
probably gonna set up the disappointment
because it looked like this so
so on the Left we've got the Machine
we're running on and on the right we've
got like the big machine and they're
exactly the same there's like a 10k
difference and you're thinking well it's
like a ten times more powerful machine
so obviously we'd only do 10,000 more
connections and you know I'd love to end
here but there's more so so what was
causing this this to happen like this
was good in a way right because it's
disappointing but it also shows us that
it's not a hardware limit the problems
in the code so it can probably fixed and
indeed a can so this is a third
optimization and there's a couple things
are striking about this for me probably
one is waiting for you
but the commit message has changed PG 2x
from bag to duplicate bag to improve
performance relevant to same key five
months ago
Gabi Zuniga and the reason that's
interesting for me is because Gabi's
actually my colleague at voyeur he's a
CTO and I had no idea who was doing this
and I came in one morning and I got
opened up github issues and ourselves
pull requests from him so I was like hey
Gabi I didn't know you're doing this if
you said but you didn't but the more
interesting thing is that there's one
insertion one deletion so like it's
probably gonna be more interesting at
the next slide actually so show that so
this is the difference the one line of
code can make yeah it's kind of a big
deal so what you'll see in the right one
is like the two eyes just go up
uniformly up until like maybe the late
200 thousands and then there's like a
peak off but the other great thing here
is that eventually like the lines meet
so like there's maybe a handful of drop
connections maybe like tens of drop
connections but at this point again we'd
maxed out our our machine but I just
want to go over this optimization so you
can see what the thing was I've put the
diff here so that you can read it
so if you can't read in the back here
the difference is the word bag has been
replaced with the word duplicate bag um
so what does this do so you should know
your ends types because they're
important and you saw that from the last
slide so what's what's happening is with
a bag you whenever you insert an element
into the table it'll do a check to see
if the key already exists and if it does
then it will reject it I think maybe it
over writes it it does one of the two
things but the duplicates don't matter
in this case because each subscriber is
unique so what was happening is you're
inserting your element and as the it
grew and this is with like the
bottlenecks were earlier on as it grew
the number of elements it would have to
check to see if it's a duplicate would
increase and that's why it was capping
at like a 50k was where the problem
started if I just go back here like
that's when it started to split so
that's probably when it was starting to
hit the limit and it just got worse and
worse from there but each subscriber is
definitely unique
so duplicate bags find it but the the
main benefit from this beyond the the
bigger number is that the arrival rate
was we were able to increase that from a
thousand to ten thousand which you can
imagine dramatically reduces the amount
of time that the subsequent tests take
so we were capped on machines at this
point and just enough he's about
somewhere but his company life help now
actually set up like for a servers for
us which was pretty generous because it
allowed us to do more numbers so we ran
it with all this load like all these
machines that we had and you'll see that
this slide here it goes over 1 million
it goes to like 1.1 so that was this was
like the first part where like yes Wed
scale like 1 million and then we
remember that that's a 2011 thing so so
we were like you know five years behind
but you'll see here there's like a very
obvious problem at the 1.1 million mark
so it keeps going on to like one and a
half now
right but at this point so the last time
you remember the problem is 100,000 uses
didn't connect and this time we've got
like like half a million users not
connecting it's you know that's a lot of
dropped connections I mean being able to
get up to 1 million without any dropouts
is fantastic but you can you can
probably always do better so at this
point we were thinking well all the
low-hanging fruits gone right but we did
see that the first time the second time
and the third time so there's maybe
still low-hanging fruit you know
existing if you want to try and find it
but what would occasionally happen is so
you've got all these you know 40
machines or 45 machines all connected to
this one server and one of them would
crash and it's 60 thousand connections
would all drop at once so you get 60,000
down messages on the server which is
what causes climax on new connections
because still handling all these down
messages and the other issues like a
broadcast was taking five seconds to all
users and Justin sounded really
disappointed when he found that out he's
like yeah as five seconds is like like
three seconds too long so what we did we
paralyze the broadcast which fixed the
broadcast time but we still have the
issues with the timeouts when one of the
nodes would die and that kind of leads
us onto this optimization which says add
random local pool and Charlotte
subscription as such our subscribers
Chris McCord so Chris wrote this I think
it's maybe Justin's original idea and
interests implemented it
there's 73 insertions of 51 deletions
which so disappointment we actually to
add code in this case to improve it and
this is the first time we added code so
yeah so what we did in this case is we
instead of having like this one process
handling all the connections we have a
pool of servers and a pool of X tables
and then based on the page of the
subscriber you can use this function
Erlang P hash to to get a consistent
result back from shard slice so if we
had like 45 shards we can say the for
this page it's always going to go to
number three so that's the function that
we use there and you can configure this
with the pub sub pool size
and you want to set that to the number
of schedulers you don't need to do this
manually anymore because when I went to
do some additional tests for this I was
like complaining and Chris is like Chris
the results aren't as good as last time
he's like yeah what's your pool size set
to yeah I definitely remember to
configure that because it's set to one
so so that's not higher so you can said
like say defaults now to the number of
schedulers that the airline has
available I've been with this we're able
to get like one to two second broadcasts
which is much better and I'm just gonna
go over this commit in a little more
detail actually took these slides
straight from Chris's airline factory
keynote so if you recognize them that's
where they're from thanks Chris
so it's this is the old version so each
node has a pub local and etch table and
a PG two server our Gen server and the
connections communications are done via
the PG 2 and then locally it was just
the one and afterwards it looks like
this so you've got n number of local
servers and etch tables so you've got
much less going to a single process and
then PG to still be used for the
connections and stash I mentioned is
talk yesterday the about using an atom
for naming and that's what we do this
case this was the case you mentioned
about Phoenix pub/sub so we know that's
not gonna exceed the number of
schedulers unless you say to a
ridiculously high number which you
shouldn't and with this so this is Chris
showed this earlier this is the two
million one that's everyone likes to
tweet about and you'll see that the line
goes up it's a pretty wavy line you know
you'd expect if you set the arrival rate
to something uniform they would go up
linearly but it doesn't because it can
you've got like 40 45 machines to try
and you know get uniform connections
being coming from and you just can so
that's why it's like a really wavy line
and you'll see it seems to cap out at
exactly 2 million I am which I don't if
you remember why
well maybe go into that so yes that's
what it keeps generating users and we
actually I need
to confess that we actually never got to
two million we got to one nine nine nine
nine eight four but the good news is
here the the the sixteen probably aren't
dropped connections they're probably the
file descriptor is being used for other
stuff on the machine so so there's a
positive but the really interesting
thing here is we're not even memory
maxed we're using eighty-three Oh 128
gigs so there's probably a bit more that
could be done with this you see all the
cores are idle and they generally are
and I said message comes in and then
they'll spike up and then they'll come
back down again
so yeah so I'm just gonna go over the
ways you can optimize ahem so the first
way is like like say we're after like 10
minutes feels like hey use this branch
is better and you know that's one of the
ways so I guess not many of us can do
that that someone probably can
the second way if you seek all these
amazing tools that ship with with OTP
that you can use and they're available
and you should learn how to use them so
you can find these bottlenecks and I
would encourage you to do these sorts of
things on your own machines as well
because just cuz Phoenix can get 2
million it says absolutely nothing about
your actual like what you've built all
we know is that's what the the
frameworks capable of isolate the
bottlenecks as well so it's an
interesting one when I spoke to Gabby is
like Gabby how did you find the
duplicate bag thing and he said well I
just sort of had a theory on where the
bottleneck would be and I just ran it in
isolation I was like yeah I never
thought to do that I thought you'd have
to run like all the things at once and
do like these massive distributed tests
but you don't you can find things on
your like laptop just if you know where
to look
no you're at state talk datatypes so I
don't think I'm gonna be making the
duplicate bag issue again I think every
time I'm creating an X table now I'm
gonna really consider the the type them
using and use a pool if the processes
bottlenecked as well so like this is one
of the first things you should do if
you've got a single process that's
taking all this load you should probably
consider using a pool lots of libraries
ecto well DB connection for example do
the same same thing so this point we've
got like essentially a chat room with
too many
people I can't think when you'd ever
need a chat room with two moon people
but just for reference like 2 million
would be enough to host the population
of Phoenix in Arizona and a single chat
room so so it's a lot but I mean
practically you probably wouldn't have a
chat room but you may have some other
use case where you need all the machines
to be able to talk to each other but do
they do anything the answer is yes
so you'll see that the this is the
network traffic chart and you'll see all
these little spikes and that's where
like Chris and I were testing and it's
sending a little message to each other
like hello and you see this massive
spike at the end and that's when Josie
decides to give it a little test as well
and post the entire contents of a
Wikipedia article to two million people
I don't know which Wikipedia page he
chose to post but if I had to guess I
would probably say this one okay so if
you haven't worked out yet why the the
chart looks like this Chris Chris did
mention earlier that the configuration
was wrong and this was the the culprit
so when you set it to a number that you
think you're never gonna reach probably
double it because we thought you know
let's set the you limit to two million
that's that's a high number and it's
like if we so we didn't you know we had
all these machines and we got this
result but we couldn't do any more we
had to shut them down at some point you
know Justin's company was paying for
them all so we actually didn't get to
max out the machine which is unfortunate
but maybe at some point in the future we
will so some common inch issues you'll
probably run into if you want to run
these yourself everything requires a
hostname of some so and it needs to be
correct as well so when you're setting
this up set up your HTC host file with
all the IP addresses for all the clients
and the clients also need the controller
in the host file so make sure you do
that and these we correct for every
client as well it seems like a weird
thing to stay in a slide but you know
make sure it's correct the SSH keys need
to be set up as well so the controller
needs to be able to communicate with all
the clients and you do this via like
your authorized keys
so make sure that you can ssh to all the
clients from the controller and the um
it needs to be set so you limit give us
a lot of problems on the server but this
also needs to be set for both your
controller and all the clients and just
everywhere every machine you use just
make sure you set a new limit so yeah
and when you configure in phoenix as
well yeah so quite often and IRC people
come in and go hey phoenix is really
slow yeah it's not there to to big
things you need to do you need to use
the production environment and you need
to disable logging because if you don't
do either these things it's gonna gonna
go slow disabling logging is really
important if you don't then you just get
this giant stream of logs and the i/o
really slows down what the the server
can handle when it's incoming so yeah
that's like a six gig gift by the way
our six Meg if even to a six gig gif
imagine that that's insane yeah so one
of the easiest ways I've found to do
this at scale so you know if you if
you're doing this for like two or three
machines you can probably set them up
manually if you're doing this for 45
machines you can probably set up
manually but and we did but don't so
what you want to do is create like your
first server and install Erlang and Sun
on it and create an SSH key using like
SSH key gene or ever and add it to your
authorized keys and this way when you
image it all the clients will already
have the controllers SSH key available
and it'll be able to communicate set
your own hostname as well to something
like some controller set your you limit
and then you create an image and then
this way every new server that you spawn
from this image is already configured in
a way that will work straightaway with
the Sun controller so yeah that's that's
kind of what we did and how we did it so
I guess what's next one thing to know is
the benchmarking is really expensive in
terms of both time and server cost
because you imagine you've got all these
servers and you can only generate
connections so fast so you need to keep
them open for a long time so if there's
any like Y Combinator dropouts or
anything with like a hundred thousand
dollars of Amazon credits and they need
to spend them somehow then
we could probably do that so so this
test here was only for a single server
and when I say server as well we need to
clarify I mean like a physical machine
or a VM I don't mean like a gen server
or something so but what we'd like to do
is multi node as well so we know Phoenix
can handle multi-node but we don't
really know the performance impact that
you're gonna have if any from from multi
node solution something that more
simulates real life so we have the chat
room and we had two million all your
people and that would be like the worst
chatroom ever because nothing's
happening so it would be nice to have
additional like with the sessions and
you can set periodically on them so
probabilities on them it'd be nice to
have one that's actually sending
messages and we could measure and work
out what's happening with that
benchmarking more chat rooms on a single
server as well so this is a more
real-life use case where you've got like
you know lots of chat rooms each holding
some people so it'd be better to have
that I'd the IP aliasing one so it's
definitely possible to get more than
60,000 connections in one machine but we
didn't so I would like to you know
document how to do that so that people
can do that easily easily more easily
and also automate the test this is a big
one automate the test for each release
so for both WebSockets and HTTP so
sometimes people will raise an issue on
Phoenix and you know the core team would
be like okay the there's possibly a
performance aggression here but we don't
know because we don't run it like all
the time so we have to run these before
each release of different manually and
it'd be nice if there was a way we could
just write we're preparing for a release
now so let's let's run all the tests for
for WebSockets and HTTP and then we can
work out if there's any any regressions
and that's it
so thanks for listening
Oh No
so I actually forgot to mention that
there's two additional things
Phoenix presence is definitely one of
the things we want to check that it
hasn't had any impact on the performance
of existing Phoenix pub/sub stuff and
also if using the presence has any
impact on it and the other one that I
forgot to mention is like exo-m releases
so we want to make sure a lot of people
are gonna be using the xrm for their
Phoenix applications so we want to make
sure there's no performance impacts of
using releases for that so I mean that's
a good question we didn't because we'd
sort of the reason we didn't is because
the limits of the the older test was the
memory of the the connections that were
jet-like we've maxed out the memory of
the server and it's unlikely the using a
pool is going to reduce the memory for
the server so I think we were maybe
memory capped at that point but yeah we
may be sure them how much cash so the
the big server that was donate just by
Rackspace cost about $1,300 a month if
you were to run it I think luckily we
didn't have to pay for that one the the
smaller machines I think are probably
about $2 a day so depending on how long
you leave them running for so because we
span them up and shut them down over a
fairly short period of time it didn't
cost a huge amount but it's really
frustrating to have to you know start
again each time because you don't want
to keep all these servers open so okay
so this is a late entry this guy yeah
that'd be a great idea</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>