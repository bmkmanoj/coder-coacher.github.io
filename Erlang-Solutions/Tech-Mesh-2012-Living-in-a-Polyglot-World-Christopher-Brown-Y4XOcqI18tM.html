<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Tech Mesh 2012 - Living in a Polyglot World - Christopher Brown | Coder Coacher - Coaching Coders</title><meta content="Tech Mesh 2012 - Living in a Polyglot World - Christopher Brown - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Tech Mesh 2012 - Living in a Polyglot World - Christopher Brown</b></h2><h5 class="post__date">2013-08-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Y4XOcqI18tM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">fabulous thank you everybody hear me
okay good you I just leaned down and
pulled on the little cord from the
microphone i was afraid i broke the
whole thing so that's absolutely right
i'm going to talk about the the last
basically the last four years of our
experience from having written a fairly
large system in ruby and then deciding
which parts of it should and should not
be and i'm going to talk about the pros
and cons and then we'll probably
discover mistakes we made along the way
as well undoubtedly most of these things
you discover or actually after you make
a mistake right first very very quickly
so this is me I was one of the early
guys on amazon ec2 I actually staffed
the team for the first two years in Cape
Town South Africa so a fun bumpy road on
how many of you have used ec2 ok so
there's a whole series of things you can
blame me for after the talk because I it
happens every time after that I was that
guy did something remarkably like ec2
you on the inside of Microsoft and then
finally for the last nearly four years
now I've been working at Opscode I'm the
CTO there this was a salasa t how many
of you've used chef which is ops kids
product wow I in I wasn't sure what to
expect coming over to this conference
how many of you are rubyists ah even
better how many Erlang programmers that
ok there we go that hits the expectation
there's going to be a lot of fun then
all right so very quickly I'm going to
talk about what our product is to set
the context for how we made our
decisions and how we made our mistakes
talk about it both from you know who
uses it but then from an implementers
perspective again why it is we made
choices why we chose Ruby why we chose
Erlang and then how we ported our server
side from Ruby to Erlang and what we got
out of doing it by the way up we have a
very very large open source component to
what we do so the server part that I'm
talking about the port that we did from
Ruby to Erlang is basically just hitting
the shelves now we've had preview builds
for a while but it's all available on
github I can send out links to it we're
sending out
release candidates for the entire
package this week so you can go take a
look at exactly what I said first of all
so chef is for systems administrators or
four systems architects doing
deployments doing infrastructure
automation so you can think about it in
the same evolutionary family as CF
engine or puppet and to some extent
tools that have gone before like
bladelogic or ops where so everything
from you have a bit of an operating
system on your machine and you want to
go all the way up to deployed
applications deployed monitoring state
and asset tracking of those things on
the server so this is a great quote it's
like a little sis admin robot that's
exactly what it is it produces the same
actions repeatedly over and over again
you can ask it to work all night long
it's built up of a number of different
conceptual pieces there's a code
repository our mantra is infrastructure
as code so the notion is from a
development point of view you should be
able to treat all the things that define
your infrastructure as if they were also
code so you check in your source code
you also check in the description of
your infrastructure which is in fact
executable so you conversion it the same
way you can push it down the same
pipelines as you do everything else and
it's really a great way for developers
and systems administrators to reach a
common ground to talk about the same
thing so you often hear us wrapped up in
the entire DevOps discussion and DevOps
argument because of that we are actually
a bridge tool between we've got a
server-side component which is basically
a publishing platform you know you send
us these descriptions of your
infrastructure so that all of your
infrastructure can then fetch those
after the fact so we need to be fairly
scalable in that you publish something
once perhaps but you fetch it across
every server in your infrastructure and
multiple times so it could be thousands
of machines and it could be quite often
and then we've also got a client side
piece which is there actually two bits
of it there's the piece that executes on
every server under management and then
there's sort of an administrators
command-line tool and at the end of the
day they're both just consumers of the
server API and that's another thing that
we really we hammer on
over and over again we try to put very
little policy in the API itself there's
this separation everything can call the
api everything can get the same results
so our client that we write would be no
different than a client that you might
write in java or in pearl or in
something else because at the end of the
day you know we want as many folks
across the the development landscape to
be able to consume these tools we've got
a piece that we call data bags where
basically this is where you put unique
and descriptive data of your
infrastructure again being a publishing
platform that's another thing where you
know you might save it once and fetch it
many times or you it's hard for us to
tell what the symmetry is you may be
reading and writing both quite often so
it's an interesting use case we've got
recipes in cookbooks and I'll talk in
depth about exactly how those function
later and then rolls in run lists which
are ways to compose your infrastructure
where you can talk about them at a
slightly higher level okay so this is
this is a recipe and if you were here
for the previous talk there was a bit of
a discussion about when you should
create a domain-specific language and
what it actually does on the client side
we are very much about a domain-specific
language and we've got some fairly
serious reasons for doing it ah this is
a recipe recipes are lists of resources
and they're evaluated in order the in
order part matters and we can talk about
that later that's actually the big fight
in the convergent infrastructure and
infrastructure automation academic world
it's all about order and it's all about
convergence so these if you look at so
if i can make fancy tool work hey there
we go um each of these sections is
fairly self-descriptive um we talked
about this is basically being the Holy
Trinity you have packages what do you do
with packages you install them quite
often those packages that you've
installed our services see that down
here and services have actions you start
them you stop them you might ask them
for status of the other one here
templates or files you quite often have
configuration that travels along with
these and that configuration is
typically data driven so we make it very
easy for you to create a template that
you then just rendered
like values into so very powerful in
that you can write a recipe once you
parameterize that and you're going to
send it out to every one of the machines
that needs to execute it driven by the
data that's specific to that machine so
its usual thing you know do the work
once have everything else work for you
and this this is the the sort of
cornerstone to our dsl and I'll talk a
bit later about exactly why it's shaped
the way it is and and how we built it
this is a pretty small crowd we can be
interactive feel free to stop me and ask
questions or heckle yeah I figured that
the last the last talk in here got a
little contentious at the end I'd like
to spread contentious across the entire
talk we're on video after all it's not
like I'm escaping so resources resources
are those stanzas that you saw in the
recipe resources have types like I said
you know packages templates when you
look at resources the first thing you
see we want this to be easily consumed
by systems administrators who don't like
the notion of of learning yet again
another configuration language or
another programming language so our main
plan here is to not shove a bunch of new
concepts in your face domain-specific
languages should be about your domain
right so these have a type they have a
name so a particular service it could be
a patchy two or it could be Microsoft
sequel server you know the name should
be descriptive of what it does right as
parameters because as I said these
things are all data driven and then we
take actions to place the resource from
the current state that it's in to the
desired state and the desired state is
what's reflected in the recipe so here
we also attempt to model these things in
an item potent fashion we shouldn't take
an action twice if it's not necessary
and if we do take that action its result
in the same outcome so what you should
have is something that's very very
predictable right so in this first case
package apache2 the action is installed
and actually you could leave that out
the default is install right the second
part of this if you look at the the
template declaration here and sorry for
the wrapping it's actually a little
easier to read if it's not wrapped it's
exactly what you would expect well
what's the source of this
patchy to calm you know that's the thing
that Apache is going to need to run and
you know that you edit it right that for
sites enabled and all the other things
we happen to use er B which is basically
a ruby renderer so these things the
configuration files the templates are
written with parameterised little blocks
of ruby inside them so what we do is we
copy these out and then we basically run
Ruby over the top of it so fairly fairly
easy to see what we're doing but like
any other file on your file system it's
got an owner it's got a group it's got a
mode and what are we going to do with
this thing we're going to create it on
the file system if it doesn't exist we
also even though it's not shown here we
have item potency stanzas little things
that you can do to these resources to
say only if a particular condition
exists or not if a particular condition
exists so you can make these things very
item potent if you need to check
something about the system and say I'd
always take these actions unless I find
the system in a particular state you can
tell you can tell us that right there on
the resource make sense so far so I sort
of harped on you know what does it look
like from the consumer side why we would
do this for a systems administrator from
an implementer standpoint so we've got
two fairly different pieces we've got a
set of client-side tools which are most
often run from the command line there's
the client the execution agent that runs
on all the machines and like I said
there's also an administrative form of
that tool that some smaller number of
folks run either way nine times out of
ten if somebody is running something
against the chef server it's one of
those two tools that we've written so on
the reason I frame frame it this way is
I'll talk about the choices that we made
in implementing those tools radically
different from what we do on the server
the second part of it is we've got this
thing we for lack of better terms call a
convergence engine it's the piece that
actually execute these recipes it puts
all the resources together from all the
recipes you've specified puts them in a
particular order and D dupes them and
then execute all of them and tells you
about the out
because as you can imagine quite often
these actions fail for one reason or
another so you want to know exactly how
they're executing and you want to know
what the outcomes are and you want to be
able to report back so that convergence
engine is the thing that takes all your
input pieces of data and then actually
runs it across your infrastructure
that's all done from the client side
from the server side I'm sure you've
heard the litany a dozen times now we
are a mostly stateless restful Jason
speaking API when you you can
practically you can write that on the
back of the tin for almost every product
here these days right it's it just feels
like the right thing to do I mentioned
that we're a publishing platform in that
you write to us the things you want
executed and then you fetch them from
all of the clients so there's a little
asymmetry most often in the number of
times particular objects are written to
us rather than read there are other
types of objects where we know there's
almost one-to-one correspondence reading
and writing happen equally as often
which is a little weird I need to be
scalable we weave end this product out
in a number of flavors but one of them
we call hosted chef that's us running a
large scalable service on your behalf
and so you can imagine if our service is
the thing that configures your
infrastructure you've really hated if we
took down time right now it's not like
we're one hundred percent reliable
because nobody is but we take it fairly
seriously and that we don't we try not
to have scheduled maintenance windows we
try to do a number of changes live in
the background when we do the ploys even
going so far as doing very large data
migrations while the engine is running
and I'm going to talk about one of those
and then of course fault tolerant
because you can't say scalable without
saying fault tolerant or or I'd get
heckled again client design goals
radically different from the server so
we want it to be easy to create tools we
want you to be able to consume our API
there are there are some bumps along the
road we have an interesting off protocol
but other than that anything can make a
restful call Andrey Jason right we want
to make this open to multiple languages
i wrote a AP I rapper implementation for
testing in emacs
Lisp that I actually from the inside of
Emacs because i live in Emacs and if you
can write it in emacs lisp you can write
it in anything really easy to hack on
the like I said we've got a large open
source contingent it's fair to say that
most of the interesting client-side code
is actually written by others and
there's a huge I keep saying asymmetry
there's a huge asymmetry there the
client site very very active community
hundreds of developers 150 or so
corporations have signed our license
agreement to contribute lots of work
goes on on the client so it needs to be
easy to hack on these be easily
understood in a language that's
approachable by the masses on our server
side almost nobody hacks on it I think
we have one external committer right now
so very very different it changes the
choices that you're that you're both
constrained and allowed to make in the
implementation and then on the client
side nearly ubiquitous platform support
we want to be the thing that you use to
converge your infrastructure regardless
of whether or not you're on Linux or on
windows or Solaris we support really old
Solaris and we support you know windows
2008 r2 and the span between them is
really ugly right they don't look
anything alike the bedrock for that on
the client side is a modern Ruby if you
can get modern Ruby on the system
chances are good we can make the rest of
what we do actually work so there's a
choice and then finally the other thing
that made the last talk contentious
metaprogramming and dsl's I showed you
an example of what we do on the client
side we are very very much about that
dsl and about continuing that and most
likely introducing you know new new
dimensions to that dsl over time and our
choice of ruby made that really
straightforward so really quickly just
to poke the bear lots of languages to
consider on the client side we could
have written this in something else we
want folks to be able to consume our API
and other languages but there are pros
and cons right I could absolutely see as
a matter of fact there is one
implementation of the client in Java you
guys know Jay clouds there's a dup know
ah cool how many Java folks actually in
the room
okay so there's there's a correspondence
there that makes sense Jay clouds rapper
in Java for many of the cloudy api's
there's also a rapper and Jay clouds for
chef so it's probably second to our
implementation the most complete rapper
out there so we could have done
something on the JVM but there are a
number of reasons that's hard for us one
is up until recently there really wasn't
a great language for doing dsl easy meta
programming and good dsl support right
I'll talk a little bit more about that
could have done it in Perl actually
there was a bit of an implementation at
one point when you think about it pearl
is quite approachable it's attractive to
systems administrators and if you squint
at it right it's not so hard to fashion
a DSL that's consumable so actually
pearl was a you know a neck-and-neck
option at one point Adam Jacob one of
our co-founders is a real pearl bigot
and actually started out writing it in
Perl and then sort of realized that for
better for worse at that time the pearl
community was losing traction and the
Ruby community was gaining traction
especially amongst developers so and
then you know a series of other
possibilities this could be done in
something like ml where you get great
typing and some interesting syntax you
could do it in Haskell for basically the
same reasons I know I'm going to get
faulted for this but I tend to think
personally of Haskell as ml with futures
I like a lot of the same things about it
i I've done ml and I haven't done much
Haskell so that's my mental mapping
finally if I had my first choice it
would be done in a lisp and I know
that's that's the one that actually
starts the most fights so I bet most of
this i think that goals that dsl
translate your domain expertise to a
language of implementation right the
thing we don't want folks to do you can
imagine systems administrators walk up
to this they look at a recipe to go hey
it's a package and it says it installs
if i wrote that in java i would probably
have something that says new package
manager factory something or other and
then the guys would be asking well why
new what's the scope of the lifetime
what the hell is an object in its
lifetime anyway and you're off to the
races it would it would be kind of hard
up so that backs up the second point
what do you want to do you want to
reduce that sense
dick or that cognitive load on the
consumer you don't want them worrying
about the rest of the stuff that's there
so in the last talk there was some
discussion about whether or not
parenthesis in Lisp add to cognitive
load I I personally don't think so but I
get the notion there right that's if
that's your consideration if the folks
that are using the tool the first thing
they run into is a thing they can't
stare past you've kind of already lost
oh yes yeah the ubiquitous i'd i'd be
that guy if i were a little braver so
the problems in choice and this is an
interesting separation between us
actually in our nearest competitor
puppet do you create an internal DSL or
an external dsl I'm really familiar with
the differences ok so that the top-level
notion is internal dsl is actually the
syntax of the implementing language it's
just typically the languages that are
good for it allow you to permute it in
such a way that you don't stare at a lot
of syntax I mean we've talked about why
you know why why parenthesis at the end
of the day aren't really syntax and Lisp
but anyway external dsl's are ones where
you write a lecture and parser or
whatever in your implementing language
but the dsl language itself is something
completely different you at that point
control the entire space so that's the
problem right how much of the original
language do you carry along if it's an
internal dsl how much of the language do
you implement if it's an external dsl
and how easy is it to understand and to
teach what constructs are necessary so
I've heard people talk about some of
these external dsl's as well they're
fine for what they do until I run into a
thing they don't do and then they don't
do it you're just sort of done if you
leave out a looping construct or a
conditional construct in the domain
specific language you're kind of done
right how do you how do you move forward
so this this is my personal progression
I don't know how much of this makes
sense to you folks but I ran into sick
pea and it as some other people have
said it just sort of changed my world
the meta circular evaluator in what does
it chapter 4 chapter 6 that's the thing
that made it all work for me and turn
of why I would implement something in
scheme why I would implement you know a
language in a language which led me to
Lisp in small pieces which is nothing
but that over and over again and then I
realized I could do it on the cheap and
other people would understand it because
Ruby Ruby is sort of the love child of
small talk and Lisp then appealing to
pearl developers I think that's fair so
this is my take on parenthesis I you
know I enlist you just don't see him
after a while right it's like staring at
the matrix anybody who's worked in list
for a while the parenthesis just sort of
fall away so I think I talked about all
of this oh yeah the heritage of Lisp and
small talk and things like that the
flexibility of the syntax and that
decision of whether or not you inherit
types and structures if you're doing an
internal dsl and you know that you're
implementing language has things like
hash tables or whatever do you simply
cart those along into your dsl and allow
your users to directly use them do you
need to dumb down the construct or
change it somehow for us we decided that
you look at those resources you can't
tell those resources are Ruby for the
most part until you do something like
write one of the conditionals if you say
not if something well that thing you
want to check like most often it's uh
you check the existence of a file out on
the file system so what you have to
write is not if file colon colon exist ?
in the name of the file that looks like
Ruby and again you're sort of off to the
races at that point you need to learn at
least enough Ruby to recognize it and
the external dsl again in for a penny in
for a pound right you're responsible for
everything there are some great tools
out there that help you along but man I
don't know how many of you spent time in
lex and yak yeah um antler antlers a
fine to live did there's some yeah see
it's it's sort of funny everybody starts
with one and graduates to the other if
you're still doing it but again you're
then responsible for the whole thing I
just loved this quote because yeah
because it starts fights this was ola
beanie when he was sort of looking at
the same things realized the java is not
good enough language to implement
applications i'm not sure i'd agree with
that
for applications but I think it's
interesting that the JVM has sparked so
much development in recent years and
that the language is that we were
talking about at this conference are
ones on the JVM that radically differ in
their intent right I'm a big closure fan
why because I love Lisp and finally
somebody rejuvenated it and brought it
somewhere um just to knock on the point
for just a second um yeah did i do I
even need to say anything cuz this is
actually um this is a snippet from what
used to be Sun and one server
provisioning system this is a piece of
software that does something that's a
lot like what chef does and if you stare
at the XML pretty closely the constructs
look like our resources it's really kind
of crazy you've got you've got this
deployment component you've got the
install steps you've actually even got a
little shell thing that executes at the
bottom so you can get to what i showed
earlier package template service if you
start here and factor down so we
actually did a large project where we
took a bunch of n1 execution plans turn
them into chef resources so the mapping
is very direct but the syntactic load is
hugely different Erlang I love me some
Erlang we've got Erlang all over the
server I would not try to tell systems
administrators to write something that
looks like that I like it I just don't
think I can teach 6,000 guys who want to
use perl to do something so radically
different pearl on the other hand so
this is why i said earlier if you squint
at it that looks a lot like the other
dsl i showed you right you know the
resource to file resource that's the
name of the file and then it gets a
little weird and that you've got this
subroutine I guess that you have to do
and why am I shifting this stuff but
it's got an owner and it's got an action
and if you don't think about it too hard
you could you could get there especially
if you're assisted min who already knows
the language right this is this is my
favorite um Jack figure out why right
it's a resource that the file resource
it's got an owner and it's got an action
that looks basically just like the ruby
version if you strip the / ends off of
it alright and you can even make it
simpler if you really wanted to get to
the point where you just called the
resources by their type file or template
or whatever I did it this way at the top
just to show that you know everything is
a resource of a specific type alright so
that's pretty much it on the client side
questions about that outright lies
fabrications servers ankles like I said
I'm very very different when we started
out both the client and the server were
written in Ruby and pragmatically you
know you can see how you get there we
were a start-up the first implementation
was basically one guy who then put it
out into the world and let other people
start working on it I'm hugely hugely
approachable you know one codebase one
language right ah the design goals
though when we built hosted chef when we
started you know we put in some multi
tendency we put in some other isolation
and we started running this for hundreds
of customers doing thousands of
convergences we ran into some problems
so our goals again horizontally scalable
you want to be able to add new capacity
to this service without you know
intertwining it with everything else
highly concurrent which means that
mostly stateless request handling you
shouldn't have to think about which
server handles the request whether or
not the request comes in twice whether
or not you have two concurrent requests
that are talking about the same
resources and again fault tolerant
because I have to put it on every slide
on the server side same set of choices
now in terms of languages but the the
list of them you know sort of balances
differently when you go down don't need
thousands and thousands of people to
know how to hack on it like I said the
server side not where our contributors
come from startup time kind of
inconsequential these are all long
running processes now suddenly the JVM
starts looking a whole lot better all
right we could implement in almost any
language that's good on the JVM the one
I left off this list and I don't know
why was JRuby actually JRuby was the
highest can
tender for us when we first started the
port why because we got lots of guys who
know Ruby really well and we want a
thing that might be better threading
that might be better with some of the
memory concerns pearl know ml you're not
going to get enough guys who know how to
do it and it's not exactly at the top of
the list for web service implementations
right Haskell may be coming along we
didn't have anybody that knew it well
enough to say and then unless you're on
the JVM there's no scheme or Lisp that
that you can get enough people that know
that is also battle-hardened you could
pay thousands of dollars for Lisp works
I personally did in a past life or you
could rely on something that's out there
for free but again it's not like folks
are building lots of frameworks today
for it so pragmatically you know the one
that's missing on the slide though is
the one that we chose which is early so
we started with this thing that is Ruby
running merb for folks in the know Merv
is a lot like rails burb burb was an
offshoot for a while that was then
brought back in so the request
processing and routing stuff in rails 3
is in fact merb so merb Ruby unicorn as
a web server running behind engine X as
a reverse proxy so again stateless
scalable all that stuff we talked to
couchdb on the back end we had a custom
authorization service and we have a
nifty search feature that is basically
us fronting solar so pretty pretty
standard the requests look like this
we've got a public key we used for
authentication and typically what this
thing does more often than enough than
anything else is it schleps node data
back and forth a node is a server under
management that node data is that full
description attributes and run list of
that server so the median sized we
looked at for hosted chef 22k top of the
third quartile 44k for these things so
not a huge payload but also not tiny we
weren't shipping around hundreds of
bytes we were shipping around something
more like half 100k quite often and then
we have these fairly expensive
authorization checks we do because we
actually have role-based access control
at a fairly fine level we've got you
know
can you read these can you write these
can you delete them or create them on
all the objects in the ecosystem so that
can be a bottleneck we have to check
these on every request and then finally
we you know we've got the set of
operations you'd sort of expect you know
you can create them you can delete them
they map very easily to you know restful
HTTP verbs so here's the the problem
statement that amongst others you look
at that sort of support point there and
first of all there's a huge variability
in our response times lots and lots of
wiggle right but there's a support point
there's somewhere around 500
milliseconds which for a number of our
request is really kind of abysmal I mean
you could see it for larger request but
just not fast not fast not happy with it
so that's me on this yes thank you too
we write um so the the question is why
not JRuby uh some of these things are
they were just a matter of when we tried
them we had native it for one thing we
had native extensions at the time that
weren't supported which is a real bummer
right because you can't get part of the
way there we could probably having
changed things we've changed now we
could probably run completely there now
I'll probably would have been a great
choice the there was also a bit of
momentum we had been building some other
things like our authorization service
was built Erlang from day one so we
already had an example of a thing that
we thought ran well and so that's yeah
so you know pragmatically that it wasn't
a wasn't black and white we certainly
could have ended up there it's right so
over time the service looked a little
more like this it was slow in places
highly irregular in ways we couldn't
control and then we had issues with
early builds of CouchDB this is uh this
is an example of our up time graph the
we run high availability you know
failover so the places where there's no
data at all or places where we in fact
failed over so this is a view of only
one side but you can see what was
happening is that over time it would run
for a while run for a while and then
we'd either have to restart or it would
crash it was consuming resources
typically file handles behind us and
getting slower and slower all the time
so we you know part of our dilemma was
our data store was in fact the
bottleneck for a number of things that
we did and we found out during the
course of inspection there were some
really good reasons so you can see that
the way the graph yes yeah I know that's
what i was getting such a fabulous
question so we got why does he get
better toward the end this is a horrible
thing to admit we had a cron script that
just restarted it yeah i just i dunno
i'm so glad somebody played the straight
man for me on that because that's all so
there you go heavy on system resources
ah the other thing we were looking at is
so how much ram should this entire
running system all the request handlers
and the data store and everything how
much ram should it actually use because
if you're running a hosted service
obviously you don't want all of the
resources consumed to scale with the
number of customers that you're adding
or sooner or later you well you at least
don't want some sort of multiple right
you don't want this to scale out of
control so we looked at it so we were
doing at the time about 60 requests a
second which is not huge ah 44k third
quartile for payload so that's roughly
you know just totally non-scientific
this is 2.7 megs of actual active data
being schlepped around right and
obviously there's all sorts of space for
for code that's running in all of the
the Ruby interpreters all sorts of other
copying going on both from Colonel to
userspace multiple user space copies a
lot of things you don't directly control
so let's just put a multiplier on it
again not scientific let's say it
actually takes 27 Meg's as far as the
data and it's copies are concerned and
then we'll figure out how much space the
code takes right so 27 makes nope so
each of our Ruby merb unicorn workers
was consuming a hundred megs of ram at
rest after startup and these days you
know Rams chief machines are cheap but a
hundred makes for a worker that's not
actually doing any work yet and what's
the concur
see it's one request per worker so
you're consuming a hundred Meg's every
time somebody makes a call at least
right that's the way unicorn works you
know you read the outside of the tin and
it says should be used for fast requests
don't worry about concurrency we got you
covered you've got one process and one
request super easy to understand it's
actually a great model for a number of
things because you don't have any
threading concerns right and to be kind
to the two masses Ruby interpreter
threadings not a thing you really want
to approach lightly right so this is a
good model except under load 204 makes
around consumed for each of the workers
12 workers per server eight servers
what's the magic total I've got a 19
point 2 gigs of ram consumed just too
there we go schlep some Jason in and out
of a database I mean it just hurts right
I mean it Rams were again Rams fairly
cheap but seriously nearly 20 gigs to
move Jason back and forth we're doing
involved does it doesn't mean they're
necessarily bad components we're doing
it wrong so what's the moral of the
story unicorns eat Ram solution I had to
do right fits the pitch right up we we
moved over to to Erlang this is a web
service so we're using web machine from
the fine folks at bosch Oh see them
everywhere any bachelor folks in the
room that's a yes of course amongst
other things actually there's a couple
of plugs in here so web machine is
basically a state machine for HTTP super
cool and that that thing that you see
over here on the right um that's what
you get if you enable tracing you
actually get these images spit out of
where your request goes what it went
through to get there and what the result
was which for debugging is glamorous
right it's a view that we didn't have
before a and it's also just a good
framework so we made the switch how did
we do the Erlang processes at as an
aggregate at idle I'm sorry each worker
at idle 19 Meg's loaded 75 megs
so under load we're consuming 600 megs
of ram total across the system running
the Erlang servers we had nearly 20 gigs
running the Ruby once again I'm not
necessarily faulting Ruby what were we
doing it wrong ice is so much better it
was we made a bet when we started
writing in Erlang because like I said we
could have done it in JRuby or something
else ah that paid off that was a huge
difference so we win yay but wait we
weren't done right there we looked at
what Ruby was doing some of this was
researched to tell us we were going in
the right direction where was the ruby
version of the spending its time was it
in the database because you know couch
was was not helping us at the time turns
out it wasn't so much in the database
Jason parsing is slow in every language
right it turns out it wasn't in JSON
parsing either was it in crypto because
we do a bunch of key stuff and it's kind
of cpu unfriendly wasn't in crypto
garbage collection garbage collection we
spent forty percent of the CPU in
garbage collection we were abusing the
interpreter in the the pattern that we
had we spent forty percent of the time
and garbage collection so you know like
I said clearly we were doing it wrong I
I'm not I'm not faulting anybody else's
code but when you see that happening
like gotta be a better way to do it
right this was cpu usage sort of before
and after so you can see the not only
was it variable and higher it goes down
and it goes flat one of the other things
that we got out of this is that this we
can now characterize how the system
works even under load system works the
same way all the time we've got a very
very very large customer in testing
right now who had the original version
and then progressively got these
versions as we rewrote pieces in Erlang
and my favorite piece of feedback was
wow our front ends now are doing so
little you ought to figure out what else
you can run on them like they basically
got all their resources back right so we
shed a little tear because we also in
the process of this move from CouchDB to
a relational database and there's a bit
of a discussion about that
so why did we start on couch again it's
these pragmatic choices super easy to
approach in the beginning it's you know
it's jason documents behind a restful
interface right who doesn't want that
it's it's so easy to get started on so
we're doing frequent gets inputs of node
jason all this node data and frequent
compaction because anybody how many of
you have used couchdb okay so uh it's
it's append only mvcc so you're every
time you write you are actually
appending to the file and it gets bigger
and bigger and at some point from
outside the system you have to tell it
go compact now and this is true both for
the main database files where your data
is but also their equivalent of computed
views that do the same thing so you got
to think about if you're doing read like
stood for our node objects where reads
and writes are roughly you know the same
frequency symmetric you're writing a lot
of the time you end up spending time
compacting early builds we were running
on no concurrency accessing a single
database so you have to decide you know
what's your model how many databases if
you have thousands of customers you're
not putting them in the same database
because now your concurrency goes to one
again do you split them up one database
per customer and have thousands of
databases and this by the way got fixed
to be fair we went the thousands of
databases or album it's really easy to
isolate customers if every one of them
has a separate database also a little
bit better on the security front because
it's really hard then to commit to
somebody else's database right it's it's
equivalent cross database joins turned
out wasn't that reliable for thousands
of databases so we thought we'd solved
one problem but we played whack-a-mole
and that we created another one and you
can't with the builds we were using you
could not in fact ask it to run off and
do compaction across those databases on
its own we had to do some stuff
internally to sort of statistically
decide which ones needed compaction
compact only those and as you can
imagine right in the face of this it was
leaking file handles as it was doing so
so that's one of the reasons why you'd
see it run for a while and
we have to restart it at some point we
would simply run out of file handles it
had a bunch open just in normal
operation and then we would start
performing these games and it would take
off again and we had to had to restart
so it became an operations thing I if
you got paged in the middle of the night
the first place you started was with the
database which sucks right especially if
it's happening multiple times a week at
some point somebody says can we get rid
of it and I'm not trying to bag on the
couch guys but it's horses for courses
it was the wrong thing for us to use in
that environment at the time so what do
we actually need there do we go to
replace it so needs to be happy with the
right level load because a right heavy
load because we do rights to nodes all
the time every chef client run commits a
note at least once support for fairly
sophisticated queries it's not just key
value sometimes we ask slightly more
interesting questions and then it needs
a supportable you know high availability
mode something that's fairly easy to you
know for both for us to comprehend
operationally and then for customers
that we sell this to perfect so the
obvious question did you consider the
other no sequel databases absolutely we
did as a matter of fact we were running
react for a while still big fans of
react but we also asked a different
question can our problem as easily be
solved just running sequel and again
this was a pragmatic choice because for
us internally if the only thing we were
running was hosted chef we could pick
any technology we wanted and train
people up on it but this is also a thing
that we sell the folks and it's already
a bitter pill to swallow if you say oh
they're all these weird services in here
and this is what you need to know to
keep them running and by the way we have
this weird database technology you don't
know and you don't have guys to run it
it's just it's more load right so we
measured right which which of these
actually works can we actually use
sequel and again the fine folks at bosch
o bachelor bench super cool tool for
this and it's it's the nerd kind of tool
because not only can you define your own
kinds of web testing but then you use
our to do the analysis yeah I can't say
enough about that
of using our up we're fortunate we have
our guys bachelor does as well we got
our guys at the company well one of our
lead developers is an arc emitter I
would suggest that goes in your hiring
profile because that's cool so we
replaced couch originally with MySQL
which for what we were doing worked
really well and we didn't have to
convince folks that we were selling into
I i hate to hammer on that but it's
really it's one of those things it made
it so easy especially for customers this
is the thing especially for customers
already using it you don't have to teach
them anything like you got dba's on
staff reg got guys who know how to do my
sequel replication check and one you
know one complaint about your product
goes away cool thing is we replaced it
underneath while the system was running
so this is the equivalent of what we did
we moved thousands of customers and tens
of thousands of node objects while the
system was running and nobody noticed I
love that by the way apparently this is
a thing that's like not just this video
like this is the thing that lots and
lots of people do now not recommended
but I'm going to I'm going to spin
through some of the rest of this fairly
quickly because we're running out of
time but um talk just a little bit very
quickly about how we did that live
migration because it you know it starts
out you think it's fairly easy and you
got a plan right you don't want to take
down time for the reasons I said earlier
so all these organizations basically
each customer put them into a read-only
mode copy their data over change the
route so we have the running service
over here in Ruby we're going to change
the route to the running service in
Erlang nobody's going to notice that is
in fact in abstract what we did turns
out it gets harder it gets really hard
really fast right we wrote this tool
that we basically have a dark launch
feature flipper for any of these new
features we can dark launch an
organization no other organizations know
about it only that one of them is
affected so you have to coordinate that
with your load balancer config right or
rather your reverse proxy to change
these routes move batches of orbs around
because if you do them one by one and
you start multiplying it out like how
long does that take wow it's a batch
operation
really want to go faster up tracking the
status as you go and then you know these
things tend to crash in flight if you
drop the pieces on the floor you need to
know how to pick them up as well right
so you need to track the in-flight
requests you need to be able to drain
them off when they're going to the old
database before you move over to the new
database here's the thing nobody really
thought of this feels like a scripting
job right oh yeah we could have written
it in Ruby strangely enough Jan fsm
writing a finite state machine in Erlang
this lent itself very directly super
cool is one of the things we came out
the other side realizing it's a pattern
we're going to keep applying when we do
this right you're moving through various
states be its success or failure and
having to decide what happens in that
state first of all you look at the
problem and it looks like a state
machine and then you solve it with the
state machine plus you get a free rapid
all right so flip through here fairly
quickly um but of course yeah you know
the the quote right no plan survives
first contact with the enemy I won't go
through all the details here but the you
know CouchDB CouchDB cpu usage and then
my sequel by the way um that's actually
my sequel yeah um the think it actually
might be the there we go same graphs you
know the variable the variability and
you know just a lower load average right
and then my favorite here I talked about
the wiggle before API average latency
the wiggle went away and the average
dropped dramatically so under load we're
seeing these these front end services
written in Erlang perform the same way
like I said you can characterize the
system you know what it's going to do
even as concurrency goes up same thing
here right then 90th percentile latency
/ endpoint
one of these oh yeah this is the UNAM in
terms of memory this is the interesting
one red up here that's swap that was
diving into swap and you know the moment
you had the moment your service dives in
to swap you're done I just basically
stops responding um there's no swap here
right requests this basically says it
dropped dramatically because almost all
our traffic is no traffic first thing we
moved was nodes we run an out Oh see now
every time I ash moves side and then
finally same thing on network traffic
decreased dramatically for for two
reasons that the most important of which
actually is we learned the lesson here
and we started G zipping our content
super simple thing is low-hanging fruit
right so now when we move these nodes
back and forth so this is funny it's not
actually a separate product we do a
really poor job wait chef solo is the
convergence engine basically just not
talking to the server so it will work
with the when I said server is a
publishing platform it's it's all about
you know being able to upload versions
of cookbooks track version 8 download
them into the proper places if you
subtract that publishing fortune and you
say all copy the conflicts around
myself and not Spencer pushing then once
a good works on the file system it's
jeff so sort of encouragement and some
folks used to do it that way because
they've already got some sort of you
know background way to share files or it
got some sort of shared file system
across their infrastructure and they
don't want an additional server on the
server side of things wait you guys
switch through movies or like talked
about many things and so on what about
everything I sort of glossed over the
the CPU graphs everything everything
went down um I can't tell you right now
exactly because I don't have current
data exactly how many course we have
devoted to all of the other line points
because when we did this this this
slides are a bit dated now we did the
original analysis this was right after
having moved basically the heaviest
endpoints we started with knows because
it's the most data search because it's
really highly trafficked and then after
that I think we did rules so I don't
know what the totals come out to but in
each of those cases lot less cbeebies
and then than just the concurrency not
having to pee in process to a request
singular with the other the other thing
I didn't touch up directly is on you
part of the reason that there's so much
RAM uses Rick usage is usually like
popular and semantics and we use from
the enterprise edition
rent matches except that the way all of
this term goes and then other artifacts
are the way below things everything gets
touched when it gets touched you don't
get copy-on-write everybody gets their
own and so we basically defeated the
system so we're leaving choice those no
seniors so we do think that uncontrolled
is that going and advise people often
vallejo there this was actually the best
choices you could make inside we do
anything different um I would say yes
they were the the best choices at the
time given the other concerns I I
wouldn't necessarily say that a
relational database is the closest now
to what we do but it is certainly the
easiest thing to explain to our external
customers if we only ran this as a
service on hosted service on our own
it's not clear I mean ur like yes the
relational database in hospital and one
of them so we were using react for a
while and we were a little too early on
and then search wasn't quite we wanted
at the time and I think it's before side
here indices so so that's that's viable
candidate now especially
yeah something about culinary 130 that's
a good question and I said this is
fairly dated I don't actually know i
will i'll find out it's a good question
i want to say that it's over sooner just
without alright cool
how was the migrations were oh yeah and
i had to find in touch on that we forget
it would take about three hours took
three days I'm sorry I mean I just I
just outed myself didn't I the
development effort all told the entire
port of all of the API endpoints I mean
we had other work going on at the time
but it took us nearly a year we are just
now finishing and a lot of that is that
we built a really interesting test frame
while we were doing before because the
thing that we realize is we need to
fidelity with the existing server and we
so we built up this testing framework
that we then pointed at both as we
report
really cool site I would say even thirty
percent of the time expansion total to
probably intestine and that's all from
the developers plus the 17 yep what did
fun most difficult included there were
cases where where we knew what we wanted
to outcome of the request to be but
mapping that to two things both mapping
that to web machine in it's fairly you
know straight intent was difficult there
are points where you just sort of want
to bail and you can but it's not exactly
obvious that that's what you want to do
and there are other cases where you're
working your way through the request
pipeline and you realize that they're
going to gather some data here that's
actually not useful to tell over here so
you have to put it somewhere memorizing
until you actually use it so that mental
mapping from the way we have done it
Andrew lead to the way whether she
expected us to do it that part was
difficult the other part that I don't
know if I'd call it difficult but it was
a thing we decided to spend some time
line was a way to do much better code
sharing across resources limitations we
played some games originally harsh
transforms and went away from that what
we ended up with a thing where now we we
can share both quite a bit of the
standard resourcing invitation and
actually standard record and when they
sort of a default set of fields in a
record that we then sort of expand and
the many on which epi an acquaintance is
so it was all down to that that
conceptual mapping how do you best use
this tool rather than the way we're
thinking about before with both the
lines of code really that soon that's a
great question um I don't know that's
another election
go somewhere because I couldn't
necessarily say from that standpoint
there's a clear win because in both
cases we really enjoy heavily on the
frameworks beneath us so I'm not sure
how easy comparison all right</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>