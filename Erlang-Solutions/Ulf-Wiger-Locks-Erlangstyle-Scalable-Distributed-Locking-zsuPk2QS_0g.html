<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Ulf Wiger - Locks - Erlang-style Scalable Distributed Locking | Coder Coacher - Coaching Coders</title><meta content="Ulf Wiger - Locks - Erlang-style Scalable Distributed Locking - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Ulf Wiger - Locks - Erlang-style Scalable Distributed Locking</b></h2><h5 class="post__date">2014-06-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zsuPk2QS_0g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is a library that I've been working
on for a while and of course in the
especially in the Erlang community it
seems like locking is the one thing that
everyone wants to avoid now for those of
you who were listening to Hans's
presentation he actually did mention why
you want to have locking and also why
you want to have a locking system that
both scales but is allows you to control
locality so you don't have to you don't
have to lock everything now locking
itself is just a convenient pattern
obviously erling is an an orchestration
language a coordination language locking
is a coordination pattern Erlang should
have a good locking library and one of
the things that I've been thinking is
that if you're building really big
systems for example using a react or or
react I know in react to point 0 for
example they are adding a strict
consistency so that once you've written
an object written a value and you've
read it back you're guaranteed that
you're actually going to get the same
value back until you change it next time
which would read repair for example you
you're not guaranteed this would allow
you to be able to run localized
transactions on top of react and
actually get transaction consistency on
top of that assuming that you have a
library that scales pretty well now the
problems with distributed locking is
partly scalability but also with locking
in general obviously you have a
complexity problem for example
forgetting to unlock
resources that you claimed and things
like that with in the distributed case
and in concurrent systems I mean the
biggest problem is deadlock and there
are various approaches to scaling that
now if you want to make another problem
obviously with distribution is net
splits so if you have a resource that
you're locking and you get a split
network you can actually have two people
who have claimed the same lock and then
if the network heals you have a conflict
that you have to resolve and in the
general case if you want to build a
complete locking library you need to be
able to have or at least you usually
want to have read and write locks we're
right locks obviously our exclusive
locks only one at a time can have them
read locks are non-exclusive so several
people can claim the same object at the
same time you also want to have
hierarchical locks for the classical
hierarchical lock in a database is that
you either have table Docs or object
locks for example in in for labs where
we do device management we like to work
with the tree structure databases and
there you want to generalize the
hierarchy so that it's actually you want
to be able to go down into a tree and
lock just a particular subtree so very
simple dependency or this is more an
introduction to the notation because I
don't think I have to explain dependency
graphs so I just use an arrow an arrow
from A to B means that a waits for B and
over there you have a deadlock a waits
for BB waits for a you can also have an
indirect deadlock
so in the distributed case the different
approaches that you may see is that you
maintain a central dependency graph
actually you may not see that in many
cases because it's a really bad solution
obviously you get a bottleneck and also
you get a single point of failure and
also if you if you want to maintain a
global dependency graph that is very
expensive you can use deadlock
prevention Indonesia database for
example I guess that's the most famous
Erlang exponent of deadlock prevention
the trick then is that dependencies can
only go in one direction you simply do
not allow dependencies to go say from
bigger transactions to look into smaller
transactions and if you get one such
dependency you restart a transaction
this is cheap it's very easy to check
you don't have to maintain a dependency
graph you just have to compare the pits
in in our dependency that you find of
course the problem is that you can you
can have phantom deadlocks you will
restart transactions that actually were
not part of a deadlock they just could
potentially lead to a deadlock and we've
seen in some cases that are exercising
easier reasonably hard that you can have
say a ten to twenty percent overhead
just from restarting transactions
without actually having deadlox and also
if you run very large transactions the
chances increase and you have a lot of
concurrency so in some cases you can
actually have a lot of transaction
restarts another problem is that since
transactions are restarted as a
pre-emptive measure
you cannot use side effects except the
approved side effects so in most cases
you can design your application so that
you will not have deadlox but if you're
using for example in easier that is not
a sufficient guarantee that you will not
have transaction restarts so you cannot
use side effects anyway I wanted to use
side effects there in my database
transactions but I was willing to pay
the price that if I have a deadlock then
I will abort that or the transaction
involved another technique is probes
where the transactions actually share
dependency info with each other or the
database agents or however it is
implemented and my algorithm is
essentially a probe based algorithm but
it's not exactly like the ones
documented in literature the algorithm
itself I actually designed that back in
93 when I started using Erlang the
reason why you started using our
language that I wanted to build a
distributed messaging system and also i
needed a distributed database back in 93
we didn't even have an easier we didn't
have ads so i had to start from the
ground up needless to say i didn't
finish but i did design deadlock
detection algorithm and it ended up
being reasonably unique because I was
cooped up in a basement in Alaska and I
didn't have access to much literature at
the time so I essentially just sat down
and thought really hard for about three
days and came up with something that I
thought should work later on I actually
I was talking to Thomas arts and I part
of it was that at ericsson we were
asked to apply for patents and I took
the opportunity to talk to him and say
well before we go further with this
could we actually see if it works so he
ended up he thought it was a cool little
project and he ended up model checking
it and after a few tweaks he was able to
verify after model checking that it
would it was not only robust but also
minimal which is a good property so I
guess that was mainly a fluke I would
say but after that I I picked it up
again and i've added the things that i
think a lock manager should have for
example read/write locks and
hierarchical locks and also multi-node
locks none of these things were part of
the model checking but obviously none of
these will actually bring up the
algorithm because when you add stuff but
after model checking that never breaks
anything I also added gin leader type
behavior that i will talk a little bit
about so the implementation is quite
early in order to maximize latency you
have the user process spawns a locking
agent this process will do the
dependency analysis it talks to a lock
server every node has its own lock
server and the agents can also request
locks and other nodes and actually one
of the things I haven't implemented
which might be a bit unusual for a for a
locking library is unlock there is no
unlock feature what you do is you end
the transaction this is I think if
imagine or think sane easier
transactions you will accumulate locks
until you commit and then you release
your locks at the end of the transaction
so essentially you just
the locks agent and the lock server will
note that and and release all locks it's
quite convenient I think you well it
wouldn't be that hard to implement
unlock I just haven't found a use for it
yet so i think it's sort of a Erlang in
the lock itself is a process actually I
have one law one server implementing all
locked processes but essentially the
agent talks to the lock process and it
talks back and it's all a synchronous
message passing and and all dependency
analysis is distributed essentially you
could think of distributed analysis or
dependency analysis in the literature is
you have one database manager here you
have one database manager here each of
them has its own dependency analysis and
sometimes they talk to each other in
this case every transaction is its own
dependency manager so I have written
some graphs to illustrate how it could
look here we have two clients behind c1
and c2 and I have one lock in this case
and this is a simple case the client one
locks l1 and it gets a message back and
the way the lock manager response is
that it sends you the lock and
essentially the cue and in this case the
queue is one client so I have the lot
because I'm at the head of the queue now
client two tries to lock the same object
and it gets now the lock manager sends a
message to each client here with an
updated queue so c2 is waiting for c1
now here we pretend that there is an
unlock and
if client one unlocks then C 2 will get
an updated message with a new Q and it
knows that it has the lock so in this
case we have two clients one lock three
lock operations resulting in seven
messages so essentially it's our one
message pair per lock operation plus an
additional message there for the
dependency since one client is waiting
for another we make it a little bit more
difficult this is actually a deadlock
situation I can point to this one for a
while client see one locks l1c two tries
or locks l2 and see one tries to lock l2
and is put in the queue and see two
tries to lock l1 now in this case this
is a trivial dead law case because both
clients have enough information to
detect a deadlock so essentially it just
maintains a dependency graph and in this
case it finds a cycle see one waits for
c2 which waits for c1 and in this case
the rule is the biggest client can
surrender this lock so it sends a
surrender message to 4 lock two and then
the information is updated and now see
one has both locks and in this case
actually the lock manager took c2 and
put in put the put put it at the end of
the queue
so in this case we had two clients two
locks for lock operations to
dependencies were see one was waiting
for C 2 and C 2 was waiting for C 1 and
1 deadlock resolution operation and that
resulted in 13 messages okay a little
bit more difficult than three clients
three locks client one locks l1 client
to lock cell to Klein three locks l3
client one tries to lock l2 but is put
in the queue client two tries to lock l3
a little typo there is put in the queue
and client three is trying to lock l1 so
now there is a deadlock but none of the
clients have enough information to
resolve or to detect the deadlock so now
we get to the additional feature that is
needed and this is where probes come in
the the agents need to share information
with each other and there are some
examples in the literature there is the
chandi maestra hoss detection algorithm
from 83 where where an agent or a
transaction is waiting for a lock it
sends a probe message to the lock owners
that it is waiting for to the other lock
of owners owners and they when they
receive a probe message they will send
that message to all lock holders that it
is waiting for and so on and eventually
if it comes around in a loop then you
have a deadlock in the syllabus shots
Galvan detection algorithm from 93 s
eventually you imagine that you have one
dependency graph per node and then you
put in a little proxy or external
indicator here saying in this particular
dependency p3 for example is on this
node so then I have to send this
information the one that it doesn't know
about to this node and then hopefully it
will know enough to detect the
information so what we're saying is we
send information to clients lock holders
where their bid is greater than ours and
they are not involved in that particular
lock because if they were in the queue
they would already know about it so we
find for each lock holder that is
greater than us if they are not in the
queue we send that lock information to
them and this will and this is what
Thomas arts showed eventually one agent
will have sufficient information to
detect the deadlock so in this case we
actually let me go back we were here I
restarting from here l2 or see one tries
to lock l2 and see to try to lock l3
same typo in this case client to sends
information to client 3 about lock to
which is which it is not involved in and
when L one tries to law or C 3 tries to
lock l1 actually client one will also
send a message to client too so ideally
here we might be able to get away with
sending just one because in this case
actually only one of them but I think
there are some corner cases we actually
have to send both to be sure that
deadlock is detected so in this case
once this message you get that
complimentary message and/or and this
lock message then C 3 will have enough
information to detect the deadlock and
in this case C 3 will surrender c 2 will
also detect the deadlock but it will
know that c 3 is the greater agent so it
will just lock oh wait for c3 in this
case we had three clients three locks
six-block operations three direct
dependencies and then we also added to
indirect dependencies to information
messages and then one deadlock
resolution operation which means six
message pairs for the operations adding
three direct dependency messages to
indirect dependency messages and then
three messages for the the surrender and
then they have 20 messages in all now
surrendering is really cool I worked
hard on that feature but it is not
always useful now if you have a database
transaction where you're reading that
you're locking objects you're reading
data and based on the data you've read
you claim other locks then you cannot
have the transaction surrender a lock
that you've already operated on and
claimed other locks based on
so in that case what you want to do is
most likely abort instead you have a
true did you have a true deadlock it's
not a phantom deadlock it's a true
deadlock but if you're halfway through a
database transaction all you can do then
is aboard so the idea here is you have
an option say abort on deadlock and you
can still do a surrender but it depends
on whether the client has asked for
confirmation that it has the locks as
the log so if you've actually informed
the client that the lock is held you
cannot surrender it then you will abort
instead but otherwise it's perfectly
okay to abort a to surrender and this
becomes interesting when you have
multi-node locks this was not part of
the model checking but the idea here is
that you take the lock resource and pair
it with the node identity that becomes
your lock instance so if you want to
claim a lock on multiple nodes the
dependency algorithm treats every lock
instance as a separate lock and in that
case you don't really have to worry
about the dependency the dependency
analysis is exactly the same I actually
didn't have to change that at all what
you also want to do is you want to be
able to tell the lock agent that for
example the nodes if you want to claim a
knock lock on a number of nodes you can
add the information that you want the
lock to be granted on every node or on
just a minority of the nodes a majority
of the nodes or the majority of majority
of the nodes that are alive for example
those are the options set I support
right now
and this could actually mean that if
you've required all a lock on all all
nodes and some of those nodes go away
there is an option that you can either
wait for them to reappear or simply
abort because now you cannot claim all
the locks that you asked for so
read/write locks that was another
challenge so but it also doesn't
actually affect the dependency analysis
except for little the check of who waits
for whom but that's actually in the lock
server so you have the queue so what I
have actually is a read lock is an entry
in the queue where it's a red flag and
then all the agents or clients that are
holding that lock so once this list is
empty you can serve the next lock which
could be a write lock and so on so that
actually also didn't modify the
dependency of them the really tricky
part was a hierarchal hierarchical
blocks where the idea here is that the
lock ID is a list list of identifiers so
in this case it could be the the
database a database instance a table in
the database and an object or whatever
this is just an example the thing here
was to introduce implicit locks where if
I've locked the resource a be for
example this would mean or and then I
lock abc1 then the lock server would
notice that there is an implicit lock on
a B which is a parent of a b c 1 so
there is an in place
right lock from client one so then
client to here is put in the queue and
it will actually create parent lock
entries when needed so for example I can
have I could lock abc1 and abc2 it would
create those lock entries but then if
someone is trying to lock a be after
that then first you find the child
entries and you enter implicit lock
entries in the queue and then you insert
the the new client in the queue was that
understandable and so the only thing is
that the log server needs to keep track
of these implicit locks and remove them
to once once the agent terminates but
again this didn't change the dependency
analysis because it doesn't care if a
lock is implicit or explicit so I did
some optimizations I actually haven't
pushed these changes but since klarna
found a little scalability bug Indonesia
lock server where if you had thousands
of locks in the same transaction it
would actually be like a hundred times
slower I tested my code and found that
it was even worse I following joe
armstrong's advice to make this code as
inefficient as possible this was
actually as inefficient as possible
after some optimizations I did run some
this is actually basically claiming a
thousand locks in the same in the same
transaction and then thousand 1002 up to
a thousand ten and then running 10
iterations and averaging the time it
took per lock request so you can see
that it's not exactly blazingly fast but
it
doesn't get slower as you go to 3,000
locks 5,000 locks this is latency so
it's actually run time in microseconds
so if you use the synchronous begin
transaction function it takes about a
hundred seconds to create a transaction
context and possibly adding some locks
lock requests in the in the start and
waiting for those i found that that was
not what I wanted most of the time so I
added an asynchronous spawn agent we
takes about 20 micro seconds plus some
50 microseconds of setup in the agent
and then you can go on claiming locks
from there so I think in you know
obviously it would not be a drop-in
replacement for the mini zia locker
because the cheapest cases in necia are
much cheaper than this it's possible
that you could optimize it even more so
the leader election and the idea there
was that since I have the multimode
locks and I have a deadlock resolution
algorithm basically if you have several
processes trying to claim the same locks
on on a bunch of notes you're almost
guaranteed to have a deadlock but since
the algorithm detects and resolves that
it will eventually pick one transaction
that holds all the locks so the the
locks leader behavior will just the way
it works is it you when you start it you
name you give it a lock name and it will
try to claim that lock on all the nodes
it sees or and it will do so
asynchronously so this process will get
it will get lock info updates from its
lock agent
including a message saying now you have
all locks so then it will know that it
is the leader because it got all the
locks that it claimed and after that it
works pretty much like Jen leader now if
you have workers let's see I actually
have a slide for that it's the same
picture the thing about the the lockinfo
messages in the asynchronous mode the
you get discovery you get a lock info
message and it has all the other
candidates in the queue so then you're
actually informed of new candidates so
one of the problems with Jen leader was
that it didn't do well with nodes that
would come and go but this will actually
just auto detect new nodes and add them
to to the list of candidates now another
thing that you have in Gen leader is
workers workers are not candidates for
leaders but they actually they want to
be part of the group so in this case
obviously they you don't want them to
attempt to lock the resource so what
they do is they go to the lock server
and subscribe to lockinfo messages and
so the lock server will inform all all
involved agents and all processes that
actually subscribe to state changes in
that lock so then they will be informed
at all of all the candidates and they
will then contact those candidates so
then the candidates are informed of of
all the workers so the question is is
this a better Jen leader than Jen leader
I don't know it does handle dynamic
networks in a much cleaner way than Jen
leader did essentially with Jen leader
there have been a few hacks to add
dynamic no discovery in
in Gen leader but it's it's a bit
awkward and also you have to change the
underlying algorithm to be able to to
fix that another thing about this is
that you can actually have multiple
leader candidates you can have a whole
leader election structure on the same
airline node because it only cares about
the name of the lock for one thing
that's really good for testing because
you don't have to fire up a bunch of
slave nodes in order to test the the
algorithm you don't have to register
candidates so you can you can fire up
anonymous leader election structures one
of the examples I have is as a global
dictionary where you just start
processes that are you name the
dictionary essentially by giving it a
lock name and then you can have multiple
processes and they will just replicate
the dictionary one thing that I added
this is actually the same dictionary
that was in general idar as an example
but I added healing from net splits and
merging dictionary merging just to
verify that it that actually works so I
did adnet split handling and conflict
resolution a few more functions for
example ask candidates so the when the
leader is elected it can actually go out
and talk to the other candidates and for
example fetch data and do dat emerging
so as far as actually being used I have
seen that some people are using the
locks leader behavior some people have
actually identified some issues but I
can't say that there is a tremendous
amount of traffic yet on the repository
what I'm doing is I'm integrating this
into the kV DB DB NS which I presented a
while back at Alyssa not the the last
Erlang factory but one before that in
San Francisco so I I have a branch of
that database system that I'm running
the our device management test Suites on
it's a fairly complex application and
all the test suites are passing which is
nice and i also have a branch of g proc
using the locks leader a application and
so if you want to use g proc with
dynamic no discovery i would recommend
this instead of the gen leader branch
and it would be great to have people
actually try this and find bugs of
course there aren't any I had never have
any bugs in my code except the ones that
John Hughes keeps finding and giving
presentations now I'm his guinea pig for
quick check and the unit test I I don't
use quick check to test this actually or
haven't I have a little script evaluator
where I can read a reasonably high level
describe different scenarios and what I
expect from each lock operation so the
unit test actually does test some
reasonably weird deadlock situations and
lock upgrades and hierarchical locks and
things like that and I'm also working on
a locks leader unit test but I'm not
quite finished with that yet so there is
the the address and well do you have any
questions he doesn't bite everything is
clear Costas isn't here so apologies
fight if I miss this in the top but what
is the protocol in the case of a genuine
net split and in the case of high
latency which might be misinterpreted as
a as an xsplit so the the lock agents
don't really understand net split per se
and remember that all lock or lock ID
and node instances are one single lock
or one single lock instance so if you
get they will actually monitor other
nodes or the lock servers and other
nodes so obviously what happens is that
those locks will will disappear now if
you so when once you recover there is
actually a little once you get a node up
from another node that you're monitoring
if you have the option that you want to
follow other nodes and wait for them to
come back what you do when you get a
node up is you send a little actually a
script an erlang with abstract format
script and you do Earl eval evaluation
that actually sets a little registers a
little process so that as soon as the
lock server comes up it will try to
notify all waiting lock agents using
that little
and and then you may actually have a
deadlock or at least that could be the
case if you have instances that that are
claiming the same lock so in the locked
leader actually the lock leader behavior
is the one that detects that there could
be a leader conflict the the leader
algorithm or the lock locking algorithm
will just treat this as any deadlock and
it will resolve it and it will pick one
instance that has all those logs so the
what what remains for the locked leader
code is to note that it actually was the
leader so if it gets informed that there
is another leader some somebody else's
leader and my leader flag was set then
this has actually happened there was a
disconnect and now there has to be a
resolution so and so the it does the
healing automatically the trick in the
in the leader election behavior is it
you have to own it you have to know that
it happened know if it does it's a bug
and I mean it's a reactive design so I
the you don't wait for or time out and
start wondering if there is a deadlock
you actually find out pretty much as
soon as you get the information and then
you act on it so it's it's pretty Swift
in in detecting and resolving deadlox so
the
and so one of the things we wanted to
achieve was to make it at least as close
to minimal as possible so that you have
a minimum of messages flying back and
forth in a distributed case and him I
have a question because an aloof doesn't
bite until it's dark so every task now
after being bought a few beers okay okay
yeah so where I bike before that oh hey
I'll make sure you get a beer anyway did
you get the patent it was interesting we
we actually got the worst dumbest patent
engineer or I hope so I tried him so and
essentially we learned that that even
though Ericsson actually did pay some
money for being you know getting to the
point where you actually officially
apply for the patent it's not worth it
just the stupidity and the horribleness
of the process it's not worth the money
we got to the point that after about a
year we got a really stupid response
back with a bunch of texts patents that
supposedly already solved this which
they didn't so we sent a long reply back
saying this is nothing like our
algorithm and actually the way the
patent process works is that you have to
if you're actually different in just one
claim it is not the same patent and and
the basically the one claimed that they
had was that it was also a deadlock
detection algorithm but that's not
enough to him to say that you have a
blocking patent but essentially since
Erickson wasn't using the algorithm at
the time we agreed to drop the whole
thing and I did ask Erickson afterwards
if
it was okay for them to for me to
continue and so the the two algorithms I
showed here were actually closer to this
algorithm then those patents were so I
wouldn't worry about them so it was just
a long very painful process for us and
we decided it wasn't worth the time
because it actually does cost money to
to fight the patent engineers it wasn't
worth it since we actually weren't using
the algorithm at the time and I would
say what this does is a very fairly
small modification of that algorithm
from 83 that I showed it's it's
essentially just that you don't you
don't send quite as many messages so I
had approval from erickson to release it
as open source and i would say that
there is plenty of prior art i have
looked at a lot of patents and there
isn't no patented algorithm that that
does this and i don't think you can
patent it actually because there is so
much prior art so I know the the pain
you've been through I used to work for a
big telco company too and yeah one of
the requirements for getting promoted
was that you had to file for patents and
get Ross and actually the idea was to
get the patent and just release it as
open source so yeah so it is now
released as open source it's Apache no
it's not an Apache it's the MPL to
license and a fan don't worry about the
patent issue it's not that ended and
it's not in violation either any other
questions or were there only two brave
men in the room or women
okay going once twice locked both go on
the way out</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>