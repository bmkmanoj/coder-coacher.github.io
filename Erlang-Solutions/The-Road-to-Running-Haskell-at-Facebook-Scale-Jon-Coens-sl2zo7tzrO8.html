<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Road to Running Haskell at Facebook Scale - Jon Coens | Coder Coacher - Coaching Coders</title><meta content="The Road to Running Haskell at Facebook Scale - Jon Coens - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Road to Running Haskell at Facebook Scale - Jon Coens</b></h2><h5 class="post__date">2015-11-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sl2zo7tzrO8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Thank You William so today I'd like to
tell you about how gone through this
road of running Haskell at face book
scale and if there's one thing that I
want people to take away instead I feel
that Haskell is ready for industry you
know we we have a solid data point here
that using Haskell is applicable within
industry I think that there are many too
many problems out there that people
don't realize that Haskell is a viable
tool to use so I'll take you on this
journey of how we're protecting facebook
with Haskell
so first let's let's learn about our
world Facebook lets people do a whole
bunch of things they can send friend
requests they can send messages you can
post the latest cat video to your wall
and most of these are good you know we
know that there's real people behind
them having real conversations but some
of these are bad so there are spammers
out there they're fake accounts and we
want to be able to know which of the
good things that we need to let happen
and which are the bad things and to do
this we have a rule engine so someone
comes in tries to send a message and we
ask this rule engine hey is this evil
and so depending on what that event is
you know a message a friend request we
can run a set of rules to try and pick
out the good things and the bad and if
it is good you know great you can set it
on forward people can have their latest
conversations but if it's bad we can nip
it in the bud so these things don't
spread anymore on the platform so to
protect Facebook or our world is really
this rule engine so let's look a little
bit closer at that say we want a rule
that says if someone is posting about
monads which is already suspicious
and they have more than 100 friends and
more than half of them like C++ we
should probably stop this someone's up
to no good
if not then let's allow it so what do we
need to make this rule a thing we need
to info about the content like what are
they posting about yeah and that's part
of the event so that's nice and fast we
should have that then we also need the
friend list of whoever's posting this
and you could fetch this ahead of time
and send it in your request but if
someone's not talking about monads you
don't need that list of IDs so if you
send it ahead of time you're kind of
wasting some efforts there so it'd be
better to only pick that up when you
need it
which means you're leaving the box which
means it's a little bit slower and then
for each of those friends you need an
additional piece of information so
instead of one request and we have n
requests and since we're leaving the box
again with n requests that's even slower
so given something that works like this
what what language should we use how can
we express this stuff and we've found
that a great sweet spot in the design is
a combination of pure functions and
read-only data fetching so take another
look at this right you're combining some
things together we're intersecting
things we were adding some things and
then we're reading things elsewhere and
these events are so complex that you
have to get stuff from elsewhere you
can't fetch everything ahead of time and
we found that this data fetching will
make or break your systems performance
if you don't if you're not smart about
it if you don't do it well your system
just will not keep up so ok this you
know we came across this a while ago Oh
what did we build here here where our
high high level required
and we need to be latency-sensitive you
know people people are waiting for that
message to get to their friend they're
waiting to log into the service you want
to be have complex expressive logic the
rule I showed before was a pile of if
statements or ends hands and oars but
you know we want to map things we want
to filter things you want to have
higher-order functions we need a ship
code as soon as possible
spammers out there move ridiculously
quickly and we need to be able to react
just as quickly so waiting for that
Weekly push that daily push just isn't
going to cut it and at that time we had
to handle about a hundred thousand
requests a second and so we decided
given all these constraints that we
really just wanted to control the entire
environment and we built our own
interpreter and a language called fxl
and so to be latency-sensitive
when you have control over the whole
language you can batch all this data
fetching up at will instead of sending
things naively one at a time you can
send the things that don't depend on
each other all at the same time and if
you're in control of the entire
environment you can do that
simultaneously you don't need the
programmer to tell you which things are
going to leave the box to get pieces of
information you know that to get the
friends of someone that
behind-the-scenes I'm gonna go do the
data fetching as I need I don't need the
developer to say oh go async of this or
go await that or yield this thing and
then wait for then come back and use it
you can hide all that behind the scenes
and you can build your own dynamic
loader again if you're in charge of
everything you just when a new set of
rules comes in you can bring them into
your process use those for the new
requests and dump out the old ones when
the old requests are finished and a
hundred thousand requests per second was
fast enough on our hardware and
everything was great in our happy little
world
but then tragedy struck scale each of
these checks that we were doing becoming
more and more expensive you know as new
rules as new spam was coming in we
needed more information from what we
knew to make a decision furthermore
Facebook continued to grow in all of its
product offerings and so we needed to
protect more things our surface area
kept increasing and the things inside it
became much much more dense our happy
world wasn't so happy anymore and we
were found we were failing to scale in
two different dimensions the first was
typical computer stuff we were running
out of CPU running out of memory but we
were also failing to scale on a people
level the kinds of things that this
interpreter could do wasn't
sophisticated enough for what our spam
fighters really wanted to do so so
here's an example of some actual code
that we had this is some fxl don't worry
too much about the details but this just
this is what was required to take a map
of something and turn it into a list of
pairs and whenever a developer needed
some functionality like this they needed
to go and implement it all on their own
it'd be much better if something like
this was done natively so that they
didn't have to think about it if every
developer comes across some higher-order
function that they need and they need to
re-implement it from scratch it's a
great way to introduce bugs and
commonplaces plus if you're writing it
in your language in your interpreter
that's going to feed back into your
computer side problems because instead
of being native now you're running
inside your interpreter we hit on this
thing with a hammer for years trying to
make it more efficient but we could only
take it so far and at some point we
decided we need a rewrite I went from
our happy little world to needing to
scrap our entire implementation
and that took us to a fun time right
when you're designing a new system if
writing this from scratch today what
would you build and so I mentioned
before this data fetching is really the
the core concept here if you can't do
data fetching it doesn't matter all the
other pieces that you build out so let's
look look through a couple examples here
so in the first one we want to get the
common friends of two people a naive
implementation of this would first go
make the network request get me the
friends of X wait for it to come back
then say oh I need the Friends of Y go
make the questions friends of Y come
back and then take it and intersect
everything so you're waiting for the sum
of these two requests together for how
long you're waiting but the Friends of X
and Friends of Y don't depend on each
other so it'd be better to send those
requests out simultaneously at the same
time so you're only waiting for the
maximum rather than the sum and in the
next case if you're mapping something
that needs data over a list of things
you have to do one request to get the
friends but then you need to do n
requests to get pieces of information
about each of those and a naive one you
know you're waiting again for the some
of these end things rather than the
maximum of them or would be better to
send those all out simultaneously so you
can you can override intersect you can
override map to know to do all these
things but that it starts to get kind of
hairy when you mix these together you
know you want to take the result of the
intersect and use it in one of your
functions as a map
and so this this is this is what we want
like this is the syntax that we want we
want to use this kind of language to
describe what information we need not
how to fetch it I don't want to say you
know async friends elects async friends
of why wait for I don't want the
programmer to need to do that it's a
great way to have tons of concurrency
bugs and so here's the cord design
challenge writing expressive code in
your favorite language that auto batches
i/o is almost impossible that's what I
mean by expressive its syntax like this
that is doing all the optimal data
fetching behind the scenes for you ok
everybody think about it everyone's
going through the rain wall could you do
this send me code later I'd love to see
it I just tried this in JavaScript the
other day and it was scary but yeah I'd
love to see anything that does this and
so you know you fight with this for a
while anything well you know should we
should you write your own language your
own interpreter to do this it seems like
a great idea to start with but you get
hooked by things that you don't see
coming you know it's great you implement
your killer feature you get this great
bit data fetching and if it works guess
what you also get to build profilers
and rules you need to re-implement all
of the standard libraries which is a
wonderful exercise but not something I
would recommend and then you have to
maintain it forever because you are in
charge of it you know if you're
implementing a standard sort how
standard sort works or if you're
implementing how the and operator works
you're probably doing it wrong there are
things you can use there
okay so so this is automatic data
fetching it sounds like reordering the
execution of a syntax tree squint at
that that sounds like a domain-specific
language and so is there anything out
there that's performance for running
dsls domain-specific languages what
about high school you know it's it's
known for being able to do these kinds
of things it's based on GHC which is
this very mature runtime with lots of
engineering effort behind it so okay
let's what would that look like
it's not a typical thing so here's what
our requirements would be then some of
these I should look familiar you know we
need to be latency sensitive we need
this expressive logic we need ship code
as soon as possible and we need to take
at least a million requests per second
now so okay can can you build the DSL
that does all this magic data fetching
behind the scenes yes as you can
we did it we built it it's called hack
cyl you can find it on github the
details of how this works is not this
talk if you're interested in that I'd
recommend going online Simon Marlowe has
a pile of excellent talks describing
what we're doing it's essentially a
monad with a special kind of applicative
instance to let us look down both
branches at a time so we once sent my
one slide to try and convince you that
this actually is possible so a naive
version of Friends of you get an idea
you get a list of IDs and the only
change you need to do so that it's
capable of doing all this magic batching
behind the scenes is instead of just
returning a list of ID's it's a let a
axial list of ID's you know the Delta
between those is pretty small and at the
bottom here
naively mapping our data fetching our
function that requires data fetching
over a list which would take again the
sum of all those times and at the bottom
of the axial version that does all the
batching behind the scenes you just need
to call map n instead of a map and again
the Delta there is is minut so that's
cool
axel gives us both the latency
sensitivity that we need and allows us
to have these complex expressive
application logic that we're looking for
but what about shipping new code as soon
as possible we're no longer in charge of
the entire stack
Haskell's this being compiled language
well GHC has a built in runtime linker
it was originally written as part of the
repple so as you're editing code you
import some new module or new library to
use and the ripple says oh hey that's a
new library I know that exists over here
and then just suck it in and so then you
can keep going forward but unloading was
kind of sort of written so we needed to
flush that out a little bit more but
with those two that gives us the same
exact properties that we needed we could
compile our rules into some new code
bring that into a server with the linker
and dump out the old one all without
restarting a server because restarting
servers can be very expensive given how
many connections we need to make so we
want to change things as quickly as we
possibly can so the linker what's a ship
code as soon as possible what about a
million requests per second Wow
you know we built some artificial
experiments we tried to put GHC through
its paces and it looked like it was
working but there's really only one way
to know for sure that's a good time time
time to build this you know the
prototype looks good let's let's make
the production worthy system this
required multiple and
years full time to build all the
connections between Haskell and our data
sources the same data sources that our
interpreter was connected to we needed
to build out equivalent things
connecting Haskell and from that we can
move on to our house called brave new
world but we tripped over the foreign
function interface so here here's a
diagram when one a diagram of what our
server can look like so we have a C++
backed server and we have C++ data
sources and we're using C++ because
those are already existing pieces of
technology that are very finely tuned we
didn't want to rewrite all those from
scratch as then we would be in charge of
maintaining all of those things from
scratch we'd much rather have the
clients maintain their own data source
that we can then use rather than you
need to constantly play catch-up and
that leaves us with two foreign function
boundaries we need to be marshalling
data from C++ and Haskell as well as
Haskell back into C++ and unsurprisingly
C++ exceptions really don't like hitting
us boundary usually results in a seg
fault so we've actually got some sig
faults within sake faults as our sake
fault handler was trying to figure out
what the heck happened and stay folded
itself as it was going so we hit we had
to whack them all these things as they
would come up we built some custom
libraries to make this a little easier
but one of one of our takeaways was that
exception handling can be pretty tricky
with this foreign function interface and
I really see this as a right place to
make Haskell better another challenge
so speaking of this foreign function
interface here's here's some code to
connect Haskell to a c function it's
called count art burke's
we've marked it as unsafe and this means
that as Haskell is going along it can
just make the C call just you know new
stack frame here's my dad I'm just go no
which is super performant really really
quick but it's bad when one of these
calls decides to go out to lunch
you know I as Haskell's going along it's
like okay new stack frame keep executing
in some C code and if that takes way too
long
GHC cannot garbage collect in that state
it needs that thread to come back before
it's allowed to garbage collect which
means that one request that's just kind
of sitting out there doing this thing
could bring down the entire runtime
could stall the whole thing but there's
another way you can call a function it's
called safe and this is where the
runtime will first package itself up
nice and cleanly and then call your C
function so the kernel thread can go out
to lunch but GHC can happily garbage
collect as it goes but it becomes a
problem when you have your you're really
fast function here you know counter
aardvarks doesn't take that long or if
you have a function that is less
expensive than packaging up the runtime
you start running into some contention
issues and so another take away with
that foreign function interface is that
you need a balance of safe and unsafe
calls we still whack them all these
today
you know the 99.99% of the time it works
fine but in that long tail if just one
of these times it takes too long it can
slow down an entire machine and so with
that we can move on to our brave new
world but we also need allocation limits
so here's a graph of the whole run times
memory usage over time and as we were
testing things we turned on a new call
site and bring done brought in a new
heavy rate request and requests will
happily go along and chew up as many
resources as you give them this one in
particular was orders of magnitude
heavier than other things that we were
doing and if you let an elephant like
that into your run time when everything
else is nice and small it can slow down
the entire runtimes performance and
that's no good
so we needed to build allocation limits
into GHC this works at the per Haskell
thread level so any thread you say okay
you are now allowed this amount of
allocation and as it goes gh is keeping
track of things and whenever it runs out
it throws an async exception into the
computation of your thread stopping it
bubbling up all the way you can enable
it you can disable it as you need and
this was really really easy within the
exception framework of Haskell it's
almost trivial you just an async
exception appears and all the cleanup
happens nice and cleanly which would be
very very difficult in C++ we had
something that did sort of this using a
custom allocator that would start
failing once you reached a certain
amount but it just it hath worked it
wasn't quite as clean where in Haskell
you just drop the exception in and
everything bubbles up so to save
performance you need to limit resources
per request not just the runtime
so now with the brave new world but then
we ran into semantic differences you
know you have two different runtimes
there they're gonna differ at some point
there's no way that you're gonna be able
to make one exactly the same as the
other so this was me no small
differences in implementation will get
lost in the noise know some things just
just rounding a number no off tanida
round exactly 0.5 the only time that
this ever comes up well it happens and
completely different branches of
execution would be taken because of this
difference leading into different
results in the end unsurprisingly
regular expression engines are a a
source of never-ending differences given
different versions of the same regular
expression engines and my personal
favorite if you take the floor of
infinity you either get a negative large
number or a positive even larger number
and so when you're working at a million
requests a second one in a million
happens all the time
heck one in a billion happens every
three times an hour
so speaking of one in a billion we use
Aysen to parse some JSON and we found
that if you send a couple megabytes of
backslashes to a sound it decides it
once to allocate something like 30
gigabytes of memory which is not okay so
we sent this back up to brando sullivan
and he has a great blog post here of
what he did to fix this you know who
comes up with a million like a couple
megabytes of backslashes is your JSON
and so now we're on our brave new world
we built out all of the equivalent
pieces and then then there was a
decision you know going back is really
difficult this is taking some control
out of our hands we would no longer have
our interpreter we would be based on
Haskell so should we do it we we were
watching our top level metrics you know
this isn't a particular machine this
isn't CPUs and memory these are top
level metrics and here's where we switch
to Haskell it boggles my mind that given
the same request you can run it through
different sets of ones and zeros
projects with completely different
histories behind them and out the other
side comes out essentially the same
thing and so then this was GHC handling
our massive load that works so one of
our spoils of victory here is that by
switching to GHC and some minimal
tweaking we got a 30% throughput
increase on the same exact hardware now
this previous system is something we'd
been working on for years so you know it
wasn't perfect but it also wasn't
completely ridiculous what about the
garbage collector know we're running
this massive latency-sensitive service
it's a managed programming language
surely we run into the garbage collector
I hear horror stories of other garbage
collected runtimes having issues and we
found one bug one bug in the garbage
collector that had been in JT for years
for years but the garbage collector
itself was never a first order problem
the high allocation the high GC times
are actually allocation limit issues or
single requests like the elephant will
come into the room and slow everybody
down and we push GHC to ways that it's
never seen before and so we found
numerous low-hanging optima
Asians that we've sent back upstream
speaking of upstream we've actually set
the whole pile of things back upstream
so applicative do coming out in 8.0 is a
way to make haskell even more expressive
than just the monadic version allocation
long as I talked about garbage collector
linker unloading I've also been
improving GHC I Apple and so that was
all the technical bits but what about
people you know we had a bunch of
developers who knew how to use this old
system and like oh no I have to teach
them Haskell well we ran multi-day
hands-on workshops we created a so we
use Facebook the product internally a
lot for internal communications we're
headed a group a Facebook group for
therapy which is essentially our async
office hours so when someone has a
question they can post there and we can
respond and we were taking our old
language fxl and translating it into
Haskell so we had the mapping of what
function means what where so as a
developer would say I knew how to do
this in the old thing but I forget how
to do it in Haskell now and we provide
this rosetta stone for them to say no
control find here's the bunch of oh
that's the thing I call and I should say
that we not really cheated but our
previous language was already a pure ish
functional programming language so the
delta between that and haskell is not
what it would be from say Python or Java
to Haskell and so now today we have
dozens of Haskell developers writing
production code protecting Facebook
every day and that is our brave new
world
so hopefully I've given you a taste a
data point of how Haskell itself Haskell
in its implementation is ready for
industry I would encourage people to
think of Haskell as a tool in places
that you might not have thought of
before so many people were a part of
this effort some of which are sitting in
the audience today go around and say hi
any questions do Mike
Thanks um I've not done much Haskell but
what I can gather is that there is a
great scope for let's say creativity
when trying to solve a problem there's
lots and lots of ways to solve a
particular problem in Haskell which
we're perhaps wouldn't be present in a
simpler language so I think it could be
quite easy to create confusing code just
because you have all these tools you'll
dispose of all these different types of
high-level high order things how do you
cope with that problem or does not
probably not exist so that's I would say
that's more of a software engineering
problem than necessarily a language
problem so we have a wide range of
developer skills contributing to our
code base and we don't have a a solid
solution on this yet we don't have any
hard and fast coding style rules on that
we're letting people feel out the
language and the features that they want
there are a couple things that we
quickly try and steer people away from
as they tend to be code smells of people
say oh hey here's this brand new shiny
thing I'm just going to try and use it
and people who are more versed in
Haskell can look at it and say like you
don't actually need that you need this
over here so we do rely a lot of code
review to catch these kinds of things
but we do have people creating their own
data types obviously no one's created
their own DSL inside actually yet I'm
waiting for that to happen
does that answer question is it just
thank you
can I just ask what's the elapsed time
from first thinking we're gonna rewrite
this too I suppose the first in
production system sorry say again how
long did it take from first thinking
we're gonna rewrite this to production
so that depends what you mean by running
a production we we have a long roll out
phase so from starting the project you
know starting the prototype like is this
even possible to taking our first
production traffic was on the order of I
want to say 16 months 15 months did we
had dozens of connections that we need
to build out lots of infrastructure to
rebuild and then it took another I want
to say half year or so before everything
had been fully migrated
this is a follow-up to the last question
- you did a great job of describing the
technical challenges that you faced and
overcame what was it like on the social
side how did the team work how did you
get them together were there people up
above you saying Haskell what are you up
to how did it go
it actually wasn't too tough of a cell
it was clear that our previous
implementation was falling over and that
we needed to rewrite in something else
so we went through the the mental list
of like okay so what if we you know we
have a lot of C++ some structure let's
do in C++ or like we have PHP and hack
and I just do it and all that but we
really wanted to preserve since we were
already coming from a functional
language we wanted to stay in a
functional language given that sweet
spot in the design I mentioned earlier
and at Facebook we have this saying code
wins arguments so if there was enough
question of like I'm not really sure we
let people have the leash that they need
to go say look I just wrote it and here
it is it's working the time the
development time for just the prototype
between starting it and getting that
running was all I say less than a month
maybe a month it was that Simon Marlowe
or that was me and Simon yeah cool
I'm just wondering since you're running
Haskell at big scale if you've ever had
any issues with synchronicity threading
if all that just works not flawlessly
Rafi about tackling issues regarding
that issues around which exact running
most under 2000 of requests at once
basically trading and so on if there's
ever been a problem with husk no that's
the core of the problem that we came
across was allocation limits the single
threads coming in and breaking
everything else down and the garbage
collector can can handle what we can do
we have other ideas of how we can make
things even better I'm potentially
changing GC in a couple ways but it's
not a first order problem all right
thank you
did you have any problems with the
tooling while developing the system or
tooling as in no profiling debugging etc
no development wise IDs or I know we let
people use whatever development
environments they want these typically
are Emacs and developers so there's a
pile tooling out there but this is
definitely something that we're looking
very closely at to try and make it
easier a much more integrated way to do
these things we don't have any really
good solutions for that yet but that's
kind of a next stage that we're working
on so now now that we're in the Haskell
world now we can make this Haskell
platform more usable and hopefully those
things are things we can also send back
upstream looking forward it
hi so you've explained why it was not
necessarily as scary to try a new
language in this particular for this
particular task as it might have seemed
because of your origins with this pure
functional language you're using before
now you've reached this level it must be
very tempting to look out into the wider
organization and Facebook can say we can
solve all your problems to you I mean I
you must have done that to some extent I
mean in some sense my question is how do
you resist the urge to sort of tell
everyone else that they're doing it
wrong and that they should follow your
way with Haskell well that's assuming
that I'm resisting that but no no it's
you know the whole point is using the
right tool for the right job
and Haskell isn't necessarily the right
tool for every job you know this was
this was a data point showing that
running a DSL is something that Haskell
can do there are other parts that have
potential but there's not a clear next
step of like oh yeah we're gonna you
know rewrite entire PHP infrastructure
and Haskell and that's that's not gonna
happen but yeah that's that's definitely
something that I am the team are looking
at so you're looking for opportunities
to use it more widely and internally
yeah because I don't think people
realize that Haskell is a viable tool to
use and so bring the tool there or bring
the awareness and that'll bring the
serendipity of use cases
hi I might be wrong but I thought the
hack language itself had some background
in Haskell as well is that correct
which language so the the hack vm h h vm
was there was some work done in haskell
around making that performance is that
right i don't know enough about that to
say josh watzmann is here from the
hacked oak there he is he's right over
there you should ask him probably I was
just wondering what an interaction there
was with other teams at Facebook around
Haskell we have one other Haskell one
one other active Haskell team right now
on a different problem it is not the
hack compiler
hi you mentioned that you didn't want
the developer to explicitly specify what
is synchronous and what's synchronous
and stuff like that isn't developer
choosing to use magnetic or applicative
API is kind of specifying sink or a sink
you yes and no I see what you're getting
at with that the thing that I feel
Haskel really brings to this is that
it's very very easy to drop in and out
of the magnetic computation compared to
being able to do the same things in
other languages like doing this in Scala
doing this in JavaScript what have you
you have to lift essentially everything
into your DSL and that just gets
disgusting
and so our our computation does a little
more than just the data fetching we also
have some interesting exception
frameworks inside there as well they're
also part of the computation so if it's
if one of your computations does
something that's an exception in this
realm thing then it also needs to be
Minh addict it's not necessarily data
fetching in that stage but I see what
you're saying and it's the being able to
get in and out easily easily that is the
real difference maker here in my opinion
okay thanks
any other questions for John I've got a
question can you talk a little more
about the Rosetta Stone was that
automatic translation yes how did that
work
it was a Haskell program that read in
our entire source tree all of our source
translated it over to Haskell we had to
manually create a map of you know foo in
FX Ella was food this and Haskell and
then we given that map we could spit out
the source code as well as some I fear
was some markup language to display it
nice and pretty for people and how close
was that automatic translation to the
sort of code you ended up using how much
it was exactly the code we used the
machine translated code as our first
version for people to work on which had
its own fun little issues that were
making better how big was the diff
between that machine translated code and
sort of the code you ended up with the
people wrote by hand after that is an
ongoing story and another question I
have is this is a great story for
Haskell and it shows that you know
functional programming can make real
impact in industry
are there any takeaways for people
working in other functional languages in
industry Oh camel or closure or scholar
a nuisance
yeah I'm not sure how much translates
I'll be honest I haven't done very much
programming in many other languages at
least not to the depth that I have in
Haskell to know where the problems are
and ESL's are great use them alright
thank you very much John</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>