<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Exercise Analysis - Jan Machacek | Coder Coacher - Coaching Coders</title><meta content="Exercise Analysis - Jan Machacek - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Exercise Analysis - Jan Machacek</b></h2><h5 class="post__date">2015-11-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/GPvF8RUEJdg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so let's get started we built this
system I'm sure you will if you've seen
the talk you you recognize so we have a
mobile app and an app on on a wearable
device we have apple watch now and a
pebble and we might connect to heart
rate monitor or any other fitness device
that you might have we collect data as
users exercise we send the data to
further analysis into our acha cluster
they say where we keep all the state for
all the users we might run further
analytics we might actually learn new
things that's where the spark code comes
in so we have gathered data from all the
users they've told us what exercise
they've done or we do the hard work if
you know if you don't want to
participate and then that means we have
now improved our model we can recognize
more things or we can be more successful
in recognizing some other things we
recognized previously so we pushed the
model back to the mobile devices we run
the classification all right so we had
this we build this and it was great
right and then we actually took it to
production so to speak we have a local
gym and we gave it to users and yeah
what's terrible none of it I mean none
of it worked so much so that users
exercise and because we did all the all
the analytics in our acha cluster the
delay which was about a second second
and a half that made it unusable that
was the first problem when the users
finished their exercise on Oh what did I
do 23 and they hated the app second
problem was that sometimes we even lost
3g connectivity or any kind of
connectivity so the users exercised and
we did nothing what made it even worse
is because of these delays we had no
feedback on our machine lang learning
models imagine that you go to the gym
exercise for an hour and then you come
back and push the result to your mobile
and Singh you've done all of this stuff
but could you tell me what you did ten
minutes in well I don't know it could
have been something maybe nothing so
there was no way to improve it was
actually very difficult to improve our
our models we were sending all sorts of
unnecessary data over the network now
again from our testing we found out that
most users actually spend most of their
time in the gym not exercising that
that's quite bizarre right but most
people actually sit down so even though
they were sitting down we're sending all
these accelerometer and heart rate races
over the network which was completely
pointless we of course kept or amazon
infrastructure busy computing these
pointless things so that was costing us
money so that wasn't great so so sorry
in other words it was terrible so what
now well we thought we need to improve
the sensor and signal processing from
the devices we need much much much
social experiment cycle so the idea that
someone goes in exercises labels the
data or push it to our storage we can
improve our models retrain them and see
if we can reclassify everything that
needed to be much much much shorter what
we the code we had before it did this
would have been a day days exercise with
the improvements this is now you know
down two minutes and most of the time is
spent up doing the exercise which is
kind of what we wanted and finally no
experts ha so of course we looked at all
the accelerometer traces and we looked
at the graph so we eyeballed and we said
I know I know these are the features
that identify exercise surely we're
getting it right and so we humans
extracted about 15-20 features from each
exercise and we were getting it's so
wrong it was hard to believe so no
experts let's just build something a bit
better where I can just throw the raw
data at the inputs and you know outcomes
this was exercise B C or D maybe in May
alright so we've divided this is the
traditional am directed speed layer and
the bachelor speed lay should get
results immediately bachelors store up
the same requests and we do some further
processing on them so applied to to our
app this was what we had
this was the failing model so if
anyone's trying to you know build a
fitness and analysis AB don't do that
that's that just not going to work we
need to shift things around so it's not
it's going to be a massive change we're
just going to extend the speed layer the
thing that does the immediate analysis
and we're going to include the mobile
phones in it so we'll get the users to
do a lot of the computation for us and
we'll actually do it most of it on the
phone so imagine that we have trained
the model somehow we'll get to how and
we pushed it to the mobile phone now the
phone receives data from these very
unreliable devices but it can do the
immediate classification and so that the
only thing that goes to the server is
confirmation from the users ideally so
in the best case scenario with the users
will look at that phone go oh yeah
that's this is it or maybe even enrich
the information so we've computed that
the user has done exercise a and the
user might say oh actually I've done 10
kilos of exercise a that's great or the
user might say this was actually really
hard so we now have a confirmation that
this particular trace of data from the
sensors was exercised a but we have a
little bit more information for that
particular user so we then back in the
spark world we can then close to these
users and say actually we have let's
call them complete beginners never ever
exercised they behave in a certain way
they need different models and then we
have you know whatever groups of users
you might want to have in them in the
app that we have at the minute we
actually compute model / user because we
have so few users we can actually afford
to run the computation hopefully when we
become a billion dollar startup I'll
take 10 million it doesn't matter right
but we'll need to cluster the users and
say well actually let's run the same
number of training runs but we'll have
to punch the users together any case we
are doing now more on the phone so we
are resilient and responsive so here's
here's an example of
accelerometer trace that we recorded
from the watch this is I don't know what
exercises was but it gives you an idea
of the happy scenario nearly happy right
you can probably sport that there's
something odd going on here users don't
move that way this is you know 20 g
acceleration that's not going to happen
so that's kind of odd but ok this isn't
too bad this is worse so this was in the
pebble world and it's sometimes just
forgets there is no way to recover we
had all sorts of retry buffering we
tried many many many different ways to
solve the communication gaps but the
reality is that it just the hardware
just doesn't do it the original pebble
is you know 16-bit CPU you get all of I
think 16 k of memory for your program
and data and it's not a real time or
less so sometimes it just forgets so we
have to be able to deal with that and
then of course the final thing let's get
rid of human experts that really didn't
work for us so let's let's move it back
and let's let's get rid of all of this
horrible stuff and let me show you what
we've actually done so we have sensor
data so first stab at the sensor data
that we had this was in C++ and we used
opencv and we used opencv for
convenience because it had all of the
signal processing functions baked in
this is great we can do smoothing we can
do frequency analysis in just one call
what we sort of missed out is the memory
layout for these devices isn't
completely great in opencv or at least
in the way that we've used it so if you
think about recording matrices so like
the samples think about columns of you
know x y&amp;amp;z and the rows represent the
number of each sample one two three and
so on add to it heart rate add to it
rotation well then it becomes much
easier at least for the for the hardware
to encode it as a sin
array with a stride into the array so in
the first element we have acceleration X
and then the second element of that
array we have Y and then Z and in the
fourth element we have X again as though
it were on the second row now that turns
out to be really really really useful
for you know doing all the analytic
functions in using the DSPs and vector
libraries that are available in the
hardware so we'll actually get to see
this but the difference between doing a
naive loop or you just iterate over all
the elements and apply I don't know
exponential to to each or the element
versus using one of the blasts or vector
lib functions is order of magnitude so
you know it takes 100 units of time to
do that in a in a in a loop and it takes
one unit of time to use one of the
vector or blast functions to do
something that that we find useful so
that was the first change to encode it
in the sensor data structure and then we
have the actual classifier so we use
multi-layer perceptron and the code that
runs on the phone is just the forward
propagation so we give it to the trained
model with the structure of the network
the way it's the biases and the
activation functions and when given a
block of sensor data we spit out a
result of exercises that we've
classified in the data so this is this
is quite nice writing your writing this
code feels really great unfortunately it
gets slightly worse because then it sort
of needs to wire into the rest of the
iOS code and if anyone has been writing
objective-c yes it's just it it has
these horrible names so did end versus
end it it's just terrible but but of
course we didn't want to go against it
this is bad enough this is worse so we
who here who here has done hibernate in
the world of Java excellent this was
this is core data this is sort of like
hibernate but
much worse it's like I bet it's terrible
in any case that the data has to persist
because the devices might be out of
range and I get to travel which isn't
glamorous at all because I arrived
somewhere I go so how much for a
megabyte you mean three pounds you know
so I need to store the data on the
device that I can then send to the
server that I can use to improve the
model so all of it has to be persisted
and it then gets even worse you think
Swift this is nice right Modern Language
immutable functional and then we do that
sort of horror we take a nice array and
we construct an unsafe mutable pointer
for it and we just grab the memory and
then we're going to do something with it
nevertheless those of you who have sort
of played around with some neural
networks and machine learning you might
recognize these functions you might
recognize sigmoid you might recognize
hyperbolic tanh you might recognize real
this is done in one take this is all the
support that you get either in the DSP
in the hardware or in fact lip so this
stuff actually runs at pretty amazing
speeds on the processors and on the
devices versus actually typing it out in
a loop the price you pay for it is that
horror of pointers but it's worth doing
and if you get the structure of the
input data right you can just sort of
stride into the array so you can say for
every element this case here we have
stride one so every element if I wanted
to do just X's and I had three elements
in the array it would be strike three so
every third so that's that's all really
quite useful and then we have xcode and
it's all just these are hideous in any
case that's that's the mobile side of
things some of the exercise so this is
what what it looks like when you
actually collect data so these are the
traces again the stuff at the start
where people set up and then they do
however many things that they've done so
even if
as a human so this was our starting
point right as humans we looked at it
never mind what these actually are so
that's actually easy to recognize right
it can spot groups of exercise and so
say okay well okay one and two look
similar than three four five same kind
of thing so really our starting point
was collecting all this data and then
saying surely a computer must be able to
do that if we can do it as humans and
the rest of it was was implementation
detail all right next up we have the
vehicle cluster which receives all the
data persists the state so we say we get
data from the devices that are confirmed
classified labeled data Sicily the
device has computed what it is and the
user has confirmed now in our world
users confirmed by not doing anything
because the idea is that run the app you
get on with it there's no fiddling no
buttons involved I had to look at many
many other apps and the whole process of
exercising was go to the gym okay so
suppose I want to do you know let's
let's lift a bag I ass complicated
exercise okay so what are you going to
do okay I'm going to lift the back so
you have to look look it up in the list
ok how many repetitions are going to do
I don't know three all right how heavy
is the back okay really I just want to
get on with it so again that's the main
motivation for training so we have used
in physiotherapy where the users
actually under someone's guidance train
it we have the luxury of per user model
so you can take the app say I'm going to
do this physiotherapist does whatever
exercises the user has to do the
restriction of course being that the
sensor has to be on the limb that moves
and then they save the data and then we
compute a new model that we can deliver
to the phone and so the next time the
user exercises again we cannot yet give
quality measurement so to whoever is
doing the exercise we can't say no
you're doing it well you're not doing it
well you need to do five more but we can
actually measure progress so the next
time the physiotherapist
the patient and say oh okay so you've
done all this stuff well done which is
actually quite good rather than you know
selling this stuff to people who can
afford to buy Apple watch to go to the
gym anyway I get cynical so all this
data ends up in our in our occur cluster
which we persist into some sort of
Journal and then we load the read the
journal for all the users and we compute
the new models in spark so I'd see how
it's done data arrives from from the
from the sensors rather from the mobile
over the internet through vlb and then
we have let's pick two services just to
illustrate a point we have I'll get it
wrong exercise service and profile
service I bet they're the other way
around but let's see what they do and
then of course we have push
notifications we could build in some
sort of social media something that's
not all right no no I was right okay so
the the orange one is user profile so we
receive use a problem typical stuff
register what's your username and
password and whatever biometric data
that we collect about you hits the user
profile service which in anoka and
sprays talk is the rest api rights a
thing that receives HTTP requests and
somehow turns them into messages that we
then sent to the other components in the
system use a profile processor in the
sea QRS world is the validator right so
we check that I don't user name isn't
yet taken that's that's Annie easiest
one and then we have per user profile
right so we then treat this distributed
state all the user profiles as instances
or we use a profile actor and these
three lines that's that's the little
magic of cluster flooding we have as
many machines as we have as we want to
have three in reality but you know as
many as you want to have and each
machine has some number of user profiles
living on it these are the views on the
data that's kept in a journal and in
snapshots excellent no no user profile
exercise service that's that that's the
thing right I know you use a
registration anyone can do it it's a
it's a it's a practically the same story
the difference is we have a user x
sighs processor / active exercise
session so when the users to us I'm
exercising and if we have internet
connection we can give them more
feedback so the motivation in future
versions will do some sort of
motivational messages more harder
something on those lines and then we
have views on the same data so this is
analytics so someone might do the
exercise session say okay so what have I
done let's review all my exercise
sessions let's review my exercise
programs let's have a look at how much
weight I've lost gained whatever your
thing is all right so we'll ways through
the code to me this is readable
hopefully to you who have yeah
everyone's happy okay stunned silence
that's good too usual business api's
right get and post so i can check
particular user i can set an image i can
register an iOS device for push
notifications i can register an android
device for push notifications that data
these HTTP requests got tended to
messages that this processor actor
receives this is the validator right so
let's let's go through a registration
folks someone clicks now I want to
register all right that's nice and easy
first best-case scenario as far as our
program is concerned the user name is
already taken we have nothing left to do
we check whether the accounts already
contains the email address if it does
reply back with a value on the left that
says user name already taken that's some
sort of 400 message that goes back to
whoever whoever's requesting it slightly
worse for us is a scenario where the
user register message arrives and we
don't have the user account so we have
to do something about it persist the
message so it ends up in the journal so
this guy crashes we can replay back and
never forget anything we will create a
new user profile in the in the cluster
will mutate our accounts stable sailor
snapshots just so we don't have to do
this over and over again and reply to
the API to whoever called us with a
value on the right that gets translated
to a 200 thank you this is your uuid
excellent and that all works really well
if only we had if we only had just one
note but this user profile processor
might be you know on multiple nodes and
it is into in fact there's one on every
node and that was good except there is
this thing right user accounts this is
our state even here so as a fancy name
known accounts but imagine a map one out
now if I register on this note that's an
okay you registered it ends up in a
journal or jolly good now the second
registration message goes here say with
the same email address so i won't be
able to detect it this middle case is
actually a nice happy scenario because i
save a snapshot every time i register
when this new user profile processor
that sits in the middle gets created it
gets recovered from the snapshot so it
sees the state that you know whatever
the last snapshot was in so to make it
work we have to connect them with some
sort of message bus that shares the
state and you might be thinking I this
is how it's done encoding you might be
thinking well it could be inconsistent
oh yeah it could be in this case we
favored availability over consistency it
has to be partitioned torrent right
because we're on amazon i don't like to
pay money so we're on the cheapest
machines so they will fail and I'm
thinking this is a billion dollar
startup idea again I'll take your checks
after the talk um so let's let's be
available right let's allow the users to
register let's allow the system to stay
alive even if thousands and thousands
and thousands of users are registering
it means that there is the odd user that
will fail right so this guy when a
message is received from this pub sub us
from someone other than me this is where
I have a chance to detect that's I've
let someone else in it's too late
because I let you let both of them in
but I can do something about it here my
thinking is this is a user interface
problem we'll just forget the other user
but your program might want to do
something else use a profile this is now
the same story it's a state now this is
a nice this is a lot easier I have an
actor that has a fire state so it's this
mutable state the state is encapsulated
inside the actor the actor is
distributed across my cluster using
cluster shouting and all I have to do is
send it messages and then it's nice and
easy because I mean consider this if you
went to the pendulum talk one of the
points was let's not do all this busy
work by that i mean if i have a user
that is register on my system and I say
okay give me my profile well I don't
want to go to the database to load the
profile because well I actually have it
here it's in the state the state lives
somewhere in the cluster and the cluster
the cluster sharding code actually
ensures that this will get removed from
memory if it's not used very often so
you don't want to have all these users
in memory but this is nice and easy way
of doing it right no select star from
something or MongoDB internet net income
um it's all good it's all good we just
replied with what we have in memory all
right exercising it's the same thing
like we receive a session assisted and
then we can do something about it so
that's the that's the upper cluster now
we have spark now now what right so we
have all this data all this labeled data
and we need to process it I said that at
the minute we around the training
program per user so if all of you
download the app and if you have the
secret URL that you can send the data to
and we will train the model for you for
your exercise so if you decide to do
something completely crazy we can
recognize it for you specifically so
that thing how do we do it well first
thing that we need to solve and if
you're writing these these kinds of
systems first thing you have to solve
this the journal now it's it was all
really great in the in the scholar world
when I could say persist so have some
message persists in the journal and then
read it back
great does anyone know how it works by
default what assistive what happens then
so the horrible secret is that the
message gets turned into bites okay so
far so good using Java serialization and
that's terrible right so then all I have
to do is add one more field that's it
boom or even use different version of
scholar which is usually a problem
anyhow but but but on top of everything
right now you can't read your messages
from the journal so that's a bit of a
problem and it's slow did i mention that
it's terribly slow so that that monster
in the journal right if you just keep
persisting things into the journal and
want to read them it will fail
completely so we want something better
something it's fast stable compatible is
a bit of an old word right but if you
have let's say you have your shiny new
arca cluster that uses skoloff to
whatever it is 12 or Dottie or something
but then you have to analyze it you have
to run it in spark and spark is slightly
more conservative in its users of
scholar so you might actually be a big
point version of scholar off and even if
somehow you managed to you know get
everything built on the same version of
scar this is a bit of an architectural
smell right you don't want to be in this
fragile position so you need to have
code that can read both things you also
need to have code that plays well with
all the libraries that are baked into
spark so if you're thinking i know i'll
use creo i know i'll use protobuf i know
i'll use this you have to be very
careful and select by process of
horrible trial and error version that
plays well on both sides what does work
at the minute is creo and chill so
crayon chill is a library that defines
particular format that is compatible
both on the spark side and the scholar
side and all that you have to do in your
configuration is say these are the types
that our car should use to persist
messages in that particular format and
then you can read both ends on the spark
side as well as
skala side so that's actually quite
useful which was a really painful
exercise well now what now we have all
the events in the journal so now we can
read everything that we persist which is
kind of nice we add to it the spark
analytics code for Cassandra and now we
get to see event table which is
everything all the events that got in by
calling persist excellent well except
now of course it's every event so we
need to do something more about you we
need to write this program that we then
submit to the spark cluster in a way
that filters out maybe some of the data
that maps them it transforms them in a
useful way maybe like this so what we
want to do we want to read all the all
the events that we can't escape from
that but we only want to pull out those
that represent the entire session I so
the abuser when they stop exercising
they say ok I'm done the mobile
discovers that it's online it submits
all the labeled data and we have it
right so this is all the accelerometer
traces with the right labels with
confirmation from the users so we want
to take all the events that we had and
leave out pick out only the ones for a
particular user will only pick out the
correct examples of these are the
confirmations yes the user has said that
this is indeed exercise so-and-so group
and by user ID remember doing it per
user and then ok you might start with
just dumping the files in a CSV file so
you cloned the code and you run this and
out comes a collection of CSV files that
have essentially accelerometer traces
and labels or now what well this is what
they look like right so I took a few so
you might run a program and again I'm
completely unfiltered data this is what
actually arrives from the sensors
and then you train it I will get to
training program so we have actually we
haven't this was in the days before the
spark MLP implementation now there is
actually a multi-layer perceptron
implementation in spark that you can
paralyze so unfortunately we don't do
that yet we do really stupid
parallelization and the MLP the back
propagation is done in one thread if you
like and we paralyze very naively per
user we have a hundred so that that kind
of adds up really well now on these
exercises that I've selected we're doing
actually really pretty pretty well now
they're big exercises and you know tuned
for this talk but even with larger
exercise sets the success rate is
actually really really really good okay
here's another one except this isn't any
old exercise the big problem that we
have is exercise versus no exercise so
uses a walking around right I can pick
up something into exercise and then then
I stop now if the users just stopped and
did that and not moved at all that would
be kind of nice but they don't they keep
walking around and fill with their
phones so we need to find a way to
detect exercise from no exercise now it
wouldn't make sense to build classifiers
so want one idea is say okay well we
have all these classes exercise ax BX I
see we can train the multi-layer
perceptron to recognize a B and C we
could add one more label d that has and
everything else but it's actually quite
useful to balance the number of inputs
for each class so you'd have to have
lighter you'd have a hundred inputs for
class a hundred examples of class b
hundred examples of Garcia and now
everything else presumably everything
else is quite a lot of things so that
doesn't really work what we have at the
minute is two classifiers one that does
exercise versus as we call it here
slacking which is reasonably successful
right and exercises all the exercises so
we only have two two classes and given
our training it is it's not
too bad and then only for the blocks
where you know we do exercise we
actually attempt to save here's what it
was all right um you know what you know
what you know what we have a we have a
demo how about that don't worry I won't
exercise so okay so we have this switch
playground this is the first thing we
want to do so I have let's let's run it
right so I have collected some data and
just to see so here's one so this is x
axis you know the stride zero the first
honest if I change it to one will go
element 1 and then plus three which is
four and then plus three which is seven
and then I'm lost but you get the idea
and this is a thousand samples we sample
at 50 Hertz or rather the hardware here
samples at 50 Hertz so you know this is
what I don't know many many things this
isn't my good day and anyway here's what
it looks like so um how about this
classifier right so it should be really
easy to just uncomment that now I've
built one for for the demo it's called
demo so what's happening here right
that's a look it has this named thing
and then it has layer configured labels
so labels that's probably pretty clear
these are the three classes it can
recognize whatever they may be right
Leia conflict well that sort of looks
like the number of perceptrons in each
layer so we have 1200 at the input which
means that we throw at it 1200 values so
400 in x y&amp;amp;z because we've sample at 50
hertz it is eight seconds worth of data
so we looked at all the exercises that
users do and even big exercises like
squats they take less than eight seconds
but to put another way if you're taking
more than eight seconds you're not doing
it hard enough and we won't recognize it
but we have 1200 the input and we have
three layers three neurons at the output
so three labels out will come three
numbers and the last thing we want the
difficult stuff is the weight sexual
at how we load it we grab the weights of
type role button' you know just an array
of floats dumped into a file and those
represent the weights between the new
neurons in the layer so presumably we
could just run this now again well the
same thing well that's that's what you
see this is not good I mean luckily
practiced so this is okay what's
happening is that we're missing this
file demo alright so we're trying to
load this no no no no no come on you
were trying to load demo from the
resources which represent the weights
and we don't have one how do we get our
hands on this model well we train it
right nice and easy so we have a whole
bunch of Python code that I can run that
has the labels I me show you the late
the data first so let's try that right
this is the model that we're going to
train and it has exercised and as I said
this is nothing to complicate it right
it has the accelerometer traces and the
label nothing else to it owns a whole
bunch of labeled files so that's all
there is to it so we just run this
Python program we give it the data it's
where it should get the labeled sources
we have some visualization can see it's
going to all look wonderful let's just
write okay so here are examples yeah now
it fails again so the problem in this
particular case is what I have deleted
is the way in which we construct the
network so if you notice again I'll get
into details of it delay the network
that we've constructed and it matches
has to match the iOS side we have 1200
inputs and then we have a layer that has
250 Iran's the one below and then we
have a hundred and then we have a three
so looking at our Python code this is
nearly right right 250 middle a defining
an activation
function so this is just a threshold and
then we have another function 100 euros
lower just a threshold again and what
we're missing here is the final one just
to construct the entire network now
based on you wouldn't normally type it
in code right so if you're actually
running this at scale you need another
program that discovers what the best
shape of this network is what are the
best what are the activation functions
that it should use we have a sigmoid
here at the output so now I can run my
training program is going to load all
the data and there your it's going to do
things so we have 10 epochs with all the
labeled data that I have running through
network that 1200 that has 1200 inputs
and 250 hundred and three of the output
with these biases and activation
functions well that going to give out is
you know spit a couple of files that
represent the labels the shape of the
network and ultimately the weights
that's that's what we really wanted to
do now and even there you go so this is
actually doing pretty well all right so
from all the exercises it gets it wrong
0.7 percent of the cases which is not
bad at all so they can download this
program download the training data and
have a go so can actually see what it
spat out there's an output directory so
here's an example so I just picks this
the same chance that you've seen in the
talk so this is one of the examples that
it picked out it also produces
evaluation so this is how we're doing
with that data set so this is like less
massage than the one you saw in the talk
where these were zero something that's
just not going to happen right this case
we get it right for biceps curl in nine
hundred cases get it wrong in 10 so this
is doing reasonably well and finally we
have the weights so all I have to do yes
this is all very nice so all I have to
do is drop in the weight file like so
and presumably that will be it right so
i can now run the play round again
just going to load the weight in my
classify and all will be good right
there we go okay that's going to look
the same alright alright alright so it's
done something we have some output on
the on the console all right well hockey
it would be useful to have smoke right
so let's actually do the classification
result is class if exercise classifier
come on does code completion but it
likes it plus if I this is the sensor
data block let's have 10 results of the
most doesn't really matter because we
have three labels anyhow this throws an
exception so we can just make it shut up
by saying try bang which is essentially
try and catch a non catch fatal error so
that's kind of nice right is proper code
we login we don't even log the exception
we could just crash anyway and then for
the result for each let's print that
thing all right see I mean Swift is it's
annoyingly almost good it's like tiny
old with bits are missing it would be
ever so useful not to have to construct
a function literal here but ok so we've
done the classification but I now if you
look at the result so these are the
classification results for each window
as we run this 400 pixels 400 samples
long window says okay well that's good
but this thing here that really
shouldn't be happening right i was
expecting number between 0 and 1 not 26
is kind of good right i mean it's super
like three thousand percent sure that
it's the right thing but it gets well
Kyle Evans not too bad right so it seems
that we have some sort of problem in the
way that we run the evaluation and the
problem is that i've been trigger happy
with delete at our activation functions
so I remember what I said about vector
libraries and vector code particularly
in iOS right we could have written just
a follow up here right so for every
element let's do
i don't know i mean real it would be
easy hyperbolic tanh would be nice and
easy but it would be it is even better
to use the vector functions now if you
look at their prototypes they actually
do look a bit scary right an unsafe
mutable pointer float too unsafe pointer
float too unsafe pointer you and fetid
air just looks angry it's because the
direct translation of the blast and
spars blast and vector clip code that's
been with us since the days of Fortran
so actual actual implementation then
goes to you know a pointer to float and
const pointer to float so the only thing
to make it work in Swift is that you
have to do this point of gymnastics
really to get it to work well now that
I've successfully pasted that in we can
go back to our worksheet and hopefully
we'll get some reasonable results so
let's see again same thing we've seen
before on how it looks better does it
yes so these are the actual results
where the much better confidence we
don't predict repetitions just yet in
that code but of course there is code in
the playground that you can have a look
at that does repetition situation now
this is all really good and we're nearly
done I promise but the actual demo of
course is the thing that moves now again
don't worry I'm not going to access sort
of difficult to see what I have on the
watch but so this when you run it at
least in the bloody hell that's a little
ambitious isn't it alright so when you
run it on the watch but a little you can
see that that connects
a different simulator 1m that
oh come on there we go right so this is
the user interface that you would get on
the watch now if I were doing it for
real just press Start and get on with it
recalls the accelerometer data keeps
them in memory let's not do that now
mainly because the simulator doesn't
have accelerometers support which is
really great isn't it now mind I can run
the controlling application and start
demo and these are actual accelerometer
traces that I've recorded when I press
one of these buttons is as though i've
done that particular exercise asks or
how much crisis push that in we run the
classification immediately on the device
and this is it's actually fairly
miserable to see isn't it just so you
believe me it actually done that it has
actually done that the length of time
and what it was I can do another one and
there it is today I can now stop the
session and if I had everything wired up
this would then go to the server this
has now stopped the session is over
because I press stop and watch but now I
have confirmed examples that are stored
in the database on the device one
connected to the server they end up in
our acosta which end up in a journal
which end up in a spy program and I can
spit out a new model with improved
classification so so that's it there are
a couple of things that are missing how
to find the best shot shape of the
perceptrons it's magic how to train it
at speed right so you have thousand
users that's magic how to get the
training data that in particular is
magic how to build the infrastructure
magic actually not magic come and see it
at scale exchange will have all the
infrastructure with GPUs alright thanks
very much
yeah I think we're out of time so we can
take her questions offline thank you for
the very cool interactive demo and I
play it Idol keep clothing as the code a
look</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>