<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>VM Tuning, Know Your Engine - Part II: the BEAM - Erik Stenman | Coder Coacher - Coaching Coders</title><meta content="VM Tuning, Know Your Engine - Part II: the BEAM - Erik Stenman - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>VM Tuning, Know Your Engine - Part II: the BEAM - Erik Stenman</b></h2><h5 class="post__date">2013-07-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/RcyN2yS5PRU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yeah so this is part 2 of a long series
of talks about the airline runtime
system so the engine tuning part will
not come in this talk so sorry to
disappoint you this is the know your
engine part so I will talk about how
things works a bit so that in future
talks we can talk about how to tune the
engine and the first talk was given at a
cloner Tech Talk and in San Francisco so
many of you might have missed that I
will do a short recap of some of the
things from a first talk which was about
processes and garbage collection and
then we'll talk about the beam today so
this is a picture of the engine in my
car and this is sort of the way I guess
most people look at an airline runtime
system you can open the HUD but there's
sort of nothing there that you can do
anything about because you don't really
know what it is so basically I have this
huge engine that does magic things and
somewhere I can feel water and oil
probably not oil but water that's what I
can do here so without knowing exactly
how these this thing works I cannot tune
it so the idea here is that slowly we're
going to learn more and more about
airline runtime systems so that we can
tune it for the applications that we
want to run so I started writing airline
code in 94 and then I worked on the
first native code compiler for a line
which is called Jericho that no one has
heard of it was the predecessor of hype
so then I wrote most of the second or
parts of the second native code compiler
hype and then I went to
Lausanne and worked on Scala for a while
but that wasn't really my world so I
came back and have been working with
airline again since 2005 for a company
called Kelowna and now I'm writing a
book about airline run time system
because while working for Kelowna and
trying to keep this 24/7 service up
there's all the time
questions coming up why is the system
behaving like this why is this behaving
badly and how can you make it better and
without understanding the airline
runtime system we can't really do that
so I'm now writing the book I wished I
had had by my side during these last
eight years or whatever it is and also
presenting parts from this book at
conferences so I can get feedback so
please come and talk to me afterwards
what you want to have in the book and
what you think about the content that I
present here so hopefully there will be
a book in February at Riley's for their
long runtime system so what is their
line runtime system this is not that
long right this is the heating in my
home it's a bit complicated but you can
see the a long runtime system as source
code so if you download the source code
for a line of TP you will find the arts
directory and then you find the emulator
directory and in there you find the beam
directory and that's where most of the
funding resides there's also the pipe
directory with the night native code
compiler so the best way to
to learn about the airline random system
today is to actually read this source
code you can also see the Alan random
system as components so we have the beam
interpreter which going to talk about
today we have processes we have the
scheduler the garbage collector the
native code compiler the input/output
system and so on so previous talk was
about the garbage collector and
processes and future talks will be on
the scheduler if I ever understand that
piece but it will be challenging so in
Erlang we have processes this is sort of
the most important concept in the
language and conceptually in the
implementation of processes they are
just four memory areas and a pointer
there's a stack a heap in male books
where you receive messages and the PCB
that process control blocks with flags
and information about the process so a
third way of looking at the airline
random system is as memory areas so we
have the code which we you can find in
the at it's directory the C code there's
a C stack for running this code there's
lots of queues and there's binaries and
then there's processes and the beam code
that is loaded into a system also
resides in memory so if you look at the
process we can refine the view a bit so
there's actually one memory area for the
stack and the heap they drove towards
each other and then the message queue we
can refine this a bit more there's
actually not only one message queue but
let's look at it like this and there's a
native stack
which is actually the C stack where you
can run native code on the process so
that's about what I'm going to say about
processes that I'm not going to talk
about garbage collection so you can see
my previous talk at San Francisco you
can download the video or stream the
video for that one to know more about
garbage collection but today I want to
talk about the beam interpreter so beam
is a garbage collecting reduction
counting non-preemptive directly
threaded register virtual machine if
that doesn't tell you much I hope it
will tell you something after this talk
so I'll talk a little bit about each of
these areas and we'll start from the end
so beam is a virtual machine that is
it's it's not implemented in hardware
that's basically what it means I mean in
the name beam it's a it's actually from
the beginning bogden's Erlang abstract
machine named in same way as warrens
abstract machine which was the prologue
machine and here abstract machine means
the same thing as virtual machine but
you could actually argue that there's an
abstract machine is more mathematical
concept and a virtual machine is an
implementation of an abstract machine
but I'll use those words as ever I feel
like so let's say it's a virtual
machines and the one small problem with
the B
compared to for example the JVM is that
there's no specification of the beam so
you can see it as a problem or you can
see it as an advantage so it's hard for
anyone else except the people who
actually know the implementation of the
beam to come up and make a new beam that
can run a line code in exactly the same
way as airline OTP does because there's
no specification to follow on right you
have to actually look at the C code and
see what does the C code do and then you
have the thing
hmm is this really something that has to
be done this way or does it just happen
to be done this way in this C code can I
change it if I make another version of
of the airline virtual machine or not so
a specification would be nice if you
want to have many beams but perhaps we
don't bond many beams because we have
one stable one and everyone can work on
that one instead and hopefully we can
get everyone to work on one project and
get it as good as possible and also
since there's no specification OTP can
choose to change things without warning
if they want to which team I think is
good and other people might not think is
good but it's at least they won't break
the specification yes
well yes but there's not a language
specification as such either so yes so
it's a virtual machine anyway there has
been attempts to actually implement it
as FPGA things like this as physical
hardware but I haven't seen anyone
running anyway so beam is a register
machine and it's not a stack machine so
in a stack machine you have a working
stack and every argument that you want
to work on you push on the stack and
then you operate on arguments on the
stack and it's very easy to compile to a
stack machine and it's very easy to
implement a stack machine so I just
wrote a blog post about the beam
dispatcher and there I have an egg
really simple example of a stack machine
written in C and a compiler for that
stack machine so if you are interested
in how to write this simple stack
virtual machine you can look at my blog
but a stack machine then pushes
everything to memory and pops everything
from memory and if it needs to use
arguments out of order it needs to swap
them around on the stack in order to get
them in the right order for the next
instruction and so on with the register
machine you don't have to do all these
memory operations instead you keep your
arguments in registers and all your app
operands take actually a register as an
argument and hopefully this can be more
efficient and if you really tuned it it
will be more efficient but it's a lot
harder so if you just want to write your
own virtual machine a stack machine is
probably the best way to go first and
for a line also the first virtual
machines like the jam was stack machines
but the beam is a more tuned register
machine and it Maps some of the
registers to real physical registers in
the hardware also so if you're running
on x86 architecture for example you will
get nice mapping of registers to real
registers in beam there's two types of
registers X registers and my registers
and white registers are really the stack
so the the terms X register and buy
register also comes from the VAM the
prologue implementation and if you want
a a function need to save its argument
when calling another function it writes
them to Y registers and these buy
registers has to be allocated on the
stack also so the allocates space on the
stack and writes them so the beam
actually
stack and of course it has to have a
stack in order to be able to have
function calls save the return pointers
for the code so there is a stack even
though it's not a stack machine and
there's a special register X 0 which in
most of the beam code and in
instructions is called R instead and
it's the accumulator where you keep
arguments to functions and to operate
operations and then there's some special
purpose registers like the heap top the
stack top I the instruction pointer
keeping track of where you are in the
code F calls which keep track of the
number of productions will come to that
tune and then there's also floating
point registers for doing Floyd floating
point operations within a function
so now we come to sort of the meat of
the implementation of the beam and beam
is implemented with directly threaded
code so instead of having a big switch
statement in the code that looks at each
instruction and see what instruction is
this and I'm jumped to the right place
in the interpreter or call the right
place in the interpreter to do in
interpret that function the code
actually contains pointer to each
instruction to be run so we have the
instruction register instruction pointer
register I pointing to an address in
code and here we have some code that has
been compiled this is in between two
functions calls in a in a small add
function and what it does is move the
accumulator register to another X
register then it reads up a caller saved
register that is saved before during a
previous call to an extra register to
the accumulator to have it ready for the
next function call and then it saves the
value the return value of the previous
function call on the stack so moving
into Y register so this is not really
what it looks like in the beam I just
try to make the example a bit easier to
understand but it almost looked like
this
so these instructions get that you have
in the external format actually
rewritten to
other instructions so the move x0 is
actually a move or instruction in the
loaded code and in the code of this
function then at the address 1000
there's a pointer to the implementation
of the move instruction and then there's
the arguments to the function and again
this is not exactly what it looks like
there's a special instruction for moving
the accumulator register 0 and these
offsets are actually byte offsets but
conceptually you have a pointer to the
implementation and the arguments and
then the next instruction pointer to the
implementation and arguments and the
next move instruction pointer to the
implementation and arguments and in the
beam op emulator there's a move
instruction so in this case it would be
moved from X register to X register and
this is another lie this instruction
doesn't exist but we don't really want
to go into exactly how this looks in the
beam right now but imagine that this
instruction existed it takes argument 0
reads the value in the extra reserved
pointed to by the first argument in
instruction and writes it to a second
one increments the instruction pointer
and then jumps to it so the Arg and
macro reads the nth word from the
instruction pointer plus 1 for the
actual instruction that we're there and
then you get an airline
out of this and they go to instruction
takes this instruction pointer and jumps
to it and this is something that I was
confused by yesterday when I was reading
the code again so it says go to star but
go to star is the way to say jump to an
instruction point or not dereference the
pointer here because it's already
dereferenced here so you increment the
instruction pointer to point your next
instruction dereference it get a pointer
to the next instruction and then use the
go to a pointer construct in c so then
it will take i plus three and read the
next address and jump to that address
and there is the implementation of the
move to from a white register and then
it will read increment i be the next one
and jump to the last instruction
was that clear was it new did everyone
know this no scheduling so I'm not going
to talk about this schedulers per se
that's for a future talk but the basic
is that in a line you have pre-emptive
scheduling so you write your a line code
and you don't need you think about this
function needs to yield and let some
other this process need to yield and
let's mother process run you have all
right you're a line code and then you
hope that the beam emulator will
actually preempt the process and let
other processes run so that you get
concurrency but on the beam level it's
not really pre-emptive anymore so it
will only yield it will yield at
specific places in the code and it will
determine when to yield by counting
reductions so for each function call
that you does do in in the code you will
use one reduction so since there is no
way to to create loops in a line code
without actually writing a tail
recursive call or a recursive call of
any type you will actually use
reductions also in loops because that
will be a scene of function calls now in
the compiler some of this is taken away
but not reduction counting so you will
actually have a loop in the code in the
on the beam level but it will still see
it as a function call and count
reductions for it and when you enter a
function then beam will test have I used
up all the reductions that I had for
this process and in that case
the process will yield and just upon
entry to a function the process state is
always in a nice known state it doesn't
it's not in the middle of creating a
topo on the heap or have allocated some
memory that it's us and start using or
anything like this and all the arguments
are nicely tagged and you haven't broken
the run part so in my previous talk I
also presented how the tagging scheme
works in in Erlang so to keep track of
the types each word each term has a tag
that tells you what it is but for beam
to actually work on on integers for
example and to add them
he needs to untag the the integers and
then add them and then tag them again
and and so on and you don't really want
to yield while you're doing operations
like this so that you have untagged
pointers to the heap laying around in
memory because then if someone else
inspects your process from the outside
doing back trace on it or it needs to D
do garbage collection for some reason
things would go very very bad so it's
only at very specific places that beam
will actually yield a process or trap as
it's usually called in the beam code and
it's not really defined what the
reduction is but it's a function call
but then there's other things where it
should be a small piece of work and it
should be incremented each time a
process does some work but for some
beefs and if you write your own NIF's
for example you might actually do
of work without incrementing the
reductions and that can become a problem
because then the process will not yield
so yes yes
next time it comes back it will have
what it is 4,000 new reductions to burn
I think it sound we it does burn is here
so yes
so but it might be actually that it
checks for less than one I'm not sure
doesn't really matter but and I think it
gets four thousand reductions each time
it's scheduled of course if you do
receive and you don't have anything in
your mailbox or anything that matches in
your mailbox then the process will also
yield yes I think so there's a airline :
yield yes you can also bump reductions
so if you call term to binary for
example with a large term it's only
counted as one reduction and then you
can do bump reduction size of binary
afterwards to actually use the number of
reductions that you needed or you wait
for a next release of airline which will
actually count to the right number of
reductions for term to Byner
yes any more questions on yes yes
yes so I think I'll pass that to John
beep yeah it's already in Coraline I
think it's becomes function calls yes
yeah so it will actually if you ask some
running process if you do I in the shell
for example if you have a process that -
term - by neuron a huge term for example
and you do I in the shell that collects
information you will see that the shell
actually hangs for a while because it
will wait for that process to be in a
state where it can query it so those
bits that actually query processes will
only do it when there are only nice
state also so then the other process
will also hang yes and you're supposed
to do that definitely and you should be
able to yield from an if but also there
you have to make sure that you leave
everything in a nice date but if your
NIF is doing a lot of work count
reduction and yield that or wait for the
what are called schedulers the new
schedulers for r17 the darky schedulers
yes for your Biff's
nips
and then there's the whole thing about
how the schedulers actually work
choosing the next process to run and so
on and then we'll not talk about that
now in airline code you don't have to
worry about memory management almost at
all so magically behind your back there
will be garbage collection done and
garbage will just disappear some slight
problems with binaries if you don't
really think about it carefully you can
actually have binaries hanging around
for a long time but basically you don't
need to worry about memory management on
the airline level and if you do usually
do it like spawning a process and let it
die and then you will quickly get back
the memory that that process uses but on
the team level you actually have to
allocate memory or make sure that there
is memory on the stack and heap so you
have to check that the stack pointer and
he pointer don't pass each other so they
were growing in the same memory era
towards each other and when they meet
you need to do garbage collection so
there is an instruction test heap that
you can use to make sure that you have
space for your topple or whatever you
need to put on deep if you generate pin
code yourself not recommended but fun
and then under the garbage collector
there is a whole big area of memory
alligators like 14 of them or something
like that that you can give thousands of
flags to so that's a whole other talk on
how to actually tune those alligators
depending on what if you're running on a
2 terabyte system like I am or on a
Raspberry Pi that some of you are so you
might probably not want to use the same
type of memory allocation in those two
scenarios so now you should sort of know
what a garbage collection reduction
counting non-preemptive directly
threaded register virtual machine is
that's beam so you can actually look at
generated beam code quite easily by
giving flags to the compiler so if we
have this little HR all file with
defines the string hello world the
greeting and a advanced program here
that you can call and it will return the
string hello world so if you compile
this with the flag P it will do the
pre-processing so then you can see what
will happen after pre-processing so this
is quite useful if you're doing hairy
macro stuff not recommended either but
sometimes necessary then the macro is
replaced here and you will if you had
code in your HR L file not recommended
either but sometimes you need to that
code would show up here and you would
know that you're in
actually from this file and then we come
to the this file and then you have the
expanded code if you instead give the S
flag you will get assembler output I
guess it sort of means or something like
that
the actual beam instructions so
these are the external beam instructions
for the hello world so it will tell you
that this is a module world and there's
a version comment in a file and then the
export information so it exports the
function hello that you've wrote and
then it exports module info 0 1 1 so
this is automatically added by the
compiler and then you can have
attributes and then it tells you how
many labels you have in your code and
then it says here comes a function
called hello we take zero arguments
starts at label two and then there's a
label one with information about the
function and label 2 where the code
actually starts and then there is just a
move instruction move the literal hello
world to the accumulator register or or
X zero and then return and then there's
actually code for the module info but
it's not really that interesting code
because it actually just calls the
standard module info code and I think
this is optimized away in the loader in
some excellent now the interesting thing
with if you just give the S flag or the
PFLAG and so on the beam compiler will
actually write the code to a file with
that extension or some extension in the
P it's DP P I think or something like
that the extension is and you can look
into that file but if you want to
actually get the code back as an airline
term there's a flag called binary so
this was from the beginning to return
the whole compiled code as a binary
which you can load into memory
but it actually works for each of the
flags that you can give so if you give
the S flag comma binary you get the
binary code or you get this term
basically back and then you can
processes as you want and actually use
it
rewrite it compile it to the next stage
of the compiler if you want to so if we
look at another example of bean code we
have a very small module here called add
export one function that takes two
argument at and it calls it identity
identity function for the arguments and
then add them so this will give us some
to not have the compiler optimize things
away this is a neat trick if you want to
look at the generated code so if we skip
all the things about module info and
other information this is the actual add
function so here we see that it actually
doesn't allocate because it will need to
use space on the stack to keep the
result of the first call to the ID
function while it calls the second ID
function so it moves the second argument
x 1 that's B to the stack just allocated
slot then it calls function at label f4
which is actually the ID function when
it comes back it has the result in the
accumulator
and moves it to the x1 register to store
it for a while then it moves the thing
that was stored on the stack before
which was B into the accumulator and
then it stores the result of this call
which was in x1 back to the stack and
then it calls the other ID function and
then it calls
plus with y0 the stack position and x0
and when it has added these two it has
to deallocate the extra stack slot that
it allocated in the beginning and then
can return so well at lunch here I met
Buuren and he showed me a fantastic
function that I didn't know existed so
this was really nice there's actually
another way to get in code which is you
call adds the bug the bug DF on your
module and it will produce a listing
file with they actually translated the
instructions in the beam so the
instructions that you see here the move
and so on if you look at the C code
they're not there they don't exist
because they are translated one more
time at load time but if you use that
adds the bug DF you can actually see the
instructions that you can see in the C
code of the emulator so that was a nice
trick
so basically we've learned a little bit
about how the beam works it does
reduction counting to do yield its
directly threaded so it jumps between
the implementation of each instruction
in the emulator and it's a register
machine has X&amp;amp;Y registers and Y
registers actually the stack and you can
use the s and binary option to the
compiler the binary option only works
with file compile not see in the shell
you cannot do cite just see foo binary
but if you do file compile you can do it
questions
when you talk about memory management
and collection we said that it was an
exception with binaries yes yes we see
Eretz in the garbage collector so
pioneers are reference counted but one
thing that you can do with pioneers is
to try to decrease them by coping out a
part of the binary but then you still
have a reference to the big binary so
you will not get rid of this huge thing
so that's one problem but the worst
problem is that if you send the binary
to another process this other process
also get a reference to the binary and
then you send it to yet another process
then that process has a reference to it
also so I have a long example of what
can happen here but basically you take
in binaries you send it to dispatcher
function and the only thing you do here
is look at the message coming in the
code what type of messages and send it
on and you don't even see that you have
a binary and you send it to another
process and this dispatcher process
doesn't really use any heap at all so it
will never garbage collect and it will
keep a reference to each binary and you
will never get rid of those binaries
until you run out of memory and die so
the solution to that today is to just
add a explicit garbage collect every now
and then in this
immediately to your response dying means
the process dies and then now I'll get
rid now there's the runtime system dies
no more questions then thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>