<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Lambda Days 2018 - Valentin Kasas - These 10000 classes I never wrote | Coder Coacher - Coaching Coders</title><meta content="Lambda Days 2018 - Valentin Kasas - These 10000 classes I never wrote - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Lambda Days 2018 - Valentin Kasas - These 10000 classes I never wrote</b></h2><h5 class="post__date">2018-04-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/P9dbMclkD7A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everybody thank you for coming is
everybody in good shape this morning
yeah great so let's talk about thousands
lines of code I didn't rent so I
introduced myself maybe with some time
I'm from Paris I'm a member of the Scala
community in France I organized the
Paris car user group and I'm part of the
team that organizes the scaleo
conference and before we begin I have to
warn you a little bit I have only so
much time and much much to to present so
there will be no time for cat pictures
and funny things like that there will be
a lot of code that might look a little
bit scary
but bear with me it will be okay and
probably the code that I will show you
is incorrect but that's not a real
problem
okay so this is a Surrey of a project
I've been working on in the past few
years and it was we were a small team
it's a fairly large company in France
that spans around a hundred entities and
we were tasked to build a data platform
that will collect and store all the data
from the entities each entities of
roughly a hundred tables or streams or
data structures so it sums up to roughly
10,000 data structures we started from
scratch in June 2016 and we had to be on
prediction by December of the same year
and we were a small team of five or six
developers so it's data platform that
data is coming through big batches and
we use spark or through streaming
to gasket topics we had to implement
so-called privacy by design which means
that the sources the entities that gives
us the data are telling us which fields
which columns contain personal
information and we had to take measures
to make sure that the privacy of the
people where was protected and of course
it was a fairly big project and we knew
that all that data sources wouldn't give
us the data on day one they will come
under the course of one or two years so
basically when you was working with
spark okay when you want to validate
data with Park basically you write a
scholar caseless and you use some kind
of tooling to automatically validate
some say adjacent documents to make sure
it's complies to the structure of your
cases but we have ten thousands of the
data structures so we wouldn't be able
to have been able to write ten thousand
case classes right where we had only six
months and five developers so it's just
impossible so we understood that our
pipeline we need to be configured at run
time in other words we wanted to have
only a single artifact on a single piece
of code able to validate and transform
all the data for all the sources we
needed a schema to that and that schema
needed to have a custom format because
we wanted the the sources to be able to
express that each field is or isn't
personal information and of course we we
had to work with multiple data formats
semi-structured in inputs like JSON or
CSV and we wanted to transform it to
more useable formats like pocket or ever
right nothing fancy so the solution we
we found was to to build the oil
pipeline around the concept of schema we
we fit a schema inside into the
validating process and it builds up a
validator that will validate them the
the incoming data so that enables us to
have a single piece of code that
validates arbitrary kinds of data and we
to take into account that specific
schema with privacy concerns and so on
schema so cool
actually there are blueprints for a
building whole bunch of application we
can use a schema to build a validator
you can use a schema to generate a
random data you can use a schema to
translate data between different formats
so it was the the the good concept to
build our pipeline round and schemas are
recursive structures inside the schema
you have smaller schemas that contain
smaller schemas and so on and so forth
and the data there represents like Jason
for example is also a recursive
structure inside the Jason you have
smaller Jason objects and so on and so
forth but the problem is that with
recursive structure structures you end
up writing it recursive functions and
there are very various problems with
recursive functions of course it's
difficult to make sure that your
function asks as stack safe
so your risk to to have stuck on the
first which is not really a problem with
schemas and data because it's not deep
enough to blow up the script stack but
more importantly when you write a
recursive function you are mixing two
concerns you are mixing how you walk
through your recursive structure with
what you are doing at each step which
means that your Kurds isn't reusable
because if you have to write another
function you will again write outer
world through your structure and what
you want to do at each step this isn't
cool but in functional programming we
have a technique that called recursion
schemes that comes from a paper from
1991 with a very funny title functional
programming with bananas lenses
envelopes and barbed wire from Eric
Meyer with which familiar with recursion
schemes already okay cool
and basically recursion schemes are a
way to decouple how we traverse a
recursive structure from what we do with
each elements of that structure and
there is an implementation in Scala the
library is called matryoshka and it's a
pretty much complete implementation 3qu
and so we decided to use recursion
schemes to build our process around
schemas and data so first I will explain
you a little bit about the theory and
then we'll see a practical application
of it
so our recursion schemes define three
families of traversals first you are
false
like in
in the standard library the default of
our lists it takes a list which is a
complex object and it destroy its it
collapses it to a single element who's
already using fault in Scala yeah cool
the most simple example of a fault is
called cat oh it's a cat a morphism it's
like the same cat ah as in catastrophe
for example then even you have unfolds
they do the converse they take a simple
elements and they build up a complex
structure out of it there is a method
called unfold in the scale a standard
library but it's more seldom used and
the simplest the simplest unfold is
called an app for anamorphisms and then
you have results that combine a fold and
unfold and the simplest refold is in a
morphism like you know oh and one
important thing to notice we come we
will repeat that throughout the talk is
that false they destroy a structure
button up from the leaf you before you
fold the structure starting from the
leaf and unfold they they act top-down
they start from the roots and they
unfold until you have a full tree it's
important to keep that in the faculty
man so to use a recursion scheme you
need three elements one is optional but
most of the time you you need three
elements
first you need a functor it will be
called a pattern shorter and it's just a
regular factor you can do recursion
scheme on option or lists or things like
that like that so it will be interesting
then you need a fix points who is
already the name fixed points
okay well see what it means and why it's
you it's useful and finally you need an
algebra or a CO algebra above and these
are the recipe of what you want to do at
each step okay so far so let's start
with a small example first we need a
pattern filter
so a typical recursive structure is the
binary tree right so usually if we we
are to implement a binary tree in Scala
we will write a silk family like a trait
three node that has two branches which
are recursive trees and leaves that only
label or something like that so the
first thing we have to do is to change
that type to replace each recursive
occurrence with a type parameter like so
right we also often add an F to the name
of the the type so that we remember it's
a functor and so we add we have a node
where each tree has been replaced than
by an A Okay and it's almost ready also
to write a function instance for that
type you just have to apply the function
f to each branch of the node that's okay
leaf is like Neil from the for the list
front row it just contains nothing so we
just have to change its type parameter
when we map it okay so far so good
but there is a problem when we do that
because because we we become unable to
have a single type for all our trees
because now the depth of the tree
Appeals in its type right is air I have
a
two levels deep three and it's type is
not of not of live of nothing but if I
have only a one level that tree its type
will be node of leaf nothing and if I
have mixed that an unbalanced tree I
have a even weirder type right so it's
it's a problem because we want to write
functions that takes trees but we cannot
find a type 2 2 2 2 to label our trees
and that's when we need a fixed points
it's just a trick
that's Heights or swallows the recursion
in our structure if we wrap each level
of our tree inside this fix class we get
a uniform type for all our trees so I've
trust me I have written again the the
trees from the previous slide using fix
which is not really practical but it
works and let's work that out
here I have a leaf so if I fix this leaf
I have a fix of 3 F ok again if I other
leaf there and I fixed it we fix it I
have also a fix of 3 F so this node here
is a tree F of fix of 3 F and if I wrap
it in fix I have again a fix of 3 F is
that ok
and the same is with this more
complicated tree right so it's just you
see the recursion here we have F 2 times
so it just hides one recursive step and
it's enough to completely swallow the
the recursion at the type level
this so the question is does this does
it imply a performance penalty and can
we get rid of its actually this there
are multiple fixed point types fix is
the simplest one and rapping always
occurs incurs a personal penalty but for
results like helo morphism you don't
need a fix
you only need a fix for Qatar and Anna
so if you have a performance penalty you
first try to rewrite it using you know
rather than get out one but yes it's
only a trick to please the compiler that
incurs of course a performance penalty
and more memory being used so that
that's a good question so we have a
patent factor we have a fixed point type
now we need algebra so algebras is a big
name just for functions they define what
we do with each layer of our structure
and are really really simple an algebra
it collapses one layer at a time for
function of our structure and it's
simply a function from F of a to a right
you can think about high school algebra
where we were tasked to take big
expressions and computer results the big
expression is a F of a in the results is
innate okay and like everything in
category theory when you add Co in front
of the name you reverse the arrows and
you get a new thing and that's it that
is co algebra ecology but it builds up
one a year at a time of your structure
and it's just a function from A to F of
a and also in the context of recursion
schemes the a of the algebra is often
referred to as the carrier of the
algebra that's just a little so let's
look at what it it means and how ill
enough isn't work I choose to it you to
show in a morphism because every other
scheme can be implemented in terms of a
needle so we need our pattern factored
it will be these little purple boxes we
need an algebra we need a college abroad
and we need two types a and B here is
the definition it's very simple it's the
real definition from matryoshka with a
little rewriting gap and let's look at
it how it works so we start with an A
right because we need an age to apply
here on it then the first thing we we
have to do is to call the Co algebra on
that a right and a co algebra is just a
function from A to F a so it just
produces an F of a since F is a filter
we can now map over it and it's like
peeking inside its elements and applying
function and the function we want to
apply is yellow because it's the
recursion right and so again we have to
call our core algebra limits which
produces an F of a and so we can map
over it and again called you know which
calls the co algebra and produce an F of
a but this time I've decided it's a leaf
so there is no more elements inside this
F of a so when I map over its the
function yellow isn't cold but it
returns immediately an F of B ok so far
so now that I have a F of B I can call
the algebra notes and the algebra only
takes an F of B to a B so I end up with
Abby and I finished for this brunch but
before that I was mapping over this note
there and maybe it as another animal
inside it so I need to call in orbits
which calls the call algebra this is
producing an f of a which is again empty
because I decided it was a leaf so when
I map the function isn't called and it
returns an F of B on which I can apply
the algebra and obtain me now I'm
finished for the map of this node and it
has becomes an F of B on which I can
apply the algebra gives me a B and I'm
finished with this branch but I was
still mapping over the the roots maybe
there is another element in the inside
it's I need to call you know which calls
the crow algebra gives me a leaf because
it's becoming boring right which is
already an F of B I call the algebra not
on its yes maybe so now my roots is only
f of B I can call the algebra on it and
I have my B and that's it
I have transformed an A to B through a
big data data structure which was a tree
and there are two important things to to
notice is that first I only built one
branch at a time the old tree was never
displayed on screen right and I applied
Kohl algebra why when I was descending
through the tree and algebra when I was
ascending toward the root is that
okay so you know everything there is to
know about recursion Skip's so now let's
apply this to our real problem so we had
a bunch of values schemas and data
formats we had our custom schema we had
pocket
we had Avro and we are probably many
more so the first thing we have we had
to do was to define the pattern factor
for a risky map
and then we just defined a bunch of
algebra and Co algebra to go from into
our pattern factor and the first cool
thing thing is that it gives us for free
all these other hours and this is really
cool because once you've written these
little algebras you will not able to
transform a pocket schema into a ver
schema back and forth which is cool
there is no library than that so let's
look at what it what it means I've
simplified a bit
our pattern factor but we have threads
that are only a map of string to feel we
have a race that only contains the type
of its elements and we have simple types
integers and strings and dates and so on
again writing for instance for that is
pretty trivial and we are good to go
now we just have to write algebras to
convert back in fourth and four for
example let's write an algebra that
converts our schema f2 pocket schema so
inspark
the the name of the type families to
describe pocket schemas is type so this
is a function from schemas of data type
to data type this is the the the very
important point the field here
we get is the results of the algebra
applied to those sub trees below so it's
already spark datatype right so all we
have to do is just wrap this each field
in a structure which is a spark type and
then we add a struct type which is also
the stocks thing to build a new data
type for arrays it's even simpler we
have M which is already a data type in
the spark well so we just have to wrap
it into arrow type and for the simple
stock types it's even simpler so this is
really really cool because we only have
to care about one a year at a time and
everything is already done for us by the
the recursion to call it suppose we have
a fix of scheme F we just have to call
the method cattle nets with our algebra
and it gives us a data type okay the
other way around
suppose I want to transform an avro
schema into my schema F all I have to do
is provide a Corral jibra of schemas and
schema which is the Avro type for all
the skills so this is basically a
function from average schema to schema F
of Avro schema right again I only have
to build one year at a time
I will build schema that contains little
smaller bits of Avro schemas and it's
pretty easy
afros as the this method get' type which
tells me which kind of schema it is if
it's a record I need to build a
structure and just grab the fields and
make a map of string to field and again
this is an address schema order arrays
it's simpler it's simpler I just want to
build an RAF with the schema of the
and so on and so forth really easy I
don't have to think about it it's radio
kinetic let's go I can transform an
average schema into my skin eyes but
they have to tell the library which
fixed points type I use because there
are many of them and I can also
automatically transform my other scheme
are two pockets by using an LM off isn't
right with the algebra I've defined just
the slide before and the co algebra
you'll find it cool so now I have play
with you now let's validate data because
that's what we are test asked to do so
two for that we used the GT of
validation library which is the Jason
Jason and CSV validation library from
the play format but it's distributed as
a single library and it defines a type
rule which is basically a function that
will take an input like JSON or CSV and
produce an output or a list of
validation errors the problem with
algebra is that you have to have a
single a a single carrier so we needed
to define a new ADT to represent data so
that we killed right algebras with a
single output right so again it's really
simple we call it data F it's almost the
same as the schema but now arrays of
list of elements and not only the type
of the elements it's the the only
difference it's so producing a validator
is really easy again we start from
schema and we produce a rule that will
take Chasen and build a fix of data
I'm sorry rule as an applicative
instance so we can use it to traverse
the list and it will give us a rule of
list of fields so we just a traverse the
list with a function that takes a pair
of field name and the validator of for
the field because again we are in
algebra so this is already a rule of
choose value to sixth attacks later and
we just use it this is jakeel stuff and
finally we map the result to build a fix
of data as okay that that's the the
divide eats that is important how it
works it's not really important you
don't and again for arrays
if we have a rule for elements we can
use the method pick lists to make a rule
for list of the elements and we use that
to build a fix of G array and for simple
types it's even simpler so that's it we
have a way to use schemas to build
validators we have a way to translate
from one format to another so we are
almost done
oh wait for it stands for generic in
that context we the problem is is that
in Avro you have a type generic data so
we couldn't write generic data and so
that's that's why we just use the gene
and since we already used struct F RAF
and so on it would have been you know
confusing okay so that was the simple
stuff so I hope it's still okay for you
because now we are getting into the more
difficult stuff I have ten minutes yeah
okay
so we are going into the difficult stuff
real quick so everything isn't like easy
as that
for example with our schema
representation our schema F we cannot
directly build an algebra to produce
avro schemas because the Avro I API
requires that every schema inside a
schema every sub schema as a single name
and we do not add enough information in
our schema F ADT to come up with a name
for each sub schema so we have to find a
solution there are actually two
solutions I might skip the second one
for now and we get back to it if we have
time but the simple solution is to use
the path of each schema elements as the
name of the Avro schema we are building
so in matryoshka
we have a little they call this
utilities patterns this one is called
empty and it allows you to label each
node of recursive structure structure
with a value of type e so the idea is to
start from the top
with enough ISM and label each element
of the schema with its path inside the
tree so by doing that we'll be sure that
every nodes of a single name and we can
use that to build Avro schema so it's a
bit noisy but it's very simple the only
part that can come up into the path of a
node is the name of the struct fields so
all we have to do we start with a pair
of string and fix of schema and we build
a lake
all three with the path and we just used
the path we already had we put the name
of the field at the end of the path and
we return an empty with that path and
instructor and at the end we end up with
a route having path empty string and
then each of its field have path the
name of the field and so on separated by
dots okay and so we just need to change
a little bit our algebra to use that
path and since empty is the case class
we just have to pattern match on it we
have the path we have structs and we can
use we need a namespace for other stuff
we can pass it through to the algebra
and we need to build a record and then
everything is just other stuff we put
the fields and so on yeah you you cannot
we actually we we wept all these
functions inside a small library and we
explicitly say we want to transform
these pockets to have rope so we knew
that we needed
the rights algebra and closure
oh no no because you you have one
algebra perform at so the the only thing
that is common is the new pattern center
and everything around can move the new
you can really do what you want so we we
use that with simply varying a schema
with an empty path and coming calling in
over frizam with our algebra i forget to
pass the namespace I'm sorry and the
quality about that labels with little so
I will skip that's formals and now we
have a little last thing to do is needs
to write our data that has been
validated so it's a fix of data s2
pockets or a verb so let's look at a
pocket in packet you when you use it
with spark you just have to write a row
and fit it too
I don't remember which method with along
with the schema and it will sell you
lies it to the pocket from it so this is
convenience because we can nest rows
inside whenever when another we are not
forced to have you know linear rows you
can have structured columns but in the
case of simple types like integers
strings and so on we don't want to wrap
them too much so being able to wrap rows
inside rows is cool because we can write
an algebra we have a unique carrier and
unique type but we don't want each level
to be wrapped in a row because for
example if you
two columns table which we just want to
output row of column 1 column 2 and not
row of row column 1 and row : 2 so
that's a problem because I said so far
that we only care about one level of our
structure which means that we cannot
know where we are in our tree when we
are applying here our algebra so that's
a problem because basically we want to
not wrap things inside rows when we are
at the bottom of the tree but there is a
solution does there were another schemes
than kata Anna yellow and so on that
have more sophisticated in the interface
and one of them is para it gives you
what you've computed it's a it's a
separa is a fold so it's a descendant of
of kata it gives you what you've
computed with the previous level though
the subtrees but it also gives you the
subtree that you have previously
destroyed okay so for that issues it
chooses another kind of algebra which is
called geogebra this is not the same G
for general German generalized I mean it
takes three type parameters W and F and
an A and instead of transforming an F of
a to a it transforms an F of W of a to 8
and that's used in impera to wrap the
previous results with inside a pair with
the previous tree you have destroyed so
that looks like that we geogebra that
takes data F of pair of fixed data and
row and we produce a rope so here if we
imagine we have a function that tells us
is
a tree represents a simple type like
integer string date and so on
you just have to check that the previous
tree was a simple type in that case we
had wrapped it in a row but we shouldn't
have so we just need to unwrap it and
build a bigger row out of these fields
and if not we just use that to build a
new row okay and for simple types we
just read them and it there will be
unwrapped one level so I think I'm
running out of time so I have many many
more usage I could have shown you but I
have only so much time and I have a
confession to make
actually Allah I lie to you this is
inspired from real facts but we didn't
basically we are refactoring our code
using recursion schemes we didn't start
right out with recursion scheme we write
we wrote because the function and we
suffer the lots and we have many
problems but then we met with our
mascots then we used matryoshka and it
was really cool at first when you start
using that you you might feel like this
fully pixelated gas it's it can look
quite odd but keep up and it will get
better
trust me thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>