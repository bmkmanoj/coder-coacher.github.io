<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Jonathan Olsson - STEVE - Performance Testing a $1 Billion SOA | Coder Coacher - Coaching Coders</title><meta content="Jonathan Olsson - STEVE - Performance Testing a $1 Billion SOA - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Jonathan Olsson - STEVE - Performance Testing a $1 Billion SOA</b></h2><h5 class="post__date">2014-07-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/d_gH8SveRhY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so my name is Jonathan and I work as a
developer Clara and have been for
roughly four years now with a short
detour as a development manager now i'm
back again in one of the Erlang core
teams and most recently i've been
involved in this project here we call
steve together with the masa if you saw
the last talking here he is the lead
architect of this and I'm is sort of
errand boy sort of them yeah doing these
kind of promotions and so Steve is short
for I think at least system test and
verification environment some sassy
things like that but what it's really
about is trying to tackle the system
testing challenges that we're facing at
Farnham and initially it will be mostly
geared toward performance testing but
hopefully as it matures it may also be
used for functional testing I guess and
so I think I will start off by giving
you a bit of a background to florin a
sort of if you've been to other chrono
talks you might have heard parts of this
before but I think it's a nice thing to
get some sort of background so where are
we coming from I'll of course also
describe what we're trying to achieve
with Steve and what we're trying to do
and hopefully we'll have some time for
other demonstration of a couple of tools
where we are open sourcing to the
community so we'll see exactly how much
time we left what I'll show em so Clara
we are actually hiring so if you're
interested in Cana you can go to this
fancy blog we're apparently or having em
so if you don't know anything about
corner where a financial company within
the payments industry so we shuffle
shovel money around all over
Europe pretty nice so if you went to
masters presentation you can see I have
much more fancy pictures than he has so
when i started at cana this was as i
said four years ago and in essence there
was one system doing it all one system
that matter at least and this system was
called cred cred was and is still today
quite the monolith it has its roots I
think in some prototype cluck and Tay
left guys built in three months or
something to get the company started
when I started I think it consisted of
somewhere around maybe four to six
erling applications roughly and these
applications did everything at Clara
they handled purchase requests for
merchants they handle Dunning chains
they handled bookkeeping they even
served web pages for our merchants and
for our customer service agents you know
it was pretty nasty so you know at that
time we were also around maybe 30
developers we were working this
monolithic highly coupled code base
trying to constantly add an enhanced
functionality maintain existing
functionality as well as you know expand
into new markets so we were running
pretty fast to try to keep up with the
businesses demands and you know the
system wasn't really built with testing
in mind and testing was sad to say
pretty low on the priority list not that
we didn't do testing of course we did
testing but the tooling around it was
pretty poor and this especially from a
system test perspective blackbox testing
for instance was non existing at this
point so as the business was growing in
transaction volume it became pretty
clear even back then that the current
architecture would not probably not
going to withstand year-over-year
exponential growth that we pretty much
still is seeing and you know this won't
go on forever and they combine that with
the fact that we
were also cramming more and more
developers into an already crammed
codebase so you can see this is probably
not a good idea so the work to break up
this nice little monster here was
initiated a couple of years back I think
last year at EUC a colleague of mine
Daniel Lee gave a talk on the work we
did to break up this panel if and how we
did it just a short recap of that so
sense all this functionality we had in
this old system credit was pretty arcane
clown I didn't of course want to force
new API some its customers nor did we
want to change the behavior of our
existing api's we chose a pretty how
shall I say conservative a migration
approach so this little stone and here
is symbolizes the new system Fred them
which instead of being a monolith is
more like it's basically a cluster of
react nodes with some functionality on
top so the intention was to break out
all the front and functionality from the
monolith so by front and I mean all
calls basically terminating purchases so
we wanted to lift this out and do this
in a safe way so you know the couple
application and wiring all the spaghetti
and then move the necessary applications
to the new platform and since we didn't
have a really sophisticated system
testing infrastructure in place we sort
of have had to move you know keep code
in both platforms so we move the
application student to the new system
some of the frameworks built for new
systems will put it back into the old
system and you know run the code
momentarily on the old system as well
and then start routing up traffic and I
mean in one sense maybe not literally
but at least we split the system in half
so we have one house handling the
fronton traffic and one system handling
all the back-office functionality these
systems still communicate today with
each other in various ways but the idea
here is that if the back office goes
down the front and can still be open and
take purchases and of course is not just
this system other systems are also
coming up like you know for doing credit
assessments maybe we have a third-party
solution for that and all different
kinds of systems are popping up and this
second system is actually also becoming
obsolete since our third platform is
already under development so this is the
new fancy enterprise service oriented
architecture kind of thingy and so the
intention here is to take new markets
with this new platform and then migrate
existing markets to this news is
platform as well so that means that some
things will have to be replaced by
third-party components some things will
probably be broken out and service if I
to stand alone services and other things
will maybe be rewritten I don't know
what the future holds there but one
thing I can say is that the lack of
external black box minded tests makes
this kind of migration work much slower
than it really needs to be so from my
point of view it's very clear that we
could benefit here from some sort of at
least semi automatic way of testing the
integrity of the system and a point I
want to drive here is that you really
want to keep the tests separate from the
from the code base of the system because
that makes it much easier to sort of
actually test the new system and see
that it actually behaves as the old
system so certainly if you're observant
so far are mostly covered and talked
about the lacking test for functional
requirements of the system right and
historically I think this has made a lot
of sense because the kind of loads we
have been seeing before in history maybe
aren't that big and not that there have
been small and it's definitely
increasing but it probably hasn't been
the biggest challenge for us I think but
this is changing so as we are expanding
in new markets as well as continuing to
grow in the existing ones we continue to
see more and more load coming into our
systems and this requires us to be much
more aware of you know where we are at
from a non functional perspective now a
problem is that the introducing
performance testing in such a late stage
of a company when you already have a lot
of systems and more system popping up
it's proven to be quite hard you know so
it's much harder to do this late than it
is to do it early so I would suggest to
do this from day one make sure that you
have a proper system test infrastructure
up and running you know from day one
because it might take some time but it's
nowhere near the time it takes to do it
after the fact and also of course
changes to to the system cannot you know
it's hard to to note this if you
introduce really severe bugs so I know
how to mentioned
in his talk Eric Steelman if you went to
his talk yesterday he mentioned that it
a nice feature in Erlang or 15 that was
introduced which is a way for you to
actually see what line number in the
stack trees you can see the line number
of where where you know when wearing the
code a crash occurs for instance and
this seems like a pretty non-dangerous
feature for anyone it only so happens
that the one of those frame where I was
talking about with reporting some of the
frameworks from the new system to the
old system right to make sure that both
code could live in both systems so one
of these frameworks had a little nice
feature that it caught every exception
that it that it got basically and it
didn't know what to do with it so we'd
call the gate stack trace and it so
happens that we didn't you do this once
or twice we did this like I don't know
what did you say like 50,000 times a
second something ish so I mean we after
12 or 15 we started seeing some problems
and the system wasn't really behaving
that well and I did some instrumentation
of this and you know the garbage
collection was just insane we spent like
30 percent in garbage collection gar
being about like 100 megs of ram every
call you know something was up and
eventually we found found the bug of
course and if we had more automatic way
of discovering these things it wouldn't
have happened so I'm not saying that
we're not doing in a performance testing
at all or haven't we have always done
that but in my opinion they have been a
bit lacking and so I don't know I don't
want to go too much into the details
here but basically you have sort of a
setup where you you suit theories the
system under test you set it up in a
particular state and then you replayed
logs from the from from from the live
logs on
you the system and see how it behaves
and then you could use maybe a different
code or something to test this but this
setup had a few problems one of course
is that you don't want to deal with
personal data because that is a very
sensitive matter so either you have to
be extremely extremely tight about about
locking this environment down or you
have to anonymize the data which is also
you know quite tricky so to do this we
had to do pretty time-consuming setups
and if we wanted to run traffic at a
higher rate than the original load then
we have to sort of compress the traffic
and then run it and this was of course
especially problematic if you have
multiple cord calls that has to come in
in a particular order and those you know
kind of things so it was pretty hard to
get reliable results it was nearly
impossible to reproduce test scenarios
in a timely manner and so forth so we
know something has to be done about
these things right moral of the story we
need more sophisticated non functional
tests in order to find a fix bottlenecks
and bugs more preemptively they need to
be easy to run and automate and so forth
so ya know how many testers are in here
12 okay I'm not a tester so but for the
rest of you then just so we know what we
want to do here yeah I don't know
they're there are slight differences
between these different the things here
so the testers might want to correct me
if I'm incorrect but the my
understanding performance test is
perhaps a bit more manual process where
you sort of gradually want to increase
load to a system you want to look for
bottlenecks and you know measure and you
know find measurements and yeah
benchmark the system basically as load
test is more of a procedure
where you figure out how the system is
behaving under a predefined level of
load so for instance you want to see
okay the maximum amount of the load the
system can handle how much is that and
for how long can it handle it or
something something of the sorts a
stress test is more determining at what
level of load the system cannot cope
anymore when does it break down how does
it break down and so forth what's this
fairly correct disagree yeah okay yeah
so sounds like complementary definitions
done yeah yeah but anyways we have
testers that chron also who know this
better and I'm sure must I can add some
to it anyway so we started this
fantastic project Steve and we had a
little wish list i guess and musty you
can add to this if you want to but I
mean one thing I talked about it already
we wanted the scenarios to be external
in order to you know how to be able to
disregard from the implementation of the
system
and we wanted to test to be completely
black box so yeah the monitoring of
course has to consider a system in a
white box manner because how else are we
going to instrument the system we wanted
to use synthetic data to get around all
these nasty business with dealing with
privacy concerns we wanted the results
to be highly reproducible and we wanted
to run the system on the test with our
live configuration basically so no no
test data no no test configuration in
any in any manner basically yes so I
hope I hope it will accomplish this and
some extent will already have so this is
just a little bird view of it really
meaningless slide in one sense so on
this level you can basically see Steve
as a software stack for pushing data
into our system under test and all what
i want to emphasize here again is that
the software fest we're doing is
completely separated from the system we
are actually testing here so i have a
little bit more of an executive summary
r of it and i'm going to run through
exactly what we're doing here so if you
look here we have the system on the test
and we have the synthetic internet in
one aspect this is actually external to
steve because this system monitors could
be we wanted to be able to be any setup
really because we have multiple multiple
different system that we want to test in
different configurations maybe and we
want to be able to reuse our software
testing component for all these
different systems so you could for
instance choose to deploy your system on
full-blown
replicas of the of the system hardware
for instance you can deploy a single
node system on a developer laptop and
run some tests and in our sort of live
like setup we are configuring it so that
the system under test is guarded by a
firewall that is configured exactly as a
live fire wall we have a synthetic
internet here that blocks any outgoing
traffic from all of these components to
make sure we don't actually by mistake
start sending emails to left and right
or sending text messages or or what have
you so another thing we're doing here is
that we have a fake DNS in the synthetic
Internet so let's say that the system
under test want to do a credit look up
for instance it might want to try to
contact the Swedish provider credit safe
or something of the sorts we actually
hijack that dns and and routes it to one
of our external mocks that you can see
there so from the system point of view
it's actually a live system and yeah
that's pretty nice so we know we're
actually testing the real thing here so
deploy it as live and keep it as
lifelike as you possibly can so if we
then go to the coordinator then we call
this de spider and it's really literally
it's de spidering this whole thing in
here it has a set of API drivers that
are pluggable so for every API you want
to test you need to have an API driver
so that they coordinate to know how to
actually talk to the system you are
trying to test or the API you are trying
to test here so the coordinator sort of
takes we take a sort of a what you call
it a declarative approach here so the
coordinator declares defines a set of
high really high level scenarios that
you can run
so for instance we have a product called
the clonus check out it's a pretty fancy
thing and let's say we want to test
successful purchase in Sweden on the
checkout for instance that's a very high
level so you get the idea that we try to
you know not be too detailed on this on
this high level and the coordinator also
knows how to generate their synthetic
data that it needs so in essence you can
say that the coordinator knows how to
transform the high level scenarios that
we define into actual traffic that gets
sent to the system it knows what API
drivers the trigger and in what order
and we put data and the coordinated and
only talks to the system on the test
through its AP is no specific
configuration that differentiates from a
live system in in this case and yeah the
load generator yeah it's only concerned
about generating different load patterns
be it constant bursts or maybe a a model
of live traffic somehow we also have a
little mirror there of the state of the
system so so the coordinator knows
roughly at least what they ties in the
system so we know about all the
consumers and what different depths they
have towards us and and so forth and so
what's next any questions on this so far
you're smiling doesn't it
so the data generation of course you
know you need to generate all required
data points for specific scenario and as
I said before we want to test to be
reproducible somehow we wanted to be
able to maybe run the same test twice
with different configurations or or
something of the sorts so this data
generation is sequence-based meaning
that we have a sequence number and from
the sequence number we generate the hash
and procedurally generate the data that
is going to be sent to the system so
give the coordinator the same sequence
number and you will end up with the same
data so you can of course randomized
data then by randomizing what sequence
number you're sending can rate the hash
and then there you go you have you have
data so I think that's a pretty
brilliant approach all right so i think
i'll go ahead and go to see what time do
have yes so for load generation we are
using a little tool that we're actually
built in the house it's called ponos
it's named after the Greek god of hard
labor and toil and my Russian colleagues
informed me that this word apparently
means diarrhea in Russian and I figured
that yeah well makes sense so let's keep
it so I mean this is this I guess it
started more of like a toy you know we
wanted something that had a minimal
configuration that was easy to work with
no external dependencies you know it had
to be concerned about load patterns oh
only that's the only thing we wanted to
do with it we wanted the low patterns to
be flexible so we didn't only want to
say oh I want 10 calls per second or 100
calls per second I wanted to say I want
ok 10 card per second then I want burst
of 20 calls per second every 20 seconds
or something and I want the sawtooth I
want you know whatever kind of load
patent you you you want really and you
know the obvious question is of course
why would you roll your own there are a
lot of other good load generators out
there and indeed there is and so we have
sort of built it in a way so that we can
actually replace this polo slow
generator if you want to if we see the
need for it but it's turned out to be
quite useful actually will we used to
use a lot of Bosch bench within klarna
before I don't know how many of you
special bench okay a few people so it
was a bit I don't know it it's also
pretty easy to get started and it's
accessible and so forth but I don't know
we found you know it tests a whole bunch
of external dependencies on everything
from Cassandra to I don't know what so
half the Erlang open source contribution
is in there a bit acceleration of course
but and also we didn't at least my
understanding the load patterns that you
can produce or not that's flexible you
can basically say that you want X amount
of workers and they are supposed to
operate at a certain amount of calls per
second and that's pretty much what you
have so we just wanted something that
was really super easy to work with and
so that's why we did it i thought i
should just do a short demo of it to
show you a bit what you can do we're
open source and it's not on github yet
but it will be shortly i hope let's see
now
I don't know yet there I need all right
can we see this is due large enough for
you all right so currently we only have
a command line or only I mean what else
do you need a command line interface for
this little beauty and toners has only
one important concept really and that is
low generators load generators has a few
things to them not that much so for
instance we have a name this could be
pretty much anything in this case it's
the atom constant alright so what else
do we need we need some work to be
performed and this is a list of
functions so let's just do a function
that returns okay nothing too tricky
here all right so what else do we need
we need something that we call a load
specification here and this is what we
wanted to make flexible so I guess this
is this is the interesting part here and
what what a load spec is is really just
a function of time so instead of saying
I want ten calls per second I say here
is a function that takes the time in i
think in milliseconds sense the load
generator started and then it returns
the current load yes or no question okay
so for instance if i wanted to make a
constant load i could actually just do
this and I will get the statistic all
the time and always give me ten calls
per second now we do have some so far a
few predefined low patterns that you can
use as to
it's in bonus load specs see so we have
currently implemented the burst triangle
constant sawtooth in staircase functions
and and I mean this list could grow
indefinitely and I mean I think the most
interesting thing here would be to
actually be able to analyze a load
pattern from your live traffic and
actually you know make sure you create a
function that that the corresponds to
that pattern another feature here that I
want to implement is the ability to I
don't know maybe not combine them maybe
but at least do some operations on these
load patterns as well so maybe you could
multiply a pattern by two so you have
analyzed your pattern this is how my
traffic looks what happened if this
pattern goes to two or something so not
sure how useful it is but I think it's
pretty cool so let's just do the simple
thing here and add some constant load
let's say five calls per second
something small okay right there are the
options you can add but so a simpler
generator is this is just all you need
so you need a name so the name you need
a list of tasks tasks and you need a
load back all right pretty
straightforward so let's go ahead and
add this load generator to
can you see this it's a bit too long
down ah panos call on add load
generators so this takes a list of low
generated so you can add several ones
several ones at once whoops okay now my
mighty max session is acting up
good file right so this was better right
all right so this is basically the same
thing now let's pray to the gods all
right so that's pretty much it so what
do we have now there are some
rudimentary things we need to expect
this so here we can see that it's
actually running at 4.99 750 12 calls
per second so this works actually by
sampling this this load specification
function so i don't know let's add
something else here we can add just to
show so named can actually be anything
we can have let's say tasks this is
pretty nice as well you will recognize
it from basher bench if you used it so
we can have one function that returns
low and then we do this this one returns
mike and i put a two there so you can
actually make these tasks waited as well
so what this means that the function
that returns mike will on average get
sixty-six percent of of the triggered
calls and the function that returns low
will get to the rest of the thirty three
percent so I named tasks and we have
some loads back here as well let's call
it let's do like make some burst so
every 10 seconds for 10 secs 910 load
for 10 secs i want let's say mmm 10
calls per second alright and then we
create this little thing here named
tasks don't speak
alright and now we get you can see
bursters who are currently operating at
0.0 see has its past 10 seconds yes
there we go so do you have the model
load is done basically that you can see
here is what are we expecting what kind
of load does the load specifications
actually dictate an hour back to zero
there and so on and on it goes and so
where are we on time ten minutes okay so
another little thingy then you can also
I mean of course this is all nice and so
but there is another thing you can do
you can actually so all things that
happen within ponos triggers events
right so when a load generator starts
when it finishes you can set the
duration for the for a load generator so
when it finishes when it starts when it
triggers the task and when it completes
task and so forth so these events you
can actually listen to through an event
manager so there is we call these ones
little babies collectors there is a row
collector that you can use that
basically just dumps the events to file
so let's call it the the EUC log this
should be a string all right
so we can actually see that currently
it's only the constant function running
okay right now and soon we will see the
bursts coming in here right you see
somewhere do Mike some are doing hello
and this is this sort of thing is pretty
handy constant or the colleague is mine
is actually working on a regulator for
through this event tender so you could
actually then see so okay maybe we
should just hang on here so what you see
here task run so you get the name of the
of the load the generator you get the
time it took as reported by timer TC and
you get the end result here also so you
could actually make sure that your the
toss that you're running are returning
other kinds of metrics that you want to
that you want to log so in conscious
case he is sort of writing a load
specification that I think utilizes this
to see how what is this system actually
responding and as long as everything is
fine he just keeps increasing the load
and once the load once the system starts
returning errors or timeouts or
something like that you decrease the
load again so yeah this will be coming
up on github short shortish so I think
we're sort of running out of time okay
we were here so oops so questions
cool stuff I really liked it the
simplicity is it's really nice so if you
do this load testing how do we as users
add extra load specs because the
loadspec is kind of the strategy of how
to put a load on there is it simple to
write those loads back so yeah I mean so
so it's just it's just the yes turn RT
one function and ponos will pass the
time passed in milliseconds sense the
load generator started and I mean I can
show you some of the current ones how
they look they might need some cleaning
up here but so here is an example from
how to make the burst and below you see
the constant one is just this regard to
time so so it's pretty straightforward
how to do this then of course if you
want to make a really complex pattern
yeah the implementation will be more
complex
so we're planning or are you planning to
do some kind of generation of the
responsiveness from the external mocks
from the external service yes so if we
are planning to to do what excited too
so yeah so you can generate the load on
your system and see how it behaves yes
however you're you're you're doing the
mocks for external system is behavior or
behavior right but what what if they
misbehave start taking the load to
respond etcetera etcetera you can see ya
then were customs well we're actually we
ran into one of these issues one of the
components was actually so we ran a lot
of traffic against the system and we
realized that something is off here and
they turned out to be one of the
components so the question is do quantum
model those as well as part of this this
coordinator and you know that it can sue
mean if you can configure them to behave
in a certain specific way exactly like
you I know one percent of the call
stakes you know one second and the rest
aches and currently we don't have that
support but why not it's a great idea
actually so because that is also of
course an interesting aspect of being
able to mock these systems that you can
actually see how our system behaves if
that one starts misbehaving so do I get
the concept correctly that because
you're transitioning to you know a
service-oriented architecture like more
breakdown so the system under test could
actually be any small component of your
system and then external modes will be
other services yeah yeah I mean you see
so so that that's what i think is beauti
beautiful about this setup is that steve
is sort of completely ignorant about
what system it's testing it cares about
what API is were testing and how they
are configured from our point of view we
don't really care actually well we care
that the API saw there but yeah
I have a question about these tasks
their funds you should were quite simple
would you simulate if you want to do a
sequence of signals for example than you
you need to save state between the
signals you send yeah well I mean then
you would have to implement that
yourself so I mean we could have called
you mean if you if we could thread some
state through the different calls or a
yes don't you need that for your own
testing or is every task independent of
each other the way we have chosen to
build is that we only have the high
level scenarios defined in the ending
the coordinator basically so from from
the low generators point of view it
doesn't care but I can definitely see
that you would have a need of the
threading state through different tasks
of course but it's also hard I mean
sense i mean currently you don't what we
also need to implement ear is of course
a way to make because the load
generators are completely a synchronous
it only it only guarantees that you will
have a certain load triggered you know
it's got a calls per second but it but
you don't you don't have a way of saying
as you can do in bash advantage for
instance that you can say i want 10
workers and i want them to work at a
certain speed but don't send another
request until the last one returns for
instance so currently that what you're
suggesting wouldn't make much sense
because you know all the tasks are
considered to be independent so if you
see what I mean that they are sort of
completely a synchronous so it just
triggers off these tasks and I think in
many systems the sort of thing you're
simulating could be emulated with some
kind of state machine so the your fun
would typically send a message to a
process
s that is simulating the state machine
and he will do the next state transition
then he could live for a long while and
then you sort of you could simulate the
million mobile phones for example like
we do yeah it looks great this hmm sweet
nothing else yeah anybody now if you
don't have any questions and thank you
for the presentation</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>