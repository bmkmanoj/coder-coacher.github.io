<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>From delayed polling to Real-Time Telematics with RabbitMQ and Erlang | Coder Coacher - Coaching Coders</title><meta content="From delayed polling to Real-Time Telematics with RabbitMQ and Erlang - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>From delayed polling to Real-Time Telematics with RabbitMQ and Erlang</b></h2><h5 class="post__date">2014-03-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/09sFFI91NSc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks very much everybody for coming
along I think the sailor and I are
between you guys and lunch so hopefully
we won't go too much over so the talk is
you've probably seen from the abstract
from the title from delayed polling to
real-time telematics with RabbitMQ and
Ellie this piece of work all started I
suppose about August us at timber last
year when I received an email through
github from from the tardeo asking for
some help to get something going with
with rabbitmq which for some years now
has been one of my favorite little
pieces of software rabbit and hurling
all good stuff and the net result was
that well we came up with what was
hopefully a pretty good solution well
natalia came up with the solution i just
helped to get it going i guess and when
i had an email from monica for abstracts
for the yelling factory I thought gee I
wonder if I could convince Natalia to do
a joint talk and I put together a very
wordy abstract that you're looking at
now so you've obviously will read the
abstract or at least part of it which is
why you're here I guess so I'm not going
to go through all that because it would
waste a lot of time and it's very boring
and there's lots of words and that
yellows of it painful on the eyes but
essentially lucid logistics the company
Natalia works for provides an end to end
solutions for companies around GPS
monitoring management and tracking of
remote assets via satellite and
traditionally the data is being provided
to their customers in some sort of
delayed fashion either via user
interfaces into a database hosted by
lucid or at one point they tried a
polling solution which Natalia will talk
about later which ended rather badly and
in recent times more and more customers
have been coming to lucid logistics and
saying hey look we really want to get
this data in real time or as near as
real time as possible as soon as you
guys get the feed off the satellite and
decode that information we want those
messages they can then use that data
more efficiently they can fold it in
with their internal in-house
applications to may be optimized routing
of the vehicle fleets or whatever so
loose that have been coming under a lot
of pressure to provide some sort of near
time solution and essentially what this
talk about is is about as the journey
that Natalia went on to come up with a
good near real-time solution for those
customers and how we implemented it so
I'll let me tell you talk about itself
in a moment and i'll try not seek in
wordy right everything I write is very
weird i work for HP cloud services my
role is senior software architect we're
responsible for creating services for HP
Cloud things like databases the service
message queuing as a service those sorts
of things I've worked with her legs
since around about 2007 2008 and
possibly you know I wouldn't claim to be
the world's greatest delaying programmer
a lot of my knowledge actually seems to
be more in the sum of the internals as
I've sort of said in the blurb there i
ported Erlang to some obscure HP legacy
operating systems openvms and just
recently hp-ux as well so whilst I like
to think I have a reasonable knowledge
of the internal workings of my
programming skills and maybe not as good
as I'd like them to be but I'm working
on that anyway enough about me I'll jump
out of the way for a while and let
mitali at least I'm talking and she'll
just go over basically like I said the
challenge that they were facing with
their customers and the solution that
was devised and then I'll talk about the
boring stuff and which are the details
of the solution and you know we'll put
up a few slides with some little bits of
code and things like that oak to you ice
breath mentioned i work for wizard
logistics here in california we provide
telematics solutions to our customers
and to end solutions i work in web
development have been doing web
development for 15 years with last seven
in telematics field and so a little
background on the company so entering
solutions with a subsidiary of quake
global i don't know if you heard that
they that name but they provide hardware
solutions and we use the hardware
platform to build a full solution so you
utilize iridium lower
orbit satellite network and our own
proprietary message protocol and then as
the last piece will expose a piece of
web software that's a web portal for our
customers to look at their data
worldwide customer base so customers are
not just in North America but anywhere
in the world oken different kinds of
industries but typically when you think
about satellite its remote areas and
what happens in remote areas is mining
oil gas some military operations where
there is no cell cellular coverage the
types of messages oh yeah so there's a
lot of players in our field obviously
most of them are in cellular field and
not a lot of satellite end-to-end
providers we do both satellite just pure
pure satellite and dual mode which means
that we cover you in cellular area but
then once you cross once you lose
reception we start using satellite to
transmit the data so that's very helpful
and that allows you to save money when
you're in cellular field the what sets
us apart is that we provide over-the-air
firmware upgrades and configurations we
guarantee message delivery which is
pretty important because a lot of
commercial satellite networks they never
once you send a message to your asset
they never give you an acknowledgement
of whether that message made it all the
way through they give you an ack at the
gateway level but then you don't know
what happens so we had to implement our
own ethnic mechanism to make sure that
our customers know exactly what what's
on their units what else so the types of
data that we provide this obviously
location of our assets we provide
emergency notifications for example if
vehicle broke down somewhere in the
middle of nowhere and driver needs help
we install panic button in the vehicle
and driver can press it and hopefully
his manager can dispatch help in timely
manner
what else vehicle driver behavior we
track that and that's pretty important
because a lot of big companies it's a
liability for big companies of their
driver for example speeds through school
zone and then something bad happens so
they want to make sure that drivers are
not speeding then also fuel economy is
very important fuel efficiency so we
track excessive idling so excessive
speeding successive idling excessive
heartbreaking so that those are the
types of things that a lot of customers
are interested in monitoring as it
health data so when you talk about
telematics it's not necessarily location
although in most cases we're talking
location data but we also monitor fixed
assets it's called SCADA I guess
supervisory data acquisition and data
acquisition and something if I get how
that abbreviation spells out but so if
as it has j bus protocol and that is
usually big generator somewhere or big
truck we can read information off of
sensors running on that protocol and
those types of things are cooling
temperatures oil pressures rpms so any
kind of information that it gets us both
exposed through j bus we can read and we
can transmit and that's important to
customers that have like generator
somewhere in the jungle and they need to
send like a maintenance person to make
sure that it's healthy and operating
well so this way they can remotely
monitor it and make sure that everything
is working as expected so telematics and
we stole couple of definitions from wiki
here but essentially telematics just
means a long-distance wireless transfer
of computer data and it can be any data
although in most cases people think GPS
location but it's anything and so here's
the little diagram the
kind of describes the message path how
it so we have a unit installed on one of
the assets the unit it's like a little
black box it has GPS chip has its own
operating system it acquires location
from GPS satellites then it reads the
data off of vehicle or any other asset
then transmit the data over satellite
network to a region gateway and then we
get it in our data center eventually we
parse the message and displayed on in
web application and mobile devices
specifics of our regional Network
iridium network is a lower Earth orbit
low Earth orbit spans from around 100
miles to about 800 miles above the
Earth's surface and this is where all
human spaceflights take place except for
lunar landing but most of them are
within that range I region constellation
spends at altitude of 475 miles i
believe above the Earth's surface it
consists of six to six satellites and
six spares and it covers entire earth so
there is no dead spots as in the case
like if you look at other satellite
providers which are called like geo
station is one exam example they are
located on high altitude at about twenty
twenty-two twenty-two thousand miles i
believe above the Earth's surface and
their positions directly above
positioned directly above equator and
they have great coverage of the equator
area but then once you get farther away
the coverage degrades pretty quickly and
so advantage of iridium in this case is
that it covers entire earth another
thing about iridium our network which
sets it apart from other leo's is that
each satellite on that network can talk
to neighbors satellites and where it's
important is when satellite goes over
the ground station if it doesn't have
enough time to establish connection and
transmit the data than
on any other network you're out of luck
essentially have to decide a light has
to wait until it sees another ground
station and then it will transmit the
data so the latencies then go from
seconds to minutes and even hours and in
most cases it's and accept unacceptable
to a customer so I read your satellites
they talk to each other so if one did
not have enough time to transmit it
delegate this task to another one and
that other one finishes the transmission
and usually the latencies we've been
seeing are within 30 seconds for a
single message I've seen some messages
come back and like under 10 seconds even
because this service is so superior and
so great it's very expensive so to be
able to use it and stay competitive we
had to work on some strategies so I
really provide a couple of services the
one that we are using specific with cold
sbd short bursts data surface service we
sent little packets of data and usually
every single packet does not exceed 250
bytes our messages are much smaller we
try to stay within 10 to 20 bytes and we
try to stuff as much data as we can so
we're using every single bite carefully
and so we can transmit a lot of data in
a very small message we yeah highly
compacted messages and yeah some other
algorithms I guess I can't really talk
about here but this is an example of one
week worth of satellite traffic this is
data from 2011 we are in white so that
white area is the service that we are
using sbd service they also have this
high-speed data traffic for phone calls
for satellite phone calls and some some
others oh I guess for internet and voice
calls are in yellow but this is your
typical traffic that iridium manages
again so our messages are pretty compact
we follow our own our own internally
developed message protocol we have
pretty light load compared to some
numbers I've heard here yesterday we
don't have high message throughput but
as our customer base increases and as we
start reporting on additional parameters
and start monitoring some additional
things messages grow in size and load
increases so the challenge when people
subscribe to our service a lot of them
are happy with what we can provide and
they go in the log in to our back-end we
try to keep our approach product generic
because it's a it's multi-tenant
environment so we try to keep it as
generic as possible but you can't
because certain customers will have
different requirements all the time and
and we don't want to you know like spin
our wheels and deliver to each
individual customer so in which case our
back-end becomes unusable to them
because it doesn't satisfy all all their
rules so typical historically the way
the data was served was through reports
scheduled or ad hoc reports through web
UI through email alerts and of to
satisfy requirements of these customers
with their own business rules we would
use soap web services and the customers
were talking about they're typically
larger customers with like I said some
custom business rules or maybe they
already have another telematics solution
in house and they have another back end
they don't want to deal with two
backgrounds they just want to accept
like data feed and then deal with that
on their own conditions so it's just
like what's going to follow so based
solution so initial approach for us was
to provide our soap based web services
which is was kind of fine
but there are some problems with it and
first of all customers have to pull and
that's I guess the biggest thing so that
means they pull on some predefined
intervals but they want to receive data
in real time they don't want to poll
every three or whatever five minutes so
when we expose our web services what
we've been seeing is that a lot of
customers were coming at our service
every five seconds because they want to
know like do I have anything latest dog
is there anything for me and so that was
putting a lot of strain on our servers
and database as well so we had to
actually replicate the databases so our
web customers web UI customers don't get
hit with that like traffic because
traffic was coming into the same
location so separated databases then we
had to implement the rules for people
not to hit us every three minutes and
that of course made am very unhappy so
when there was like a lot of wasted
resources a lot of unhappy customers and
as developers because we didn't want to
implement this additional logic
additional like databases so we wanted
to message to arrive and being served to
the customer and we didn't have have to
worry about what happens so here's the
diagram this diagram was just regular
soap response request response and it
actually outlines the whole path from
the time message hits the satellite goes
through gateway goes to our processing
server gets stirred into database and
then gets its essential awaiting at that
point for requests to come in and then
it gets served to the customers so so
even though re domes are you doing
latencies are within 30 seconds when you
go through this type of scheme you're
looking at minutes and minutes are
unacceptable for our customers so those
this dislike just outlines what I just
said about wasting resources and how
servers get affected and all that so we
looked so there but their pros and cons
so we thought like we need to implement
implement some kind of push solution and
so we started looking at
pros and cons of polling versus pushing
and pulling is very easy to implement
that's one thing it handles case of
subscriber or client going down or
server going down pretty easily because
if client goes down then we'll just keep
piling the data in data based and we
wait until they come and get it if
subscriber or client goes down we don't
I mean like if server goes under
meetings or something they just keep
asking for it and eventually they'll get
it so that that case is covered but
again there's a real time element is not
there so we started looking at
alternatives and we needed to find a
better approach and up immediately when
we thought about we thought about push
technology and started looking at some
web hook based solution so what that
would did for us and was providing HTTP
communication with flexible message
format it would be mostly firewall
friendly and it would require no polling
so we knew that this was the approach we
just were not sure what kind of like
protocol what kind of product was
available out there so about like 20
minutes of googling brought us to google
project page of pubsubhubbub that's a
funny name for a push protocol developed
by a couple of Google guys brad
fitzpatrick and brad slatkin it's an
open web hook based protocol for
distributed publishing publish-subscribe
communications over HTTP and it was
initially designed a long time ago I
believe before like two thousand eight
or even earlier to support RSS feed to
push RSS updates to customers as soon as
there were anything new and so
subscribers under this protocol would
get near real-time updates and it's done
using web hooks callbacks we could call
back so subscriber essentially
tells the server here is the URL you
have to post your data to and then
server starts posting any new data that
it finds for that specific subscriber
and Brett is going to talk about details
of how that thing works and how it comes
together with rabbit mq and okay so like
I said I get boring but so I get to talk
about the protocol and other boring
stuff so pubsubhubbub it is a silly name
but compensation for that is that you
know one of the inventors of it is also
named Brett so that makes up for it as
far as I'm concerned key components
pretty simple publishers subscribers and
hubs under the polling model obviously
the subscriber is going to the publisher
and saying hey if you got the
information for me if you've got any new
data and just cycling like that under
this particular publish-subscribe model
basically the publisher relinquishes the
publisher publishes all the data to the
hub and the hub the in takes
responsibility for the cement
disseminating that information to any
subscribers that have subscribed to the
topic in question so a fairly simple
concept and like Natalia said basically
the subscribers once they know about a
hub they will subscribe to a particular
topic supplying a callback URL from that
point on whenever the publisher
publishes something pertaining to that
topic into the hub the hub will forward
it via that specified URL to the
relevant subscriber or subscribers
basically publishers are going to use
HTTP POST to send updates to hubs and
the hubs are going to use HTTP POST to
push data out to subscribers all a
pretty simple concept there are some
other little quirks in there that I
won't go into any detail of for example
subscribers can actually you know maybe
ask the publisher hey have you got a hub
that i can use so i don't have to poll
you and things like that just looking at
it a little bit more detailed I've
already covered most of the stuff that's
here and essentially the key thing is
that publishers are delegating
responsibility for district data
distribution to the hubs these hubs
could run you know Google and
Kofi to have public hubs that you know
community-based hubs I suppose you would
call them anyone can use or what we'll
talk about soon with with RabbitMQ
Andrea hub you can create your own
pubsubhubbub environment like I
mentioned a subscriber can can either
maybe find out via whatever means i
don't know bring up your friend and ask
them what the URL for the hovers or they
can talk to the the publisher directly
and say hey can you tell me the URL for
a hub i can use to actually get your
data feeds please some additional
details about the protocol and obviously
we're talking about the hub is going to
do an HTTP POST https post to push the
data out to subscribers this is a server
to server protocol so it's not going to
work in the situation where for example
you've got a PC or something like that
that's sitting behind a firewall or a
net device if your subscriber is
something like that your subscriber
needs to be able to receive a feed via
HTTP POST it's probably really the only
restriction on it there's kind of a
simple subscription verification process
it's a fairly simple check you could
send a subscription request on behalf of
somebody else and just supply some
random URL so the protocol needs some
way of actually validating that that
callback URL and it just does a very
simple challenge-response check to do
that and there's also another feature
you can build in which gives the
subscriber some some level of security I
suppose around the authentic authentic
of the of the hub so from italia's
perspective like she said this this
looked perfect HTTP is fairly ubiquitous
anyone can pretty much deal with that no
problem as far as her customers are
concerned pushing the data out to them
via HTTP POST this will look like a
pretty good solution 20 minutes googling
we've solved the problem that's
excellent on the hub sub hubbub website
there are several implementations of
this thing listed I mentioned Google and
super feeder before WordPress have got
one that
used for handling blog updates and
things like that but but these three
none of these three could really be used
by lucid logistics because well I mean I
think one or other of them you've got to
actually pay for but that's that's not
such a big deal but there are other
issues like some of the data that that
is coming through this system from the
satellites is fairly sensitive
confidential information and you
probably don't really want it sitting
out there or flowing through some kind
of public or open hub so for that reason
these these options weren't necessarily
viable also like Natalia said also these
implementations were more geared towards
atman RSS feeds and they were fairly
specific about the format of the data
that you were going to push through
typically xml and philly load blobs of
the stuff but the the pub sub hub
website also listed this thing called
rabbit hub and this led natalia too well
rabbit hub obviously which was an
implementation and early implementation
of the protocol implemented by tony
ganic jones who some of you may may know
tony was one of the original developers
of rabbit in queue absolutely superb
software engineer very smart guy and
tony is also very very prolific if you
go to his github site tonyg you'll see
all sorts of weird and wonderful things
that Tony's created over the years and
continues to create he's now up around
boston area doing his PhD i'm not sure
when that's going to finish which
unfortunately means he doesn't
necessarily have a lot of time to keep
some of these things up to date and
we'll talk a little bit more about that
later but I discovered rabbit hub I
don't know a while back and and I've
taken an interest in it purely from the
perspective around rabbitmq of creating
some sort of multi-protocol messaging
hub and as a consequence of that I'd
done a little bit of work with it I'd
taken a fork of Tony's rabbit hub thing
on github and made a few changes so
Natalia contacted me in the hope that I
could help you to keep this going
because it looked perfect for the job
what Tony owed implemented wasn't
necessarily a full implementation of the
pub sub hubub protocol and if you look
at it very simply what it does is as
I've listed here okay so if you're from
rabbitmq and you're familiar with
exchanges in the a.m QP protocol and so
forth essentially it provides a very
simple almost restful like interface to
RabbitMQ it gives every amqp exchange
and cue hosted by the broker two URLs
one URL can be used for delivering
messages to the exchange or the queue or
strictly speaking you really only
publish to exchange as opposed to a
queue but that's semantics and it also
gives you a URL that you can use to
subscribe for messages that are
forwarded on by the exchange will queue
okay and as per the the pub sub protocol
subscriptions subscriptions when you
subscribe to this thing you supply your
callback URL and details about those
subscriptions are nicely stored and in
Asia so a really nice elegant little
plugin for forever D and Q that gives
you essentially as I say a mechanism
whereby using HTTP you can publish
messages in the rabbit and you can get
messages out of rabbit biggest advantage
from attorneys perspective here I'll
probably too but one of the biggest was
the fact that unlike some of the other
implementations of the protocol rabbit
hub didn't give a kit couldn't care less
what your message content was you know
as per rabbit a message can just be an
opaque blog blob a random array of bytes
it doesn't matter it doesn't have to be
an XML document Jason documented could
be whatever you whatever you want the
scene through and of course you know the
reason why we're here today is we all
are burling and all the goodness that
comes with that that RabbitMQ takes
advantage of rabbit hub and therefore
the solution is able to benefit from you
know with rabbit you've got built-in
security mechanisms so as far as lucid
logistics customers are concerned it's
pretty easy to suit them up with a
secure login to the rabbit hub
environment you've got all the
administrative goodies and things you
need and courtesy of Erlang and so forth
we've got some excellent fault tolerant
scalability and performance so you know
almost seemed too good to be true 20
minutes googling pretty much got a
solution nailed but of course it isn't
even that simple so like I said Tony's
been very busy working on his PA
d and consequently rabbit hub originally
written in 2009 required some changes
reberty and Q had evolved considerably
since that time rabbit hub makes quite
extensive use of some of the internal
api's within rabbit to make its magic
happen and you know it required a I
suppose you know a reasonable amount of
effort on my part to bring it up to spec
to work with I can't remember I think it
might've been rabbit three point two
point O or three point two point one or
something like that but a fairly recent
version there are a number of changes
that had to be made to the code as I say
to make it compatible with changes to
rabbit that had happened since 2009
there are also some changes you know for
newer versions of Erlang OTP and there
were some weird version issues around
mati web which I won't go into because
they caused me much frustration and I
just get upset and sad when I have to
think about it but also as part of the
solution we had to do a number of other
things so it's fairly important for
loose its customers that that they were
receiving data securely so we need to
build in support for HTTPS posting those
messages out to the customers via HTTPS
instead of http Tony when he wrote the
plugin originally had had written a
really sneaky little hand rolled HTTP
client which is probably very efficient
and so forth but you know there was no
support for HTTPS an important
requirement from Natalia's perspective
was making sure that messages were
durable we we talked before about you
know what if the consumer goes offline
for some reason they don't want to lose
messages they don't want to lose data so
we modified rabbit husband in this case
to make sure that you could publish a
message into the thing in a durable
fashion so it's it's persisted to disk
and so on and so forth it'll survive
restarts of rabbit it doesn't matter if
a consumer goes away for a while
messages will just build up in queue
it's fine we had to make a number of
other changes that I've listed here just
to bring it up to spec and a few other
reasons one of the funny ones that I did
some time ago though when working with
rabbit plugins is I got really really
frustrated the guys for some reason have
this thing they call the Revit II and Q
public umbrella which which they promote
is providing a nice framework for
developing and working on plugins rabbit
it's a pain in the ass quite frankly and
you know they really need to do
something about it so a little while
back I came up with actually I think I
probably stole a rebar based built build
process which grossly simplifies this so
Natalia has been something like what
three or four days fighting with this
public umbrella thing trying to get
something built and working and it just
wasn't happening and I said oh well look
you know go to my repo and github and
just do this and type about three
commands in cygwin and magic will happen
and you know sure enough it did I mean
it's just so much easier I need to talk
to the guys about that public umbrella
well that's that's really neat and tidy
that's that's that's mr. camera man's
fault for going for the 600 x 800
resolution that's my excuse anyway so
I'll just I just wanted to talk about
just some of the changes that we made so
whilst you look at the blurry screen
I'll talk like I mentioned one of the
things we had to do was to replace Tony
sneaky little hand-rolled HTTP client
with with something that could talk
HTTPS so the obvious solution there is
OTP these days supports quite a nice
HTTP client library and it was pretty
straight forward to just hack out what
Tony had done and and throw in the the
OTP HTTP client which fully supports
https so you know I mean not not rocket
science in that regard similarly in
addition to https i don't think you were
using it but that there may be a
requirement for when you're publishing
these messages out when you're pushing
these messages out via HTTP POST to to
the customers and so forth to actually
push everything through a proxy server
so again just a few lines of code and
config file and in the rabbit hub start
up to two loads and configuration
options for the HTTP client all pretty
naughty stuff very easy to do using air
laying of course
message delivery mode like I said it's
fairly important that we don't lose
messages we want use durable cues we
want to use durable messaging so
originally rabbit hub didn't didn't do
this everything was volatile if rabbit
fell over and died you would lose all
your data and so forth so Natalia coded
up and I helped remember me in a very
very simple change here where as part of
the query string when you post a message
via rabbit hub into the environment you
can specify whether you want persistence
true or false again you know a very
simple fix to change so rabbit basic
message is essentially one of the
functions within rabbit that you can use
for publishing messages into an exchange
and we really just added the delivery
mode to that so for those of you who are
familiar with rabbit delivery mode 2 is
durable another important thing to
remember there when you are dealing with
persistent messages and so forth is you
must create your cues as durable cues
kind of pointless specifying please
persist my message but you haven't got a
durable Q rabbit crash as well the cue
goes well these audio message is gone so
down the bottom of just put a really
simple command here kill command that is
illustrative of what you would do
possibly programmatically or possibly
via a script to kill script or whatever
to publish and data into this thing so
we've got moshi web listening for
incoming requests on port 1 50 60 70 and
in this case we're going to publish a
message to the a.m q direct exchange and
we're going to use a routing key of foo
which is identified by the hub topic
thing and we've said we want to persist
that data so whatever q that's going to
end up then hopefully is declared as
being a durable Q plugins startup
actually another one of Tony's fantastic
inventions early on in the days of
reberty and Q and actually I talked
about this at the airline factory last
year with these these magical boot steps
rabbit spins up quite a lot of
subsystems when it starts and so Tony
came up with this really cunning scheme
which uses quite a complex tree
structure
and this funny little rabbit boot step
thing to magically start up or rabbit
subsystems and the way in which plugins
predominantly used to be implemented
they would also use this particular boot
step mechanism to start up any bits and
pieces that they required with the
evolution of rabbit there in our kind of
different ways of doing things and like
I see it I was also having some fun with
with moshe whip and so basically we
shifted all the the boot steps into into
just a start routine for rabbit hub I
mentioned before that rabbit hub uses in
Asia for storing subscription details so
its startup it just checks do those the
relevant tables exist if not create them
things like that obviously we need to
start SSL because we're going to be
potentially using SSL bow their HTTP
client options spin up moshe leib see
what subscriptions of the air and
basically start doing stuff all pretty
easy mental note I need to add some more
error handling to that code but in mind
rebar based build owner it's just so
easy you know fighting for three or four
days trying to use the rabbit in queue
umbrella thing for working with plugins
is just silly I mean essentially all
entirely had to do and the cygwin was to
type like those four commands to build
rabbit hub on her laptop instead of
having to do battle with ubuntu and all
sorts of strange stuff that she didn't
necessarily work with all that often I
mean as far as rabbit hub goes the rebar
conflict is pretty simple the only
dependency really is this thing that
I've got here rabbit common which is
just the common stuff you need when
you're building a plug in hrl files
things like that and that's versioned so
you know when you build rabbit hub for
Revit in q3 point to point one you're
going to get the right the right version
of the rabbit common and so forth
so the resulting solution perfect really
fit for what lucid logistics required
it's very simple for Natalya to fold
this into the overall processing stream
as illustrated on the diagram I never
noticed before how this is like it like
a rabbit right excellent so essentially
most of the code on your site is in
c-sharp and its publishing publishing
messages via HTTP POST into rabbit hub
and those messages are being pushed out
to whoever subscribe to them and so
forth no polling overhead or goodness
there the messages happen to be
formatted in JSON but like i said the
solution really doesn't care what what
format they're in at all not a problem
and also like i said you can do all
sorts of good stuff with rabbit knurling
and we can do we can cluster it and you
know have replicated queues and all
sorts of fancy things like that and from
the customers perspective message Layton
sees that what they don't have to poll
or anything like that and the latencies
have gone down from minutes to
milliseconds so happy customer in my
experience is a good customer just a
simple illustration really before I hand
back to Natalia about how you subscribe
to rabbit hub so again just using a
really really simple curl command when
I'm testing this thing I team to
actually do it using a ruby Sinatra
which is why port five six seven four
five six seven is there but that's
beside the point the curl command here
essentially what that's saying is that
any any messages that get published to
the exchange a in queue direct yeah with
a routing key of foo are going to be
forwarded by a rabbit hub to this URL to
the callback URL that we've nominated
and this particular subscription the
lease is going to expire after 600
seconds which is maybe not such a good
idea you can specify essentially an
infinite lease or you can put some time
restriction on it these subscriptions
can be to a cure or an exchange if you
subscribe to an exchange then rabbit hub
creates an exclusive queue for you and
binds it to that exchange and things
like that and rabbit hub doesn't care
how message is get into a queue so you
know rabbit supports other protocols
like stomping MQTT
and obviously a and Q P it really
doesn't matter how mrs. jizz are
published into rabbit how they arrived
in the queue as far as rabbit hub is
concerned is irrelevant it's still going
to push them out to the consumers okay
and from a management perspective as far
as Natalia is concerned is a very very
simple little script to provision a user
create whatever accused they might need
create their login details and so forth
done in a matter of minutes and we'll
hand back to you to sum up so the
current status is that this
implementation has been on production
for a few months now we do have a couple
of beta customers that are pretty happy
with it and whenever we'll have a sales
call with some prospects this question
always comes up so it's very important
for customer to have access direct
access to their data not through some
kind of reporting and you I packages but
like direct data feed and so whenever
that question comes off we say yeah we
can push the data no problem and that
actually is a big point in our sales
process potential future developments so
this says future but it's actually
already been implemented so as soon as
we got RabbitMQ installed we realized oh
we can use it for some other things
because obviously when we receive data
from satellite provider from my region
we don't immediately put it in the
database because we need to apply our
algorithms for parsing it and so we used
to have our own homegrown cues for that
and then we're like oh that can go away
and so we replaced it with rhythm queue
and that was a very successful change
and we're very happy about it so I guess
that's a summary so we got rid of
polling our customers are happy we're
happy we were extremely I was extremely
pleased with support from RabbitMQ
community I did a test drive couple of
other like Brett mentioned there a
couple of other implementations on
pubsubhubbub site they're like Ruby on
Rails PHP can't remember something else
so I test drove those and and Google's
own and I did not get good response from
women like Google Groups forever trying
to get through littlest problems and so
but rabbitmq was extremely helpful and
we're very happy about that side of
things as developers so I guess that
would finish our talk I don't know if
you have any questions huh no I think
that's about it yeah any questions
it's a HTTPS connection so hopefully
it's all in creeper to you I can't
remember whether your honor like a
private network or is it is going out
over the internet but it's encrypted are
you in tahoe customers yeah it's just
goes over ste TPS we don't provide VPN I
n it's being sufficient so both sides we
give them the hub link the hub URL https
and their site so obviously they have to
run web server to be able to accept our
post so they're using https as well so
we think we're pretty good no yeah we
tell them to get a certificate from
trusted authority
Oh
no so the way it's implemented at the
moment this it's a fairly implicit
assumption that the messages are getting
in there so there's no publisher
confirms or anything like that at the
moment and and the way it's being used
at the moment that doesn't seem to be
necessary but like I see it you know as
far as rabbits concerned so the moment
Natalia is pushing publishing the
messages in the Avaya HTTP through
rabbit up but you could just as easily
publish those messages in via amqp and
do the publisher confirms thing and so
forth so I'm sorry you're publishing
messages in via HTTP at the moment oh
gee yeah the you know note that you
could actually publish me such as in via
HTTP just using the management API as
well or any as I say any other protocol
the rabbit support yeah sorry
very slow hi error rates
I you are this
Oh
yeah I suppose that's more well the
latter part of your question I guess is
more a coordination thing with the
customers yeah yeah so far we had one
case of customer returning 500 to us in
which case we terminate the subscription
and the customer of course they don't
always read the documentation so they
got kind of like what's going on where's
my messages like read the doc which is
terminated you have to return 204 and so
they just research in which case they
just resubscribe and they get all the
spooled messages the messages starts
pulling in the queue and as soon as they
subscribe back to us we push it
not yet I think you could probably
handle that reasonably well with rabbit
yeah a little bit of work maybe but you
know I wouldn't be too worried about
large numbers of messages queuing up the
biggest issue there is more likely to be
that the guy at the other end you know
the URL that's copping all those
messages just one after the other and
whether they can absorb them I'm not
sure what the best approach would be
there possibly we could look at
modifying rabbit hard to just put some
kind of throttle on or something like
that maybe yes it does so that's another
option for example if you can't if you
can't shift a message or you could see
it messages up for example you could put
an expiry time on messages so maybe if a
message hasn't been consumed within an
hour just pick a number you can have
rabbit configured to shift that message
into a dead-letter queue yeah you can do
that as well yes
it's it's pretty flexible and that sort
of regard there's some fairly
sophisticated functionality oh okay yeah
i mean it's tightly integrated with
rabbit so it's able to take pretty much
full advantage of those things i mean if
you had messages going into a
dead-letter queue you probably have to
write some little bit of code to make
sure they loop back around but you know
it's not going to be big yeah their
questions hold on lunchtime</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>