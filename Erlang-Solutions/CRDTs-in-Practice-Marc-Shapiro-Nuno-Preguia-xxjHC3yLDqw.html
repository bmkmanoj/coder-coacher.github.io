<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CRDTs in Practice - Marc Shapiro &amp; Nuno Preguiça | Coder Coacher - Coaching Coders</title><meta content="CRDTs in Practice - Marc Shapiro &amp; Nuno Preguiça - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CRDTs in Practice - Marc Shapiro &amp; Nuno Preguiça</b></h2><h5 class="post__date">2015-11-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/xxjHC3yLDqw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so as he said I'm Mark Shapiro I'm work
in Paris at in real and at the
University the Science University I'm
Ali Cooley over there
so today we will with nuno will tell you
a little bit more about your duties I
assume that most of you have read the
papers so we would not go too much into
the detail of what a co DG is but more
about the design philosophy and what
we've learned in the past few years
so we all know about cloud computing and
the problems we have was called
computing we have replicas we have
databases that are replicated in
different data centers latency failures
etc so for all these reasons you're
going to replicate the data in different
places move the data as close as
possible to the users have your
application logic running next to the
data next to the database and in order
to have availability you want to be able
to accept reads and updates at all the
different replicas without synchronizing
because synchronizing is costly and is
not available if there's a problem so
this is where our starting point and the
what we've been trying to do is you know
make this a lot easier for for
programmers move to so you of course you
we all know about key value stores and
and no sequel databases where we're
trying to move one level up to higher
level abstractions that are more useful
to the user to the developer and another
thing we want to do is look to the
future so today there might be you know
a few tens of data centers around in the
world but this is changing very quickly
and there's more and more and more you
know locations for your data that are
possible the the 5g revolution is coming
very soon where the phone operators I'm
going to put a data center in every base
station so there'll be thousands and
tens of thousands of data centers around
the world and you're gonna have to put
your replicas in Harran and manage that
and you want to be able to move your
application logic really really close to
the
so he's only you know a few microseconds
away you know from keystroke to or mouse
movement to to to to response and what
we want to do is we want to move the
guarantees that we might give today in
in the data centers to those replicas
very close so you know we're not there
yet
obviously but sometime in the future
we'll have to be able to manage you know
tens of thousands of replicas and and of
course do that in a fault-tolerant
way so the approach we've proposed is
called conflict-free replicated
datatypes see our duties and the
insights here are first of all it's a
data type so it's well encapsulated and
you sort of hiding the ugly aspects
behind a nice you know interface which
is familiar to users of course it's
replicated at multiple nodes but the way
it's replicated is that in order to
ensure availability first of all we were
always ready to accept updates
so therefore updates can be concurrent
and non synchronized but we still
guarantee that your data will eventually
converge and it's not just registers
that do reads and writes
it's higher-level data types such as
sets or graphs or sequences or you know
complex things that are much more useful
for application programmers and I will
not go into the details of how we prove
this but it's in the papers you know if
you just follow some very says
mathematical properties but it's just
really some very simple design rules you
will ensure that this these things will
will converge and thanks to this design
everything is decentralized and
everything happens in a very pure de
pere manner so why would anybody use
these data types well first of all
because if they ensure availability if
you if it availability is not your prime
motive in life I mean forget sorry T's
and forget parallelism you know might as
well do things sequentially it's a lot
easier a lot simpler
and much more familiar so if you know
availability is your thing then maybe
surgery T's is something you want to
look at surgery T's are as I said higher
level data types so if if you don't need
higher level data types
right if ret just you know readwrite
registers key value stores are okay for
your application by all means stick with
that but you know if you have if you if
you have like I don't know some
distributed game with game state that is
highly mutable and highly distributed
over these ten thousand replicas again
maybe this is the way something you meet
you should be looking at mobile
computing there's another example
because you know your mobile computers
might be completely disconnected from
the network and you want to be able to
do your region and updates even though
you're disconnected and be sure that
you're going to reconverge when you
reconnect it's also useful in listen
within the data center to have more
parallelism inside the data center
avoid avoid synchronization so some of
the concepts some of the design ideas so
first of all these are data types that
are supposed to be familiar so acidity
set should look as closely as possible
to your sequential set right and has the
same operations to add and remove
elements in the set and a graph should
look like the graphic cetera but of
course you know if you want concurrency
then you have to do some you have to
accept some you need to lower your
expectations some odd okay but anyway
you need to be the sort of top level bit
is you need to be backward compatible
with sequential data types this is not
written into the papers it's so obvious
that we never stated but it's actually a
very important property and the second
principle is you want your operation to
commute okay because if you have
operations that updates the commute
right then it doesn't matter which order
they're received so if I do you know
some operation up here you and that's
other operation
down here V somebody might receive you
followed by V somebody else might be
receive V followed by you but it
shouldn't matter right so if your
operations already commute in the
sequential data type you're home free
right so you have things like you know
if I'm talking about a set I have
operations like adding an element II and
removing a set a different element F
okay that commutes because a D followed
by remove F you know ease in the set F
is not in the set and that's true even
if you swap the two so naturally
concurrent a D and remove F should have
exactly the same semantics okay but if
your operations do not commute okay then
you have a design choice and what you
need to do is ensure that these two
concurrent operations that do not
commute in the sequential sense still
come up with a you know it doesn't
matter whether I receive so for instance
removing and adding the same element
right it sequentially is not does not
compute right if I do
Ruby followed by a DI expect e to be in
the set but if I do a default by Ruby I
expect me not to be in the set so I have
to make some choice some design decision
so it has to be deterministic so that
all the replicas come to the same
conclusion no matter what order they
received these operations in so it has
to be deterministic that's really the
destroy the assent essence of sorority's
but it also should be explainable to
users and developers so you want it to
be as close as possible to one of the
sequential executes it cannot be exactly
the same okay
and sometimes the anomalies will show
through but you know it should be close
enough let's say there's no there's no
good measure but close enough so
basically you will say well if you know
add if I have concurrent remove Ian at E
I will choose one of these two solutions
making you know I will decide that well
in that case at should win or maybe I'll
decide that remove should win but it
doesn't matter it has to be
deterministic
okay and of course you don't want to
lose updates all right so last rider
wins approaches for instance that are
widely used in key value stores they
work they commute in this sense but
they're ugly because you lose updates
and the stable preconditions I will talk
about in a minute
so sororities are a an academic concept
that were published in 2009 and the main
paper is 2011 but they've been picked up
by by industry and these are some of the
companies well these are the companies
that we know about that have announced
in some way or another that are actually
using CRT T's internally so we must be
doing something right here and I will
talk about one of these guys and I
there's probably some people from bet365
in the room so they they will correct me
if I say anything stupid this this is
knowledge I know from their website and
you know videos that they posted I don't
have any particular insight knowledge
okay but okay so these these are
apparently they say the largest European
online betting operator and they have a
very bursty low they have up to two and
a half million users at any point in
time simultaneous users banging on their
data one terabyte working set I'm not
sure what's in that working set but I I
know that a substantial fraction of that
working set is actually stored in C our
duties and sort of the the top level
requirements is for them is that has to
be available so users have to be able to
place their bets at any point in time in
whatever their soccer game and you know
even if they even if one of their server
fails and they also want some the
results to be understandable
so just eventual consistency is not good
enough you have to have some kind of
monotonicity that is if I made a bet and
I look at the database I should be able
to
see my bed right or if I read somebody's
you know some results somebody made the
bet a minute later I should look at the
database and still find it there right
there you don't get those guarantees if
you just ask for eventual consistency
and they want transparency that is they
want the results to be explainable to
users so again this is why I think
probably the reasons why they they chose
to look at CEO duties and in the old
days a few years ago they used sequel
server and found that that didn't that
didn't scale at all and that when they
had a failure it took hours for the
sister to reconvert and mid-2013 they
decided to look at react which is no
sequel database which was fine in terms
of availability but when a failure would
occur there was come up with they would
have siblings and this was really so so
multiple values to the same data item
which was very hard for them to to deal
with manually so at some point they
decided to look at CEO duties and
they're actually using strategies in
production since almost a year now and
what they're using is the observe remove
set that it has been implemented by by
Russell in in react and again I don't
know the details of how they use it but
basically they just put those bets in
the set and at some point they look at
this set and see which which bets match
and what they say is that this was
really transformational for them that
their developers from this point on
could concentrate on developing
interesting applications and not
concentrate on debugging you know
anomalies in distributed systems and
whenever there was a failure it would
reconverge very quickly incorrectly and
I asked them you know what what would
they like for the future what's their
wish list and so that the wish list is
more of the same right so they would
like you know the same you know
availability and all
but you know a little bit more
guarantees about you know maybe I want
to update two things at once and not
just a single set so I already talked a
little bit about this I can skip this
slide so sets is sort of the you know
poster child of absurdities and this is
the thing that everybody's been looking
at but I didn't want to make it is too
boring so let's invent a new data type
okay a new serie DT right so you're
starting a you have this idea for a new
startup you're going to manage wedding
lists for for you know people who get
married and everybody will have a copy
of their wedding list on their iPhone
and okay so here's my wedding list it
has you know I want a TV and I want and
I want to you know my honeymoon in
Venice and it's an ordered list as TV
and you know buying the TV is more
important to me than than going to
Venice and then of course I might do you
know add things so I will point at one
of the items in my list and I will say
well I'm going to add something right
after this one okay so what looks less
important going to do Venice and after
all know maybe I don't want to go to
Venice so I will delete pointed Venice
and say delete right and then you know
my spouse to be on her replica will also
pointed Venice she doesn't know that I
deleted Venice because we're working
independently and on different replicas
so she points at Venice and says well
you know I would also like to go on a
ski trip but you know then it's still
more important to me and then at some
point you know the data will be
exchanged and will we converge and now
you see that Venice is gone right and
that all the things that I have added
are in there and they're in the right
order okay so yeah so you know here's
the here's the specification I want to
be able to look up the contents of my
wish list I want to be able to add a
wish to my list and I want to remove
you know something from my list easy
enough so how can i implement that well
basically you know it's a linked list
right I'm adding and removing elements
to a sequential linked list has a
beginning marker and an end marker and
every time I want to add something it
will just say add after this position
right so let's start with you know the
list that contains TV and Venice and
then I will add laptop by you know just
doing the usual linked list thing I
replace the you know next pointer that
is in the Venice note with the pointer
to laptop rather than the pointer to to
the end and laptop points to the end you
know you you all know how to do linked
lists and then I can do the same thing
I'll insert books and then maybe
concurrently you know oh no and then I'm
deleting Venice okay so deleting I I'm
not allowed to remove Venice from the
list immediately because my spouse by me
it might be adding things after Venice
right which is exactly what happened in
that in the example I showed you so I
can still insert the ski trip that there
at the right position okay so what
happens if two on two replicas we insert
two things at the same position right so
I want to buy this new drone that Apple
just came out with and you know my
spouse is less materialistic than me and
she wants world peace okay so we have to
resolve this just any any any way of
resolving it is okay as long as it's
deterministic right so let's just
resolve it by by alphabetical order and
we're done okay and there you have their
data types that you need it for for
linked lists so I cheated I didn't
really invent this this is called RGA
and it's been in it is in one of the co
DT publications but it's a little bit of
secure okay so maybe we can improve this
right so mmm no this looks wrong right I
mean world peace definitely cannot be
important than than buying a drone right
I want to move world peace up to the top
right but simultaneously my spouse says
Oh world peace
this is doesn't make any sense you know
world peace is not achievable so it
doesn't belong at the top of the list
I'll move it to the bottom right and
well we end up now with world peace in
duplicate of course okay so something
went wrong here all right this is
something that you know I asked for move
right I asked which implicitly means
this thing cannot be in two places at
the same time if it is in two places at
the same time by the way I've messed up
my linked list but you know that's just
a technical question
so in effect I've just added you know
two copies of world peace and and
removed the the single ones so I didn't
get what I wanted and the other thing of
course I would like to do is you know
now that I have my wedding lists people
are gonna buy me my presents right so my
father is going to say okay I mark the I
drone as being you know I'm going to buy
the the AI drone and then Russell who
really likes likes my spouse also says
oh I'm going to buy you the Hydra and we
end up with two copies of the I drone
right which again is not what we wanted
so what happened here so what's the
difference between remove which just
marked something is being removed and
offer which also this mark something is
being offered okay well there's a big
difference the so here I'm writing a
specification sort of the whore triple
style so here I have an operation
removed and then to the left is the
precondition the things that have to be
true before I apply this operation and
so the right to post condition the
things that should be true afterwards
right so when I remove I expect the
thing that I've removing to be marked as
a tombs
okay but it doesn't really matter what
the state is before even if it was a
tombstone before it's okay right so
there is no no real precondition but its
bark is true here whereas in the move
case or in the offer case I want to make
sure that the item is unique right so
this invariant that this this item
appears only once right comes out in
this precondition right so in a
sequential execution if I want to offer
something I make sure that it hasn't
been offered before right so I have this
precondition it's not offered yet and I
offer it and therefore afterwards it
will be in the offered State but now you
see just looking at this you see that if
I have two concurrent offers executing
one of these offers is going to violate
the precondition that the other one okay
so this is really the reason why move or
offer didn't work okay I'm trying to
maintain an invariant and in order to
maintain that is invariant I need a I
need a precondition but the concurrent
operation is violating that precondition
so I'll say that the precondition is not
stable so and people who who came to our
tutorial yesterday we explained this in
a little bit more detail but basically
there's a proof that says that if all
the invariants are sorry if all the
preconditions are stable under all
concurrent updates then the invert is
guaranteed but if not all bets are off
so see lessons learned before I pass the
mic to you know so if you want
availability you have to accept
concurrent updates and you know there's
undesirable effects but you can often
mask those invariable undesirable
effects so for instance if I if I add
the same thing twice okay it's okay
right I can accept them both and just
sort of hide the second item I want to
be backwards compatible so this if any
any secret if if someone uses my CDT in
it
normal sequential program it should have
exactly the same effect as the the
sequential data type if two operations
commute then I want the concurrent
semantics to be the same but otherwise I
have to choose something that is
deterministic again and close enough and
I'm maintaining that if I want to
maintain invariance this is something
really new that is not in the papers if
you want to maintain some invariance
then the the thing you need to mean sure
is that your preconditions are stable
okay so now I will try to explain you
how we can maintain some of the
invariants so if you look at the
manipulations so many applications need
to 24 invariants of the form kind of
some counter must be greater or equal to
K for example if we are counting the
number of ad impressions in a in an
application that has some amount of ads
to print so the number of impressions
left must be greater or equal to zero if
we keep put many afikoman in again okay
we want too many to be greater or equal
to zero of course if it's real many we
also wanted to the bank also wants the
money that you have in the bank account
to be greater or equal to zero so it's
exactly the same problem so how can we
try to to address this problem one thing
that it is important to understand is
that if you are trying to do for example
to keep the number of impressions left
greater or equal to zero most of the
times we don't have problems if the
number of impressions left are one
thousand or twenty thousand or something
like that
so the cremating by one well it will not
make it under zero okay so only when we
are closing to zero to zero we we get
into into problems okay so to try to
address these these numeric invariants
what we do is we try to see
the current value of the counter okay as
the number of Rights twins acute a
decrement for example if X if I have a
counter X and then fell off the counter
for example is 1000 that means that I
have 1000 rights to twins acute
decrement okay and these 1000 rights to
execute decrement and HIDA Street these
rights by multiple replicas okay
so every time I is equal to decrement I
will consume when right every time is
acute an increment I create a new right
okay so and this is the the key IDF to
to to enforce these numeric invariants
okay we will have this right we will
distribute these rights among replicas
and we want to not consume more rights
than then then it exists okay so the
problem now is we could do that using a
central server you would go to the
central server see if there is any right
over wall okay but we don't want to do
this okay what we would like to do is to
distributed these among multiple
replicas so that each replica can can
access the counter independently just
like it is a CR DT okay so it's replica
is it's it's copy F of this object
it's replicas execute operations locally
replicas will synchronize peer-to-peer
as any other Theory T okay
so using the normal rules if we have
stuck biased ER duties will send this
light we will do the merge as in any
other CR DT okay there is a slight
difference okay so if we don't want the
counter to be negative sometimes when we
use acute an operation locally the
operation will will have to file so I
will try to decrement and my replica
will tell me okay you cannot decrement
because if you decrement we might break
the invariant okay
the only difference when compare it with
a normal city in which you'll be allow
it to decrement but you could go
negative
okay so we've built a reality that is
call it the bounded counter DePandi's
counter basically you can create about
it counter you have one operation to
increment a value even operation to
decrement a given value you can see the
current value in your bonded counter and
you can transfer rights from one replica
to another replica okay so I can give
rights to another replica I will I will
now show how this works so so this is a
bit scary okay so basically we have our
our CR dt supposing that we have three
replicas okay as a matrix each line its
corresponds to an replicas each column
corresponds to an replicas okay and now
I will show how we updated this matrix
so we start with all zeros meaning that
Kira was the counter is zero okay and
now I can increment in in the first
replica when I increment in the first
replica okay I will write the the matrix
in the position 1 1 okay if I increment
in the second replica I will use the
second line second column ok saying that
I'm incrementing and the same thing for
the third replica so I'm incrementing
instead of Africa by eight I will use
third line third column 8 okay later on
I will explain exactly what each line
and column means so now we want to do
the comments ok we have done increments
we can always do increments no problem
ok now I want to do a decrement so in
first replica I want to decrement by 15
I will not explain at this moment I will
check if we can decrement by 15 or not
but we know that we cannot because in
that replica of only incremented by 10 I
have not synchronized with
replicas so this will have to fail okay
later on I will explain I really
understand that it needs to fail so in
the second replica I want to decrement
by five okay this replica I can
decrement by five and I have to hit
record information that I want to
decrement by five so all the way I do
this so I will use the exit column
saying that okay I want to commend five
by five okay so I'll do idea to a
transfer so in the sort of replica
I have incremented by eight so that
means that I have eight rights to do
decrement okay
so suppose now I want to transfer some
of these rights to replica one okay that
wanted to decrement more than ten so I
want to transfer for rights to replica
one so what do i do is i will update
that information in my in my matrix okay
basically I use the last line so
replicas free will always uses this line
okay and we will record that information
in the first column saying that okay
I've transferred for to replica one it's
for right yes because this is the valid
I've incremented okay initially and this
is the value that I've transferred okay
so this is how I update the the matrix
when I do increments or transfers or
decrements okay so all the way merge so
in CID T's when we do a merge we seen
the state of one replicate within the
replica okay and in these guys merging
is pretty simple it's pretty simple
because each replica only modifies its
its line okay no other so in the first
line only replica one touch on the
second line only replicate two touches
on third line only replicas three
touches so to March is
to the max every column so merging the
first replica with the second replica is
just do the max and I could do this time
from replicas free okay and I would have
the various so so now let's look again
how we really handled the comments so so
now we have the this value okay
the this value of the depended counter
and I want to do a decrement by f12 okay
how do I know that whether I can do with
the comment of 12 or not so I need to
check if I have 12 or more rights to do
the comments okay and to do this
basically what I do is I will add the
Iowa at the the position when when in
the matrix that those are the values
that I've incremented okay
so those are the the rights that I've
created okay
I add the values in the in the in the
column the other values in the column
those are the rights that some replicas
transfer to me so that for means that
replica three transferred for rights to
me so I have fourteen rights okay and I
have to decrement the values that I've
transferred to other replicas and that
I've consumed in this guy's I have not
consumed any other any value so far so
in fact I have fourteen rights available
so I can is acute depression locally and
guarantee that I I can decrement and by
the commenting that the the value of the
country will not go negative
okay so Oh what can we do when you use
bonded cutters basically in in summary
we execute operations locally so if
there is no enough rights we file
locally
of course we can try to transfer rights
from other replicas at that moment okay
so we can redistribute it right
proactively okay replicas can be
transferring rights among them or they
can transfer when I do a decrement and I
don't have enough rights I can ask other
replicas to transfer me some rights
so synchronization is using a peer to
peer synchronization and we have built a
prototype on top of react we have we've
done some micro benchmarking okay so we
have deployed this in Amazon using three
three data centers okay and we compare
basically a solution that uses strong
consistency bicyclist inconsistency in
with this approach is having a single
single data center and all updates will
go to that data center okay so latency
is the very slightest is pretty high
because some of the updates have to the
cross to some other data center and we
are using this case we are using the
stone consistency approach of react so
performance it doesn't scales to very
large numbers well we have not so many
keys if we had more keys probably it
will scale more but this is so for
anything apples to apples comparison
this is what we have so if we have if we
have we consistency and this is react
with react counters okay basically we
have much higher throughput and much
lower latency basically each point of
this was is taken by incrementing number
of clients so for some given number of
clients I can achieve some throughput
with a given average latency so this is
what this line means so a line Mart into
this direction is better aligned more in
a per it's it's worse okay worse in
terms of throughput and worse in terms
of latency
so what we can do is something in the
middle we are not as good as as react
via counters native weekly consciousness
okay one of the reasons for this is that
our objects are larger so we have to
store more information okay but we are
much much better than having typical
strong consistency okay
and what of what we also have when
compared with we consistency is that we
guarantee that that evidence will not be
broken while when you use only weak
consistency when you are closing to the
limits the even with a check if the
value of the counter is greater or equal
to zero if you have lots of documents
being executed concurrently as they are
being executed in different data centers
we can execute more decrements then then
then we can okay so this is the bounded
counter so we had a couple more slides
about something some system that we have
done that is Swift thought I will pass
over this slide but just in one minute
what is Swift well we have built a
database there is a paper online that
you can read the idea is that we in
Swiss cloud we have instead of having
just the full database we've moved with
cached part of the database in the
client machines okay and allow
applications to executing those client
machines okay and I will pass all the
slides and I will just give you some
some numbers that I think are
interesting so we have done this so
basically that is we move part of the
data to the client okay
and as we move part of dota 2 client and
allow applications to access the data
that is cached in the
okay in these two lines the the pink and
blue you can see that we have very good
way to see our latency is almost zero
because most of the operations most of
the operations go is acute locally okay
because data will be on cash okay if you
use a typical approach that is going to
a data center the weight issue it will
be worse because we have the time to
send our request to data center and to
get the reply back from from the client
okay so is however when area there that
is important and if you are thinking
about moving your data to the client
side this is an important message that
they that I want to leave here today
that is after you have a first cache
miss so you're in the client you are
executing operations and you have a
cache miss if you miss you have to go to
the server or if you are doing a complex
query where you don't have all that you
have to go to the to the server to to
fetch more data as soon as you go to the
server you are in two problems okay your
idea of getting your data into the
client is not so great anymore because
you may end up having to go to the
server instead of going just once you
might end up going more than once to to
fetch all the data you need okay so one
thing that that if that you might do if
you are trying to do something like this
is on the first fashion is try to move
your computation to the server the rest
of your computation to the server and
get the ezq temp in the server so just
to conclude let me let me conclude fast
so things that we have learned from our
experience and from experience of others
that are using CDs is that applications
require multiple types of C oddities so
set C R DT will not solve all their
problems okay so when important part is
when you build applications you want
to the composition of multiple see
oddities so the work that Russell and
the batch of people is doing its trick
it's a trick map it's okay it's great
so it's marking is shown so when you see
this you have to lower your expectation
so the system will not behave like
everything is single a single server
okay but you can still enforce some
invariants and you can still do some
interesting things so you can do
multiple keep lights with Iowa with
transactions something that we have in
in sooth loud I invite you to read the
paper so you might have first causality
okay that also helps with some
invariants you might enforce memory key
variance as I shown with the bonded
counter and you can address general
invariant using just right consistency
so that is the the work that that mark
mention it before so with this I
finished my my talk and I can take
questions so those are workers so part
of the work has been doing to those
persons and that's
thank you very much so questions okay
when Mark was talking about waiting
lists I could help but think operational
transformation is there some connection
the connection is that operational
transformation tries to take something
that is non commutative and flip it on
its head and make it commutative after
the fact which i think is the wrong way
to do it might as well make it commuted
from the design point thanks
questions I had a question about the
boundary counters yeah I wondered if you
you have some interesting metrics only
you have metrics on cases where a
bounded counter request failed when they
should have passed because the rights
were in the system but not in the right
location we might have some numbers on
that but that depends usually on the on
the number on the on whether you are
doing proactive distribution of Rights
or not so in our prototype basically
what we do is how do when the system is
is running the replicas try to exchange
rights between them so that they are
more or less even amongst them so in
that case when they are really really
close to the to the to the limit you
might end up into the situation's I
don't have those numbers in fact in our
prototype we have kind of flag that the
the client could ask to be at an on
demand transfer if he really wants to do
that so also with the bounded counter do
you have a heuristic to determine when
one replicas should transfer some of its
how is that decided wind up transfer
we don't have anything fancy we are
doing it periodically after some time we
just we just transfer with it when we
synchronize replicas we use that to to
level up the levels of Rights that each
replicas so you had this graph of strong
and weak consistency if you could go
back to that one or not is that yes the
one with all the data there you go
so I gathered from the names that weak
provides less strong guarantees than
strong yes basically weeks's is plainly
a quick I might overspend I might go
below zero sir with week I might
overspend yes
does BC give you the same guarantees as
strong BC can teach you that you will
not overspend and strong guarantees
you'll not have respond and strong will
guarantee that you will not overspend
the difference is what was implied in
the question bye bye bye Russell that is
if you have if you have a strong you
when you want to do a decrement and you
have only one right available so imagine
the counter is equal to one you go to
the central server in the centre of
servers knows how it's when you can
decrement and everything is fine so when
you have the bonnet counters and for
example if you have just one right and
that's right can be in any replica so if
you are doing decrement in the replica
data that don't have that right your
operation may fail so we'll see you need
to balance things across the different
replicas and with strong you do not
right because you only have one
replicate with strong again with BC you
have
replicas so instead of using squares and
these dot you should have used apples
and oranges okay so I should use Apple a
nerd yes they give you the same service
there it's comparable in some ways but
it would help to clarify what the
differences are as well it's part of
lowering your expectations right we're
giving you something that's very close
to strong consistency but we also giving
you some a lot of a lot more parallelism
okay we tend to use the term trade-off
by the way not lowering your
expectations see me question but most of
these theologies are fine grained data
types right so small things have you
done any research always thinking about
it doing any reason which you took it
about cause grain cities so for example
a graph databases itself the CEO duty a
graph database do you have the graph
data types right we have react supports
very large people have several gigabytes
so I mean it's fine great in the sense
that they're the individual elements are
fine grained but the data itself is very
large and I think you would have the
same you could argue that the graph
database will be very similar because
the the individual element is just you
know a vertex or a or an arc but the the
goal here is to be able to especially
the Swift cloud is to be able to handle
very large databases but only replicate
the the small part that you are
you're really interested in partial
replication which is a very hard problem
actually any more any more questions
so back in your reading list example
perhaps I missed something you had this
operation one of the two replicas could
decide if they would but these are
actually happens so you can't update the
replica yet back and change it after the
fact right that was the point I was
trying to make is that if you want to
maintain its invariance okay to maintain
these invariants you have to have the
precondition so the precondition here is
that you know nobody has bid on this
thing yet right and if you evaluate that
you know locally and you might you might
read the wrong value for your
precondition okay so in these cases I
mean this there there's a proof here I
mean the important thing is that is so
intuitively yes you understand that you
know maybe I need to do something here
but we have a proof that there is only
two choices right either but there it's
a design choice it's a design choice
with only two alternatives one is okay I
need to synchronize and it cannot be a
co duty anymore cannot be available
anymore or I have to live with lower
expectations so I have to live with the
fact that two people could bid at the
same time for the same thing so this is
something we knew intuitively but now we
have a proof
okay any more questions okay completing
the speakers again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>