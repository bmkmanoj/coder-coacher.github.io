<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Deploying Erlang applications in the Heroku cloud: Blake Gentry, Geoff Cant | Coder Coacher - Coaching Coders</title><meta content="Deploying Erlang applications in the Heroku cloud: Blake Gentry, Geoff Cant - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Deploying Erlang applications in the Heroku cloud: Blake Gentry, Geoff Cant</b></h2><h5 class="post__date">2012-06-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/DOF0yeCkEHo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">take it away blank all right my Blake
this is jeff both work for her if you
actually we're both software engineers
on a refuser routing team while giving
up what that means exactly a little
later but for those of you they're not
actually familiar with her I could
probably help stake in the background
there first so what is the Roku we are a
cloud application platform as a service
a bunch of buzzwords i guess but
essentially what that means is that we
manage servers so you don't have to we
like to focus on building your
application and we keep your app running
for you so once wants you deploy your
app on roku if it crashes if a server
dies it's restarted immediately
somewhere else and there's almost no
downtime for you if you're running
multiple copies of your app then there
is no downtime for you one of the big
things about her okay we offer
completely painless deploys so when you
make changes to your code when you push
out a new revision it's totally painless
and almost instantaneous for you to roll
out a new version of it and have it
immediately available live forever to
the world and also in addition to that
we offer simple instant a scaling so if
suddenly your app gets featured on
hacker news or splash todd and your
traffic starts spiking a simple one line
commands ability in order to add 10
times or a hundred times more capacity
to be able to handle it so let's walk
through what it means to get started in
typical cloud employment so what you
normally have to you have to provision a
resource some whether it's an ec2
instance or pick your cloud provider of
choice maybe where X base doesn't make a
difference you have to request that you
have to wait several minutes that to
come online once it does you have to
actually solve all your operating system
packages you know afgan Excel or leg or
whatever else is your X whatever your
app is dependent on and once you install
those you have the pleasure of
configuring all of this and then
security them nobody really likes
writing igenix config as far as I know
so that's never fun job and once you've
actually got your server setup that you
can clone your application and get ready
to deploy it of course if it goes down
you need to have some monitoring to
restart it or to alert you in case your
app crashes and it's an
another thing you got to do and of
course when you grow you have to do this
all over again unless you had the
foresight to do this all with chef or
some automated tool the first time
through and have like a repeatable
deploy process then you've got to
replicate all your work over again to do
this for a second server and of course
that takes a lot of time every time they
need to grow so let's not do any that
deployment broken let's do this every
way to provision a nap same same as a
producing an ec2 instance who could
create simple one-line command that you
run into ER we'll go ahead and provision
a resource for you it'll give you a name
if you don't specify one in this case a
pict cold river 2049 it's just a random
haiku name it sounds better than appt 1
2 3 4 5 and also shows you the URL where
your map is going to be available at and
sets up a get people for you I keep
remote and you're crying app directory
so once we've created that work that we
have to actually deploy our code to it
and that's completely painless as well
so get pushed Roku master oroku receives
your code goes through this process of
detecting what type of app you're
pushing up whether it's Ruby or line or
node installs all the dependencies for
your application and compiles that all
down into false log which is just an
environment that contains you know all
of your app dependencies and launches
that so at one that's done me available
at that address anywhere in the world
instant scaling is the next part of it
that I talked about so if your app
started suddenly sees a nice and rush
hour traffic from getting featured on
the website let's say or or maybe you
have to scale up and down during the day
to meet your demand during business
hours scaling on roku is a simple
one-line command I specify what you want
your new capacity for your process time
to be so let's say that you want to go
from running a single web process to
running 30 of them and maybe running
seven background workers at the same
time at one command in a matter of
seconds all of a sudden you've got 30
times in my capacity as you have before
so it's pretty powerful when you can do
that in sentence so the HT routing mesh
this is actually one of the components
that
and I work on it is built in a run and
the primary purpose here is to balance
incoming HTTP requests to your
application between the guy knows that
that's a term that we have in America
it's basically just that I like sea
container that contains I wanting copy
of your application and you run multiple
dinos they'll be spread out on multiple
like actual virtual machines in the
cloud virtual virtual machines I suppose
but again the point there is that when
when your dinos are you vendors are
crashing or starting and stopping the
routing mesh is smart enough to make
sure that it only rats requests to apps
that are actually running so if a
process does your customers don't notice
because we don't say any more requests
there until it started somewhere else
and of course we're an inner line that's
why I drove into this conference so
languages that we have support for work
dude traditionally we were actually a
ruby on rails hosting company that's
what our origin was and I've actually
moved that to sport all through the apps
and more recently in the past year so
we've been added support for a lot of
additional languages nodejs Python Java
skylight closure there's a lot of
options now but also you can really
deployed anything to work or including
the Erlang which is again why we're here
today so all this language support that
we're talking about comes from something
that we call it build pack really the
gist of it is that I built back just
tells a rogue who how to turn your
application source code into a running
binary and how to deal with you know
dependencies we'll talk and talk about
that little more in depth for the end of
this but that's essentially revealed
backers and there's a lot of existing
bill packs out there these are there's
links actually own each one of these
things will have that the presentation
at the end of this but each one of these
is a different repository that contains
the code for the build pack and these
are things that anybody can create and
anybody can use their own build pack or
use one of these official built text or
you know we have built acts for NES for
example just a lot of random community
contributed contributor build ups and be
able to run essentially any type of
application so we'll talk more about
that later obviously you guys probably
need or more about the Erlang specifics
so right now we currently have build
packs for our 14 B 3 and r
can be also just going to give a
demonstration on that later but first
let's hear about his first early boy to
review yeah so actually one of the the
first applications that I've ever pushed
up to run on Heroku yeah so one of the
first apps that I actually ever pushed
up do any of these mics work I don't
really printer was was an erlang app
that I created to help me debug the
process of creating an erlang build pack
so what I'm going to do now is just run
through the process of like the the
standard create an erlang web app create
an o-line web app in the normal way and
then the extra steps that you have to
take to get that running on Heroku so it
starts off as usual created get
directory for your project rebar out all
the boilerplate because that's kind of
tedious I have modified the the standard
rebar at template slightly and put that
up on github it just has extra
boilerplate that I like like logging
functions and a couple of startup things
to start your OTP app dependencies as
well so I try that make sure that it all
works standard things the dash S example
app command is just a function that runs
through and starts all of the
application dependencies of the
application we're building and then
starts the application itself so if we
if we run this we can get it running
application which applications yep seems
good all right let's commit that to get
yep so far so good but what about the
cloud we said something about that and
so to Heroku comes with a command line
client for interacting with the platform
much in the same way that Amazon
provides the sort of ec2
command-line tools that sort of thing
it's I guess it's a kind of Ruby based
thing so you can either install it with
gem if you have a ruby environment on
your machine already or we have this
kind of standalone installation process
which you can get at tool belt heroku
com it looks like this and we have the
the standalone installation for the
major operating systems that you're
likely to develop on so we recreate the
the Heroku application resource because
we're going to use a custom build pack
we're going to use the the newer laying
ar-15 build pack that I've created we
specify a couple of extra arguments to
create we give the we give the upper
name or laying factory 2012 example and
we give it the github URL to my account
with my copy of the Erlang build pack so
if you want you can take my build pack
and fork it and change it from using
rebar to using email or make or if
you're dangerously insane you could use
auto tools in which case I would disown
you and then we we go deploy the
application where we launch the ec2
instance I mean staller laying and we
clone the app and build it and write
some init scripts and then to bug them
forever oh no wait let's not do that it
is a kind of just what it says on the
box you get pushed your okra master like
the Heroku command line client actually
adds a get remote in when you create the
app and a get directory which is kind of
handy you push it up and we have a thing
called a slug compiler that receives
these get pushes so the slope compiler
allocates actually another app on a
running on our platform allocates a
little container in which it takes your
code it grabs the build pack from that
build pack URL that we specified when we
created the app and it runs the scripts
in the build pack to build the code so
in this case I'm grabbing a copy of
laying our 15 from s3 bringing that down
to the
to the place where we're compiling it
just installing the the copy of OTP
locally using rebar to build my code
round about their ish and then at the
bottom it it keeps the OTP plus my
compiled application files and we get
what's called a slug which is just like
a file system that will use to boot
those LXE containers so we're
essentially pre baking you know our vm
container images and then that gets
pushed up into the magical Heroku
storage space and you just get a little
message at the bottom saying that HTTP
colon slash slash your app named oh crap
com has been deployed to Heroku so at
this point if we had actually pushed up
a web application instead of just like
OTP boilerplate we would be able to
Heroku open this URL and go and look at
our web page but that doesn't work right
now because we have no web processes we
have no web servers in our code base
that are actually listening so we need
to fix that so let's add a web server to
a little example application I did this
with cowboy but you can do it with
anything that speaks HTTP so if you want
to do it with mistltein or yours or
whichever then that's that's entirely up
to you because I'm doing this in rieber
I just add cowboy as a rebar dependency
both in my rebar config and I add it as
an application as an OTP application
dependency in my app file get depth and
we compile it and then because we're
good little developers we test our code
before we push it this doesn't actually
happen in real life I just you know made
nice for this wait we we start adding a
few more vm arguments so that we can get
this thing to start up properly we need
add the the Earl libs environment
variable so that our debts directory
full of currently cowboy and proper will
be picked up so that cowboy can be
loaded
here I also add an OTP application
config variable which I'm not quite
using yet but we will get to it called
HTTP port so that I can tell my I can
configure on the command line what port
my web server is eventually going to
listen on so if you run it at this point
you can see that it all starts up so my
application startup happens correctly my
example F is running cowboy is now
running as well and if I inspect my
applications environment configure I see
that the HTTP port thing is there and
available ok well it's that's cool beans
now we actually need to get it to do
something when we when we hit it so this
is about the the shortest cowboy HTTP
handler that I figured out how to write
in that it just does a 200 ok text plain
hello world for any requests that hits
this handler but it is a complete little
cowboy handler so now we're at the point
where we have cowboy running but not
actually listening on any kind of port
and we have a request process and module
as well and we need to configure cowboy
to actually use those things and listen
on that port so that it will do
something useful so what I decided to do
is add an OTP start phase two the
application so the system will start up
start my top level supervisor wait for
all of that stuff to be running
currently there are no children of that
but in a non-trivial application you
would probably have to do something at
startup read some information from disk
maybe establish some connections to
back-end systems and so on and so forth
and you don't really want to receive
traffic before all of that is done
because if you did receive traffic than
you would throw a bunch of errors so we
just went until our supervisor startup
is complete before we actually go and
configure for sort of inbound traffic
so added a start phase called listen and
a start phase function in my application
callback module which just configures
the cowboy listener to to grab the HTTP
port out of my OTP environment and then
add my little HTTP handler module as the
thing to dispatch to for all requests
okay so that's all fine and good use the
same command line that we did before we
check that it starts up that's cool and
another terminal window we curl it and
we get back hello world okay great so do
we need to do anything else to make this
work on Heroku yes we need to add
something called a proc file and a proc
file is Heroku is equivalent of a net of
an init script and how it works is you
have processed types and commonly on our
platform those are usually like there's
one call there's a process type called
web which is something that our ralphing
layer will send HTTP requests to and
then any other process type can do
whatever you like frequently people use
them for sort of background and batch
processing kind of jobs so what I've
done is I have just taken the command
line that i was using locally to test it
and I've said that that's what I want
the system to run for web process types
the thing that got cut off on the end of
the slide is just dollars or caps port
when when the Heroku platform boots your
LXE container it pokes some environment
variables in there and one of those is a
variable called port which tells you
which port you should listen on for
traffic from the routing layer we also
needed add no shell and no input because
there's no useful standard in in the
cloud and then the tedious deployment
process again we have to get pushed
recruit master and then in frozen
margarita and then Heroku open to pop up
our website and maybe we can tail out
logs
but yeah at this point when we did the
code push you know it grabbed down OTP
again recompiled our code it grabbed a
copy of rebar built that all bundled up
into an image that can be you know
easily booted on multiple you know
physical instances inside our cloud
configure the routing layer to listen
for the the domain that we provision for
you the your app name.com you can also
add additional domains to that via the
the roku command-line client so then the
railing layer then spots that your app
has come up and it's listening on the
port that the platform told you to
listen on and it now routes all of that
external traffic to to your app so yeah
the short version of this series of
slides is if you have an erlang
application that you can configure to
listen for HTTP traffic on a given port
that you can start with like a command
line one-liner then you can run it on
Heroku right now with not a lot of extra
work really if you have the existing
project you just need to add the prop
file and that's and get push master and
that's kind of it and so now i'm going
to hand back over to to blake for some
ideas of you know other things you can
do with other platform features so
that's the basic part of actually
getting your app deployed once you've
done that and you're running in the
cloud there's this question of what else
can I do with that what were the other
benefits of running in the cloud I mean
yeah I've just availability to have your
app posted but are there any other
services that come along with that so
Heroku f offers something called add-ons
which are either first party services or
third party services that are also
hosted within the cloud in to believe
their services like Redis or postgres
they're going to be hosted within the
same data centers that we're running
Roku on so these are going to be very
low latency services that are offered by
third parties BF we have our own
in-house Postgres database service that
you can
to use even outside of a Roku app if you
want to it's actually the largest
postgres as a service in the world
there's SMS add-ons Redis all these
things are just available and there is
easy to install as it is to deploy on
rope so installing it out on add-ons ad
register go Oroku add-ons at same
command and a few seconds here I'm going
to have a free rent is a time available
in my app and of course there's varying
sizes that we have to be able many of
the add-ons have free versions Redis for
example gives you a free 5 megabyte
reddest plan but you can also pay
monthly to get larger instances of Redis
available to you so same thing you have
all these all these additional services
available just as your fingertips with a
couple of commands and what we set up
configured for your application for
config shows you the environment
variables that are set up that are
available to all of your diagnose when
I'm running Jeff mentioned poor earlier
which is the one that each diner gets to
tell at which port to bind to there's
also other ones that get set up you can
set these manually or if you had a
service for example the URL gets added
for that surface including the
authentication credentials so all you
have to do is read that environment
variable and you'll know where your
cloud services available so earlier you
said something about build packs promise
we get into that a little more so let's
talk about exactly what they are what
they do so like we said bill pack is
responsible for the language and
framework specific details I'm telling
her how to turn that specific app into
something that can run on a roku and
what that typically involves is
installing your language binaries for
the airline pack we have to install
Orlando TP that might be a different
language let's say you're running nodejs
and you want to run a custom version of
that you have to include that binary as
well that's what the bill pack does
resolves dependencies for your
applications so these are third-party
modules or gems verga gems NPM packages
whatever you want to call it for your
app so during the build process when you
push up a version of your code the build
package responsible for looking at your
bill dependencies and pulling those in
putting them in with a slope so that
they're available
whenever your app is launched and again
has to build and compile the code so
that it's actually a final form that can
run if this is a ruby that obviously
don't have to do any compilation on it
but if it's or lying or go or any of
these languages that require compilation
that's an additional last part that
build back process so there's
documentation available up on our deaf
center telling you a little bit more
about how build packs work and giving
you some some extra links to some
samples but Jeff's actually gonna walk
you through the airline build back right
here okie dokie we have two versions of
the o-line build pack right now one of
them was immensely simpler to write
because our runtime ever jizz had Erlang
debs installed on all of them already so
we could actually just use the existing
pre-installed early and that was easy
and then when I got to the point of
actually wanting like a different OTP
version I can't really upgrade the one
that's there right now because our
notional Erlang are 14 b03 customers
would probably be unhappy if they woke
up one morning and found they were
running our 15 so i wrote a language
build pack that did things in a better
way I pre-compiled some Erlang binaries
for just 64-bit ubuntu it's not anything
amazing I did this by hand because this
was the first build pack that I've
written and I'm trying to brainstorm
ways that I can actually automate this
process for building future versions was
as I was sitting in costs as's talk
earlier today it'd be kind of cool if I
could push up some pre-compiled Erlang
with LLVM compiler options so yeah but
basically the idea is we pre compile a
copy of OTP tired up and we stick it in
s3 just because that's a convenient and
cheap place that we can download it to
all of our compile instances so we have
a directory called cash for that and
which just saves us some copying around
if this language build pack has been
run on this compile machine recently so
then to install it we just untie it and
then we run OTPs wonderful new install
script the install script is important
because it relocates the binaries and
the scripts to wherever we've actually
unpacked it on the file system this step
is a little non-obvious and it's
something I would quite like our build
pack implemented people to fix in that
OTP requires you to run the install
script from basically the location that
you will end up using it from and the
place that builds little slugs and the
place that runs them actually look
different file system wise so i added a
symlink during the build process to to
get around that from here on out it just
looks like a standard bash script that
you would write if you wanted to
automate building summer laying software
we add OTP to our path to the location
we just installed it to we check to see
if the the Erlang source code that the
user is trying to compile already
contains a prebuilt copy of rebar if
they do then we're just going to use it
otherwise we're going to install one
that we include with the build pack and
then we we just run get depths and
compile some sort of said and she'll
magic at the bottom just to indent the
output a bit but that's that's it that's
all it is so if you wanted to build with
a make you would just do l dash make
here if you wanted to build with auto
tools then you can go to hell and if you
wanted to do something different you
know basically it's it's not hard you
just need to write a bash script that
will do it and the nice thing about the
the compile and the build pack system is
that it gives you a repeatable build
environment like the build system the
file system is always fresh
so all of that gets taken care of you
don't have to worry about running the
script once and changing the state of
the file system and then running it
again and all of a sudden your script is
broken there was no cleanup script
between that you have to worry about and
do you just did yeah no clean up clean
up is terrible awesome alright so what
can I do the Heroku platform has
limitations right now because the I
guess the previous targeted languages
were things like Ruby on Rails and I
guess Clojure web apps and PHP and a few
other few other things that have enjoyed
good support those web applications are
built in a way that you guys all know is
different from the way we built Erlang
stuff they're simple processes that
don't communicate with each other to
coordinate they have some kind of shared
resource like a database or a Redis or
what have you and unfortunately the
Heroku platform was basically designed
to do that so we don't allow
communication between our appt
containers right now also our routing
layer only recognizes a single TCP port
to route stuff into you with so yeah I
mean these these limitations add up to
things which are difficult to build you
know distributed elaine systems on
because you can't run Erlang
distribution between your dinos right
now yeah that's so yeah basically if you
want communication between your dinos
they have to have a shared resource like
a Redis or approach grace or whatever so
that sucks that's you know you can you
can do it right now and that's great and
for everybody that wants to build Erlang
where bets that look like you know
traditional rails apps that kind of
thing you can do that right now and I
would have to say that in my earlier
Erlang career would probably be two or
three years into Erlang before I
actually started building multi-node
systems so this is enough for some
applications however I'm way past that
point now
and I would like it to be an awful lot
better so ideas that we have in mind
right now and the lawyer in my head is
telling me to say that these are
forward-looking statements which no way
reflect what I'm actually going to do
and if you believe will make investment
decisions based on this then you deserve
all the fail you will so richly get ya
so we know that if you're going to be
building or laying applications and you
want to run them on Heroku chances are
you're not going to be building just web
apps or if they are web apps then they
also do other things like they make
connections out to IRC servers or XMPP
servers or you know who knows what
they're going to probably speak some
kind of other protocol at some point you
can make outbound requests from your
dinos today but we haven't yet added a
way to to give you additional like
inbound tcp stuff we do have like a
running experimental feature called tcp
router which which lets you do that but
unfortunately it routes to the same port
that you receive HTTP traffic on so
you'd better be using one or the other
or your protocol had better be able to
distinguish between an incoming HTTP
connection and and then coming whatever
protocol connection so that is highly
suboptimal and we also want to let you
down multiple ports so that it's easy to
distinguish what protocol the incoming
traffic is going to be on we definitely
want to allow Dino Dino networking we
have some ideas around there and
holger's talk about open flow and open V
switch was terribly fascinating and
that's something we're going to be
investigating very shortly so yeah we
think that if we worked on these
particular aspects then we would be able
to run a 5 greater range of Erlang
applications maybe finally actually be
able to run react on the Heroku platform
it's kind of like one of the goals that
I have in mind for for some of this work
already I guess this is the part of the
talk where we normally do this but you
know lolz JK I guess we probably are but
we're not really set out on doing it
what we would like to do is
we have offices here in San Francisco so
if you want to come and talk about you
know erlanger stuff or cloud stuff or
you know the perils of running on Amazon
or the tremendous opportunities of
running on Amazon yeah get in touch we
have lunch in the office and ping pong
and drinks and coffee and all kinds of
things and yeah we'd love we'd love to
chat we're also trying to get into the
habit of running Earl lounges for the
San Francisco Bay Area a lot more often
than we have done in the past we did one
back in January February and there was
actually to my mind like a surprising
amount of sort of novice or just
interested people who weren't
necessarily professional were lying
programmers who turned up so I think one
of the things that we would like to do
is use that to get a few more people
into writing Erlang apps so we're kind
of hoping that we'll run some like code
workshops and style workshops so come in
and you know we'll have you know some
kind of style guide for elaine
programming or you know improving
existing beginner projects and just
showing you if you use things like
supervision trees and OTP style and your
code the benefits that gives you so that
group is run through meetup com and i
hope to make an announcement about a no
large scheduled inside of the next month
cool ok that's I think all we've got so
any questions students yes
the question was if you use a build pack
does it block you from using other
languages in the same application at the
same time um so I think the answer is
yes yes they know there's as far as I
know there's no composite build packs
out there right now and that's that's
something that we're looking into we've
always found that it generally makes a
lot more sense to separate there's those
languages into different applications
different logical apps on Heroku just
makes for a much cleaner process but
obviously if there's some specific use
cases for that kind of thing we're
always interested in hearing about those
and seeing what we're what we're not
covering currently yeah i think the the
approach that people use on Heroku right
now is they have those shared resources
the Redis of the postgres and you have
multiple apps configured with the same
shared resource credential should also
mention apps are free so you can create
single process apps for free it's only
when you scale them up and add
additional resources that they actually
cost you anything so the overhead of
having a neck strap is next to nothing
which obviously it helps with that
problem yes every app gets one free Dino
a month so it's kind of nice for
experimentation alright anybody else
burning questions yes actually no I have
not we don't have anything published on
that there's a lot of important people
that have gone out and tested that so I
can't really point you to anything in
particular but I'm sure if you search it
should that aren't turn it up it's
obviously it's it's a multi-tenant
system I think you get 768 megs of ram /
downs it roughly on there in right so
the RAM thing is the only thing that we
actually guarantee you but aside from
that yeah feel free to test it out and
like we said they're cheap so you can I
mean given that I would expect the
performance of an erlang web server to
be relatively more efficient than it
rails out
and we have some pretty large customers
running some pretty high traffic rails
apps on the platform but no I have no
measurements no we have no limitations
whatsoever on the threads that you can
run or released if we do they're very
high so there may be a threat of it but
it's not one it's definitely dozens or
hundreds of my shirt so I the the
question was about do we have thread
limits and dinos or was it concurrent
HTTP requests because we support both
you can run multiple definitely multiple
threads I think you can even run
multiple unix processes inside your Dino
so you can spawn executables if you want
and additionally the routing layer has
no concurrent number of requests that
are consent your Dino limit not in Cedar
anyway on a rod staggered did but you
stack the one that actually runs over
like that there's no limitations as far
as being a floor on lots of requests a
single die at once yeah I should also
add one thing that we're that we care
deeply about is making it so that
there's as little change as possible
that's necessary to run your app on
Miroku and once you do that there's
nothing that prevents you from taking
that exact code and running it somewhere
else I think that's one way to be
different from App Engine and that
there's no vendor specific aspects of a
roku and most of the things that people
sometimes think our vendor specific are
really just like best practices that
people would do elsewhere if they really
thought about how they were setting
things up so there's nothing that
prevents you from running any Heroku act
like just taking it in a couple of days
and setting it up on amazon if you want
to but of course you lose all the
benefits of it there yes
what are like fun what about so the
question is about using zeromq or
RabbitMQ as the shared coordination
point between your dinos if we have a
rabid mq vendor in our add-ons program
or if you want to run your own rabbitmq
on ec2 right now you can absolutely go
and do that VI are actually does have an
rabbitmq adam i believe it's and data
still but so that's one option of the
troll in me just wants to say it seemed
the cloud yep right so repeat for the
people on the recording so it's concern
obviously is that if you don't know
where that third party services running
it could possibly be like another
country or be on the west coast and your
app is running on the east coast of the
US there's going to be quite a bit of
latency between those those endpoints
but I think all of our add-ons that I'm
aware of that are in any way latency
sensitive those all run in u.s. East
those providers are running at least
servers in there or at least very close
to us use the Amazon so that's very low
latency it's it's no different than it
was it was running on a Roku so cut off
yeah does that answer question I mean we
don't provide a whole lot of control
over placement at the moment largely
because we are mainly in one amazon
region so we can currently guarantee
that all of your resources are in u.s.
East and as we add support for extra
regions and stuff then we'll change the
command line tool in our API it's so
that you can spare
five placement that sort of thing okay
any last questions all right thank you
very very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>