<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Lambda Days 2018 - Daniel Krzywicki - Scaling functional multi-agent computations (...) | Coder Coacher - Coaching Coders</title><meta content="Lambda Days 2018 - Daniel Krzywicki - Scaling functional multi-agent computations (...) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Lambda Days 2018 - Daniel Krzywicki - Scaling functional multi-agent computations (...)</b></h2><h5 class="post__date">2018-04-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Bzm5zZu9vOo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi my name is daniel savitsky I'm a PhD
student here at agh University of
Science and Technology and also a
technical lead at Fabri noble
technologies and today I would like to
share with you the most reasons of most
recent results of my work on concurrency
in multi agents computations using
reactive streams so first let's start
with a bit of context the domain of my
work our evolutionary multi-agent
systems they are a class of optimization
algorithms which combine multi-agent
systems with evolutionary algorithms so
just like in evolutionary algorithms we
evolved a population where every agent
represents a candidate solution to the
optimization problem however just like
in multi-agent systems there is no
global knowledge there is no central
selection mechanism and selective
pressure emerges from individual agent
interactions so this hybrid approach has
proven very efficient in hard
optimization problems and it lends
itself very well to parallelization as
we'll see later so here is an example of
a very simple MS with such emergence
elective pressure so first we create a
population of agents where every agent
is given a candidate solution this
associated fitness and some this
discrete non-renewable energy and then
agents interact with each other and for
every pair of agents even have enough
energy they reproduce and create new
agents as a result the children will
have the candidate solution derived from
the parents using variation operators
just like in evolutionary algorithms
however they they will also get some of
the energy of the parents as a result
however if the meeting agents don't have
enough energy they fight they fight by
comparing their Fitness values and the
winner takes some energy from from the
loser
and finally if an agent
if an agent's energy drops to zero he is
removed from the computation so by
following these rules agents repeatedly
interact they repeatedly fight and
reproduce and better agents will
accumulate more energy and will be more
likely to reproduce and also there will
be Selective pressure in the system even
though we don't have any central central
points which dictates who who wins and
who loses yeah so just when one node
because of these energy dynamics the
population size involve algorithm
doesn't needs to be fixed like in
traditional level evolutionary
algorithms it can change over time
however it is bounded by the total
number with the total amount of energy
in the system which is fixed and in
contrast with traditional evolutionary
algorithms this decentralized nature
will make it very easy to paralyze
however initial implementations were
mostly sequential or at best they were
paralyzed in a very naive way following
what is called the island model where we
just divide the population into sub
populations and simulate each one on a
separate on a separate thread or on a
separate node and occasionally you
communicate between them by migrating
some individuals you do that because you
want to keep the communication overhead
very low however that's not really
efficient especially on modern many core
hardware so for the last few years I've
been exploring new ways to introduce
more concurrency and more parallelism to
these kind of algorithms parallelism is
like I said this is useful to take
advantage of modern hardware and
concurrency is interesting in turn
because it allows us to more closely
model the centralized agent paradigm so
in previous work we introduced a design
pattern which allows to actually
decouple the semantics of algorithms so
for example the rules I just showed you
from the actual way agents will meet and
interact with each other and we did it
binds by in a way which is inspired by
the MapReduce programming model for
ensured the algorithm the semantics of
earlier
can be defined by two kinds of functions
the first function is a behavior
function which defines what agents will
do depending on the state so depending
on the set of the agent it chooses a
behavior in our previous example
possible behaviors will be fight
reproduction or death for example and
the second function defiance would
actually happen when agents of similar
behavior meet so for example fighting
agents will exchange energy while dying
agents will simply be removed from the
output so how does it connect well in
other words we first compute the
behavior of every agent this is similar
to the mapping phase of a MapReduce
algorithm when we group agents of
similar behavior into what we call
meeting arenas and in these arenas we
apply the meeting function on every
group of agents so every such meeting
may potentially yield a new set of
agents which may be empty like in the
death arena which may be increased like
in the case of reproduction and if
finally what we do is that we combine
all the results from all the meetings
from all the arena's into as the new
population now this diagram looks
sequential but there are actually many
ways in which we could compute these
functions and group the agents and some
of these ways could be done concurrently
or in parallel and that's the main
advantage of that pattern as we decouple
the semantics of the algorithm all
that's left is the execution model which
is how we actually assemble those
functions and we can explore different
approaches while being sure that we're
not comparing apples to oranges so in
previous work we've experimenting with
two approaches the first was an
implementation where every agent and
every arena were model as actors and
everything was happening concurrently
from message passing the results were
very interesting there are very
interesting concurrent properties in in
the algorithm however it was a bit
suboptimal as we were still some
overhead related to this communication
by message passing even though were very
clear and
communication patterns in the sense that
the very same agents were usually
communicating with a very same arenas
and and back forth so our second trial
was to try to make these communication
patterns explicit by by composing for
this called parallel skeletons they
stream like fashion so for example well
this MapReduce pattern is something can
be considered as a skeleton which we can
combine with a pipeline to to create
something which resembles a stream and
the results were added more efficient
however we lost some of interesting
concurrent properties of the previous
approach so now in our most recent work
we managed to combine the advantages of
both approaches into an implementation
based on reactive streams and this is
important with variable data right we
could actually model agents as elements
flowing into a stream and buy locally
compacting or expect or expanding the
stream we can make agents meet with each
other interact so that for example can
generate new agents into the stream or
disappear from the stream and not only
is this approach more efficient but as
we all see it also allows to very
explicitly control the concurrency auto
algorithm and so in the rest of this
talk I will present you the main
building blocks of such a model so for
those of you who don't know it while
reactive streams are a standard for a
synchronous stream processing which
allowed to match the rate of producers
with consumers in a stream while
ensuring that we don't run out of buffer
space that's basically it to do it we
use something called dynamic back
pressure and in our case we take
advantage of the fact that in such
streams we can very easily model a
variable element rate which means that
in different parts of the stream we can
have different troop with different
different numbers of allotments passing
debris by unit of time and this is what
we all know has to locally construct or
expand the rate of agents to make them
interact with each other so our
implementation is based on the data
streams library in Scala so it's
trimming Scala is actually build out of
stages stages can have a number of input
and output ports stages of a single
output are called soul
stages with a single input-output sings
and stages with a single input and
output are called flows so basically
sources flows and sinks can model any
kind of line near a stream however in
our case in order to be able to have any
kind of interaction
to be able to have some interactive
properties of our algorithm we'll need
some kind of feedback loop in the stream
so we need stages with multiple inputs
and multiple outputs and fortunately I
can stream provides several such stages
out of the box so there is a conquered
stage for example which will consume the
first input until it is completed and
then it will start consuming from the
second input and there is also a
broadcast stage which simply emits every
input element into both outputs yeah
so first let's see how how to model an
evolutionary algorithm which is
iterative by nature as a reactive stream
of individuals the first building block
in our solution will be a looping graph
something to make or introduce a loop in
the stream so let's break it down so
we'll have an initial source which will
contain the initial population of the
algorithm will have an infinite sink
which will keep draining edges from the
flow and for example it will be
computing some statistics will have a
main step stage where the actual agent
interaction will be happening and then
will be have a feedback loop with an
explicit buffer in it so how is it how
will it work
so first the conquered stage will
consume all the agents from the initial
source they will flow through the step
stage and into the broadcast which will
broadcast them both into the sink and
drive into the buffer in the feedback
loop and when it's done when the
internal source is all processed well
then the conquered stage will start
consuming data from the feedback loop
again through the step stage and back
into the buffer and that's what will
create an actual loop in varrock in
algorithm like I said it is in the step
stage that the actual agent interaction
will happen so for every agent which
will enter the stage
for maybe zero one or more agents which
will eventually leave the stage yeah so
now for those of you who know extremes
or reactive strings in general it's not
trivial to ensure both of the live knee
less and the boundedness of a stream
which has feedback loops in general
either the total number of elements must
be bounded and not exceed the capacity
of the internal buffers in the feedback
loop order must be a conflating stage
which can compute aggregates out of roll
values fast enough we in our case it's
it's it's simple because the maximum
possible number of agents is bounded by
the total energy in the simulation so we
can just size the buffer accordingly so
a second building block is within the
step stage this is where the meeting
arenas are implemented so the flow of
incoming agents is actually partitioned
by behavior this is why where we apply
the behavior function and we start a sub
stream for every behavior and in every
sub stream we use a grouped within stage
I grouped within stage will accumulate
agents until a fixed number of them are
received or some timeout passes so
basically it will transform for example
a buffer a group within stage of size 2
will actually transform a flow of agents
of elements into a flow of pairs of
subsequent elements okay
and then every such pair will go through
meeting stages yielding a variable
number of output agents depending on the
kind of of behavior the mythix of
subsequent pairs are paralyzed as much
as possible and eventually all the
outputs from all the meetings from all
the behaviors are marriage into a single
output stream so far so good so with
these two building blocks we could
actually run the algorithm by plugging
these media arenas into the step stage
however the results won't be very great
because there is not enough randomness
basically agents can mostly interact
with their neighbors in the stream with
edges which can just before just after
and usually in in evolutionary algorithm
stream you need much more stochasticity
to have better results in general so how
can
shuffle an infinite stream when we
actually never see the entire population
at once
well our idea is based on an algorithm
called reservoir sampling it's a
technique from selecting a sample of
elements from a possibly infinite stream
it basically works by maintaining an
internal pool of selected elements and
every time we observe a new element
we'll replace it with one of the
elements in the pool with some
probability and the probability changes
over time so that when we stop the
sampling every element we have observed
so far has an equal probability of any
lack of ending up in the result so we
use a similar technique to actually
shuffle the agents in our stream we
maintain an internal buffer and fill it
with incoming agents and when an output
element is requested by the down stream
we select an a an agent from the buffer
we according to some policy as observed
from a side the order of agents appears
to change and different policies I want
to simulate different execution models
for example the first strategy we
explored was simply a random shuffling
buffer so we maintain an internal pool
and every time we an output element is
requested we just choose one randomly
sum from the point of view of a down
stream for lemons look like they are
randomly shuffled of course not every
permutation is possible as will have to
consume the whole stream into a buffer
right and also not every permutation is
is equally probable however by changing
the size of his buffer we can increase
the number of possible permutations and
also make the distribution more uniform
however if we increase the size of a
buffer too much we might like we may pin
too big too big a fraction of the
population so we we can vary the
trade-off here with a bigger of the
buffer the more shuffle the stream seems
but the last agents we have to do the
actual virtual interactions so another
very simple strategy is best fitness so
basically every time we choose the agent
of the best fitness to go into the
output and then another strategy is it
is actually combining those two so we
have a hybrid buffer which behaves like
the first
with probability P and like the second
one with probability 1 minus P and the
probability P decreases exponentially
over time right so like just like in
simulated annealing so at first it's
more random and there is more and then
it's more than deterministic and the
final strategy we consider is more
complex but it's very interesting
because it actually allows to simulate
within a stream a classical sequential
discrete step execution so actually we
have within the buffer we actually
disconnect the input and the output and
we keep consuming the input until all
the population is inside how can we tell
well we know the total energy in the
system so when we observe that the sum
of the agents energy in the buffer is
enough we know that we have consumed the
whole population then we actually
shuffle it and we close the input and we
open the output and and then we wait
until the population is fully drained
from from the buffer so in this way we
can guarantee that agents from different
generations never ended and mixed up
with each other so using this butter we
can actually we show in a paper that
this model the streaming model is
actually more general than the previous
ones as weak they can be simulated in
this way so we applied the algorithm to
to classical benchmark problems in
optimization algorithms for a string in
under active function I won't bother
with the desired results there will be
in the paper but basically the main
conclusion we can draw is that the
barrier buffer actually really had
similar characteristic to a sequential
to a sequential execution so it was
really simulated like a classical
algorithm the random buffer had similar
characteristics as our implementation
based on actors so basically it
simulated the dispatcher in a in an
actor based implementation however it
was the unyielding which actually
performed better because it gave more
randomness in the beginning to allow for
greater exploration of the solution
space but as time went by it
narrowed the Selective pressure and and
allowed to to more faster converge in
the later stages of the algorithm so
what's the what's the future work well
we want to explore other shuffling
policies for example ones with more out
adaptation so for example that we could
detect that converge that we have
provider convergence or to adapt the
randomness of the shuffling we also want
to extend the model with support for
multi multiple populations so again to
be able to simulate an islam model on
this kind of stream and finally we want
to test algorithm or on real-world
optimization problems not only
benchmarking once so that's it i hope
you enjoyed it do you have any questions
thank you for the presentation and I
wanted to ask are there any github
repositories or sources online with this
works that you can have a look at and
run and see how it works on our
computers yeah yeah actually all this I
published a small library while it's not
production already it's more to like a
showcase for my PhD start my PhD work
this streaming stuff is still not on the
branch which is not merging Fumero main
the main one but you may you can check
it out
and run it locally I think I will share
the slides and the link to the repo with
other organizers later
if I heard you correctly you mentioned
that the actor approach was somehow
suboptimal can you elaborate on that
especially that we have more time though
so you mentioned that the actor approach
gave you like interesting interesting
possibilities in terms of concurrency
but has been suboptimal you like shuffle
to do two different topic so could you
elaborate what was yeah well actually we
observed very interesting results where
we actually when we actually plotted the
best fitness the best solution found at
a given time
but not on the x-axis not not we didn't
put the time but the number of total
evaluations of the fitness function
right so it's it's a bit like a measure
of efficiency of the algorithm and we we
found out that this actor based
implementation was not only being faster
or slower than a traditional one
depending on how many cores we gave it
but it was actually like quantitative
quantitative quantity
chiefly better in the sense that the
shape the shape of the progression of
fitness over the number of evaluation
was was significantly better so there
was something happening which was just
which was wasn't only just more
efficient than in a traditional non
paralyzed algorithm but it was also more
effective however the problem is that as
we had what we had not direct control
over the dispatcher so we had we
couldn't really control for the
concurrency right something was
happening it was better but we didn't
really know why so in this model we want
to make this concurrency more explicit
because basically in this shuffling
buffer we can simulate any kind of
dispatcher
thank you very much for the talk I have
a question
what kind of real-world problems do you
have in mind when you're like done with
a benchmark and you're sure that your
algorithm is efficient enough like what
kind of problems are you going to test
it against well actually an example of
problem which which can be handled with
kind of algorithms if is optimizing a
marketing campaigns and we've actually
had we've tried a company using our
research to do that in Sweden it wasn't
based on this implementation this in
this model but the previous one the
skeleton based one which was was done in
Erlang so it was actually put into
production another another kind of
application is for example optimizing
employees schedules or where any kind of
team is actually any kind of opting of
hard optimization problems for which you
don't have specific algorithms which for
example construction construction
algorithms which are really suited to
this particular kind of problem this
kind of this kind of algorithm are
working on are called metaheuristics in
the sense but they're really abstract
from the underlying problem they have no
knowledge at all about the problem
itself so basically they can be applied
to any kind of optimization problem and
for those problems for which there
exists a specialized algorithm they will
be worse however they also work on
problems on which there is no special
either specialized algorithm
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>