<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Riak on OTP-19 - Ted Burghart | Coder Coacher - Coaching Coders</title><meta content="Riak on OTP-19 - Ted Burghart - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Riak on OTP-19 - Ted Burghart</b></h2><h5 class="post__date">2017-03-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/TcUTsYjEon4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">morning I'm Ted Burkhart I'm an engineer
at Bosch oh we make react i tinker with
the Erlang VM actually I've done a lot
of that before I got into this
conversion process and some other things
playing around with the Erlang VM
internals and trying to use them to our
best advantage so a lot of people have
asked us about getting react off the
current version of OTP that it's on and
on to something at least a little bit
more current and I'll try to fill you in
on the adventure that that has been so a
brief agenda these are roughly two
things that I'm going to talk about I
hope it'll be straightforward as we go
along and we're gonna do my best to
allow a few minutes for questions at the
end
I expect that some people here may have
more in depth questions I'll be around
for the remainder of the conference if
you want to pull me aside we're gonna do
a question and answer thing at the 255
breakdown on the tenth floor later on
which is not specific to this but
questions are welcome so there are
basically two flavors of react kV and TS
kV is the basic key value datastore and
TS is a time series data store ts is a
newer product it shares a lot of the
backend with kV but I'm gonna focus
mostly on the kV side since that's where
the current effort to get on to a
current version of OTP is focused TS
will come along after that and in fact
that's part of the plan is after we get
kV then we merge the TS stuff with the
kV stuff to come out with one
consolidated product that will runs on
current OTP we'll see how that works so
as most you know reacts in no sequel
database it's based on Amazon's dynamo
model so it's widely distributed it's
highly resilient
two network partitions hardware failures
it's very scalable and of course it's
written in Erlang
so getting into what goes into react
it's mostly open source we have an
open-source version and an enterprise
version that has some additional goodies
add it in for paying customers most of
what I'm talking about here is just
relates to the open source the
enterprise version just is more of the
same it's comprised of depending on how
you count 60 or so github repos maybe I
should turn off the sound on my phone
roughly a third of them are now Forks
they weren't always we used to use them
out of their originators repositories
and we'll get into that in a little bit
and there are again depending on how its
configured roughly half a dozen if
libraries that are implemented in C and
in a couple of cases C++ and a couple of
those are pretty substantial so the
current 2x series runs on bash has own
fairly heavily modified version of our
16 which is obviously a few years old
we're up to the 10th iteration of it and
I've avoided doing any more revisions to
it since 2015 although our product
managers were just asking me last week
about hey there's this cool new feature
in OTP 19 can you back forward it to our
16 and we're just no no we only support
16-bit Intel processors which allows us
to make some modifications that wouldn't
necessarily be compatible with other
platforms so we've been able to add some
performance improvements and we've done
a lot in the SSL area to tighten up
security there mitigate Pluto attacks we
have actually back ported some resource
leak patches and
stability patches from later versions of
OTP we've made some separate revisions
to handle malformed certificates more
gracefully and there's some other odds
and ends in there but the bulk of it
deals with performance and SSL stability
and as I said I'm trying really hard not
to modify that code anymore and we have
paying customers so it's a database and
they'd really like it if we don't lose
their data mm-hmm so we have to be a
little bit cautious about what we change
and where to make sure that we don't
lose or corrupt data that's stored in it
because that's the sort of thing that
gives databases a black guy a little but
about bash oh we are not a huge
corporation we have ongoing product
releases to address customer requests
things that we know we can improve and
of course trying to attract more
customers so we also have finite
resources because we're not huge so we
can't just throw a hundred people at
this or any particular feature so I
actually get called off onto other
things as well which is which adds some
delay into the process it's unfortunate
but it's the way it goes so moving react
to the next version of OTP or something
after that should be easy right maybe
not so in 2014
OTP 17 came out we looked at it and
thought we should see if we can move to
that now mind you at the time there were
still some people who were still having
like night terrors about the move from
hour 15 to 16 in the react codebase and
they they were a little bit jittery
about this whole thing but that winter
we put put together a plan to do that
the idea was to maintain backward
compatibility of the source code base so
that the same production source tree
could be built on 16 and 17 and that
would allow us to
compare performance and behavior and
things like that regression testing we
still had a lot of our 15 compatibility
in a lot of the source repos because we
were still supporting a previous LTS
version of react though the 1x series
was still supported at that time and it
ran on our 15 and the plan is we'd use
compile time conditionals preprocessor
macros and that would give us the
ability to perform regression testing
and all that good stuff and keep the
source tree compatible so that meant we
were going to keep the same build
structure as we had in the current
branch which was based on rebar - using
make files to glue the steps together
because rebar - couldn't really do as
much stuff as we needed it to do rebar 3
of course was in its infancy then so it
wasn't anything we were ready to build
our production system son and there was
also some debate going on whether we
might want to transition to the Erlang
make based build model luckily we
avoided going down that particular
rabbit hole long enough for it to become
moot with rebar three subsequent
adoption by Erlang I took on the task in
the winter 2015 and I wound up creating
OTP 17 branches in dozens of
repositories we attempted to use
third-party repos where they sat in
other words if we were using somebody
else's repo we didn't fork it we tried
to use it directly because we wanted to
the theory is that you know if somebody
makes an a fix in their in their repo we
want to we want to pick that up and pull
it in and we tried to work around issues
as they came up with compatibility
macros you know things like the name
space type macro that you've seen
everywhere and left the left over are
fifteen crypto compatibility because
that API changed in 16 and there was a
lot of stuff left over for that so as a
plugging along through it and I started
to realize that maybe it was a bigger
task than we originally thought
so what went right with it well the
compatibility macros and the
repositories we had control over worked
out okay
for the types that have moved into
namespaces we were able to handle that
without too much trouble you've all seen
how it's done probably some of the API
changes we handled at run time instead
of compile time
for instance Erlang system monitor was
extended in 16 bo1 but because of
preprocessor limitations it was easier
to detect it in runtime and adjust the
configuration accordingly than it was to
conditional eyes half of a gen server
module the change to UTF source utf-8
source code got a little hairier places
because we do have some places in the
code especially in tests but in the main
code as well where we beat the system
pretty hard with unicode characters and
it took some work to get those
modifications to all those pieces
working together correctly what went
wrong we were too optimistic in our
planning you've all done that there's no
two ways about it
building with the hodgepodge of make
files and rebar scripts especially
pulled in from those third-party repos
who was pretty painful at times as I
mentioned before rebar too could handle
steps for us but not sequences so we
still wound up with make files some of
which we're not pretty and as I just
talked about our language preprocessor
is actually pretty weak if we could
conditional eyes at the line of code
level or even distinct function heads as
opposed to the entire function and make
things a lot easier
and using the third-party repos in place
turned out to be a big mistake and I'm
gonna get into that a little bit more
we also found that we had more technical
debt than we realized you can call it
skeletons in the closet or dirty laundry
or whatever you want any large body of
code has stuff in it that you're not
proud of when you pull stuff in from
third-party repos you don't necessarily
have any control over what's in them
those may not be technical debt of your
own making but you still have to pay the
bill so there were a lot more things
than we realized starting out now mind
you this is only for OTP 17 and as we
move forward to 18 19 and 20 there's a
lot more that comes up but we're still a
couple of minutes away from that I'll
get into the second item dependency
he'll shortly but the basic idea is that
it's really hard to manage dependencies
in a large graph of interdependent
repositories and data encoding this was
one we didn't see coming at all and it
caused us a lot of pain the issue was
that in our 16 that default encoding was
latin-1
and an OTB 17 the default encoding
changed to utf-8 if you wrote some terms
using the i/o libraries P format in
Latin one it could potentially put
characters in the output file that when
you read them in in the default of utf-8
would blow up the parser take down the
process that was doing the reading we we
had cases where we were storing
configuration and status information as
terms in our 16 and when we read them
back it took down the process and of
course the key here is to write an
encoding marker into the file or to
write them with the W format but these
were files that are already been written
in customers databases so we that kind
of blindsided us and it was
obviously a backward compatibility issue
that we're gonna have to deal with what
we wound up doing was standardizing on
writing with the W format specifier and
hoping that we can get everybody
converted over so that when we release
on a utf-8 based version
none of those files will still be left
around that's what we're hoping so the
end result is gee maybe this isn't as
easy as we thought it's a recurring
theme you'll see the recurring theme of
skeletons in the closet but there's a
lot of stuff under the covers so we just
didn't realize we were facing when we
tried to do this now at the same time we
were trying to do this we've course had
product delivery pressures and it was
clear that it was too difficult to get
the product onto ot b17 when we thought
we could so at the time OTP 18 was chest
out and it obviously had significant
differences even from 17 much less 16
and we realized that things weren't
going as planned was 17 and maybe we
should step back get caught up on some
of the product features and regroup was
a better plan in a little bit so we did
get back to it late in 2015 and by the
spring of 2016
we'd come up with a new plan figuring
that OTP 19 would probably be the target
even though 18 was current at the time
we were learning that this was going to
take time and we were a lot more
pessimistic in our planning we realized
that we really needed a strong
definition of exactly what it was we
were trying to accomplish so the plan we
came up with was all of the repos would
be in the bash o org if it was a third
party we'd fork it so that we could make
whatever modifications we needed to and
protect ourselves against anything going
away because of somebody closing their
account on github or making a repo
private or who knows what
we actually have experience source-code
vanishing off github overnight and we
were lucky in the past really lucky in
that I had just cloned the repo the day
before but we didn't want to leave it to
luck in the future the OTP 19 target was
going to be strictly rebar three rebar
three was viable at that point it was
apparent that it was the way forward and
we weren't gonna use rebar to or make
files or rebar config scripts were gonna
make a clean break and we were only
going to target OTP 19 we weren't going
to try to maintain backward
compatibility with 16 or any other
previous release now odds are that when
we're done we'll probably be compatible
with OTP 18 I have not hit anything that
I've felt we were gonna have an issue
with between 18 and 19 but we're
definitely not going to be compatible
with 17 and certainly nothing before it
so as part of the pessimistic planning
we went into it with eyes wide open and
said okay there's technical debt we're
going to run into on my previous pass
through the repos I've gotten an eyeful
of a lot of them and we've got to take
it on head-on we can't dance around it
so obviously we're not going to fix
everything that we don't find to be
perfect about our and everybody else's
code bases but for the stuff that really
needs to be fixed we're going to fix it
rather than trying to work around it
we're gonna do something about the
dependency hell and I will get into that
and to the extent that we need tools to
do the things we need to do we're going
to build the tools initially we thought
that we'd write some custom scripts but
I think the solution we came up with is
actually a lot better so for react on
OTP 19 the definition of done is that it
builds to release with rebar three means
we're going to employ relics instead of
rail tool and some of the other pieces
that we have cobbled together we still
don't know for sure how much pain that's
going to entail because we haven't
gotten all the way up to the top of the
stack yet we're gonna have consistent
dependencies you'll see this subject
you've already seen it coming up over
and over that's because we want a
definition of done to include that all
the dependencies are consistent and that
we have a way to keep them that way we
also want it to pass all of its system
tests so we have some tests that are not
as deterministic as we'd like them to be
given the nature of the system itself
you know it's an eventually consistent
system does that mean that eventually
all tests pass consistently we we don't
know yet but it's conceivable we'll
still have some that are that we have to
average you know a number of runs and
say did it pass at least 60% of the time
or something like that because with
eventual consistency you don't have a
guarantee that the value in in one node
is going to be the same as the value in
another node at any given point in time
and in order to get those tests working
consistently for some definition of
consistently we're gonna take on the
technical debt rather than again rather
than just dancing around it so that was
the top level for react so for every
single repo we wanted to beacon we
wanted to conform entry bar 3 build in
other words we wanted a cookie cutter
pattern that we knew would hold in every
repo that we were working in we wanted
true consistent dependencies not just
consistent in that they all use the same
version of a given repo but that they
all tell the truth about what they
depend on the rebar config file in both
rebar 3 and rebar 2 is a static
configuration it's not actually based on
what the code depends on it's based on
what you tell rebar the
depends on we want to clean xref and
dialyzer runs on everything absolutely
everything if we get any warnings out we
want to find out what's causing them and
fix them or where we have to adjust
options for those specific functions
where it's appropriate to do so the
dialyzer attribute that was added and
ogp 18 it's a wonderful wonderful thing
now there are some places where we can't
even do that MEC comes to mind and where
we want to react to pass all its system
tests we want each repository to pass
all of its unit tests consistently so
patterns rebar 3as profiles yay it's a
wonderful thing this is something that's
been hacked around in rebar config
scripts in make files environment
environment variables phases of the Moon
for all I know it's just there there's a
wide variety of ways that people have
addressed these and they all kind of
suck compared to just using profiles so
we decided to use a predefined set of
profiles some of which are assumed by
rebar 3 and some of which we've just
standardized on this is basically the
list for every repository we're touching
we have a pride profile now that's the
you may or may not know that when you
build a dependency under rebar 3 that's
affected that's the implicit profile
that's used to compile it not for the
project you're working on but for the
things it depends on we have a check
profile which is just like prod but it
forces debug information on the current
build and all its dependencies and adds
X ref and dialyzer configurations fairly
extensive ones the test prior profile
that's the default for a unit CT cover
we also add a pulse profile where we
have
pulse tests there are a couple of repos
where we do and it basically is an
extension of the test profile we have a
doc profile pretty straightforward it's
the default for the doc target if there
is example code we have an example
profile and we have this validate
profile that I put in right at the
beginning which is basically a torture
test virtually nothing passes it it
turns on every warning as and and does a
string strong validation so it doesn't
actually generate beam files it doesn't
stop the compilation when it hits them
but it fills your screen with warnings
over just everything that you might have
done that wasn't 100% perfect dependency
hell so I keep mentioning this and what
the hell am I talking about
so dependencies often have transitive
paths two of them multiple transitive
paths they depend on other dependencies
and on down the chain so each place
those dependencies are declared they
generally have an explicit version
specifier a tag or a branch or commit
sometimes and if they differ rebar can
tell you about it but it doesn't really
give you much in the way of help about
getting them matched up the first one it
encounters is the version you get and
everything else has to live with it
so ideally you want to use branches for
development so you're always getting the
latest work but that's a moving target
to the rebar three gives you a little
help with that with the lock command
packages aren't going to save you
they're fine for stable code but when
they're up to date but you're often
working on multiple interrelated repos
at least in the in the reactor where we
leverage a lot of other repos so you're
often actively developing in a number of
repos in in parallel and you really need
to be getting the heads of there
use me respective branches as you go so
I'm making a modification in react or I
may go I'm changing the behavior of some
API I may then go over to react kV and
make a change in there I've got all
these things in my checkouts directory
it's it's not realistic to suggest that
I can that I can use packages for that a
couple of examples in the open source
version of react there are four other
repos that depend on react core there
are seven repos that depend on logger
and there are ten that depending on
cuttlefish so this is a graph of the
react to dot to open source dependencies
I know you can't read it from where
you're sitting that's not the point to
give you an idea of the complexity in
fact it's not even entirely accurate the
true picture is worse I cleaned it up
some
I actually took out some of the stuff
that I've already taken out in doing the
rebar three conversion but in this
version they're still undeclared but
necessary transitive dependencies and
you remember I said there were ten
dependencies on cuttlefish cuttlefish
over here you'll see it better in a
minute inside that red circle is
cuttlefish more of those ten
dependencies it's only showing you three
of them those are the ones that are
declared in rebar config files the other
seven are implicit we're a package
assumes cuttlefish will be there because
one of its eventual dependencies lists
it as an explicit dependency and that is
a pretty big assumption to make you can
imagine what happens when something
somewhere down the tree is changed
dependency is removed or maybe it no
longer needs cuttlefish that's not
actually likely to happen but but
something that depends on it still does
need it and the whole thing blows up
this actually gets even worse
when you add our various testing tools
into the mix many of them are guilty of
the same sins of relying on implicit
transitive dependencies that aren't
actually declared where they should be
if for the C programmers you learned a
long time ago that if you use a function
in your file make sure you include the
header file in that file don't rely on
somebody else including it this is
exactly the same sort of thing so maybe
we can do something about that as I said
earlier we originally thought that we'd
come up with some scripts to try to rein
this in and some other problems rein in
this and some other problems but the
more I tinkered around with things
somewhere I realized that we could do it
all in a rebar 3 plugin so I created the
bash Oh rebar tools plug-in which I'll
refer to as BRT it's on github it's
plugin for rebar 3 it works on every
version of err line from our 16 on
including 20 or today's version of 20 I
test it rigorously and frequently to
make sure that it works that's primarily
for 20 which is a moving target so some
of the things that does are it uses xref
throughout to figure out what the true
dependencies are of the code as opposed
to what the rebar config files say the
dependencies are so that information is
then used to generate rebar config files
it's also used with a top-level
configuration of the dependency versions
so that it can regenerate or update
rebar config files so that everything
that uses a particular dependency uses
the same version of it so basically I
can hit a button go down through the
tree make sure everything that uses
logger is using the same version of
logger has support for git commands and
the github API so it can do things like
helping us synchronize to upstream
repositories where we fork them
and doing things across trees of git
repositories it generates various
supporting files for us it actually
mainly uses rebar three templates not
for the rebar config file but from a lot
of other stuff but they're wrapped in
simplified commands to get the right
variables set to the right values
the basic idea is that it supports our
workflow which isn't necessarily your
workflow but I think it's a decent
example of how you can use plugins in
rebar 3 to help you with your workflow
so that rather than having something on
your internal wiki page that tells a
developer here are the steps you follow
to make sure that your rebar 3 config
file is in is in sync or your here's our
here's our standard get ignore file for
a repo or something like that it just
has a rebar 3 command that you run and
it does the right thing so we don't have
to worry about what version of a tools
installed or whether the developer went
and looked on the wiki page or where the
tools are installed it's all included
it's all up-to-date but it's very much
work in progress it's it's it's very
stable and it's been proven to be a good
approach but there are a lot of things I
want to extend in it we also have
another tool we use called thumbs we use
this outside the rebar 3 stuff as well
it's not unlike Travis CI with some
github PR workflow handling built in so
when somebody creates a pull request in
a repo it'll run through a sequence of
build steps if they all pass it can well
build and test steps it can then enforce
some review policies and help us avoid
merging broken code into mainline
branches it's been very helpful in that
regard
it's as I said it's more general purpose
than BRT and it's enabled in most of our
repos now
among the supporting files that BRT
generates are the thumbs configuration
files that go into all the repos as I
convert them or as we convert them
because it's now more than just me
working on it and as we all know two
tools work best when lubricated this is
my preferred lubricant so is it done yet
nope I had hoped to be able to point to
some beta like version of react on OTP
19 by the time I gave this talk that
didn't happen
turned out to be more labor intensive
than that optimistic target but I'll
note that I'm still within our
pessimistic target goals so BRT is
stable thumbs are stable at last count
which is changing on an almost daily
basis last time I counted 31 repos were
done on their first pass and what I'm
defining is their first pass is even
though the definition of done doesn't
include backward compatibility to the
extent that we can we're trying to keep
them backward compatible at this point
simply for regression testing and
performance comparison and things like
that
well once we know that so we're not
trying to keep them production grade
backward compatible we're just trying to
keep them enough so that we can tell we
haven't veered too far off from what we
should be doing once we know we have
everything working then we're gonna
strip all that conditional code out so
that we don't have to maintain it going
forward most possibly all of the
third-party repos are done some of those
were pretty challenging
most of the NIF's are done maybe one
left that hasn't been done but I've
switched them all to make files where
they had previously used the rebar
two-port compiler I was able to come up
with some with some with a pattern for a
C and C++ make file
the targets our platforms more
accurately than either the port compiler
plugin or the C make template and rebar
3 I may make that itself into a template
in VRT but with the current NIF's pretty
much done there's not a lot of pressure
for that right now we're very close to
getting it getting up the stack to the
react kV repository that's the big
target react core is done if you're
familiar with the structure of react
react core is pretty much the heart of
some of the a lot of the underlying
components of the system
it was non-trivial to get that done I
actually removed at least one module
that I think had been copied directly
out of our 13 into it so core is done kV
is the next one it's it'll be the big
one once we get past that it should be
pretty smooth sailing until we get to
the part about building with relex and
and getting rid of some of the funky
stuff that we do to actually build a
release of react at this point so we're
getting pretty close even though I
previously said there were around 60
repos and I just said that a little over
half of them are done the half that are
done are the harder ones for the most
part it gets easier as we move up the
tree especially with the patterns ironed
out some of the repos literally only
take a couple of hours at this point to
get them up to speed if frequently
tastes longer to run them through the
all of the builds and tests that we want
to be sure past than it does to do the
actual conversion because a lot of that
conversion is done by these automated
commands that we've added to rebar 3
with the plug-in of course some of them
like react kV are going to take weeks
but it's getting better so what have we
learned lots and lots of things there's
some truly ugly code out there on the
Internet
well we all knew that but some of its
uglier than we thought some of it's ours
and if you're managing a repository with
a significant amount of code in it some
of its probably yours it's it's not all
other people's code as we've worked up
the stack we've gotten a lot more
aggressive
we're not timid at all about what we're
willing to do to a repository at this
point when I started on this I was
trying to tread lightly keep my changes
as minimal as possible
you know don't rock the boat any more
than I not need it to the hell with that
that's out the window there's there's
there's very little I'm not willing to
entertain as a possibility at this point
one of the targets for me is a repo that
only has one thing depending on it and
when I look that dependency is very
narrow that's something I want to
consider just removing the dependency
altogether in some cases just a single
module maybe even a single statement
uses some additional repo that's that's
pulling a whole repo into our into our
tree into our maintenance burden it's
often a lot easier to work rework the
code so it just doesn't need that
external dependency removing it all
together is a lot easier than then
keeping it as an ongoing maintenance
burden in other cases we were pointing
to repos that didn't do what the calling
code assumed it did either because the
caller made an incorrect assumption
about what the collie claimed to do or
because the implementation of the collie
didn't do what the collie said it did
and again it was easier to fix the code
the the calling code removed the
dependency and then to convert the repo
it was calling into comments comments
comments comments so rebar react has
been around for quite a while
lots and lots and lots of people have
worked on it some of them have been like
feverish midnight coding sessions and
they've just blasted out this code and
yeah you look at it and you're going oh
my god what does this do
comments really help in cases like that
folks I cannot impress this upon you
enough if you're doing something really
strange and weird and you're and
wonderful in your code throw a comment
in and save what it is a huge amount of
time in this process has been spent
trying to figure out what a piece of
code does it's also it's it's changed
the way I write code to I mean when I'm
writing a piece of code I throw comments
in because I have encountered this
enough times now that I say I don't want
anybody else doing it to deal with this
and my memory is not getting any better
I may come back to the cinetic the next
week and not remember what it was
supposed to do myself
so like take changing from the random
module to the ran module there api's are
very close but there are some subtle
differences in how they do things
especially with regard to the random
number generator seed we actually came
across tests that depended on the static
initializer in the random module I don't
mean they depended on it being a static
initializer I mean they depended on the
specific integers that were in that
initializer a comment in that particular
code would have saved me days saying you
know what you're doing why you did it
justify why you did this it that
particular one I won't forget that one
soon
and if you're not doing it already track
your technical debt
we've all got places in our code where
we did something and said gee if I just
had more time to spend on this I could
make this so much better or you know a
week later you're farther up the stack
and you say I wish I had implemented
that differently put it in your bug
tracking system as a go back and look at
this or a to-do or something like that
we've taken to adding everything we
everything we encounter in the stack if
we don't fix it we put comments in the
code and we put it in our bug tracking
system saying hey there's something
flaky over here that somebody may want
to go back and look at at some point
those are really the high points I could
go on and on but I want to give people a
little bit of time for questions
and as I said I'll be around and there
will be a Q&amp;amp;A later this afternoon so
any questions I can answer
yes
entirely three and because of that is
necessarily something that they want to
adopt right now to abandon we've made
the corporate decision to abandon remark
to not everybody else but certainly in
the areas where we're finding bugs in
code in a lot of cases at this point
there are a couple of paper pages we've
already done the PRS and they've
actually been pulled into the upstream
proposal in a couple other places we
made notations in our bug tracking
systems to go back and see if there's
some part of this we can extract to make
a clean CR for the opportunity you have
to be definitely there every boaters out
there that could use
so I've been I basically I've been on
this for on and off for over two years
and 100% of my estimates been have been
off by potentially orders of magnitude I
would really like to be able to say that
within the next month or two the
open-source version of react would be
running on OTP 19 but I would not want
to commit to that I mean it's it's going
along well it's a lot more work than
originally estimated on the other hand
our original our original pessimistic
estimate basically I gave the most
pessimistic estimates I could other
people contributed by like multiplying
those as which is the only reason we're
still within the window yes
we we have not yet I really want to
that's one of the big things I want to
get off of that's one of the mistakes
one of the fundamental mistakes we made
I think when we were planning the OT
b-17 stuff was the idea was we don't
want to adopt Maps because we want to
keep the backward-compatible codebase
but especially with some of the
improvements that have been made to how
maps work ie
bug fixes and subsequent releases you
know the idea of being able to match to
do pattern matching in a function head
on the contents of a map that's really
really appealing I mean the performance
difference yeah that'd be cool
but it's being able to match in a
function head I really want that yes
ouch directory is your friend the
checkouts directory is wonderful you
just put it so so you've got you've got
it you your directory your your my
development directory you check out the
repo you want into that it's it's a peer
of the one you're working in you put a
check outs directory and the one you're
working in and a symbolic link back to
that or in my case you just put make
some check outs as a symbolic link back
to the whole freaking tree because I'm
working on 20 repos at a time it's it's
great and then you simply do one without
the check outs directory and it pulls
everything down and you see if it
actually
does what you thought the whole mess was
going to do but it's you know I used to
work in in rebar - I've worked in the
depth directory all the time and I had
all of them had symlinks you know back
to their parent directory he had
circular links all over the place and it
was a mess
the the check outs directory makes life
easier and and that's one of the things
I addressed would this would this rebar
plugin was as I said to support our
workflow basically my workflow and and
other developers can say no I'd rather
do it this way and then we can have that
discussion about okay we'll make it do
it that way but you know basically I was
sort of forging this path and I said gee
it would be nice if it did this it would
be nice of it did that so I made it do
those things and then I throw it out to
the bash o developers and say you guys
like it you want it changed what do you
want
you know it's an iterative process but
by having it as having it as a plugin
that gets automatically pulled down you
know when you you check out a repo you
have the tools to work on the repo and
this check outs model is no check outs
isn't my my idea it's built into rebar
three I don't know which who's who's
responsible for it but it's good what's
that
whatever but
that's the best kind of coat somebody's
in stole from somebody else yeah yeah
been there you know it used to be I used
to concern myself a pretty accurate
estimator but on the other hand I
haven't I haven't been in the rillette
there's still areas in the react code
that I just don't understand at all I
don't know how those features work I
understand on a conceptual level what
they do but I haven't been into the code
to see how they actually work so you
know there are areas where I'm going
into code that I've never seen before
and gee surprise surprise it's worse
than I thought it was what are you gonna
do</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>