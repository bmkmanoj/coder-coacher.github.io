<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Kevin Hammond - ParaFormance: Finding Patterns of Parallelism | Coder Coacher - Coaching Coders</title><meta content="Kevin Hammond - ParaFormance: Finding Patterns of Parallelism - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Kevin Hammond - ParaFormance: Finding Patterns of Parallelism</b></h2><h5 class="post__date">2016-11-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UQpme4OJEjE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I like to have fun too
especially my talks and especially the
audience so what I always say to my
audiences is please do ask me questions
during the presentation if you don't ask
me any questions I am going to ask you
some questions and I've had time to
think about this right you have been
warned
so I'm going to show you about is what
we've been doing over the last few years
fun go ahead most of my life since I did
a PhD so what I'm wanting to check out
is some what we've been doing over the
last few years
funded by various folders including the
European Union and particularly social
enterprise so what we're trying to do is
to take some research work and we're
trying to make it more practical we're
trying to bring it into the real world
so I'm gonna tell you about something
something about how we're going to do
that so let me start by motivating the
problems so multi core is now ubiquitous
I don't need to tell you this even this
little laptop which sitting down here
giving the presentation this is a
multi-core machine so how many cores
does my laptop have so you weren't quick
enough with the questions how many calls
do I have in my laptop won't here choose
no change mind for a Vance what any any
- who thinks - for more than four 16:32
no it's Apple well let me turn let me
tell you
so let's work this out well I've got two
x86 CPU cores that is a pretty good
guess but maybe even hyper-threading so
maybe if maybe there are four rather
than two what I mean by a core what is a
call okay philosophy question oh I've
got 12 GPU execution units okay we don't
normally think those as being calls but
I'm pretty sure they're processes of
some type mumping so 12 of those it
restricted but they're definitely calls
oh I've got to HD video encoders
decoders these are calls too I have a
Bluetooth controller so the little
device are setting in there just
speaking to my phone or to my pointer
thing and keep maintaining connections
that's a core - I've got a disk
controller just speaking to the disk
I've got a power management unit and the
power management unit it's job is very
simple it's just sitting there in this
laptop it's waiting to for me to press
the key it's trying to keep the device
running efficiently and that little
power management unit is more powerful
than very first process that I have a
programmed which happened to be a 6502
way back when so in total we've iced
some
20 or more calls not all of them
conventional CPU cores but they're all
pressed to some type I'm apparently is
very proud of the fact that it has more
cause in a Mac than Intel does where are
we now
well where we are now is moving into a
brave new world from these multiple
devices which has started to take a
bland scope scale escape towards much
more powerful devices things like this
one that was released in September the
Intel Xeon Phi 79 20 this has 72 x86
processor cores in a single package
phenomenal device anyone knows any
interesting features about this clock
quite low yeah good good observation 1.5
gigahertz don't even make presses that
slow anymore I guess anything else
well 260 watts that's quite a lot of
juice I wouldn't want that in my laptop
it'd be a little on the warm side
there's a compromise going on between
the core speed and the amount of power
that devices can are consuming and this
is driving the future of computing
roughly speaking we can have more
processors for the same energy input
provided we make them run slower come
back to the point later on you also
please see go ahead
possibly
let's try on good feedback
so if you can measure the heat coming
off oppress the could you figure out
what it was doing and the possibly could
but then if I was really worried about
things like that
I could always for example just run a
background computation there's always
been something right and then you
wouldn't be able to tell so if that was
the real issue if it's a real issue you
could you could do that
single-chip this is intel's most
powerful device ever and i fear in the
market for a macbook pro you'll see it's
a bargain at only six thousand dollars
so go out and buy a few where are we
going well we can confidently predict
that we're heading towards the future
where we don't just have tens of cores
on a processor but we have hundreds we
have thousands maybe thinking way ahead
we even have millions of cores on a chip
i'm calling this the mega core computer
you can check it on Wikipedia is imbued
I passed a few weeks ago there's a
Wikipedia editor there any pricing he
try and get this name attributed to me
so that's going to be my claim to fame
apart from doing some stuff with Haskell
one of these things they look like well
they're going to have nodes linked into
into systems each of those you can
expect predictor is going to have
several large CPU cores plus price and
specialist accelerators who highly
heterogeneous probably hyphens network
linking the nodes and probably not much
memory per core because the memory you
just cannot scale in the same way you
can scale the presence of technology so
memory is going to become much more
limited relative to the number of cores
that we have probably we're probably not
going to have shared memory isn't that
fun
it works it's vast vast vast Lemoore
parallel and this is a route that you
can see manufacturers pushing so the
cell architecture was basically
specialized very specialized poster
architecture it was essentially designed
for same kind of market as a graphics
market and GPUs they're pretty
successful okay so in architectural
terms yeah pretty similar this is where
we're going driven by the imperative
vent of energy versus performance we
predict probably not shared memory so
you can see this happening already in
tell it has been dipping it's turned the
water with things like Hardware
transactional memory assuming a shared
memory hardware model is simply not
going to work in the future
uniform shared memory is not going to be
there wait wait a minute
this reminds me of something wait was it
actors actors yeah a bit like actors
yeah yeah and there's a language that
dance things a bit like actors right
it's oh yeah Erlang that's right yes I
remember that
and this Haskell thing didn't we do
since in the past these languages look
like they could be the right kind of
thing to fit this the architectural
models that we're pushing towards
because you're not stepping away from
very tight integration shed it's
naturally you have a natural
decomposition of objects into tasks let
me tell you a bit about the fastest
computer in the world today just show
you that the mega core computer is not
complete sci-fi this one here is the
second fastest computer in the world it
was the fastest for three years which is
pretty impressive
in China it's the tn2 from the Chinese
National University of Defense
technology I wonder what they're doing
with that please don't tell me
very high-performance 33.86 petaflops it
has 16,000 nodes each of them has two
Ivy Bridge multicores though they're
pretty juicy
I even compare with currently check
Apple take note and each of them has
three Xeon Phi's built-in since each of
the nodes has three of those
accelerators that's going to be
something like 200 cores
plus the CPU cores per node of this
device linked up using a complex network
you can do the math as I say in the US
if you do that you realize you've got
three million 120,000 calls so megacorps
computers are not just the future
they're the present if you're the state
of China and this one just took over in
2016
just show you the things of getting even
more exciting this the fastest computer
in the world know where this one is
China good guess
some wage highlights the national
supercomputing Center in Russia in China
94 patter flops is about three times
more power from the previous ownership
this one interestingly it has 40,000
nose Easton has 200 chip with 256 Sun
way course in them these are China's own
CPU design okay very interesting device
you have on Wikipedia you'll find it
again if you do the math 10 million
calls in this device pretty impressive
and slightly more expensive than those
Xeon Phi / AG mega cool I think or maybe
mega hot right because energy usage
scales linearly with number of cores
which is great cubic ly with the clock
frequency and you can birch the clock
frequency on these devices is getting
pretty high it's not going to be the 1.5
gigahertz that we saw for the xeon phi
it's going to be 3 gigahertz or
gigahertz etc huge power and energy
usage and this is critical for today's
computers as Samsung have discovered
it's not just about large systems it's
also about small ones so even mobile
phones are multi core sampling has
advice call it's not fine option this
has eight cores in it pretty cool at any
point in time they're only using four of
them bit weird yeah let the others cool
down well yeah yeah the others are
monitoring the device to make sure it
doesn't catch fire perhaps no there are
four big fast juicy course the
equivalent of the x86 and there are four
lightweight low performance cores and
the device can switch between them so
you can either have the big ones running
all the small ones running so if you're
doing stuff like reading your email
calculating spreadsheet all that boring
work staff used small course and if
you're running Angry Birds you can use
the big ones right so you've got a
choice
and even embedded systems are becoming
multi-core and heterogeneous they would
like to go faster they would like to go
bigger but their constraints on for
example a cost in the embedded space and
be safety okay you really have to worry
about some of these devices we need
solve the morta call many called problem
to make progress in almost all areas of
computer science almost all applications
I can confidently predict that all
future programming is going to be
parallel it already is to a large extent
if you're doing Big Data buzzword it is
about big data performance matters here
and the Internet of Things is going to
produce humongous amounts of data which
have to be processed very very
efficiently hanging to do that if you
don't have big iron to do it you cannot
decompose all the data
and strike it out along a lot of tiny
cloud devices you have to have some
really serious processing power
underpinning that so it's going to push
its towards more powerful computing
devices but doesn't that mean that
you're going to have means of threads
running on a mega core machine well do
ya of course you are here's a little
application that I did earlier what
you'll probably see the green is
basically showing the application
running this application ran for about
five seconds I don't you can read the
numbers down here but I'll read them out
for you three three one zero sorry three
three one one six one five two two okay
that's the number of threads this
application created in 4.5 seconds fun
unless you've got the wrong system how
do we how do we get out of work this is
not future tech this is Haskell what
happened is we took those 331 million
threads which are potential work and we
transformed them using sophisticated
runtime technology into 20,000 that did
the real work still quite a lot of
threads but much more manageable on this
device it only had about four or eight
cores than 331 million and that's the
secret have more parallelism than you
need and then you have ultimate
scalability you can run on small devices
phones etc you can run on big devices
your application will still work ok
portable scalability so no giant Gress
and I'm going to tell you how to build a
wall in this sort of authorities in
Watson from the University of Manchester
I gave a talk there one time and incent
me yeah that's all great no all these
threads is great but there are just some
problems that you can't decompose that
you can't make into parallel problems oh
yeah ok sounds good
like what ok I like a challenge
see and said well you can't build a wall
in parallel can you you gotta put a
brick and another brick okay and you've
got a course of bricks laid out and then
you've got to put another set of bricks
right and then the third row of bricks
and clearly that is a sequential process
yeah complete the first row then the
second row and the third row I thought
well let's imagine that we can employ
four polish builders whilst they're
still allowed to build walls for us how
well could they do well for we could
place a number of bricks
yeah and we can play four more bricks
then we do the same and we could do the
same and hey it's parallel it goes
faster how much faster
four times
that's for for yeah for yeah length of
the wall six
if I can work it out placed three it
falls looking a bit dodgy already and
another three so it's looking very dodgy
four okay data and another three and
another three and a final three so it's
a bit more than three even though we've
got four presses highly efficient no
synchronization purely theoretical we
still can't get all of them working all
at the same time to do that you need to
have the excess amounts of parallelism
that I described a few slides again then
your call
so there are fundamental limits even if
you throw more coarse at a problem it
ain't necessarily going to go faster if
you can't break the problem down even
further and you'll see any better ways
to do this
while I've seen people say you could
prefab a complete row section that all
you're to do is lift it into place
somehow and put it in and then you get
essentially infinite speed up strike
that yeah how are you going strike it
yeah yeah bill tank me yeah that's right
you could do that yeah which is a very
cool technique and one that people use
when they can currently people mostly
program those things by hand okay that's
a bit tedious let me show you how not to
build a wall
place the brick place the brick never
got one memo on and so on and we end up
with our wall okay now if there any
mathematicians in the audience you'll
see this is provably equivalent to the
previous wall it is functionally
equivalent but it's nonsense why is it
nonsense gravity yeah I ignored
fundamental dependencies when I place
the first brick here there was nothing
to support it and we know from
real-world experience that when you put
something down you have to have the
necessary supports there are fundamental
restrictions however the idea that you
have to place the first row first that's
a completely arbitrary our dependency we
thought we had to do that but it wasn't
really necessary breaking those
unnecessary dependencies but realizing
that there may be necessary dependencies
is the foundation for getting good
parallel performance and that's what we
want to try to do break as many
dependencies as we can so task
identification finding the bricks is not
the only problem we also have to
consider lots and lots of other issues
to coordination communication the
bricklayers have to talk to each other
if they don't their fingers get trapped
we have to worry about where the bricks
get placed which one goes first we have
to worry about which brick layer does
their task first etc etc huge complex
coordination task as the programmer we
should not have to deal with that but if
you're using a typical concurrency
approach today's programming languages
by and large you are forced to solve
these problems
yourself by hand and that is one of the
reasons why we're still on two or four
calls and not on hundreds or thousands
of this at this point in time
we need structure we need abstraction we
don't need a brick in the wall one of
our heroes be honest is too hard and
they're worried they're in parallel
software now here are a few that you're
probably familiar with everyone gets
taught about pipelines in their
university degree very few people
probably program using pipelines but a
pipeline what happens is we have a piece
of code we take do something pass it on
to the next pipeline stage and so on and
if we have multiple processors each of
those cause could be executing a
different pipeline stages they can get
parallelism multiple things happening at
the same time good rows will be boring
we can also do things like maths your
function you all know about functional
programming right yeah good so a map we
can take a data structure like a list we
can apply an operation over the data
structure so we apply the same operation
to all the elements of the data
structure
hey that's parallel I have I can scale
that almost as far as I like certainly
to the number of elements in the data
structure which could be Millions okay
it's a bingo
good way to keep my morta called my mega
core systems fed or I could use this
pattern a task farm now it looks pretty
much like a man difference is that with
a task farm the number of workers is
going to be fixed and what we get to do
is going to take the tasks and spread
them out amongst the workers so we don't
just create one task per element of data
structure what you do is you can have
complicated workers working on different
tasks as they come in and producing
results not necessarily all at the same
time but as they become available so
that turns out to be incredibly powerful
mechanism if you're living in today's
sadly rather restricted world where you
only have a few calls
tens of course you don't have yet have
your thousands or millions because then
you can say ok we actually it's
basically map some of the operations
onto the course that we have these
become our workers bingo all works very
nicely and are the nice things to
reduces our divide and conquers etcetera
etcetera this is great so let me show
you a couple of implementations of those
patterns first one is how you implant a
parallel task farm well what we do is
we've got a fixed number of workers all
doing the same thing we've got items
tossed coming in and we split the mark
months the workers in some way each of
these does its own thing and at the end
out comes the stream of results where
the worker has been
it should be incoming elements not
necessarily in the same order functional
correctness or pipeline take some input
president said pass it on do something
pass it on and earnest that here I'm
using some buffering just to keep just
in case these pipeline stages are not
running at exactly the same rate there's
a whole you can write complete PhD
theses on how to deal with different
rates between between different pipeline
stages people do so what we going to do
what we're trying to do in the work
we've been investigating well the idea
is to produce a programming methodology
which is going to be tool supported
where we start bottom-up identify
components in the program the bricks in
the program using refactoring tools
think about patterns of parallelism so
how can these components be structured
together to build some pattern which can
then be collated to build the wall
structure them into the parallel program
turning them into concrete skeletons or
concrete task forms pipelines etc it's a
real code
and you probably want to take things
like performance and energy etc into
account at that stage yeah I wasn't
going to go into that just yet and but
code the problem is that if you've got
two pieces of code that in ranked then
that creates the dependency between one
piece of code and the other so very
important when we were building wall but
the dependencies were all explicit we
could see when we placed this brick
there's a defense between that and the
one above it if you have two components
and they share a variable that's pretty
uncool it's now got to work out what the
possible or execution orders between
these are because you can't simply plug
them together in knob tree orders
it's bears the dependency though okay so
when I say strongly hygienic what I mean
is the components shouldn't interact in
ways that are not clear because then I
can't detect the dependencies if you're
a scholar programmer do you have any C
programmers
maybe but if you're a scholar programmer
or someone who likes it thanks I don't
really care what happens inside the
component it's nobody sees that so that
Scientifics inside a component who cares
doesn't matter it's for visible ones the
interactions that are really important
okay so that's fun of me by strongly
hygienic good
so components clearly take advantage of
functional programming concepts they
they provide clean abstraction pure
computations which are easily scheduled
and exposed the dependencies that we've
just saying and you do need hygiene or
discipline to make this work or because
unwanted State leakage is going to kill
you okay shared memory is going to kill
you
so I can find these passions well you
could just sit there and structure ahead
for a while and hope they pop out but we
quite like developing tooling to do this
so it's Halloween what we're going to do
is use a process called an T unification
this is going to frighten the type
theorists no end basically what happens
is we can be merged two bits of code so
we answer unify two pieces of code and
the anti unification creates the most
general piece of code from those two
parts okay
the code that I'm driving my programmer
has written I've got some pattern some
code representing a pattern if I answer
unify them what happens is I get a
generalized version of the pattern that
I can then instantiate however I want
okay so don't have to pop in program
specified skeleton instances I can do at
a unification and it will tell me hey
look that thing over there it's a map
that thing over there hey could be a
pipeline pretty cool check out atom bar
Welles PhD thesis next year it's over
looking to the future or talk to us if
you're just trying stuff out please tell
us
we very much working with like working
with guinea pigs so how does its work
start the original program sorry it
stopped with the original function this
is part of a particle simulator so it's
mass calculation what does take list of
particles and works out the energy
doesn't really matter what it does I
don't care I'm a computer scientist good
occasion that's what it looks like so
what we're doing is applying an
operation over an empty list and we get
some by integer out or we work over a
list with a park Orton's mother
particles and we just add the mass for
the particle into that and we recurse
okay you'll see what this is do
yeah recognize the pattern yet so what
we have to do is to find the H the anti
unifier with some person so what you can
figure out is well H is a function and
what it does it takes functions the
argument is something called in it and a
list it gives us back in it or it takes
a particle and what our ancestors apply
some function to em and then recurse
it's a fault yeah it's very good my
Scottish it's a fault see you can do the
stuff you don't need the computer to do
it for you it's kind of handy
unfortunately the version I just created
doesn't quite work okay
so got the right structure unfortunately
the types are a bit screwy
so actually what I really need is this
guy here which is a pure fault but in
general I might end up something which
is more general than fault you might
have more things than the fall it might
be more special it might be specialized
to the particular construct but I'm
dealing with having got that you can
just rewrite it now I know H I know
because I've picked the patterns to be
specific patterns I know I've got good
parallel implementations for those and I
can also check all the site conditions
is the thing hygienic etcetera etcetera
okay I've written it in Haskell so of
course it's hygienic but if you're in
one of these more primitive languages
well yeah you need to do some checking
at that point
I'm trying to offend everybody yeah
possibly
who's saying I'm steering arguments
through that point yeah the fault but
it's just a pattern if I if I do it as
you're describing you you think I'm
going to fold like that don't you well
it's just that it's not normally a very
good parallel person only but a Falls
but a fold is a good parallel person
even if I'm adding the lambda and still
good parallel pattern the reason I know
it's a good parallel pattern is that's
the way the GPUs work we I program to
get on but the technical details are
there are properties that it needs to be
assessed it needs to be applied to the
operation including associativity and
then you can use the left hand right
fold so you're not restricted to just
the rightful version use the left or
right bolt slammed isn't problem but he
does have to have the right properties
good so how do I find the right pattern
well you can capture the parallel
structure as a type and there's a paper
that we presented in October
that's last month I guess now in Japan
that tells you how to do that space to
take your program build some type get a
type to the structure build a formal
semantics and parallel costs model got
paper that we wrote last year which has
just been published the channel see you
how to do that and then use some type
magic to automatically rewrite the
source code okay you'll know what the
type magic is go and read RI CFP paper
but roughly speaking it's the third
homomorphism theory and category theory
okay simple all we have to do is
understand category theory and now you
can rewrite parallel programs great or
we could do it for you so this is the
idea start off with your initial program
discover patterns using outer
unification build a structured parallel
program do some type inference on that
to tell us what the parallel types are
from that we can work out an operation
semantics
and the operation semantics tells us
what the costs are of executing each of
the parallel structures this then lets
us define some transformations using the
third homomorphism theorem etc etc that
allow us to take one structured parallel
program and turn it into another one ok
once you've encoded these
transformations you can forget all about
the category theory they're just things
to tell you how when is it finally to do
one transformation to another and we can
do that we can have a try it type driven
system running our transformations and
choosing different parallel structures
under tight control just change the type
and your program runs faster and does
all the transformations for you and then
we spit out skeletons at the bottom neat
little example image merge what image
merge does it takes a list of pairs of
images and gives us back a merged one to
operations of merge and marks I'm using
composition here sequential composition
there are lots of implementations of
that including farming the entire thing
so where you've got sequential execution
of emergen the mark you could pipeline
the mark with a farm you could pipeline
a farm on the first on the merge with
the mark lots and lots of alternative
parallel implementations from this very
simple definition how do we choose one
well what we can do is decorate the
function type with an intonation that
tells us just what the type is as a
structure especially captured the code
structure in the type and now using our
cost model we can say we can use that to
automatically select image merge two if
that's the most efficient implementation
and you if you want you can leave holes
in the types and let the system in bits
to or described in this is FP paper so
please ask for a copy of that we're
using that to produce a refactoring tool
so the ideas are going to build this
into an IDE we're currently working on
eclipse but we're also looking at visual
studio I were doing this for C C++ okay
I know it's not functional but you saw
what be on the stress drop they're
saying you know those guys need our help
right and who are we to stand back and
let them suffer when we know all this
cool stuff about hilar morphisms etc
yeah
yeah
yes yeah this is a very very it's very
question so the question is when when
are you allowed to apply these
operations now if you're taking a purist
for you then you can only do these when
you have very strong mathematical
properties okay but most of us are
computer scientists and we kind of don't
care things are slightly wonky in
various places so depending on your
application you may have weaker
conditions over what it means for two
programs to be functionally equivalent
you notice for example ice reordering
tasts earlier a lot of applications
doesn't really matter you're googling
for example it doesn't matter which
search gets done first so by plowing the
temporarily ordered requirement there
were over serializing but if you do need
to know those properties what you need
to do in principle it's to use the
theorem prover good theorem provers
today include working out the rules are
and applying them automatically in your
system using Idris etc etc so there are
good mechanized ways to deal with these
properties for some properties or you
can put in checks saying well we don't
think this is good know if you'd still
want to go ahead and transform it
you're the programmer you're the boss no
live dangerously we're not going to
guarantee you that you're still getting
at the same result out but hey you're
already living in that world because you
have testing okay I've got about five
minutes left before I need to stop I've
got a video here I can show you the tool
an operation or I can skip ahead what
you want to do vote for the tool few of
you yeah most of you let's go and do
that and I'll skip over the next bedroom
just show you this thing in operation
and I'm going to call on the services of
my colleague in st. Andrews Chris Brown
the performance tool on an application
that generates this fractal image many
calculations used in software from
banking to automated the first step is
to identify the opportunities for
multiple up to three moments these are
displayed in green we can then choose
one of these and we factor it to enable
it to the multi core before we proceed
however the safety warning message is
displayed indicating inattention and
this is software developers face when
writing multi core software assuming we
are a typical software developer however
when we think we know better we are
going to ignore this error for now and
continue anyway preview pane is
displayed showing the changes that the
tool is going to make and this allows us
to run our application getting a three
time speed-up over the original but
shock over it gives us the incorrect
result and this is because we ignored
the safety warning from before so we
revert our changes this allows us to
rerun the safety check safety check
tells us where when the program the
error occurs giving us more information
in the problem pane below
we can then repair this using the menu
item and we factor it to again enable it
for multi-core this time there are no
safety warnings and we run the
application again three times faster
this time giving the correct result our
power Foreman's tool is a compelling
proposition because it enables software
developers to write multi-core software
in a matter of minutes as opposed to
days or weeks this brings products
faster to market saving companies time
and money
that's the presentation
so you seemed at all see that it's
pretty easy to use menu Trevon and helps
identify the kind of problems that you
might face in paralysing paralysing code
we're applying this to some large-scale
demonstration applications are one of
which is developing a cure for cancer
okay so really going to be saving
people's lives using this technology
pretty pretty neat and these
applications are no good if you don't
get speed-up that's as good as you can
do by hand what you can see from this
graph is the automated solutions are
just about as good as the hand produced
ones in some cases we're doing better
than hand produced code but it takes a
few hours using tool rather than a few
days weeks months of effort and we know
code is right so to conclude many-core
is here functional programming and
patterns greatly add abstraction we need
software engineering to address
parallelism intrinsically and that's
what we're trying to do are through this
performance tool and EU project if I
have I think a good take-home message is
hey functional programming is the main
stream all these new versions of
languages are including function
programming constructs and that's going
to let us do the kind of thing that I've
just shown you in those languages
so tomorrow C++ then Java then the world
we're grateful to our funders European
Union and to our partners IBM etc for
putting this into real practice I'm
trying to commercialize this at this
point in time you'll notice that the
video was basically a pitch so we took
that in May we secured 400,000 pounds of
funding to keeps going for next year
also we need you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>