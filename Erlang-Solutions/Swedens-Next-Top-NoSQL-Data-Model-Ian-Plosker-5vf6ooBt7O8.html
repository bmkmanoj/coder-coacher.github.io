<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sweden's Next Top NoSQL Data Model: Ian Plosker | Coder Coacher - Coaching Coders</title><meta content="Sweden's Next Top NoSQL Data Model: Ian Plosker - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Sweden's Next Top NoSQL Data Model: Ian Plosker</b></h2><h5 class="post__date">2012-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5vf6ooBt7O8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I learned that a lot of people didn't
get the joke how many people actually
knew what top model is i can't say i've
actually seen Top Model but can't say so
anyway on I'm going to talk a little bit
about data modeling but really what I'm
going to talk about is the fact that
you're doing it wrong I think all of us
have made a lot of fundamental mistakes
in the way we store data and databases
the way we think about building data
models so I just want to go through some
of the common mistakes and maybe give
you some ideas of better ways to think
about storing data so just to introduce
myself I'm Ian Foster I'm the technical
lead of international operations at
fasho we're just opening an office in
London so I'm employee number one in
London there's one other guy I'm going
to mention this now and I'll mention at
the end we're hiring so anyone who is
looking for a job at basho in come find
me and we can talk looking for
developers in in the London area to
start and maybe eventually a few other
places in Europe so just in case you
don't know who Bachelor is we make real
and we like to think of ourselves as
distributed systems experts and yes we
really do wear hats like that that's how
we do your voice chat so all right so
really this talk is about databases how
many people here use databases
that's what I thought so I think we
spend a lot of time building things like
bats working relational databases in
building crazy scala's where we just
tear apart our data we turn it into this
normalized form and we think that
there's some sort of elegance and the
fact that we separated each little bit
of data down to its tiny little smallest
detail um I mean is this how you guys
approach working with a relational
database that you normalize data user
data goes here user activity data go
somewhere else you know my who my
friends are go somewhere else and we end
up with these data structures this data
model that doesn't look at all like what
our applications want to consume the way
we actually interact with the data so
you know obviously this is for a
relational database is a relational data
model and those sorts of data models
work really well in a relational
database actually as long as you have
lots of membrane joins aren't expensive
if your whole data set fits in memory
joins become expensive when you have to
do random seats on disk so if you have
lots of memory go ahead keep using data
models like this but well actually I
want to talk a little bit about arms and
ODMs as well I think these exist for the
fact that there's massive impedance
between our data models and the way we
want to work with our data model how
many people here have used a norm I know
your Erlang developer sins but how many
of you have written in or okay sometimes
people to raise their hands to that I
think I've worked with five or six
different ORMs and written to and they
exist simply because we need to map our
relational data model to you know to
data we can use their applications and
they simply exist because we've created
in
it's between our data model or query
model and our application so this comes
to a head when you start working with no
sequel databases new sequel databases I
think what actually defines the category
a sort of two things Steve mentioned it
before one is just in opposition to
database monoculture that there should
be choices relational databases fit some
problems but other problems are better
sort or served by other tools I think
the other thing that no sequel that
unifies no sequel databases is none of
them support joins so that relational
data model that we looked at a second
ago doesn't work we need to think about
something else it forces us to think so
let's talk about how to date a model
first off like I just said how the thing
I think this is what we're lacking more
than anything is we actually kind of
think data modeling self-evident
especially with the relational databases
we just sit down and it's obvious right
the user data goes here the activity
data goes here um you know I build a
cross table between users and users to
express friend relationships but I
didn't really think I just did I did
what everyone does so first off stop and
have a thang and we'll talk about what
you should think about so how do you
store your data ready you need to fit
your data model to your application
model we need to think about what our
application does how we're going to
consume data in our application that's
really the key our data model exists to
serve our application and I think too
often we look at it the reverse way we
just start with our data in this first
normal form in a relational data
structure and it just doesn't fit we
build tools just to fix that problem to
start mapping our data to
application so what I mean by this is
well get into it but your data inquiry
model should live in harmony you need to
think about how am I going to query the
data what queries I'm going to perform
and your data should probably look as
close to what the queries are going to
produce as possible I can't stress this
enough in fact even in a relational
database where you have the ability to
do joins if your data set doesn't fit in
membrane that's really expensive that's
where you get seeks that's where you get
slow performance so if you spend a
little bit of time even using a
relational database reducing the
impedance between data and querying
you're going to make your life a lot
easier you're going to make application
performance a lot easier and besides
that if you decide to scale your
relational database sharding actually
becomes a viable option so this is a
sequel save and someone i found this
online someone posted this and was
really proud of it I don't know I
wouldn't be so proud of something like
this but this is exactly what I'm
talking about this is data and querying
data and application not harmonizing I
mean the amount of work that needs to be
done here to produce something that's
useful to whatever applications got is
building I didn't spend the time to look
at that I just googled massive sequel
statement and I forgot at some point I
found the joins in here I think they
were implicit somewhere along the way
but don't do this that's not harmony
your data and query model should be
directly tied together so at the same
time I think we hear this word
denormalized right we should do you
normalize our data don't just
denormalize for the sake of D
normalizing you don't need to be a
database hipster you can just
you can you need to denormalize for
reason we're solving a problem so what
is the problem or solving day via data
query together should be stored together
I love this picture you can't see it but
this is a check cashing store and a beer
store they sell voice ters and po boys
yeah so good that people want together
sold together data that's queried
together should be stored together it's
as simple as that in yes when you change
how you queer your data you probably
need to do a little bit of work to
actually migrate your data to fit I
think it's hard I mean even in a
relational database if you have a large
data set and you decide to alter table
it can take a long time changing all of
those indexes and expensive actually
mysql is the worst with that postgres is
actually pretty good postgres doesn't
actually force you to to realize the
cost of indexing rate up front when you
do an altar table so pick a good
relational database if you want to do
that but um yeah it's it's hard i I
don't know applications change we can do
our best to figure out what requirements
we may have in the future and hopefully
build the data model that's flexible one
option that's common in new sequel
databases and even now in relational
databases is using a semi-structured
data to allow us to manipulate our data
structures have more flexible data
structures stored in the database and I
think with rioc it's pretty common that
people are storing Jason XML I know some
people storing protocol buffers so I
don't know if I answered your question
but I want to talk a little bit about a
approach to storing data together that
we talked a lot about in Riyadh so time
series data how would you normally store
time series data you might have a table
with events and each event get some row
and we just keep adding data to this
something like rioc that uses consistent
hashing that's distributing data around
a cluster this is really inefficient
because when you go to query your data
when you go to query this time series
when you want an hour of time series
data you have to go all around the
cluster to gather the data and that's
really expensive what you really want is
to be able to go to one object and
retrieve it which is very fast operation
and have all that data there so this is
kind of the perfect example because when
you sit down and think about what the
query is what is the normal unit of time
that I want to look at my time series
data in is it that I'm showing a user in
my application the past hour of activity
well if that's the case then maybe I
should store all the beds for the past
hour in a single object so I can pull
out that data very quickly and reduce
the discrepancy between how my data
stored and how my application consumes
it so we call this approach time boxing
but it requires thinking and it requires
knowing ahead of time what you want to
do with the data how you want to display
the data and how users want to interact
with it
so this is kind of a side note um how
many people have fun well we get a
question very often what's your security
model in rioc and the reason i'd ask
this is relational databases have
security models right they tell you oh
will encrypt your data on disk you just
you know have an encryption key and will
encrypt the data the thing about
encryption like that is you're only
doing at the endpoint rights your it
would be as if you brought in a prisoner
to present and you didn't have them in
handcuffs and walking around the prison
only once you get them to your to their
cell do you close the door and lock them
up but then when you pull the data out
you just open the door and let them walk
around it's pretty silly what you really
want for data security is to guarantee
that your data is locked up through the
whole sack so one approach is how the
users actually create encryption tokens
encrypt data throughout the entire stack
don't leave it to your database I think
that's a big mistake even with
relational databases that have you know
complicated security models another
piece of advice use natural keys how
many people use auto increment of keys
in their relational database why well
the schema editor provides like ID auto
increment yeah I'm so much hassle to
change know what's funny is I see people
using Auto incremented keys and they
rarely actually query on the auto
increment of keys maybe they'll do a
joint across there you know this primary
key but the reason why you want to use
natural keys is the data is discoverable
it's naturally discoverable if I'm
sorting user data the way I'm going to
look up my user data is my username
right when I mean maybe if the user
knows they're crazy auto in fermented
ID or some uuid it works but in general
there is some natural identifier for
your data but there'd be a user name and
email address um sometimes the natural
identifier is sort of a generated token
if you are using an embed code for a
video let's set in a web page but yes I
think this is a really fundamental
mistake just it's as I said to enhance
data discoverability in fact and
something like Rihanna it's very hard to
find something if you don't have a
natural key it's a key value store if
you're using something that you don't
know ahead of time you know if you have
a username and you need to figure out
what the you know what the user
identifier is you know this auto
increment ID you have to do another
query a slower aquarium you know maybe a
secondary index query whereas if you use
a natural p you can instantly get at
your data so i think another thing that
people mess is it isn't just your
database that needs to be scalable
picking a scalable database isn't going
to solve your scaling problems it's
actually also your data model that needs
to be scalable now what do I mean by
this I mean part of it is thinking about
how I construct your data so that
commonly Creek data data that's pretty
together is stored together but part of
it is thinking about okay I need this I
need a skeletal system I'm going to move
to a distributed system how do I deal
with the complexities of a distributed
system with my data model how do I deal
with concurrent actors for example how
do I deal with with net splits what if
two writers come in on opposite sides of
the Nets plan and update the same piece
of data so in real I think yesterday
there was a pop on quick chat where this
was explaining rioc will actually accept
concurrent rights from two different
actors the
same key and when that happens you'll
produce a sibling rial can't tell which
value is the correct value so rioc punts
to the application and says here you go
decide which the correct you know what's
the correct piece of data there's one
correct do you want to merge them maybe
it's just a SAT and it's easy enough
it's easy enough to do a set in Union um
but if you don't think it ahead of time
how to deal with the complexities of a
distributed system you'll get into
trouble you won't have a resolvable data
model in the case of you know working
with an eventually consistent system so
we've actually thought about em fasho
and there's been a number of papers
written on certain data types that
actually can enable you to deal with
eventual consistency and deal with being
in a distributed environment so
so-called some convergent and
commutative replicated data types and
basically what these do is their data
types that guarantee resolve ability
their data types that are that get
eventual consistency they're built to
exist in a world where where multiple
actors can come in and modify the same
piece of data where next what's happen
they're designed for distributed systems
so one really complicated thing to do is
people asked us at at pacha of alaska's
when are you guys going to add counters
to rioc we really want distributed
counters but distributed counters are
really hard how do you deal with you
know for example let's say we had we
just store an integer in real right so
it's replicated three times and it
starts out and we have a count of one
and an actor comes in and increments its
chill and then there's a next flip and
we have nudes partition on either side
of the net split and an actor comes in
on one side and up the net split and
does
internet so the value reads three and
then an actor on the opposite side of
the net split comes in and increments to
three as well and that's what's healed
and we look at the data and we go oh
there's no conflict they both read three
but we've actually had four increments
so you need a different approach to
counters crdt s proposed are there are
counters implemented as c or DTS that
can guarantee result ability in fact
they look a lot like vector clocks
essentially they are metric locks
they're just an actor performing this
increment maybe you know you include a
timestamp as well so instead of just
storing an integer we store all of the
increment events that guarantees that
when we do need to resolve it when we do
get accomplished we can guarantee result
ability so really I think what's
important the point of this whole talk
and the point of the no sequel movement
is picking the right solution picking
the solution that fits your problem i
think as developers we often like to do
the new cool thing and we like to pick
solutions rather than picking the
solution that solves our problem we
think the solution we want to use and
find a problem for it or shape our
problem to fit the solution we want to
use um it's a huge mistake this is how
we get ourselves into corners as
engineers as developers so think ahead
of time think about what your problem is
what you need to solve I think when you
look out there at databases today it's
amazing how many choices you have you
have relational databases you have key
value stores which have been around
forever I mean Steve mentioned Berkeley
DB there plenty of key value stores
before Berkeley DB if you look at the
tribute system
you have real and distributed key value
store Cassandra it's a column family has
a column family data model databases
like HBase which are more also
interesting data model each week there's
something new have any of you guys seen
rich Nikki's data Vista Tomic I think
that's a really interesting database I
don't even know what to call it maybe
it's record oriented database but all of
these serve certain problems because I
also forgot the forgot graph databases
neo4j is pretty interesting as well we
have lots of different problems and when
we build applications maybe we have a
bunch of separate problems that can be
solved by different tools we shouldn't
assume that we'll just pick one database
and will solve all of our problems so
figure out what your problems actually
are and think about what solution
actually prefers it because the fittest
solution will survive and above all keep
it simple don't complicate but we the
worst thing you can do when solving
engineering problems I know everyone
says this but I'll say it again I'm
stating the obvious throughout this
whole talk is keep it simple stupid
actually just figure out what your
fundamental problem is and solve that
and simplify your problem as much as
possible to start maybe you know you
actually do have a complicated problem
but find the core of it find the root of
it and solve that and then go around the
edges and figure out how to solve the
harder problems the more complicated
things once you've saw a simple problem
so that's it I think I sped through my
talk but just again um we're hiring a
pasho so if you're interested come talk
to me my email address is Ian at
bachelor calm and anyone have any
questions
so you're saying there is no silver
bullet sure it's not just that there's
no silver bullet I think really the
thing I want to impress upon people this
is to actually spend time thinking I to
me um what I've run into with clients is
they'll just run into the problem they
are sure they know how to solve it they
don't even spend the time to think hey
how are we going to look at this data
what is our application going to do with
it and mapping their what their
application wants to do with the data
what they want to do with the data to
the data model so data modeling has just
been taken for granted I don't think a
lot of people actually spend time
thinking about it we spend more time
thinking about our queries especially in
relational databases that's why you end
up with a crazy sequel query that has 18
joins and computation in it any other
crd tease
so crdt is re familiar well I I won't
take for granted that people are
familiar with vector clocks but vector
clocks are what Rihanna uses to track
causality in Bri off to figure out who
did what and in what order so instead of
using timestamps to resolve complex
Rihanna uses these vector comps and
essentially what a vector clock looks
like it's a list of tuples that have an
actor ID and the number of times that
two tuples that the an actor ID and the
number of times the actor has done
something in the system actually I think
there's a timestamp in there as well but
it's not important so from that we can
reason about who did what when crdt is
actually look a lot like that but they
include an action not just you know this
person did some things this piece of
data over here the data and the and the
causality are stored together so I can
say this person added this item to a set
or this actor added it to you know
removed it from the set so actually
there's something called an observed
removes observer move set as a type of
crdt so you can observe items in a set
which means you add them or you can add
an event that removes the item from a
set and given the whole set of these
operations you can determine what the
set itself the underlying set should
look like on the counter is very similar
we have a list of actors and and the
fact that paper incremented or
decremented the counter and there's a
whole there's a great paper on crdt us
that has dozens of different types of CR
DTS and what's really interesting about
them is a crdt composed of CR DTS as a
crdt so you can do composition all you
can build these together and to konami
compose them into larger structures and
allow you to build complicated
mobile data structures so hopefully that
answered your question so you're right
they are bigger than just storing a
counter in fact I think one of the
biggest challenges of crd tease the
reason why well one of the reasons why
they're not you know a feature of
clients for real or rioc itself now is
his garbage collection is you end up
with a lot of garbage and reales
eventually consistent the whole point of
these were to solve a problem eventual
consistency and now we need to
consistent garbage collection we need to
get everyone on board garbage collecting
actually with vector clocks and Rihanna
we do garbage collect them and they can
call garbage collection in certain cases
certain educators can actually cause you
to think there's a conflict when there
really isn't so if you only garbage
collector Patrick lock on particular
nodes you can end up with conflicts it's
not a big deal and we off because you
can reason about okay well I really
wanted this one you know it only happens
once in a while but no it's it's hard
you have to so in your client
application you can probably garbage
collect them from time to time but it
isn't simple there are some crd T's
there's a recent paper that had a
proposal for how to build see our duties
that are a little bit easier to garbage
collect but I'm actually not so familiar
with it if you look up crdt year
convergent commutative replicated data
types you'll find plenty of information
about them any other questions
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>