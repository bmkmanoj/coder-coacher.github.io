<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang metaprogramming made easy: Richard Carlsson | Coder Coacher - Coaching Coders</title><meta content="Erlang metaprogramming made easy: Richard Carlsson - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang metaprogramming made easy: Richard Carlsson</b></h2><h5 class="post__date">2012-06-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/RA7QcMNBKfg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so i'll be talking about about meta
programming in Erlang so first what is
meta programming and if you you're not
all that familiar with the term it just
means writing programs that create or
manipulate data structures that
represent programs so basically writing
programs that right programs so if
you're working with what's known as a
home I iconic language it's pretty
simple to quote lnk who coined the
phrase apparently their internal and
external representation so essentially
the same so if you take a piece of Lisp
code here the program that adds two and
three looks just like the data structure
representing the program that adds two
and three and there's a built-in
facility for evaluating the
representation of the program as a
program butter line is not one of these
languages so Erlang code and other lung
data looks fairly different so if you
rip if you represent a line code as
Erlang data it won't look the same and
typically if somebody gets interested in
generating airline code from Erlang
they'll start by looking at the Erlang
scanner and parser so you'll take a
piece of string as a piece of text and
you pass that to else can string and
give it a some sort of initial line
number to start with and you'll get a
bunch of tokens and then you can pass
those tokens to ol parse and tell it to
parse these as expressions and assuming
that there's no no error in your string
you'll get you'll get those past
expressions as a abstract syntax tree
but you have to be slightly aware of
what it is that you're trying to pass so
if it's expressions as in this case you
use that function but if you're passing
a hole like a function declaration or
record declaration something you have to
use the past form function instead or if
you're passing a constant term you can
use past term so you have to know these
things
and what you get is known as the
abstract format it didn't once upon a
time used to be actually officially
documented but nowadays it is you can go
to that URL there and find the complete
documentation as part of the OTP
documentation so the representation of
that function call in the abstract form
it will look something like this you
have a tuple it says this is a call and
the function component says that this is
a remote Cole call consisting of the
atomic foo and the Aten bar and the
arguments to the function call is the
atom baths and the integral 17 ok so as
you saw each of these has an individual
field telling it which original line
number in the source it came from which
gets fairly fairly annoying after a time
when you're working with this so
problems with this representation is
that it's not nearly an abstract enough
you have this explicit type of
representation there are unnecessary
details like you're lying numbers it's
kind of ad hoc it's just been growing
organically over the years so there are
several contexts dependencies in there
so so you have to know if at a certain
point if you want to represent a
particular atom should just be the atom
at that point or should it be one of
these tuples saying that this is an atom
called foo and if you find a couple
tagged record field now that could be
any one of a multiple number of things
because that's sort of overloaded the
meaning of that and of course any any
time that the lang language change it
changes a bit you can make an addition
that means that your existing code will
break because it didn't know about this
new topple that just appeared in the
source code and despite this there's no
room for additional information that you
might want to tag on to this if you're
working with it if you want to make
annotations and on the syntax tree while
you're working with it there's no room
for that so
in the late 90s as a PhD student in the
hype team I wrote the syntax tools with
the old syntax modules providing a
proper abstract data types for for
working with our long syntax trees and
that hides all the details and makes it
possible to an ad arbitrary annotations
and comments on different modes in the
tree it's not content context-dependent
so if you find a particular a note of
the particular type you know it's that
type you don't have to know if it's part
of an expression and part of a form or
whatever I can also take these sort of
old style abstract format trees as input
and keep working on there are generic
functions of you at least for working
for doing things like mapping over a
whole tree or doing a fold traversing
but when you're done if you want to pass
this on to the compiler you have to call
a revert function to sort of go back to
the standard format that the compiler
understands usually not a problem but
this API is rather too verbose so say
that I want to reconstruct this foucault
lombar as 17 I have to write something
like this which gets sort of long in the
tooth after a while and even worse when
you're when you're trying to analyze you
get a syntax tree from somewhere and you
want to sort of pick it apart and see
what is this then you have to do
something like this you call Earl
simplex type of the tree and see okay
this was an application so it's a
function call then I can extract the
operator from that from that function
call and again call else in text type on
that and find out that oh it's a module
qualifier so it's a remote cold and then
I can pick up pick out the module and
function components of that etc etc so
it becomes very verbose which is
probably why a lot of people still just
prefer to work with this old-style
abstract format because you can you can
do matching just ordinary pageant
pattern matching so even if it might
take you a while to get this particular
pattern right
when you've got it right it's it's just
a one line when it works so the question
is what if L syntax had some kind of
patterns no back then I had that idea
and I thought oh yeah I could probably
do that but then I had sort of other
fish to fry and other beer to drink so
it's never I never got to do it so let's
fast-forward 15 years and I'm now
working for Clara and once when we were
still a very young company we had all
our business logic as airline code just
part of the system which meant that
management and finance could not go in
there and read it and at any time they
wanted to make a change to the business
logic or even just to just find out what
is the current business logic they had
to go to the developer who had to go
into the code and change it or just read
it and explain to them what was going to
happen that got very annoying there was
also things like if they wanted to make
a slight tweak we had to make a code
upgrade for all of that and also
important if you're doing financial
stuff there was no trace of how
decisions were actually made so let's
say a customer foam says and says that
he was trying to make a purchase two
days ago and he was denied of course we
want to what want to know why was this
person tonight so we can maybe explain
it to him or find out if some if
something's wrong into the system but if
we don't have a trace of what the
reasoning was behind our refusal this
customer we don't know so we wanted to
break out this stuff so tawba ya started
out by making a simple decision engine
where he kind of recognized that the
main things that you want that you
needed was kind of just a conjunction
and disjunction operators that orelsan
and also basically shortcutting
operators
that just don't evaluate more than they
need and some primitives like testing
equality and doing addition so forth and
so you could you could express business
rules using tuples and lists like this
and you'd give this to an evaluation
engine together with a dict that defined
a number of variables but like the age
of the customer and so on and so on and
you'd evaluate this so it got a bit
better but it was still in Erlang even
though we now had it sort of in a single
place instead of spread out and it was
mostly unreadable to non-developers
still because non developers would just
see braces brackets question marks get
me out of here so one day I bumped into
our CEO in the corridor we were small
company so we did that all the time and
he said something like and annoying this
Kent couldn't you like at least
visualize the rules for us like in the
wiki and we were we had been using a
media wiki for about a year or so so
they were getting the hang of that like
with labels and bullet points and so on
so I thought mmm now that that's an idea
could you use the wiki syntax as the dsl
itself because the stuff that we were
trying to express actually match the
notation of the media wiki pretty well
so you could write something like rule
name and then side some comments and
then bullet points for the for the test
the conditionals that you needed and in
order to sort of remove this from
dependency on a particular honor line we
decided that we should use more like
JavaScript semantics for for the values
and names and operators so it would be
more familiar to people who had maybe
done a bit of web programming or
something so now the input environment
to these rules where was a simple JSON
structure instead of a ticket
meant that you could write pretty easily
nested conditionals that were fairly
readable something something like this
these are just hypothetical examples
that I tossed together there's nothing
from our actual code base here and the
thing was that you could take these
rules and just paste them into mediawiki
you didn't have to do any translation or
anything so people could share the rules
and look at them and comment on them and
so on and for funk for rule sub calls we
actually chose the syntax for local
links on the same page so they
automatically became clickable and it's
not really much worse than any other
function call syntax and we also made it
so that rules could take parameters so
that if the first bullet point after the
title of the rule says input X or you
could have more more than one input
parameter then that defines what the
parameters are so this was reasonably
expressive so the good part of this was
that non-developers could suddenly read
and mostly understand our business rules
they could even start writing new rules
pretty quickly a bit too quickly for our
taste it meant that we could update the
rules separately from the code it meant
that we could have the rules engine save
evaluation traces on the side so we
could pick them up maybe a week or more
later and say that oh this customer who
tried to make a purchase at that time
yeah well he was denied because this
rule triggered and we had all the rules
in one place we don't we don't mix up
the rules with the system implementation
details all very nice the bad parts if
anybody has experience from prologue
you'll know that negation is failure can
be kind of tricky when you're trying to
express negative rules that was not
something that sort of ordinary
non-programmers can handle it's barely
ordinary programmers can handle it and
of course the requirements changed so
the initial requirement that these rules
should just say basically yes or no that
of course change do well we'd also like
to compute some kind of score that we
get back from the evaluation and okay
now that we got that wouldn't it be nice
if we could also compute this and that
so we had to extend the language to
manipulate state while it was executing
the rules but we try to keep it a bit
controlled so that if the sub-goal
failed you just roll back in sort of
throw away the state changes that you
did at that point but people didn't
quite get that either so i'm starting to
wonder what people do get at all I don't
quite so where do we go now we have a
button some thousands of lines of rules
now it this stuff has served as quite
well for a few years it did it did take
a whole load of our development
department I would very much like to
take the lessons learned so far and sort
of rework the entire language but they
will probably not be any time for that
so we're thinking about maybe we should
switch to real business rules engine we
looked at stuff like era see if we want
to stay in it in our line or maybe use
some some enterprise system one of the
advantages with stick sticking within
our languid be that we wouldn't have to
sort of go out over the network to a
rules server somewhere on our internal
network for every little rule we want to
evaluate we can stay in with in Erlang
but we have not made any decisions okay
back to some technical stuff so to
implement this the first version I wrote
was an interpreted version in Erlang
it's pretty easy to write interpreters
of all sorts in in Erlang writing an
interpreter make means it's fairly easy
to tweak and debug while you're going
and even if the dsl itself has fairly
different semantics from our line it's
kind of simple to simulate that while
you're doing in
interpreter but there are a couple of
drawbacks as you know in our lang dito
structure like huge nested blah blah
tuples of tuples of temples which in
this case was the rules it's hard to
share that between processes in our line
so what we did was simply we set up
single evaluation server that holds the
current rule set and other processes
would do a gents gents server call to
say could you please evaluate this rule
with these inputs you will get would get
an answer that was usually pretty fast
but in some cases that I can't go into
now but when the system load got heavier
this request could start backing up a
bit so we got it an evaluation queue
which eventually meant meant that
customers would start to see more delays
when they were trying to make a purchase
and we wouldn't answer for maybe a
couple of seconds so we decided to go
for completion and the advantage with
completion is that if you generate be
modules BB modules are obviously shared
as read-only objects between Erlang
processes so there is no execution
bottleneck any number of processes can
execute the same code and we had already
had this idea that we will probably
compile this to Erlang one one day or
another so we had made sure to sort of
match the concepts fairly well we had an
idea of rule namespaces that we could
easily compile to the single Erlang
module okay so when we generate the code
we generate a line code not correr lang
as opposed to what robert has been doing
for his languages and that is to ensure
that we're on the completely safe side
and we get all the sanity checks and so
on if you generate coraline code you
have an opportunity to do strange things
and sort of bypass a lot of safety
checks that are compiling it normally
does so it's much more up to you if you
go that route
and we compile and load directly to
memory so we don't need to create any
intermediate source files that we can
compile it load okay however here's
where you notice that the different
semantics of a DSL which in our case
that works on JSON structures causes the
the generated airline code to be quite
verbals so from given an input file of
say 5k lines of rules in this wiki
format that will translate to something
like 50k lines of airline code if you
pretty print that which in its turn
compiled compiled to something like a
600 k beam image taking about 10 seconds
to generate so it gets kind of heavy but
it also shows that the dsl is a very
compact way of expressing these things
but writing that code generators kind of
got me thinking about that old stuff
maybe I should try out that that idea I
had once and that led to a library
called Merrill also known as why the
hell did I didn't I do that this years
ago so the first thing is that I made
kind of a smarter parser which takes as
I said previously the the normal passing
functions you have to tell them what
what it is that you're trying to pass so
but with the these fungal this quote
function here you can give it a single
expression or a couple of comma
separated expressions and it will figure
out that this is this is one thing and
this is two things so you'll get a list
in this case but you can also do stuff
like giving it a closed without any
further context you don't have you don't
have to say case something of etc etc so
it it figures these things out on its
own or you can write complete function
declarations even more than one if you
want
and if you need to split the input over
several lines which is sometimes handy
for readability you could you can pass
it a list of strings like this this is
better i found them then forcing you to
sort of end each line with a backslash n
to make sure that you have your new
lines okay but that's just the passing
stage to sort of get from from the
easily writable strings to to your
syntax trees but you also want to do
meta variable substitution so this is a
helper function this mold term that
takes any constant term and converts
that to the corresponding syntax tree
representing that that term so you can
do something with it and typically you'd
insert that into another tree we do here
so i have this quasi quote q code
function which you also can give a
string as usual but you also give it a
list of key value pairs and then you can
use meta variables within the strings
and since it's this one starts with an
underscore it's normal Erlang variable
and the at signals that this is a meta
variable so what Merle will do is
transform this into a syntax tree and it
will find the meta variable and then it
would do the substitution here so it
will insert the value here into the
generated syntax tree and if you pretty
print that back to a string you'll get
this ok so the quasi quote is a phrase
that contains meta variables that's all
it means really now the ER line parser
is a bit finicky so in some contexts
you're not allowed to put anything
except a particular kind of token so
ordinarily you could use variables like
this most in most places but in some
positions as the name of a function for
instance
a variable is just not allowed so you
have to sneak in an atom here so an atom
that starts with an app that's also met
a variable and in some cases you you
might even have to use a particularly
encoded number like if you want to make
the arity of a name / arity pair into a
meta variable you can do that and
there's even a couple of cases where you
actually the parser only accepts string
literals like in this file declaration
here the new there's a particular form
of strings that are recognized as meta
variables but those are fairly special
cases usually these two are pretty much
all you need then there's another
technicality which is that sometimes you
want to replace a thing with a meta
variable but the parcel only allows you
to write sort of a larger thing at that
point typical example is export
declarations so in an export whatever is
between these brackets here has to be a
name / arity pair and in order to
explain to Merrill that what you really
mean is for this whole thing to be
replaced by the meta variable you have
to use a lifted meta variable which is
signaled by using this underscore after
the initial at so what happens is that
mo will find this one and recognize that
oh I have to lift this so it brings it
up one level and replaces this whole
thing with a meta variable and this
dummy one here is just discarded so I
can in this string here i can substitute
this whole name arity pair with
something whatever like this
okay so macros can be handy they make
your lines shorter but that in itself is
not really reason enough to start using
macros for everything one thing you can
do these days is that you can have
macros with varying numbers of arguments
just as you cannot can with function in
erlangen there are actually different
macros so this corresponds to the normal
quote function in this corresponds to
the quasi code function but what but the
important thing that these do is that
they also pass on the line number from
your source code into the parser now if
you don't do that you'll get a default
line number which is one which doesn't
help you very much if you have if you
have say 40 of these expressions in your
in your module and you get a runtime
error saying power 6 parse error at line
one okay so if you use these macros it
will instead tell you that this
expression online so and so in your in
your source file cost the parse error at
runtime that helps okay what you also
want to do of course is to do matching
you want to be able to use these
variables to match out parts of your
expressions what's your set of your
syntax trees so let's say that you use
this quote to create a pattern
containing both two variables x and y
here as part of a couple and then you
called moral match matching the pattern
against some other syntax tree in this
case contain also containing two
elements in a couple and that will
succeed and returning a list that by
kind of binds the name X to the first
sub tree and the name y to the second
sub tree and if you try it against a
syntax tree that doesn't match
get an error you can also use in
matching anonymous meta variables which
are well just like anonymous variables
in our Langley and with just just an
underscore so you could do something
like this match something with just
ignore this but extract that part from
that okay so I showed a very early
version of this to Simon Thompson in
London in well last year and he said oh
that looks a lot like what we just did
for writing refactorings in wrangler so
okay challenge accepted so I did the old
conference driven development thing
where I agreed to talk about it here in
in san francisco now so I so I had
motivation enough to actually work on
improving this stuff first thing I had
to make sure I had was a globe meta
variables because Simon had that that
means that for instance if you want to
match out all the arguments of a
function call you can do that a globe
meta variable is one that has an extra
app after the initial one and you can
also combine that with lifting so that
you get at underscore apt to say that I
want I want to match out all the
functionality pairs of this export
declaration instance like this
it can also do globs with static prefix
and suffix saying that okay i have a
function call i know that i'll have
first two arguments they want to extract
separately then there's zero more
possible arguments and the final
argument here so if I match that against
F of 1 2 3 4 5 a and B will match
against one and to see will match
against five and rest will match against
three and four and as you can see this
list is always returned in order sorted
on the keys which helps you when you
want to extract stuff
nothing you hope you have to you have to
separate separate the syntactical form
here and the the tree form in the tree
form there are no commas okay so a
technicality is that when you when you
call quote across a quote the results
you get from that is an abstract syntax
tree which is of the Earl syntax flavor
so you can do stuff like add annotations
that are found and what you typically do
with that is insert it in another larger
syntax tree and so on generate code but
when you want to do variable
substitution or matching trees first
have to be converted to a more efficient
form that I call templates so what quasi
quote really does is that it first
parses this string and then it gets the
syntax tree and then it calls the
substation which does the actual
substitution and that accepts both trees
and templates as input so if it gets a
something that is not yet a template it
will convert it from a tree to a
template that basically means going
through it and finding the meta
variables but if you know that you're
going to do multiple matches or
substitutions you can sort of do the
passing and call a call the template
function to convert the tree to a
template once and for all and then you
can do substitution or matching on that
just to speed things up normally you
don't need to think much about this if
you know me you know that there will be
a parse transform somewhere so when you
include the Merle dot hrl file it also
enables the parse transform you can turn
this off if you want by defining Merle
no transform first and what the
transform does is that it evaluates
constant Merle calls and parses quoted
strings into templates at compile time
so for instance if you have a simple
thing like you call moral term of
constant thing here then that will be
simply replaced by the corresponding
constant syntax tree
at compile time and similarly if you
have something like this this string
will be passed and then turned into a
template and replaced with the template
at compile time so you don't loose you
don't get any runtime overhead for that
part and of course since the past
transform is of course written using the
MER library itself using the MER library
I'd like to run itself on itself so that
it speeds up itself if you follow me and
I do that with using some makefile magic
okay but if I already have a parse
transform going how about this if you
write something if you write a meta
variable in your string that looks like
a normal airline variable then I can
lift that to the Erlang level so you
don't really have to write this list of
tag tuples you can just say in Erlang
that the Erlang variable foo is bound to
the syntax tree representing this stuff
and bar is the syntax tree that contain
that uses the inline meta variable foo
so that means that you don't have to
right lit this slightly ugly list of tag
tuples to do the substitution the
substitution becomes faster however the
code now needs the transform to work it
if you do this you cannot compile it
without the transformer because it won't
do anything
but it saves quite a lot of typing and
when I did that I found that another
very common thing that you do is that
you you have some constant some some
Erlang data and you want to create the
corresponding syntax tree for that and
then you want to insert that syntax tree
into larger syntax tree so what you do
is you say okay temporary variable foo
is the result of converting this to us
in to the abstract form and then i'll
insert temp through here okay but i can
do that with a naming convention that
says that if you i have this inline
variable that ends with an apt that
means that it should automatically do
this abstraction for me so all i have to
write is this line it will just take
whatever the variable foo is bound to
convert that to a syntax tree insert it
and you're done so that it eliminated
both most of the needs for intermediate
variable names and these small calls to
Merle term which you tend to do a fair
amount of if you're writing a code
generator and here's another little
thing that I did to make make it easier
to write case which is over these
patterns so that you have a switch
function which take takes a tree as
input and then you can define a list of
clauses that contain patterns and
corresponding actions so it tries these
in order and then you can have a default
you can even have a guards if you want
what i haven't done yet but i'm
considering doing it is to make the
parse transform also expand if it
finally finds calls like these it should
also expand those at compile time to
just basically a big case which and
there's also a module building API as
part of the Murrell module so that when
you when you want to generate code you
call
in it module and say give it a more the
name of the module you're going to
generate and then you can start building
up your the code function by function
and added adding it to the state that
you're passing around here you can add
rate record definitions imports
attributes so you can also set the
source file information between between
these if you want to sort of get a
connection between your generated
airline code and the source file that
your dsl was specified in and then when
you're done adding all the functions
you're generating you call module forms
to get the complete list of forms of the
module pass that to can put through the
compiler and you're done so this stuff
will hopefully be on github soon I'm
still still want to do some final
touches to the API before I hand it over
to people I want to submit it for
inclusion in OTP probably as part of the
syntax tools because it's really just a
couple of extra modules but if somebody
sees a reason to make this a completely
separate app I'm willing to hear that
decomposing stuff is still a little
messy so when you're right writing
switches or matches it doesn't look too
good with these key value pairs in the
and the result so it would be nice if
you could have the inline meta variables
also in in matching and switching so you
just get them automatically bound to
know like Erlang variable and Houston
okay so let's see if I can show you some
example here is
yeah let's start with this one so here's
the compiler for the domain-specific
language that we're using you can see
some of the interesting strings here the
fragments of code that we're generating
and that's all it's 300 plus lines and
that's the complete compiler for our dsl
so let's look at something else here's a
little example where i wrote a trivial
Lisp like an interpreter for a trivial
Lisp like language so you do something
initialization and then you have the
eval loop which is it's not very long
that's the whole value in the loop and
then there's a few utility functions and
a couple of built-ins including the y
combinator to do recursion so it's 150
lines here including some error checking
now so let's look at the corresponding
compiler
so this generates first a little
preamble with some with the definitions
that we need for the built-ins including
the Y Combinator Combinator there and
you can see what it does here it yeah
here it initializes called Merle in it
module give it a module name add the
main function yeah ah there's the call
to the main code generation first so
that I compile everything here for
simplicity just a single big or lung
function and I use the Y Combinator for
recursion so it's it's not a it's not a
pretty way of mapping Lisp onto our line
but it works and for debugging i printed
also to file so i can look at the code
and i called merrill compile and load
the forms and that's all the actual
generation loop is here so it's actually
smaller
than the interpreter this is the whole
file and that's ninety three lines for a
compiled list
kind of nice i think i can show you also
I think I had some generated code but
now I can't find it nevermind it's not
particularly exciting so this stuff
works I wrote some tests for it as well
to just check that the the Lisp is doing
what it's supposed to do including a
small Fibonacci function here and
writing this as a using the preprocessor
I include the tests in both the both
interpreted and the compiled version so
i mean i run the same tests in both and
they work in both versions so i guess
that's it questions
so when this isn't really related to the
here but when you're generating these
big 100k several hundred kilobyte
megabyte file isn't loading them into
your service schedule loading a single
module is that much of a problem usually
it's more than when you're when you're
doing sort of major upgrades with maybe
200 changed modules than you're starting
to get problems and that's that's
independent of whether or not it's
generated code or and written code
that's been touched
we don't have much of a problem with
with upgrading code multiple times a day
but we've had problems okay can't say
that we've seen much that on the other
hand we don't tweak the the rules that
often maybe these days once a month or
something okay Jay
yeah it's completely independent of a
unit so you should be able to generate
tests and run them yes well as I said
we've been using it for a couple of
years for at least two years now I think
and it's definitely sort of removed the
the problem of understanding and
maintaining the business logic from the
developers and put that onto the the
business guys you can sit down and think
about what they really want to want the
rules to express I mean previously we
had cases like at least once a day some
some business person would come in to a
developer and say listen if a Norwegian
guy of the age of 20 were to buy this
from that store would he be accepted or
not and the developer would have to sort
of dig out the code and try to interpret
the stuff in his head and figure out
that yeah I think so maybe and we've
gotten completely rid of most of that
yeah yeah okay you met you meant
compiling yeah yeah it completely
removed the bottleneck so there's no
queuing up of evaluation requests and
the requests are something like at least
10 times faster that might not sound
them sound much but you have to remember
that what what these rules are do a lot
is that they are sort of going down into
JSON structures and picking out stuff
and comparing them so it's not really
it's not really fast code it's
ability of just turning the rebel rebel
over to them and saying here's a
function you wrote looks like just an
input play around with the test fit get
your head around functions independent
frame we're going to back the
application you just deliver the
function is that totally office and just
reservation do you mean let them learn
erlanger we sort of thought about that
as well but this seemed like it better
yeah I think that I think the thing is
that if you if you give them a bit of
airline they will start to ask for a
little bit more a little bit more a
little bit more and then eventually the
the rules will start to sort of grow
different depending on which guy was was
in there tweaking it like one guy knows
about this or length feature and thinks
it's really nifty and one guy knows
about that girl I'm feature but there
they don't have the same understanding
so they don't understand each other's
rules anymore and yeah it sounds like
what happens in C++ basically yeah oh
yeah oh yeah we have rules unboxing but
we don't give them all over lang yeah
well it's pretty much like any
compilation errors we try to we try to
point out exactly at what line in the in
the rules source file that they made an
error so I mean this doesn't at all
address the problem of parsing the rules
and checking them for sanity and so
forth that's a completely different
problem from actually evaluating the
rules for compiling the rules so that's
still just traditional compiler
technology I don't think I can answer
that because I don't know anymore but
that's how far removed I've become from
it it's just a solved problem they're
doing it I don't care somebody else is
probably providing them with some some
stuff for debugging no result no no I
didn't do that yeah I good memory yeah i
could but i thought it why not compile
it that was much more fun than doing
something like some kind of ugly sharing
heck
no I could possibly oh wait a minute I
think I annotated but I mean most of
them just say yeah syntax tree in syntax
tree out so it's not very very
interesting this summer that you'll
you'll have to do that yourself as I
said when when you're interpreting an
exotic language it's usually pretty easy
because they interpreted the interpreter
code gets still fairly compact because
it only does say say that you want to
trade stuff okay then you the
interpreter will see it okay I'm going
to do it I'm going to do as a sub rule
call and okay then i'm going to omit
some tracing info and then I'm do the
call and I'll come back and I I met
another event that says I finish this
call but yes yeah but if you want when
you compile that then you suddenly have
to generate code that does this omission
that's one of the reasons why it kind of
blows up quite a lot because there's a
lot of between every little sort of
bullet point in that code there's a lot
of stuff going on shove shoveling data
back and forth and doing tracing and
okay
Russians all right thank you Richard</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>