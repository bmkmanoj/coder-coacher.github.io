<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Tech Mesh 2012 - Conversational Big Data - Darach Ennis | Coder Coacher - Coaching Coders</title><meta content="Tech Mesh 2012 - Conversational Big Data - Darach Ennis - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Tech Mesh 2012 - Conversational Big Data - Darach Ennis</b></h2><h5 class="post__date">2013-08-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/iwDpgAfwNns" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">right so I'm the chief scientist that a
small British company called push
technology we sent to do messaging
systems but we do it differently we do
it for more machine to human it's about
experiences with server-side systems on
a mobile or the web so we break all of
the rules and I'm going to talk about
conversational big data okay so what
what is big data at the panel discussion
earlier we return this quan data because
you know you had a sub value people talk
about size volumetric it's not about
that about extracting value from data
some interesting article on linkedin
this week talks about it's about two
connections right so it's much about
conversations is about the value it's
about connections so we're already at a
point where we've got say with 1 million
devices if point zero zero one percent
of them are connected you're talking
about five million connections and more
devices we have as we have device
expansion well we've got a lot more
connections with other voices things
again massively interconnected and it's
those interconnections that creates this
opportunity to innovate with messaging
in a way that no sequel has emerged to
have specialized databases that do
specialized things with data so
Cassandra is time series oriented it's
no longer relational data the same thing
really needs to happen with messaging ok
so I'm talking about the communication
aspects of big data and getting at the
value accessing those result sets the
Intel early in the year came out with
this really interesting infographic on
what happens in an Internet minute ok so
we can see there's six million Facebook
views there's about 277,000 logins in a
minute it's 1300 new mobile users every
minute 204 millions million emails are
sent from every minute so again
massively interconnected we've got a lot
of data being distributed over this
network today and if we zoom in so my
background is going to capital markets
so I'm small data that's really fast
most people are gonna use the web scale
so draw something for example
is about the same order so cough markets
so in currencies you might send the data
10 10 times more 10 times faster but
this draw something data is 10 times
bigger so kind of balances out it's it's
a good proxy okay makes sense good but
the last mile is actually really really
hard hey this is my home broadband this
is in kind of 2007 right you see this
red line that's what I'm actually
receiving I measure the latency in the
throughput that's what I'm purchasing
that's what my isp actually sold me
right so I actually left them into
another isp and I got the same red line
again okay so that's home broadband and
mobile is a lot worse you got up in the
morning if you get up early you'll get
about two point five megabits on 3g in
London at nine o'clock when everyone's
commuting and checking their emails you
get that point five megabits per second
all right so latency isn't fair either
right and then the last thing that we're
going to look at is machine to human so
this is conversing with people
interactive data right this is the back
human that's not a vent systems and data
so messaging has come from before the
internet ok so it's ancient no one has
reconsidered the first principles and
we're going to do that that's basically
how I'm going to approach the talk today
okay so traditional messaging you got
producers and consumers it's loosely
coupled these are all good things you've
got cues on each side very good for
durable subscriptions for example but
again it was invented when that was in
your pocket well hanging off your hip
really didn't fit in your pocket in
those days anyone remember these or deck
message queues this is before amqp and
rabbit and 0 and although the cool
technologies we know today in messaging
and they were very hard to actually
configure and deploy and operate I used
to support this in manufacturing
environment it was a lot of pain so we
don't like pain anymore we're trying to
move away from that and the fallacies
were simple so inside the network it's
reasonably reliable right it doesn't
fail too often as you might think and
the latency it's
typically fast enough for most of the
things that were were interested in but
it's not the same over mobile you're
going over long distances it's highly
variable it's using radio frequencies
which get interfere there's a lot of
retransmissions a lot of retries so it's
not the same ok so in 1992 20 years ago
surfing the internet was coined as a
term the internet happened web browsing
mosaic the first steps of mass will sent
this is 20 years ago we haven't
redesigned messaging really in that time
I think it's now starting to become
obvious stop old school behind the
firewall messaging over the Internet
just really doesn't work ok so that's
exactly what I'm going to be talking
about this internet thing was really
popular so a grew and grew and then in
2007 the god phone was invented right we
start to be able to get internet on our
phones while we're moving around we're
walking on our tablets on our iPads are
in accesses whichever one of these
devices we happen to be using today so
now you've got the internet and your
portable and you're moving ok so we
started touching the internet right on
our phones and on our tablets so we put
everything into the internet this is
cloud right so all of our software and
platforms became services and they
became hosted in a utility somewhere and
you can turn on power just like a tap
you can turn on these services you can
add source skills and people so you can
all the specialties rather than you
running your own production platform or
having your own data center you just use
the awesome people at amazon or
Rackspace and let them solve that
problem you run whatever it is for your
business it's now cheaper for you to
innovate and do what it is that you do
all right and acrylic real like all the
good things do so we invented big data
right because now we need to pay for
building all these clouds right so we
invented big data to work around outs
it's a marketing term we're going to
have a technology talk and get more
tactical as we go through ok it's
nothing new there's a big problem though
with most human experiences on the web
hands up who likes Twitter beers is it a
lot rent on it everyone okay and you
know when you post something up to
Twitter because whoa something wrong
happened you go so you send your tweet
again and then it says I already have
that right and why are you telling me so
you got us don't tell me just at some
point later you can be eventually
consistent it doesn't it's immediately
inconsistent will something bad happens
so you resend and it goes oh no i've
already got that right that's confused
you twice over something that we should
have just done right the first time and
even if it did fail i certainly
shouldn't expose it to you like we're
expecting higher grade experience as
they say but it was really successful
and a corona crew okay so hopefully now
you're realizing that the latency is
imperfect and bandwidth isn't free and
there's a lot of issues that are more
nuanced today than they were before okay
so this is about nuance and trade often
that's why we have this specialization
in the storage community okay the same
really needs to happen for messaging
over the web especially when you're
interacting with things in real time
okay so so why do we want to do this is
the cord of what big data is about right
it's what value do we get out of it what
insights do we glean what implications
are there for taking or not taking a
certain decision what and how is the
technology of it what we do it because
the why is where the money is okay and
the way I do it essentially is to
measure the nuances and trade-offs and
I'm definitely trading for this human
experience and trading away certain
things I have to I can't have everything
I have to take something I need to give
something away hey there has to be
balance and these are all benchmarks so
we're going to go deep into some numbers
in a second all right so conversational
data or conversational big data
interacting with these streams of
content we're generating at higher and
higher frequencies for more and more
more heavily connected devices will
require a lot more intelligence around
communication sending the right data at
the right time so has to be relevant
timely we wanted to be a responsive
set of interactions we don't want these
whoa you've already done that moments
that we're getting with existing
platforms and systems and we have to
have better understand the device in the
context within which those mobile
endpoints are communicating with us
right at nine in the morning in London
on my phones ISP I going to get point
five megabits per second during the day
around lunchtime it's a bet the same
most of the rest of the day about 2.5
megabits if I'm traveling to say
Berkshire and back in the train it's
variable connectivity all the way right
if you go under a bridge you lose your
phone connection it's gone what happens
when you get at the other side of the
bridge you gotta recover all of that
data if you're interacting with them
what happens with that state the changes
on the server side on the client side
while you were under the bridge so we're
trying to solve those kinds of problems
so you don't notice that gap that delay
it recovers seamlessly and elegantly so
we changed messaging okay so you know
the cues on the client side and a
typical messaging system what happens if
I move them to the server side well now
when you're your bandwidth drops and
this cube acts up I can see it backing
up I can drop the rate of messaging I'm
standing just for your device or just
for your device you might certainly find
a Wi-Fi network suddenly you've got an
infinite amount of bandwidth compared to
you for example so we can actually adapt
and tailor the services in real time it
becomes smart or adaptive now that's one
change we can make we can store state
inside the messaging system I don't just
have to treat as a stateless and pass it
through we can store and cash it now
it's one half closer to your device
which could be useful okay so we're now
kind of we've got this traditional topic
space for messaging it's now
fundamentally distributed it it goes
across a network okay another thing we
can do is exploit the physical data
structures right so now that we have the
data in memory we can actually have a
look at it and go is this different to
what i sent before if it isn't don't
send it again don't repeat yourself
don't resend the message because
bandwidth relate to your expensive okay
so we can start to do things like that
so the messaging kind of I work with
when you connect to subscribe to a thing
it send you a snapshot of what I already
has and subsequently ascend do Delta's
of change or updates because you're not
interested in both of the repetitive
redundant information anyway so we don't
send it okay think about it if you've
got low capacity low fidelity devices
this can make massive savings okay
another thing we can do is we can inject
logic inside the engines if you don't
like the way we built it you can kind of
roll your own you entirely change the
way the messaging product works which is
kind of cool so if you wanted react
stall routing then you could just plug
in a dynamo thing that does it that way
on a ring for example and you could
represent that in the topic space in a
dynamo like way if that made sense okay
and the last thing we can do is
something called structural conflation
okay so this is an instance of a complex
event processing inside a messaging
system so most people are used to
business intelligence workflow tools
expertise and futures now their use of
these as things in and of themselves but
if you use out of the framework and a
plug-in inside a messaging engine this
is what it ends up looking like am I
going to go slightly deep into this okay
so in a normal messaging system you have
Q of events that you're pushing in so
that's the left-hand side here my left
your right and on the right hand side on
the other side of this Q you're going to
receive on the other side and system and
assist of my work this client ID cues on
the server side so we haven't sent the
message yet we haven't occurred the cost
so if I'm using replace conflation if I
have two topics here so there's two
values about to be sent and I gone hmm
why don't I just replace the newest
value in the slot of the one that was
early as out on the water okay so you
get three messages rather than five
essays bandwidth and it's always current
right because current information is
important we want to avoid buffer boat
okay I want to reduce the amount of data
that I'm standing to absolutely the most
current and reduce the volumetric of
that down as well actively with merge
conflation we're doing the same when
forming some computation
operation on that data at the time that
we're confessing that then okay because
there's only three good sizes of q's
zero I have nothing in the queue ID
nothing to tell you one I have something
to tell you and greater than that I'm
boring you we should start doing that
especially over high latency mediums
such as the internet on the web okay
does that make sense that sounds really
good what does it work so let's measure
it second part of my talk performance
isn't the number okay it doesn't go to
11 right most benchmarks and white
papers that you might read people who go
we measure this at a thousand bytes
you're thinking it must suck at a
thousand one bites under 999 bites right
why do all messaging vendors do this
they give you here's our results we're
using the sea 10k thing and we're doing
thousand or 24 bytes exactly guy if
something's wrong here yeah they can do
really big messages you can't do small
messages okay so we should pick a
spectrum and they idealize the
benchmarks to make their product work
really good here's how I approach it or
how my company approach is it so we take
through button we find what's the worst
possible thing I can do to a machine
while I'm just saturated right so at a
regular rate i will throw 750 new
concurrent connections at the server
every five seconds here's another 750
connecting at the same time just throw
it at the server and see what happens
and we do it across a range of message
sizes for a soft designed rate for these
clients that should be receiving about
200 messages per second so it's fairly
good throughput test see what breaks
when right it's a stress test something
has to break or we're doing it wrong
that's fair right it's fairer than
here's a thousand bytes oh look all the
other message sizes are wrong use a
thousand by messages that doesn't work
like that for latency going to show you
the best case it doesn't get better than
this right so I'm going to run a single
client with a single message got a ping
pong / to you got the single hop right
performance and rail systems you're not
going to run to breaking point of
saturation it probably won't be as good
as this because you have more than one
client it's going to
somewhere in the middle right you've got
a ballpark where you can go that's where
real systems live does that make sense
so here's what regular messaging looks
like okay so we can see larger message
sizes here a red quickly ran the machine
I've tested this on to saturation ok
these dealer running 10 gig Knicks so
you can see after about 30 40 seconds
that 10 gig deck is saturated like
there's 1.2 5 gigabytes or just under
going between two machines see for
smaller message sizes it doesn't
saturate at all but smaller message
sizes are much more expensive to marshal
because they're more of them so you
saturate cpu with the smaller message
sizes ok so and this is a five-minute
running does that make sense it's not
conflated with your sending as many as
we can we're continuously ramping
clients once it saturates interesting
things happen so here's what happens
when messaging breaks for a regular
messaging system and the really
interesting thing if you've already
noticed you see this waveform that's
back pressure right so you get back
pressure from the cards they're running
as fast as possible you're still
throwing in new clients every five
seconds here take another 750 clients
something's going to break so new
connections they just get refused
connections that are now being badly
served get dropped things break its
supposed to break it's stressful right
and different cards actually give you
different em kind of the same amplitude
but different wavelengths it's really
interesting if you pick a low latency
courage you get a difference for
amplitudes and if you pick a a regular
commodity off-the-shelf 10 gig card it's
really interesting but something has to
give okay does that make sense so for
smaller message sides as these kind of
blue ones 125 x 2 in about five million
a second for the larger ones two
thousand that half a million something
like that it's kind of the range okay if
we use conflation however you'll see it
take slightly longer to reach saturation
and for the smaller message sizes it
starts to taper off quite quickly
because you see those cues we're
dropping messages we're only ever
sending you current messages so the
higher frequency of messages in for a
really fast producer you get more value
we never spam the client
right makes sense it's always current
and under emerge conflation can be
always consistent too because you can
perform computations on these cues all
right remember they're on the server
side you haven't sent anything yet okay
okay it's another view of the status is
from the client perspective notice how
the waveform is gone just adapt my
saturation so you can handle more
concurrent connections and you can send
an increasing number of messages but the
Cure West will adapt accordingly okay so
it's more stable beyond the point you
should ever run this in production I
might not but it's still more stable you
can measure the effect of completion hey
you can see it it's fairly obvious at
you know two thousand bytes reasonably
are obvious at a thousand bytes for the
smaller message sizes you don't see it
so much you start actually hitting CPU
it's really interesting two thousand
bytes just saturate those 10 gigs 125
bites unless you can saturate your cpu
cores really interesting okay it's kind
of numbers we're looking at is about
1.09 Giga bytes of payload data not
WebSocket framing not TCP or IP overhead
it's pure business critical data out to
all of these connected clients okay
that's right eighty seven point two
percent efficient it's pretty efficient
okay so it's all business value data
that's going over the water and the
latency is pretty good good latency
spikes are on the left hand side and
they're typically spiky we can see
there's some variation across message
sizes but it's nice and tight so
actually the marketing version there's a
lower latency log version them got a
little Hill here but it's three orders
of magnitude less than that nice set of
peaks over there so we can ignore that
but okay so I'm just skip these to go
straight to this one so the survey work
was in Java right and state of the art
and job today people are hitting around
five microseconds in terms of messaging
between two boxes state of the art and C
or assembly you'll be hitting about 2.4
microseconds you're hitting the limits
of the actual hardware using to get a
message from egg to vehicross box and
then crazy people gives FPGAs and don't
bother
boxes and operating systems and stuff
like that but it's really expensive okay
so this is this is quite a good place to
be and for something that's going over
the web to mobile I hope you've gotten
the point that it's not about really
latency or ultra low latency it's too
bad if you minify the cost of everything
then what you have left is overhead to
soak up more load or to provide more
capacity with last ten this is about
cost it's about saving money that's what
big data is about it's about value is
about providing a service cheaper right
it's getting better skills for less up
front okay that's the meaning of big
data and we're trying to do this over
the web and make it conversational okay
so kind of a theme throughout this
conference really has been it's about
the data stupid right that's basically
what this conference is all about it's
not about Skylar or a Koror Haskell or
Erlang or Java running like this is
about data we send data because it's
valuable so maximizing for value by
sending important data makes sense but
once we have the data what we want to do
with it use the play framework to
visualize it or you want to process or
analyze it in some way so kind of you're
getting into joins and merges and
Combinator's and event processing so the
last section of my talk is really about
stream processing it's about complex
event processing okay but embedded
inside something like inside the play
frame or put it Ortiz and futures which
was the last talk on this track okay so
this is CEP simplified with it the
complex so I wrote a little framework
all eep because CP is scary so I gave it
a scary name but it's just CP simplified
and embeddable okay so we have maps so
you can get a message processor add or
remove fields topples lists elements
segments chunks and then return the
results you can take a subset of data to
streaming over time this in flight and
CP these are called windows right you
can branch or split things you can join
gather combine merge temporary power
match multiple streams produce a single
output stream and you can have in memory
state if you want
very simple they're the things that you
do with messages okay so I decided I'd
what's the most useful thing i can add
right wells windows right because a lot
of the other stuff you might use you
might use for very specific things but
the most useful thing I use all the time
since leaving the CP world's I still use
I still think in terms over these
windows are very powerful so a tumbling
window if I have an event I'll gather
these n events or accumulate these
events oh and I've got those n events
will perform some computation give me
the standard deviation the kurtosis can
be the average do some threshold hang
out rhythm so I can make decisions in
real time that makes it and these are
non-overlapping so discreet and events
followed by has headed the street and
events can be client or server side it
doesn't matter looks a little bit like
this if you were to wrap going to that
behavior and interface around this that
has you initialize the window you
accumulate events inside the window and
at certain points in time depending on
the window type you limit results from
the windows its consumer to your ear
Utley with a result for example of
course if you write this in just happens
to be no doctor assets JavaScript if you
write this in real code right in a real
language all these control structures
you don't get any re yet reuse out of
right you keep on rewriting these
control structures and and although it
looks innocuous you get off by one it'll
go about so we want to write that once
so we can abstract that away by taking
the function the operation you want to
perform average median standard
deviation right that once and write it
well nice so we provide out of the
library okay now we can take this
control structure and we can write that
out too so this becomes a window type
that makes sense so it should look more
like this isn't much simpler code and
it's obvious what it's doing what you
know what a tumbling window is that make
sense cool quite simple now sliding
windows are much more useful but they
exhibit some unfortunate and performance
characteristics on a sliding window
let's say I have two events a heartbeat
from a server somewhere I'm alive I'm
I've the absence of an event probably
dead so if you look at these dips and
the absence of an event as a set of
events you'll be able to look at the
current and prior so if it was dead and
it's now alive well then it's alive
again so I should do something I should
fail back maybe to this system or
something if it is if it was alive when
it's now dead it's gone down I should
fade over to something okay so you can
detect these events with a sliding
window because it is overlapping but if
it's overlapping and you're looking back
across a set of events in the past
although the events are streaming so you
amortize the effects of the events
happening right now because you're
looking back into a window in the past
if that's a very high frequency it's n
times n 2 n squared is exponentially
degrading for a larger end ok most CP
engines actually implement sliding
windows like this it doesn't look much
different from the tumbling case you to
know what a window is also the periodic
windows so every 10 seconds right made a
set of results for a set of
accumulations and monotonic windows
right because time time can change
daylight savings stuff like that leap
seconds horrible things like that so we
have monotonic windows as well which you
have this little take method which
updates an internal clock and then will
cause an omission of a side of event ok
so monatomic looks pretty much the same
ok skip skip so I call this EEP it's on
github I'm probably going to write it in
Erlang you're going to write it in
vertex so it's kind of growing if you're
interested in event processing
techniques it's a good reference for a
minimal simple lightweight
implementation of cep techniques these
are sliding windows notice it is
exponentially degrading and the
performance is fast enough that you see
saw I was saturating these 10 gigs about
5 million messages per second if your
programming language can do more than
this stop you don't need to go faster
than that so it doesn't matter how fast
your programming languages people go oh
no you shouldn't use this language it's
slow I'm going together your network
hardest
lower so it doesn't matter it doesn't
matter how slow your languages trust me
latency over the interwebs are slower
it's irrelevant what's relevant is send
current information everywhere to all of
the things and please make that
consistent because humans don't like the
wool something went wrong message that's
just bad it's bad design we should stop
doing that okay and these techniques
help you actually build this is the
technology so they're really useful okay
but we can actually fix it anyone here
got a mathematical background physics
second law of thermodynamics yeah okay
things are going there things haven't
gotten weird before it's going to get
weird there okay so see this algorithm
I'm back propagating the current value
to the last set of events in the sliding
window this do-while loop is soaking up
all of that performance if I can get rid
of it inside the heart of this construct
this algorithm then we can go pretty
fast agreed it turns out you can
actually do that if you don't your
performance looks like this in a sliding
window it's you're taking a swan dive
away from happiness it's just
exponentially grading it's bad right the
fix and i'm pretty sure known has done
this in commercial offerings is to use
the second law of thermodynamics as i'm
sliding up through the window instead I
have this compensate function which
reverses the effect of the value i'm
about to eject from the window right i
have n events so first four events
arriving on the fifth event i'll take
the value of the first event that
arrived because i've got a window of
size 4 i'll reverse it so if i was
adding i'll remove from counting opal
kenta now from incrementing or decrement
got it I'll essentially row bad its
effect so that the window slides over
time right compensate now the
performance risk compensation which is a
slightly different flavor of this window
see here this one would have cascaded
down but I took the effect of that
mathematical operation way so if i use
reversible mathematics I go from N
squared to Lin
performance which is interesting because
one of the reasons why I don't use a lot
of complex combinators and pattern
matching and CEP was because these joins
are really expensive these joints are
cheap really cheap but you need to use
reversible computing so all of the hard
math you had to do for statistics you
don't have to do it backwards so it's
reversible but some of the benefits are
you can now slide backwards through time
you don't have to go forwards so it
solves that problem too I don't know why
you'd want to go backwards in time but
you could totally do that with you know
reversible aggregate functions make
sense cool so conversational big data so
it's not really about bigger too bad
value and what we're talking about
conversations to humans is to us right
it's to people's to organisations as the
bed socialist event experience an
expectation right so this all drives
back do you think should be relevant
timely responsive I mean have to have
sympathy for the devices in the context
within which were connecting
communicating to things so that was my
mad mystical mystery tour through
messaging why you should be revisited
for the internet the web and mobile
today backed up with a few numbers and a
little bit of event processing many
questions still in shock
okay I had one question so you were
talking about sending the latest data
yep it was recently for their scenarios
where you really want to keep the whole
history and that's not going to be the
right thing and there are use cases that
I work with where data is being sent
into an organization so for forensic
storage for example so you're recording
AV and tax on a mobile phone pumping it
into corporate for forensic storage
where you want absolutely everything in
most cases you typically want to drop
down what do we think of high frequency
data it's like gambling gaming trading
prices all this data is recoverable
right so it's okay to conflate using
replace or merge conflation or under
some operation and it's okay to tune the
consistency to not have it fully
consistent under certain conditions for
certain use cases but there's certain
things you should never complained like
don't convey to your transaction like an
order deposits and withdrawals from the
bank never can take those things this
way madness lies that that's just wrong
so there I think there are cases for
both and it's about using the right
thing in the right way more so than
anything else most people obsessing you
must use this technology it is the best
there we go it's the best for that thing
in that way right about the use case
there is no one-size-fits-all solution
anyone who tells you there is a selling
something oh we're technologists we
should run away or point the matter
non-technology people talk to them
they're also they look like things good
question any other questions
it's basically similar to the JavaScript
note version but it's more or lanky and
it's implemented in airline so I've got
the bed that about half done so it will
be on github in about a couple of weeks
but it's the same kind of notion so for
example if you want to use a monitoring
solution use falsin because it's awesome
if you just want to do these CP like
things it'll just have windows it's very
small does one thing and one thing well
at the moment it might add combinators
later so so that will be on get up in
about a couple of weeks so I'm currently
obsessing over should i leave it the way
it is or rewrite it and see and expose
it as an f4 for speed so I don't know
whether to do that yet so okay other
questions no thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>