<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Tech Mesh 2012 - Panel Debate: What the hell is Big Data | Coder Coacher - Coaching Coders</title><meta content="Tech Mesh 2012 - Panel Debate: What the hell is Big Data - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Tech Mesh 2012 - Panel Debate: What the hell is Big Data</b></h2><h5 class="post__date">2013-09-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/w8h3Bnakh84" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I don't know so Pablo just wanted to
everybody to answer what what the hell
is big data I've know I've mostly my you
know my encounter with this question
it's very much some very mixed because
when i when i go to I've done a lot of a
bunch of work with noise curl data
stores and kind of conversational state
and systems not really analytics stuff
but often when I go to a customer site
and they want to hear something about
Norris ql what they really want to hear
is about analytics and open source
analytics for instance so there's a lot
of confucian people don't know what they
want and they don't know what's out
there really so I think really we need
some we need somebody to do landscapes
for this entire new space right so baby
maybe we could start by each introducing
what how do you see the landscape I
don't know somebody has comments on that
has anyone here heard of the four V's of
big data volume velocity that's
horseshit no big data has nothing to do
with volume velocity you know how big
your phallus is or anything like this
big data is very very simple it's like
everything else where we're tactical so
we're what and where how people would
like to figure things out big data is
about why it's a bit value what are the
implications of doing something and what
are the implications of not doing
something it's about inside and the
timeliness or relevance of this is where
big data starts so it's trying to adapt
technologies to your needs right now and
the time frames that are important to
you so for me that's what big data is
about technology is a secondary concern
she'll take a shot so I do a lot of
consulting in the Hadoop space and of
course big date is a marketing term
right and it means that the suits are
throwing money at it but when I tell
people what I think it means I mean
litter
that's you know it's where the money is
right now I tell them that you know it's
basically data that's big enough that
it's become unwieldy with traditional
technologies or maybe it's too expensive
we have customers who can fit everything
in their Oracle databases or their Tara
data warehouses but it's they're tired
of paying a million dollars which is
still a lot of money in the u.s. at
these you know big systems so they want
something cheaper so they'll go to these
alternative technologies and then that
brings up you know all of these other
things that nobody understands like the
no sequel databases and what are they
actually solving do I actually need them
so the other problem I run into is
customers know or think they should be
on this bandwagon but actually they have
no idea what it means and in fact they
often don't have data that's so big that
they have to use these alternatives and
people forget that we only gave up
transactions and sequel because we felt
we had to and and now we're seeing a
trend towards putting all that back in
like Google has got these as you
mentioned in our intro this morning
these they're building distribute
transactional systems again all of the
no sequel stores have some sort of query
language now or at least they're adding
them so we're kind of going full circle
like we always tend to do in technology
next question next question I don't I
don't think you really answered my
question any what you mean what is the
landscape I mean what are the kinds of
what people really want to know is what
are the kinds of data stores out there
listen it well um I think that it's not
only about data stores but actually um I
agree with you think that I also do this
a big data consulting is the I think
that what we first need is to sort out
different business cases what are the
business cases for big data how can we
help with this I
with this stupid two birds how can we
help help really improve companies I've
been talking about changing the world
and stuff but anyway when we concern the
company's it's all about gaining
information out of nothing so if you
don't have that you need to produce
dator you need to buy data to get it
into data stores actually but um at some
point when you go to a company and says
I'm a big big data expert the most
interesting thing you can tell them is I
can show you 20 business cases and
business cases are for example saving
money that's what you told like using no
sequel data stores open source software
and and so on and so forth or for
example where to get data for analytics
how to use Hadoop in order to replace
huge IBM whatever serious where they pay
like gazillions of dollars for for just
a small performance both so I think that
before we make a landscape we need to
clearly name the business cases at all
because when we don't do this it will be
only one how can I save money using no
signal data stores actually this is what
I experienced and I I think it's stupid
but this is the first question I'm
getting asked right now
so maybe a lot of companies they they
think in solutions where they've won
store one database that will solve the
whole problem whereas to me it seems
more like big data is kind of
facilitating a process facilitating
approaches to analyze your data and
there's this new thing anesthesia or
something like that the school the thing
and so it's it's it's it's not the new
anymore well I just heard about it a
couple of months ago that's all seems
like a very big solution very expensive
to deal with this big data thing whereas
probably a simple system like Hadoop or
a disco could do the same job much more
cheap so I think you brought up a good
point about what are the actual scenario
so one of them is of course size but you
know for Alyssa companies I deal with if
they're doing just traditional analytics
or their you're capturing you know sales
on the store or whatever unless your
Amazon or Google you can probably still
do it in your Oracle's my sequels and so
forth and you still have those rich
tools for reporting and all the usual
stuff we like to have but it's some of
these new scenarios that Pablo was
talking about in this last talked there
are also driving a lot of this interests
like can I mind Twitter to find out what
people are saying about my company or to
understand what market niches exist that
I don't know about and those kinds of
things are where you get into not only
the problem of the relational stores
aren't designed for doing like you know
natural language processing or other
kinds of machine learning and that
brings in additional processing
requirements that have led to MapReduce
and so forth but also the kind of data
that your story is now it's not what you
traditionally think of is useful for a
relational store like raw text for twit
twoo it's some case it's the case for
for tweets that you want to somehow do
this a natural language processing on so
you need a lot more flexibility now for
processing the data and if you really do
have a lot of data if you are lucky
enough to be a twitter or face
book or whatever then you have to have
some way of storing it in a
cost-effective way just a little factoid
Facebook has something like 600
petabytes of data now in Hadoop clusters
and by the way you cannot put that much
data in one who do cluster there are all
kinds of limitations to how much you can
actually store in a single cluster but
so obviously they have the real problems
that are driving the innovation that the
rest of us are kind of spoon feeding off
of i think it's it's also interesting
how the canonic and big the canonical
Big Data example is web scale right it's
Facebook or Google I'm a small fast data
guy I built gambling and trading systems
I don't hit disk it's slow even solid
state disk is slow relative to not
hating desk at all hitting level tree
cash is painful enough and when you're
building those kinds of system it
changes the way you think of the world
right at different context different
environment the first principles the
trade-offs and nuances kind of are
inverted from the typical case so let me
give you an example how many messages
per second in north america so Canada
and the United States are they sending
per second during market open and
equities and options like about 19
different exchanges three million a
second on average but they're only about
50 bytes right it's not a 1k document so
would you use HTTP for this know there's
about a 1k overhead and headers protocol
and so on they use efficient packed
binary protocols so if you take the
currency markets so trading your
sterling dollars stuff like that that's
about a 1k document but you might get a
hundred micro second kind of latency
profile for something like this and then
you look at something like draw
something which mg puff came out
recently was quite a big kind of
couchbase story they grew from I think
32 90 boxes in the first six weeks we're
quite successful then didn't Zynga by
OMG pop and then it wasn't successful I
don't know something like that but they
have I reckon those vector drawings are
about a 10k document right but they have
a 1 milli second time frame so size
speed we're removing away
from value here is about what are the
implications what insights want business
intelligence what advantage can I gain
or what costs can i reduce through
processing data whether it's in flight
around disk I don't think that matters
and the tools we choose are really
dependent on those decisions if it's
already hit disk well used to dupe it's
fine if it hasn't hit disk yet process
it in flight reduce the amount of data
you need to store to disk so sometimes
it's about the data and quality
qualities of service around that data in
flight and sometimes it's not it's
you've already stored this data so it's
about further leverage after the fact so
use the right tool for the job Israeli
where and think about using the right
tool for the job as where big data
starts compared to older technique so
that was I will just use the Oracle
database because that was always the
answer so asking the question is
irrelevant right big data is about
asking those questions because now
they're relevant just to add to this
best tool for the job when I'm going to
a customer and I hear the first question
is like can you compare MongoDB with
Hadoop like okay I need the story for
that I'm all right seriously there is
it's necessary it's a lot of confusion
around this hype word so I think a
landscape business case is a combination
of the absolutely right with that
somebody has to define it i mean
actually probably i can i still can use
some of it of these thoughts in my book
which will come out in january but his
german so it's like 400 people to read
it i'll just throw in one of the
factoids it kind of ties it the two
together the Large Hadron Collider at
CERN that just discovered the Higgs
boson this year that it generates
something like I think it's a petabyte
of data every hour or something number
like that and of course you can't
actually there's no network them
actually you know distribute that much
data at once so they actually do a lot
of the filtering of the signal in
hardware and those massive detectors
you've seen pictures of and so you know
it's it's reduced by many orders of
magnitude by the time the interesting
data gets out to the computer networks
that are going around the world
but they're not using hit do for that
either of course magnets right when the
moon is straight even when a train goes
by yeah we had the maestro of data
coming to go to in Aarhus a couple of
months ago talking about that entire
system it's really amazing ah but you
know it kind of dwarfs the rest of us in
terms of data needs no we're just
building you know maybe medium to large
scale business applications and I think
see lots of people miss stepping into
using these technologies even though
they don't need to are there they
probably they want to try something new
and you know it's kind of encouraging
for the employees and blah blah blah but
it's kind of the one of them more
interesting comments on this was we had
a panel like this I'd go to recently and
Watson follow us on the panel and he
said you know the basic rule is don't
use any of this you know you know you
really don't want to encourage everybody
to go out and pick up Noel stores and
big data things unless they really have
to know what they're doing and we offer
I mean you often see people
experimenting with this and you know
wasting whole boat loads of time and
money I'm playing with this when they
don't really get any value out of it
that was kind of an interesting comment
from there I don't know if you've seen
stories of something like this yeah but
actually one of the things i recommend a
client says just get on amazon and use
their Hadoop ecosystem for a while to
understand it because you know it's
relatively cheap and you're not making
of this big commitment in a huge cluster
that's going to sit idle when you
realize it's not what you actually need
but I think that's a great comment that
Martin made that a lot of times you
should be skeptical of things and
convince yourself through business cases
that this is actually solving the
problem I really have and not just
something to make the engineers have
something new to play with but as much
as we all like to do that but yeah so
maybe there's some questions from the
audience
so we say um maybe we shouldn't use
these technologies for small data but in
some settings Kunak license make sense
to use something like react or where you
have like very distributed data because
in the traditional world you could like
create a an SQL server that has slaves
master and some slaves and their that's
also kind of eventually consistent
anyway so maybe some of the no SQL
databases would actually fit your your
data models and your usage is without
being big data does that make sense
speak also speaking of stories it's a
one one example to answer your question
I wasn't a project it was called big
data and I quickly realized that this
big data is like four gigabyte pic and I
can I can put it on my on my flash
memory but anyway the problem there was
that they had like 20 different
absolutely different data sources the
data came from absolutely different
things and you had to formalize this in
a way to normalize this to have one
representation for one single feature
and they also expected this part of the
system to scale up to 20 millions
requests per second so it's four gig of
data actually but it's a scalability
request like wow go find technologies
for that so you go will you start with C
10k and then so on and so forth justice
scale for and this the whole stack the
big data stack will include tools like
that it's not only storage it's
everything it's just there are
technologies around who will allow you
to go that far yeah yeah that's that's
an interesting point so I was going to
talk about this this afternoon and my
talk that one of the trends that's
driving a lot of this
is that you do have to integrate a lot
of different data sources better
sometimes evolving rapidly so spending a
lot of time doing data modeling and the
way we used to do actually just doesn't
pay the same dividends that used to pay
because it's going to change anyway so
you just have to be adaptable and in
fact rich Hickey mentioned this
yesterday about you know thinking about
associative stores are associative data
structures basically you know maps of
key values that working with those is a
much more flexible approach I think the
other factor that led into like things
like react and why they're important
verses say Oracle and my sequel is the
cap theorem which many of you may have
heard of which is a consistency
availability versus partition tolerance
it's basically picked to although really
what it means is if the part if you get
a partition in your network so that now
that I've got a couple of these shards
that are no longer connected do I give
up availability so that I'm absolutely
consistent at all times when somebody
talks to any part of the system or do I
give up a veil of see I guess they said
that already if I give up I give up
availability that I'm consistent but if
I if I really want to be available then
maybe I tolerate inconsistencies or
eventual consistency and for me one of
the great examples is the Amazon catalog
if I go shopping on Amazon they're
willing to show me a stale catalog but
rather than not show me anything and
they'll fix up any problems like if I
buy something that actually is out of
stock you know that that's okay that's a
problem it's solvable so that's the
another factor that's driving this and
to do what published said a second ago I
had a customer recently that they could
do everything they needed to do with
their data in SAS except one thing which
was a big machine learning algorithm
they ran on this data for marketing
purposes and this is very classic
scenario they they would take the data
import it into Hadoop to run this
algorithm and you know one-tenth of time
and then export the results back into
SAS because they had all that mature
tool in that they understood and so
forth so that's the other part of it you
nobody just throws away their old stuff
they just bring in more stuff that they
have to work with and manage and figure
out how to integrate but it is an
interesting question so one of the great
things about the database community
recently is you're seeing a lot of these
different more niche specialized
databases coming out so I've kind of car
market II and the finance so what are
they using cap markets will do a lot of
time series processing so they use
Cassandra it's just it's what you use if
you want a good time series kind of data
store although if you go deeper within
capital markets they have databases that
the regular community has never heard of
has anyone heard of the k or q
programming languages few weird people
like us some of you but these are data
parallel programming language like
MATLAB or Mathematica so Julia which is
a pretty cool new language coming out so
there's a lot of specialization there's
the value they're called tick stores are
not even called databases because they
have a very fine-grained notion of time
much in the same way than they tomek
does right it's it allows you to zoom
into the past but these tipping I had to
zoom into the past but also in a
forensic Lee auditable way so they have
two notions of time when you store data
and then when you mutated it so it does
tend to further and further specialize
as your needs become more and more
fine-grained the more you know what you
know the less everything kind of fits
the model the shape that you're trying
to fit things into so the simple verse
is easy or d complexing notions that
rich Hickey has just just think that way
because he's got right yeah we had a we
had a use case where were these
completely different requirements also
went into play when we picked out ano
squirrel store I was just exactly the
cap stuff we needed these systems to be
able to operate completely if they're
isolated being able to do updates and
record information and was perfectly
okay to continue operating on on old
theta which was eventual consistent of
course the men do you have to deal with
all these potential conflicts but that's
just the value it added was so much
bigger that that was really the
interesting case that's it's not
necessarily even a business case but
it's a it was it was in terms of making
it cheaper it was just making making
that actually possible
which is and this wasn't really a big
data case you know it's very manageable
data sizes but just being able to manage
the offline data and synchronization and
stuff like that for medium scale
projects but critical projects what's a
completely different case probably we
need to we need some effort in the
community to change this term I mean big
data doesn't say anything it's you can't
even sell this because what what yeah
yes you can of course you can yeah well
I mean you know yes exactly yeah awesome
okay no you know what I mean it's a it's
it doesn't say anything so I also don't
think that it's possible to have one
term for everything there so I'm
absolutely with grass near to define a
landscape to define a also the business
cases and so on like a catalog just big
well as simple as cap I mean simple as
one of the most difficult things you can
buy but anyway just simple as this pic
23 out of something based on your based
on your business case based on your
needs and we also need community effort
to help potential customers recognize
new business cases and I think this this
is very important this development
that's that there is a profession called
data scientist and i'm absolutely in
love with this professionals like 25
years are too late for me to become data
scientist but anyway i'm doing my best
here to recall all these things but
still it's a profession where a guy goes
into a company and and tries to define
new ways to gain information out of data
and when he says that we don't have this
data we need to get this data somewhere
we need to produce logs we need to to
buy it by DataSift whatever
whatever it is and somebody who just
pushes it and analyzes the whole
existing MDM sent you name them it's a I
I think it's also absolutely necessary
to to to combine this approaches with
classic BI tools with everything just
just to have a map of things that in an
enterprise can win out of data
information useful information I think
we everyone seen the film Jerry Maguire
rider I think we should call it Kwan
data it's not just the money right we
should call it Kwan data right because
it's the back gaining value gaining
insight understanding implications it's
not about volume velocity that's vacuous
vomitus Smith it's not about any of
these things like it literally is try
and understand and sometimes that's an
algorithm problem sometimes a data
problem sometimes it's a technology
problem a lot of the times today
especially web-scale because that's the
canonical and she was a people problem
right it's machine to human right so
twitter has been really really
successful everyone uses that we're
Anton it all the time what's the most
annoying thing about Twitter whoops you
already said that no it didn't you just
said I already said that but I didn't
and then so you go what did it didn't
actually get that so I'll send it again
is no we've already have that but you
just said yeah hang on that's wrong it's
immediately inconsistent right and it's
these things which are a problem for
humans but eventually consistent may be
right it's these systems and Anna sees I
call them I Beckham so the problem is
the bird just look at the bird it's so
successful because it really useful it's
the small niggling things we need to fix
it's like you go to a conference on your
other damn on some of those awesome demo
with a spin up like 200 Amazon Web
machines to process two gigs of data and
you go but you've got a solid state
drive in your machine you can process
this in a few seconds with grep why did
you even bother with the demo is that I
look at these demos ago it's not a bit
spinning up machines it's it's about
processing that data and trust me you
can do that in your hard drive with arc
and it'll be done and that's really
simple it's it's about relevance right
rel
events and being able to spin up a
couple of hundred machines with the J
Claire's API might be fun but it sure as
hell ain't relevant and big data is
about Kwan not big right the big is just
the wrong word and I think everyone's
getting caught up on it so just tell
them they're wrong yeah I think there's
an interesting gap right now but as far
as tooling and need for end users
between the really big stuff which we
kind of have more or less recently
nailed with MapReduce if as flawed as it
is as I'll discuss later but there's a
smaller data set and then how do I make
that how do I let the average data
analyst who only know sequel do
analytics and ask the big questions and
experiment and understand what he's seen
and so forth that is a huge problem
there's actually a big opportunity I
think right there for not only
addressing the medium sized data sizes
but also making this stuff accessible to
people who aren't geeks like us in fact
I think actually one of the i co-wrote a
book on this sequel language called high
for MapReduce and I'm not really a
sequel guy but this is so important this
tool and it didn't have documentation
that I felt that it was essential to get
it or documentation out there so kind of
jumping on it for that reason questions
guys
I need to force it is big yeah she's
gone you asked about Twitter oh yes sir
yeah well I have to think about it okay
ask a question and I agree complete with
what you said about big day and not
being able actual volumes and sizes of
files and what have you but there is a
perception with last 10 or people that
is about this so when people are working
with you and it gets to a specific size
do you think okay we might have to that
look at alternative solution style and I
think roughly that's kind of when you
get two terabytes people start to think
like this but I think in the next few
years I mean that will become more
commonplace to be generating like a
terabyte of this how do you see it
progressing like what will be there the
point which people will think okay let's
look at something else
well I think we'll start seeing a couple
of different kinds of things being
adopted as kind of standard technologies
and that kind of alleviate it like
having a kv store it's going to probably
be part of standard infrastructure just
like everybody has some kind of SQL
database under standard infrastructure
everybody's going to have a kv store and
that's going to be that's it that's an
example of an easy point where you can
easily we've gone in also to customers
and have had big expensive Oracle and
installations and said well basically
you can reduce your data size by putting
know sixty percent or eighty percent of
your data into kv stores because that's
the way you're accessing it anyway and
then you leave the indexing and whatever
needed for ad-hoc query maybe you can
put all you maybe they're putting media
or something else in Oracle stores and
and we can basically there's a very
straightforward business case for just
you know putting number of bytes
somewhere else where it's where it's
less expensive a number of transactions
or not so there's like kv stores and
there's probably also other you can
imagine time serious stores various
kinds of stores that are probably going
to come in as part of stand up standard
infrastructure and i think that i think
we will see that more than actually a
cutoff for where does Big Data start
people starting to move understand you
know these are these various things and
and starting to use it more comfortably
it's instead of today as you said
several times that you imagine it you
have to put everything into one kind of
database right now right yeah I said
earlier that sometimes I have clients
who really don't need Hadoop yet but
they think they need to jump on the
bandwagon and certainly the
counter-argument is well they're
probably going to need it eventually or
technologies like that and so sort of
greasing the skids as it were to be
aware of this stuff is certainly
something worth doing and one of the
things I think it's great about all of
this stuff is that it's kind of forcing
people to think flexibly and to learn
how to build componentized systems that
glue together well and
so they can you know build what they
need today and adapt and grow whereas
some of the more traditional data
technologies were you know a little more
monolithic a little bit more resistant
to change and so a lot of this stuff
will kind of force this kind of change
in thinking it's going to have to happen
for people to be able to adapt to these
larger data sets but hopefully not do it
too soon but only on demand I think um
good justjust do too just to name it um
I think that speaking of distributed
data stores and I think that we all
agree on the fact that huge amounts of
data that can grow and they're probably
if you go for the atomic and things like
that they will probably be always there
you will not even delete anything that
so this will grow and grow it will it's
a it's a it's the uncertain part of it
but anyway what what I mean is that I
think that this classic master data
management systems I'm not sure you're
aware of the systems it's like the
typical enterprise problem having an MDM
in the enterprise it's it's for its is
there to collect from all the different
datas to us they have picked all over
the years like 20 different databases
all dbms is because well because of
contracts because because of whatever I
mean there are enterprises as big as
whole huge countries right so anyway
this MDM and I think this development
will go in this direction people are
already discussing HDFS behind Hadoop as
the future of MDM I think it's not only
this one I think it's also there is
plenty room for four react for systems
like that that that will just go into
this direction and it also will go in a
way into this cloudy thing right because
for some different reasons it's it's
it's not very simple to have public
clouds for in Germany so in Germany they
go for for data protection reasons they
go for private clouds but
it's lost its about elastic solutions
that's what I mean with it and it will
grow and grow and grow and grow and it
has potential with the stores we have
now with the technologies we have now to
replace the classic fat customizable for
lots of money MDM solutions because just
look at that couch just look at the tree
out which is one level deeper lower its
it can it can take anything as value so
you are absolutely not depending on the
representation on the on the other side
you can you can pull it together you can
put it together in one data store you
can have schemas every day schema second
second schema like at this second we had
this schema and enterprise it's
difficult to discuss this with
enterprise architects this is a big
problem because the only reason for them
to exist is to to maintain data models
in the company's I think the data model
has gone you will have to have a data
model in your application need to have
and thus the understanding for that but
it's not about storage you need to pick
technologies to store anything this is
the point and I think that this this
will go into this direction and it
doesn't matter if it's the HDFS if it's
react whatever it's similar approaches
and luckily it's really simple to detect
if you have a big data opportunity in
your organization are you suffering a
lot of pain you've got a big data
problem it's it's that simple we don't
know what it is but we know what it
feels like I mean that's so you've got a
data problem that's too bigger is the
wrong shape it's a big data problem and
as you have more diversity in
communication systems and storage
systems and analytics platforms you'll
find that you can compose these better
to suit your particular shape or type or
size of problem and I think that's the
kind of revolution we're seeing is that
people are going I'm suffering so I'm
going to do a different kind of database
so that creates a date home and a react
and under this under that as we're going
I'm no longer using what everyone else
uses because my problem is different so
I'm going to approach the solution in a
way that suits the needs of my problem
so I think we're wising up so I think
over the next
years most of the disruptive companies
will do with the right way for them and
that's the way we're doing it if you
have the same problem use that I think
we'll be using simpler systems and will
be composing them a lot better so again
I think a lot of the structural shaping
talk that rich Hickey does speaks
directly to this and I think that's the
definitive trend whether it's big data
Quan data small data it doesn't matter
why it's it's all moving in that
direction we're moving away from the
pain now I think you know computer
science is about to mature River we're
getting good at it almost just you
reminded me I think that one of the
reasons obviously that functional
programming has become so popular after
you know decades of academic you know
oblivion or whatever is because it
really is kind of the killer app or this
big data stuff is kind of the killer app
for it just the recognition that be more
flexible about data schema also means
being flexible about object models and
maybe they don't make as much sense as
everything is just in a big collection
and I just need to process this
collection with standard tools like my
maps and my group buys and filters and
float folds and stuff like that so I
kind of see this as sort of driving that
evolution away from object-oriented
languages at least for these kinds of
problems towards your air lang's your
scholars your Haskell's and so forth
yeah i think we which we should probably
close up pretty soon I don't know if you
there's there's an interesting thing
that kind of popped up a couple of times
is that these whoever's in charge of
data currently and many enterprises are
are you know they're sitting on these
mDM's monolithic systems I mean how we
gonna what is the transition but the
transition we need to kind of loosen up
those organizations and make them a
proactive part and in making the
transition to two more kind of
decomposed system oriented architecture
rather than this monolithic put an MDM
or big
data store in the center of things how
do how do we get there I have started to
create a strategy for that because I'm
in the consulting company so we actually
need to sell stuff in a technological
way so the strategies I used to be
enterprise architect on my own so I know
the paint's are not how people think the
point here is that when you manage to do
what what Derek mentioned like having a
zoo of technologies ah which has to get
to be managed to put in tool chains to
test it adequately and stuff like that
right there is a reason still a reason
for the same people to exist and you
still need those positions you need you
still need those roles in the companies
because if it grows big enough have
millions of applications in your company
somebody has to track this all right
exactly its kima police but the schema
police is not is not restricted anymore
saying we need three months to check if
this application expecting them the
overall Enterprise model to get extended
if it's okay if it doesn't break the
rest or whatever just put it into your
store there and then success it later
they just need to track technologies
tools licenses whatever so in terms of
that data going inside the organization
and he's increasing migraine nightmare
headache with you know the expectations
we have had of data now which are
becoming increasingly sophisticated none
of us are in this room at this
conference will solve that problem when
the people who are going to solve this
problem are the data visualization guys
in the new york times in the guardian
who are coming up with awesome ways to
understand data simply to take complex
statistics so that you and just you just
understand that it makes sense it's the
right size and shape i think those
people will drive more innovation around
the technology that supports it than
technologists ourselves because it's
about understanding it's about
implication
it's a bad value it's about business
it's got diddly squat to do with
technology so big data is really about
big business and big money it's about
value it's about relevant so I think
they're going to drive more innovation
than we will we'll just we'll just
bumble along as we always have gone yeah
we're awesome now but I really think
it's these really high value
visualizations so there's this d3.js
kind of a guy in square wrote it it's
you people are coming up with awesome
ways to visualize to drill into and
enter you know extract value from data
and I think that will drive a lot of our
expectations in terms of how we can
interact with it and those interactions
will dictate the compositions of the
systems based on the components we build
and the more sophisticated they get the
more reuse we want so it drives towards
smaller simpler more composable systems
and I think that's going to be the trend
like we're just going to react it's
everyone else will take take that yeah
via the other way that this will happen
is sort of the way airline kind of its
story within ericsson is sometimes these
things start a skunk work projects or
one team just has to use like react then
they can't just use the canonical oracle
blessed data store and it'll kind of
grow from there and eventually higher
ups and the company will realize this is
what we need to be doing more globally
and it'll kind of infect the rest of the
organization seal off I think you'll see
that as well but I think it's a great
point and when people see things like
the New York Times visualizations or the
Guardian it just you know the light
bulbs kind of explode or something in
your head and and they know they have to
be doing something to address that need
well yeah another reason why focusing on
value is also that's what's visible to
senior management also right i mean
because these kind of radical changes
typically have to come top down through
organizations there
yeah okay I think we have to we have to
close up here there's lunch coming on I
think we could probably go on and
discuss this forever but we should um
would take some disc discussions offline
if there are more questions I think but
let's say thank you to each other thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>