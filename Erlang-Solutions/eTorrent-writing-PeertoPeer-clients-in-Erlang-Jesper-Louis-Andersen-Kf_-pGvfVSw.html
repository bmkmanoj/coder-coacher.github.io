<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>eTorrent, writing Peer-to-Peer clients in Erlang: Jesper Louis Andersen | Coder Coacher - Coaching Coders</title><meta content="eTorrent, writing Peer-to-Peer clients in Erlang: Jesper Louis Andersen - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>eTorrent, writing Peer-to-Peer clients in Erlang: Jesper Louis Andersen</b></h2><h5 class="post__date">2012-05-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Kf_-pGvfVSw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm going to be speaking about each
earned which is a bit turn client
in erlang originally gave this talk more
or less this talk about a year ago at
the London Erlang factory and so I
thought that we have to do something
completely different here so essentially
i'm going to be have some overlap with
that talk but i'm trying to push in some
new stuff so there's something new to
listen to because otherwise you could
just go on the web look at the look at
the top layer because it's online and
you would have the same talk that
wouldn't be fun right so what is it that
we're doing with this peer-to-peer thing
well we I think that the most important
part is that we are making each client a
client and a server at the same time so
a client acts both as a client and a
server at the same time and that is
essentially what is defining this
peer-to-peer technology and that means
everybody is going to talk with
everybody in a full mesh and of course
that complicates things essentially my
dears that I'm bidding that this is the
future I'm betting that after we after
the cloud and after this centralized
cloud we'll see more and more services
that tries to pick up this idea where
each client becomes part of the cloud of
becomes part of the server thing of the
cloud by essentially having a small
batch of all the data so you're
spreading data out in a distributed
fashion among a large amount of things
and each thing is both a client and a
server at the same time so bit turned is
such a protocol it's a protocol that
allows you to distribute content in a
peer-to-peer fashion so basically
whenever you have a consumer of content
Hills also a producer or Pusha in the
sense that he is actually and in the
game for distributing the content as
well and the trend is interesting
because it it's there it works so if you
want to study these kinds of things
study these kinds of PHP applications
well then be turned is actually a pretty
good thing to look at
and then of course yeah a decentralized
cloud would necessarily mean that we
need to look into peer-to-peer stuff so
perhaps the easiest way to make a
comparison between bit turned and
something else would be HTTP simply
because they're both about content
distribution I have a string of bite
when array of bytes and I want to
basically distribute that array of bytes
or more generally I have a resource I
want to distribute the resource and what
you can see here is that essentially and
if you begin looking into it bit trend
is the complete opposite of what HTTP is
trying to do so HTTP tries to be simple
stateless and and so on where's Peter
and is basically totally faithful you
have a lot of state going on inside a
bittorrent client everything everything
is about this thing that the more
consumers we have the more upstream
bandwidth we have and thus the more
available bandwidth we have for
distribution and that is essentially
what we're sacrificing everything to get
this everything so what is the idea this
is between in one slide I've given talks
and returned for some time now i think
that at last I have boiled bit turned
down to one slide so I know more or less
what we turn is about the goal is that
we want to distribute an array of bytes
that is essentially a file and we want
to do it in a concurrent way so while we
are fetching stuff from one party we
want to be pushing stuff to another
party or we might actually be fetching
stuff for say ten parties and pushing
stuff 25 and that's what what often
happens the basic idea is very simple we
take the file we split it into something
called a piece and each piece we have a
cryptographic checksum for so we could
do an integrity check on that part so as
soon as we get it we can verify that we
got the right part so we have the air a
split it into pieces and now the game is
to exchange the pieces and there's an
economy there's an system about economy
going on
inside be turned that picks clever
pieces to exchange all the time so
you're trying to optimize for peas
exchange and the way it works is Angela
that you are doing optimistic
socializing so all your friends you
already know you're going to shake hand
with hands with and if there's a new guy
that comes into the room you do not know
you try to shake hands with him a bit
and it is a good guy and he is basically
giving you stuff back you are happy with
him and he becomes one of your friends
but whenever there's somebody who is not
giving you something back you're going
to boot the guy that's essentially what
are the economy in the system works
there are two key points one is that
each peer for each peer we have state
and we keep that stayed in a process
inside inside each earned but the point
is that we're really not carrying about
that state if the process crashes we
lose the state but that doesn't matter
because the connection to the pier got
closed as well so that state is not any
more valid so we can basically crash all
the processes in the system that
pertains to peer communication it's not
important the second key point is that
what we do want to have unstable storage
is as soon as a piece and we download
part of the turn we download passes an
integrity check so we know it's the
right data then we want it unstable
storage as fast as possible because that
means that when we restart we can go
through our stable storage see what we
already have and start from there so
that that basically is the two key
points this is interesting so if you
really take into what be turned is it
turns out that bit trend is an
asynchronous messaging protocol with a
framing system on top of TCP so it's
basically just shoving back and forth
erling terms the protocol is different
but you could write it as a binary terms
of binary binary to term and send and
receive of those over the line where the
TCP thing has a packet for inet options
set on it the
would be enough essentially to do it the
protocol is different but passing it and
coding it and decoding it is about yeah
20 lines of 20 lines of binary pair
matches and that's it a bit of history
about he turned its it started a couple
of years ago and and it I worked on it
on and off I did courses at the local
university the first working version was
about 2008 and it's about eight thousand
lines of code you can do it with about
four thousand but we have more stuff in
there more extensions so we are up at 28
thousand lines at the wound there are
two main developers me and my owners and
he's here and and then we have a number
of contributors on the project as well
and who has contributed made different
contributions to the project so as I
said the key components is that you are
actually doing asynchronous messaging to
the other peers and that for tolerance
and the stable storage is enough to
actually that those are the key points
and then the system is highly concurrent
and since it's highly concurrent it
means that it's a really really good fit
for early so imagine that we have like
two peers 1pm might be doing one thing
it might be handshaking with the other
end in order to set up a connection
while the other p over here is actually
communicating in with data and we need
to cope with that and in Erlang it's
very easy because basically we just
create two processes right I have a
philosophy about contributions to the
project which is that it's more
important so basically the the
contributor is more important than the
contribution it's more important to get
people on the project than it is that
their contributions are right so my
basic philosophy is get in contributions
to the project push them to the master
branch and then try to fix them
basically the ideas that I'm trying to
follow as saying by Lee knows Charles
which boils down to the idea that
you know that every program out there is
clueless totally clueless they are
idiots right and by extension it means
that you yourself happens to be clueless
and an idiot right because you are a
program on this project so what is often
the case is that what you want to do is
that whenever somebody comes by he
usually have something you don't and
that means that you're interested in
getting that knowledge that you do not
have on to the project and the best way
to do that is to assume that you're the
coolest guy and he actually has a clue
in which case the important thing is
that you get out of the way so he can do
work so that's basically my philosophy
on leading projects you basically have
to get out of the way so people can do
work on the project here is the
supervisor three for each earned it
isn't that scary actually what we have
is so it's probably most easy to easy to
describe if we go in here because if we
have a single torrent we want to
download there's a simple one for one
supervisor here maintaining a pool of
peers and the peers down here are
actually free processes under
supervisors there's one that controls
the thing one that sends out stuff and
one that decodes and receive stuff so
that's three down there and it's little
supervisor construction and then we have
for each turned we have an i/o
supervisor and for that that one has a
number of supervisors for file i/o so
essentially there we are concerned you
might have more files in a torrent file
so we basically have a process per file
and if you want some data in that
process you go to the file and ask and
say I or if you want data in the file
you go to the process that is associated
with the file and yeah you've asked that
for the data and we have many of these
so for each time we have a tree like
this they are linked into a major turn
pool here which is the supervisor for
turns and then there's some extra things
around it and there's actually more than
this but these things are basically
bookkeeping processes all of the
maintains a many of the ones up here
maintains a table of something and
monitors other things so it's basically
just bookkeeping then we have the dude
distributed hash table thing there's a
whole tree under there i'm not drawing
here there's a little supervisor for
incoming connections so we spawn them up
here then we move them to the right turn
when we know basically with a
controlling process core so we move them
from here down there the D connection
there is a way so the tracker is when
you need to get peers and return you go
to a tragar which is normally in HTTP
core to a given system and what you get
back is you get a very list of peers
that list the IP addresses and those IP
addresses are the peers you want to
communicate with so that's how you start
the you have a file which is the dot
turn file that file contains a URL for
the tracker and how do you boost drive
it well you go to that URL get a list
bunch of peers on the tracker and then
you are set to go you can begin
connecting two guys handshaking starting
up the system well the point is then
that this tracker thing is actually not
that fast when it's TCP and it's it is
HTTP so what they did was they made an
extension that allows you to do you too
Pete reading that is tracking away UDP
and that part of the tree here is about
handling that UDP track of thing so
you're basically running a specialized
protocol in UDP to get IP addresses you
want to communicate with so some tricks
we are about as fast as the sea clients
if you load the system with a couple of
torrents so if you load with a single
turned the see clients tends to beat us
by quite much but load some more turns
in there so we get the concurrency up
and this system actually begins to
perform really really well and a certain
point we hit criticality in the sense
that we are better the way we do it is
that we fight unfair so basically the
first thing we do is we of course search
for the good algorithm
and we can do that basically because we
are writing things in their line so we
are not set in stone a lot of the
clients the see clients are actually
doing brute force surges and errors
because it's too hard for them to change
the their internal representation in the
code and it is very very easy for us to
do because it's learning so we have that
freedom it's very often possible to
fight unfair by changing the algorithm
the second thing we do is we use
heuristics a lot so rather than going
for the optimal algorithm we look at the
probability of a given path in the code
being hit and then we basically optimize
our code paths on such that the common
path is the fastest one and then we have
a lot of other paths but they might be
slow we don't care because we hit them
rarely right so a common trait for
instances that we have a lot of
statistics going on in the system each
peer is storing statistics in a net
stable and then when you want to for
instance look at how what is our users
you are current bandwidth use we'll just
do a match on the whole table and
aggregate it down to a value but we
guess that that is a rare thing to do
compared to the thing of updating the
statistics because that's something our
peers are going to do all the time so we
do a lot of those kinds of things and
another trick we use a lot is that we do
a lot of approximations so rather than
going for the rather than going for the
optimal solution we go for a sub optimal
but Nia optimal solution to the problem
so there's a lot of places where good
enough cuts it and I think Jay do mark
did some talk about that yesterday
perhaps but the basic idea is that say
for instance you have a priority queue
it's not always the case that you are
interested in this has priority 6 and
this has priority 7 what you're
interested in is that these two things
have low priority and they have priority
lower than this bunch of things so it's
actually not it's not precisely a given
priority
you are worried about you are worried
about a rough poor part of what kind is
this a high priority or low priority
thing and by playing with that idea you
can actually do a lot of optimizations
because you are more losing your
definitions and that opens up the path
for more efficient algorithms and so I
was basically going to talk about new
stuff and the interesting new stuff that
is going on inside Peter and is that I
built a micro TP protocol prototype so
my TP is essentially a TCP
implementation it's a and it's a variant
of TCP and Peter in Christ Klein's uses
it and I thought it was would be fun to
look at well let's build a TCP
implementation or TCP variant
implementation inner line it's
interesting to discuss why they are
using it and why they are there going
that way why build your own very end of
TCP and do all the hassle of doing that
that's interesting and it turns out that
it has to do with the with buffers in
networks Scott fridge he had a thing
about TCP in cast a couple of months ago
the basic idea here is that no buffers
is a problem so suppose you have a
switch suppose that multiple ports
access the same port on the switch then
you'll have a collision on that port and
that collision will lead to retransmits
on the port meaning that tcp would say
see this tcp would see a drop packet and
it will say oh I have a congestion
situation so I have to turn down the
speed by which I'm communicating and by
adding a small buffer you fix that
problem because now things get buffered
up and then you basically we've in these
multiple packets that arrive at the same
time on the port but it turns out that
Jim Gettys has the opposite thing in
observation that if you have two large
buffers that's a problem as well so I'm
modern router on the network usually
have
like 1 gigabyte of a buffer space I'm
not kidding you it's about one gigabyte
of buffer space so what happens is if
you have a high bandwidth line and your
end I as a packet to it what really
happens is that this high bandwidth line
will well the packet will end of the
buffer right and it'll stay in the Baba
very for a very long time before it gets
the queued in the other end and that
messes with latency because now if the
if the buffers is almost empty and I
entire packet there'll be no latency
whereas if the buff is almost most full
and i put in a packet to it it has to
live in the bath until it's the buff is
a queue right so it has to live in the
queue until it gets DQ'd so the ladies
is much higher and that means that we're
amazing a lot with latency and is
imagine that you have a typical line at
home you have a router an adsl modem or
cable modem there that bothers usually
about round eight packets which is
really really low and and basically all
these kinds of trouble will mess with
latency you will have buffers on each
hop on the way to watch your peer this
gives you a lot of latency problems the
problem is essentially the TCP uses
packet loss to detect congestion so when
a packet gets queued in these latency
bothers on the on the way we get into
the trouble where when we get the packet
losses when's one of the buffers in
there is four and that's too late
because we've been turning up speed all
the time because yeah we have this
product bandwidth delay it looks fine we
can just turn up the speed of it all the
time so this is called buff uploader
dark buffers and it was identified about
a year ago by Jim Gettys and my go-to
piece idea is write a TCP variant that
measures latency on the line so
basically we're measuring how long time
does it get to reach the end point and
then have a target latency like 100
milliseconds and whenever we go about
whenever it happens to be the case that
we send it out a packet and we go above
that target latency
we'll turn down the rate by which we are
sending and of course if we are under
the targeted agency we will send packets
faster so basically we are trying to
target a specific latency and the idea
who is that then you can run your
between client at full speed and still
have an HSA in an ssh session that works
and or you can run your tcp client at
full speed and still have a skype call
working next beside it so that's the
basic idea of why we're doing this and
it's fun to see how can you implement
this idea in early it turns out that
there's very little documentation
there's a C++ reference implementation
though contains one object the object
has like 60 fields so the reverse
engineering starts to figure out what to
do about that because you won't you own
you won't want a state record in your
language 60 fields that just sounds bad
so the key point here I think I did
Mikey conclusion was that c++ code is
control flow or injured in the way that
you write statements whereas urlencode
tend to be data flow oriented because
you are telling the system how to
manipulate data from one state to
another so the idea is basically to
change the code such that from a control
flow oriented way into a data flow
oriented way and as soon as you get that
model right things should just pop out
in the right order essentially so here's
the first kind of idea I got we have the
stack in the middle and we begin looking
at what kinds of events can happen this
system so there's an internet it can
send us packets or we can send packets
to it there's a timer with that can
trigger time events to the stack and
there are clients inside the system that
will do is send or receive on a given
day my TP socket so this basically says
that there's only a few events that can
manipulate the stack and those events
are the ones we
interested in if we can write a system
that happens to be based on exactly
those events and reacts when it was one
of the such events happens then we're
basically done we then we have a good
model and there are two key insights
then the first one is of course find the
right process split finding the right
processes to have in your system in
order to do this and the second key
inside is that given a process it will
have a record with state and if we can
find the right way to split that stayed
up into sub states such that it makes
sense whenever you operate on it then
you have a really good model so these
two are probably the two main key
insights and here's the supervisor tree
for the beast and it turns out that what
you need is that actually this guy here
is the main guy when you call send or
receive you you go in here the idea is
that packets from the outside from the
internet will come in here get to the
decoder be decoded and then dispatch to
one of the workers a worker here
represents the socket so each working
down here in the pool happens to be a
socket the pit of that is actually the
socket that a client will use the way if
a client wants to hear out here want to
send something it'll have the pit
directly into the worker here that
allows it to send things each worker is
basically just at jennifer's em and like
TCP you have all these kind of states
where you can be established you can be
listening you can accept you can
establish a connection you could be in a
fin state you can be and so on all these
states you know from TCP basically exist
there and use of those becomes a state
in the gen fsm so the trays are up here
is a trick essentially I have a separate
process that allows me to do run time
tracing of the system so i can do event
raising of what is happening and i can
then do get the event raises and see if
my protocol works correctly so that is
the reason for the tracer
normally it is disabled so it has a call
you call the tracer and there's a return
in there which just as hopefully traced
that's the add some you get back but
then you can use the runtime system
inner line to attach a real debugging
tracer to that and then you can get out
information so there's a dummy function
I use as a probe in there in order to
get tracing of the system when I wanted
for the state in so we have word us here
so the state and a word looks like this
it turns out that what makes sense is to
say we have a major state and it
contains three parts so the process
parts is basically an incoming outgoing
buffer queue the idea is that if you are
processed that want to send on the
socket you end up in a queue there until
you are allowed to send if you want to
receive say 24 bytes you end up in here
in a queue until you want to receive or
until there's 24 bytes ready and the
basic idea is that I can put this in a
separate process or in a separate module
so I can put this in a separate module
and that makes it a lot easier because
whenever I want to do process management
I just call to that module that's a nice
abstraction the puff over here has to do
with the reorder buffer for incoming
packets when they buy a packet is
incoming I place it over there in a
reorder buffer and the buffer or there
also has to do with retransmissions so
if you want to retransmit a packet it's
in there in the buffer construction
somewhere and you can just ask the
buffer I want to have packet number 24
and it will hand it back to you again
it's a separate module so basically this
is the module split I figured out what's
the best one the circuit is down here
but it is wrapped in a network and the
network part contains all the windows of
the system so like TCP we have sliding
windows so the network part here knows
how big the sliding window is can change
the size of the sliding window and so on
so forth it turns out that that this
model is actually brings the best code
in the beginning I had everything in the
state and that didn't
it was simply too hard to figure out
what was going on so I began fiddling
with this kind of split and I ended up
at this split and I think it's okay for
most of the code then we have a little
final key inside so there's this concept
known named boolean blindness then one
who knows about that No okay so the idea
of boolean blindness is that bullion's
are the Scorch of programming they're
really really bad hate them with the
passion and the problem is that if we
have here is some expression and we
computer you to Drew we have no evidence
ye was true right we know we know that
he has is some computation that ended up
and true but we do not know why because
the computation we flew out so along the
way in that computation that might have
been a clue to why Seyi was a
conjunction between a and B so it was a
and B right we might want to know that
we might be able to ask why was it true
yeah because we had a and B and both
were true right that's kind of a
description of why and why this is true
and it has to do with the fact that a
boolean is data but it is not a
proposition hey part of a proof so what
happens is that whenever we compute
something to true we lose the evidence
and that means that true carries no
additional meaning right we have a value
true why is it true we don't know as
programmers we have to look in the
context of the code to understand what
true means and more importantly true is
no proof it isn't a proof of something
it's just a simple bit at one bit value
and that means that whenever we see
bullion's encode we should be worried
and here comes the example for why
this one is basically equivalent to this
one right up here we are asking for the
length of a list we equal with zero if
it's true we do something if it's false
well then the length of list must be
greater than zero so there must be a hit
we can project out of the list right and
there must be a tail we can project out
to the list and I hope that everyone
agrees that this is kind of like bad
code no Erlang programmers should write
this they should prefer stuff like this
down here where you say okay we have a
list the list has a structure so we can
case split on that structure and what we
learn is essentially that if the
structures mg we would have nothing
bound here but if the structure is
consists of a console that has a head
and a tail head and tail will be bound
in the body and we can use a drink and
in a certain way this is better than
this one because up here we didn't learn
anything when it was true we didn't
learn anything when it was forced we
have to reconstruct the information that
there's a head of a list and there is a
tale of a list so what I try to do in
the code is I try to avoid this kind of
situation where we have booty bullion's
because whenever you see it in code you
might actually be coding this very
situation right it might be that you're
writing up code that is this just in a
disguise so be worried about the
bullion's that's essentially the message
the idea is essentially that you want to
rather do it like this you want to write
some kind of analyzer function that
returns a term our data type that does
some analysis of the of the thing and
the analysis should provide some kind of
evidence for what happened and then UK
split on with some kind of executor UK
split on that analysis and do things
based on that analysis hopefully this
means that your code will have much less
analysis based on is this true and false
is this true enforce is this true
enforce you will have much less if mazes
in your code base or case mazes in the
case of Berlin
it splits with the concerns so you have
a simple concern and you do not have to
recompute the evidence of why something
was true so here is a very simple
example from the code and essentially we
want to handle a receive of a packet the
packet has a sequence number payload we
have above a packet buffer and we have a
state this update receive of a core here
is the analyzer it'll go in with the
sequence number of the payload it will
scrutinize the packet buffer and will
give us one out of three possibilities
either it'll say the packet is a
duplicate in which case we can basically
just return the packet buffer and we
tell this is a propolis that'll tell the
upper levels of the system that we want
to act this we can get okay buffer with
a new buffer so that means the packet
was absorbed into the buffer in which
case we return the new buffer and we
consider that we might want to send an
act but that's not necessarily true it
might be that we have a delayed at going
on so it might not be the case that we
want to say send it right away in this
case there henceforth the consider sent
back and the last possibilities that we
might get a film packet in here and a
buffer in which case we also want to say
then we want the AG as fast as possible
but we also want to tell the the levels
above in the system that we got a fin
packet so I hope you can see the idea is
that update receive buffers the analyzer
that goes in and scrutinizes a lot of
data and returns a term here either
duplicate okay pavagadh fin buffer which
we can then execute on we could have
written it with a lot of true forms if
mazes right we could have written we
could have written a lot of things that
would go in and analyze but basically we
have hidden those parts and we have
simplified those parts away from the
main code so it's in there somewhere but
usually we can we can avoid having true
and false in the code by thinking about
this so the main part of the code has no
occurrence of basically pulliam's and
i've been using this a lot
in my code bases now and it turns out to
be really interesting and it's a really
cool way to write it so the current
state is something like this it works we
have about eighty percent implemented of
the guy what we're missing is
selectively acts and other small stuff
it has been tested or the internet it
has been tested with Nettie m which is a
linux kernel module you'll load and then
it can it'll basically mess up your
connection so it'll say you can say to
it I want to reorder eighty percent of
the packets I want three-person
duplicates I want to have a four-person
packet loss and it'll just simulate that
for you so when you're sending and
receiving packets raw packets on the
line you're basically getting messed up
and then you can check that your system
because you're implementing it TCP
connection right so you need to be sure
that it is reliable and hence the idea
here is that you can use an ATM to check
that you actually are doing the right
thing with respect to reliability it
cannot talk with the reference
implementation yet because it needs
selectively acts to do that so that's
kind of the negative at the moment and
that's about it the code is on github
there is a mighty p branch down there if
you want to look at the mighty decode
yeah that's about it any questions yep
you cannot communicate with the
reference implementations UTP is there
any other implementation that you're
able to communicate to or is eat or
everything you have a good probably all
it can use well at the moment the
problem is that there are two
implementations out there the referent
implementing right and this that's it
there's only two possible
implementations and i think that the
reference ref ref implementation is so
hard to understand for many people that
they are not going to use it and this
protocol relax documentation the
documentation is basically it's like tcp
button and it's not like tcp when you
begin digging into it then the small
things that are different for instance
TCP allows you to have what is called
half open connections so you actually
have to close the connection in both
directions this protocol does not if
you're close in one direction the other
direction automatically closes and it
gives all kinds of nasty problems
actually so it's it isn't it isn't when
you begin digging into it it turns out
that that it isn't just TCP pot right
there any other questions huh magnet
links you think yeah not yet my guess is
that it would be around 30 lines of code
or something like that to fix you need
the distributed hash table stop we have
that so the only thing you need to do is
you need to ask the distributed hash
table for I look up and then you should
basically have the turn and be able to
run and more or less so around 30 lines
of code is my guess yeah
there is actually it turns out that what
it is used for is to distribute stuff
inside server farms so you have to
imagine you have 1000 pcs or 1000
machines and you have a PHP thing say
and you pack up everything into a towel
and that tab all is one gigabyte in size
now you want to distribute that as
quickly as possible in a deployment
scheme to these thousand machines it
turns out bit turned is a very good way
to do that because you're maximizing the
bandwidth in your backbone network and
it has been used for that I know that
and that's a good major use of it quick
distribution of deployment yeah it is
adopted in some clients actually and the
official mainstream mainline client has
it and uses it and around so the reason
I began studying it was because around I
figured that around by about ten person
door traffic on the internet uses this
protocol for that reference
implementation and nobody knows what it
does right so that was the reason for
why I began studying it the other
interesting thing is that the latency
happening is what is called a lap pad if
you know about that so you might know
Vegas and Reno and cubic these
congestion avoid congestion algorithms
that bet is a very end of that that
looks at latency and this protocol uses
it and all these things that Jim get is
started with buffer blows and stuff like
that it's probably going to be active
queue management that solves that but
it's fun to look into other ways of
doing it because you might not end up
going the active Hugh management way
because essentially that carries are not
interested in that right
there's no interest in making skype work
better than it does right now nobody is
interested in doing that they would much
rather have that you cannot upload an
image wise skiving right that's much
better because that gives a worse
product and you're going to be you're
going to take your mobile phone and core
instead or something else right that's
exactly what they want so if you take
that kind of path this is important as I
see it because it's research that opens
up the way to solve this kind of thing
in the long run if execute management
does not get there yes yeah yep</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>