<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory SF 2016 -  Build Scientific Computing Infrastructure with Rebar3 and Docker | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory SF 2016 -  Build Scientific Computing Infrastructure with Rebar3 and Docker - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang Factory SF 2016 -  Build Scientific Computing Infrastructure with Rebar3 and Docker</b></h2><h5 class="post__date">2016-03-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JtjYC8kDRy4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi my name is Eric sage and I work in
this building right here this is the
biomedical research facility number two
on ucs DS campus that's part of the UCSD
health and sciences department and I
specifically work in a laboratory at
riata core lab and I'm part of a large
consortium of the cytoscape consortium
which is very focused on network biology
and our uses for Erlang are are solving
problems not only in network biology but
also building infrastructure for
computational biologist and anybody is
interested in building biological
services that can be used by other
scientists and by clients such as a
elsevier which is a medical journal
publisher and other publishers that I
want to be able to visualize and
networks and what I'm going to talk
about today is building a scientific
telecommunications network which is our
infrastructure that we've built out in
order to house services like an
automated gene ontology machine which
I'm going to get to in a little bit so
what I want to go through today is an
example of a biological service and what
that biological service will be used for
and then I'm going to gather some
requirements on what it is that the
biological community needs from Erlang
and then we'll supply some not
necessarily maybe bad solutions but
solutions that don't meet the needs of
the scientific community perfectly and
then we'll supply our solution which
does user lang and the reasons why uses
Erling and the features and challenges
that we faced using or lang and then
we'll go into some details about
deployment such as how we've deployed
using docker and rebar 3 and then we'll
evaluate the final product that we've
come up with and go over our next steps
for our product
so biology today a network biology is
specifically interested in gene
annotations and other types of networks
that hold information that describe your
genome and the products of your genes so
there are many complicated biological
processes that are occurring in your
body right now and the basic building
blocks or at least the instructions to
create those building blocks or your
genes so if you have a network a go
annotated network which is a gene
ontology then you have a mapping of
genes to gene products and by examining
that network we can start to see models
appear of what exactly is going on in
your body and in the body of other
animals and in cells specifically and
what we can do with that information is
we can begin to create very targeted
responses to diseases like cancer and
Alzheimer's which are affected by the
mutations that occur naturally in your
body most of those mutations are
obviously handled by protectors in your
body and so despite the fact that
mutations are always occurring they
aren't usually malignant but in the case
of cancer those mutations get out of
control and so it's your genetics that
are influencing your risk of cancer and
also what type of cure that your body
needs in order to overcome cancer so
I've already gone over essentially
differential analysis as work which is
where we take many different networks
that we've gathered most of them hand
created by biologists that illustrate
the very various biological processes
that we expect to occur and then we can
look at your genome and we can begin to
understand the biological processes that
are occurring in your body and by doing
a differential analysis on those
networks we can start to create targeted
drugs too for things like cancer and
although the the drug itself is
not in the domain of network biology
it's not what we're focused on the
research that we're coming up with is
directly pertinent to to that specific
case and we also are working on Big Data
integrations so one of the things I'm
going to talk about is how we're trying
to automate the process of creating
these annotations and these we're also
trying to create machines that will
create machines that will create
annotations so there are many times
where you cannot generalize a solution
for creating automated gene ontology but
you can create a generalized solution
for a very small subset of genes or for
a small category of problems like a
specific type of cancer and so we want
to be able to automatically create those
machines that will then be configured
correctly for that that target disease
or that target subset of genes and then
the last thing we want to do is we want
to be able to create multiscale views of
genomics so we have a entire genome
sequence now and if you look at an
entire genome as a network of nodes and
edges you're going to quickly be
overwhelmed and the only thing you're
going to really take away from that is
you want to take away the size and maybe
this the sparsity of the network or what
when you really want to do is you want
be able to look at specific sub modules
that are really impacting the thing that
you're trying to study whether it be a
disease or whether it be a specific sub
process in your in your body so what we
want to do is create multiscale where
you have networks that represents sort
of the macro of what's going on your
body and summarize it in very few nodes
and edges but as you drill down through
those nodes they become networks and of
themselves that represent sort of the
micro of what's going on in your body so
going beyond go so go and biology is not
a programming language its gene ontology
and it's specifically a basically a
formalized way of describing a
you're your gene in your gene products
right it has a standard language and
that's what they're really trying to do
is standardized upon a specific way of
describing the the processes that occur
in your body so the problem with this is
that takes many months to create gene
annotations especially for genomes that
we've never seen before so we've
sequenced the entire human genome but
there are many other animals and and we
have not sequence and when we sequence
them sometimes sections of the genome
will look very similar to the human
genome our genome that we've already
researched and in that case we can
summarize and say like well it's
probably jeans are probably the same but
in animals where the genes are not the
same then we don't really have an idea
of what those jeans are doing unless we
take a very close look and start to do
experiments and this takes a lot of time
and what we really want to do is we will
to automate this process and as computer
scientists we can bring the automation
to the the field of biology and that's
where computational biology comes from
so one of the services so the service
that I'm using it as example today the
service that would be useful to a
biologist and a biological community is
called a 80 g 0 which is a like I said
it's a specific machine learning program
to build annotations for a very specific
subset of network biology but echo is
also tackling the bigger problem of
automatically creating machines that
will be able to create automated gene
ontology so it's very cool software and
it's being developed in i decree lab but
the important part is that it's a
service so it takes as input data
pre-existing data about genes that we
already know and then it spits out an
annotated network so it's doing some
students of machine learning in order to
try and correctly come up with this
annotated network that a biologist might
have to build by hand and it's saving us
months of time so the goal for a
computer scientists
that is trying to enter into a symbiotic
relationship with the field of biology
is to make the biologists have the best
experience possible with the aspects of
computer science that they need to
harness to solve their problems and also
for us to simplify and not allow them to
now allow them to rediscover the
problems that we've already faces
computer scientists and software
engineers as software engineers we've
all faced a multi to a multitude of
problems that we're already very well
aware about and we've come up with
various ways of handling them we come up
with frameworks so we come up with
patterns but these aren't things that
biologists are thinking about even
though they have basic understanding of
programming languages they don't have
the understanding of how to build robust
systems and they don't have time to
build those robust systems either right
they have very little time to invest in
software engineering and that's a
problem with the computational ecosystem
when you have very little time to invest
in that because you're focused on
biology you know your PhD is in biology
and that's really where the entire world
is getting the benefit is from the
discoveries we make in biology and not
in computer science then it's us to up
to us as software engineers and computer
scientists to come up with better ways
for them to develop services that will
be of greater use to humankind and the
other problems with how biologists
create services is that they do
construct poor implementations and
suffer from reinvention reinvention in
the sense that a lot of times it's very
hard for them to share code with one
another because they don't have access
to the same types of service discovery
that we've discovered and also because
the implementations they create are
often created off off cuff to fulfill
the requirements of a thesis right so
your discovery is getting you a PhD and
it's the discovery itself that's
important right but the implementation
is also important to many people who
want to go farther with that or who
actually find a use in that in their own
products or are trying to create
products right and so what we want to be
able to do is not only get people to
discover things and get their
dissertations finished but also for us
to have a finished product at the end of
the day to deliver back into the
community and that's going to add double
the value so yeah the the summarization
here is a software is hard and biology
is hard you should only pick one so the
software engineers can do the software
and the computer scientist we can offer
them the the know-how to build robust
services or at least insulate them and
handle that complexity ourselves which
is what we're going to talk about a
little bit and then let them handle the
other hard part which we have no
business getting into which is the
biology right if we separate the
concerns and we each tackle our own
problems and we'll have a much better
chance of succeeding in the long run so
the requirements for these biological
services is that they do need to be able
to scale because lots of these services
are going to be so popular that and so
resource intensive because these aren't
easy problems that we need them to be
able to scale up to handle large loads
and then we need be able to distribute
them for fault tolerance because there's
no point in having services they're not
going to be up we need to be able to
locate them and also allow them to
become discoverable by other other
biologists because we don't want people
reinventing the wheel and one of the
hardest parts about becoming a PhD is
that you have to know the breadth of
your field or else you could just be
reinventing or redoing some bit of
research that someone's already done and
we don't want that and then last we need
to organically grow and these services
such that they will remain the main are
useful but also will stay very low in
the overall complexity and we want these
systems to be verifiably correct which
may or may not be a goal that we're
going to be reaching in the short term
but in the long term we also want to
also introduce to them tools that they
can use to verify the their services so
the first thing that comes to mind you
think of services as a service oriented
architecture right it's a very
fashionable thing to build right now so
build a distribution system of services
because it does have a lot of nice
Ortiz it it allows you to standardize
upon a certain set of principles for
your services it offers free
discoverability and the evolved ability
of a so is immensely easier than a
monolithic system and there are lots and
lots of other properties of so as that
we don't get into like late bindings
which are really only only important for
us computer scientists but we want them
to we want them to inherit those
properties because ventually it will be
used to them as well so here the
illustration is of a community where you
have many services each one of those
services providing a different
biological functionality to the overall
community and everyone is able to access
that community so a few okay ideas for
implementing a so ax and some of these
are really good ideas if you are a
computer scientist or software engineer
so you can enforce an ecosystem if you
enforce everyone to use one language in
one framework then you can just build a
framework that handles all the fault
tolerance and all the scalability
problems and allow them to write a
minimal amount of code unfortunately
this isn't possible these engineers are
using a multitude of different languages
each one has its own strengths and
weaknesses and its own libraries python
are bioconductor pandas these are all
different languages that have different
strengths and some of them can't even
handle some of the the problems we
mentioned in our requirements so we're
going to need to just to skip over
shoehorning them in one ecosystem and
allow them to discover and continue to
use all the resources available to them
in all these different communities the
next approach we can take is the Jeff
bezos's mandate which if you've ever
seen the paper that was delivered by
Jeff Bezos to his employees it spells
out how they are going to create a
service-oriented architecture by
mandating that all services have good
isolation and all of them are basically
becoming good neighbors one another and
that's also not possible because in
order to have the type of services that
amazon has you have to have both the
resources and you also have to have the
the talent pool of software engineers
in order to make this happen and while
we do have very talented computer
scientists we don't have nearly the
resources to sit there and write the
service for every single biologists that
comes through the door and neither
should we because it's up to the
biologists to understand and sure that
the algorithms that are being
implemented are correct and then the
last thing is that we could choose an
enterprise-grade so a tool like
Enterprise Service bus but again this
fall's sort of on the same category of
enforcing an ecosystem because a lot of
these Enterprise Service buses do fall
under the one ecosystem rule and a lot
of them are both overkill for the
biological community which is very
focused on doing biology and not
learning the ins and outs of frameworks
or XML or anything like that we want
them to focus on being able to write
just the minimal amount of code to get
their service out there and make it
useful to biology so we do have a
symbiotic relationship here we are
reliant upon these biologists to further
the knowledge of humankind and to solve
these very very distressing problems
that we have with our health but at the
same time it's up to us as software
engineers to provide them with the tools
necessary for them to focus on those
problems and not on the problems that
we've already solved for them so our
solution is called Elsa which stands for
the Erlang submit agent and I'm going to
get a little more about why it's called
the Erlang submit agent but essentially
it's a it's a routing knowed it it runs
on a server and you connect services to
it so on the right hand side I have a
lot of services it also handles the
versioning of those services so at the
top we can see that right now the
annotation as a service is on version 2
while some of the other services are
still on version 2 1 and then we have a
lot of clients some who may be using one
service some may be using a subset of
services but Elsa is essentially adding
a middleware that encapsulates all the
complexities that the services would
have normally have had to handle
themselves and that's really the power
that
going for here no longer do these
biologists need to create robust
services because Erlang as the
technology is already robust and if we
add in all the features that they want
to have in those services such as
versioning and such as the ability to
handle long-running tasks there is no
need for them to ever worry about those
features and those those requirements so
we can also connect anodes together and
this is where we get into the
telecommunications example because when
we connect multiple nodes together it
forms a relay Network when you have a
client that wants a service it's the
node that is currently connected to that
it's currently in connecting to doesn't
have that service it can relay and
create a channel between nodes to a
service and that services connection
becomes registered to that client such
that there is a dedicated pipe and that
dedicated pipe is why it's defined as a
relay Network this is extremely useful
because there are many communities all
over the world that are working on the
same scientific problems and by being
able to connect to notes together we can
create interesting domains where we have
some groups that want their own
communities of nodes and some groups
that want to have a global community of
nodes and we also want to give people
the ability to sort of create the
opposite type of relationship where
instead of having maybe a top-level node
you have a node that you run locally on
your machine and then it connects to the
top-level node and proxies out those
service calls that does not have into
the global infrastructure there's a lot
of really interesting so patterns that
can be illustrated via using this
chaining of notes pattern so each node
provides a robust API it uses cowboy to
provide essentially a JSON restful
responses resources that allow
applications to dynamically discover
services and this is very powerful
feature one of the greatest features of
so is the ability to dynamically late
bind to services and also allows you to
do this by
using a restful api to represent
services and also tasks which are
long-running requests so if your request
which is just a normal HTTP request is
taking taking too long you can specify a
timeout period which will return
attached structure and this tash
structure will allow you to periodically
check in with a service and employing
mechanism or register a callback and
some biological services do take on the
order of hours today so this is a very
necessary feature for scientific
computing and lastly you can also have
introspection on to the nodes so we want
to be able to see the logging
information of not only the note itself
if you're the SIS ops engineer who's
managing note but also to get a better
understanding of what the services are
doing when they're being requested and
also atomic resources such as threads
which each will get two threads in a
little bit when we talk more about how
to get services into a Nelson node and
register with another node so if we have
a single service call looks like this
and this is very familiar this is just
an HTTP request and we have a domain and
then we have an endpoint that we're
trying to reach on that service so the
idea here is that in order to make Elsa
valuable to the biological community we
need to mutate this call as little as
possible to provide the necessary
information to Elsa be able to route the
call and so what we come up with is
something like this where we replace the
domain of the service with the domain of
the ELSA note that you want to connect
to and then this name of the service
that you want is embedded into the URL
and so is the semantic version that you
want and because we're using semantic
versioning we can actually specify
ranges of versions of services that we'd
be okay with or we can pin to a certain
version and then we just append the
endpoint so there's only really two
little pieces that we've added here
besides changing the domain name in
order to completely proxy a call to one
of these services so for service writers
and this is the most important part if
you know rest you
Oh to build a service and this is really
where we're getting value over using a
framework or using enterprise service
bus because rest is a very
well-documented technology it exists in
almost every language there's almost
always a at least a web server that you
can build and almost all the biologists
that are working on these know how to
build the minimal web service and I
don't know how to add versioning what
how to create these things in monolith
fashion but because they can just take
whatever pre-existing tools they've
created and a lot of them create CLI
tools every function at anything with
the inputs and outputs can be connected
to a handler to create a robust well
maybe not a robust service but at least
a service that we can connect into our
Elsa note and and turn into our bus
service so the life cycle of a service
looks something like you must register
the server via JSON which will show the
registration a little bit to the ELSA
node and then you just receive requests
like normal and to the service after its
registered it it doesn't even know that
it's a part of some large relay network
that's providing at all these benefits
and we'll even see later on that would
docker we can even get rid of the
registration part where we can deploy a
docker container that automatically
registers the service and biologists
just needs to know how do you deploy a
regular service so for the registration
again it needs to be very simple and it
needs to be able to grow and so what we
have is something where we can register
the name of the service and we can have
a version and we can increment that
version via semantic versioning this is
just an example so it's not semantically
versioned and then we can register any
number of instances so this is where we
can get fault tolerance if somebody
deploys many instances of their service
or if they provide their service on
github and then many people download it
and connect it to the same Elsa node
then we can grow it into a very fault
tolerant system because also will be
able to multiplex between many nodes and
we'll be able to automatically detect
failures and recover from them for the
service each service can also
so declare a number of threads which is
just the number of simultaneous
connections that it can have and that's
an optional field if it doesn't then
it's just simply declaring that it can
handle as many simultaneous connections
as Elsa wants to give it it specifies
the location which can specify the
protocol that wants to be connected to
so either HTTP or HTTPS and else does
also handling cores as well so the
service does not need to handle course
and we can also optionally specify
syslog for the ELSA service or the also
know to ship logs to and we and we can
see that in the second JSON object in
the instances list that the second
object was much more simplified but
still a valid instance so just with this
small amount of JSON we've handled
versioning we've handled adding multiple
instances forwarding logs and service
discovery load balancing amongst those
services and this is nothing that the
service writer needs to worry about and
this is nothing new if you are familiar
with building so applications but what's
unique about it is that we've made it so
simple for these people to become a part
of who aren't familiar with these types
of architectures and with these types of
answers to the hard questions of how do
i make my services ready for the real
world and it's all thanks to earling as
well because it's expecting as earling
is now the central point of failure that
it will be robust to failure and it is
so deploying notes so now I've shown you
that it's both easy to create and
consume services using Elsa but it must
also be easy to must also be easy to
deploy Elsa or also no one will be a be
inclined to use it as well because
scientists will want to create their own
domains and not need a computer
scientist or software engineer or sis
ops engineer or devops engineer to set
it up for them and so we've used three
tools here and I think there's some
interesting aspects of them that I'm
going to get into so first one is Elsa
development so Elsa was written inside
of a docker container
instead of going to the normal approach
of where every developer on Elsa needs
to download Erlang OTP and download
their own development tools and download
all of the other tools that go along
with it in their own dependencies we
provide a container that has everything
in it from the vim config to the Erlang
OTP release and so all you need to do is
run our container and you have an entire
development environment in fact the same
development of ira it was written to and
so this is not only a shippable
infrastructure but also shippable
shippable development environment and
that just makes it so much easier to
develop right so we're making almost
every story here very easy and
straightforward even for people that
want to pick up Elsa and just work on it
or hack on it we also have to dr. files
so the first docker file with all the
tools on it would obviously be too too
large to be useful but if we have to dr.
files which is perfectly okay in fact
docker automated builds on docker hub
can handle this then we can have one
docker file that actually builds the
release and when the image is built it
just switches out a sista config file
for asus da config docker file since
obviously inside the container the
characteristics of the note are
different than outside if you're running
it just on a bare note and we can also
set up the dev container such that when
it is run its entry point is the rebar 3
tool and rebar 3 is made development of
this so much easier than we could have
ever imagined and so we're really
thankful for the rebar team for making
it such a great tool so I mentioned
earlier that with docker we can actually
get rid of the registration and this is
one of the probably most advanced the
uses of docker that we're currently
using and that is that a with docker the
idea is that you always have one you
always have one process running per
container correct but we can actually
sneak processes into the container and
how we do this is we have an on build
instruction and so if a biologist has a
service that's written in our they
inherit from a bio service with an R tag
and the bio service image has an on
build instruction that sneaks in a very
small lightweight application that
understands how to read in the
environment variables and register
itself with an Elsa node so no longer do
the biologists even need to know how to
make HTTP calls to an Elsa note register
or how to serialize JSON all I need to
know how to do is simply set up some
HTTP handlers and that's that's really
incredible and this is way different
than creating a framework so there is no
in framework if you want to create a
framework / language the overhead is
that you must learn the ins and outs and
the in the correct way to describe your
processes in that language but in this
instance the on build instruction per
container it must set up the correct
environment for that language but the on
build is always putting in the exact
same application every time so you don't
have to create a different registration
application for our for Python it's all
written in the same language and then
the deployment isn't easy so you just
use docker Erlang is interesting in that
it already has a distribution story so
it doesn't really fit the same mantra
pack as many containers into an instance
as possible you would normally want to
only deploy a Elsa node on one host and
then deploy the rest of your doctor
containers containing all of your
services on other nodes which could be
running anywhere and this really fits in
nicely with other tools like Cooper
Nettie's or compose or mesosphere which
don't really solve the the problem the
networking problems that also is trying
to solve and one of the things that I've
run into why using those tools is that I
always wanted a better way to perform
service discovery and so I think this is
not only solving problems with
biological munity but is also sort of
solving that problem of how do you very
simply set up services that are running
on these platforms to connect to one
another and form a cohesive distributed
application
so what we've come up with so far with
evaluating Elsa is that there's very
little investment to use it and it's
very easy to use there's not a whole lot
you need to know the tutorial is very
small and that's exactly what we wanted
we didn't want to provide a framework
that has a lot of cool features but has
a very large tutorial to biologists we
wanted to say we know you have services
that are providing great value and we
know that you you have created great
algorithms but we need to handle for you
those problems that all all pieces of
software eventually encounter and so
we've I think we've really done that
very well and we benefit a lot from so
as a whole so we were very well aware of
all the benefits of so and there are
even more benefits like late binding
where we can get into building
frameworks on top of Elsa that will
allow us to essentially connect services
the very last possible moment and gain
all sorts of additional properties and
we've also created a central point of
development so no longer do we need to
walk from biologist to buy all just
saying okay now you need to add this to
your code in order to become robust or
you need to add this to your code to be
able to handle this or that instead we
can just work on Elsa and whenever you
work on Elsa you're not just providing
benefit to Elsa you're writing it to all
the services that are going to be
connected to Tulsa and all the clients
will be connected Elsa and the cons are
that there are is a round-trip delay and
that's something that we're monitoring
very closely but so far the milliseconds
delays that we are seeing from using
Erling instead of going directly to our
service is so small that the value are
getting from using the system and the
the features that it comes with our far
outweighing that and then we also have
the central point of failure problem and
this is really why Erlang was the right
tool for this job because Erlang it
gives you these guarantees that if you
distribute it in the correct way and you
write robust Erlang code that you're
going to get nodes where you can be sure
they're going to stay
right that's that's the this story of
Erlang is that it is a system that was
built for telecommunications for nodes
that need to stay up and they're going
to run for a very long time and that's
what we needed so we see this is sort of
a big win for the scientific community
being able to use Erlang as it was
intended to to really get value for the
scientists and biologists and this is
some more examples of computing and
biology I'm not going to go over them
but just to say that computing has done
so much for the biological community is
it's really an understatement I mean
when we first sequence the first human
genome it took us a decade of research
and time and a billion dollars and now
it takes in the hundreds of dollars and
in the order of hours and that's really
really incredible because it only
happened 20 or 30 years ago and so now
we're trying to add even more value to
the biology community by giving them not
only the ability to automate the things
that they're working on but make those
things available to everyone in the
community and make them shareable and
make them as robust as the services that
we're creating for one another and we're
creating for end consumers that aren't
programming and we're going to continue
to work on this and through these
services we're going to continue to
analyze and get a better understanding
of genomes and the interactions of
genome and the interactions of cells and
by doing that we're going to be able to
create more targeted cures for diseases
and we're going to be able to better
understand the history of human
evolution as well and we're going to be
able to draw out models of computation
from biological systems so you've
already probably encountered neural
networks and genetic algorithms which
take their name steaks from the
processes in the human body that we've
modeled and we're going to get a lot
more than future so
yeah so where we need to go next is
we're going to be working on creating a
gooey administrative GUI for the node
and adding in more features like
scheduling pluggable scheduling drivers
for scheduling and working on node
latency and just working on the overall
robustness of the node and if you want
to go further with this we have a site
escape which is the main consortium that
is funding this project and we also have
two versions of Elsa one is our previous
version that's currently in our main
repository and the version I have on my
github which is a sort of a
next-generation and I'd like to a
knowledge dr. Barry dim shack and dr.
Chaddha Kerr who are sort of the
forerunners and on this this project all
right that's it any questions yeah yes
yes so what we're doing is we're we've
had a wedding in a basically a general
way to detect service failure by using
sort of a heartbeat mechanism but in the
future we might add in more fields to
the registration document that would
allow you to sort of subscribe maybe
status in points or for you to be able
to ping the ELSA node and that way we
can add additional strategies that we've
flexible to the different types of
services people might create
distribution right right and so that's
well understood algorithm is scheduling
and and right now we have basically a
pluggable architecture where you can add
in different ways of handling service
load distribution so one of the easiest
way is just round robin or selecting
service that has the least amount of
threads the most amount of threads and
working that way because you could also
have multiple instances that have
different number of threads but there's
still the same service and so you can
then make the decision on whether or not
you think that you'd rather fill up the
smaller servers first and then go to the
larger servers or whatever it is that's
going to be bet most economical for you
right
well there's no way for Elsa or the
services to do that yet but also does
have essentially like a tacked-on
protocol where if the service it where
the client can send it a tolerance and a
header and if the tolerance in the
tolerance is specified in milliseconds
and if you if you want sort of like a
task structure and then allow the
service to wait and performance
computation before sending a response
back to you then that's fine because
you're going to have a structure that's
going to detail how to get that
information later so yeah that doesn't
directly address the problem of well
some services might want to handle long
loads and some might be better at
handling shorter loads which is a good
idea for future schedulers well what
you're describing is more along the
lines of an enterprise service bus which
would start services in response to a
certain workflow and that's that's
definitely a feature that some
scientific services use they need
workflows but for Elsa we're relying
more upon the external tools like kuber
netezza mesosphere which sort of have
that ability to spin up multiple
instances at the same time and manage
those for us and a lot of times these
services are deployed statically because
these scientists are I mean a lot of
them aren't very concerned with densely
packing servers or things like that so
and our and the hardware at UCSD is very
hello Jean Ritter genius so there are a
lot of mix-and-match sort of solutions
going on so we probably wouldn't add as
much value to add in a feature where it
could start up them automatically yeah
right well cytoscape is a consortium and
there are many schools globally that are
included in that organization and there
are other laboratories to and other
projects that we work very closely with
that our alpha testing Elsa so we don't
really have any hard crunch numbers on
how many on the sort of the scale that
we're going to get although we know that
it for now it's it's meeting the
expectations of our laboratories which
is good and we run services and sort of
like the hundreds range so it's yeah
that's sort of where we're setting it
but um for now we're starting take the
approach of optimized after right so any
other questions yeah
right that's a very important topic
right does Elsa need to handle security
and how secure to these services need to
be and the answer right now is we don't
need security we're we are in a
community where security isn't paramount
to our mission and a lot of our things
are cordoned off from the rest of like
the global networks that you that you're
deploying these business services on it
could be an important part in the future
for us but right now i mean the internet
was developed in laboratories where
security wasn't concern and its remains
to be so that for biological services
the security isn't a paramount feature
for us right well that's the reason why
the domains is so important to us and
the ability connect two nodes because
some institutions need to have their own
else's some of them have grants that
specifically are saying we need to
package up this entire thing and have
everything running right here and so for
them they need their own node they don't
need your own repository of networks
they need everything and so for them
they're going to be consumers but other
times we can sort of connect all
services from different institutions
together and we have services running an
amazon and services running at the san
diego supercomputing center and they're
all connected to the same elsa nodes so
yeah we are getting some of that and the
stories are buried there yeah
you can build a global network just
providing like you give us you let to
node into that pool and you get it to
run everything yeah yeah yeahs one of
the things that we were really
interested in is sort of coming up with
this and it's been done many times
before where people have said you can
donate resources to scientific community
computing communities and they'll run
their services on your hardware and then
you'll be participating in wherein
donating extra hardware and extra
resources to these communities are
trying to solve these challenging
problems that's one thing that we really
might be able to do in the future but
obviously the security story has to be
better there because for public hardware
we have to know that these services
aren't going to be tampered with yeah
and we're already pretty good at
handling dude hacia yeah exactly yeah
yeah so we're definitely interested in
that type of you know community
computation where we're all sort of
contributing towards finding the answers
to these these really cool problems yeah
any more questions let's good questions
all right thank y'all so</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>