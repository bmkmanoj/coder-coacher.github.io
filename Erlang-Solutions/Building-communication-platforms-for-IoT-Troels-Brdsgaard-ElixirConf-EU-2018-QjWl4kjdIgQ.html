<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building communication platforms for IoT - Troels Brødsgaard - ElixirConf EU 2018 | Coder Coacher - Coaching Coders</title><meta content="Building communication platforms for IoT - Troels Brødsgaard - ElixirConf EU 2018 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Building communication platforms for IoT - Troels Brødsgaard - ElixirConf EU 2018</b></h2><h5 class="post__date">2018-05-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/QjWl4kjdIgQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">and I'm not so far away in the western
part of the Baltic Sea there's a
practical research factor called Echo
crater and Pond home is about the size
of Oshawa has 40,000 people living there
and yeah this is where we are talking
about consuming heat pumps
so the pond home power system is has
some nice properties about it for
research because it is isolated and not
too big it's connected by sea cable to
Sweden and we can so you can run an
island boat when we need to do some
experiments with the power system and
one of the properties of the power
system is that it always has to be in
balance though all this has to be a
balance between production and
consumption and if there's significant
imbalance that's going to result in
either damages to electrical equipment
or paranoid simply accounts and in the
good old days production was very much
controlled we had the central power
plants producing powerful fossil fuels
and because the query is very much
instrumented for live and introspection
people can see the the sense of power
plants and control consumption or
control production so that always
matches consumption and and since
consumption is also quite easy to
forecast that makes it what made this
sort of easy to figure out the panics
problem earlier but in the brave new
world we'll be bringing in a lot of new
power sources like solar energy and wind
energy which is not very controllable we
need some other tools for creating this
balance and in the EU what we're trying
to do is utilize flexible consumption
men are controlling consumption so that
we can we don't have to control
production as much so this is about
stuff like heat pumps and heat panels
electric cars and washing machines which
for example with the heat you don't
really care when you heat parents is on
you just care about your comfort so if
you're feeling comfortable you don't
care about the rest of it so what we're
doing in eco credit EU is trying to
control these heat pumps and heat pals
we have a thousand pieces of those and
one home and trying to push the time
where they consume power so that it
matches when we actually control power
when we actually produce power and the
system works like this on your left hand
you have the tears OS and the diesels
which are the great operators who can
forecast when they need flexible
flexibility from the consumers and on
the right side you have the consumers
who have installed some kind of smart
heating equipment home energy management
system stuff of that and the consumers
will sign up with an aggregator and the
applicator then receives requests for
flexible flexibility from the grid
operators and then they have all those
consumers who subscribe to the
aggregator that they can put all their
flexibility into a big pool and then
they can fit into the market that we can
offer one megawatt of flexibility and
then if the wind they can actually go
out and activate the flexibility by
setting off the heat or turning it on
one more important part take away 2.0 is
a big research project running over
three years with all our partners
universities and very clever people who
know a lot about the power system we at
a time really to make things talked
together
we are there to see people who can
hopefully figure out that problem
because there's a problem without making
all these kinds of things talking
together we have in our project just two
kinds of different home energy
management systems but they are not out
there already there are going to come a
lot of new stuff on board and what we
really want is to for the consumers if
you buy equipment from Philips or
Siemens or whatever you buy you should
that be locked into using them as
aggregator magics you have to be able to
choose from any aggregator because they
could offer you somewhat of a you
financial optimization of your
consumption others might offer you
surveillance of your equipment and stuff
like that so it's kind of like your film
you have to be able to switch carrier so
you have to be able to switch your
aggregator no matter what equipment you
have on the other hand if an aggregator
if something is thinking about becoming
an aggregator they want to speak as
possible a pool of flexibility in order
to make money so we have to solve the
interoperability problem and then
aggregate we talked a lot about with the
researchers who still knows stuff a lot
about this area how to decide a protocol
and what we sort of came up with this as
a our ideal version of the protocol is
we have at the bottom we have the DRS
which are the heat pumps heat panels
distributed energy resource and at the
top you have the aggregators and the di
will fill in with the aggregator and
establish a bi-directional communication
channel and then they can basically use
a pops up mega destined to talk to the
aggregator
but in the aggregate project as a
soldier we have two kinds of equipment
and none of those can be can speak this
protocol so we have Siemens and bring
the equipment which sort of hangs on to
their proprietary cloud solutions then
we have the aggregators and then what
we're building it is practical and what
I'm going to talk about today is the
flexibility interoperability platform
which offers a it just broke of each of
the activators and then they have this
virtual tea which talks that this new
interoperability protocol and then
delicates into the to the cloud services
in order to activate the equipment to
control the equipment so why use elixir
for doing something like this we are not
an elixir shop yet we have some tools
for the elixir but this the thing that
really matters to us here is that India
has a great platform and has some great
building blocks and articles for the
language so the the building blocks are
how you structure your program right
with this data as structs and then you
have modules which you can put functions
that describe your behavior and I think
this this is common in most functional
languages but then Alexia has this
processes thing which is the secret
sauce for electron current system the
goals of the language match very much
what we want from a system like this it
has to be reliable he has been in a
noble and productivity is really really
important here because we don't have
unlimited massive resources supporting
this into this project but the platform
is the most important thing the fact
that it is
super-solid runtime can do lots of
concurrency being fast and then the the
share nothing mrs. memory model and
failing fast and I think rolling
failures from supervisors is that that
really makes us okay we want to be in
the beam and the Dell to were the ones
that make us choose the mixer so what we
want to share from this what we learn
building the system is a few topics that
we have learned something about maybe
cut parent buy and one of them is
supervising dynamic processes how to do
collaborating processes which are
isolated then some things about managing
state and what goes wrong if you don't
do it correctly and then some other sort
of learnings from production like how to
deploy how to a monetary system so
supervising dynamic processes at the top
level of the application we have just
yes billed as one single application
like it's a monolith like session
earlier I talked about we put up and
then we put up a metric Explorer which
is a clock endpoint for metrics then we
have an elixir registry that we use to
facilitate communication between the
processes then we have an Excel repo
ecto repository for database stuff and
then we get to the application specific
parts where we have a Siemens supervisor
and Siemens manager and premium
supervisor and creavy manager and this
is what it looks like for one of those
trees the Siemens virtual the substrate
let the supervisor and the manager and
then for each installation
each household that we need to connect
to we have a bunch of processes that
need to collaborate and these are all
spoiled by what we call an installation
supervisor so
the top seaman supervisor is simple
wonderful one or dynamic supervisor so
we can dynamically add and remove
children then the next one is a
one-for-one supervisor which is with a
permanent permanent restart strategy and
it just spawns five children our queue a
scheduler controller and QT client and
an executor and what the idea here is
that when the system boots the CMAs
manager will go to the database find out
what installations is to start they know
send a signal to the scene in supervisor
to start each one and then since it's a
simple one for one with the trench entry
structure we start strategy it should
restart children if they fail but it
should be allowed to be removed again
the children yeah so that worked really
well until one day we had a crash of an
external system which then impact the
amount of learning process we see is
mostly just worrying about 2,000
processes until one day it drops to 500
processes and we are sort of wondering
what went wrong here because it's
supposed to be restarted if it fails
right so we go to lock the lock file and
find this the installation supervisor
has exited the reason of reached max
restart intensity mean that one of its
children has been let's try to restart
one of his children too many times and
it's given up and I was blowing up and
then asking for the supervisor above it
to handle this case but actually when
the thracian supervisor decides to give
up it doesn't that's actually a normal
error
so the transient restart strange doesn't
catch it its essence it talks if you
read them that if you supervised and
reaches maximum restart intensity then
it will exit with a shutdown reason and
in this case the supervisor only will be
restarted if the supervisor above it has
a permanent restart strategy and says
even more clearly and supervisors pick
that if you're using the transient
restart strategy then it will only
restart the process if it terminates
with an exit reason other than normal or
shut down or shorten turn in this case
it's shut down so the process did not
get restarted so we were being a little
too much naive about that
superb accent dynamic processes so I
watched you talk by refresher but just a
few weeks ago from I think it was six
days I think explains like that's
actually how it should be you know what
you supervised it to be super
complicated and trying to handle all
these failures
instead you should have the manager
there has to do some more work so it has
to continually be watching the children
if they are dead if they're live still
if they keep dying try starting with an
exponential back-off and intense another
to someone so that there's case and can
be handled because we would have gone
even more wrong if we had used the
permanent restart strategy because then
the installation supervisor would just
fail so fast and then is this top-level
supervisor would have died and it will
crest all the installations so we've got
a lost data from all of them so isolated
but collaborating processes these are
the five process processes in a CMAs
installation
and they only to collaborate but they
also isolated in that data really care
that the controller doesn't we look at
that the cue is that cue that he talked
to previously it just has to be a cue
that is having messages for this
installation so they can come and go
independently just as long as they can
always find one that they need to talk
to what happens when this system builds
is that the MTC file connected to the
program and the executor connects to the
Siemens cloud yes you may be sick
mansion that the executor is there to to
actually execute commands against the
the CMAs the installation and the
equipment out there is pretty fragile we
learn you can't do any kind of parallel
request against an installation if you
try to do that you would just overwhelm
attend or equal to offline so we have to
manage carefully how much would local
put on there what the equipment so we
put a cue in there which is sort of
first-in first-out
with a bit of priority scheduling in it
and then we have a scheduler which you
patrol start some jobs that have to run
sort of every ten minutes we have to go
one scrape information from there from
the device about what the settings are
in the device and then the the control
there is get messages from the amputee
client and converts that into commands
to be sent by the executor yeah so what
happens when the executor is connected
it will start crawling the configuration
of the seniors device to figure out what
they can do and once it knows all of
that it will send a message to both the
schedule and the controller that it's
now ready and this is the configuration
that they can use for generating
commands and then we'll tell the queue
to DQ the next job and right now the
queue is empty so it's just gonna wait
for a message to arrive
the schedule of incidents start signal
to itself because now we can start
scheduling jobs it reads the
configuration generates a bunch of
commands and push those into queue and
then the column executors will get their
new commands run it against the Stevens
is device and then send the results back
to the set the schedule and this is what
happens when the messages come from
energy program gets to the client it
forwards it to the controller
it took add then depending depending on
the message it can maybe respond
immediately or if you have to generate a
command that is in cute with the queue
then the executor runs it and since it's
back to the controller which campaign
generate response to their to the
aggregator and the as I said the queue
as knows a little part of priority so
all the commands coming from the mqg
client are high priority and the skip
towards low priority and then it sort of
most of the time it would give out a
high priority command so yeah what can
go wrong here seems pretty simple but
when the system boots all the scheduler
boots it will just sit there and wait to
get this message that the executor is
ready and the executor only generates
this message once it is done booting and
has Trotter configuration so if the
scheduler happens to crash for some
reason maybe talking to the database and
the database wasn't there then it will
crash and the supervisor we started
comes back up and it's fine but now it's
just sitting there waiting for the
initial radio signal is not going to do
anything so just because something is
isolated does not really mean is
independent you have to keep that in
mind one way this could have been solved
is
supervision strategy here was it so
instead of being and making it a
one-for-one supervisor it could have
been a restful one and then everyone
killed it which one of them died it
would restart the rest of them so it's a
skateboard I don't we start executors
and then it would do all the stuff that
had to do but well another way we sold
the voice just to make the executors
take the convict every ten minutes so
that would at least get this ready
signal after ten minutes they just have
to people be aware out there making
processes talked together when they are
dynamic and going and coming away is
actually very easy in the mixer if you
used the registry so this is how we did
it when one of these processes boots up
it generates an ID which is used to
register with with the registry and it
does so giving it value this in this
case it's control which will then be
used when so no one needs to speak to
the control of this to Yahoo just ask a
refugee for the for the for the process
like this so in this case it's the
controller which is needs to talk to the
queue so it's just says register find
someone with my ID and has to be a queue
and then it can send the message to the
queue and then the registry also offers
this dispatch function which can be used
for doing sort of pops up like things in
this case this is the executor when it's
done calling the configuration it tells
the registry to dispatch for each injury
that matches this topic everyone through
the list and then if it's one of those
processes that that needs to know if it
that the conversion configuration has
been noted then it will send that
message to the process so the registry
was added in 1.4 version of elixir and
it's really works really well as long as
on a single note which we are in our
case so if you need to do something like
that just use it
I mean alternatives are things like deep
rock or Phoenix pops up or was just a
normal name of the note by Adam but I
think there is she is pretty good
because it has the first ones
functionality to do pops up like things
when you need them
so expecting the unexpected what's the
schedule doing here it so since a few
commands to the queue gets the results
back from the executor and then what is
it doing it's trying to save it to the
database the results right and we did it
this way because we don't really care
that much if there's no it's not stored
it's just something we're doing
periodical periodically to check if the
if the custom out there has been
changing settings on the device and so
so we don't actually match the return
value we just say well go and do it and
we're using the non-bang variant of the
form of the insert function because we
don't care if it succeeds or not but
that's not enough right
sometimes it crashes anyway and turns
out that if efecto can find a worker
fast enough to do the actual answer it
will crash with a time out of five
seconds of that's the default right with
the pool boy as as you're pulling
library so even though you think you're
just trying to insert something you
don't care if it fails
doing this way is not safe because then
you crash the schedule that's why we had
the other problem with the scheduler
just sitting there and doing nothing so
yeah don't just depend on a function
being a non bang if you want if you want
to be really safe about the accident
carrying out
you should wrap it and a try-catch or
you should spawn a process to do it so
yeah that was kind of a stupid mistake
to make and then we have these stateful
processes which are all mingling here
with some other processes below the same
supervisor and we looking at it we knew
that their MQTT client was prone to fail
and also the executor was prone to fail
because they are talking to a external
systems so we keep those totally
stateless and we make sure the state is
the other three processes
now there was I was sort of a super
smart when I did that but it turns out
that of course if any of those processes
crisis too quickly and their supervisor
keeps up then it's going to crash all
the children so there's a pattern that
you should look into if you're doing
stuff like that the error current
pattern and so what we should have done
in this case were to instead of putting
all those process below the same
supervisor we should have some current
nested supervised submission tree in
order to ensure that the the ones with
important state don't get killed just
because a supervisor gives up on
restarting one of these volatile
processes and you probably cannot have
too much supervision so errors this is
just cut off from all of the module a
function that for the Simmons client
that since I'm dressed too
to the CMAs device and they can get a
lot of different errors back like it
wasn't wasn't invalid style code or I
could Dakota Jason and stuff like that
and what we did initially was just wrap
all those up and into tuples with era as
the first element of discipline and then
the second element was something that
described the error and that's that
works until a point because but then you
get to when I need to lock this error
maybe someone is calling it ready to put
it into lock that they would never or
maybe you need to track a metric and you
need to figure out what what kind of
different there was do we even have that
could return from this function so
instead of just returning there were
troubles with some kind of weird top of
describing the error we decided to use
the TIFF exception macro to define a
struct which implements behavior and
that is used by by elixir just had to
implement two functions exception which
is a kind of constructor and then
message which is used to return a string
error that can be used to print the
message in a lock so just very simple we
had a simple one single module for all
of our different error codes or arrows
and then that kind of gives us one place
to go and look for it right and now
instead the code looks like this so if
you get an error back we format the
error that's basically just calling it
an exception with the tuple we want then
we can just lock it with our third
message and we can do send it to a
metric system for for increasing the
account of that kind of error and that
makes it easy to match on you know you
have just one place to go and look for
what the different kind
and this was based on a blog post
described that describes the process by
McHale that is linked here and yeah
basically we put everything into one
single arrow module because there was
good enough for us of course if you have
a large system with a lot of different
stuff you should probably have a few of
those arrows struts for your modules so
instrumentation of metrics we use
Prometheus to monitor or the data center
that is being used for this project and
not only can I capture a metric from all
our services but you can also build it
into two hours our our project so we use
the Prometheus IX library which has all
the things you need and then when
permits us goes to get metrics it makes
an HTTP request to your service and it
returns something that looks like this a
line for every cattle metric and then
it's also in its database and you can
use it to make or use a file to make -
posters kind of shows how you list for
your services - and we've been very
happy with that maybe and this comes a
standard you can download this - but
from Copernicus all lot of metrics from
from the beam like what is your process
count what is your love what is your
garbage collection look looks like and
then you can make your own custom
metrics like you use previous metric you
define a set of function which will be
called when you click application loads
and here define the different kind of
metrics you have and then every time you
have an error you just call observe
or some function that that will
increment the counter for you that's
basically all you need and we use this
also to pull to get measures from
hackney which is we use it's poison for
for HTTP requests and Hackney is kind of
the one to win to work there and it has
an option where you can actually go and
define which much of you want to to you
attractive and then you can define your
own that just real lives so yeah do some
monitoring you can do Prometheus tons of
other options but it just fit into our
stack really well and once you have a
sense of what normal operations look
like you should set error so that if you
know your process counts certainly drops
by 80% you should probably send an error
to someone so deployment is all running
on a single virtual machine running TV
and Jesse and we use ansible for all of
management both operating system and app
configuration and for to interference
and ansible if you don't know it's a
kind of it's a system like former Indian
country is a configuration manager for
u.s. Forest Service and the tooling that
we use is distillery which we used to
build our release and then conform so
that we can configure the release then
we have built our own ansible role which
does the job of building a release
inside of a toga image and then actually
sending it to the server and just
restarts a service so that the new code
is loaded and then we use vacant for
testing our deployments to make sure
that work and on the server the our
release is being run by system T it with
gel system T to forward its locks to
Parsons lock and then
we use lock motor too many locks so this
is super simple doesn't require any kind
of big expensive setup yeah it works
well for us to set up what we need to
get started with releases you first
install distillery and generate a
release config you had to conform plugin
for managing configuration and then you
generate your configuration schema and a
sample config file with conform when we
deploy we use makes release the command
to build distiller we do this inside
taça to make sure it matches the
operating system of the of the virtual
machine we define to that produces a
tacky set file which we SCP up to the
server and here we all are cover to the
proper directory and then make any
changes we need to the configuration
file and then that sounds like a lot of
work but once we have it automated is
just the single command to run it on
production of stating over you know
whatever environment you want to so
about configuration just wanted to touch
on that mix config is be baked into the
Cisco fig looks like that looks like
this it's not very nice to manage for
people who don't know it looks alright
so we use conformed to give us a sort of
nice in style format of controller
configuration and the this is done by
with conforming generate a schema file
SSL which has an information about all
the different kinds you can configure
through the mix config and then it knows
how to translate from the from the
simple in style config to the system
config and the only sort of annoyance
we've had with that is that the schema
file has to be every time we make a
change to your mix config you have to be
generated a new schema and then if you
have to sync with the old schema
basically
but yeah configuration is getting easier
in the future hope hopefully already in
alexia 1.7 but yeah news releases the
been baked into the system for the
turning ecosystem for a long long time
and they can give you what you need we
haven't used how to encode be loading
and stuff like that just because we
wanted to keep it simple I wanted to
touch briefly on debugging if you ship
your release with runtime tools then you
have access to debug and you just make a
remote console into the machine then you
type dbg dots and you get all these
nicely self-documenting functions for
how to figure out what your system is
doing which doesn't work really well but
it worked for us in our case when I was
submitting the talk we had the issue of
why is nothing happening on this
installation we can see the schedule as
there was it like doing things we
associate into it cut a little console
running set a trace for one of the
processes and then some and the end
which figure out that was because that
it had been restarted and didn't receive
there the new sequences to start getting
data from the device so I don't have a
lot of experience with debugging in
production other than that but the tools
are there the platform is very
introspective and you'll need you need
some way to find your processes we use
the registry for this and then don't use
debug really if you want to if you don't
don't want to shoot yourself in the foot
get something like recon or tracer which
are more safe through our production
it's kind of its respective things that
work well for us in this system I talked
a lot about stupid mistakes we made
but in excess actually pretty well it
has been running stable motor design but
we didn't
to sip stuff we kept this avocation
stable to ship fast and then using these
exception structs using Prometheus with
monitoring and using the rich turned out
to be good decisions things we would
have done differently read the
documentation more carefully to more
granular supervision and more extensive
testing of fitness scenarios because it
exists new to us we should have spent
more time working with Docs and types
because it really helps when you're new
to to read the documentation and then
the last thing that we've started doing
is to separate the concerns inside
inside the Chancellor because at the
beginning we started out just having a
monolith one of the Chancellor with the
public API and the OTP callbacks and
then the actual business logic inside
one module but then we heard about
Dave's approach of separating these
kinds of things so that you
yeah separate stuff and that's a
no-brainer just go into it I think
that's it for me thank you for listening
and yeah any questions
you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>