<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory 2014 -- Verified Vector Clocks  An Unexpected Journey | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory 2014 -- Verified Vector Clocks  An Unexpected Journey - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang Factory 2014 -- Verified Vector Clocks  An Unexpected Journey</b></h2><h5 class="post__date">2014-03-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/IINmkv4izVQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">look okay hi welcome to Erlang factory
so the disclaimer I'll start off with
before we get going here is the actual
name of this talk is vector clocks in
 and experience report but Garrett
Smith who I'm sure you're all familiar
with a range is somehow consistently
with program committees to get all of my
talk titles changed to an unexpected
journey specifically because I've not
seen the hobbit nor read the hobbit and
yeah you know he's got this joke which i
think is pretty funny that all
technology that i use somehow i get this
unexpected journey and i never know what
is going to happen so I'm gonna just
keep ripping with it so um yeah so the
talk is called vector clocks and cocking
experience report I'm a software
engineer at fasho technologies um excuse
me that was loud where I primarily work
on multi data center replication in
addition of that I do some graduate work
when i have time which is few and far
between these days and this is kind of
just a project that i've been exploring
on my own because i think it's
interesting so it doesn't really not
very it's not super practical it's just
an interesting approach to looking at
how to potentially solve a problem that
that may or may not be interesting to
you so the general outline of the talk
we're just going to walk through a
introduction we'll do a little
background on what is what Kirk or
Erlang is the extraction mechanism that
we use to generate the code which is not
written by me which was written by
somebody else and then we'll talk about
how we can actually use that that
utility and build some adapter like glue
layer between it so we actually can use
the generated code inside of the reactor
base obviously that batch Alixe will
look at the evaluation how it performs
what the challenges were and then we'll
kind of talk about what I think of their
next steps that I'm going to continue
researching towards furthering the idea
of like verifying models and properties
of things and using them in a production
system
okay so what are the goals of the
project the goals of the project are
very different will talk about the very
specific goals of the project but that
goes with a project very very different
than the goals of the actual talk I'm
going to gloss over a bunch of stuff i'm
not going to show a lot of the core or
lang code just obviously because like if
i put a slide up for 10 seconds you're
not going to be able to digest it so
there is an open source repo we'll all
of the code I've written a blog a series
of blog posts that actually walk through
it so those will be a little bit more
technical version of the talk that i'm
going to give today and then we'll look
at the contributions of what the repo
provides there's also a paper that's
been written that outlines a lot of the
work a lot more detail than this talk
and what the things that we're out of
scope for this project were and how it
relates to other stuff that's relate
that I also have repose for that can go
investigate if you are interested in
pursuing this further and I'm happy to
talk about it too because I think it's
really interesting idea so what are the
goals of the project so at every con
west I gave a talk about distributed
data structures so how many people here
are familiar with CR DTS okay a few so C
or D t's were basically data structures
it's a way to build these data
structures that build off of bounded
joint semi lattices and they have a very
nice unique they have a very nice useful
property for distributed systems where
operations on those data structure is
because of the lattice properties they
observe can be associative community of
an item potent so it allows for batches
of events to be reordered it allows
individual events to be reordered and it
also allows to replay the same event
multiple time so we like these things
because we can get determinism and an
otherwise non-deterministic distributed
system so there's been a bunch of work
fasho has involved in doing a lot of
research on CR dt's I think there was
maybe a talk at rolling factory last
year about it there was one at recon
there's some other talks that people
have given at other conferences around
here about CR DTS and how you use them
and what I start out to do as part of
course work when i was at brown
university was finding a way to formally
specify
the crd T's in the proof assistant and
then prove some trivial properties about
them and explore how we might be able to
use that in further work since then some
people at Kaiser slowing have been
working on this as well and in addition
to that some of the people at inria have
also been working on it so they've taken
it much further than I did and they have
a lot of work based on how to they also
have some talks coming up at a
conference in April about how to specify
these things so this is the original
motivation of the work is how can we
write these data structures and use them
in react but formally prove some
properties about them and it'd be nice
to have it so we don't have to like
formally approve some properties about
it and then write it in Erlang and then
also like test every possible
combination of like inner leavings of
operations on those events or things
like that so the general idea is we want
to explore the applicability of
extracting code from so the proof
assistant itself has the ability it has
its own dependently type functional
programming language it also has the
ability to take the code that you write
and extract that code out into either o
camel haskell or scheme and we're going
to talk about core Erlang which is a
what somebody has a experimental project
that allows them to do and the whole
goal is to a you know to provide this
alternative to rigorous testing right
like the way we go about certifying
these things now is we write a quick
check model and we have people double
check it and triple check the quick
check model and then we run the quick
check model forever you know like three
days there's something crazy like that
and it'd be nice to not have to do that
or to provide an alternative to
exploring ways to do that and you know a
big problem is that you were developers
who are writing these you know what we
do is we take an academic paper that
comes off the shelf you know that's like
here's how you write down to version
vectors or something you know in the
paper defines a series of lemons about
property you know there's a series of
lemons and a formal specification and we
take that and then we interpret it the
best way we can in Erlang and then we
write a quick check model and the
problem is is that you know that
translation is not always correct and
you run into situations where hey the
quick check model says everything's fine
i thought i asserted these properties
that you know
I read and I consume from the paper and
then you find a flaw in the quickcheck
model right like from a trivial use case
where something breaks and then you're
kind of like okay I have to go back and
reassess did I even write the quickcheck
model correctly so you know it's this
classic problem of how do you take like
this very formal model of something and
then how do you look at the the actual
implementation of it and make sure that
that implementation is correct so what
are the goals of the actual talk so will
provide a brief introduction to a
brief introduction to court Erlang we'll
talk about what vector clocks are if you
haven't heard basher talk about that
enough and will provide an overall
experience report of the entire process
cool so what are the contributions so we
have a model providing an
implementation of vector clocks or
virgin vectors depending on how you use
them we have extracted we have extracted
a core Erlang module that is generated
from this code using the extraction tool
that will talk about we have a glue
module that's used to basically do type
conversions and a bunch of other
environment things will get invert the
specifics that we have to deal with
their about how to get the boundaries to
work when we cross those boundaries
there's a detailed experience report
that's written up in a paper and then
there's an extension to rebar that's an
open source that allows for compilation
of quarreling so that's a very general
thing that you could use if you're
writing coraline in your project so
what's out of scope for the work so
verification of the actual model we're
not going to talk about any of the
lemmas that we could prove about the
vector clock model it's actually pretty
trivial I have another repo that has a
more efficient implementation that has a
bunch of properties proven that's not
the focus of this work and one of the
reasons it's not the focus is because
we're exploring the applicability of the
code generation aspect and not writing
that they're writing the theorems you
know that's like not really appropriate
for the conference as well as the way
the proof assistant the way you prove a
lot of these properties through
induction and stuff like that and the
proof assistant are tied very closely to
the way that data structures are modeled
and during this work I had to basically
you know it was originally implemented
on top of fine
maps than finite sets then then it was
implemented on like a normal a
conductive list and all of these things
so I kept changing the the data
structures and every time I change it
all the proofs would break so so that's
not that's not the focus of there's work
also efficiency the cogeneration doesn't
generate really efficient stuff you know
the stuff that we fight with practically
you know in our everyday work the proof
assistant is going to generate a code
and say I should use a Nordic try than a
dict because of like time and space
efficiencies it's not going to look at
any of that stuff so we're also not
going to talk about efficiency we're
going to look at a very very simple
implementation very simple because it
will be easier to consume as listeners
at the talk so we'll talk about the
background so um so cocky is an
interactive Deer improver if you haven't
seen it before it has has like three
kind of languages in it's got a
vernacular for dealing with stuff it's
got a dependently typed a programming
language inside of it called galena you
basically you know write a series of
functions and definitions and properties
about things and then he can go and
improve properties about those things
too like D structuring and induction and
all stuff like this and it can do some
automated stuff but not as much as
others and you know in terms of code
extraction it has the ability to extract
code to scheme Haskell and o camel it's
actually written in no camel so the o
camel code that gets generated is is
probably the most functional code we do
have some stuff that we played around
with doing with Haskell code extraction
in relation to vector clocks as well and
finally quarter lang is an experimental
module that has been written by somebody
named Tim carstens who built it as it
appears to be a school project but it
doesn't really say and it's not really
maintain that much anymore but it does
have a bunch of examples with things
like interval hash trees and stuffs that
have been implemented in the proof
assistant extracted out into an erlang
module that you can run so we'll walk
through a brief example of what this
stuff kind of looks like we'll do a
couple slides so when you
shall we start to see the code that we
wrote it'll make a little bit more sense
so you know if you're familiar with type
systems or typed languages here's an
inductive data type called net which
models piano numbers so you have two
constructors and you have a the 0
constructor which is the base case and
then you have the S constructor which
takes a gnat and returns an that there's
some formatting stuff that was left out
of here because I copied and pasted it
and it didn't work out well and led tech
but I apologize for that so that's
pretty straightforward you have two ways
to construct natural numbers so like a
three would be you know the successor
applied to the base case a number of
times and that's how you build up your
number types so obviously naturals 0
greater and then you know if we want to
implement again sorry about the
formatting and then if we want to
implement ble net which is a boolean
function that it's a returns a boolean
that computes if number is less than or
equal to another basically you know
there's a function signature it's going
to take NM of type net return type bool
then we basically just do some simple
pattern matching they should be familiar
to erlanger zor anybody's done like
Haskell or o camel where we just pattern
match and then you know destruct on the
pattern there so you have like we're
going to match end with the base case
it's true a s of n and then oh and
folsom looks like that so cool so a
quarter lang how many people who are
familiar with quarter lang or have
worked with it ok so a few more people
so quarter lang is an intermediate
representation burling there's a bunch
of papers about it cost us is in the
crowd Oh probably have something to say
about that you know it's designed for
programmatic manipulation of code so
it's designed for tools to basically be
able to like you know compile the coral
and programmatically manipulate it in
rewrite part of the program so it has a
very very simple to emer it's very very
disagreed and we'll see an example of
this so a lot of the the guards are not
enforced as cards it's all but there's a
lot of it's all boil down to kick case
statements basically and here's you know
here are the two functions that we would
use if you're actually inside of an
erlang shell you can do see module name
to core or from course so you can
basically and this from core is actually
going to look for a file with dot
or is the extension a rather unfortunate
file extension if you ask me if your
unix programmer but you know so it this
will look for a dot core file and then
try to compile eight and all the support
we added to rebar so you can basically
have source directory with dot earl and
core files and it will build them and
compile it all and package it up so
that's good and that's how we actually
we provide a version of rebar in this V
V clocks package which implements this
that you can just like put into a
project so we just were able to add it
as a dependency of react compile react
using the new rebar and build all the
core files and have it all work so
here's an example of the extracted code
so this is not very idiomatic at all but
here's the same function we looked at
the less than or equal to and you know
we're modeling it's important it's
important to note here that we're
modeling the constructors as tuples is
that we have an atom the atom 0
represents the base case and then we
have the atom s with n inside of a tuple
and that represents the successor case
so you can imagine that this becomes a
nested tuple of a nested tuple of a nest
and tuple and that would represent like
the number 5 and that's this is the core
idea of how this extraction program
basically does the mapping between the
two because you don't have this type
system you don't have this ability to do
these abstract data types so you you
basically encode constructor calls so
the first part of the tuple if there if
it takes more than one argument you know
it has a tuple and it uses the first
position of the two Perl to represent
the actual constructor name and then it
has the rest of the arguments to the
function cool so so ver lang or V Erlang
I don't know how you would pronounce
that verbally is an experimental
extraction module for that will
generate core or leg code and the way
that this does so this is the project
written by Tim Carson's it's open source
on github so the way it works is that
when you go to do the extraction the
extraction itself uses an intermediary
language called mini
which is a like D sugared subset of ml
and then that goes to either Haskell or
camel or scheme and what this does is it
basically provides a mapping from mini
ml to quarter lang and it's got a number
of caveats because you can imagine we're
going from a you know a very typed
language to a language that's
dynamically typed so there's a bunch of
challenges about how you map that stuff
together so let's look at what these
caveats are so the first one is the lack
of module nesting so when you
actually are programming in it you have
the ability to do nested modules as far
as you want and you can namespace things
and call things correlating doesn't
Erlang doesn't really support this
really there have been some attempts
obviously it doesn't quarter link does
not support this at all modules have one
name and it's just like it's an atom so
we don't really have the ability to do
this module nesting so we have to kind
of munge the namespace a little bit and
the way we do this is through taking the
fully the full name space name and
basically using like a quoted atom with
a fully qualified path which obviously
starts to make things a little bit more
complicated um there's no currying right
so in earling you don't have currying
like you have in like Haskell or a camel
you can kind of do it manually in the
same way you could do it in like
JavaScript but you don't have you can't
use no like real partial application
right so this is problematic when using
higher order functions like things like
folds and filters and things like that
and we'll see an example of I have a
slide where I show code that the
extraction is completely wrong because
what we want to do is we partially apply
a function and pass it around but that's
not possible so what it essentially does
is convert that to a function that takes
you know if rather than have a return of
function it basically creates a function
that takes two arguments and then the
code fails to execute at runtime because
it has no way of catching it at compile
time the other difference is inter vs
inter module call SoCo Erlang has a way
to distinguish intro vs inter module
calls through call versus apply we don't
have that concept here
especially because of the weird way
namespacing happens so you can easily
work around this by just fully
qualifying all the calls and treating
every call as a inter module call
finally there's no receive primitive
right like the proof assistant does not
unless you encode all the Erlang
semantics which there are projects that
have attempted to do this as well you
know you have no concept of what a
receive is what a process is things like
that so without this received primitive
it limits a lot of what you can do and
we'll we'll see I don't actually have a
on this slide for that but I do have
some examples of that as well so we'll
do the vector clocks review we'll keep
it quick so what r vector clocks some
vector clocks are a method for reasoning
about events in a distributed system it
allows you to identify causal
dependencies or causality violations or
things that are actually events that are
really concurrent in the way that does
this is you basically pass around a
vector of these clocks and these clocks
basically have an actor identifier of
somebody that's performing an action and
then anna has an identifier of how many
times they've performed an action and
sometimes you have time stamps we talk
about the challenges of introducing time
stamps for pruning because vector clocks
can get very big when you have unbounded
actors and you know if you're familiar
with how databases kind of track
causality between versions in the
database that's commonly referred to as
a version vector structurally the
objects are exactly the same but they
have different semantics about how
they're actually used similarly if you
look at in the crdt literature there's a
type of crdt that's called a G counter
which is a counter that grows only and
that that is associative commutative
idempotent and you know so converges to
the correct value regardless of the
ordering of events and what that does is
track how many times the G counter is
actually interesting because it does not
have it does not have item potent
updates but there are other counters
that do but it basically tracks it in
the same way that you would a vector
clock just the number of operations
perform by actors and that Stuart is
basically a list of if you want to think
about it in terms of Erlang that's going
to be stored as a list of two tuples and
the two tuples will basically be the
actor identifier and then
the count and if you look at we actually
model as three two poles because we put
a time stamp in for pruning but if you
look at on V clock Earl and react we
have a full implementation of vector
clocks with the eqc tests and everything
so you can go and play around with that
if you'd like we also have a dot a
version vector and a diversion vector as
well okay so implementation so we'll
talk about the vector clocks and we'll
look at the code extraction and then
finally we'll look at the adapter layer
so what do we want to do so we want to
provide an API that's compatible with
react course so we want to provide exact
same API that V clocked out early and
react core uses so we can basically
transparently swap out or module with
the module that we generate the react
Roger well with the object that we
generate and here's a sampling of the
API functions that we need to provide
over vector clock so we have a way to
generate a vector clock through fresh we
have an increment call and quality check
a descendant check which is a descendant
of it determines if the second argument
is a descendant of the first it's not
there's a strict descendants as well and
which we check both ways and then
there's a domination function as well
merge function to take two vector clocks
and combine them a get counter which
basically says give me an act given an
actor I'll tell you what the counter is
currently at give it an actor I can tell
you what the time stamps at would get
time stamp a method to return all of the
nodes that exist all of the nodes that
have been involved in updates on the
vector clock and then a mechanism to
prune the vector clock so based on a
given time stamp or a series of given
time stamps I know how to remove certain
entries from that vector clock and
that's and that's primarily used in the
event where an actor has gone away or
something like that right so what does
this look like in the purpose in so to
simplify things for the purpose of this
we're going to model everything as
natural numbers so we're going to treat
the actors as natural numbers for the
point of this we're going to define the
count as a natural number which makes
sense right you start at zero you count
upwards up based on operations we're
going to treat timestamps as natural
numbers so the proof assistant doesn't
have a concept of what a unix timestamp
is or a time stamp or things like that
right so what we're going to do is we're
going to make an assumption that you
next time stamps do monotonically
increase and clocks don't roll backwards
which is not
true in the real world as we've all seen
but we're going to make that assumption
for the purpose of this work and then
we're going to define an individual
clock as the product of an actor with
the product of account in a timestamp so
what does that really look like it's
basically a 3-2 poll right it's priced
product of these three so the actors
account and the time stamps with three
natural numbers and then we're going to
define a vector clock so we're going to
create a new type called be clock and
the lid we're going to define it as a
list of the clocks pretty
straightforward and the list is
inductively based on an eel and a con so
if you've ever done like a list and
scheme or closure or you've ever read
the sicp you know this like concept of
like nil and cons and they're here we
say fresh returns the type V clock with
the nil constructor so a list so what
does the increment function look like so
to increment we want to basically
provide an actor and then we want to
provide a vector clock and this is where
things start to get hairy so ignore the
repetition we'll talk about that in a
second but what we want to do is we want
to find the actor in the V clock if it
exists if we do for so you know so this
returns an option types we either get
nun or some with the value and this is
us destructing it so what we basically
do is if it's not there we create a new
one so we create the pair of the actor
and then we call this an it count method
and this an it timestamp method so the
Annette count gives us the initial count
to start at and this is so we don't we
just it's provide a lightweight
abstraction so we can just call to get
the increment count or to get the
initial count because later we have to
replace those functions will talk about
why and then we create the new one we
cons it onto the list in the event that
it's already there we get the existing
one out we increment the counter using
the inker count function we increment
the time stamp using the increment time
function and then we basically just add
it to the list with the one removed so
obviously not written for efficiency but
written for clarity so it's interesting
why we have to do this in it count in a
timestamp and inker count and anchor
times damn right so when the purpose is
then what does it mean to increment
account a timestamp well those are
natural numbers so Anna models piano
numbers so we apply it the successor
function of those numbers
at the new one however in the actual
database we're not going to just
increment the timestamp x 1 right so
what do we have to do there so actually
when we perform the code extraction we
have to provide a bunch of functions
that we replace at extraction time to
say well the increment timestamp
function really just gets the current
time and puts it in so these functions
serve as placeholders that allow us to
reason about things in the proof
assistant but then when we actually go
to do the extraction we have to swap
those functions out with real functions
so this is this Big E this is the
starting point where things start to
break down when we start thinking about
like the real system where a lot of
these things have to happen and like use
real data like from the environment or
from the time of the clock and things
like that so things start to get more
complicated additionally will see that
this function here is this is a finds is
a higher-order function that takes a
function and it takes a clock and it's
applied against the clock and we passing
this function here so we basically say
you're going to give me a clock d
structure and then perform the equality
so see if the numbers match that's how
we know we have the match detector now
this function has to be so what I really
like to do and what we did the initial
version is we say well I just you know
this matter here I can just call this
match or like whatever eat actor equals
or something I can create a function
right for it the problem is this has to
close over actor here so i need to
partially apply it and if i partially
apply it when i go to actually do the
extraction it generates Orlan code that
doesn't work so we have to duplicate
this functional a lot of places so this
is a bug this a bug that I'm working on
fixing but you know it's another place
where we have this impedance mismatch
between the two so if we look at merge
merge is basically the same thing you
see the repetition of the equals here
you see the repetition of the filter
where we remove the actor so this is the
max function and this is the merge
function so what's the merge so to merge
two vector clocks what we're going to do
is fold over the vector clocks use one
as the base and the other one match the
actors and then just perform a pairwise
maximum over the elements it's pretty
straightforward function here is
basically the same thing we perform this
same pattern we got to search through
the list find the actor
extract the actor out and you know find
the actual increment do it for the
second one perform the max function
against the two so you'll see the
application of that here we say you know
get the max of the counters and get the
max of the timestamp merge them and then
just recon solace back together so it's
actually really straightforward but
again you see a lot of repetition so
this is like unfortunately this is like
a very this is not the best way to do
this right so in the in the in the
original crdt work that I was working on
in that one we use like a set or
something where we can perform a find on
it or we use a map or something like
that that's a lot more efficient
obviously the problem is is that code
really fails to extract because it uses
it actually it has to support a ton has
to use an extraction of a ton of
supporting libraries so it has to take
all these core libraries and the proof
assistant and convert them as well
because you have dependencies on all
these core libraries pruning pruning is
interesting as well so prunings a fixed
point so this is just a recursive
function that takes a V clock and then
it takes time stamps so this is actually
a typo this should say time stamp here
but time stamp in that are the same type
so it does work small large young and
old so we'll see why this is problematic
shortly but again you know you have the
same pattern here we have 2d structure
the things just apply lengths you know
and we D structure on the V clock as a
list you have an ill constructor and you
have a consequence structor which I've
left off but it's basically very similar
same with descends as well similar
pattern we do a fold again this one we
actually use it descends helper because
we don't need a closed over one of the
values and we explicitly just pass in so
we pass in to vector clocks and then we
just compute based on the pair's whether
one is a descendant or the other so with
the core or laying code extraction and
the three main problems that we deal
with immediately which are bugs in the
extraction procedure our data
constructors so missing data
constructors to the constructor like
when you construct like an ill type it
just basically doesn't extract it at all
so we have
annually right these and at the time of
extraction we have to insert that code
back in we also deal with incorrectly
qualified calls so because of this
module nesting and everything wants to
be an inter module call sometimes calls
get miss qualified with an additional
namespace so we also need to have a
procedure to go through and prune out
the name spaces that are redundant and
again lack of currying which we briefly
talked about and we'll see an example of
in two slides lack of carrying proves a
problem with any function that you want
to repeat that you want to partially
apply so missing data constructors so
here's the missing data constructor for
fresh that didn't get exported because
it was the middle type so we basically
just manually rights in court Erlang not
very complicated should be pretty
straightforward fresh as the name of the
function it's a verities 0 it's a
function that returns an empty list when
dealing with incorrectly qualified calls
we have a problem where you know see we
see the duplication of V clock here so
the actual file is VV clock lower case
letters BB clock dot V and there's a
module called VV clock inside of it
because it has a bunch of other
supporting stuff in there that I'm not
showing so some of these calls get
incorrectly qualified so here we see
we're calling that a natural number in a
quality function and this is this is the
call sense so this is calling with the
arguments of actor and a which I
obviously have been left off so what we
need to do is go through and prune this
part out here so just cut this out and
leave just the VV clock ble net and that
would be the module function arguments
sir familiar we also deal with functions
with missing era DS as well so here's a
call to a function it's call it wants to
call this descends function this
descends helper no arity on it so
obviously that fails to that does not
actually fail to compile that actually
fails at runtime it does not detect out
at compile time which is unfortunate to
do a bug
oh yeah a lot of this is really
unfortunate to the bug when you actually
have to see it work lack of currying so
here's an example so here's our function
as we defined it in so it's a fine
function that takes an actor and it
returns a function that takes a clock
and so this is the helper for the find
function that basically takes a clock
returns type clock and it matches and
just says hey did the one you know did
it does the actor match is this clock
actually the one I'm looking for or not
so it's just a simple test function
simple predicate and here we see that
the code that it generates in court
Erlang isn't exactly correct because
it's returning a function that takes two
arguments so that doesn't really work
when we attempt to call it with only one
later on so this is why we have to
inline this call everywhere so we'll
talk about the adapter layer so in terms
of the adapter layer there's a bunch of
things that we have to address so first
one is we saw the things oh my goodness
what did I do I don't know how computers
work so the adapter layer the first
thing we have to address is type
conversions right so we've already seen
how we have to model everything is two
poles and these tuples have to be nested
with the Constructors so those types
obviously don't exist in Erlang at all
so we have to provide a conversion
mechanism to go between the two types
also will see that boolean is
problematic right boolean is a is a debt
is a data type with two constructors
true and false and you match on the
constructors that doesn't exactly work
in Erlang right because in Erlang true
is a atom of true and there's one
occurrence at that Adam right same
impulse is obviously the same way so we
have to provide conversion between those
two timestamps so we've modeled them as
piano numbers so we need to actually
provide glue code to convert that to the
actual native datatype for modeling
timestamps and we do that with UNIX
unique style timestamp so the Gregorian
conversion actors as well so actors in
react in the V clock model can be any
term so we need to provide a way to
convert terms that two terms to
natural numbers which is problematic and
we won't get into that but we'll briefly
touch on it and environment variables or
another problem how do we deal with
things that the proof assistant doesn't
know how to get things out of the Erlang
environment doesn't know how to do an
application get em call right again api
normalization is another problem because
some of the functions that have been
exported after that quarterly module
might not necessarily match the calling
the actual calling conventions that we
want envy clock so we actually have to
do a little bit of tweaking to make that
work as well and finally we have these
weird circular dependencies that we have
where I say you know somebody calls into
the verge the vector clock function and
says I want to increment we call int or
verified one and say increment this guy
that has to call back out to get the
timestamp it has to call return back in
to do the timestamp and do the
conversion so that's also interesting
and not necessarily wonderful so with
the type conversions will briefly look
this is obviously the most inefficient
but easiest enough to reason about in
the on the screen way to convert a
natural to piano so basically right you
know if we have zero we pattern match we
have zero we return 0 if not we return s
and we recursively call so obviously
that could be way better if it was a
tail call but whatever same to go back
piano to natural whatever works type
conversions here's the example of
boolean so our equal function in our
vector clock adapter that takes the 2 V
clocks calls into the verified version
and calls the quality on it and then we
match on the atom capital true which is
the true constructor for the boolean
type in the bool bool library and
then descends same thing right so we
have to do that same conversion again in
relation to time stamps so with
timestamps we call calendar date time to
Gregorian seconds erlang universal time
to generate a timestamp and then we have
piano time stamp which basically takes
that timestamp converts it to a piano
number and that's the caller for the
verified version to get the timestamp to
use when it goes to make the vector
clock
so with actors so actors are interesting
so with actors you could define a way to
you know convert some sort of Erlang
term uniquely to a number or hash it to
a number somehow but you need but it
needs to be 28 right so you can't use
something like a shot one because you
have to be able to go back and say hey
the verified version gave me this thing
I need to convert it back so there's a
bunch of ways that you can do this but
it's slow right because those numbers
are not going to be small they're going
to be big especially if you need them to
be unique across all Erlang terms so you
could instead model the data type and
 as a string so what is a string a
string is the empty string so it's just
like a list right it's a basic cons as
an empty string and then you have a
string that takes a string of s key and
an existing string and returns a string
and this is the definition of the base
type of a straining so what's a straight
so what's an ASCII and ascii is a series
of series of bits that compute false or
true so inductive writing the conversion
for this obviously is slow as well it's
not as slow but it's really slow
regardless so it's interesting how you
want to deal with that as well so one
thing that we explored was saying well
maybe we don't prove anything about the
actors at all we just use things that
stand in for it and you know because the
actors are not really important part
here what we want to verify are things
like the pruning function in the merge
function to make sure that they're
always deterministic so here's the prune
function so the proof function in react
takes three arguments it takes a vector
clock a timestamp and it takes bucket
properties so yeah doesn't know
anything about react it definitely
doesn't know anything about bucket
properties I barely know anything about
bucket properties and i work at bash oh
and and you know so we can't pass that
stuff to the prune function so what we
have to do is we have to write the
verified print functions is why I showed
it earlier taking the four timestamps it
takes the vector clock it takes the
small timestamp takes the large takes
young takes the old so it has to take
all the arguments it needs to be it
needs to have all the arguments formal
right and then what we can do is we can
prove that that prune function is always
going to prune correctly
right that it's always going to prune uh
you know younger than the great you know
greater than the whatever it is younger
than the oldest greater than the
youngest greater than the smallest one
of the largest or whatever so we can
ensure all that stuff so we have to
write this wrapper code here right so
this gap property is something that goes
to react gets the bucket property he's
examines the bucket properties pulls out
these atoms out of the bucket properties
then performs the conversion so there's
a bunch of adapter stuff like this well
we didn't think about functions that
explicitly go and talk to the
environment which you actually have to
do in real systems normalizing the API
little stuff like that you see that you
know again for the type conversion on
the increment we have we take the actor
in the V clock and we basically have to
do the piano term conversion stuff on
the actor and we have to make sure that
when we get it back we convert it the
opposite way with the merge function
that this is how it's actually these are
the three types of case clauses that the
the actual one from Erlang has so what
you know we wrote a pair what excuse me
we wrote a pairwise merge which is
easier to prove things about so what we
need to do is apply that to a list and
again you know with the circular
dependencies here's an example of this
is the generated court or lanco and this
is the actual so this is the call this
is the V clocked RL so this is our
adapter and this is the VV clock or so
what we do is you know the increment we
call into the increment but the
increment needs to either generate a new
time stamp or know how to update the
time stamp which we've said that in the
real world we just want to get the
current time so what we do is we have to
in the quarter lang we have to do that
extraction time substitution where we
say really call back into the clock and
get the time stamp and this would
normally be the successor in the actual
extracted version because that's how we
defined it in the original
implementation so what's the evaluation
look like here so the test we passes
which is pretty cool took a lot of work
to get there there's lots of little
weird things we have to do it runs
really slowly really slowly hence the
performance problems right the data
structures are implemented really
inefficiently it'd be nice to use some
of the more advanced data structures but
you know use the faster data structures
of the more compact representation data
structures in the proof assistant you
don't necessarily guarantee that the
extracted code matches that at all you
could use the most efficient
implementation in the proof assistant
and get out like the worst quarter lang
code possible obviously it doesn't know
anything about Erlang so it doesn't know
how to compile code that's relatively
performs well or anything like that and
obviously a lot of the other performance
penalties come from the overhead that's
required from doing all the coercion
between types and all of these
conversions to go from Naturals piano
and you know terms to things and
integers to things and Adams two things
so a lot of that slow and cumbersome and
not necessarily great in a system where
you want things to be super fast like
our database finally there's this idea
of testability right so now I've wrote
this thing and I've formally proven that
my merge function will never you know it
will never merge incorrectly they'll
never be a missing value that's great
right the problem is that i wrote this
whole adapter layer that has to do all
this type conversion and that's not
tested at all and that's where a lot of
the problems were obviously so that's
also an interesting thing obviously
quickcheck helps here that's where I
initially went to to say well can I
quick check all these functions that
basically do all these conversions and
verify things went well and for the most
part you know it does work but it's not
necessarily great so so what are we
thinking about for future work so
obviously fixing all the bugs that we
discovered and manually patched around
to like scripts that would either fix
code or apply things obviously all of
those bugs that we found in the
extraction utility itself I will be
working on fixing and pushing that
forward so people will not have to deal
with that stuff in the future we really
want to explore other applications crd
tease where the initial version
of y CR DTS were the initial version of
this work the G counter i simplified it
to vector clocks because the g counter
and vector clocks were very similar but
people had more were more familiar with
vector clocks and because i had a nice
testing platform that i could actually
run my code inside of react and it would
work so that was nice but what we really
want to do is when we start building
these more more complex to your duties
that are composed and nested and span
multiple keys and that allow us to do
transactions over when we start building
more more complicated data structures we
want a way other than like writing a
quick check test that could possibly be
flawed which we've have real-world
experience with dealing but ultimately
we're not at that point yet as you as
you've seen this is the point of the
talk again the adapter layer is just
terrible for performance and testability
it adds a bunch of additional work it
makes you really start questioning why
you did the additional work in the first
place for something that's not super
complex but you know it's it it's an
interesting experience of realizing what
it takes to encode a language with types
inside of a language that does not have
types or the same type of types haha and
finally the work that I'm exploring now
which i think is more interesting as
saying well rather than say rather than
looking at the ability to generate
Erlang code from the formal
specification why don't we try
generating quick check models so an
alternative approach would be I can
prove these properties about some things
so I can basically take a paper and say
hey there's this lemma and I'm going to
put this thing in here I'm going to
prove these properties about it using
the exact same proof that's in the paper
prove it in here and have that
automatically generate a quick check
model to guide my implementation of the
code as i write it in Erlang in the most
efficient manner as well which seems
like it might be a more practical
approach obviously or quick check gets
quick check gets complicated fast if you
built anything that's sufficiently
involved so so that's interesting for
their work and that's about it thanks
great good do we have any questions yes
I know in what regards that point the
partial application with the car name
know what we're doing is just manually
inlining all those calls in the actual
in the actual code so then it
doesn't actually generate it actually
generates correct it's just as yeah it's
a matter of just the way you write it
and how the extraction process works
it's basically just a bug in the
extraction that doesn't understand how
to properly extract those functions I'm
curious what how what would be to
introduce processes
so so there's a really interesting work
that somebody did in i think it was
china as part of their master's thesis
where they wanted to they were working
on i forget what it was it was some
database or something they were working
on some academic fraud database project
that they wanted that that they were
involved in and they wanted to basically
find a way to prove properties about an
algorithm that was used in the database
and what they did was encoded they
encoded a bunch of properties about how
Erlang message passing works like a very
high level so they formalize it is like
as a series of functions that take like
step relations like a bunch of processes
are basically functions at step two new
state over time so they model it like
that and they have a whole paper that
talks about how to verify the algorithm
I think that's one of the major only
other works about like trying to so
they're doing the inverse right there
trying to encode they're not trying to
write like a very simple data structure
and export it they're trying to take all
the Erlang semantics and put it inside
of the proof assistance so they actually
can reason about it I don't know how far
they got I read part of the paper when I
started doing this work initially but I
did not finish it to be honest so many
other papers hurried I already did
approve this I have no clue I couldn't i
could not speculate what would you prove
about anyway I mean yeah that's an
interesting question right if you want
to prove the eventual consistency model
there's actually an erlang factorytalk
from 2009-2010 John Meredith's yeah so I
mean yeah yeah to do it formulae yeah I
don't know I have no clue yeah I mean
there's a bunch of there's a bunch of
papers on formula proving properties
about eventually consistent systems and
like people like Peter Alvaro and Peter
bailiffs and stuff have worked on
similar stuff but yeah I haven't i I've
no clue offhand right
thanks a lot Chris was great thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>