<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Scaling RabbitMQ at SoundCloud - Sebastian Ohm | Coder Coacher - Coaching Coders</title><meta content="Scaling RabbitMQ at SoundCloud - Sebastian Ohm - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Scaling RabbitMQ at SoundCloud - Sebastian Ohm</b></h2><h5 class="post__date">2013-07-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3DlNS5Ohf6w" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Hey
see you
for attending my talk as it was
mentioned my name is Sebastian I'm going
to talk about scaling rabbitmq at
SoundCloud and I'm gonna tell you a
little bit about what SoundCloud is I
don't know who of you has heard of
SoundCloud well that's a lot of you
that's amazing so you're part of this
figure so for those that have no clue
SoundCloud is an audio platform a few
numbers about our our scale or reach is
that so every minute we receive about 12
hours of audio that is being uploaded to
SoundCloud so 12 hours per minute is
it's the current the current upload
metric and we reach about 200 million
people a month which breaks down to 8%
of the entire Internet I've been told if
you know some cloud you probably know
these things this is this is how we make
the content available so we're entirely
user-generated content and we offer a
plethora of ways that this content is
accessible so there's players on the web
there's embeddable widgets there's
native applications for iOS and Android
and there's more things coming like I
mentioned all of our content is
user-generated so without our users
uploading audio to the platform we would
not have any content all of this
user-generated content needs to be
processed so there's obviously audio
processing for you know aspects of ours
various streaming formats we we support
a wide range of clients and basically
the contract is that our platform is
able to supply the required audio
formats so one of those is mp3 so as a
as a SoundCloud client as an official
client you're going to be able to access
the audio streams
encoded in mp3 other aspects of
processing the user-generated content is
image generation so all of these nice
waveform images they're all pre computed
so upon upload these things are
generated and they're stored and then
when the content is delivered we just
basically read the processed content
that we generated ourselves we started
doing this a few years ago in the advent
of cloud computing and cloud storage and
the way it breaks down is that we store
all of our media and s3 and we scale our
processing of these assets in ec2 and a
few years back we had the big question
of okay so we have this infinitely
scalable storage we have this infinitely
scalable processing resource how do we
coordinate processing and storage and
use those and we picked mqp as we
evaluated a lot of different things we
looked at storm we looked at a huge
variety of you know freely open source
freely available open source projects
and we eventually decided to stick with
AMQP I'm going to briefly who is certify
mqp okay that's also a fair amount so
I'm not going to be telling you any news
to those that have no no clue about mqp
MTP has a very basic handful of useful
primitives so there's messages which
which means they transport information
they're encapsulated state and they are
delivered from A to B messages typically
are delivered to exchanges or publish to
exchanges which you can you know
the mental model is that's the mailbox
at the post office where you like you
put your message in there and then the
post is going to take care of delivering
it to the recipient in order to know who
the recipient is each message has
metadata specifically a routing key
which is basically the recipient address
and then as soon as a message has been
accepted by the broker system and the
routing information is clear it is
routed to a queue which is your local
mailbox so whatever message has been
published with us the intended recipient
it's going to be picked up for you from
a queue which is like your local mailbox
at home simple diagram so producer
publishes to exchange message gets
routed to queue and consumer reads from
queue very very straightforward the key
benefit of this this queueing model is
that the two actors in the system so
producers and consumers are entirely
decoupled so by by sticking a queue in
the middle you you're making sure that
you know if you ever need to scale for
example your consumer pool you can do
that by just adding more consumers and
it's not going to not going to affect
producers in any way this means it's
highly scalable the part of soundcloud
that you know handles the processing of
the user-generated content and media
assets is what we call transcoding
eternally transcoding just means input
format output format it's it's not a
great term because there's a ton of
things going on nowadays it's not just
media transcoding but that's still the
name of that project and the few of you
that can read this slide there's Howard
rails SoundCloud is a ruby ruby shop
or was a ruby shop the main application
everything that you know every single
HTTP request that there was through
SoundCloud these days it's still
terminated by the Ruby application by
the rails application we are working
really hard on making that not so so
we're trying to which we're evolving our
architecture towards a service-oriented
architecture and it's in some parts
unfortunate that we have you know the
history with there would be one time
that we have because we have a lot of
code in Ruby and it all needs to be
ported because you know you can't just
say okay we're now service or
service-oriented without redoing crazy
bits of work that you've already done so
I'm gonna walk you through this is some
Ruby code for people that are unfamiliar
with Ruby it's fairly straightforward to
understand I think and this this
basically is going to be a walk through
of you know the the high-level parts of
the Ruby code base that are concerned
with transcoding so whenever a user
uploads a media file we create a
transcoding model which active record
base signifies that it's something that
is written to a database we're using my
sequel exclusively for better or for
worse and the thing that is going to
happen whenever this this domain model
of transcoding has been created we
publish a message to the media exchange
with the routing key a media was
uploaded and the message is gonna
contain a unique identifier that we can
later use to reference the the asset
that was uploaded we're now leaving the
reservation and we're hopping on to easy
to wear something that we call the
transcoder is running which you know
declares a subscription on the media
exchange binds the media uploaded queue
and basically basically it's the
recipient of the messages that the rails
application publishes so whenever a new
message comes in this it's going to be
dispatched to this do end block there's
going to be headers and there's going to
be the message the message is going to
be processed and then the message is
going to be acknowledged there's more
stuff so when the transcoder has
finished processing like this is this is
the high level implementation of the the
process message so do some work is all
of the all of these secret sauce that
we're doing to transcode audio when the
audio has been transcoded and the assets
have been processed we publish another
message saying okay media exchange media
dot finished containing the UID and the
asset location so this is this is the
response the main responsibility of the
transcode worker is to you know perform
the the transcoding work and generate a
variety of artifacts from images to
media files and put them somewhere on
easy to honest s3 sorry where they can
be addressed by a URI and then that URI
is published those locations are
published and received by the rails
application which then persists persist
those in the database as well we chose
RabbitMQ as our broker implementation
once on Aer Lingus most of you know our
line has this nice property or the
Erlang VMs is a nice property of being
rock stable so we never were really
forced to look into what is going on we
just added this component and had great
performance great operations no issues
basically
and we also didn't have any Erlang
knowledge in the house so you know it
was introduced as a black box and it
remained a black spot black box for a
while a simple diagram of how this looks
our data center where where our physical
machines are located is in Amsterdam
RabbitMQ runs in our data center and
transcoding workers in AWS connect to
the broker for coordination and this is
this is the the first big scaling
challenge that soundcloud mastered and
we mastered this extremely well so we
have it we have an auto scaling worker
pool which means we can basically handle
arbitrary amounts of user uploads we can
quickly and automatically scale the
transcoder pool so you know whenever
there's a spike in an upload volume
we're just adding more workers and you
know in parallel process the workload we
learned that RabbitMQ is a really solid
broker implementation that handles you
know a lot of concurrent connections a
lot of throughput without too many
problems
here's an example of spikes and upload
volume so this is the queue depth of the
media transcode queue plotted over time
there's a few days and periodically
there's going to be you know I'm not
going to say that those are those spikes
are necessarily due to increased volume
and uploads
they may also other be issues going on
like connectivity issues too easy to
Arabic Arabic problem but anyway so the
the pattern that that you can see here
is that you know whenever whenever we
spike and have a lot of transporting
jobs queued the AWS autoscaler is going
again and the backlog is going to be
gone very very quickly so we've
recovered from backlogs of many tens of
thousands of uploads in a matter of a
few hours which is pretty good so in
typical startup fashion you know this
does end it out ended up working really
well so we should be using more of it
because it's it's it just works so well
this there's nothing that could possibly
go wrong so so we started mapping more
functionality onto on to RabbitMQ the
first thing that we did is you know the
the the Ruby runtime has a few
limitations that may seem strange to
people that are mostly doing or land but
the Ruby runtime basically has a no
concurrency so every single web
application server that we run can
handle one request at a time and that's
it so if we want to handle 200 requests
concurrently we're gonna have to run 200
application service and we are running I
think 500 these days yeah so in order to
you know sidestep some of these
limitation and you know the FIR
processing of you know expensive tasks
we introduced you know queuing of slow
actions that would then be handled by a
dedicated worker pool that only did one
thing and this would allow us to you
know satisfy an HTTP request very
quickly and then you know do the actual
work later we also started building a
lot of transcoding like services so
things that work on the asset in s3
among those are some some really fancy
projects that are way over my head like
auto classification auto tagging and
content identification so you know we're
basically applying machine learning
ideas to the user-generated content to
be able to say okay this is gonna be
heavy metal music this is going to be
dubstep the heuristic in this case is is
really simple because 50% of the time
it's going to be dubstep so this is one
of the one of the hairier parts so when
we when we started doing this we had one
broken machine so you know I don't I
don't usually do any testing but when I
do testing I do it in production and
this is kind of what we did we had we
have this this idea of you know name
spacing exchanges and queues and what we
ended up with is you know testing and
development cues on the production
broker which don't think about doing it
we've had so many issues of you know
like even strange issues of people you
know running code on their local machine
I've connected to the VPN and then just
shutting the laptop at the end of the
day and going home and bindings you know
how sticking around so queues would end
up pooling messages and pooling messages
and there would be no consumers for you
know code that was being tested so
eventually the broker runs out of memory
and the Ourang VM you know as as solid
as it is if you keep allocating more
memory at some point it's going to stop
and it's going to stop the world the
biggest the biggest scaling issue
rabbitmq is that we faced his project
that we internally call activities and
what it is is you know feeds a site
activity that are materialized for every
single user so if you signup to
SoundCloud you're gonna have storage and
Cassandra allocated specifically for
your dashboard this is an example of a
dashboard so you log into SoundCloud you
see what happened since the last time
came by it's very similar to something
like that the Facebook activity feed we
have you know new uploads from from
people that you follow
we have repos from from people that you
follow etc the way we made this made
this work is that we basically needed a
mechanism to you know observe changes in
the rails application figure out the
relevant relevant dashboards to write to
and then actually perform the right so a
little more Ruby code because it's fun
Ruby such a quirky magical language we
can't we came up with a very simple idea
of basically externalizing or
advertising state transitions in the
Ruby code base so the title or the the
working name of this of this project is
called model broadcast and what it is is
a few lines of code that you include
into your domain model and then you know
whenever our or M would perform an
action that would mutate the database
this mutation would have as a
side-effect of publication of the of the
state the new state and the database
this has this has a few issues and this
is why like these issues are the reason
why this is a scalability nightmare so
imagine there's there's a hugely popular
soundcloud user with ten million
followers and that person uploads a new
track to soundcloud so the first line of
code along those lines would be executed
there would be a message publish to the
model broadcast exchanges the consumer
would select perform a select statement
against the my sequel database to figure
out you know who should I notify of this
upload and then it would publish one
message for every single dashboard that
would have to
be updated so in this case we're turning
one trigger message into 10 million
event messages that need to you know
eventually also turn into Cassandra
rights so Cassandra is handling a lot of
Rights that's that's crazy
and we basically ended up in a situation
where you know we had a single point of
failure in our architecture and we were
heavily depending on it
there was no fault isolation there was
no resource isolation so whenever you
know Skrillex would upload a new album
of ten tracks and all of his ten million
followers would have to be notified that
would be a 100 million messages that
would just be pushed through all the
systems and then ripple through the
infrastructure with it sometimes not
holding up and this up until maybe a
year ago this was the daily reality
almost at some point in the during the
day when you know traffic traffic was
high there was a lot of site activity
the broker would start to stutter and
start to apply back pressure on
producers who by virtue of their not
optimal
MVP client implementations would just
buckle and crash so the broker would die
and the site was down yeah it didn't
help that song code is like we have we
have an interesting popularity
distribution I would say we're you know
mainly known in Europe but if the US
wakes up our wires start to glow because
it overlaps you know us waking up and
Europe you know early afternoon late
afternoon this would mean that would be
our peak time and we would have
incredibly bursty loads that we would
just not be able to handle
every once in a while things would just
fall over here's a fun graph I hope you
never see something like this this is
memory allocation for you know one of
the one of the problematic brokers and
what you can see is that it just
increases every single time and then
every one of those drops that's a
machine we start so that that correlates
to uptime in it and I mean it's it's
impressive
uptime it's like a few months at a time
and then it would be would be dead so I
mean this is this is but still this is
not there was not optimal it's it's you
know very impressive that it worked as
well but you don't want to be in this
position so of course what do we do we
had we had some funding we were able to
you know buy buy additional machines so
what we did in our capacity planning is
we said okay we're going to buy another
broker machine and we're gonna you know
partition the workload so have the old
broker handle side traffic and
transcoding and handle the new broker
have the new broker handle activity
feeds we started using more queues
because we were you know gaining
knowledge about how things work
internally so more processes aka more
queues means things work a little
smoother and we had some breathing room
but not for long because you know we
still had single brokers no higher
availability so whenever there was
issues and there were a lot of issues
due to our traffic pattern we would
still be down so eventually we
discovered okay this cannot just kind of
go on like this we need to come up with
a scheme of you know higher availability
and if that is gonna end up being
something that scales that's that's
great
so what we did is really simple we
introduced you know instead of having
physical machines be the broker we said
okay we're gonna have multiple multiple
machines form a cluster and this is
going to be one logical unit and as an
application your configuration would
always point at one of these clusters
you would publish to one and you would
subscribe from all brokers in that
cluster a little diagram to you know
explain this a little more we would have
a very very straightforward setup of you
know putting a load balancer in front of
a rabbitmq cluster so the load Paulo
load balancer would be something like IP
vs and what I would do is when a worker
process would want to establish a
connection for publishing messages it
would connect to the load balancer and
if it wanted to consume messages that
have been published to this distal adji
it would establish direct connections to
all of the backends and this has this
has the benefit of you know when one of
one of the one of the backends goes down
you're still able you're still in a
position where you're able to maintain
service there was only there was only
really a few changes that we had to
force upon our clients so the big change
is you know instead of having one
connection to one broker that you would
use to publish messages and consume
messages you would be connecting to one
load-balanced broker for publishing and
you would connect to you know an
backends for consumption
whenever one of these TCP connections
will go away I was upon you to reconnect
periodically so with you know some
back-off algorithm it would be the onus
would be on you to reconnect to the
faulty machine we also discovered that
using MVP heartbeats would make this a
little smoother because you know and
there in the in the case of a client
crashing the broker would know faster
that the client had gone away we've
we've had some really weird experiences
with you know consumers being listed as
active that have that had crashed a week
ago this is this is the activities
broker at apology it's currently two two
machines and this is you know a plot of
the publish rate over time so you can
you can see our diurnal rhythm so every
every peak would be afternoon off a day
this is a weekend also interesting maybe
and you can you can see that we're
handling you know on average at peak
time something between 20k and 30k
messages a second those are all
persistent messages and I do a little
arrow into this into this plot because
we actually took down one of the
machines at that time and performed
maintenance we did a kernel update
because there was a vulnerability
operations people told us to upgrade so
this is actually you know full-on
operation with a maintenance window and
there's no impact on throughput so the
benefits of this approach it's it's
really simple all logic is and clients
we have achieved availability something
that was you know the motive
factor for investigating these options
but we've also discovered that we've you
know kind of by accident added
scalability so by virtue of publishing
connections being round-robin over all
existing backends if at some point one
of the backends is at the limit when it
comes to publication rates we can just
add another back-end and have you know
messages or message volume be allocated
by a third per per back end instead of
you know half in half we've actually
pulled this off on a variety of
platforms SoundCloud is a very polyglot
company these days so obviously there's
Ruby there's the JVM clients so closure
and Scala are things that we use heavily
I'm personally proud that this is in
here because that's all me and we have a
big big momentum of goal right now so
this does a lot of we've actually
developed an AMQP client in the house
that is available for the go programming
language there's going to be a lot more
work of course I mean we were in a way
in a position where we have breathing
room we have solved our immediate issues
we're available
we're scalable but you know that the
work never stops so the position that
we're in right now is that we're running
basically two clusters one for the
activity feeds and one for everything
else which is obviously a bad idea when
it comes to fault isolation so you know
if the activity's topology you know
should have catastrophic failure and
would be down that's fine but if the
other topology would go down there would
be so many services that are affected
that it's not funny
so we need to you know instead of one of
the things we did is you know more more
funding bigger hardware we did not make
the mistake of you know
the broker machine upgrades again so we
actually have super beefy machines with
24 gig of ram and many many cores
running our rabbitmq brokers right now
but that's not how you want to scale
these critical components so instead of
having really beefy hardware we want to
use commodity hardware so in our case
that would be what we consider
application class machines so you know
just not as much ram not as much CPU the
other big thing is that you know with we
still have some artifacts of the
exchange and queue namespacing around so
there's still like every single queue is
still called production life something
and that is just you know a relic of how
we started doing this stuff and using
you know active record side effects as
your integration api is a terrible idea
as well so we actually want to or what
we are doing right now is we're moving
towards an API that is much stricter
much more well-defined and you know
arbitrary my sequel column names which
has the the working title semantics
events and this is actually going to be
a very key component in our service
orientation efforts so we're going to be
using the semantics event system to
advertise state changes in all of our
applications and use MVP as something of
an overlay Network - you know shuffle
state from things that are in charge of
that state to things that are interested
in changes of that state but are not in
charge the big the big thing that we're
working on on in parallel is discovery
so right now what we're doing is
manually assigning physical host names
to applications so we're saying this is
your broker pair connect to those three
brokers and in the future we want to
have there's a little more dynamic so we
want to be able to you know when our
configuration management brings up a
broker instance we wanted to register in
a central registry and we want
applications to you know switch over to
new resources when that is necessary so
instead of you know hard hard coding
configuration values we want to have
configuration dynamic and that's it
any questions yes
yeah
right so so abstract AMQP we thought
about it and it's actually something
that is in the back of my head for you
know things where we're currently seeing
problems with a MTPs a transport so you
know things that run in a physical
location that is far away from our data
center we have historically had issues
with you know long lived connections
which is you know AMQP a TCP connection
that tunnels a MTP is a long lived
connection so we would occasionally see
those connections go away and you know
some abstraction that you know would you
know do maybe TCP keepalive or HTTP keep
alive but much much shorter connection
times is something that we thought about
we haven't we haven't fully done it and
the service discovery component is
actually going to be something like you
only like as an application you only
have to advertise this is my that's my
name like this is my application name
and the response is going to be okay
here's your broker configuration and
that can be one broker that can be five
that can be ten that is entirely not up
to the to the application to the side
that's currently how it is because we
don't have the discovery mechanism
yes there's so we have a prototype and
it's not gonna survive prototype stage
I'm gonna have go out on a limb there's
a few like like I mentioned go has a lot
of momentum at the company right now and
there's a Paxos implementation and go
Doozer deep which currently functions as
the storage as a distributed storage of
the discovery state Doozer D has this
unfortunate history of you know it was
built by Heroku and it was then
abandoned so you know it's it has some
issues and we haven't we haven't solved
those issues so we're probably gonna you
know investigate other other things yeah
yeah yeah so one of the big drawbacks of
this system is that you know if you have
if you have this cluster and you're not
using you know RabbitMQ specifics like
my read queues in the in the case of a
catastrophic failure so that is
something where you know you lose
storage so your hard disk is not
recoverable we're gonna be losing
messages in that case and the other
thing is you know even in you know a
regular outage like a maintenance outage
what is going to happen when the broker
comes back up there's going to be
messages stored on there that are going
to be you know way out of order in terms
of you know temporalities or we're not
losing those messages but they're going
to be arriving to two days or you know
however long the maintenance takes after
the fact and that is actually something
that's very very easy to combat or to
minimize at least which is you should be
empty and they should be empty anyways
because otherwise
yeah
we did we actually looked at a lot of
things and one of one of the I mean it's
it's it's stupid but you know it's it's
always this periodical thing of what is
what is technology that you want to
invest in and what isn't and the JVM is
one of the things that you know a few
years ago deterred everyone from you
know I don't want to be on the on the
JVM I'm gonna use everything else and
this is now this is now changing a lot
of people that know way more about you
know distributed systems and work queues
than we have looked at Kafka and we have
decided that we're gonna gonna stick to
RabbitMQ yeah
that's actually so the organization of
you know SoundCloud engineering is
application teams so what used to be the
monolithic rails application is now
actually four five teams that are you
know reimplemented bits of that
functionality and most of our you know
new web application layer is written in
closure all right thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>