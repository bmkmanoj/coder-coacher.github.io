<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Cutting Edge Chatops with Elixir &amp; Erlang - Kevin Smith | Coder Coacher - Coaching Coders</title><meta content="Cutting Edge Chatops with Elixir &amp; Erlang - Kevin Smith - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Cutting Edge Chatops with Elixir &amp; Erlang - Kevin Smith</b></h2><h5 class="post__date">2017-05-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/iq-WxnWiqCw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so this is a little different talk
from what I normally give normally I try
to be fairly technical this is going to
be more of an experience report of what
it was like it at a company I co-founded
operable we built a product that was
chat office automation and we built it
entirely pretty much on top of the
Erlang VM using a lick sir in a little
smattering of go so I'm just going to
share like some of the experiences we
had building this in kind of what it was
like why we chose Erlang an elixir at
originally planned on also having like a
little demo but the network gods are not
kind of conferences so that's not going
to be possible however I do have part of
a canned screencast so we can at least
see what the stuff looks like in action
so a little bit about myself I've been
using Erlang since around 2008 and
elixir since 2015 somewhat controversial
statement I guess is I really really
like beam the VM Erlang is okay but I
really felt like elixir is the language
that the beam deserves in a lot of ways
it's so like I said I've been doing
Erlang for a long time I've done Erlang
training I've at one point I worked at
chef where we build a big engineering
team around Erlang and so I had to level
up about 36 devs to get them used to
writing Erlang and that's all doable
elixir is just that much easier because
it looks a lot more like modern
languages that folks have more
experience with like Python or Ruby so
I'll get that out of the way and I've
worked at a number of places where I
have used Erlang mostly so Engine Yard
back in the day Heroku chef and more
recently at operable so how many people
here know what chat Ops is a few people
alright so I'm going to define it a
little bit in the short term a great way
to think about chat ops is that you're
performing operational tasks in chat so
if it work you used to
something like slack or hit chat to
communicate with the rest of your team
chat offs gives you the ability to
perform a lot of like your day-to-day
tasks you might do like say managing CI
or CD builds checking monitoring metrics
provisioning new environments paging
people when goes sideways just to be
brutally honest um these are all things
you can do with chat ons longer-term I
think the vision is make chat act like a
shared command line and really the way
you want to think about it is a
multi-user collaborative shell and
that's where we were trying to go so
this is a book that came out I believe
last fall it's written by a guy named
Jason han who works at Victor ops it's a
really great introduction and kind of
summary of the current state of the
world in chat ops so if you're at all
interested in this kind of thing and
want to learn more this is a great place
to start and it'll give you a lot of
starting context another good place to
look on YouTube
Jessie Nuland who is I believe the ops
lead at github did a talk back in 2013
about chat ops because github is kind of
what really started evangelizing and
building a lot of interest in chat ops
and so that's that's worth a view as
well so chat ups architecture today
let's talk about that a little bit
so typically hello
is it lanyard off yeah one moment please
there maybe we'll keep the annoying
thumbs down to a minimum
okay so chat offs architecture today
mother how's that is that bit as it me
yeah alright alright so chat ops
architecture today as it stands so
really popular chat ops BOTS for lack of
a better term the most popular one I
think most people have heard of is Hugh
bot there's another one called leta Hugh
BOTS written entirely in CoffeeScript so
it runs on nodejs
Lita is written in I believe Ruby they
both have basically the same
architecture so you have this chat
interface that's responsible for talking
to whichever your your chat provider is
it's got some core bot logic that's
responsible for things like noticing
when a user types of command Wow
noticing when a user types of command
and doing something with it and then
it's got these other two components down
here that are responsible for doing
things like loading scripts when you add
a new command to this system and
actually executing the command the
drawback to this approach is that this
is all in a single OS process and so
what we found was while this is great
for smaller teams at smaller companies
where it's maybe like a total of six six
people on a team all working on one
thing if you're if you need any kind of
security guarantees about the system the
fact that you're loading basically
arbitrary code into the same process
that's responsible for enforcing say
like system invariance that's kind of
problematic and
so well let's see yeah and so on one
thing you see a lot especially with Hugh
bot is folks have over time kind of
invented and reinvented different
firewall mechanisms for trying to
control lot like these scripts have
access to and how you access you know
adding concept of like apples access
control list to control who can execute
what script again the problem with all
this is is that since all this is
running in the same process and the same
like JavaScript virtual machine these
scripts can just do an end run around
the code so not great so we looked at
this and said hmm can this be improved
upon and we said well what are the real
requirements so it needs to be reliable
because this is with any luck going to
be a critical path tool for a team
you're asking folks to base their whole
workflow around you know your your chat
op solution whatever it is so even if
like you as an individual want to bring
a cubed or leta or what I'm talking
about here are our platform called cog
into your team you know one thing you
have to realize is what you're really
asking folks to do is start relying on
this so like when stuff breaks and
you've got to get up at 2 a.m. and fix
it you know if chat ops is how you're
doing things then the bot needs to be
available in work a lot of the time
these bots are going to have access to
sensitive information and systems and
this is especially true for companies
that are operating where they have to
deal with things like credit card
regulations about you know who can touch
what data and what kind of audit logs
you have to maintain or healthcare
companies that have to deal with like
HIPAA requirements so that's reliable
reliability the bots also needs to be
extensible because everyone every team
every company has their own unique
itches they want to scratch and the bot
is only as good as your
ability to extend it and so you might be
wondering alright so you have a bot
that's written in Erlang and elixir and
you're going to ask folks to extend it
what were you thinking but I'll get to
that we didn't ask them to write a lexer
although they could if you want to make
it really easy to scratch new itches you
need to realize that even though they're
like in Hue BOTS case there is an
absolute ton of scripts already
available and they're easy to install
and use that generally they're always
going to need to be customized
because what's right for one person's
environment is going to be right for for
your environment necessarily even if
you're like trying to administer you're
like you need to talk to graphite and
pull some graphs and put them in chat
the way you name things and graphite
isn't going to be the same as another
company so on so on there's also some
challenges here I mentioned security
you've got you know again the system
sensitive information and systems access
I larger teams are also going to want
some sort of audit these are things that
the current crop of bots don't really do
it all they just kind of punt on this
whole thing so one example that came up
at a conference I was at I saw someone
from github presenting about chat offs
and some in the audience said so does
this mean that anyone that that can get
into the chat room can talk to the bot
well yeah
so anyone that can log into slack for
example could reconfigure your border
routers you know problem you know why
would you not want that
you're also functioning most of the time
in a dynamic cloudy environment so lots
and lots of lots and lots of workloads
run on AWS and more and more people are
running on things like cloud formation
and kubernetes and meso sphere and so
you need to be able to play well in
those kinds of environments and then
finally and this kind of gets into the
extensibility thing third party API
integrations on you need to be able to
talk to stuff like data dog
and graph I and pager Duty and Status
page I oh I mean there's just a plethora
of api's and it seems like you know for
there's so many api's and these
companies will ship like client
libraries but they're written in any
number of languages right so if you say
I'm going to write my bot in Ruby you
almost guarantee that something you
really want to use is only going to have
like a Python client at some point that
happens and so how do you deal with that
so we came after we kind of did this
little design exercise we said well can
we do better and we said well what if we
combine a robust highly concurrent VM
not to name any names with an accessible
functional programming language not the
name any names and this is what we came
up with so this was our cute little
mascot cog he was written in a lick sir
and he was responsible for running all
of the core logic of the bot so
enforcing access control and noticing
like when you type the command that was
all done here
these guys were separate processes
potentially even running on other
machines and all they were responsible
for was executing commands this was all
really simple to implement because
Erlang has baked in right into the core
of the language in the VM this whole
notion of message passing and
distribution so this was a really
natural way for us to to model the
system what's nice too about this is you
notice that since these guys are out
board processes potentially not even
running on the same machine on you don't
you get away from the security problems
you had initially with the other design
where you're loading arbitrary code into
the core of your application so for
commands that need to like say access
your customer database and production
knowing that you know any command that
you install here can't really subvert
your core logic you know that
that's a nice reassurance to have the
other great thing about this approach is
that you can have separate ones of these
relay processes running that have access
to a limited subset of your environment
so you never get into the situation
where this guy has complete access to
everything so in a worse case you know
nobody ever wants this but if you have a
breach here whatever they're able to
compromise here doesn't necessarily mean
that they can leapfrog somewhere else so
going back over the requirements
reliable where the actor shared-nothing
model by default this kind of allows us
to be very concurrent we were able to
model the commands coming in to the bot
as each got their own Erlang process
kind of very similar to how you might
build a web app so you know it's very
natural in when you're doing web
programming with elixir or Erlang each
request is its own process same thing
here
beam VM I need to say know more about
that extensible so elixir and docker for
the win and if I could do a demo I would
get in more into how we integrate a
docker into our stuff but needless to
say what we did here is we took a page
from Heroku x' playbook and rather than
requiring that all the commands be
written in elixir we allowed them to be
written in any language you wanted and
the way that we executed them was to run
them as a docker image so in a container
and set a bunch of environment variables
and then just tell the command to go so
we set environment variables it said
like here's or who's a current user is
here's our arguments you were called
with now run so it's basically kind of
shelling out into docker every time we
ran a command and this allowed us to say
you know write to come in and whatever
language you want we really
care we just need it to be packaged as a
docker image so I think I've already
talked about that we implemented apples
which I won't really get into today
because I'm not up here to show about
what we built on but we used leaks and
yet to build our own kind of custom
Apple language really decent experience
with that and dynamic environment we
really embrace cloudy tools so we
shipped out of the box as docker images
and we built everything so they could be
run as cloud from in a cloud formation
template and as I was saying earlier
with the chat commands we also kind of
wound up using docker as a package
manager which sounds kind of weird when
I say it out loud but it worked really
really well and as I've said like other
talks I've done doctors real innovation
is not like containers what they're real
innovation is is the image and the whole
idea that the docker image is basically
an executable package that comes like
all together with everything it needs so
if you're distributing software this is
a really great model to use and we got
to the point where really the only thing
we shipped with sets of images we didn't
build like Erlang releases and shipped
those as Deb's and rpms and whatnot we
just built images and shipped those
because that's what our users wanted so
third-party integrations I think I
already touched on this yep so before I
kind of show what this looked like in
action
I want to if you'll indulge me a small
mini rant syntax matters and it matters
a lot so this is something I ripped from
there was a group at HP Enterprise I
think they were spun out that was really
pushing chat ops at one point on and
this is how they built their commands
this is fairly indicative right now of
the current state of chat ops I kind of
call this pidgin English I guess it's
nice to read it seems like that would be
held to type because in chat you
don't have autocomplete anywhere so yeah
if you wanted to whatever this thing
does if you wanted to run this BPM
process of whatever whatever whatever
you've got to type in all of this
so imagine this is like something
related to what you do every day and
your phone is going off at 2:00 a.m. and
you're going to type something like this
in like this just seems like a nightmare
if only this was a solved problem and it
makes me a little sad that more people
don't think of this I'm so UNIX piping
command since 1973 I don't know why this
hasn't kind of become more of a thing if
you look at like one of these
indications here's the stuff you really
care about like you're invoking some BPM
process for this app from some other
thing bla bla bla bla bla you've got
like a host and a location and an
instance right so there's like a total
of 21 words here and like well over half
of them are just connect your words that
don't really add much they make it nice
to read kind of like English so if
instead you make it look a little bit
more like a UNIX command and so you see
there's this pipe operator here so I'm
taking the output of one command and
piping it in to the next like you would
in a regular command line and I'm using
arguments and options I don't know to me
and maybe I'm kind of old-school and
crusty this to me seems a little bit
more readable and more like what I would
expect so this is shorter on less words
no connector words and you know maybe
this is a little hyperbolic but I don't
know this to me seems to be a lot more
concise and understandable kind of gets
right to the point and this is what our
commands look like so before I move on
from this any questions about what I've
talked about so far okay
so as part of building these pipelines
we went through several iterations of
the code behind this we started off with
Jin FSM how many people here have used
Jim FSM how many people like using
genetic assume or oh one guy we had a
Jin FSM that started at something like
300 lines of code and by the time we
were like yeah we really need to
refactor this sucker we're up to almost
3000 lines it got really hairy really
quickly and so what we wound up using
was Jin stage and I know there's already
been another talk on it so I'm not going
to belabor the point too much I will
talk a little bit about it
Jin stage is awesome if you're building
something that looks like a processing
pipeline with like discrete stages and
you need to wire those stages together
this is it's really really nice
so what is Jin stage so experimental OTP
behavior for building pipelines and
we'll take a look at it in a second um
it's got notion of producers and
consumers subscribers it has multiple
flow control strategies which is really
nice so you can do things like streaming
between two stages or you can do batch
and it is streaming by default which I
don't know if anyone's ever tried to
implement this kind of thing on their
own like I've built this kind of code a
couple of times and it's always really
fiddly to get right because handling
flow control tends to get a little racy
at times and it's hard to coordinate so
the fact that we have a behavior like
this it does all that for you and does
it well really nice so applying gen
stage to command pipelines
while this stage as I try not to step on
so you've got three commands here foo
bar and Baz and I want a pipe output
from one to the other to the final one
each one of these commands can generate
arbitrary amount of output so the way we
modeled it was to say okay here's here's
what the user typed in and then we would
add these implied nodes begin and end
begin was responsible for initiating the
pipeline and n was responsible for
gathering everything up and sending it
back to the user so applying templates
to the output and making it look nice
doing any kind of error reporting that
kind of thing
so in gen stage terminology beginning in
were pure producers and consumers and
everything in the middle was a producer
and a consumer and we were able to use
Jen stages flow control strategies to
handle getting the data from one stage
to another without having to write any
code on our part so when every time a
user typed in one of these pipelines we
would have a whole chain of Jen stage
processes stitched together and
executing you know all supervise it was
in fact it's really nice so let me
conclude I'd actually built more time in
to do a demo but like I said the Oh are
you kidding me and network gods really
don't like me hold on one second OOP
haha here we go so this is the
screencast we did to demonstrate what it
was like to to work with one of these
commands and we're not going to sit here
and go through the whole thing because
that would just be like violating the
Geneva Conventions a little bit but I'll
highlight a few things here so like a
lot of bots you know this is how you get
its attention you prefix any command you
want to run with the with a bang and so
you can type like help CFN and you get
all this nice output about the command
so really similar to like your unix
command experience you know with this
being more like a man page let's skip
forward here a little bit
okay so the command had this notion of
having stacks so if you didn't have any
stacks yet created you could build one
from templates you can list all the
templates and yeah here we go and so
then you can use the stat create command
- - once you know the name of the stack
and and the the parameters you want to
pass to your template you can create it
there which I think will happen here in
just a moment yep so it gets created and
tells you what all the parameters were
and then hopefully here we show yeah so
this is piped through we had a
templating engine that would generate
all these nice templates regardless of
what chat provider you were using so we
try to make the output look the same
across everything
um but yeah so that's kind of what it
looked like in practice and that's it
any questions
cool thank you oh yeah
oh so we were founded in 2015 we got a
nice seed round and we built all this
out we had several companies using our
stuff so we had a team at Oracle and we
had an ops team at Kickstarter using our
stuff and we had maybe around I'd say
somewhere between 50 and 100 installs in
our in our open source community and so
we were going for our next round of
funding after a couple years of working
on this and just weren't able to quite
close the deal so all of the stuff I've
showed you is open source we did all of
our work as Apache 2 license code and
this is all available up on github
but unfortunately we were unable to get
more funding so we wound up having to
wind down actually at the beginning of
the month so that's kind of the current
state thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>