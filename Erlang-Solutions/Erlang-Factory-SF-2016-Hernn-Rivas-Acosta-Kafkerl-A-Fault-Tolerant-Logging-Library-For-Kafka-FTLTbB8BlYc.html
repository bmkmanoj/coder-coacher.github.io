<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory SF 2016 - Hernán Rivas Acosta - Kafkerl: A Fault Tolerant Logging Library For Kafka | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory SF 2016 - Hernán Rivas Acosta - Kafkerl: A Fault Tolerant Logging Library For Kafka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Erlang Factory SF 2016 - Hernán Rivas Acosta - Kafkerl: A Fault Tolerant Logging Library For Kafka</b></h2><h5 class="post__date">2016-03-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FTLTbB8BlYc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Sapna Luis Acosta I i work at
anaka part of maryland solutions and i
started out as a game developer like a
few years ago and i discovered airline
to make a multiplayer server for a game
and since then i loved it and it was
really really lucky to get into Enoch
and be able to work an airline full-time
so today's talk is about making a
reliable reporting system with Gasca but
it's also about how did I actually
design goth girl and what lessons we can
take from that particularly on how to
build a library more than anything else
so first of all we started out by
choosing like what were the right tools
for the shop and this this was a system
we will for tiger text messaging
application that has quite a few
requirements in particular its HEPA the
key part requirements like the secrecy
and the audits for medical applications
so we not only have like a lot of
services and different processes
generating reports all the time we need
to make sure those messages are not lost
and also we have an unknown number of
simultaneous systems reading from this
from the feet of blogs not to generate
like an error log or to see what went
wrong but to see what exactly happened
so for example this person shined and
now it's talking to this other person
and it's sending these messages because
all this is part of the rules that HEPA
imposes on us also having for example
the order is preferred this is because
we are trying to make a lot of what
happened to make enough for any audits
that may be required later on by the
hospital and we're also using it for the
statistics so losing things in general
is a better idea and we looked at the
options and we found quite a few
of course we picked kefka but like
RabbitMQ sore great choice erm q flume
they're all great choices but we chose
Kafka and for a few reasons so the main
focus of goth guy is high throughput and
low latency and this was very appealing
to us because there were those were two
things we were going to have high
throughput because we're generating fume
a few blogs for every message that is
sent on this messaging application
things like Skype for doctors and it was
also used by linkedin ueber Netflix
among others like those are the most
famous ones so we knew that if the if it
candles whatever volume lincoln in can
throw at it then we are just safe we're
we're good to go also there redundancies
are great because again we are forced to
have a bunch of redundancies and a data
engineering team comes from LinkedIn so
you know it wasn't it was an obvious
choice for us however there are things
that make Africa special like their
things are this kind of a specific to
CAF guitar word really good for us the
distributed architecture okay not
exclusive to Kafka but it did the way it
works is pretty interesting using world
topic and partitions a topic is like a
feed of records when you when you send a
log you just say this belongs to a topic
and then you go and now the process goes
and reads from a single topic and gets
the list of messages partitions are
usually not used semantically but you
can basically are like subtopics inside
a topic you have multiple partitions and
you can write to any partition you give
it the meaning you want it doesn't have
any of the box and the and it also has a
replication factor that is highly tied
to the topic so if you have a
replication factor of three you know
that every topic partition pair is going
to be at least actually exactly on but
technically at least three different
brokers three different computers
if at least one of those is alive then
you can consume from it so you're not
losing information if you use a high
replication factor you can be pretty
garden like you can offer to guarantee
that you will not lose anything and also
the performance another cool thing about
having this distributed is that there
are a bunch of brokers think of a broker
just like a server any normal server on
running Kafka and each one of those is
the leader of certain partition and
topics the leader means that if you want
to consume that then you have to go to
it so the performance mean it comes from
the fact that is paralyzed do you it's
well distributed among the different the
different notes so we had to implement
we had to use this on our side it has a
binary protocol and we needed a library
and they work or a few options we we
Google a bit but like keep in mind our
focus was to support the features that
made us choose Kafka that is the way it
handles the throughput by using multiple
brokers for example so it had to be well
distributed in the library too and we
found multiple choices well this is
basically a summary of what we were
looking for but I mentioned it and
there's the libraries that we found were
what first of all I found this from
booga booga is a gaming company I know
them from back in the day when I did
video games they they were the company I
cited when I wanted to use our line for
a server so great company you know them
the protocol is tested but it has a
problem where it buffers the entire
response basically when you request the
logs to Kafka you get you don't get a
huge binder you get like multiple small
ones and we're Kafka decides to cut them
it's up to Kafka and it's unpredictable
and there is nothing you can do about it
one thing that you can do Jeff Garlin
from Woollett asset is
you buffer the entire response and then
parse it and it's easy to parse that way
however that means that if you're
getting a bunch of logs it's gonna chew
up a big chunk of ram and you usually
can't afford that on on this on these on
your life systems and also it doesn't
offer support for the latest version of
Kafka 0.8 so that was you know pretty
much out the next one I found was
brought by klarna Broadus a nice name
it's the east cafcass biographer the
protocol is again tested it's very well
documented but it has two problems first
of all it does the same thing I
mentioned before of buffering the entire
response and then it C realizes every
message through Russian server and what
I mean by this is that when you send a
message to Kafka there is I don't
remember name but like Brad L it is it
has a gin server and every message goes
through it and it gets into the message
queue and then it builds the binaries
and send some to Kafka this means that
you have a single process that's
basically not exactly a single point of
failure I mean it could be if that
process crashes and it has a large
message queue that's all gone forever
but the other problem is that it's a
bottleneck it's a performance bottleneck
that you have all this fantastic
distributed architecture and your
bottlenecking on your application and
finally we found a calf which has
excellent documentation the other ones
have good documentation this is
excellent it's being maintained the code
is really easy to read it uses an FSM to
handle the different states of when it's
connected to calf car and when it's
expecting responses from Kafka that's a
really clever solution to the problem
super easy to read because those who has
like comments everywhere it's a
fantastic quote but it has the same
issue socially for like the bottle
necking not Russian service fruition fsm
and it has no consumer which was a
bummer because we could have you know
started adding
small details but we found out it was
may be easier to just you know go for it
ourselves so well we start building calf
girl and it has a bunch of things like
it I try to do basically everything that
was implemented in Kafka so trying to
use better bandwidth Kafka allows you to
bundle a bunch of messages together we
do that we cash the messages it's
concurrent I will talk about this later
we don't lose the messages we use
backups before like before sending them
we back them up and when we get a
confirmation that they were delivered
then that's when we can safely discard
that that backup it I also had a I also
had the idea of making a simple API
using the same words that the kafka
documentation has but what I mean by
this is like the concept of consumers
producers and all that stuff that's the
names i have for the the API that means
that you should probably if you know
Kafka you probably already know how to
use this library and how how exactly did
I implemented things well we avoided
serialization by using ets tables i'll
have a few slides explaining this more
deaf but basically there are a bunch of
ets tables where everyone that wants to
log something rights to and this gives
us a smashing currency ask africa
because we have an ets table for each
topic and partition and since Kafka uses
the topic and partitions to provide
concurrency we are doing same thing and
we have the same amount of concurrency
that Kafka has so for example if you say
ok GAF case being overloaded we need
more like we need to increase the amount
of partitions in topics then catechol
will reflect this instantly because it
will respond more ets table so you will
have the same solution to the same
problem on both sides also the message
parsing well I handled partial responses
basically by say
leaving the part of the binary couldn't
parse i parse until I can't until fails
and then I save the extra binary and
when the next binary from TCP comes I
just put in the start and try to parse
it again and again until until I finally
have the like the last answer there's
full turbulence will built-in basically
using the ETS as I mentioned before
Syrian confirmation and also the ETS all
of them are supervised separately like
that's a very you know basic scheme of
how it works separately so I separate
the messages from all the processes
meaning that if a process goes down
there is nothing that goes down with it
like the messages are not stored there
so we're we don't care about the message
queues of those processes also if the
80s becomes too big because that could
happen for example if we're trying to
send to cough and cough gets down then
our ETS will start to you know what for
the messages that didn't get
confirmation yet so if that gets too big
we dump them all to disk that yes that
causes us to disorder but we're talking
about like a service oddish so well
nothing we can do about it also this
architecture allows us to handle the
broker changes Kafka can do that
whenever it wants for example if broker
falls down it will redistribute the load
or startup more instances all that is
handled automatically becomes again the
process are connected through 20 speed
to Kafka don't really matter if I remove
them all I haven't lost any messages so
there's like no special handling that
needs to do I just took them all down
put them all up and finally I don't let
it crash this is this is like a next
thing i know it's usually a good idea
and in fact there are few places in
graphical world yeah let any crashes a
smart thing for example if a broker
connection fall fails i don't care but
what i mean by this is don't let it
crush unless you have to and if you have
to you need to have a way to you know
restore the whole thing so for example a
broker falls yes the process may crash
so as far as I know they don't I haven't
seen a single log that they say they
don't because all the different
responses I try to handle and I kill
them by hand if I think it's good idea
again we need to make sure we are not
losing messages so any step we can take
to minimize that risk is a good thing
and and how and how do the ETS work and
how they provide concurrency basically
how I'm using this to do what I
mentioned before making cafcass
architecture on the other side so first
of all we have like cough girl the
library and mr. gafcon the right the
writer and your request them at the data
and the metadata has a bunch of
information but mostly we care about the
how many topics we have including the
names of the topics and stuff and how
many brokers we have also there is some
mapping but it I mean it it's like
implied there is a mapping there which
brokers handle which partitions and
topics so first of all what we do we
create one ets table for each topic
partition in this case we have three
because that's what fits in the slides
but we have like a field Dawson's on on
the production server and we also create
a broker connection that's a process for
each broker and Kafka that just has a
shin TCP connection and that's a very
small pieces of logic regarding one to
one to talk to Kafka so we'd receive a
message from any process it goes to the
right EDS and it's written there and the
cool thing about this is that the
process creating log the message that's
the one that writes with DTS so
everything to the right of the orange
boxes that's untouched that doesn't have
any performance impact no matter how
many messages you receive they all get
router at the same time ETS allows for
concurrent rights internally and I also
use library from Shay Nelson yeah you're
over there so i use concurrent
controls that simplifies a bit because
the API for ets is well could could use
some love and well he did it and it's
way better that way but again the most
important thing is this is extremely
concurrent all the messages are routed
by the process generating them so the
concurrency is equal to the to the
amount of topics or DTS tables that
kafka has again the same strengths and
perhaps the same weaknesses so what
happens later is that the broker
connections themselves choose to send
information to Kafka how they do this
well there are two ways either time they
try to send a message every few sec you
seconds like 30 seconds or when the ETS
tables have too many messages they can
try to send multiple ones the only thing
that blocks them is that until I get
confirmation from calc I don't try to
send them because I don't want to over
like overload the the backup ETS that
each broker has the one that waits for
the message isn't that they are like
confirmed so basically this broker
decides for whatever reason to send to
Kafka so what it does is it picks up
whatever ETS tables it's tied to and
this is the same that that happens in
the kafka site so in this case CAF group
would have two brokers with three
topical importations and one of those
brokers is going to handle to two
different topic partitions so it's again
the same architecture on the other side
and we can see messages arriving on the
left side and it doesn't affect anything
that happens to the right of the ets
tables so this builds the binary i skip
the part where i do the backup thing are
no ets table and it sends the binary to
Kafka there's also like the whole thing
with compressing like Kafka accepts
compression on those messages so you
have a binary can't and since it's
mostly text and a few repeating heathers
it that's that compresses really nicely
so you can compress it another extra of
advantage of this is that it compresses
all the data and Kafka
right the compressed data so it saves up
to this directly it's really clever how
it works on the on that side and what we
see here is a leadership change this is
something that Kafka besides for
whatever reason maybe a broker went down
or maybe we change the replication
factor like in this case so what I do is
again as you can see the left side
message came coming in and we remove the
brokers the broker connections through
TCP this is just killing them and spawn
new ones and this will have their own
timers and they keep working like before
so the system at no point between
sending messages between changing
leadership at no point had a downtime
and that's basically in summary what
what what's going on the messages were
never see realized through a single
process or multiple processes we can
brighten currently treatise tables we
cannot crush a process and lose messages
because this is this is not reliable
reliant on the state of ash and server
or the message queue efficient server or
any process for that matter and also we
have the simultaneous reason right and a
better summary would be to say that we
have no downtime no missing messages no
special cases and no errors because we
know we separated all the messages that
we don't want to lose from the rest of
the system and we don't really care if
it goes down or not a certain level and
that you know that brings me to what
what I consider good design and by good
design I mean that if we chose Kafka
which we're there we did that for a
reason we did that because we like the
architecture we like the solutions it
proposed to the problems so why would we
reinvent the wheel when we're doing the
API we try if we try to mimic what we
did what kefka there then we're going to
arrive to the same advantages that Kafka
has that we liked and also there there's
also the simplicity on naming methods
that we try to name the methods in the
same way Kafka does and simple data
types because Kafka is written in Scala
and
if you're going to be honest about it
only uses wineries and integrals
integrals for the partitions and
binaries for everything else so we use
only that data we do you suppose but
that's just to wrap the message inside
so it's a very simple that type that
anyone could again pick up with Daniel
Kafka and that's that's kind of the
point like this is an example of the API
we have that's like there are a few more
functions but basically we have produced
overload consume and request metadata
there are a few more like stop consuming
is its depending on if you want to
consume actively or not like if you want
to like keep pulling up automatically
for new messages but all you know the
API is super simple and if you ever use
Kafka you will be familiar with those
terms because those are taken directly
from cafcass documentation and also
another small detail on regarding this
is that we use very strict data types
again with the hole binaries and an
interest but more to the point we could
use I'll lists to send messages like the
messages could be on your list but if we
did that we could we would have to make
sure that there are no errors anywhere
else right now when you send a message I
know it's a binary so I know there won't
be any surprises if it's a nihilist
maybe you sent an apple inside or an
atom and that will crash when we're
trying to like package the messages and
how do I fix that well if the brokered
were to crash while sending the message
then it will simply retry and crash
again and we try and crush again and
eventually the supervisor will crash and
die and the next and it will bring the
entire system that so to make sure that
never happens we're very strict and what
we accept so that any errors will be
caught early on and we have no surprises
or edge cases particularly sending Iola
star just actually lists and that's an
example of what the simple API looks
like we shall have the topic partition
our binary and integrating with the
payload it's a binary nothing nothing
took strange nothing weird to accept
there and all in all this is like the
objective was to use a fake eight
pattern to meaning we have an
easy-to-understand API it's all in the
same one same module like the rest of
the complexities hidden away and it's
super simple to use that was one of our
points because we have a lot of
developers and we can't afford to just
have people learning this new library
and in case I had to change anything
learn them learn everything again so the
last point is testing and Kafka has this
thing that is kind of hard to test why
is that because what I mean and why is
that well cafcass a service that it's
not written or lying it's outside
airline so how do you test it you can
test it by for example doing mimicking
the responses or that Kafka gives you an
airline broad broad the the library
mentioned before it does exactly that it
has like a fake Kafka inside and it uses
us for the tests but that's only
changing the problem because if your
replica of Kafka is not exactly the same
you will find problems later on so first
thing we did dialyzer and I would
recommend this for everyone all the time
on everything but dialyzer is really
good it tests your API and one thing I
found later is that when you go and
change things like sometimes you make
architectural decisions and you regret
them and go back well that leaves traces
it leaves garbage it leaves functions
that you're no longer calling and you
forgot to remove well dialyzer is
fantastic for that it tells you this
functions are being called or this drd
of this function is not what you expect
and basically it's a sanity check it it
cults everything that should be caught
by a very clever developer that I am NOT
we
also have unit testing this is the
testing that I noticed most of the other
libraries had basically the protocol can
be tested the ETS table senior
implementation and basic functionality
old all those can have their own unit
tests but it's still an integration text
test is it something else and proper can
actually help you in that regard a bit
because you can use proper to generate
weird data and then connect to an actual
cafcass server running on your own
machine and see what happens but that's
but that's not exactly like a nice
integration test because again Kafka
can't reply different things and for
certain conditions that you have no
control over so you would have to make a
fantastic sweet that kills brokers on
your machine and sets them up and change
these things through sue keeper so all
that would be extremely complicated so
my point just its lives just send them I
mean if it works if it works if your
library works then put it on station and
that's one lesson that I liked it worked
from pretty early on and I put it on on
station as soon as possible and what
that gave us is so in our station
environment we have a bunch of testers
testing the application themselves and
the features that we have so they
generate GAF car reports basically by
you know by just doing their shops and
there were a bunch of errors that we
caught that way and a lot of the answers
that kafka gave us let me get an example
so sometimes Kafka will Kafka will
confirm the messages you sent all
together except when it doesn't and when
it doesn't is rare it's really rare than
it does it but it's something I never
noticed that could happen because of my
local test it it wasn't an issue however
in staging eventually it did for once it
gave me an answer it couldn't so I love
I had like for any and expected answer I
loved it and I went back to the design
board and I had to fix it so maybe so
maybe I get like confirm
of delivery of half the messages because
again it's related to the fact that
brokers have multiple topics and maybe
one topic broad correctly in there one
didn't but the point is it happens and
it's something unexpected and is
something that I wouldn't have found out
without putting on station and well this
this also mean meant that after the
station part concluded and we said okay
it's not failing anymore we felt
confident enough to just put in
production because we knew that at worst
the worst case scenario if it crashes we
lost some blogs that we didn't have any
way with us we had no longer system so
you know put it on production to what's
a good idea the staging part made sure
that we wouldn't broke anything else so
the question is how they go when we put
in production well it went really well
for like I don't know eight months I
think seven and a half months eight and
then you know eventually had to happen
it completed liar me so there was a down
time there was a dampened the kafka side
an upgrade to Kafka a new version zero
point zero point eight point two I think
well that didn't go so well and that
didn't work so well so whatever as I
mentioned before we do save to disk if
we just save to disk if the ETS gets
large so whatever right just go get the
loves and what we're doing again like
yeah they were supposed to be there
somewhere no we didn't have permission
to write that's something that you can
overcome for never gave permission to
write to random directories and you know
for the sake of the arm this was a
random directory that I that calf grove
was trying to write to so we crashed and
we lost those messages and it was a real
shame in production but then again it
did last eight months
and well that's the nice note where I'll
finish this that eventually the whole
replicating the system inc the cafe
architecture meant that we didn't have
any performance problems that we
wouldn't that we that are exclusive to
the library like any performance
problems we have been in Kafka first and
then north and also the whole put it on
station as soon as possible really paid
off and huh that's basically then if you
have any questions okay so the question
is about how are the messages stored in
the easiest well the library I mentioned
that the shape Road concurrency controls
have multiple abstractions on top of ETS
and one of them is like basically a
buffer that writes the messages in order
so we use that yeah frankly I didn't
write that part but it works pretty well
but yeah that means that it's guaranteed
the order whichever process got to write
on that slot that so it reserves a bunch
of slots in DTS and it gives permission
to write to those lots of different
processes so as soon as one says I want
to write it gives that slot to the to
the process on the back chase around
there so you can ask him specific how it
works but we rely on that tool otherwise
what we would have to do is to yeah try
to implement something similar ourselves
but that may have problems on the
ordering the ordering may not be what we
expect because you want to write to the
ETS and it's basically like a pending to
a list and maybe you lose the ordered in
there there are a few details that may
go wrong if the right fails then it will
go after whatever rights came for
however that other solution that I
mentioned from Jay well that takes care
of it on
background yeah if they're being
processed yeah you're done you do lose
the messages
well
oh we have the number but around 20
million messages to Kafka a day I know
what that is about an hour because we
have multiple for every message with
sand and I think this is also indirectly
used by whisper that they have a higher
volume that I'm unaware of yeah 20
million like Kafka rights they usually
kind of smooth we don't have too many
bursts because the worst that could
happen so we create loves when you
create an account when you showing a
group when you start a conversation and
the list multiple of those things having
the same time yeah it's not we only have
burst when so this as I mentioned before
this is for hospitals and doctors and
the birds may happen if a hospital
decides to you know showing 10 more
doctors sewed or a hundred or maybe at
organization showings so then you will
have a breaker for off everything that
happened like the organization is
created and every account is added and
all lecherous records but that's rare we
usually have a smooth nice amount of
messages all the time but the burst
never hadn't like never caused any
issues
sorry oh yeah so about how the flow
works from consuming Africa that's kind
of different well so Kafka comes with
something called a consumer console
consumer which is basically a small I
think Python app and we did basically
the same they do so you connect to a
program you connect to any kafka server
and they all have the leadership and you
get what broker you try to consume to
you connect and you read the messages
that they come there is no magic with
ETS involved in that case because you
are you can only consume from one topic
at a time if you want to consume from
sorry one topic partitioner like if you
want to consume multiple ones then you
need to spawn multiple processes because
you need to connect through different
TCP connections to to even the same
broker because every broker has like so
it knows where you are consuming from /
TCP connection so if you want to consume
two topics you need to TCP connections
to different ports because that's how it
identifies who you are
so he's asking who keeps track of where
you're reading yeah so both kind of a
while you are consuming the library
takes takes care of it and then it will
say okay I'm consuming from desktop so
it gives gives you a bunch of messages
and say okay all this messages come from
this topic and you are on this offset
now if you keep consuming from it yes
the offset will stay on on the process
that handles it on cough girl but if you
for whatever reason stop consuming that
and sergeants mean again you will have
to remember where you were when you
stopped thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>