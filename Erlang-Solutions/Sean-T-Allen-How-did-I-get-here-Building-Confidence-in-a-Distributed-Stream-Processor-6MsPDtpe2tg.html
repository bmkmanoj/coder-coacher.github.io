<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sean T Allen - How did I get here? Building Confidence in a Distributed Stream Processor | Coder Coacher - Coaching Coders</title><meta content="Sean T Allen - How did I get here? Building Confidence in a Distributed Stream Processor - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Sean T Allen - How did I get here? Building Confidence in a Distributed Stream Processor</b></h2><h5 class="post__date">2016-11-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6MsPDtpe2tg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Shanthi Allen if you're gonna
tweet about this or anything the tea is
really important please make sure that's
in there years ago before I started
using the tea if you would search for me
on on Google you'd end up with a real
estate agent in Arizona not me while
after that you started getting a guy
who'd been arrested for dealing crystal
meth in North Carolina also not me and
if you just search for Shawn L&amp;amp;T now
still not really not really me so so
remember the tea it's important so a
little bit about me before you get
started I'm one of the authors of a book
on patchy storm called storm applied I'm
a member of the pony core team Pony is a
say high performance actor based
language
I'm also the VP of engineering at
sentence we're a startup based out of
New York City and really today this is
this is an experience report for how
we've gone about getting confidence in
the system that we're building if any of
you saw Ben's talk this morning what
we're building is a stateful stream
processor originally it was called Buffy
but we're getting close to the time now
when we'd be releasing it and so you
know we didn't want to have Josh
Whedon's lawyers come around and get on
us so instead we've named it Wallaroo
which is nice because you get cute
little animals to go along with it and
in keeping with our general Buffy theme
they're still like demons they look a
little bit like Wallaroo so that's not
bad but with that change we've still
kept our general naming theme for it
which is that every component of the
system has to be named after um
characters from Buffy the Vampire Slayer
so you're gonna if you're familiar with
Buffy the Vampire Slayer you can get
reacquainted with a lot of your favorite
characters in different ways but not
willow because we haven't had anything
that's cool enough to be called willow
yet so for the system that we're
building we started in January 2016 with
a prototype that we did
in Python and we have a production
version coming out next month basically
which is written in Pony and you know in
the end we're really about we're really
about creating a system that has really
high performance our goals going to this
we're to have really high throughput
really low latency with flat tails
running on a lot less hardware to give a
general idea about that when I run it on
my 2004 2014 MacBook Pro you know we get
some pretty good performance like
220,000 events a second without really
pushing it you know doing like 99.99%
are processed in 500 microseconds or
less and there's an awful lot of work
that goes into that and we end up
changing the code an awful lot so a lot
of this talk is about how how are we
feeling comfortable making all of these
changes that we do and knowing that we
don't break the guarantees in the system
because the other big part of this is
what we really have is we have like we
have this idea of we want to be a high
fidelity system that is we are a
stateful stream processor and by being a
stateful stream process that means that
we're keeping like in memory state for
any particular calculations that would
be going on within the system and in the
face of failure we want to know that
we're actually giving correct results
because effectively we are some sort of
simplified version of a database in a
lot of ways and you want your database
to give you correct results even the
face of failure how many people here are
actually familiar with stream processing
okay good
well I'm gonna give a little bit of a
quick run-through for for people who
aren't stream processing generally is a
way of dealing with data where you
handle like a message at a time events
as they happen they come in and you
process them it's a never-ending stream
just right on through and you know when
I talk about failure through this like
what kind of failures are we talking
about
they could be machine failures it could
be a slow machine this machine can get
slow enough that it's effectively a
failure seg faulting processes GC pauses
Network errors
whatever it might be you know they're
failures that happen and in stream
processors generally you know when you
have failures you have some type of
delivery guarantees for what you're
going to do if any sort of failure
happens in general there are a couple
different ones for that one of them is
at most once this is basically a
best-effort thing where hey I tried to
deliver that to you you didn't get it
I'm not going to send it again I made my
best effort right there but there go a
stronger guarantee there would be at
least once this is basically where hey
you know I send it to you and you need
to acknowledge it if I don't get an
acknowledgement within some period of
time I'm going to go ahead and resend it
to you and then the the holy grail for
most stuff is what's called exactly once
which in general when people say exactly
once but they're really talking about is
you have at least one semantics where
you're going to keep resounding stuff
and then you have some sort of
idempotence on the other side so that if
you end up getting duplicates it's fine
it's okay they'll go ahead and they'll
be filtered out and you still get the
results so see exactly once part it's
really important we within our system we
guarantee exactly one semantics for
processing of data what this really
means if you take a really simplistic
case of like if you have a counter and
you have messages which are going to
come in tell you what you're going to do
with this counter for like adding and
subtracting from it if our counter
starts at zero and we go ahead and we
have message one comes in that says add
one we go ahead we increment to 1 if we
have message 2 comes in you know it says
hey at 5 good we go ahead get 6 if we
get a duplicate here where we have
message 1 again all right then we're not
actually going to add to it we just keep
the value of 6 and in the end that's
really basically what at least once with
idempotence is all right and that's a
guarantee that we want to have in our
system so really the core of this talk
is it's it's not about ARP and it's not
about our product it's about how we go
about feeling confident as we're doing a
lot of changes in order to get better
performance and be that you know and
the throughput latency memory uses etc
that in what is a reasonably complicated
system that we haven't broken any of
these guarantees right and so really
this in the end this is this is this is
a talk about blackbox testing and the
background faded out there a little is a
picture of a Peter Alvaro who wrote a
paper about a lineage driven fault
injection and this talk is really my
love poem to Peter because I love
lineage driven fault detection so let's
start with talking about blackbox
testing and what that is if you aren't
familiar with it basically what we have
is you have a system that's under test
and you have some input source which
sends data into that and you have
something which goes ahead and it
receives that output in our particular
case well we have is Wallaroo that's the
system on your test and we have an input
source which is called giles sender
which goes ahead and sends it in and we
have giles receiver on the backside
which receives the data and we the
reason one of the big reasons why we do
blackbox testing is because unit tests
aren't enough for this we can go ahead
and we can have all of the unit tests we
possibly have they can pass and our
system can still be completely and
utterly broken integration test
integration tests are nice but they
aren't enough either because in the end
you know in general this is usually this
is usually happy path testing and we
have a lot of different components that
when you start composing together you
get all sorts of interesting new failure
scenarios if you have the time and
inclination at some point there's some
really interesting Kafka bugs that used
to happen earlier on when different
parts of Kafka which had all been
independently tested and proven to be
correct when you actually put them
together had strange emergent new
behavior where stuff just didn't work so
even if you proven each individual
component works you don't actually know
that your entire system works so we are
big fans of blackbox testing we test the
entire system we tested end to end and
we verify that it's actually meeting our
expectations and what we said he was
going to do so a primary part of this is
Wesley Wesley is our
expectation verification stuff ooh and I
forgot to change Buffy on there I
thought I'd gotten all this oh well so
basically what Wesley does if you
imagine our black box is the thing which
takes in integers and he's going to go
ahead and double them and we have input
here which is going to be like 1 then 2
then 3 and we're gonna have some output
that we expect for this which is going
to be 2 4 and 6 an important part of
this is we have to know based on what
the black box is what our expected
output data is based on the input and
we'll get into this more later because
when you have non-trivial things that
you're talking about this gets to be one
of the really hard parts of it so in our
case right we have our input source
which comes from Giles sender we have
our output receiver which is the Giles
receiver and our input source sends like
one two three four and we expect to see
two four six eight coming out the back
side so what we have in this case right
is this is a fairly simplistic one where
we have guaranteed ordering on this and
we have we have our input we expect it
to match up to our output what we do is
we go ahead and we have Wesley and we
have we run we tell it to analyse so
what it basically does in a simplified
form is you know it looks and goes hey
okay the first entry was one we expect
to see two etc on down the line all
right and hey all right awesome it works
it's a simple basic test right there and
in the end though for this you know
that's that's a happy path test in the
end there are no failures there if that
doesn't work then we have some even
larger problem so we have another system
this is called spike and spike does
fault injection so and this is really
the big core of the talk so fault
injection and in particular we practice
a form called linear driven fault
injection fault injection is when you go
ahead and you intentionally introduce
errors into your system this can be a
really huge problem space and lineage
driven fault injection helps you narrow
down like your choices of faults that
you're going to do and it seems
really really simple for an idea but you
know it's one that until I read the
lineage or even fault detection paper I
hadn't really thought about like this is
a way to do it
so the basic process is you start from
unknown good result that you're gonna
have we're like you expect if you send
in one two three that we're gonna get
two four six then we go ahead and we
look at this and go what could go wrong
what could go wrong inside of that black
box that could cause us to get incorrect
failures and each of these things that
you come up with is a nemesis so in our
case we started because we're a
distributed stream processor but you
could do this for an any other system
coming up with different things we
started with the network is going to be
our first thing and we have a number of
nemec's but I'm just going to talk about
the network one here because in the end
this is about how could you go about
doing this yourself so we have the
network and one of the key things that's
really important here is you have to
have determinism here if you can run the
same test over and over again and with
the same fault being injected and you
get different results then this is it's
completely useless it's not going to
help you at all and getting that
determinism is one of the hardest parts
of doing this even just with network
stuff so in our system we basically have
our nodes communicating with each other
over TCP at this point in time and what
we do is we go ahead and we inject
failures based on TCP and the guarantees
that TCP makes and it makes a number of
nice guarantees for us for exaction it
says that between any point to point
communication that order sorry that
delivery is guaranteed to happen in
order if I send message one then message
two it's going to arrive as message one
message two it's not going to get
reordered so we're depending on that it
also guarantees that it like at the
packet level you there's any packet loss
that it will go ahead and resend and it
will do deduplication for us at the
network level then additionally like I
said you know it will retransmit any
lost data so now we are
building the stuff in pony so we're
gonna dive in a little and look at how
Pony does network stuff because this
becomes very much you have to hook into
how your system works in order to do
fault injection so what basically Pony
does in a network level is it's
event-driven so that when for example
you have a connection that's established
you have some code over here for a
callback that's called connected that
happens when that connection is
established when there's incoming data
the callback for received happens etc so
the the callback classes that you write
for this they're called notifiers
this is a really simple useless notifier
here right here you'll see this is this
is the notification for what happens
when connected is called in this case it
doesn't do anything other than print to
standard out that hey this connection
was opened and when the connection is
closed
hey the connection was closed so the
first the first one that we wanted to go
about testing was what happens with drop
connections you know basically like
network partitions etc they happen etc
so we came up with a bit of spike and
this is a segment of it for dropping
connections so what we have here is we
have a little bit of it and what we went
ahead and did in this particular case is
we wrapped our normal code the normal
notifier that we have up there the
letter and we went ahead and we wrap
that with the spike one and then at the
time that the application starts up you
can either choose that you're doing a
fault injection run where we turn we put
in all the spike ones where they can be
run or you don't and then we don't even
we don't put them in basic dependency
injection stuff there and then we also
have a long with that we have the dice
object is a random number generator and
we have the probability an event happen
happening so in general basically what
we have is so you go ahead and we have
our received one here and the basic way
any of these work is we go ahead and we
check to see are we supposed to spike
this if we are in this case it's a drop
connection one so we go ahead and drop
the connection
and if not we just go ahead and we do
the processing as it would normally go
and for the spike logic what we
basically have is we have our we roll
the dice and if it's less than our
probability we're going to go ahead and
we're going to drop that now the
important part to go along with that you
know is that you know this needs to be
deterministic so we need to be able to
set specific seeds for this and we want
it to happen so that if we use seed 1 2
3 that whatever happens on that on any
run for 1 2 3 with a given input set
we're always going to get the same
result otherwise we'd be chasing our
tails for ever trying to figure out
what's going on so in general these are
all different places where we ended up
introducing drop connection like hey
when an incoming connection is first
accepted we might not even get through a
full handshake it could we could
potentially have it happen then when
we're attempting to create outgoing
connections we could also have it drop
then when the connection is actually
established when data gets sent when
data is received any any of those we go
ahead and we introduce it in any of
those points and the basic way that we
go about doing this is we follow what in
general sort of looks like TDD and you
know we go ahead and we take in this
particular case we had this was a very
popular one for us in the beginning was
a simple app called double and have
because it's really easy to look at the
results for this and know that it's
correct because if you get one going in
and it goes through double and you don't
vote two two and then we send it off to
a second node where it's going to have
it then we expect to get like one back
out the outside and the Wesley tests are
really easy because this is just
identity and it should if it goes 1 2 3
in goes 1 2 3 out it's a good place to
start so alright so what we go ahead
then you know same thing with you etc
you get the idea
easy to verify and another another
reason why we do this is we're going to
we can do this as a simple one where
it's two steps and we're going to be
processing process boundaries and by
doing that we're going to cross the
network boundaries for that so the way
we do this first is
we do the double in half and we go ahead
and the first thing we do is that we run
it without spiking because hey well we
need to know that it actually works in
the first place if we have a broken
thing in the beginning then all of our
we could just be chasing our tails and
you know we test test tests you know we
have CI etc for this a every time
somebody commits it goes ahead and it
does a normal regular run and you know
if everything passes awesome then we go
ahead we take the same app and we start
turning on drop connection and we test
it and for each one of these you know it
better fail if it doesn't fail in the
beginning then we have a problem because
we have something that we didn't do
right if that if that doesn't fail then
we probably implemented something about
the spike component itself wrong and
that's that's a big part of it is that
you need to be able to guarantee that
your injection your fault injection code
is actually introducing the faults that
you expect so we go ahead we do it hey
here we go it breaks we got to fix it
right and in this particular case fixing
meant you know we need to have session
recovery where we've lost the TCP
connection we need to re-establish that
connection right so we came up with our
wonderful session recovery algorithm
it's not actually ours like it's a
standard one that most people use and
you do the same thing again where we go
through after that's been in there and
we test it and it should pass and like I
said you know we need to be able to do
repeated runs and if we get different
results then this is this is pretty
useless we're not going to be able to do
anything with it on the determinism
front this is actually really easy to
get wrong and we actually got this one
wrong multiple times before we got it
right part of that is that the TCP is
not deterministic in terms of how things
are going to arrive they can it could be
any kind of delay in between when they
when stuff shows up at the network card
we do get that we do get the delivery
order guarantee that's great we still
get the duplicate detection etc we get
not going to lose data but there's no
there's no determinism in terms of when
the stuff is going to arrive like if we
have a hundred bytes of data that we're
sending from one machine to another it
could arrive in
grouping of 50 bytes and another group
of 50 bytes or it could arrive like you
know 20 30 and then 25 25 and so what we
had originally done was we were spiking
our individual received calls and that
didn't work and once we saw it didn't
work or like oh yes that's obvious
because one time this could be called
with 25 another time this could be
called with 50 and we're gonna get these
different results so what we did is we
introduced this idea of expect which is
basically you can tell like a connection
hey don't call the receive method until
you get X amount of data and in this
particular case we're using a framed
protocol so we can know how much data is
supposed to come in so if you're not
familiar what a frame protocol is it's
basically something like this where you
have a header of some size right 4 bytes
here in this particular case which is
going to tell you like what this payload
is that's right here right so in this
particular case we have our header which
says 18 and that means that our payload
for the next one is going to be 18 right
and we get 20 the same type thing and so
basically how this works is you go ahead
and when you're inside of received for
this what you want to do is you want to
say hey I'm gonna go ahead and I'm gonna
read off these bytes here right and this
is going to get my expect value because
I'm in the header in this particular
case that should give us 18 and you're
going to go ahead and you're gonna say
okay
I'm now expecting 18 bytes for a payload
and also I'm no longer in the header and
then we can go ahead and once we're not
in the header code anymore we can do our
standard we run it through a decoder for
whatever our particular payload is to
turn it into whatever and you can see
here all right okay that matches up with
our 18 and then when we're done with
that we know that we need to expect
another 4 byte header and so we go ahead
and do that alright and so it would be
20 so what it means is that when we get
100 bytes you know and no matter how it
comes in any of these things we're
always going to get this we're always
going to have our method
called with 18 I'm sorry for then 18 and
then another four and in this particular
case 20 alright same number of notifier
method calls and matter how the data
arrives and now we have determinism
again seems remarkably simple but you
know we messed it up the first time that
was that was one of those wait what's
going on here so ya drop connection and
expect fast deterministic friends we did
another one which is for slow
connections this was this was a fun
interesting one as well how do you go
ahead and simulate a slow connection if
you want to want to put it in so what we
did in this particular case is we go
ahead and this is our delay receiver
right here right and what we do is in
this particular case we actually
override expect here where we go ahead
and we the the notifier that we're
actually wrapping what we have to do is
we have to call it expect before we do
anything and we go ahead and we get how
much it's actually expecting based on
its given state because when we're
wrapping it you you can't know like it
could be a frame protocol could be a
fixed width protocol we don't know and
then we go ahead and return zero and
what zero means is just give me all the
data that you have available all right
so we go ahead and we override that and
then our actual delay one here can
control the flow of bytes
it's basically acting then again as
another layer in between to maintain the
journalism so this actually took us a
while to get right we did multiple
attempts at this and each one of them
had slight little things that were wrong
with it but basically what it is is we
had to set up a minimum and maximum
number of bytes that we go ahead and
allow through and a a a minimum and
maximum number of bytes that we would go
ahead and delay then we use a we use a
seed and the seed well when we're it in
either a allowed data through or a delay
period it will go ahead and the seed
will pick something in that range of
this is this is how much to expect so
for any
and seed you'd have it but it's not
always going to be 500 bytes that we
allow through than 100 we buffer or
whatever there's there's some randomness
in there to try and determine edge cases
so if you'd have something like hey okay
we got this we got some input you know
and it's going to go ahead and it does
the random stuff and he'll come up we'd
say all right I'm gonna allow 800 bytes
to go through then you know I'm gonna go
ahead and I'm gonna buffer 400 bytes
before we go ahead and we send anything
else through so you know if we get a
thousand bytes that come in we're gonna
go ahead and we'll go and we'll take 800
over them and we'll send them through
immediately and we'll and we still have
200 bytes that we're buffering we're
supposed to buffer 400 so we're going to
continue buffering those 200 and we're
going to delay until we get another 400
that comes in which means we can then
start delivering stuff again so what do
we find from this well when we actually
implemented this everything seemed to be
working fine for a while but then like
maybe one out of every 50 times or so
we'd see some weird error where we
weren't actually getting the results you
were expecting coming back from Wesley
tests and it took a long time for us to
figure it out but we actually found that
we had a bug in the session recovery
where it was making certain assumptions
about like the IDS that were being used
to communicate back and forth across the
channel which were incorrect it was oh
those are always fun it's one of those
ones where you're like hey we're trying
to get a product out the door we did the
thing it was even a little to do next to
it said this might not be right we
should probably come back and look at
that later
the infamous studios which you know
those are always so fun we also found
bugs in the pony standard library that
was that was a fun one and we also found
bugs in the spike implementation I wrote
the drop connection spike implementation
one and our first thing we had to get
passed was that we actually had we had
bugs in how he was doing it and the code
that I actually showed you earlier I
left it in there the bug is actually in
that code feel free if you ever wanted
to go back and look at the slides and
see if you can figure out where the bug
is I stared at it for
an hour and a half before I realized
what was going on
but it's it's a fun one there and you
know we found still more bugs and you
know in the end you know which is really
about is the determinism was the key the
the spiked bug that we actually had that
was the worst one of them all because it
was messing up the determinism and we
weren't getting the same runs through
each time through it was causing real
problems and so like that's one of the
first things if you decide to go about
doing something like this whatever
you're using for fault injection you
need to come up with a good way to test
that you're actually getting determinism
from your fault injectors injectors and
we didn't do it in the beginning but now
like the first big thing that we really
do when first in the beginning we were
like in a real rush from like yay we're
really excited to do this so we'd write
the fault injectors we stick them in and
you know you have the good run and then
we turn it on and we just expected the
fault injector itself to work we're
testing everything else and where
somehow magic programmers who can write
fault injectors without introducing bugs
into them but you know that wasn't the
case so we spend a lot more time now and
like the biggest area that we have for
unit tests and our code base are
actually the fault injectors themselves
because those are really hard once you
turn on like the tests for the entire
system you can be end up chasing ghosts
for a long time if you have bugs in the
fault injectors and you know and but if
you have they're usually relatively easy
to find if you have a unit test for them
it's one of the areas where I much love
unit tests so I want to talk a little
about data lineage this is something
that we're looking at and we think is
really important overall when you're
doing fault injection type stuff this is
another thing from Peter Alvaro we're
looking at introducing into ours but we
haven't yet it's just something that
we've thought about so this is far less
thought-out but if this is something
that you're looking at wanting to take
on or whatever this is you know
definitely something where I think go
ahead and check out data lineage so the
basic idea for data lineage is you have
some set of outputs 2 4 6 and you want
to know how did we end up getting 2 2 4
&amp;amp; 6 all right so
if we have some input one two and three
right and we expected two four and six
but we got four and six this is this is
great it's wonderful but you know how
did we get there those those are not the
results that we were expecting you know
by the same token one two and three we
get something else here it's entirely
different it's still wrong who knows
it's great the test found the problem
for us it pointed out to us in a nice
automated fashion that we're doing
something wrong but we have to go in and
the way that we do it currently right
now is anytime there's a failing test we
store the seeds and the input set that
we use in order to do this and we go
ahead and we have to step through it and
figure it out and what we'd really like
to be able to do is be able to dump out
the data lineage and be able to like
store what actually happened in this
particular case and that would end up
saving us a lot of time in a lot of ways
really what it's doing is it's going to
verify like art do we have determinism
all right and in our particular case
it's really about to be about finding
incorrect like executions like if we
have something like that happen then in
all likelihood we have something wrong
in the core part of our problem product
where you've given us a couple different
computations right and we go ahead and
strung them together wrong so you could
take you where it's something like this
right where we accidentally routed this
through double two times when what we
meant to do is write it through half
right and if we go ahead and we have the
lineage and we know that each step along
the way right this went from double to
double then when we have that along with
the failing test result we can look that
and go oh well this was supposed to do
double to have so we have some problem
in how we're going ahead and we're
setting up these topologies for people I
mean these are fairly basic things but
we've actually had a couple cases where
we had ones where in code paths that get
executed less often we'd accidentally
done this I think my favorite one was
the one that we were looking at for a
while was we had a crashing bug which
really would have been helpful if we had
this because it turned out that
had a slight bug which type checked a
strongly typed language loved types but
you know type checking couldn't help us
when we accidentally in one part of the
bug connected we have two paths we have
the data path that everything goes down
and we have a control channel for nodes
to communicate back and forth between
each other to say things like hey I
exist I'm part of this cluster now and
what we did was we accidentally had it
so that the control path from nodes
which were only talking to ones that
were downstream from them they only had
external input sources were actually
wrapping their control panel back around
and attaching to their incoming source
and sending weird junk back down in it
was of course it was a one-character bug
as these things always are and it took
us about six hours to figure it out it
would have been really nice if we'd had
the data lineage there to show us like
where did this actually come from
beforehand you know this is this is not
a particularly new thing being able to
follow these um like google has like
dapper for example what's the what's the
Twitter one is it Zipkin Zipkin that's
right yeah I mean so these ones where
you can go ahead and you can trace off
through a system it'd be really awesome
to have you know it's also useful
outside of development I really wish in
all the times that I was running storm
clusters at my last job you know that
we'd had something like that for
production debugging you know I can't
remember the number of times I was up at
3 o'clock in the morning trying to
figure out why the jobs which were
essential to you know the business
running and making money the next day
that needed to be done by 6:00 a.m.
we're failing and had been for three or
four hours and you're looking at log
files that just spew out hundreds of
thousands of lines in a few seconds you
know so that would be really awesome to
have it would also be great to be able
to go back through later on to have like
a data lineage system in something where
you could get an audit log and you can
say hey why did you do that we're
targeting like finances our primary
space and even though we say hey this is
vaporware and might have a real serious
impact on the performance that we're
going for like lots of banks look at
that and go oh wait so you mean I can
tell the regulator's why we
made a decision based on what the state
of the world is at the time so I mean
there's a lot of value for it from that
you know it's basically a big giant
wonderful hindsight machine which is
yeah love it so if if you take one thing
away from this you know it's that you
know building confidence in these types
of systems is it's really difficult and
I think this was me most of the time it
was it was really frustrating but in the
end it's worth it
like we're getting ready to like put
stuff out into like into a POC with like
a large client where you know if it
doesn't work on those most basic levels
then we've basically sunk a potential
you know multi-million dollar project
with people and we'd never probably be
able to get another chance with them
ever again and there are only so many
really large banks in this world so we
really don't want to do that and it's
nice going into it knowing that we have
the system where we have all of these
various tests and we're running them
like on every single commit we go ahead
and we run all of these and it's really
quick and easy to spot where we might
have introduced regressions I mean it's
not always possible because we don't do
an infinite number of runs and we might
have an edge case that only happens like
one out of every 50 times but it's nice
sometimes it catches stuff which is a
really obvious one on like CI I mean it
wouldn't be obvious if you look at the
code really closely knowing the failure
but it's there and then just in general
knowing that we have this stuff running
constantly it will eventually trigger
one of those cases so you know all of
this stuff this came from inspiration
from an awful lot of people you know
number one probably on this in terms of
what we're actually doing is Peter
Alvaro the original lineage urban fault
injection paper about a system called
Mali is available there there's also a
talk which I meant to put on here but
didn't that he did a Q Khan London
earlier in the year with a colton from
Netflix about the work of how they were
doing this at Netflix it's a great talk
because it's like hey we have this
wonderful academic idea for Molly but
how you
about actually putting these into real
systems like that's the that's the
really interesting and difficult part
and I'm I'm hoping that you know some
people if they see this and want to do
it can like use this talk as well like
get some kind of clue because it took us
quite a while to figure out how to do a
lot of this stuff it was really hard
then there's another great talk of
Peters in general about testing when
it's tough around this it's called
outwards from the middle of the maze if
you're not familiar with Kyle Kingsbury
I think he also gets called in like the
bigger industry man it's like the man
who tortures databases or whatnot all of
his Jepson ones there on his website are
really great the earlier ones are better
because they have like lots of pictures
of Barbie and stuff but now that he's
doing this for money like they're a bit
more toned down and calm and
professional but you know they're still
great for that and if you want the
non-professional side of him you can
follow him on Twitter and there's plenty
of non-professional they're probably the
first for the first thing before even
the lineage different fault injection
that really got us started thinking
about this before we even started
building it was a talk the sky will
Wilson did he was at foundation DB
before it got swallowed up into Apple
and he did a talk it's strange Luke
called testing distributed systems with
deterministic fail simulation and it was
really about how they went about
building foundation and what they were
doing was they actually built a database
simulator before they built a database
and they came up with all of this stuff
where they simulated everything that was
going to happen and they introduced
faults like into the system and they
could do it in a termina stick fashion
so they could like set up a large number
of machines and they could without them
actually being like talking across no
each other in the network they could
still simulate network failures and
everything it's like really incredible
talk it's it's hugely inspirational if
you're interested in this stuff at all
you should definitely check it out Katie
who's sitting right there has a number
of great talks about verification and
distributed systems in general I mean
there's a lot more than you can do
beyond just like fault injection stuff
and whatnot
there was a great a cmq article that she
did and there's a talk version of it as
well if you don't like reading which is
also a really good one it was from Q con
check both of those out I know
who who works it fastly now you should
at least side thing it's not another but
you should follow her on Instagram
because she has the cutest cool dogs and
they're all the time and she has a great
talk called testing in the distributed
world which is another great overview of
different possibilities for how you can
go about doing this there's a chaos
engineering group that was started by
Netflix and they have principles of
chaos which talks about all the chaos
engineering stuff that they do at
Netflix where they intentionally
introduce failures into the production
environment to see what happens we don't
have a production environment to do that
in and for us anybody we don't really
want to go to a client say hey by the
way can we mess with your production
system but you might be in an
environment where it's like that and I
have to say at my previous job that I
really very much enjoyed like going in
it like two o'clock in the morning
sometimes and people hated me for this
but I would turn off random VMs just to
see what would happen and it would be
always be really scary when you could
turn off a VM and nobody would ask you
until about 7 or 8 hours later what
happened that's you can you can learn an
awful lot about your organization in
your systems from doing that so that's
another great resource to check out if
you want you can talk to me later
and I can tell you what we're doing with
these wonderful little clusters
raspberry PI's here which are actually
also part of our testing procedure
they're they're a lot of fun they're
kind of a pain in the ass to build
there's all these tiny little screws and
all of these nice little like plastic
things that make it look so cool they
have this thing to keep it from getting
scratched where it's this like little
paper film thing and you have to swell I
don't know some people might be able to
do this better but it takes me about 45
minutes for each one so it took me like
that's that's my question that I built
and it probably took me about nine hours
to put that together and most of it was
removing the piece of the paper off of
the plastic thing so it it would have
the proper aesthetic like appeal when he
was sitting on my desk a number of
people helped me with this talk
Peter Alvaro gave me great feedback
Sylvan clubs she's the creator of the
pony programming language he's he was
really good on that Zeeshan awesome
awesome John mom Rob Roland and Andrew
Turley they
all were really wonderful and helped me
out with stuff and that's it
shaunti Alan thank you remember the tea
it's very important questions also I'm
really glad I cut about 25 slides out of
this cuz that would have been a problem
I've been practicing on not speaking
like Chris Michael John from like four
years ago I did a version of this that q
con that was longer and I finished it in
22 minutes so yeah yeah a question about
the expected inputs outputs yes enough
are they hand curated input sets yes yes
that that's currently what we're doing
is we're hand curating them it's one of
the things that we've thought about
doing is trying to come up with like
something but the thing we came up with
for that is we need the first thing
you'd have to do on that then is that
you if you're going to have it randomly
generate the stuff for you in some
fashion you know which is great then
like basically property based testing
type stuff with how we're doing all the
rest of the fault injection would
require us to rethink all of that or we
implement all of the logic which we're
supposed to be sticking in there and at
that point like where it's far less of a
black box at that point and we're really
trying to stick more to the black box in
the aspect of it the the thing that
we're looking at much more before that
and we're getting ready to do now is we
did all of this on a file basis which is
wonderful for short test runs but I mean
we're building a thing which is supposed
to process you know hundreds of
thousands or millions of things a second
if you want to test that this works
correctly over two hours or eight hours
or exists in eight hours not possible on
the size of stuff that you can get from
Amazon two hours not possible in the
size of stuff you can get for Amazon we
can do 30 minute runs and it takes quite
a while to actually get the results so
we've been putting most of our time into
redoing it from being a file based thing
where our receiver actually is a system
where itself is a streaming system so if
we run it for eight hours and there was
a failure two minutes in
we're not actually going to run it for
eight hours and we're gonna fail it
after like those two minutes when we
first see the failure hello so your your
fault injector was mostly about TCP did
you also have injectors for transient
problems like file system yes performing
CPUs or whatever yeah I mean like so I
mean one of the big things that we do is
we provide you know resiliency for data
that's stored in there and our first
version is one where we can survive the
loss of a process but not the loss of a
machine because we're writing stuff out
to disk
so yeah we we are currently using this a
library which sits in between your
application and POSIX
which we control from inside of ours in
order to inject failures at the POSIX
call level for a file system operations
it's actually pretty damn cool I can't
think of the name of it at the moment
because I'm not really working on that
spot at the moment we have like one
person who's dedicated full time just to
figuring out ways to break stuff and
yeah it's it's really kind of fun and it
took us about two weeks to figure out
how to integrate it but after that it
was it was really easy you know if I
went through all the different ones that
we were doing then we'd still be here
for another two hours this TCP is a
relatively easy one to explain what's
going on there all right so there will
be coffee after this so I suggest you
just grab grab Shana tea Allen
afterwards</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>