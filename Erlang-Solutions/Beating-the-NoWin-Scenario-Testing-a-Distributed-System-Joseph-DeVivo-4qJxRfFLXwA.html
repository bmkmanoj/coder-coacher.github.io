<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Beating the No-Win Scenario: Testing a Distributed System - Joseph DeVivo | Coder Coacher - Coaching Coders</title><meta content="Beating the No-Win Scenario: Testing a Distributed System - Joseph DeVivo - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Beating the No-Win Scenario: Testing a Distributed System - Joseph DeVivo</b></h2><h5 class="post__date">2013-04-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4qJxRfFLXwA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright so first thing I want to say
before I say anything else that's why
its first is this piece of code here I
had some coloring snafu with my slides
so if you can't see that this is a
receive walk you're probably sitting too
far away but if you can see this and
understand this to read received lock or
don't care and trust me to tell you when
there's a receive block on the screen
then we're in good shape so welcome to
meeting the no-win scenario i'm joe
devivo and i'm here to talk to you about
testing distributed systems particularly
how we test react a pecho though maybe
you've heard of me so if you haven't
heard of me here's a couple of things
you should know about me I've never done
this before so that means I'm pretty
nervous up here and if I start to talk
too fast or just sort of trail off into
mumbles you know somebody come up here
and kick me or just say something is
probably more polite oh thanks thanks so
I've been a reactor since 2010 which is
weird like I don't use react anymore now
that I work here sorry not spit all over
my computer that's fine so I started
working in bachelor professional
services in about a year and a half ago
and I made a transition over to the
engineering team soon after that which
might be important later in the story
and I was then OTP expressed alumni here
last year so I'm still a little new I
mean relatively new to all this so
coming some slack so why are you here
well I'm not here I'm here to sort of
just talk to you about some stuff that I
did some cool little tricks that I
figured out and things that I did to
test react so what I don't want you to
think that I'm here to teach you
something or that I think like I know so
much more about anything than you do I'm
here to get you excited about some of
these little ideas that I had and if you
remember them sometime in the future and
think oh yeah joe did that and I'm kind
of doing something similar now you know
tweet me or email me or something and
we'll talk about it
and Michael it'll probably get better
from the conversation maybe yours will I
don't know might get worse but we're
gonna have some fun and you can tell my
slides are a little goofy so um i
mentioned i transitioned into bachelor
engineering team and around that time we
started with the valve process in
engineering and you know we decided the
short version is we decided to try this
fearless adventurer and knowing what to
do when no one's there telling you what
to do and why that's important for this
story is that i get to do whatever I
want which is pretty pretty empowering
and around the time that I started in
the engineering team we were getting
ready to test react 12 so there was a
call for testers and it was time for you
know people to just get involved and
help validate this release which was
which was ready and at that point I
reached this you know the needs of the
many bro it's like we all these people
need to test and I'm gonna be part of
that because I can actually make an
impact here and valve process gives me
the ability to choose to do that so I
get involved this validation process for
f1 to but it was a painful process you
know it was full of all sorts of scary
things like Python and virtual machines
and bears so we get to this point where
thank you so we get to this point where
we finish the validation or no actually
we didn't finish it at this point um
we're going through this and I'm
experiencing like all this like this
pain of the process that we're going
through right but I I needed the pain of
this process or I need to understand
what we're doing what where there might
be holes in this thing and I needed to
build up like this reservoir of rage so
that when i'm actually working on this
thing later on i will like remember oh
remember when I hated that thing well
now I can fix it so that was important
to me so now we finished the release now
and that were finished and it's time for
me to choose what it is I'm going to do
for like real life grown-up life at
bachelor engineering and you know a lot
of people aren't clamoring to be part of
like the test infrastructure team I know
that because there wasn't really a test
infrastructure team and so I got to that
like needs of the few bro it's like
do I even want to be doing this do I
want to get involved in testing but I
actually felt I could do it and I was
like really intimidated by all the other
like relying brainiacs at bosch oh so
I'm like yeah I I could actually help
here so I'm going to do it but then I
like looked at the problem and I felt
like I couldn't win it was like really
you know complicated it was just me so I
was originally when I like came on the
team I thought I was gonna be like
mentored a little bit somebody's gonna
tell me like you know this is how this
project worse but there was no project
and I just sorta have to figure out to
solve this problem and you know nobody's
jumping up and down like ooh me me I'm
gonna be on the test infrastructure team
with you and we'll do this all together
now I did get a lot of help from like
part-time helpers you know every once in
a while your your interests as a tester
in intersect with people who are writing
code so i didn't get all i did get a lot
of help i certainly didn't do anything
on my own but you know it's intimidating
it feels like that way so you know i
took a cue from the man here yeah I
don't like lose so let's get cracking on
this start attacking the problem there
are all sorts of little half started
test infrastructure projects before me I
was not the first person to go down this
path so I tried to sort of bridge them
all together and see what I can put
together and you know oh my god that's
complicated look at all this there's
this rehab testing the people are
talking about there's this harness any
people were talking about you know is it
going to get jen server are we going to
connect the virtual machines ssssh
what's what's going on here well it
turns out that it's a hard system
because the hard problem test
constricted systems is hard thirsty
um so Tessa Candace treated system is
hard um it's not just me who thinks this
Jared thinks so all these other people
down here think so and you know some of
them work with me and some of them are
me so it's uh yeah thanks yeah it's it's
the thing so it's so it's good it's but
it's not impossible and that's that's an
important distinction because um you
know people don't want an impossible
challenge heart is good heart is you
know stimulating but impossible is just
kind of depressing so the good news for
me is now that I'm tackling this problem
I've you know I've gone through I've
gone through the with all of these
people that were already doing this test
infrastructure thing people that were
using the test framework we were all in
it together so like I kind of knew my
customer and knew what that was trying
to get out of them but it was um there's
a lot of signal in that nor a lot of
noise in that signal right you're just
hearing everything for everybody and
everybody of course is a different
priority of what a distributed or any
test framework should do so that was a
little overwhelming but I got kind of
good at figuring out what was important
what wasn't so is it really oh no rinne
scenario scenario no I'm just being kind
of dramatic here so what makes this
problem hard let's let's talk about that
for a little bit well with something
like react and in real life you've got
you know one react node running on
multiple machines and you know those
machines are connected by networks which
you know I'll work with nodes and then
you have like you know timing issues and
then you have like you know how do you
apply load to the system and you know
what a lot of hard problems and well
who's good at solving hard problems what
would Captain Kirk to Captain Kirk would
change the conditions of the test well
we're going to try and do here thank you
I i I'm trying to play with the crowd
here I know what you guys like so what
do we do here well I tried to reduce the
scope of the problem and I tried to do
that by moving down into this
development release that we use for
react right it's this thing that we that
we try to give developers get them in
their hands as quickly as possible and
say look you can spit up all these nodes
on your computer
connect them all and never do that in
production but do that because you're a
developer well I'm a developer so that
works out for me if I can do this like
functional testing in a local
environment then I can get rid of a lot
of the the difficulty of the problem
right I don't have to deal with spinning
out virtual machines I don't have to
deal with configuring them I don't have
to do with the networking of them I can
just work on the actual functionality
that product and that saves people a lot
of time another thing I had to do is get
over myself like I just taken the OTP
Express course and you know when you
first take that kite when you first step
into OTP it's really kind of complicated
and intimidating and you know there's
always that moment where you kind of
start to get it and then you feel good
about it but I wasn't there yet and so
some of the projects that we had already
that were sort of half-finished were
very by the book and almost over
engineered for the process for the
problem and so I had that come just come
to this conclusion that I shouldn't
always focus on what's right I should
focus on what works because this is you
know this is a real problem i'm trying
to solve and I don't have time to give
you a dot every I and cross every T I
kind of gotta figure this out so you
know sometimes you just need to embrace
the tool you have so let's talk about
react test for a little bit because it
was this thing that was sort of out
there right and it was a simple
abstraction of react cluster functions
it was originally part of a quick check
test that there was written by Joe blom
stet who worse with us at Pasco it's
written in Erlang and I alluded to
before with The Wizard of Oz slide that
you know we were using Python before
nothing wrong with Python I personally
don't like it because I learned Ruby
first and there are two tools for the
same job in my opinion but we're an
erlang shop so anything that's not her
lying we're automatically reducing the
pool of test writers for for our product
so you know before if you wanted to
write an integration test you I had to
write it in Python and I wasn't going to
i will write these tests it runs on your
machine you can get it set up on your
local machine which is great because
with that without that you know there's
too much overhead and you know you want
people to use it and i'm speaking people
using it there you go people were using
it they were using this little
like rogue repo like you know checking
it out and using a pre test driven
development it really had no not like
this cult following but it was a
following and it really led me to to a
decision which is I had to embrace the
most important feature I had going for
me and that was a user base adoption was
gonna be my hardest task and people were
already using this thing so I'm just
going to take that and run with it so
that's sort of the background of the how
we got here but on let's talk about how
it actually works so so react s is a
ghetto and it's it's not really but you
know everything is a ghetto so react s
is a ghetto and let me poke holes in it
and tell you why it's not a traditional
OTP application but it doesn't make it
not an OTB application because it uses
rebar and app source and dependencies I
mean I'm not avin how to animal I'm you
know I'm civilized in this world of
relying so did you start looking at this
app and it gets sort of weird on what it
does because it's very procedural it
like you know it runs one thing and one
thing only it's we're living in this
concurrent world where everything's you
know all this things happening at once
and I'm like no one thing at a time only
and you know it's it's an e script I
mean who writes East grips anymore I
mean I don't know it was really annoying
for me to figure out how to compile one
so i guess nobody so let's talk about
how this thing works which I thought we
already were doing the East gripped is
this bein process thing right and it has
some kind of state the main the main a
process East grip thing you know parses
command-line arguments and turns them
into some sort of state data and how
we're going to do this test run and the
test Rudd has you know some data about
the environment itself you know what
what platform you are things like that
and also information about the test it's
going to run whether it's a specific
name of a test or a suite of tests so
we've got all this information in the
main process and once we start iterating
through a collection of tests a test
metadata you've had this a single object
of test metadata so let's talk about
what makes tez metadata it's pretty
simple
test metadata contains the information
about the test that we need to run and
some of that's really simple
straightforward stuff that you're going
to like like the name of the test right
that's that's easy what version of react
are we testing what platform we testing
on it perhaps the most important piece
of metadata that we're looking at is the
backend that our reactive is being
tested under we support multiple
backends and some features only work on
some of them probably the most prominent
example that is secondary indexes which
don't work on big cast so we don't test
them on that cast that would be silly so
it's important to know what you're
testing but how do we then get that test
metadata to the test writer well test
metadata is stored in the main process
like I said and what we're going to do
is we're going to spawn a test into its
own process we're gonna kick react test
into a received loop and then it's going
to answer questions about metadata but
that's just words so let's talk let's
talk architecture with boxes and lines
so we've got this main process here on
the left and its paws a test which is
this test process on the right then it
enters this received loop which
periodically gets queried right and then
once the received loop is over the test
is done and we go back and we do it
again for the next test it's pretty
straightforward so um I don't know kind
of looking at this and then let's let's
jump right to some code I mean the
receive loop is really easy right it's
see that receive now this is a received
loop the thread is terrible it looks
great on my Mac so this received lubes
just got this one clause and it probably
might not compile I'm not sure I got all
the trailing commas and stuff because
this thing's going to grow as we talk
but um it says the test process will
send this call metadata back to the main
process which is globally registered and
it will say like hey you know tell me
about your metadata and it will because
it likes to talk and you're probably
thinking to yourself now like why don't
you just pass the metadata in when you
spawn the process that seems like a good
thing to do well it probably is it's
probably a good better design decision
but it makes writing a test harder
because what happens is now you have
this method that we that we specify like
in the behavior
a test that is confirmed with era 20 and
you then as a test writer just write
this defined this confirmed function and
just start telling you what to do now if
you have to keep track of the metadata
object that comes in and then you write
these sub functions that are also doing
like little repeatable test stuff
because you're right good code you don't
like you know duplicate it you have to
pass the metadata into that and then
what happens if you didn't do that at
first because you didn't think you
needed the metadata but then you need it
later I'm taking all that stress off of
your shoulders and letting you just say
you know what whenever I need that test
metadata just ask the main process and
then I wrap that in a helper function so
you really just call like react test
metadata and it returns it for you so
that was nice of me you're welcome so um
you know there are some other cases that
we found that like eventually like a
test process might spawn a subprocess
and then that thing wants the metadata
but if you would go back to the slide we
saw that on the pit is actually hard
coded from the received loop because it
you totally know what the paid of the
process you spawn de is you spawned it
so just always send it to that guy but
then this test process sub-process comes
along and it's querying things and if
you just did that then it would start
sending with answers to the test process
not test sub-processes and that's not
what we want so we added this other from
this other clause here which basically
says if you give me a pig send it that
guy instead and this thing is usually
sent as and messaged as the temple
metadata itself no that's how that works
but otherwise it's exactly the same so
great now we're getting somewhere now we
have this thing that can spawn a test
and then you could ask the framework
about what it's doing if it needs to but
otherwise it just goes off on its own
well what good is a test you know
without our old buddy assert like if we
not assert this thing would just run it
would pass and then everything would be
fine but that's terrible I mean we want
it to fail if things go wrong so what we
wind up doing is we look at this unit
macro that exists assert and what we
find is that it winds up killing
processes and being like really
complaining when something goes wrong
and that's kind of cool because we're
already spawned in a new process but we
don't want it to kill all of react test
because of the first test and a sweet
fails we don't want it to abort the
sweet we wanted the answers about
everything so we decided to trap exits
for that
and we remember this diagram here now
the end of the test you know something
goes wrong lee assertive failure and
that pops back into this received loop
and it breaks us out what does that look
like looks like this we've got our we
got our two more clauses down here the
first one is the normal case both of
these are going to return a tuple of
status and reason if you notice the
reason for pass is undefined because
there's really no reason it passed just
passed because you know it didn't fail
but it's like you know it's like life
it's like the drama of the failure is
the thing that interests us so we're
going to send back this error message as
the thing that like is really important
and good to know so now it's great
because even you know even if I fail I
don't fail this thing is just like you
know my test prop my test engine goes on
and on which is great so um and you know
then we have this like trivial you know
the process actually succeeded and you
know it's still traps the exit reports a
pass but the undefined which is great
but it only tells part of the story
right it tells the part of the story
that is you know the boolean did this
thing pass or fail and maybe you get a
little lucky with like a like a stack
trace of an assertion this is why it
failed but that failure happens in
context and so we need to collect output
there it's getting so we need to collect
output so what do we do well like any
good bachelor employee I just use longer
and boy it actually worked out really
well for me so I hope you who came to
Andrews lager talk so we started off and
that was great right we use the logger
console back end it was just spitting
stuff out to the console and every run a
test and we'd see all the output and
we'd be so happy with ourselves to be so
verbose and we're so we're such good
test riders we deserve the day off and
we never got it so then what happens is
we decided that oh we're going to do
these like surefire inspired reports
right we're going to do a per test file
output and that's easy because we can
create a file back end for lager and use
that and name it with the name of the
test and everything's going to be great
and what we found was when we ran that
some messages were still coming to the
console and only most of them we're
going into the file but some of them
organ so they were there was like this
disjoint and what wound up hat what we
wound up finding out was that um you
know there were some buried IO format
and stuff and some helper functions that
we weren't going to go in and change and
we were making RPC calls and all that
stuff goes out to the console by default
so what do we do well we we wrote a new
group leader and well that brings up a
question right who is group leader and
what does he do well every airline
process has a group leader and that's
responsible for all the i/o for that
process and the cool thing about group
leaders is that it's inherited by any
spawn process and it's passed to any RPC
call so what you wind up what we wind up
doing is this this thing right here so
let me let me just sort of walk you
through this real quickly and this slide
should actually show up pretty well for
you guys there are equal signs there you
can see them now that they're gray it's
weird you can't see the red but the gray
is fine so first you have this group
leader function that's built into the
airline module and it's and all it does
is say you know return the group leader
which it did we set it to this variable
old group leader because we want we
don't want to lose that guy once we lose
that guy we can't output to the console
anymore i don't think i don't know why i
don't want to find out so which give him
up there then we create our new group
leader and we created this react test
group leader thing and what it does is
basically intercepts every i/o call that
comes into group leader and instead of
putting it out to the console just says
it's a logger so if you're using the
logger console back end it's still going
to go to the console and you get some
cool timestamps with it that's that's
like a bonus free time stamps who want
those and then here you call the group
leader function again this time with two
arguments the new group leader itself
and now we've reassigned the group
leader to our new group leader and we're
now writing wherever we told it to which
is a bunch of different places like
files and consoles and memory so then we
spawn the actual test and this what i
was talking about before the confirm
zero method that's just spawns the test
in a new process new group leader is
inherited by you know just because group
leaders are inherited by espanta
processes then we enter this receive
loop that you already know and love so
once that eggs is with status and reason
we got to be good citizens and clean up
and what we do is we restore the old
group leader to its rightful throne so
that looks all like that again so you
know some people don't like code so
we're going to do it in pictures really
quick you know your eye out for Matco
all we had caught by the group leader
which goes out to the console
then you change the group leader and all
of a sudden you're not sending to the
new group leader which is going to
output the lager because that's what it
does and then you know when you finally
you do some stuff and then you finally
decided to put the old old group leader
back its back you're writing out the
console again and that's great for
length of time in between tests when
react test is doing stuff and we kind of
want to know what it's up to so another
important thing for us to test is
console interaction like with the react
attached method that we have right you
open up an erlang console and then you
can talk to react with their line
commands and that's cool and but like OS
command wasn't going to cut it so we
used pork command so I don't know if
everybody knows what poor command is but
if you don't we're going to answer the
question who was pork command and what
does he do well first of all OS command
uses pork command so if you use dos
command you used for command even if you
don't know it so that's great but what
ports are for our communication between
Erlang and external programs through
binary messages and I'm going to show
you a trivial example of how a port
command can work just in the abstract
right so you've got these three lines
basically the life of a port command you
can open the port and we're using some
extra options here that OS command
doesn't use which you're going to be
allow us to interact with the console
instead of just sort of throw command at
it and wait for output so that's good
then poor command is actually what sends
those binary messages to the other
process and then once you send a message
you know depending on that was like like
a full stop that were a new line or
whatever and like console you actually
expected to do something you can just
sit around and receive data from the
port until does and you know the pattern
matches on this port from that port up
there and you know if the tuple starts
with data then the data is what you got
back so that's great it can also send
other things like process stopped ER or
whatever and you can do cool port matic
map mom pattern matching stuff with this
data block so it's it's it's kind of
cool but this is a complicated set of
things to expect a test writer to rely
on every time they write a test that
wants to touch how on test console
interaction with react so we we sort of
wrapped in something
i'm going to show you it now so we
created this RT attach a function it
takes two arguments and node is is
pretty clear it's just the node you're
going to run this thing against and then
command expectations is kind of an
interesting one and that's this list of
two tuples the the first element is
going to be either expect or send and
then the second is gonna be a string let
me show you how that works so this is
what that data structure looks like
right and so if you if you process this
correctly there like all sorts of a
certain stuff on time out trackers and
stuff under the hood so you know if this
thing didn't work but in the success
case how this thing goes is you know
first you run react attached and that
means that you're now expecting to see
this string control dita exit which if
you've started early ever you probably
know it so that we wait for that it
happens we assert the substrate contains
it does were thrilled so we move on to
send and ascend is going to send this
command to the Ryoka Tetch right it's
going to say react or ring manager get
my ring and they get my ring return some
kind of dicks right so if the output of
that returns something containing the
substring dicked and then
congratulations you've done it and now
you want to get out of this thing so you
just send this character for which is
control de which is how we exit and then
we track that at exited and that's great
so that's how we do console interaction
testing and it's kind of cool i
encourage you to check out the source by
the way the source for this is all
available react has public open source
repository yes I github Thank You github
com slash bash o / react underscore test
so um while we're on the topic of like
command line tools and interaction you
know let's talk about commands so people
have been worried about commands is at
least februari of 2008 it's you know
it's not a new problem commands bother
everybody so let's talk about the java
client test because that's going to be
sort of a good example for a couple of
these things so the java client tests we
started off with using OS command and
you know what we wanted to do is run the
j unit tests against react with the
actual running cluster in our react test
and that's great because you know what
outputs all these things to pass but i
want you to look at something and this
really bothered me and you can't see it
because this is
slide about something that happened in
the past but during the time it was
running look at those timestamps that's
like a two-and-a-half minute gap between
log messages like I don't know about you
but like if I run us up like a program
and it just does nothing for like two
minutes I start to get nervous so we
added we created this thing called
stream command which is just going to
stream output to you and what we did was
we basically said we want to hear from
you we want something spit out at least
once a second okay if you get a new line
and you want to send that great send it
i'll be happy to put it in the LAN lager
but if you don't do anything just dump
me a new line with the timestamp and
look at my time stamps now there's not
what there's not a one second gap in
there well I guess there is a one so
it's not perfect but it's enough that
you always know that it's doing
something and that's great because I get
really meaty when I'm running a test
suite and just sitting there and nothing
happens I don't know if I don't know
what's happening anymore I'd like to
know so now I know another cool feature
that we needed for the Java client was
java client test was prerequisites so
one of the things that we looked at with
the j unit test is how do we know this
thing passed well this thing passed
because it outputs this string 0 errors
well once you run a test that generates
ten errors and you see that that
assertion was dumb because 0 because ten
errors contains zero hours or failures
I'm sorry and you fix that problem you
notice something else there's that case
where you run this thing on a machine
that doesn't have Java and when you
don't have java installed the output of
a java command is never going to contain
the string zero failures it's going to
contain something like command Java not
found and if you dig into the logs which
we're logging now so we have all that
information and we have the context of
why this thing failed so even though the
error itself isn't really for both we
couldn't get to the bottom of this
mystery relatively easily but I don't
want I don't want to be digging for
mysteries i want i won't react us to
jump up and down and say this is why
this failed so we added this prereqs
feature and it might be hard to see that
but those are a module attribute called
prereq and the java test for example
requires java and curl so how does this
thing work well the first thing it does
is it goes through the module under test
and it gets all the attributes
the name prereq it's easy enough then it
runs this which function it basically
says okay is that available on the
system well it creates this sort of it
gives you a warning if it's not and it
creates sort of this list of you know
prerequisite presence pairs and I'll
show you those in a second then I'd
asserts that they're actually present
and we move on with our lives so what
does that look like to a react test run
well check for the presence of Java
checks for the presence of curl here's
the list of prereq and presence pairs we
see that they're both true so we go
ahead and run the test great so you know
that's great ever the success case is
the easy case right how's the failure
case look well I created this I ran it
again with this line added this missing
prereq line right and this thing can't
possibly exist if it does I well it
doesn't I'll just tell you that so
here's what the log output looks like it
looks for looks for job it looks for car
looks for missing prereq missing prereqs
not installed here's this list of things
you know missing three records false so
we're going to start chirping about mrs.
fruit missing prereq being Falls and
we're going to throw an assertion here
and you know true is not equal to fall
so we're done we're out of here we're
not even running the test and you know
why because you see prereqs everywhere
that word is you can't escape it so that
sort of brings me to a like an
interesting trick that we like to do
with with assertions and I found this to
be like a lifesaver because I come from
a job of background and in Java you know
every assert method has an era tea plus
one version of itself that takes a
message you can say like this is why
this happened or this is where it was
what it happened but i'll have that
inner line so I cheap because I cheated
everything so here's this classic assert
right you know you have this variable
goods ago which two slides ago we said
was equal to you know basically like a
list all true for this second element of
this tuple and so this is true then
we're good to go right so we assert that
but what happens when it's not true you
get this wonderfully cryptic error
message false is not true for good to go
great what the hell does that mean well
I can go to line 122 and find out but I
don't want to go to line 22 to find out
I want
to tell me so we see good to go that's
that's useful so we change the assert
right we assert that these two tuples
are equal and you know assert of all
prereqs present in all previous
president always going to be equal to
each other so you're so really only
comparing to a second two elements but
you get this great long message that's
like hey you know all prereqs good to go
all prereqs present true was not equal
to all previous president false and now
you know there's a prereqs issue so this
couple trick is kind of really
convenient I use it a lot see that's a
much more useful expression I think and
then Daulton things turn orange for some
reason so let's talk about reporting
because that's that's an interesting
problem too like like once you start
running these test Suites and you you
know eventually first we were doing all
to console then we were building these
local files then we were at least
outputting a summary at the bottom that
was like these paths and these failed
but you know it really we needed to be
able to see these results and so we
actually rolled this this reporting
framework called giddyup I don't know if
you can sow while you can see that but
this is the giddyup scorecard and it
provides a holistic view of release
readiness which you know I I love it I
love being able to look at this thing
and see like just based on how much
green draws my eye like how ready this
thing is to go and let me give you a
quick rundown about what all this means
because I feel like maybe the one
problem with it is that it needs
explanation columns are platforms that
we test on sent to us five I have a
pointer here centos-5 sent 06 fedora 17
freebsd OS x and then this the rows are
the actual tests that we're running some
of the more regression tests like this
some of them are like feature tests and
then you know the bubble green is pass
red is fail the letters inside represent
the back end that is under test so you
is undefined it means this test can run
with any back-end doesn't matter it's
you know command lines they run all the
time doesn't matter who you are Python
test required level DB requires memory
so those have specific back-end set
loaded upgrades the only one that's more
complicated it's got letters for the
back ends and it's got minus
1 or minus 2 there and that's how many
minor River minor revisions of react
you're going back to perform the upgrade
so this was a test run for 13 so B minus
2 is a bit cask run on react 11 and B
minus 1 is a upgrade from react 12 to
react 13 on big task that make sense to
everybody okay cool so this is great and
these platforms all exist in our data
center you know Jared put those together
for us and they're you know they're
really solid except sometimes when
they're not and I'll get to that but
this is great now because we have this
um where are these things running in
each platform and they actually send you
know you know payloads to giddyup saying
hey this test pass this test failed it
was this platform is this version of
react I can click Oh up there and say I
want to see the results for react and I
want to see it for 130 and that's that's
really cool but it doesn't tell the
whole story right or we're back at that
place where we had the boolean result
this has passed or failed so we want we
want more information up on giddyup and
how do we get it we created our own
react test lager back end which
apparently now I'm going to have to
update for lager 20 but what it does is
it's a logger back end is a gin event
and a gentleman has state so i just keep
every log event i get in memory and then
when i'm done when I'm done running the
test and i'm going to post the result of
pass or fail up to react test I also
send blog payload and what does that
mean that means when I click the button
pass or fail in giddyup it's going to
show me the history of that test run you
know if failed 21 days ago but it passed
16 days ago and 15 days ago but I can
click on this failure run and I can see
why and it failed because some thread
shutdown and some incomplete version of
a loaded upgrade test so they have
examples a little bit contrived but
that's fine I can see the logs and I'm
thrilled about it so you know I've been
talking about test suites for a while
and we used to just scan a directory and
say run every test in this directory but
that didn't quite solve the problem of
which back-end to run and stuff like
that so um you know we were thinking
about how we solved the test suite
problem and it really didn't take us
long to come up with the answer which is
we've already built this report card for
giddyup which knows every operating
system we want to test and every test we
want to run for this particular version
of this product so I can just do like a
a rest call to giddy up and say hey I'm
about to test some you know fedora 17 so
what should I test and it's like well
you want to type a soprano line but it
does matter what back-end you want and
you want to test the Java climb it
doesn't matter what back-end you want to
test Python but it matters that you use
it on leveldb and so on and so forth to
get this nice big JSON array of what
we're going to do and that's great and
the report card is also really the
schema for tests I mean there'll be some
differences based on platforms if you
notice freebsd here we don't have a test
for l minus 2 and b minus 2 because
react wasn't supported on freebsd two
minor revisions ago so there's no reason
to test an upgrade from that because in
theory nobody is upgrading from that
because it's not supported so that's
great now we can just ask giddyup what
to do and then tell giddyup when we
finished and that's wonderful so now
we're running these test Suites and we
kind of got to clean up after ourselves
between test runs and we do that by you
know returning to react to a pristine
State on disk between each run how do we
do that well we throw react Deverell in
a git repo before we start a local one
on disk and then we just basically run
these two commands between what between
between tests and boom every change we
ever made is gone so now we're getting
some complicated stuff and I'm to speed
up a little bit because I've been up
here for a while um we ready to race
conditions right we've got all these
wibbly-wobbly timey-wimey stuff where we
were putting all these sleeps in the
test and we were saying okay we're
joining an ode to a cluster and that's
gonna take a while for the ring to
converge so just like sleep for a second
and then figure out what you want to do
well that was great and it all worked on
your laptop and you were thrilled you
got working test and then Jared Brandon
on the Builder and all of a sudden it
was slow because the vm was waste lower
than your machine and everything failed
and everything fell apart because it was
waiting for things not long enough so we
added this wait until function business
and it's pretty cool so how this works
is
you know it asks a note a certain
question what's the question the
question is this fun so it asks the
question and then you know what's the
answer well I don't know here but we're
going to figure it out over here so if
it's true great we're done we're done
waiting we don't have to wait extra time
for something that might have happened
in a certain window we can just move on
with our lives now if it's not true what
we're going to do is we're going to make
sure that we're we're not going to retry
it anymore if we try 0 we just give up
and run this time out function which is
usually just return the atom fail but
sometimes it's really nasty and does
like kill nines so we'll just forget
about that for now and then you know
this other case down here which is there
are still some retries left and if so
you know we're going to sleep for this
this particular amount and then try the
whole thing again with one less retry
and these retries and delays are
actually calculated from a local
configuration file so you can like come
in with the knowledge that this virtual
machine is kind of slow so we're going
to give it more time to do things but
it's set globally for a machine and not
locally you know and so not locally to
the test so that's cool network
partitions what would how you test the
distributed system without testing
network partition so you know what I
learned from Captain Kirk well we can
use the prefix code to mess up these
communications between nodes and you
know in on notes the prefix code is
actually just the cookie so what we're
going to do is we're going to take this
cluster which is just a four node react
cluster and react test is connected as a
hidden node to all of them and reverse
the cookie on depp three and dev four
and then disconnect dev three and f4
from the other two boom now these two
the cluster is partitioned but react
tests can still tell them all what to do
and that's great because you can
actually still what's the other thing
you can do here you can actually re
reverse the cookie and bring the cluster
back together so you can heal the
partition which is nice so then there's
this thing called intercepts which is uh
it's pretty cool I'm oddly took them to
really fast because I'm running out of
time I think intercepts are basically a
Bach for mock without a mock framework
and we try to use mech but mech puts
everything through a single gen server
which with like a react get is kind of a
bad thing to do and causes other
problems so we just couldn't do that so
it basically creates a copy of the
module
uses the original modules of proxy and
then can sometimes call your fake code
to to create unconventional things so
you know I'm sitting here and I've
cheated my way around Erlang all day and
I'm patting myself on the back for how
clever I am and then I run into my melty
face mock moment which is the time that
I have to grow up and write some real
Erlang and that's my loaded up grade
test my loaded up grade test has to
spawn all of these workers against each
node in the cluster while it performs an
upgrade and what's happening is doing
ten of these supervisors and there is
spawning a test for each kind of thing
and they're all checking for valid data
and running assertions and stuff like
that but these things crash some time
because I'm asking them to do like a
whole lot and like sometimes the sockets
close or something like that and this
thing isn't really smart enough to know
what to do with it because it's just a
load generator so when the socket closes
and the process crashes I just need a
supervisor to just spin the thing back
up again and we'll try again and just
keep playing load that's what I care
about so it sort of ignores sort of
errors that don't really matter which is
great but it's like real real grown-up
Erlang so I'm like a grown-up now which
is just cool so this is a tweet I
tweeted out someday when I was writing
that test about how you should come here
and hear about why i opened up too many
file descriptors and that was all these
sockets that that test was generating
and there's actually some like
hard-coded thing in the bowels of the
OSX Erlang vm that hard limits you to
1024 file descriptors open at in a given
time but fortunately for me i had big
nosc in my corner it just was like oh
yeah just just type this one pearl line
and you know it'll read your config file
and all the sudden your line will be
great so you know props the big nos for
that so where do we go from here well
let's talk about how great we did first
this time around for react 13 we had
less people spending less hours on
released validation we wrote some test
framework that you know we have tests
for our Langer's by erlanger so we can
all contribute we're developing features
with integration testing you know
simultaneously and we're closed on
nightly validation and I'll touch on
that a little bit more in a second
because we didn't fail in some ways and
one of the ways we failed was that
release validation still took a long
calendar time well as people were done
it but it still took a while to do we
have a process problem that Knightley's
can't solve which is code isn't getting
murdered
to master soon enough to actually to
actually be worthy of running nightly
tests on so we have to solve that from a
process point of view it's not a code
problem performance testing is still
manual though gimme up is being adapted
to receive performance test results and
sometimes giddyup can cry wolf and that
might be like the FreeBSD you might have
noticed all my freebsd test passed
that's because they were running in
parallels in my local mac because the
freebsd as a smart OS kvm has some weird
io problems that jared is already fixed
but it was something that we were just
weren't sure we were unsure of was the
environment of the test so it was the
environment and that was good so here's
a short version right this is the best
release yet it's only going to get
better having a lot of fun with the
project a lot of people helped me work
on it more than this people so any
questions yeah so giddy up is like this
it's on Ruby web machine for Ruby and
because we deployed to Heroku at first
we didn't have the infrastructure to
roll it up on and the whole front end is
written up in amber right chris chris is
a big contributor to the front end of it
and it pretty much just yeah just sort
of lives up there and it just houses
this scorecard for us it was actually
born out of one of those things we liked
about a previous version of our test
infrastructure but we actually the funny
story is the guy who was working on it
went on vacation for like a week and a
half and it crashed and we couldn't get
it back up and had no credentials to the
box or anything so he wrote up a new
version of it while he was gone and then
we just that one took over anything else
yeah
if we do I didn't write it there was a
lot of porting going on from our
previous infrastructure so somebody
might have gotten something like that in
there and it can be done I just I
personally haven't done it but the
framework does facilitate that is there
anything else well we can do some of
that kind of stuff with the intercepts
and I haven't really played around with
that too much that was something that
Ryan's his desk he just swarmed in and
did because they needed it which was the
great part about working on something
like this with smart people as they just
come in and go like I need this feature
but there you go um so I don't really
know but that's the idea behind it right
that you can say like we're expecting a
get here but you know what we're going
to get return garbage and you just have
to deal with that and then we can test
to see how it handles it do we have a
time for anything else are we oh yeah
primer that's great is there anything
else I can yeah I tried it but I mean
honestly when we came into into this
situation what wound up happening to me
was that I got kind of overwhelmed with
the amount of frameworks available and I
couldn't really find good enough
documentation on common tests to dig
into it and get started because I had to
you know I also lived in the real world
where I had to start delivering but I
did hear some good things about about
common tests but I just couldn't figure
it out in time thanks
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>