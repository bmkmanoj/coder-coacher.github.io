<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>KVDB - A Database System for Configuration Data and Connected Devices - Ulf Wiger | Coder Coacher - Coaching Coders</title><meta content="KVDB - A Database System for Configuration Data and Connected Devices - Ulf Wiger - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>KVDB - A Database System for Configuration Data and Connected Devices - Ulf Wiger</b></h2><h5 class="post__date">2013-04-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/TEQL-ZQm-u4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay I don't really know what next
generation means but this was just born
so I think it is the coming generation
in that sense I work for a company
called for labs and so what we do is we
offer a service for managing connecting
connected devices and the idea there is
to bet on the the revolution that we're
about to see where to quote for example
the CEO / ericsson we expect to see like
50 billion connected devices by 2020
that just about anything that can
benefit from being connected will be
connected now obviously this is going to
create a need for solutions to manage
these devices in terms of configuration
monitoring software upgrades things like
that and and so our idea is to try to
come up with a solution that is hacker
friendly so that you can as an
entrepreneur at least that that would be
the the audience here right people who
get a device they want to get going get
a prototype up with their cool idea in a
day or two and hopefully then within a
very short time be able to demonstrate
end-to-end functionality with business
logic in the cloud software on your
prototype device and go to investors and
get lots of money so so we have a
software stack on the embedded side that
we call XO sense device and then on the
server side XO sense server and
customers can buy their own standalone
servers and run them or eventually we're
going to field a hosted
solution device management as a service
so and you know one of the challenges is
to be able to get good rate plans for
mobile communication things like that
we're also cooperating with with
solutions that can provide global
roaming data plans that are economical
things like that so our domain
automotive is one example of where we
have some initial customers and and so
far prototyping projects and telematics
is sort of the the word for collecting
data points from from the vehicles where
you would have a device a telematics
device inside the car connecting to the
canvas collecting whatever data on for
example battery performance or gps
waypoints things like that and then the
telematics server now we have a need for
a database in both in both ends I'm
looking at the coming slide on this so
on we're on the server obviously we need
we're aiming to handle millions of
connected devices so there we need high
volume high performance scalability
redundancy a bunch of stuff but we will
have fast fast disks and lots of storage
space of course on the device ID we have
small footprint usually a very good slow
disk we want to conserve energy and
there is no redundancy there is very
little concurrency
so it would seem like a stupid idea
right to use the same database on both
sides but there are actually some points
to it for us one thing is that some of
the features that i'm going to show you
we're actually using them both on the
device side and on the server side so we
are actually running exactly the same
code and that's quite useful so just to
summarize I will go through some of the
features of this and also tell you what
works and what doesn't and then I'll
give you a github repos and then you can
decide whether you want to use it or not
so KVD be was originally the working
name just key value database you know
very imaginative name it started out as
a thin layer on top of leveldb and we
were thinking that we would say Ron
leveldb on the server side maybe sqlite3
on the device ID and we wanted to have a
common API on for multiple back ends and
we decided that we're we're just going
to deal with ordered set semantics so
you can you can write new backends but
it has to be ordered set and right now
the backends we support our leveldb
through a level DB which is maintained
by basho and sqlite3 and at and we
support transactions so that we can have
a atomic commit and rollback and we also
have a special API with which supports
sort of a structured key abstraction
because when we deal with configuration
data excuse my husky voice by the way I
I gotta cook caught a cold a couple of
days ago and probably made it worse with
a few glasses of whiskey last night but
anyway the structured key API allows us
to deal with hierarchical data in a
convenient way and just about all
configuration data is is tree-structured
persistent queues because are the
devices we manage go offline and online
essentially what we one of the key
services we support is that if you from
your business logic want to talk to your
device you can send an RPC and we will
queue it and then when the device comes
online we will dispatch the RPCs and
then deliver the results back and that
also leads into needing some timing
services you may for example want to
push an RPC but you don't you want it to
timeout after 10 minutes or 24 hours or
whatever or maybe you want to have some
some scheduled retries or whatever so we
implemented some chrome like scheduling
features as well indexing is always nice
to have so we support that I'll show you
a little bit how about how the index has
worked and then just a few words about
the pluggable schema support so there
are a lot of advantages to just
hardwiring an ordered set assumption and
luckily with stuff like leveldb we can
now do high-performance ordered set well
actually we could do that 15 years ago
with I Sam files and but but anyway so
all the backend plugins have to support
ordered set
and when you create a table you can
specify how you want to encode the
objects and especially the keys and we
have two ways of encoding it either you
use sext which is a library I wrote that
allows you to serialize Erlang terms in
a way that preserves the sort order so
that means with sexting coding you can
use any Erlang term as a key and you
will get the the Erlang term sort order
on disk with raw well it's just then the
key has to be a binary and then you get
whatever your typical string sort order
so we all the objects are either key
value pairs or key attributes value
pairs and the attributes list is just a
list of key value pairs so we have a
table abstraction so if you use leveldb
that is your entire database and within
that you can you can create virtual
tables and and you give with options
actually we use the encoding option to
determine whether it's a pair or a
triplet that may not be so elegant but
it works and so then you can have for
example sext encoding of the keys and
you can have raw encoding of of the
value part or Erlang term encoding if
you want to well so if you have raw
encoding obviously you can only write
binaries to that that field
so leveldb is fast we haven't used it on
the devices yet but I know some people
actually do one worry we have is that it
creates a lot of files but that may not
be a problem are planned to use SQLite
well we ditched that pretty much because
it's so slow especially since we're
using we're actually generating SQL
queries I'm I guess there are low-level
api's but it was a lot easier to to use
the SQL interface to get it working but
it's dog slow so we don't want to use
that so what we did was we created an an
ex back end with transaction logging and
so you actually get persistency if you
turn on the transaction logging and that
seems to work reasonably well now
transactions they work fairly similarly
to an easier transactions where you have
the API functions I'm having hitting the
point on the database operations will
sense whether they run in a transaction
context or not but not like with necia
that if you use me xia read and it's not
within a transaction it's just going to
exit if you use if you're not within a
transaction it just writes directly to
the database we have two different
functions for transactions one is in
transaction that's when the one we use
most of the time it basically says I
need a transaction context for this if
the if I'm if there isn't already 1 i'm
going to create one but it will reuse an
existing transaction context if you if
you call KVD be colon transaction it
will start a new
action context so then it will be a
nested transaction if you're already in
one otherwise you get a you get a fun
and you provide a fun kind of like with
nisha but it takes an argument and this
is actually your database instance you
could say it's the the DB variable is is
a record that defines the database and
in this case it's a database where you
have a net back end on top of your
original back end so it's kind of a pair
of back ends so the ettes back end
doubles as a transaction store which was
actually nice when we were implementing
it so one thing that I think is a bit
original and you don't want to do this
in an easier for example is that you can
actually pass this transaction context
to another process and it can operate on
your transaction store so we're using
that too for example if we create a user
in our system and we want to populate
certain devices we have some security
checks in there so that you cannot
perform certain operations unless you
are actually signed into the session
manager which is a separate process so
then what we do is we call on the
session manager to authenticate the user
but of course the user hasn't been
committed to the database yet so then we
pass the transaction store and it reads
the transaction store and and and create
a user session and that feels fairly
early now obviously or at least right
now because we're not actually using
locking yet and working on the lock
manager and I'll get back to that so you
have to be a little
careful with your concurrency but
normally in this case for example we
just do a gin server call and then we
wait for it to do its thing and then we
get control back essentially and then we
we can continue we can continue with the
transaction the kV DB comp API uses
structure structured keys where we use
an asterisk as a delimiter and we have
functions to kind of like with a file
name API you can split and join parts
and create create or inspect keys and
there it also uses escaping so if you
would say you would have a device name
or whatever that happens to have
asterisks or any other funky characters
that we don't consider then we will
actually escape them in a way that
doesn't break the sort order now this
also allows us to use first and next in
the database so that you can actually
skip over an entire subtree so you can
traverse a data structure at sort of the
same level in a tree because with the
escaping we will know for example that
we can use a just attach a character
that we know is greater than any valid
unescape or escaped key character so
then we can just jump over a lot of data
we also have functions for reading an
entire subtree and then sort of
replanting it under a different route or
in a different table I have an example
there it's a bit small text
but not there we're starting kbd be i
open a nets back end that's nice
especially when you do demos now so now
it's ran only because I'm not logging to
disk or anything i write a few key value
pairs here or keys where one is a star
ones are x and bracket that actually is
a net com style list or array so you can
have if you have leaves that are
basically anonymous then this is a way
to to store them in the tree so then
obviously i can i can read back an
object and here you can see that it
actually sort of normalizes that index a
little bit but i can also read an entire
tree if as I read everything under a it
will give me a configuration tree record
with the root and then everything under
the root as a tree structure and if I I
can for example shift the root up and
down in the tree if i want to or i can
just say right tree and provide another
route and then i will get the same sub
tree but some someplace else in the so
we use this for example when we want to
push configuration data to add to a set
of devices so then we take the
configuration data and we put it in a
cache a cache table so we just read the
tree and just put it in a cache table
together with reference counting for
each device and then as they we get comp
we can contact the devices we will just
take that cache object and then we use
the same database on the device so we
get the structure and we just
put it in the in the table on the device
site now the ques so when you create a
table you can give it type FIFO or LIFO
if you want to what happens when you
push an object to a queue is that it
creates a special key using a micro
second time stamp so you get the objects
in in insertion order and then you can
pop you can you can peek into the queue
you can list objects in the queue you
can also hide objects in the queue if
you want to that they remain in the same
place but you just a toggle a flag so
they become invisible in and you just
skip over those if you want to push your
punk or pop objects you can also create
a cue that's keyed fifo for example then
it will take the the object key and put
in front of the time stamp so then if
you pop you it essentially becomes a
priority queue so it will it will take
them in key order and insertion order
and of course this also means that we
can we can store timers we also there is
a there is a server that that sets
Erlang timers basically uses this
persistent queue to sort of pop the next
time out or look at the the next time
out in in order and then set an erlang
timer if it's too far away it will set a
timer to just look again and set a new
timer until it's close enough to
to actually reach the time in within one
erlend time out so we have a library
called k vdd chrome where you can add a
timer and then we have a little grammar
where you can specify how long you're
going to wait and also if you're going
to have a repeat timer how many times
you're going to repeat or repeat until a
certain deadline and then just put
function to apply here i'm applying a
test function which is sort of handy for
testing that the timer's works where the
timers work so in this case it fires
three times with three-second intervals
that's what that means and just to
illustrate the timer timer expressions
you give a time spec and then a repeat
expression and until expression or you
can just simplify it so if you don't
have a final time you don't have to add
that or if you want to be really lazy
you can just add a number and that will
be in milliseconds so for example you
can write in two hours three minutes and
two seconds and then repeat until 1845
and and you have like daily weekly
monthly last day a month I don't know if
anyone can think of other useful
schedule expressions we can certainly
extend the grammar
so the indexing essentially you index on
the attributes or on the whole object so
you give an option where you and a list
of the attributes that you want to index
and if you just provide the name of the
attribute then that the value of the
attribute becomes the index value if the
value of the attribute is a list then
you can use for example each so you say
the name of my index is skill and each
element in the list of the skills
attribute is going to become an index
value or if it's a string then you can
just create a word index so as an
example say I create an object where you
know a person object with some skills
and and tags I can do an index get and
and find the find the object so the one
the variant I didn't show here was that
you can provide a callback function that
can either get the value of an attribute
or the entire object and then calculate
a list of index values so it's it's semi
tricky to index a tree structure where
every leaf in the tree is a separate
object in the database so then we use a
callback function that for example
inspects the key to see is this a namely
for or whatever type of leaf that I want
to index and then it can emit an index
value otherwise it just emits the empty
list and and the leaf is unindexed so
that that seems to work fairly well
so you you provide a schema call back
and right now it's it's a schema
behavior has four callback functions one
is validate and that is called first on
for example if you want to update an
object first schema validate is called
and it's supposed to return a new object
so there you can modify the object or do
type checks whatever or insert automatic
attributes if you want to have vector
clocks things like that on update is
after it's written where you can have in
this case what we use what we do is put
when you push something to a queue we
emit an event to trigger the dispatcher
if it goes from empty to non empty and
also we have pre imposed commit so still
a lot to do but we figured it's time to
publish it because we feel it's pretty
useful the big thing I think is to
integrate locking and until I have
locking integrated I don't think it's a
great idea to run this well actually you
can't run it distributed because it
doesn't have replication and things like
that and you may want to think about the
use case if you have a lot of
concurrency a lot of people hitting the
same data you may want to wait for the
locking to to be implemented or you can
just write a schema plug-in that uses
some some other locking I i'm going to
you
make the locking a separate library that
is useful in its own right and also for
for the distribution and recovery I'm
going to implement log merging we
probably will implement support for
geographical redundancy things like that
but where we're doing it in priority
order for us so for now we can actually
get by without the locking and one
little safety feature is that commits
are serialized the database instance
process is sort of a synchronization
point for it commits so you commit one
transaction at a time to to the backend
and this is also a synchronization point
for for log switches if you have the
logging turned on on the ETS table you
can set a log switch threshold where it
will start on a new log file and it will
also take a snapshot for example of the
of the table a reasonably similar to how
amazing a dis copies work and I think we
will support a couple of different
distribution patterns now so we're going
for consistent or transaction
consistency here and one problem there
is is to come up with a good just to
distributed locking algorithm that
doesn't limit scalability completely an
easier for example solves the deadlock
detection problem by using deadlock
prevention which scales reasonably well
because it doesn't have a central
dependency graph but you get phantom
deadlocks and transaction restarts and
since you have transaction restarts you
cannot do what I did in a previous slide
where I passed the transaction context
to another process and things like that
you cannot do side effects inside a
transaction I want to do side effects
inside a transaction we do lots of side
effects so I want to have an algorithm
that does scalable deadlock detection
and basically aborts on deadlock because
there should never be a deadlock in a
well-designed system I think so I have
an algorithm for that I actually wrote
it back in 93 when I first started using
Erlang and I needed a distributed
database I didn't actually finish it but
I I did design a locking algorithm and
then chided myself because if I had just
bought a good book maybe I could have
avoided three days of headache and
trying to think it through but then I I
dusted that off a few years later and
Thomas arts and I Thomas who is a
partner in cubic and quick check expert
and also expert on formal verification
he actually did model checking on this
algorithm and tuned it a little bit and
showed that it was both sound and
minimal actually so it scales well the
so I'm in the middle of rewriting it
because I needed to make the lock
manager a little bit more powerful for
example since we have tree structured
data I want to have tree-structured
locking so that you can go in in the
middle of a tree and lock a subtree for
example so it's essentially in
that of just being table an object
locking it's a generalized heart go
locker with read and write locks so the
the idea this is a cooperative locking
algorithm that depends on the locking
agents that the transactions being
essentially actors who can talk to each
other I wouldn't want to implement this
in any other language than Erlang
basically but but it works well in
Erlang so the idea is there was
apparently animation here I thought that
I had turned that off the idea is that
the lockers will not just say if you had
a lock or not it will actually return
the queue of all transactions that are
waiting in line for that lock usually
that's probably a list of one but if for
example in this case transaction one
holds lock a and transaction for is
waiting for it and transaction three is
holding Loxy and am waiting for e for
example so and this is a deadlock
situation but but none of the actors
have enough information to actually
detect it so what they do is that since
for example this transaction knows it
has a direct dependency or for has a
direct dependency 21 and of course we
know that for knows that because it's
also gotten the wait list and I have a
dependency 23 so what I do is I inform
transaction for of this lock that it's
not involved in so it's kind of like a
fill in the blanks algorithm and if you
do this in the right order
we'll with a minimal amount of messages
eventually get to the point where one
transaction has enough information to
detect the deadlock and in that case you
can either just surrender a lock to to
another transaction so that it can
complete but in in the case of KVD be I
think the right thing to do is to simply
abort so it will support both modes and
I'm also going to try to use this for
example in in jeep rock because it
occurred to me that you can do leader
election this way if all instances just
grab the same lock usually one will win
I mean there will be a deadlock but it
will be resolved so one will come up
with a lock every time and and you can
also then all detect partition networks
that way so you know that you can resync
so it's coming and it's not coming today
or tomorrow but eventually let me
that's what you get when you copy paste
they think you actually want all the
animations as well there we go so that
locker library is going to be called ddd
hasn't been published yet but it's for
distributed deadlock detection and the
idea is you should be able to use it
also say you're using react or something
you should be able to to use this I hope
in a fairly scalable manner since it's a
protocol based fairly well contained
locking algorithm and I'm building in
coram support the things like that so
that you can for example require locks
on a majority of of replicas things like
that but working progress so this is
where you'll find it for labs with a
capital F doesn't matter to http but it
does matter to get kb DB and it's an MP
l2 point 0 license and that's license
we're going to use for our open source
stuff and we chose that partly because
we do want people to contribute back so
this is similar to the Erlang public
license but it is it's a nose I approved
license so it shouldn't be a problem in
that sense it is also prepared to be GPL
compatible which we also think is a good
thing so it should play well with your
proprietary software it should be able
to play well with GPL software and so we
think it's pretty good license and any
questions yes
I'm gonna try or well in jeep rock yes
that's my I'm going to try to do that
and if it works out well then yes but
yes
oh oh I'll sit down and meditate over
exactly how that how to do that i think
i ieave I thought I figured it out but a
few months ago and then I kind of
dropped it and I've had other things too
so I don't remember exactly what it all
what it was that I figured out but I I
think it will come back to me so yes it
uses distributed Erlang I've thought
about making that optional but I don't
know for a while I thought that you know
if we if I specify it as a protocol that
is that's not Erlang centric you could
possibly use this also in cross-language
environments but it's let's say that's
not a priority it's enough of a headache
to to get all the pieces working
together so yeah it's going to use
distributed erlang for now any more
questions do it performance numbers um
yes equal light it just sucks it's I've
done some performance measurements I'd
say I haven't spent a lot of time trying
to optimize it and especially not say
for simple transactions on a ram only
database I did a test where I was doing
the same thing in Neesha and the
transaction startup time in kv DB is
significantly longer than
nessa so for simple stuff where manisha
fits well it is definitely faster the I
have prioritized functionality I don't
know how far I can optimize those things
but we've focused on some other things
for example the queuing system the idea
there is essentially we have one output
queue for every device and we plan to
support millions of devices so creating
a new queue and pushing an object into
it is dirt cheap so some things are very
scalable and and very cheap other things
maybe not so much so for example there
are some some fairly cool things you can
create tables inside a transaction and
populate the tables and then commit it
all but that also means that it needs to
check sort of pull the table metadata
into the transaction store and things
like that mmm it's some so that's an
area where i could optimize a bit but so
but no the getting top-notch performance
has not been our priority so far so we
follow joe armstrong's advice and make
it as slow as we possibly can okay the
the trees where were they oops sorry
the trees are represented by with the
structured key so every leaf in the tree
is a separate object so the tree
structure is in the key and this is one
area where you really want the ordered
set semantics because to read a subtree
you just basically go to the top and
then you just next your way through the
tree and you just you just write an
object you create a key that represents
the leaf and you you write it no so the
I you can do similar things in in
ordered sets for example that if you
have a structured key so the root is
here here's the root and then star and
then the next one and it will actually
sort so that all the three objects will
just be laid out so if you if you walk
say you go to a star one and then do
next you will actually find this element
so you can and if you want to skip that
subtree what we do I think we put a
semicolon after after the star and
that's going to be bigger than any any
key part that is an actual subtree
object so then you just jump to the next
sub tree or out of the tree entirely so
this is where ordered set semantics
actually works really well
yeah did you have a question too excuse
me how do you oh yeah yeah that was this
option you have an index option and then
you list your indexes basically name the
attributes or name sort of the the index
and then refer to the attribute and say
what you want to do with that attribute
so that's how you that's how you do it
another thing that we're trying to do is
I started looking into it with is to
integrate egg xpath because if we if
you're dealing with netcom for XML
objects you can fairly easily store
configuration trees this way and xml or
net comp uses xpath for to refer to
nodes in the tree so XPath is the query
is a query language for xml documents so
I'm going to try to add xpath support to
as a way to to query these sub trees
any other yes so for one thing you can
you can use side effects inside
transactions without losing your sanity
that is now with necia there is actually
a patch that Erlang solutions and I and
klarna did to me Z aware we added back
end plugins so for example leveldb was
one back end supported and there I also
added similar indexing capabilities so
you could have indexing callbacks and
things like that so with that actually
the the difference is smaller but I
didn't see that patch in our 16 be so I
guess if you're interested in it by Don
Goodman's on a beer or two and get him
to actually release it klarna has been
testing it and it seems to work pretty
well so but other otherwise you could do
a lot of these things in easy as well
the the reason why we didn't pick nisam
is that if things go well for us and we
grow to really huge scale we pretty much
know that necia is not going to stay
with us we know what what pains we're
going to have to suffer so at least now
we're in we're inventing our own
headaches which is a consolation but and
but we did discuss you
museum quite a lot and all the device ID
I don't know many CS is actually pretty
cool so but for us there it was a matter
of being able to reuse code and eating
our own dog from this well</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>