<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>An Evolution of a Betting Engine at William Hill - Peter Morgan | Coder Coacher - Coaching Coders</title><meta content="An Evolution of a Betting Engine at William Hill - Peter Morgan - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>An Evolution of a Betting Engine at William Hill - Peter Morgan</b></h2><h5 class="post__date">2015-11-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/111WyW3yFGQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Peter Morgan I'm from William
Hill I'm gonna talk about an evolution
of a betting engine that we have been
building in Erlang I'm head of
engineering and I'm also a head of
research and development so part of what
my team is doing is looking at different
ways that we can build systems that we
currently have within William Hill say
William Hill we have around a peak
around four hundred and sixty four bits
per second being struck in the system we
have about 160 terabytes of data that
goes through our networks on a daily
basis and we're also at 24 by 7 business
we don't have much opportunity to
actually shut the system's down we trade
globally the other interesting thing is
that our prices change we have around
five billion prices changes a day that
doesn't sound like a lot and I know if
you're doing high frequency trading and
things like that you're kind of thinking
well we do that in a femtosecond or some
other amazing number so this is betting
it isn't high frequency trading five
million for us is a large number the
only thing I will say about that is that
a lot of those price changes will happen
in in a 90-minute window because they're
their football price changes and they're
also affecting a large number of bets as
a result so what what does it look like
this is our bet stream it's essentially
five seconds of our bet stream and it's
a visualization that we use it's visual
this jeaious that we're actually using
here and it's taking a stream of bats
from William Hill on this was Saturday
and you can basically see a graph of
what bets have been placed by by our
customers in that five second period and
what you've got is a different hierarchy
of bets so you can see a customer
in yellow you can see the actual bets
they're placing which are the blue
circles and then you can see the the
actual selections that customers are
betting on so many clouds mod Royale
these are all the different selections
that customers are placing bets on and
we can basically run this stream live
and it's a great way of explaining to
people the kind of complexity of the
data loop that we have so you can see
this is essentially betting on horse
racing you can see all the customers who
are betting on the the Fortuner weather
B and you can see all the customers
who've placed the bet on on many clouds
so this is a dynamic structure that's
being created it's really for
visualization it's purely so I can
explain to my manager that this is quite
hard because it's quite hard to explain
otherwise but we also print out t-shirts
so if you want a t-shirt later on Gavin
is got the t-shirt so you can see bets
on the rugby union this was before the
Rugby Union final on Saturday say I
picked out some rugby bets buts rather
stupidly I didn't pick out any of it
what I need to do with the actual rugby
union final but you can see a cluster of
rugby union bets here you can see that
people are betting on rugby union aren't
actually betting on on other kinds of
sports and this person down here is the
only person who's betting on tennis
so it's interesting from the perspective
of how the customers bet and looking at
the kind of topology of the bets and
again if I didn't explain it very well
yellows the customer blue circle is the
bet and then you have selections and
they're different bits of our hierarchy
now the interesting bit is this bit here
this is football and the majority of our
business
like most gambling companies the
majority our business is football so you
can see a bunch of bunch of bets here on
the European major leagues here you can
see where is it they're a bet on the
next five minutes so we have lots of
very ephemeral markets so at the moment
we are we are four five minute markets
we're looking at ways that we can offer
Minik markets the customers say who's
competing to have a red card in the next
minute those kind of things
so when we combine the price changes
that we have together with the
availability of markets that we have
typically on a Saturday we have about a
hundred thousand markets four hundred
thousand and we're looking to get it to
four hundred thousand it's it's pretty
large you're thinking about football in
Solem out accumulators so here you can
see a single bet and as I'm highlighting
them you can see the variety of
selections that that it affects so when
I talk about that five million price
changes if it's an accumulator that that
can be affecting a lot very large number
of bets so the five million is
multiplied by another number which I
can't tell you so that that's that's
what our structure looks like and again
it's it's a toy it's just to show people
what what things look like so a little
bit of context cuz I'm guessing
everybody's placed a bet today nope so
where does this kind of fit in in the
whole piece so a little bit of our our
sort of terminology we talk about
placement we talk about resulting and we
talk about it settlement and pretty much
in that order
so policeman is going to our website for
example say here we are on a horse
racing page placing a bet on on our new
website we also have two and a half
thousand shops so our customers can be
placing bets in our shops at the same
time so writing down their their bet on
the bet slip and then handing it over to
the teller and for it to be to strike
that way then after your bet is placed
we allow you to cash that bet in so you
might have changed your mind
so we offer to buy that bet back or you
might have win one a little bit and you
want to cash the value of some of that
of that bet back so we offer that as an
option and one of the things that we
need to be able to do is revalue the the
price of those bad
so again those five million price
changes effects elections which affect
the the actual bets themselves then the
next thing is resulting so resulting is
really simple whore sex selection has
actually won the race or lost the race
and that's the input that goes in to
settlement and this is what we all want
to see a nice big case of cash so
settlement is paying out the customer
paying out their winners with the
winnings to the customer based on the
results that have been declared so where
do I was talking about the fact that I
had up there at the research and
development team one of the areas that
we're very interested in the moment is
around the customer experience so we're
taking his input prices and results
we're looking at bet placement and we're
looking at settlement and it's all
centered around the actual customer
experience one of the key things that we
want to be able to do is keep customers
in that loop be able to keep them
notified as things change so as your
horse comes in for a win we want to be
able to tell you that and traditionally
at the moment bookie peers of very much
it's a pull you if you're sat watching
football on a Saturday you've got an
accumulator you're sat you actually
updating your app you're having to ask
William Hill or whoever your favorite
company is what the status of your
betters and what we want to do is turn
out on the head and make it more of a
push so for example everybody's got an
Apple watch watch whatever was supposed
to call it now what we want to be able
to do is push push data out to those
devices and actually tell you this is
the value of your bet this is the status
of your bet this is this horse is one
this horse has lost
would you like to cash in at this value
all these things very much push run pull
so what what does that look like well
scary very very general sort of terms
very 20,000 foot 30,000 foot foot high
level starting right to left let's go
most of what we do is feet driven and by
that I mean that we have people in this
very stadia actually keying in the score
as the score is placed actually keying
in the fact that Rooney has kicked the
ball towards the goal is an actual
message that comes into our system if
you're a tennis fan then the umpire is
actually keying the results in on a
keypad which goes into whatever one of
our computer systems so we get fees of
data from various different providers
they go into our global trading platform
that global trading platform then talks
to a number of trading models which are
basically statistical models that are
basically analyze the market and then
determine our current price and they're
also increasingly simulation based so
what we'll do is we'll play out a
football match from that point have a
million simulations of the football
match depending on who's winning in
who's losing as a result of those
simulations we then have a price at the
top is is omni-channel so that's our
language for a better strike on an
online environment or in our retail
environment and then the key areas that
I want to sort of talk about today are
around the betting engine itself so this
data is fed into the bit into the
betting engine and the four key
components of that are bet capture
accepting that bet cash in being able to
price that bet so you can then cash it
in settlement when the results come in
we can actually pay out the right amount
to you and liability which we're quite
interesting because we want to know how
much we've got to pay you and then sort
of as a couple of examples we've got
some streams that come out of this
system and this is very much a stream
based system so we stream out results
from the betting engine we stream out
into analytics and wallets as an example
so what do they look like
so this is our bet stream so it's the
same stream that you saw but it doesn't
have the pretty graphics and essentially
is a URL that you can curl it's a server
sent events stream which is kind of the
unloved child a WebSocket but it's quite
nice because you can just curl it
it's nice and simple it presents a JSON
based object that you can just connect
to it's actually I think one of the more
useful things that we've probably done
in the last couple of years is just
being able to present our bet stream in
a way that has no ceremony whatsoever
you can essentially use a stream in in a
variety of different applications so you
can see here a bet that's been placed
for 10 pounds and you can see the
various different categories that that
bet has been placed on then the output
of this strip of this bet engine is
another stream and this is our bet
pricing sorry this is our settlement
stream rather so this is as selections
are resulted what we do is we look at
the bets that are actually affected by
that selection resulting and then you
can see the the current price the value
of that bet one that is won well it's
lost
well not it's unsettled well not it's a
refund and again it's it's a really
simple first system that allows us to
then compose other applications on top
of these streams and that's kind of a
theme if that I'm trying to get across
here that we're trying to do minimal
ceremony for these these kind of systems
and what we what we are thinking about
are ways that we can then join these
streams together to produce further
applications from it so another stream
that we have is our cash in valuations
this is a lot more chatty usually
although it's stuck right there for some
reason I don't quite know it's a lot
more chatty essentially whenever a
whenever a price has changed then what
this is doing is recalculating the value
of the bets that are affected by that
price change and what we want to be able
to do is take this stream and feed it
into other systems or take this stream
and feed it into something that goes
onto your watch one of the key
components that we're looking at for
this is Apache Kafka I'm trying not to
say it's a nice because it's not an ESB
at all in any shape or shape or
imagination but you can consider it as a
as a distributed replicator commit log
service so it's really really dumb it's
really really fast which is really
really cool but it's also sort of our
mechanism
to get persistence because a lot of what
I'm talking about we're gonna do in
memory and rely on Kafka to actually
replay what we're doing so in general
terms we see activity going through
Kafka and then product that we can that
we can build from that and in this case
if we have a stream of both bets prices
and results then we can generate streams
of output which are settlement and the
cash in valleys and in another case we
can take the output from settlement and
feed those transactions into a wallet
and we're using Kafka as our persistence
to essentially persist any transaction
that comes out of the system into Kafka
and again we could use another stream
which is our liability so if you take
different streams of data we take our
bet stream our settlement stream and our
prices and we can produce liability so a
bit more detail about our bet engine and
how we built it and the kind of problems
that we've had we've we've built the
system in Erlang it's a pretty small
team that's built it four or five people
it's being rewritten about five times
and about once a week normally is about
our normal iteration at the moment which
is it's good I mean it kind of proves
that a lot of what I think is good about
Erlang that you can basically proof of
concept sayings very very quickly build
things and actually test them out and
one of the cool things is with the
streams that yours that you've seen
they're all production streams so what
we can do is we can run this system we
can the AP test it we can run against
the current system we can run against a
system lumber building and we can test
it against the the rewrite that we've
just done this week so the main areas
that I'm talking about today and
particularly around caching and
settlement what do we build well you've
seen the stream you've seen the stream
go into Kafka and then you've seen the
the the vis Jess sort of visualization
of that that's pretty much what we're
building our link you can think about
all of these pieces
as a process and that's that's the first
iteration that we took say I love this
diagram I think picture I think it's
it's a great one to sort of represent
each individual process I lock in front
of it you can't touch it state each
mailbox has got a mailbox where you can
put the mail into and that's pretty much
the way that we have modeled the the
initial version that we built and the
way that we did that is traditional ITP
mechanisms nothing exciting nothing wild
we use Supervisors we use were workers
and we also considered but we haven't
done is using mechanism of distribution
within Erlang we're not actually using
that but it was another rare area that
we thought we might be able to go say
the great thing location transparency
you ever send messages to a process and
get it to settle another sort of ethos
that we've had is our volumes aren't
that big
the high frequency trading guys you kind
of really it's not that big we we have
some our bigger transaction days we
might be looking at make gigabytes of
bets so it's very much something that we
can fit in memory so I saw this slide
earlier today I think it's a great slide
what we were thinking of is really how
can we make this system fast and then
what we do is we use Kafka to provide
some of the resilience for us so what
we've tried to do is keep everything in
memory as much as we possibly can and
then rely on on another system so we
rely on Kafka to then be able to replay
the the system say if we have a crash
when you really play from Kafka and a
lot of what we've done is basically
trying to ensure that the system is able
to restore itself quickly after a crash
so the basic concept that we had was if
you imagine a a horse racing event
Lester at 3:30 we have a wind market we
have a horse called fat SOTA which never
wins and a whole bunch of bets so that
the
attached to it and if you think about
the Grand National it's the big race of
the the supporting calendar the number
of processes attached to that selection
could be quarter of a million it's it's
it's large numbers that we end up
getting to and the basic idea that we
had was that when we had a result come
in to say that that that particular
selection had won then it would be as
simple as sending out a win message to
that process or if the price of that
selection had changed it would be as
simple as sending a pricing message to
that process and that's essentially
though the way that we built the the
first version of the the system some
tuning that we did is we had some
horrible results to start off with
transparent huge pages and they just
don't work for the kind of systems that
we're building so one of the things that
we end up checking is our transparent
huge pages enabled for you really want
to make sure the square brackets around
whenever it's not going to do it
essentially what you'll see in your
system or what we observed was that
you'll have great transactional
attributes of the system and then
something bad will happen and it will it
will effectively stop it almost looks
like Java another thing that we found
really cool about this this way of being
able to layout the system because
everything is a mailbox it's really
really simple to find where that where
the blockages are so it's basically hunt
the queue and we've got various
different utilities within the system
that allow us to lurk a monitor the
metrics of the queues within the system
and essentially a lot of the cheating
that we did within the Erlang system was
really just finding those bottlenecks
and you find them through a few queues
we got awesome concurrency as well with
this model this was within an hour of
having access to this machine it's a 32
CPU machine no changes to the real
underlying application at all because we
start a very large number of processes
typical or in Grand National we might be
looking at six million processes within
the VM and we just see 32 CPUs just
lighting up I name
it was free well nearly yes so there was
some stuff that didn't work so well one
of the biggest issues that we had is the
inner line message passing is process to
process
there's no broadcast and that doesn't
matter when you're sending tens or low
tens of thousands of messages but when
we're sending a very large number of
messages so the example of a very
heavily backed selection if you have to
send two hundred and fifty thousand
messages to another process from that
process you very quickly find that a
line conspires against you say it will
start deep prioritizing that process
there's workarounds that you can do you
can set your priority to be high you can
send the messages and set your priority
back to below but it feels like we're
breaking stuff that we shouldn't be
breaking so that's one of the things
that we observed one of the things that
we but led us to dislike this this
implementation the this a version of the
implementation we also found our memory
kevin's consumption wasn't too bad
grand national six million bets about 40
gigs of ram not huge but it felt wrong
it felt like we were doing the wrong
thing because the actual process memory
was the main consumer of what was going
on so it was another thing that kind of
led us to a different way of thinking
about this system another issue that we
had was we were spawning lots and lots
of children and we were churning those
children and one thing that we found is
that having a supervisor with a very
large number of children 200,000 plus
then when you're churning those children
and it's the combination of those two
things it really doesn't perform and we
were finding a lots of issues with the
system being slow as a result of that so
we did a bunch of techniques we've we've
shouted supervisors we've done all sorts
of things but again they feel like we're
working around really things that are
design issues with it with the way that
we've built it
another issue that we had and we love
Jeep Rock G books great you can kind of
register things and it doesn't have to
be an atom which is kind of important if
you've got 250,000 of them to register
we use we use Jeep Rock a lot
unfortunately the underlying
implementation of Jeep Rock uses ordered
set and the combination of register and
unregister in G Park can also cause
problems so it's a really cool paper
down on the bottom most scalable ordered
set frets using our adaptation September
2014 I think it was which basically says
don't use these and unfortunately
ordered set is the thing that Jeep Rock
uses and it very very quickly stops
scaling when you've got the situations
where you are you're churning these late
these large number of children so that
was that was an issue that we fell into
quite quickly we also had another issue
where we're reading these streams and
these streams are json streams and one
of the things those streams are doing is
they're they're living for a long period
of time because the whole idea of the
stream is it's a long live connection
and part of the problem is is that the
little bits of json are less than 64
bytes and if they're less than 64 bytes
then magic seems to occur and it's not
the kind of magic that you like so we
ended up doing things to the garbage
collector which you know we're not doing
java we shouldn't need to do these
things so we ended up doing a full sweep
after five on the on the processes that
are reading from from the stream so long
running processes that don't do very
much apart from cut-up binaries and then
send the binaries to somewhere else not
great so we had a moment of clarity and
thought about this a little bit
differently we we talked about it for
for a little while maybe as much as an
hour and then started to hurry right and
so we we started thinking about things
well maybe if every concurrent type of
activity was a process that's maybe
that's a better way of modeling this
so we came up with this wonderful thing
called bet flow which is the current
implementation I'm smiling so much name
and again very very high level very high
level generally we have a we have a
change that's going through the system
so that's a result change let's say and
you have a series of steps so we can
declare in bet flight that'll allow us
and the the circle is representing the
process and the idea is is that we end
up having a process that that that
handles that change and it's not a
long-running pursue on running processes
that's doing it that actually represents
the the entity itself so for a result
change excuse me we find the effective
bets and we then resettle them as a
process and then that process dies for
price change we do pretty much the same
thing
find the affected bets and memory and
memory price them and it's a process it
lives and then it and it's gone and as
I've said we used were you shouting for
supervisors one of the things that we've
also done is we use charting for the ads
tables so in order to get the level of
concurrency that we want so when we
change from a concurrent activity no
longer inside the the process what we're
now doing is with persisting our state
inside out so keeping it within memory
but instead using outs to actually
persist that product that data so the
price range comes in and make the price
change we then persisted into inter wets
the usually that we found there is that
again you have to shout out so the the
general metric that we've used is a for
each core we have a shard and that was
very very scientific not at all
didn't seem to work another thing that
we did is because of the issues that we
found with our they did with the large
number of children that were churning
within a supervisor we switched
supervision away from OTP to use bash a
job instead and that seems to be working
pretty well for us and it's quite a cool
library
so this was this Saturday we had we have
price changes here on the on the on the
right you can see that we have 500,000
price changes pretty much from about
nine o'clock in the morning where we're
pretty seriously getting load what we
consider to be serious load and then we
have up to a hundred thousand bats in a
thirty minute period and the cool thing
this version we're using a huge one and
a half gigabytes of RAM I mean that's
HelloWorld in Java I think pretty much
and we're using 500 processes and that's
nice and steady there's a lots of very
ephemeral processes that have been
started and stopped but it's nice and
flat and we're we're pretty happy are
they the thing that's growing
we know that's growing and that's bad
but the reason why is because at the
moment we're not terminating our
children because that's evil and so
instead at the moment yes tables are
growing so that's the thing that you're
seeing that that's growing what we'll do
is over a period of time will then start
killing those children which always
sounds wrong generally we're pretty
happy but if we're pretty happy that
means we're probably doing something
very wrong so we're talking about how we
do it next so we're talking about a way
that we might be able to do this as a
hybrid so we're there are various
different attributes that we've seen of
one of the systems that would quite like
and there's other attributes that we
like from the other system so I think we
were probably presenting in six months
time the third version that we end up
with which is going to be a little bit
different so once took a little bit
about how we how we build stuff and how
we ship it this was the quality metric
at my previous companies it compiled
shipment we use docker if you don't use
docker use docker
it's it's trivial I mean if you've got a
relic script then that that's your
release your release is underscore ell
you build from a from an existing
container you expose some ports and you
have an entry point and if you're using
a long release process it's it's simple
you just build a release and some of our
containers are unique maybe a couple of
tens of megabytes it's they're tiny it's
it's really cool use docker nothing else
just use docker don't worry about
anything else so what we're looking at
is how we can scale this system and we
see Dockers mechanism us being able to
both horizontally and vertically scale
this system which is all very well and
great bad things happen
so there was a fire in Gibraltar not so
long ago
Ian's flat weather your faith say a.m.
there was a fire in Gibraltar it took
out the I think the one and only paid
power station in Gibraltar which is
reassuring and most most stammering
companies were affected by this which is
not good so obviously we don't want to
repeat that so one of the things that
we're looking at is how we can use Kafka
to actually do that replication for us
so what we're thinking is data center
data center data center and we can then
have settlement running in as many
locations as we want the great thing
about settlement is anyway results for
four races re declared so settlement has
to be able to it to be rerun so it's
something that is very much something
where we could actually think about
having competing settlement engines so
who might use Kafka to partition the
load in different ways and have
different ways of doing that so we're
thinking about how we might want a red
carpet certain customers go to these
particular systems other customers go to
different systems it's certainly
something that we could do with it with
this kind of technology and use Kafka to
kind of help us split that split that
load up within the within the actual
data center
elephant in the room nobody talks about
this so I get this asked once or twice a
day why not a car on the JVM so um this
is a true story because they're always
more fun and I it shows that things go
wrong as well as they go right and I
think when things go wrong it's more
interesting than some amazing syntax and
stuff like that so this is our system
running normally we're we're using what
gigabyte of ram at peak we're probably
trending up from birth up towards 500
megabytes let's say and this is our
price changes and easier price changes
are pretty much flat so the load is is
normal and everything looks good we went
home literally an hour later this this
is exactly the same graph but the
problem is that we're now measuring
hundreds of gigabytes of RAM and so the
the previous beautiful graph that I had
there has now completely disappeared
because it's no longer in the scale at
all and this was a pretty scary moment
because nothing's changed here you know
the loads the same these are the graphs
but they're all the same
pretty much the input has remained the
same not two minutes and then we've
nothing nothing's really changed so
what's gone on so there's an awesome
awesome awesome book Erling in anger
stuff goes bad Dhaka
Erlang in anger two things read it it's
great and we use as part of everything
that we build our our stuff ships of
recon because it makes makes this stuff
simpler and so yeah the great thing is
that we can SSH into the VM so we've set
up all the VMS that we
that we deploy one of the things that
docker makes hard is had you actually
connect into the system so one of the
things that we do is we expose an SSH
port so we can SSH directly into the VM
so we get a command line straight into
the VM and the first thing that we ran
was recon foot count I'm lying so much
when I said the first thing we ran in
retrospect the thing we should have run
first was recon program but we didn't
but anyway let's pretend we did and the
cool thing about Recon proc can't you
give it a list and there's there's ten
more of these and it's ugly Eiling
syntax but on that it's fine but the
cool thing that you get out of this is
you get a pit so five three five one oh
two is important and this is important
this is for in a bit gigs of data in one
process that is not good and we've got
ten hundred of those going on it's it's
the reason why we're using that many
gigs of RAM
but the good news is it tells us where
are we bet calc and it tells us you know
we're where we started so things were
literally on fire somewhere I'm sure and
what we did is we reran recon trace
calls we told it to trace back calc any
function any arguments and then here's
the important bit the pit and this is
cool
yeah I'd love to know languages where
you can do that because this is a system
that is dying it's about to crash and
we're still able to log into the system
we're able to determine where it's
failing and to me that's that's killer
so this is the trace and there was you
know megabytes of trace that's that's
flowing past so this is loaded up into
my trusty editor than one and only true
editor we could see no and then you can
see the bet ID and the other interesting
thing from this trace is we can see the
index is 26 a lot of the bet cottonmouth
math is around permutations and
combinations of bets and that's the
thing that costs
and that's the thing the cost of memory
so we can see the bet ID we can see the
the the index of the bet which tells us
how big that bet is and so the next cool
thing that we can do is we've got an API
within the system we've got a shell into
the system or sshd into the system it's
on fire
but we can still ask the system what's
going on so we can look up this bet
within the system and we can find that
it's actually an accumulated 25 but we
had 26 selections coming in which was
important because here's the settlement
code obviously I have to kill all of you
after showing you this but anyway here's
a settlement card and you can see it's
an accumulator it's of this size they
settled we have underlining settlement
functions for the different BET types so
settle straight-line is one of the BET
types and you see here here's the
settlement for an accumulator where the
size of the accumulator is not the size
of when the size of the number of
selections is greater than the actual
size of the accumulator which meant that
we were in this function here and if you
know anything about betting then you
know that that number 2 is wrong and
essentially what we were doing was
generating combinations or from two up
to 26 so that number should have been n
now recon didn't tell us that but it was
pretty easy for us to get to that point
to work out that that was the thing that
was wrong and 20 minutes later we had a
test case and a day later we had a a fix
and a day later we had something that
was using not how many gigabytes of RAM
it was it's now bytes so were a lot
happier said to me this is one of the
killer reasons to that to that question
it's not about the code anybody's
written airline code knows it's not
pretty it's not sweet it's not as nice
as a scholar and half a dozen ton
language but to me it's not about that
because it's all about the operational
support this
if you're a developer the thing you
worried about is the phone caller three
o'clock in the morning and that's to me
is the killer thing for 480p and I like
is that when things are going wrong
there are tools within the system that
are there
and they work and they've been tested so
you get built-in tracing
we've got a utility library that we put
in everything or utility application we
put in every single app that we deploy
and that allows us to SSH directly into
the VMS which if you're on a docker
engine then it's it's painful to get in
directly
it's more painful than it should be so
it means that we can SSH SSH - P and
then the port that we want to go to and
we can go straight into the VM and then
the other cool thing is obviously with
the shared nothing architecture it means
that crashes are really easy to
reproduce so you can basically replay
the same today replay the same message
and you're good so that's me
thank you very much for your time thank
you very much for listening we're hiring
which is such a surprise isn't it if any
of this is sounded interested
interesting headon or if you just think
we're mad which probably equally
interesting for me and then I'd love to
talk to you but if there are any
questions and please feel free
oh hello greetings indeed it's okay
thank you very much
was it good awesome okay that's cool are
you doing similar things or are you
that's a shame anymore you mentioned how
easy find real-time diagnosis of systems
I was interested what we do for testing
obviously showed us one buggy had there
which maybe he could have been found at
a small scale by much more interested in
like a full scale integration testing
type things you do load testing D do
other types of integration in full
system testing and because I'm trying to
work out how we're going to do full
system testing and load testing so we're
looking at so the question is how do we
do testing so bet calculator it's it's
heavily unit tested it's hundreds of
unit tests but the problem with that is
that there's millions of combinations so
we have looked at but haven't done
anything with yet proper quick check and
they're the obvious things so we build
the types and then we were type
generators from that and then we build
our build our test cases essentially the
way that we work at the moment is build
unit tests CI the CI then deploys two we
have two identical hardware platforms
and we have two variants of this system
the two that I talked about today and we
essentially run those two in parallel
and then we collect data the graphs
using were from elasticsearch we have a
another library that we use that
basically pokes data into elasticsearch
so what we do within our systems we we
register things that we think are
important so the number of bets and our
transaction as the number of price
changes and we graph those so all that
all the things that you saw were graphed
through that
system and that's basically sending HTTP
requests to so elasticsearch and that
allows us to look back historically and
historically sometimes at previous data
good do you have some sort of way of
identifying suspicious market behavior
such as
a huge birds that might influence market
or things like that so one of the things
we're really interested is
identification of strange bets yeah
so we those streams they get fed into
this system this system is a not a
system that we want to be able to do
that kind of analytics on so what we do
is we then feed that into Apache spark
and then we then build systems on top of
that but then look at suspicious or
different behavior and it's quite
interesting to identify some of those
behavior we had a case quite recently
where a large number of people were
miraculously betting on the correct
score for a game in Australia in the
northern territories and yeah look that
what we're trying to do is identify
those cases and identify where that
where that's happening and we're looking
at technologies like spark to be able to
do that not specifically you know like
yes yes yeah yeah any more over there
last one
oh yeah thank you no I died already know
anything about betting tall but I do I
know that sometimes he's got uh
something to do with statistics and
people say that a Lange is nobody is
slower numerics
so did you was that not a barrier the
settlement that we're talking about
sorry it's really a multiplication and
an ad and if Ellen can't do that then
it's well yeah it can the Miss
reassuring isn't so the mathematical
modeling that I was talking around our
pricing that's done in Java so the
pricing systems are built in Java the
the actual settlement of the bet
building up the combinations is is
probably the most strenuous bet and then
the actual calculation itself is fairly
simple oh good thank you very much thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>