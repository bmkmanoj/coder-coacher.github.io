<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory 2016 SF - WIND  a System for Management and Orchestration of ... | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory 2016 SF - WIND  a System for Management and Orchestration of ... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang Factory 2016 SF - WIND  a System for Management and Orchestration of ...</b></h2><h5 class="post__date">2016-03-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/fkQm16juRZ0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm sure kim lien working at the exxon
research last year Joe Armstrong came to
me and asked me and said you have been
working with a line so much and doing so
many prototypes nilan why don't you sort
of tell the rest what you have been
doing don't you have something that
you're allowed to talk about so okay I
said I presented wind this wind system
at the airline user conference last
summer and then Francesco ask me can't
you do it at their long factory as well
and do you have something else to talk
about so I will talk about wind and I
will also talk about Artemus cloud
simulation tool where you can simulate
their millions of active entities so
okay what is a distributed heterogeneous
cloud them yeah you have a club with a
lot of different data centers connected
to each other so you can have big data
centers really big data centers you can
have small data centers or you can have
really tiny data set maybe we'll one or
ten up to 10 machines sitting there and
all of these could use different cloud
operating systems or cloud stacks like
OpenStack cloudstack opennebula not that
used any longer or it could be yesterday
I provider they're sitting there so now
having that you need to manage and do
placement and so on of all the resources
you have there when things coming in to
this system we different the cloud
services that you normally have so in
win this orchestration so this is a
simplified architecture over this system
down there you see the different kinds
of types of cloud execution environments
you can have you can have OpenStack
amazon web services vmware leave it or
whatever
on top you have the dental crustacean
system and that is built up of a number
of sort of core services and that is
what you expect to have from n any cloud
service it could for network storage
compute and image services you are also
for identity now that's little bit more
complicated when you have it distributed
and different other cloud stacks that
you're working me working with because
you have to handle different kinds of
identity systems below and this identity
service also had to take care of that
you have a uniform and present uniform
identities towards the tenants inside we
also have a sort of intermediate level
services like a scaling service so that
you can scale out and in your service or
you can scale up and down things we have
trigger service that can trigger for
events that happens that could be part
of a fault management system and so on
and also the scaling service you have
local location service that is you want
to have you have an application and they
have clients coming in in the disputed
cloud they want to be able to know okay
this client comes here where it's coming
from where is the best locality for me
to route this client to that could be be
for a video conference system one client
comes in here and you know where do I
have a media server or something that
can this client can connect to so they
will get the best user experience and
that service will help doing that on top
of that we can have also have higher
order things like an orchestration
service where you can take combined
things of entire descriptions of it on
an application with all the compute
networking and storage and scaling
descriptions and feed that into this we
have also other services like SLA
service where you can see
do you fulfilled certain contract it
will create the format for the
application based on SLA parameters that
could instead of saying that I need to
have five VMS for this you can describe
things like oh I need to be able to
process this amount of requests per
second using these software components
having blueprints or of certain
applications it can configure out and
say config oh you need to have five VMS
and so now i said this is a
heterogeneous clock that means that we
need to be able to use different other
sir platforms below and above that is
that it's fully plug plug in here so we
are plugging technology that we can
adapt the interfaces both southbound and
northbound to this so we can present
this system wind can present itself with
its own api's we can present ourselves
as an OpenStack system or amazon system
also and so on just adding plugins
everything is built on restful api so
that you can devise these services they
are built separate and you can then use
each other easily they can be
implementing different language if you
like we have full multi-talent support
and also important here all applications
can use all the api's that we have and
that gives your powerful ways for to
develop your own applications if we have
an API internally that it's useful for
us that might be useful for the
application as well so we put them in in
there okay now if you look at this
picture it looks like the adaptive
northbound interface and soft bun
interface are separate components yes
and no what it's actually having is that
they are existing on each service we
have this adaptable thing
okay if we now go into just briefly to
some of these different services and how
they work or work some features they
have now these are work that I had
started like six years ago so some of
these things that you will see now oh
you will answer ask why why don't I
haven't you used heat like in OpenStack
and so on they didn't exist when we did
this so of course a compute service in a
disputed cloud suddenly location becomes
very important where do you place a
certain resource that you want to have
but it's not only your graphic a
location that you can specify here it's
also other things like give me a place
within this certain latency from this
clock this client or and so on so
different kinds location is way more
than just the geographical location now
if you go to a network service the way
we describe networking normally if we go
to white border and say oh we have this
network what do we do here we draw a
line then we draw oh we add things to
that say oh this is this is what we have
this is the how the world looks like yes
and this is the simplicity we would like
to have in this kind of system you
should only be need to specify this this
is the network you would like to have
okay yeah but if we add context to this
mmm suddenly it became very more much
more complicated now we can see that we
possibly couldn't realize this by adding
some tunnels and to sort of lay to
overlay three using gateways and so on
but this process should be totally
transparent from the tunnel they should
only see the network like they would
like to see it and if we have a
different context
like oh it dist is just a latrine
network yeah then you can envision that
we have have to configure some routers
maybe add some firewalls and so on so
orchestration service yeah they exist
now you can find different ones although
there didn't exist when we find this
what we call them in our service
containers it's a description of an
entire service you have this trip it's
fully paralyzed you can define different
objects that you need to have that could
be these objects to be servers port
networks and so on you can define
temporals order between objects when
they need to be created and so on but
the parent depending on networking I
said but we can also describe scaling
scaling rules how these should scale
over time depending on load and so on
and it could look like this in a JSON
simple JSON description we can specify
different kinds that okay we have some
server it should be placed in monsey
also known in San Jose or install and so
on and then we see that okay just create
reports okay connect the server 1 and
server to server 32 these ports and
create that Network now it happens to be
laid to network oh it has to create the
infrastructure with these tunnels and so
on or whatever technology we have to be
able to deploy LA to network over the
globe the scaling service spades on on
rules that you define set of rules that
are templates for how you should scale
it a certain application and how to add
or remove the infrastructure resources
or add like more memory and so on or add
more VMs or containers whatever they
will define the limits for this
application if you can have a minimum
number
or maximum number and so on it the
application will have full control over
the api's over this scaling so you can
either have the add the template how
scale you should be done and then the
application can itself say initiate okay
scale up or scale in because it will
have the knowledge or you can add also
specify different metrics having this
platform itself do this for for you but
there's not not all application that you
can do this automatically especially not
for scaling in that might be very hard
we had an example with that we built a
video conferencing system it's very easy
to see when a media server something is
overloaded so that you need to create
more of them so that we can do
automatically but it's very hard to know
when can you remove brings a media
server because we did today's protocols
they're so efficient with sending over
video and audio so when I speak one of
the clients doesn't speak nothing is
sound that means that we have no network
traffic so oh we have no network traffic
we can remove this no we cannot this the
Sailor session going on there the
application of that that is easier for
the application to initiate oh I know
not know nothing is you know sessions
going on on this media server and we can
remove it okay so here's scaling rules
are fully parameterised you see we can
specify things like scale-out scale in
and so on triggers different kind of
triggers depending on what kind of
metrics we will use we have a template
error we come back to that we have
notify we can tell who to notify when we
have done is change when the this rule
has been triggered
and that could be for instance load
balancer needs to know that now we have
added more workers or something like
that going back to the template the
template it where you describe the
object kind of object or resource that
you would like to create and here comes
the thing that it's good we'd use having
be using language like airline for many
years I've been doing functional program
for more than three decades now and then
you always thought you always think
recursively and you things with
operators that are closed using on close
work and so what if you have this
template it's not just a vm here or a
network what if it's a scaling rule that
will open up a lot of power in this
scaling system suddenly you can have a
scaling rule that is parameterized that
can create scaling rules that will scale
other things and we use this in this
example of a video conference system now
we could have a scaling rule that could
create entire clusters with different
machines VMs there some could be media
servers and that scaling rule had
metrics to automatically monitor this
cluster and each cluster could be
specialized through the parameter set to
which location it should be at how many
nishal instances it should have and so
on now you just instantiate such a
cluster when needed and that the
application did know that and now we
could automatically do this scaling on
that cluster for them the creates very
much power most scaling system there
today when you look at them oh you can
specify oh I want in another vm or max
this number of VMs or maybe you can
specify some kind of metrics also so
here comes in when you have this always
thinking of recursion and so on that
adds and tremendous power
okay if we look some closer look to some
experience from juicing sort of airline
in and developing things here so this
wisdom and some other here when you
decide things like here the the plugin
wind I designed the plug-in system here
it's good to see how do you do it
normally in a line when you do like y en
service how do they define them do it
similar so that you have similar kinds
of ways to call things ways to to them
and now the absorbent we will see that
okay well immediately breaking that
normally you say start and stop here we
have load and unload but you design the
things like that and today a lot of with
this agile programming you have an
tendency also to sort of that says that
you should only implement the
functionality needed at the moment yeah
here I saw that if I do this slightly
more I can do this generically and we
can use this in many applications and
that you have support for then in
dialing in the OTP system because you
can implement this as an application and
then you can reuse it in other
application as well so with these
plugins you define them you have it's
very simple behavior load or unload you
defined all the functions that you would
like to have in such a plug-in they need
to take an extra parameter state if they
can be defined sort of preload when
you're starting or when they were first
used and so on and each will have a type
I will come back to that why that's
important because like it as it looks
now it's sort of oh but why don't you
just you
SE model a module and function parameter
and use that instead but it will soon be
clear why nice so the PM is the plug-in
manager for this it does the sort of all
the management of plugins it makes sure
that the plugins in loaded when it's
needed it's thread safe here and that's
very important so that execution of
user-defined function the functions that
we have any plugin is always executed in
the process of the caller it's not in
the plug-in manager and the plugin
manager doesn't have any workers and so
on you you have support you can add in
ask for a name so the name of the
plug-in to invoke or a type of a plug-in
and there are other search function to
get out sets of plugins and I use this
to build more complex selections with
rappers like the European the wind wind
plug-in manager it's doing a
location-based look up of this remember
that this was a distributed head renal
system you have different cloud stacks
on different places that means that you
have different software that you need to
be able to adapt to and now i can have
code that doesn't know that it we are as
you say i wanted a plugin of this type
and it will look up what what are they
actually plug in for that type on this
note and the system will automatically
do that for you so that's why you don't
say module based and function will have
this going by type instead i also have a
dream that is a dry manager certain
plugins you only want to have one
instance of like most in time for a
database so that is Taylor for doing
that more simple some simple code
snippet
and this is from a compute the compute
service the compute servers have no
knowledge whatsoever how a vm is created
it creates a local token that the local
token is is how to authorize yourself so
it's an authorization token that this
I'm allowed to do this at this Sun and
then it just invoke the server create
function in the compute and we look for
a compute plug-in and we provide a set
of arguments for that and it needs to
know the local talk and the server
flavor an image and it has no knowledge
what will happen this could go now to a
liber8 call or it could go to plug in
for OpenStack or something for amazon so
we can eat it without changing any code
here we can add as many things as we
like another thing that we developed in
this product was aired it's a alling IPA
api to leave it so it's a one-to-one
mapping between all the functions in
Liberty leveraged is a hypervisor
adapter for different types of
hypervisors it's a briton see it has a
lot of functions and it's depending a
lot of callbacks so you add callbacks to
to this here it has full support for
this callback functions and it baits on
another component that we developed it's
a synchronous and synchronous port
driver it's to simplify right in these
kind of or connections there are other
existing libraries for doing connecting
a line 22 and foreign language this is
based on the porch person that you can
have but it has makes it very simple to
write bridge between a lying and C or C
you're a line
it's very simple to use and it had full
support for callback functions you can
write your callback function in a line
and add that as a call back to see
function and it whenever that function
calls call invokes that callback it will
actually invoke the Allen function it
also had a lot of convenience macros
simplifying writing the code and it has
support for logging from both ends now
that technique when testing of course
I'm using air unit and in this system
wind we have built it such a so that we
can test from any level and any level we
start from the bottom it will test all
the thing functions within that level
and then the level below as well and I
said we are building on rest well things
and when we are calling on the
southbound we will do a HBase call to
another CloudStack most most of the
times okay that means that we will do
some kind of call to HTTP client and
that we normally call eyebrows an eye
brows plugin that would make the actual
request now if we just add and change to
to usin em pull plug in emulator there I
can have an M emulated that emulates an
entire cloud fully distributing and
everything but is just emulated here
this means that i can have right test
that tests or everything all
functionality here within wind without
actually having a cloud so they can be
part of the basic unit tests here so it
makes it very simple
another reflection when you're writing
things with with Alan you use a lot of
processes that's sort of its xochitl to
use processes in a line but sometimes
it's really paste to think about what
processes do you have and what are you
using so in this we are using yours as a
web server and yours spoons of worker
process now it's designed now so
everything as much as possible is done
in this worker process to handle a
certain requests and all the requests to
the other process that we have is made
so they should be so very short and
simple as possible and then you can run
a lot of these requests at
simultaneously so you shouldn't create a
lot of process just because you can you
should carefully think about what your
process you're creating doing that you
risk less deadlocks it's very simple I
can tell you give you one example when I
designed this plug-in manager from the
beginning I had a restriction that no
plugins could do calls to anything else
except sort of 22 whatever system it
needed downward to go to external things
then I relaxed that and immediately I
got a deadlock bang the system didn't
work that what one path ended between
all the things was actually calling then
back to the plug-in manager so that's
when I made it tread safe removed
everything because i had worker
processes in the plug-in manager and
suddenly yeah it was waiting for an
answer it has a was serving one of the
messages to receive and was trying to
show that when it got another message
to the same thing so you have a deadlock
you cannot do anything it really care
you have to carefully think about that
okay I said that i'm going to present
something new as well and this is the
artemis that simulation tool that we are
done for cloud simulations and why do
did we do a simulation tool for for
clouds yeah we have been working on
placement or scheduling algorithm uted
clouds so that's sort of part of a
continuation of the wind work where we
were looking that we didn't work
anything about placement and so on we
had a very simple scheduler there now we
want to do to solve this problem because
it's basically most other ways that
exist today they cannot deal with this
it's a real hard problem you want to
play something you compound thing on a
lot that I think most other ways they
can do that in a cloud where you have a
couple of thousand nodes after that you
will not have that mean real time the
answer so we want to affect that so we
have been working hard with that and
although our managers are often very
generous they didn't want to let us have
a million machines I don't know why but
they didn't and if you're working on
small test beds physical test beds even
if you're working with get it also it
doesn't it's not enough because you can
have a brute-force algorithm test that
and that will do great on those machines
but when you go to ten thousand machines
it breaks down so you can get very
inconclusive results from that you don't
know if it's good or not so we needed a
simulation to
ok now the existing press emulation
platters don't work for these kind of
setups for cloud there exists platform
this cloud seemed and so on that often
use but their run in one machine you
cannot give them more resources they can
handle this a couple of thousand
simulation entities so so you cannot
work there are the existing tools they
have a similar problem now what we did
then was ok and this is also something
that you should really think about when
you're designing systems is that ok we
see we have a problem we need to have a
simulator for this so we started to
design a parallel simulator and
distribute simulator so we set a couple
of sessions workshops and designed
everything got to know exactly how to do
this we didn't write any not not a
single line of code but we designed it
what are the problems how do you do it
what do we need to work after that then
we start looking out ok have anyone else
solve this problem Oh unless we found
one we found Cindy ask oh they have done
this in airline good but why did I say
it's so important that you try to design
this first because now we understood the
problem now we could see what were the
pros with Cindy askah but we also did
could see immediately what was the
concert what did we need to fix that it
couldn't handle in the in the right way
so and that goes for anything else that
you are using if you don't sort of have
expert knowledge already so you know
exactly try to design it yourself first
on paper not fully but so you really
understand the problem then you can look
go out look what have they done because
then you know what you want to buy ok so
this sweet as I said it's built on top
of Cindy askah it inherits all the
scalability then from airline and Cindy
Oscar
it can you can add more if you add more
resources you can do great bigger
problems we can handle millions on
simulation entities and these are active
simulation entities running code and we
can handle hundreds of thousands or the
events per second we provide in this
templates and models for specifically
target for the cloud and the reason for
that is that we want to have it help
developers to focus on what you really
should do evolution modeling or both the
available resources workloads and so on
experiment and development or strategies
for all the problems that we see within
the cloud so you should do that without
having to do any kind of plumbing
there's a lot of things if you want to
have a meal data center or a distributed
cloud with millions or entities that's a
lot to connect and figure out this
system should do it for you and you
should be really simple to describe this
so quick overview what we have we have a
sim desk in the bottom we have a common
layer that fixes some of the issues we
have with Cindy asca what it doesn't
provide it also provides some other of
the necessary functionality on top of
that we had sort of the resource plane
where you have models for the different
kinds of resources you have cpu storage
memory whatever resource you can do how
you make connections between different
nodes models of fault we can emulate say
that ok this CPU will crash in this with
this period you see or dis likelihood
and so on or you update this machine
with more memory at
is paired and so on and so forth
different council model for these things
how you can assemble things into
different groups like racks pods and so
on we have another thing is the
consumption plane that describes how the
applications that we are simulating how
they should evolve during their life
cycle when do they start when they do
stop how much load do they have it June
certain time periods and so on that on
top of this is the control plan that's
where you dude you the most work
yourself where you have to add your
algorithm for instance when we try our
placement aguas there is where we place
that cannot go now so that's what we are
feeling into it and then we get out sort
of description of you usage statistics
and so on now one example here this is
amount of code you need to write for
doing this is a describing setting up
but just with a cloud with half a
million machines and so on with certain
models or all it's more or less a use
this model use this model and so on this
number we run this on five machines in
our own lab and this simulated 24 hours
of traffic or and everything in the data
center and it took less than 42 minutes
and in that time we had between 10 and
50 thousand events generated every
second during this 42 so it's pretty
good you think
yes but that is always in a discrete
event to simulate you have a different
clock time here you have it yeah yeah so
that's that's you have support for so
from the applications point of view and
everything it took 24 hours but
executing this to just 42 mins or yeah
Marla's and if you have really good
questions about this you have we have oh
not here in the back he knows every
detail of this okay some possible use
cases that you can use that yeah as I
say Molly large-scale cloud dynamics how
to do service placement in in Los cloud
dynamic resource management justice few
examples of what you can do these kind
of system
yes so we come to test like we're doing
placement you have a compound service
you have all the components the similar
to what we described with the the
service containers that we use in win
you have all these things with affinity
rules aunty affinity Rosie look at
geographical location how much memory
each VM needs or container and so on
everything how they should be connected
we feed that into our placement are ways
that we are testing it will try to find
so we can test how does it work with
doing this and now we we have series of
where we gin randomly generate different
kind of these descriptions and we feed
them in to the system and they exist to
over sometime they have certain
characteristics over that time and so on
and then we shake how how does this work
right when we're running using how well
does this al wit work no no it does in
this case it uses the models that we
have
yeah if you have if you have if your ad
bad bad models you will get bad results
that's true for every system nothing is
better than the moment you have for it
yes sure but that's yes that's doable
yep I can go to this line because we are
already there oh yeah initial for this
autumn is initially we have plans to
release that as open source then we
showed it to the upper management and
yeah and they found that mmm okay this
is too good so at the moment and we try
to tell them yeah but the important
thing is the models not the tool itself
so we said but there no currently
currently it's no
yeah yeah some of the other components I
started the process last year on having
some of them released as open source
it's going slow some of them are yeah
that's one of the things i have started
to see if i could release windows open
source but it's it's a slow process
unfortunately some of them i thought it
would be easier to do but I some of them
I had to to work really hard myself in
order to get things happening and I'm
sort of very busy at the moment
fortunately but there yes it it does
weigh more than OpenStack does or in
summers other things OpenStack to us
that we haven't addressed yet we could
add them as two services of course but
it spans over and tied huge set of data
centers OpenStack is a CloudStack
working for one data center wind could
be running as a cloud stack for one data
center as well that would be quite easy
we just need to add some more code for
it sort of more how you do with certain
low-level things and so on but basically
it is a CloudStack but it's also
CloudStack of cloud stacks so sorry it's
that's the difference I said we have
this scaling system we had all this
orchestration so before they even
started working with eat I wasn't
allowed I was on OpenStack conference I
wasn't allowed to talk about
unfortunately I try to sort of give them
some hints how to do things and private
conversations but I couldn't tell so
that's why it's looks different
the wind system I didn't say say this
it's this wind is 100 plus K lines of
code not mostly Alan yeah we haven't
they're not sort of interested in the
code itself but we have solved a lot of
the concepts from this it's an
experimental system for doing research
on cloud things so a lot of the concepts
that we have from they are coming into
the product and even this with the
distributive cloud when we come that
came from from this project and they
they are very keen on that that's part
of or they're working on now for for
this especially for 45 g and a lot of
other concepts that we have are finding
their way into the product but not the
code itself
ok</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>