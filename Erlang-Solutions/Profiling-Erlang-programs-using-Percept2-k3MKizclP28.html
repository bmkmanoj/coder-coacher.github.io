<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Profiling Erlang programs using Percept2 | Coder Coacher - Coaching Coders</title><meta content="Profiling Erlang programs using Percept2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Profiling Erlang programs using Percept2</b></h2><h5 class="post__date">2012-11-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/k3MKizclP28" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay I'm aware I'm the only thing
standing between you at lunch so I
better make it as quick and thus nothing
so what are we doing a this is a talk
about work I'm doing with a colleague
looking me with somewhere in the
audience right at the back you just
waving farm and what we're doing is
looking at how you move profile yeah so
this is done in the context of lapeer to
lang on multi-core systems in the
particular the European project will
release um I'll say italia bit about
that then I'll talk about percent which
is the tool of a building on this is a
standalone shoulders of giants project
we're not starting to tracking early on
something that's very good it's already
there take you through what we've added
and then talk through a short case study
about parallelizing a chill pill
wrangler which is something that we can
and i were involved in right ok so now I
multi-core i'm sure you all know which
is to to to remind you if you have
multiple cores then you'll get multiple
channels so you're able to run things in
parallel on a multi-core machine like
one here all 32 cores or other machines
which are substantially i love so that's
something that's built into a night and
we're not in a way we're not expected to
look inside the box look at the details
what's going on there but we do need to
understand our program run or multiple
in order to paralyze them effectively so
we need tools of our homes we're also in
a situation that this is like an
advertisement this european project will
release the idea of that is that's what
we want to do is build a scalable
version of airline when I say version
I'm a detective Lee a library for a life
that will allow us to use distribution
in a way the scale and that will
the point we've got to wear a year into
this project european project involving
very of walt uppsala technical
university in athens erickson the number
of other companies what we got to the
book we've got to is a notion of
scalable groups so that instead of
distribution being being Universal we're
allowed to to scale that placing placing
things on within a group implicitly so
that's that's where we're at what we
expect to have a release of release
those tools release early next year but
what we're particularly interested in is
how to build a coolness to enable us to
use these sorts of our systems effective
and that's something that I think we've
been doing for about 10 years for few
tools to help people build your programs
to refactor those what we're looking at
here is profiling so in a way the input
we might have to doing a refactoring to
make your your program work or at so the
sort of tools that you get out of the
box is fantastic I come say hi strongly
enough how good the ER line tracing
facility is the fact that you get that
without recompiling I mean I also do
some work in a school space and there
you can finish up with multiple versions
of programs because you want to do
different things you know like you just
get tracing 302 you might well use our
tracing and lots of their answer tools
out there which effectively are open
skin on top of developing tracing
deserve if you're on a Linux system or
or or a Mac or you can use a chop which
shows you in a multi-core way on
information activity per call so then I
have as did dtrace supports that's in
the latest release there's tons of
release we've been doing some work on
extending that and there's also
that's what we're focusing on here so
what this percent do it's an anagram
it's an acronym for percept being an
airline concurrency profiling tool in
the Erlang distribution mainly written
by melanie bill goldberg using the OG
beauty it uses building facilities and
it's an offline tool you run the
computation and then you can play it
back and explore my capital so that's
the key a sickie message and i realize
i'm sorry why some of my slides have the
bottle but they do a crucial message
shows off line tool that you to replay
the sort of things you can get is a
histogram of the number of processes
that are active against time control
down and find out information about the
individual processes view the run
ability of an individual process and get
your various other things so nice tool
but we felt that there were ways we
could make it even nicer but here's a
picture this is a day you missing lots
of issues the green room is talk this is
showing you the number of processes that
are active intercept our view you can
see when processes interactive that
doesn't distinguish between the being
running and the being runnable long as
you have get a sense of that day you can
see this is something where they the
maximum point there are hundred and
something about 60 process that mom
could be running at any more time so
that I think that's a sort of thing you
see the percentage um what have we added
in in going to to the set to personally
he talks about your currency but the
multi core aspect of that is invisible
so what we've added is information about
run crew run queue migration because um
you can get my greatest angles of
smoothing out queue sizes but also if a
processor is on a ship y Allah is has no
work it will still work from other
shitty so if processes can migrate and
it's surprising how much migration goes
on so we can you can see the processing
might move 20 times between cause during
the execution of the program we provide
some extra information about whether
things are rather ball versa to be
running are there are particular things
that if you I have colleagues who I know
you say this into a form that I can
believe it if you have it graph showing
something in green you tend to think
that's a good thing whereas it doesn't
they use it there so the authors of
percent newsroom a lot and I know places
where green was just the wrong color so
we're doing that well if you're looking
at parallelization you'd like to get
some information pans about the call
graph and in particular some dynamic
information lots of the aesthetic for
raw material to find out the number of
times that particular functions are
called within another function and we
also wanted to Jamaica system scalable
we realize that often with tools like
this it's great on a small demo what we
want to do is apply something a lot
bigger one so we've done having two
things in that to your all things
one is to to present the tree of
processes in a way that doesn't blow up
when when when there are more processes
around is typically if there are a lot
of child processes of a single process
they're all running similar code running
the same code so why not shrink that
down into the single single lobe and
also because there's a lot we have to do
a lot of analysis only on the trace
information we gather then line up to do
that in
oh why not you've got a trace / / 10
seconds why not split that into 10
sections and process those in power
though it isn't a t'appelle solution
okay so let me show you where we are
with descent to what's of innovation
we've added information about the number
of schedulers attractive at any one time
so this is a graph maximum number here
for and you can see in this from in this
particular organization you're talking
about your use of your schedule as put
all that time apart from this gap here
one of the things that we allow is that
if in this grass you can select a time
and zoom in on that this is forty five
percent that particular we've added this
it's all thing but allow you to zoom in
and out of this moves me very hard you
can see there there's something going on
you're not getting forced rituals or
schedulers in that particular period so
that's helpful to see we show the tree
about all the processes are running in a
way that is on jaramillo so we show here
we have the parent processes if you
click on the plus their process have
children that expands and shows you the
immediate joy so you're able to view
that I've treated up to having single
list of processes there's some structure
to the way to ensure um we also we've
also added information here you can see
that this particular process got that
this number of Rome huge in that PID 23
has changed 32 times this this one here
has changed 1900 time
we also gather information about the
message passing that goes on so the
number of messages received the scent
that anyone process signals here also
the average size of messages we were one
of the problems i'm sure you know if
you've done any tracy with a line is
that you can generate a huge amount of
information and undigestible and then
the adjustable amount of information
very quickly so one of the things we've
done under the hood is tweak the
monitoring of messages the tracing
messages so you don't when you trace a
message store the whole message just
store its its size so that's keeping log
files if you trace markets here you can
monitor you can see the average size of
messages plus receives and sent here you
see there's an example that the run
queue is true let's move front you want
to 42 13 21 to so it's been a lot of lot
of migration unfrozen then you've got
the message again you've got this
message information also you've gotta
take an indication of the percentage of
time that's spent waiting that was we've
indicated that by orange Rock green so
you've got a sense that it's waiting
it's not doing anything
the message passing stats up before
we've also here when we have a number of
processes that are similar and the same
we just insert having 66 chakra reaches
collapses into one and expanded if you
wish but typically you don't want to see
that its information which is just
getting it is just not so there we are
we can see the parent-child
relationships between processes and here
we've got some dynamic function
information so you're seeing an ASG
bloop calls the function AST there and
then this function calls the it's is
descended hundred and seven times and
then below their 397 so that's a good
indication something is going on the
point of focus ok skip over this here
you get your life yet to see the
activity of a selection processes over a
particular time on and here we've got
green signifies that something is
running I'm already signifies that
against runnable with Mach line so you
can see very clearly over that over that
time period further now what is running
what is actually running what is is
potentially the fat gives you I think a
very clear picture about what what's
going on fairly to let me talk you
through an example jogo clarify things
ok I talked about compression already
and I talked about polarization so we
take multiple log files which we process
you can you can imagine you could
process these 17 sections separately an
able to do a bit of sewing together the
the junction but you can process them
pretty much in time part of my Sophia so
then it's very little is all and here we
have some now we've got support for
distribution what we've got here is some
information about messages sent between
two particular loads you can see on here
looks like somebody's thrown anything
though lamont what we got you can see
there are two bursts of communication
between these two particular nodes what
you're getting here is on each dot
represents a message and then y axis is
the size of the messages so you can see
you're presenting messages I mean there
is any old secrets of messages of that
size or is that too probably but apart
from that you've got messages of varying
size 17 to 22 now okay so let's move on
to the case study um I guess this is
this refers to previous work with this
system will wrangler for refactoring all
the things that we do in rambler is we
do cloned attention we look for similar
code in projects across multiple
multiple laughter and the way that
regular works is that you can survive
the buyers are interested in you
those trees into aiming a huge strange
summarizes all the information trees
within that we use a string on string
comparison very fast remember
overwritten and see in fact that you
identify things that might be clones and
then we check the things that we found
are indeed loans so if we've got a
system that allows you to jump to detect
plug all the clothes and only the
clothes you don't
very possible okay let's take a look at
what sort of if you look at the existing
system system is what we did any work on
it here is what happens on a solid for
call tree I could see that pretty much
we're getting flat performance along or
a pink's where you're getting better
Teufel but basically it's a sequential
pro so what we want to look at well we
can take a look at the top level
processes what we've done here is we've
selected those processes including their
children but not all three aggregated
processes what we're going to do is
compare their what they're doing and
this gives us this picture moles the
computation as it's going on when you
can see cross station going on there
this is the main thread and then we have
these situation where these processes
are vulnerable but not running because
he really we've not got so much
opportunity that's why some devices
appear well there's not much opportunity
there but let's look at that critical
process this is the moment when all the
work is going on so that's zero in on
that see what's going on in here one we
can do that you've chosen this
particular section beginning and then we
can look to see what is actually what
functions are being called inside that
time period you can see is that these
green sections on the dark gray indicate
that during that time period this
function is exactly for that period
these are the show dull green shows that
intact it for the whole period and for
beyond
so this gives us an indication of what's
going up what we call at that particular
point and then what we can do is take a
look at the time slice within that
period of what the function falls and
here you can begin to see we've got a
cool air with one that's leaning to
seventh seven calls now they're so
focusing in on that we swap we've got a
lettuce cooperation so it's relatively
straightforward too comfortable mapped
into a parallel map so that's the first
three factor it gives us that and you
can see now within that within that
first phase we've now got utilization up
to now we've got the potential for going
up to about 12 to a lot more a lot more
than we had flattering so what we do
next is look again the game look at
these processes these are the ones that
we're interested in is the long live
once so you've got the evening parallel
stuff going on there these are long with
once let's take a look what's going on
there we look at the call graph you can
see we've got a list for each so again
that's spotted on a particular
particular case that we can which one
investigate what we do is replace after
the parallel so it's not i'm not
suggesting that the refactorings were
doing the arrow on rocket science but
the tool is zip zeroing in all the
places we can do those relatively
straightforward so now we get this
situation without passing a parallel
here we're doing the of true flattening
invalid doing loads of opportunities for
doing that we've still got a flat
section right
so let's see what's what's happening
here this is the process it's active at
that point so let's take a look at
what's going on there now if we look at
the full call graph here you could begin
to see that here we've got this examine
close candidates is calling these things
multiple times so again there's
something going on there that looks like
you should look at it what we get here
is a we don't have so you can see with
other selections things we have a list
comprehension parallels like the for
each with a paralyzed in we've got a and
explicitly recursive function that we
have to transform you to a portal to a
parallel reach so there are different
things that rise to one give rise to to
this sort of situation so I think trying
to do a purely static scan through your
program for all instances of a disk
operation or breach orale because of a
function that recursive donmar my list
you're going to get an awful lot of
false positives there's what we're doing
here because we're looking at the
dynamic information you've got we're
equal to zoom in for precisely the case
as they do so we can give that I'm Lenny
like that gives us this situation to
parallel RC parallel tree flattening
parallel search through potential
candidates
actual clothes and so what we've done in
terms of that the original structure is
you could argue until that anyone we've
been able to use the information that
we've got to direct us very clearly in
that I shows all you know it's right
it's not anything trivial example it's
allowing us to to take this this amount
of data deal with it effectively
presented particularly from those
process traces what's going on okay well
next over here we're going this is a
sweet this we don't we ultimately get
that sort of four core machine my kid
sister 4.5 without some solution
but if we forget it's like a big fellow
so what our next step we're looking at
the front end of the sentence would like
to change that to make it a bit more
interactive so using slightly more
modern html5 technology group of
students at the moment what we want to
do next is to open to doing online
protonic so getting into the light
information from computation not simply
this sort of are lots of this sort of
post-mortem done now obviously there are
there are problems there if you're
trying to put the information off multi
core system live can you get the data
off quickly enough what we need to do is
sort of ways that we can process data on
 that's using using using cause to
process things close to the place where
the data to be generated and also
looking at ways that we can we can stop
dating generating from don't my habit
and look at how will extend our recovery
this we've got some other work on
release so there's very nice paper on
paralyzing dialyzer are mainly using a
chop is indication what was going on
there that's a paper on that in the
other workshops from twelve ask you
processes ago doesn't it students long
did also take item click the grease felt
very nice benchmarking sweet facial
which I'd like represent you the rafts
the previous national there and we've
we've dominant and the guys aggressive
work on extending DTrace on the subs
is and also we does work on extending
Tracy so you can filter messages they're
not a little trace messages get it
generated all is this also this business
of Tracy smaller courtesy message signs
rather than the message itself so in
conclusion i've introduced a release
project i show you a tool that we've
been able to use to support scalable
parallelization you should have a
release of thing of the infrastructure
itself earlier than 30 and i definitely
want to say thanks i'm actually % t as
they say on the shoulders we are we are
standing this is a local source for Jen
so they're asleep it's on github so he
be interested in using it or
contributing thank you very much
Russians fire service means ten
thousands of buses device this you have
space for something more you can ship it
off onto another onto another device
innovation through a personage in this
part of the whole I mean this thing is
running before it's about I mean that's
how long you run it that's a question um
so we where we can deal with medium
sized systems yeah but I think what we
need to do we need to think about we
need to look at running it on larger
systems and see how far how much
information we have to filter at an
earlier strategy when the way that it
works at the moment is that and this is
a good thing you say I just want to take
my my system as it is collect all the
information you can and then I will I
will search through like the information
on what now that's fine but if there are
things you know that you want it might
be better to trace those things are
Thrones so we need to think about that
in the way I'm treating
and suddenly I mean there is compliment
you could just use DTrace so you could
use our like system tracing you know
precisely apologies so this gives you an
overall picture or sort of thing arm and
I kind of like my feeling is that no
tool is ever going to be covered so
we're going to use a combination but
certainly when we're thinking about ways
that we might we might tune it to allow
you to too long to trace different
things
they could be yes they're not check them
off they're not so difficult but yes the
good son yes yeah that's what I can talk
then search and one more thing obviously
things that you're accelerating the
polarization were terribly
single-threaded out anyway I dialyzer
Mustafa saw it once mental process but
you know the traditional learning app is
very very routine and very parallel as
it is so adding even more paralyzation
already slow it down so much am I really
a computer thousands are in store yeah
deals my back and they've added even
more paralyzation on top as is already
way more processed the number cause
imagine the oh and willpower zation
actually do since through them so that
we find on a linkage is detective our
applications it is it quite tall as very
much geared to start taking more
traditional single-threaded application
will stop pulling more powers parent is
how back on I'm addict
think so particular I mean I think I
can't think that that's certainly what
we've done then basically it's more
saying what seeing what's going on just
getting an overview nothing more what it
can certainly do I guess this is done
you're thinking about about next steps
again this question there are clouds
particular periods you take an overview
of the system particular thoughts in a
comment section or anything the
inhalation of the system where it looks
as though it's running sequential run
your life service and synchronization in
that area you know waiting unit and
danceable that's yes that's the thing
that's that's always going to be there
to need to think yes you mentioned a
very eclectic metric evolved process
migration between right yeah so okay we
have a number of what is it there is
president migrate a lot so what that's
very good question yes when I think what
you know is that there is something I
mean I guess that's oh right sorry I'm
sorry the question was you can see that
the process migrates a lot and so what's
wrong you do about it um well I guess in
a way that Francis symptoms or something
something problematic in thing in name
in the way that your your information is
shared with children's is in principle
if you are a few assistant with some the
self-regulating you would think that you
wouldn't have to move things around you
can create processes of course they've
spread out some work stealing but then
each for each scheduler would reveal his
own work certainly some number
proportional to the number of course
both youth that's a very interesting
shoot on it now it's a really good
question but something as far as i
understand it and I think this is
probably the right answer they are
teaching teen don't want to let us do
things like nailing processes to sure
they're not because they think that that
that won't work in a particular
situation but in general it's going to
be it's going to be not but I think it's
a symptom it's a bad smell so I'm not
sure I won't say anything visit that's a
good point with us or perhaps what we
should do is take some research might be
more girls yes thank you don't probably
could have seen that in the after you
started bullfighting go to parallel
caramelized versions it probably could
have seen those no question we shall yes
yeah thank you that's always good to
having to leave a thick let me get the
totally good question we have like
excellent regular cycle check</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>