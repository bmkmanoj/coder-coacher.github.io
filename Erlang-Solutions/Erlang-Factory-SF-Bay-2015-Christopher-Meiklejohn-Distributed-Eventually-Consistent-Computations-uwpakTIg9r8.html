<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory SF Bay 2015 - Christopher Meiklejohn - Distributed Eventually Consistent Computations | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory SF Bay 2015 - Christopher Meiklejohn - Distributed Eventually Consistent Computations - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang Factory SF Bay 2015 - Christopher Meiklejohn - Distributed Eventually Consistent Computations</b></h2><h5 class="post__date">2015-03-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/uwpakTIg9r8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay yep so I'm Chris Mikkel john i work
at bosch oh you might have heard of our
us we make some software i'm going to
talk about this thing that is called
last we're going to get into the
motivations behind it we're not going to
show at underlying code so i apologize
but it is an overlying project it is
open source so I'm github so all the
resources are available for you to look
at will look at some brief code samples
but it's more important to motivate why
we're working on this stuff so yep so
we're going to talk about distributed
eventually consistent computations so
this is my talk yep and this is a
research that's you know partly my
independent research along with peter
van roy at UCL in belgium and it's part
of a bigger project called sing free
which is focusing on large-scale
computation without synchronization so
we want to basically avoid synchronizing
whatever is possible and kind of explore
the application boundaries and figure
out how far we can push this and kind of
what the mechanisms are that we need to
you know make these computations work
make sure that they're deterministic
make sure that they're correct and make
sure that there are you know more
fundamentally like easier to use for
programmers to reason about concurrency
consistency and non determinism so we'll
talk about the kind of the motivation so
what's the motivation for the work right
so um so synchronization is expensive
right and so you know if you use you
know like you look at things like
spanner you look at Paxos multipack
sauce raft synchronization slows things
down it takes time you have to wait for
people to agree and you know at the very
first recon joe Hellerstein said you
know he was trying to motivate bloom and
our work is very similar to bloom it's
slightly you know it's more functional
than logic but um you know me motivated
by saying like yeah let's talk about
Sigmund ization all right everybody wait
it's like okay now like that that is
essentially synchronization right like
everybody waits everybody's kind of
waiting and eventually we're going to
agree on something and eventually it's
gonna have the right value but it takes
time to get everybody to agree it takes
time to detect failures we can't detect
failures perfectly and this is really
problematic when we
thinking about kind of larger scale
applications this is really really
impractical when we think about Internet
of Things and mobile and I'll motivate
each of those individual use cases I'm
shortly and again you know it's
impractical if if you want to have you
know hundreds of mobile phones or
something like that and you want to like
ensure everybody gets the same state at
the exact same time you can't do this
it's it's effectively impractical we
need these mechanisms where we make data
structures that are converging or we
have things where like we have backwards
and forwards compatibility right you
know is it like you think about like
iTunes right you start up iTunes and
they've changed something right and
they're like us are you can't buy a
movie you can't even download music that
you already own until you wait to get
the new version of itunes right so so
keeping doing versioning controlling
what these things there's really hard
it's really expensive it takes time and
it puts a lot of burden on the
programmer to make sure that all of this
you know all these computations happen
correct so we'll talk about mobile games
so one of the one of the use cases that
the sink free project is motivated by is
is a use case that comes from Rovio
entertainment so the company that makes
angry birds so they have shared safety
between clients so if Shana me are both
playing angry birds and you know we have
some state we're logged in is the same
account sean is going to update his
profile and maybe change isn't it update
our profile right and change the name to
be you know something like whatever
Charlie root and then I change the photo
to be like a donut or something right
now we've changed that state
independently right so the mobile app
wants to allow you to make those changes
independently it doesn't want you to be
on the subway and say so you don't have
internet connectivity you can't update
your profile can't update your profile
photo that's a bad user experience so
clients aren't heavy the clients are
going to go online mobile phones are not
always connected right especially a
think about going on an airplane right
you go on you you go on an airplane you
update a bunch of stuff on your mobile
phone then you get off and like now what
happens right you know do we do we you
know take your state and do a round of
paxos and get everybody to agree on the
right state you know I call Sean turn
your mobile phone on right now because
I'm about to do a round up axis with you
you know hey that's really bad all right
so you know with mobile games we have to
ensure that state is convergent we can
handle concurrent updates and provide
the best possible user experience and
here's a little article from Rovio where
they just talked about you know the
number of scales or the massive number
users are having how they're scaling and
you know this kind of stuff motivates a
problem you think about wow there's so
many mobile devices that have shared
state on them a second case is an
internet thing so like a newer thing
Internet of Things kind of a coming you
know an actual thing I guess but you
know we think about most of these
Internet of Things companies they put
sensor you know so you imagine a network
that has a centralized DC you have a
bunch of edge nodes and then you have a
bunch of like mobile clients or I mean
sensors right so these sensors are going
to aggregate state and you're going to
aggregate the state up a graph right
you're going to send it to some
centralized place and they're going to
compute some aggregates or something so
the interesting thing with Internet of
Things is these sensors are very low
power sometimes they're high power
depends sometimes are offline sometimes
you know if I if so here's a case where
I live you know I live like in you know
super upstate New York on a lake and you
know Sean lives next to me sean has
really great internet and I'm a poor
grad student so I have no internet and
you know we can talk through 8 0 14 B or
something right our sensors have 80 14b
they share they share this information I
should be able to give my information to
Sean and have him distribute it for me
but then when I come online if i send my
information back well how do I know if
I've already seen that information right
how do I reason if we've already observe
these objects in the system so with
Internet of Things and aggregates to you
know compute an aggregate send an
aggregate upstream how do I know what
that aggregate came from how do I know
if I've already observed some windowing
on that aggregate who knows right so
again clients go offline these things
aren't going to be off online all the
time you think about how we wanted to
put you know Monsanto whoever like wants
to deploy these things all over the
place they can monitor temperatures or
something right like like in this case
you know they can't guarantee these
things are going to be online all the
time you can't guarantee that there's
not going to be some solar flare or
whatever you know that like makes you
not able to connect so you have to
inherently deal with clients going
offline duplication of state and
reordering of messages so internet
thinks is slightly different because
here we're talking about disjoint state
usually right usually you have two
centers they're going to maybe compute
some aggregate together or send some
data you know just some centralized DC
or something so ultimately we have this
problem where we have no total order we
have no ordering on the events in the
system at best we have a partial order
usually and
this is because we allow clients to make
progress independently so me and Shaun
have mobile phones we make progress
independently based on some states we
have some starting state we make a bunch
of changes and eventually those changes
need to get merged and this is kind of
the core problem that we're trying to
motivate here so hopefully you believe
me hopefully the mobile case makes you
believe that if you don't believe in the
Internet of Things case but you know
this is like the general idea offline
offline clients concurrent operations
and you know how do we deal with non
determinism so um you know you might say
whoa you know we can do what spanner
does yeah no not really um you know
spanners an interest in vain because you
know one of the results of this paper
says that at best we throw so much money
at this problem and the best thing we
can do is synchronize clocks within a
very small Delta but we still can't
reason about concurrency within that
Delta well that's fine we can punt
around that right and for some
applications that might be fine but you
know the ultimate problem here is that
wall clocks are unreliable everybody
knows this if you don't believe this
tell me and i'll send you like a hundred
articles about it this is a core problem
and if you use wall clock resolution
such as the last traitor wind strategy
based on client supplied wall clocks as
some databases do its non deterministic
you have a non deterministic outcome you
know so this is bad this is really bad
so what we want to do is stop thinking
about physical time we want to think
about logical time so I'm going to give
you a little example so I'll do a quick
survey of the room how many people here
know so most of you probably on the
react car talk earlier maybe about how
many people are going to react or okay
some how many people here know crd tease
okay a lot more that's good all right
good because I'm going to talk more
about crd tease and then react you can
see 100 react court talks all right so
here we assume that we have some shared
state we assume there's two copies of
the replicas right so we have a replica
of some data item so we have replica a
replica be so this is some state we
start out with some starting state let's
pretend this is a register so we do
assignments these are going to be the
values that we assign these these are
concurrent these are concurrent
operations happening even though these
things are kind of like located on top
of each other that's just signifying
concurrency saying nothing about like
the actual
physical time so this is me and Sean so
you know here I set the zoom on replica
a replica it's the object to be one
sends the data to replica because it's
online replica p he's got one so now
concurrently and currently can happen if
you're offline it could happen now and
it could happen now that's concurrent
right we're offline we have no way to
reason about these operations in the
system so we have this problem right
when we and Sean both get online and we
communicate our state well how do we
resolve this problem here should the
answer be two should the answer be three
so when in the terms of a register this
is really hard to answer because we
don't really know a lot of systems use
physical time to try to reason about how
to resolve this conflict so again you
know what do we do forgot to advance the
slide you know speaker problems so C or
D tease co tt's I don't have time to
talk about a lot of them because this is
a subject for an entire talk but crd T's
are essentially data structures so this
is some research that we have that wave
production we put into production and
react and there are some other companies
using like SoundCloud and you know like
a Moche kind of was a early early
adopter of CRT teased before Sierra
teens I guess so CRT tease essentially
provide deterministic resolution there
are data structure that basically
encodes this causal information and has
a way to arbitrate basically which which
choice to make so it's deterministic
regardless of where the execution
happens crd T's come in a number of
flavors here we have maps so we have
maps sets counters registers and graphs
so in react you'll see map sets counters
and registers and flags flags are like
billions that will move only in one
direction right true to false false true
registers can be assigned they can
contain multiple values or a single
value counters or counters that go up
and down counters that only go up
counters that only go down whatever we
have sets we have sets that allow you to
add something once we have sets that
allow you to add something one to remove
once we have sets that allow you to do
that Norma Tory number of times each one
gets more complex you imagine you can
build one in terms of another then we
have some optimize things we have a map
which is essentially a dictionary where
you know you have res so you can do
arbitrary composition you can do nesting
somewhat arbitrary not a hundred percent
arbitrary but some
given that it adheres to a very very
strict interface and finally we have
graphs right so graphs would be that you
contain a set of vertices and a concern
of edges and you have convergence on
those so the edge the graph one is
actually really really hard because you
want to you know some of these
invariants you might want to sort / set
re well I don't have a cycle in the
graph or I don't want to ever have an
edge that's not connected right so I
mean vertice that's not connected but
essentially all of these things provide
deterministic resolution so what Ciara
tt's realized is this property this is a
very academic kind of thing but you know
it's something that we talked about here
is this property called strong eventual
consistency so in an eventual
consistency system such as you know if
we're gonna take about react with the
last rider wind strategy the not
recommended last rider win strategy we
would say that if I have concurrent
updates to an object a client supplies a
time stamp a ravine ode supplies a time
stamp it coordinates them right and then
it basically you know chooses one of the
other based on you know what the last
writer is and last Reuters even a little
fuzzy too because it's like well that
wasn't really the last writer because it
could be the last like you know it could
be when that time stamp was observed so
it's really like last last latest time
step observed resolution right so that's
interesting so what strong eventual
consistency says is that given a system
where you have an object and you have
this object distributed you have the
same copy of the object everywhere and
you have a reliable delivery mechanism
that says I will deliver a message to
say the same set of messages regardless
of ordering to all copies of that object
we guarantee the correct outcome so it's
deterministic at its deterministic in
the system each replica has a
deterministic resolution strategy so in
a literature this is called this is how
its kind of this is the informal version
from the conflict we replicated here's
the citation come from fever replicated
data types is from s SSDs in 2011 and it
was formalized a little bit earlier than
that but this is the paper that actually
has the official definition if you're
interested we say correct replicas I
have delivered the same updates have
equivalent state right so there's a
really awesome property to have in a
system long as you have a reliable
delivery mechanism you can guarantee
that everything will come out exactly
the way you want it you can reason about
a central I a distributed execution as a
centralized execution so this is great
we like this
they do not they do not sold yet so
that's why this property is interesting
right because it assumes that once all
messages artillery so it's an ambiguous
as eventual consistency so this builds
on eventual consistency but eventual
consistency makes this like kind of a
vacuous claim like you know this is the
Doug Terry criticism right is like once
all updates once all updates happening
and all messages are delivered well like
when does all of what when do all
updates stop happening they don't right
so in practice yeah so in practice you
kind of have to you know think about
this in a different way but yes that's a
that's a that's a very fair criticism so
we'll provide an example so when the CEO
tt's example does the max register so in
the max register we'd say well that's
fine right we're going to compute the
max over these numbers this max is I
definite commutative and associative so
we guarantee that I you know it doesn't
matter if we observe the 1 the 2 the 3
first as long as that these updates are
delivered and as long as we have an anti
entropy protocol to say well let's say
that some of the messages don't get
delivered a replica that does have all
of them can basically send it state and
repair it along as we have a repair
mechanism and an anti entropy mechanism
in the system we can guarantee that we
have correct conversions this object so
this is a trivial example if you have
natural numbers eacute max over that's
great nobody built an application with
just natural numbers and max unless
you're building a you know a distributed
counter service as Joe Blum said likes
to talk about all the time so yeah so
CRT fees so we'll look at a more
complicated example so one of the ones
that is basically one of the the
coordinator types that you can build
everything in terms of is something
called the observer moveset so the
observer move set is a set that allows
arbitrary additions and removals from a
set of a number of an item it could be
you know added removed added removed and
it properly captures causal information
in the object itself so that we
guarantee correct convergence so we're
going to walk through an example it's
going to be pretty complicated but
you'll get the general gist I mean it's
complicated if you've never seen crd
teased before so here we have three
replicas we have a distributed execution
this is the final state that the
replicas have and this is metadata
associated with the object so we're
going to assume at this sorry this so
these things are the metadata oval or
whatever these or whatever these shapes
are
cmath good shapes bad I'm so like ya
know like algebra grade geometry bad so
yeah so these are the states at each
replica and this above is the metadata
that's associated with each object so
we'll say at this time here we have
concurrent editions of the item one and
we track it via a unique identifier so
we say one was added we have two sets
its is a three tuple if you're familiar
with our length and there's three tuple
says that I don't want to exist in the
set with with the add unique identifier
be and no removes and we say well then
we can currently added one at a here at
replica a so we insert unique identifier
a into the ad set we have no removes and
one right so now when these two objects
merge eventually we know that we've
tracked two editions of one so we're
allowed to remove things that we've
already added right so now we move to
the second stage here we do some
replication and we see that you know
here we remove be and then we propagate
the state over here so now once the one
the set over here because it observe the
one edition at time a and the removal at
time be right and then finally when we
get here we merge everything together
and you see that the metadata is all the
same right so this metadata is a grow
only set of metadata its asset that we
can just union that information in and
then when you remove something you when
you remove something you only remove the
additions that you've observed right so
this differs than a sequential execution
of a set because in the sequential
execution you don't have this
concurrency anomaly where you have a
concurrent addition and removal an item
and you have to decide how you reason
about it so most of these data
structures are very similar but they
have biases that need to be a plate
placed in the system in the resolution
to make it to terminus tick so you have
to have a bias that says well in the
event i have concurrent removals and
editions i have to choose one or the
other so you can either bias towards the
remove winning or you can buy us towards
the ad winning you know and each of
these are useful in different cases
usually the ad bias is the one that
people like the most because it makes
the most sense under can you think about
a system here usually you know you've
reason about distributed system you'd
say well if I talk to that node over
there and I say remove this thing and I
concurrently have an addition over here
um you know the addition probably should
win because I'm usually not going to
remove things that I haven't seen yet
right so the add one seems to make the
most sense so what is interesting here
is that composition of these data types
is non-trivial we have seen this with
the map
the map allows this arbitrary
composition so Russell Brown at basho
did a ton of work on this spent a very
long time it involved a bunch of
researchers in Portugal and France and
Sean worked on it Sam Elliott and in
turn worked on it we had a lot we threw
a lot of resources at this because
composition in the map is not trivial
because you have this metadata that
flows through this object so you can't
just stick another crdt in there without
properly mapping the metadata from the
of the object that's being composed into
the composer essentially so we'll see
kind of an example so what do we mean by
composition so Cirie T's gave us this
property that allows us to have these
independent things happen in the system
we can have these happen on mobile
devices we have these happen on Internet
of Things devices we can do these things
compute these things and then join them
together that's great how do you build a
program with that will you have to
compose your dt's the composition of a
bunch of CRT T's is a bigger program and
we're going to show that this metadata
mapping is not trivial so here we have a
thing so we have replica see and we have
its timeline and then we assume that we
have a function here that's going to
take value X return to so this is just a
function that basically Maps 12 tues we
make it very simple and we're going to
have this represent the path of the comp
the composition here right so we say
that at time 1 we have one and we map it
to two but we don't map the metadata so
let's talk about we're not going to map
the metadata yet so we're going to say
ok now we have the empty set we map it
when map it fine ok so if you actually
do the mapping at every stage in the CRT
T's evolution you will get convergence
it will be correct you sorry you will
get a correct answer but you will not be
able to converge them so if we want to
take a look at a more complicated
execution this is the one that we looked
at before this is the one I explained
about five slides ago so you should be
familiar we have the set we do all these
concurrent things and we end up with the
result so here we're going to take node
B out just to make this simpler so we're
only going to look at the communications
and concurrent operations happening
between cna because cna are the ones
that do these concurrent additions and
see has the removal that happens we have
the addition concurrently we have the
synchronization with the removal here it
stays here and then we do this ok so now
we add our function application here so
fine we do get the correct result at the
end this does work right if we map from
one time to the 0 time at every single
possible time step we
that this is a synchronous mapping
between these two which is really not
going to be because we know how real
computers work we know that you know
this is going to be okay and these will
be easily able to be rebuilt we can
rebuild these we can replay this F of a
that's fine we can replace f of RFC fine
again but what we don't have is we don't
have the strong eventual consistency
property on the on the composition since
we didn't map this metadata through
correctly we end up with objects at the
end that are unmerge abul so now i have
so if you know this update here that
happened and i had the empty set here
well now i don't know if this to you
know if this if i had an empty site here
and i probably gated the empty set and i
had two and empty i don't know if that
empty said observe the addition of the
one that got mapped to two or if it
hadn't seen it yet because this
information this metadata is what's
important to understand how to do this
mapping how we resolve it this metadata
captures logical time essentially
logical time of updates in this system
okay does that make sense to everybody
that was ok clear wrote the diagram like
six times wasn't sure if anybody to
understand it I don't know there's a
couple people shaking their hands John
gave me the plus the thumbs up so that's
good ok so composition not trivial and
there's this difference because this set
has a value that's non-monotonic right
we can't reason about wanna tonicity on
the value because the set can go up and
go down so we haven't said we've only
ever add things that's fine we use Union
at the end it's fine we need no metadata
but in a situation where we have a value
that has a non-monotonic change it can
basically vary over time that's
problematic but what's here these
cheese's do provide is they provide
monotonic growth in state we always know
that we're accumulating more information
about this objects change over time so
we'll always know if we see something
and even if the values a lot less we
know if it came afterwards and time and
it observes something and then forgot
and then got rid of it right so we can
determine the difference between not
being present and it was present and
it's no longer present because I removed
it so in this example I gave you might
say well that's fine you know we can
write this function to map the metadata
this mapping the met
is non-trivial we found this out because
we've tried it a bunch of times in this
research we found out it gets really
complicated when you start doing things
with folds and and other types of data
structures and products and unions we're
going to see all that shortly in the
talk and finally if we do not have this
mapping metadata the objects are
essentially unmoral they are mirja Bowl
but you won't get the right result or
rather you'll get a result that's
defined by the function that does the
merge but you won't get the desired
result right a correct result so for any
of you who are interested in the
research kind of that led to this you
know whatever this this idea we have
this paper that was an abstract with The
Associated talk from Russell Brown and
me and Sean were involved which talks
about how to do this composition of a
dictionary and it's basically this is
the react DT map provides us is open
source library and react DT which
provides a bunch of implementations of
crdt you can use them it's on our github
it's free and yeah you should use that
because that libraries are badass
there's a second paper by me that talks
about how if you break the map apart and
you want to store it in independent
pieces that composition is non-trivial
without doing the metadata mapping
correctly and finally if you're familiar
with Neil Conway's work on bloom at UC
Berkeley and Joe Heller stains group
they in their paper where they talk
about extending the bloom system to
logic and lat essential lattices which
does a very similar thing they run into
similar problems as well when they talk
about so they have a section when they
discuss problems with the approach of
doing it with CR DTS and kind of this
scope dilemma that they talk about and
this how this composition of things
doesn't necessarily guarantee correct
merging so these are three very
important resources i highly recommend
the old Conway's paper that was at socc
11 okay all right 39 out of 133 slides
let's talk about less we're gonna talk
about this very little actually and
we'll talk a lot more about how it kind
of fits into the ecosystem so last was
essentially lattice processing clever
name right list list processing last
lattice processing I don't know the
acronym doesn't work out a hundred
percent but at the time that we came up
with the acronym we thought it did
that's what happens when you're working
all night right
so essentially what we want to do is we
want to provide a system a runtime for
centralized and distributed executions
that supports this composition of
metadata so again we want it to have
both centralized and distributed
semantics so under the centralized
semantics we assume that an anti entropy
protocol isn't needed to repair things
we assume synchronous delivery of
messages no sorry we assume a cigarettes
delivery of messages between
communicating processes on the Erlang vm
which has synchronous delivery to the
mailbox i believe and we also assume
that we never have to repair things we
never assume that like the updates are
going to come out of order even though
we're tolerant to it you don't have to
assume this in the central semantics for
the language so we'll walk through an
example here so we have a replica and
then we have a function apply to the
replica so again there should be a very
familiar slide you've seen it a bunch of
times already in this talk so we have
here the sets in one with B then we
remove it we get the ad of the added
time B and then the removal at time B
then we have here the addition of time a
and this is left out because yeah this
is a copy and paste our but you get the
general idea and when we apply this
function what we do is we essentially
map this through so we met the metadata
through and we basically change the
value in the set right so this is an
observer move set that we've talked
about the tracks additions and removals
we map the metadata through so in the
map case it's very trivial because all
you have to do is change the value it
gets a little bit interesting if you
have a function that will map to a
smaller codomain because that means that
some things are going to map into
similar things in the codomain right so
in that case we have to identify things
that already exist in the metadata and
then Union the metadata but it's that's
still pretty simple it gets really cool
when we talk about distributed semantics
so we look at distributed semantics of
these what we want to do is have yet
this which you'll never be able to
follow but you can just get the sheer
the sheer magnitude of the problem right
so here we apply this function this
function is replicated the replicas are
replicated and you know again we assume
this is at a logical time not a physical
time and you know so we say well we
perform this mapping and then when we
you know do the state synchronization
here and that
we assume that all this metadata is
going to come out correctly and merge
correctly and you know in the SEC case
it's it's simply a matter of Union in
the unoptimized set in the optimized set
it gets a lot trickier because you have
to start lunging the metadata a little
bit so that's gets a little bit more
complicated I want a sip of water
because I'm talking a lot finally the
system is designed in such a way that it
allows for composition of the runtime
system itself so you know in the system
itself in the centralized execution you
have a process you have another process
we send data and we synchronize over
these variables and we ensure that you
know these lattices change we map this
metadata correctly in the system
composition you can basically say well I
have this one last system running here
at this other last system running here
and I'm going to do the metadata mapping
between systems that's fine obviously
right now this is a research prototype
so we only support doing this in Erlang
we don't have another run time I'd love
it to be like c &amp;amp; l OV m or something
like that because then we can compile it
to all these different fancy targets and
do all sorts of crazy stuff but
obviously we don't have time for that so
this allows you know through use of just
a lot of parameterised module and
parameter not not actual parameterised
modules but through modules that kind of
our parameterised to basically take
functions to know how to through some
interface know how to apply the updates
to the other system so you know if it's
over tcp or if it's over dist oral or if
it's over you know whatever so we can do
this cross runtime in the centralized
runtime we assume a single node model so
we assume that we assume it's going to
be a bunch of processes running on the
same vm that can operate over shared
state so all these variables that we're
going to see in this language are
essentially stored in shared state and
we synchronize on these variables and we
synchronize we synchronize within a vm
we don't synchronize across vm so that's
the difference right don't think that i
got a multipack so system here running
we basically just secret eyes on berries
we wait for a variable to change we see
that that time that logical time I talk
about we say a logical time change we
know that things have happened to the
system and we can propagate changes
through the system in the distributed
run time when we just think of the
distributed runtime well it's a bunch of
nodes but at each node I'm going to have
a centralized execution right so we have
centralized execution
over a datastore that's either / process
or per vm and then we're going to have
this synchronization happens the
distributed one is going to assume that
we replicate the data and then those
replicas of the data have a single node
kind of execution it's very similar it's
not a hundred percent the same and I'm
happy to talk about all those details
but it that's to nitty gritty for the
talk all right so semantics I'm not
going to talk about them a ton we have a
paper and we have another paper that's a
draft and I'm happy to share this what
information I can about kind of have the
details of how some of the algorithms
work will walk to him quickly now but
well first quickly kind of talk about
the system model right so in the system
model we're going to think of each
variable so imagine a programming
language where each variable represents
a stream so if i go back here for just a
second we imagine this is a stream so
replica a is a replica of a single
object we assume that we can think of
time as a stream of values applied to
some object right you're thinking this
should be very familiar if you think of
any system that uses a log right ahead
log or you know a lot you know any sort
of system that uses logs for storage so
we're going to assume that each variable
is a stream and in the centralized
execution we're going to think of it
like this right so we're gonna have this
replica and we're going to have changes
over time so in a register sorry in a
set we're going to see that you know we
have this metadata that moves this
metadata is always so you think this is
a partial order this this metadata is
always going to move forward so we're
going to design the system in such a way
that we guarantee that it always only
moves forward so if somebody sends an
update to this system so imagine i'm
here i'm at time this logical time three
somebody sends an update to a system
with this object from logical time one
we ignore it right because we can
compare object at logical time one two
logical time three and we can see that
logical time three subsumes logical time
one right the set don't look at the set
look at the metadata the metadata
subsumes the other right so we think of
objects in the system as streams that
change over time and it causally advance
over time in the distributed execution
so this is the naive super optimal kind
of you know we don't have any failures
because this is a fake computer network
model and in this model we have three of
replicas of the same object and we
imagine that when we
wait to them we broadcast we do we do a
reliable atomic broadcasts and everybody
gets the same objects at the same time
so we can think of a distributed
execution as a replicated centralized
execution so you know I don't know we
work on computers right and we work on
real networks and we work in like bad
data centers so essentially we have
problems of concurrency failure and we
need anti entropy and repair mechanisms
to fix things so let's talk about what a
real execution looks like so that looks
a little bit more like a real system
right we assume that yeah we have these
things that get synchronized and oh man
maybe replica be goes offline and comes
up with no data well that doesn't happen
ever and then you know and then we
basically murdered then we merge state
back in so we merge state over here we
merge stayed over here and we basically
continue advancing of this state forward
right and eventually we get the right
thing so this replica goes offline comes
up back with nothing we can assume this
as an anti entropy process or a read
repair process if you're familiar with
like kind of the dynamo style ways of
doing things in react or it could be
hand off as well we don't support sloppy
quorums but you know that handoff
mechanism that was talked about last
talk is applicable here as well and
finally you know everything merges out
right so what's the criteria here is
that if I don't deliver all the messages
in the network which you know I don't
hear well this merge doesn't happen you
know and the later comes in here the
anti entropy protocol ensures that all
updates are observed at all replicas
there's a very important property that
you need to realize strong eventual
consistency so yeah so streams
distributed executions end up being
deterministic now as long as we can
guarantee the delivery of all updates
and you know again it requires eventual
delivery either through read repair or
anti entropy cool so the semantics the
language allow you to declare variables
we're going to see an example of this
but I'm going to talk to what they did
general operations are first they allow
you to declare variables set the values
of variables we can continuously set the
value of a variable we can say a is this
a is this is this as long as a
continuously causally moves forward as
long as it moves forward in logical time
so declare says give me a crdt type I'm
going to initialize the state at the
bottom value so these are semi lattices
and we have bottom values and you know
for a set for sake of argument we can
just say this is a you know empty set
for a counter will assume 0 right bind
allows us to assign a value to a stream
so to add another value to that stream
so for replica
they bind one by so if there's a natural
number and it increases we say find one
fine to find three find one stays at
three right because three in this we're
defining it over max if this does that
set we would use that metadata to say
I've already observed that I'm not going
to allow the assignment again I'm going
to ignore it right because it's assuming
that hey that was a message of its
delayed on the network I've already seen
it so because i got it from somebody
else we allow you to read variables but
we can't allow you to just read them at
any point because that sacrifices
determinism you might read it when it's
one you might read it when it's for so
how do I build an application that knows
how to read it and end up being correct
so if you're familiar with the elvers
worked is this idea of a threshold read
threshold reads assume that you know a
priori how the data structure is going
to change in a real system that's
distributed we don't know this
especially if it's stream processing so
we provide this monotonic read function
which ensures forward progress so we can
say in the system so the determinism
property that we want to get is that
given a stream and given all replicas
going to observe this stream we want to
ensure that we always read forward we
never read backwards we're never going
to read a delayed value we're now going
to read node value we're not married or
repaired value we're always going to
ensure that we read forward and if we
always read forward and we always have
eventual delivery of messages we can
guarantee that all over at three
replicas are going to end up with the
same state and we have some proofs about
that but they're not here we can block
on inflations which means that I change
some value you know inflation versus a
strict inflation says that if I change a
value and the value doesn't advance it's
still an inflation because I provided
some update that did advance the causal
state but necessarily didn't affect it
didn't cause like the value to increase
or the value to move forward in logical
time strict inflation's ensure we always
read a newer value we build all of our
primitives in terms of this so we have
algorithms for the mount attack to read
I don't have time to go through them but
they're there in terms of these
compositions we talked about like this
map function we've been talking about
for the most of the talk we block for
changes in inputs using that monotonic
read function so we say read this stream
but don't return to me until it's a
newer value than I previously observed
we compute some Delta over that change
to apply it we map that metadata through
and then we propagate that change so if
I met a into B I see a change I map the
metadata through I assign be and then I
basically wait on a again so we model
these things as processes in the system
these processes are replicated
so in terms of functional what do we
have we have a map we have a filter into
fold folds really complex we got some
algorithms here's one that's like really
Bonnie Python right like and uh and so
here is kind of the simple example we
talked about we map the metadata through
and we see that they object advances in
the same way and on a single execution
we guarantee these things happen
together we have a filter we have a fold
finally set theoretic we have a product
intercept I'm running a little behind so
I'm trying to pick up speed here so we
have set theoretic operations as well we
have products intersections and unions
so you can take sets and compute
Cartesian products you can build
intersections unions all the stuff that
map's the causal data through to so that
those and those are pretty cool so so
the architecture of the system so last
was built on you know it's built on
react core it relies on using a shared
variable store so if you have two
programs that are going to synchronize
on some data that's changing we require
there being a shared place where we can
store that data on a note we have
support for leveldb bit cask n debts so
s was really good until we needed to
save things so then we yeah y'all ready
to save things and evaluations but them
you know in leveldb and bit cask you
know we have persistence we see our DTS
provided by react DT so thank you to all
of the great contributors to react et
who are in the room who built these
great things that I can build all this
stuff on top of I really appreciate your
support and finally you know for the
centralized semantics we're going to
have these processes operate directly on
the variable store so it goes through
some abstraction layer to ensure things
happen correctly and then we synchronize
on these variables in the distributed
model and we're going to basically
replicate and chard that store so if you
are in the previous talkin react core
mark was saying that like you know you
kind of use this consistent hashing
function determine with place out
placement of all these replicas of
objects across a system and you have
these membership protocols that allow
you to move things around and do dynamic
membership and handle failure we do the
same thing we basically take these
variables and we break them up we also
have a mode where we can basically
create copies of them and co-locate them
together if we want to do an optimized
execution that has less network
communication we used react core to do
this I'm not going to talk about react
core because you probably heard about it
a hundred times we use quorum requests
which basically ensure that we read and
write to majorities and then we have an
anti entropy
protocol which is core to making sure
that we have all replicas observe all
updates when we can drop messages again
we have a hybrid model as well which can
which basically replicates centralized
execution so you can have the variables
spread out all over the place and have
you know do your computation across all
these different nodes or you can
basically say well I want to ensure that
all of these things are co-located on
one partition because I need it to be
fast so we had this hybrid model where
you can play around with how the
distribution works doesn't change the
semantics of it doesn't change the
semantics because the semantics are
written using the harder one where
variables are in arbitrary locations so
we'll talk about some examples quickly
so here's a sample of the language so we
declare a variable we sign it to s1 this
gives you a unique ID back for that
variable this update function takes you
know for the purpose of the prototype it
takes operations applied to see Artie T
so this uses the this uses the react DT
interface here so this is a doll says
that I you know so I declared this
should be a set screw it up and slide
whatever we say update we're going to
update this s1 that we got back here
we're going to add elements 1 2 3 to the
set and a is the actor so I've just put
some dummy value in there but what you
want to do is use unique identifiers to
properly identify concurrency in the
network so this could be whatever and
then we create a second set and then we
can map things so we say I have s1 which
is the starting set that I've added 1 2
and 3 2 I want to apply this
multiplication by to function and I want
to put the result in s2 which is also a
set pretty similar to normal Erlang kind
of map stuff this declare thing is
something that you have to do because
it's you know that we have to say we'll
go out to the network make this variable
on all these replicas so this is what
the language kind of looks like the
centralized execution uses a module
called last core which the other one
calls into last chord takes a store
variable this is a reference to a data
to a system on disk so this would be
either a level DB reference or a bit
cask reference so leveldb magic binary
bit cast reference or X table name in
this case this is how we would run on a
central centralized execution so we can
have the programmer right in this
language and we can easily compile to
this language given a store right so
that's nice and we can also compile
early into this we don't do that because
that's kind of a trivial compilation
exercise but that's a essentially the
ultimate goal or go to the Erlang a
state
alright so let's talk about a real world
kind of thing that we're trying to build
so we're trying to build an
advertisement counter this advertisement
counter is going to track impressions so
everybody here has a mobile device you
all have Angry Birds for some reason
that's weird because of all in the same
room and everybody gets a list of
advertisement so while you're playing
the game you get ads we're going to
count how many times you see certain ads
you're going to see some ads from Rovio
you're going to see some ads from Erlang
solutions and we want to count the
number of impressions so these clients
are going to go offline and they're
going to continue to see ads then we
have to synchronize so we can't use a
normal counter because if we use a
normal counter and it's like to and to
do i add them well I don't know cuz he
might have already seen my one so right
it might be three might be two might be
one how do I know so what we need to do
is ensure its deterministic we want to
disable the advertisement on all the
mobile devices when its seen by five
hundred fifty thousand impressions and
we want to push that state to the client
so we're going to talk about one
possible monotonic design that ensures
that it converges correctly requires no
synchronization no snow global
synchronization clients have to
synchronize with like the centralized
data store which stores the ads so this
is that the information flow looks so
the information flow says we start out
with some ad counters here so we have
individual our counters these two
counters and this might be not too big I
apologize we Union them into this set
that's the set of all ads we do this for
rovio and we do this for riot let's
pretend these are the two people
displaying ads and what we do is we then
Union these so we Union these and then
we we're going to basically join them
with this contract saying so contracts
say this is like a thing that says I
should display the sides right so you'll
assume that we have a hundred ads maybe
50 of them have contracts so this is
like a joint you just imagine this is an
inner joint in a database right you're
going to like kind of join the contracts
with the advertisements and then so this
here is going to compute the Cartesian
product and then we're going to apply a
filter to say with the ids are equal so
in sequel you think about how a sequel
engine works that joins computes
Cartesian product it doesn't really do
this in the implementation but in
relational algebra you you do a
Cartesian product you apply some filter
on the product with the IDS or equal
conceptually that's how it makes sense
right and then essentially we push these
ads out to these clients these clients
going to read these ads and then every
time the client gets an increment it's
going to increment a local data
structure that we sent to it and then
that data structure is going to be
propagated back occasionally so how
often do we do this well
the major divergence if we want to allow
clients display ads more than they
should that's fine you can make the
synchronization windows small each
client just has to check in periodically
if you want to ensure that the
divergence is small they have to check
in more recently if you want to ensure
that the divergence is bounded you need
to basically also send a maximum number
that that client consent but this design
is synchronization free so essentially
when this counter hits 50,000 a process
sends a thing to remove it from the set
of displayable ads or maybe it changes
the contracts and then we basically
recompute so this red path shows that we
have this update come in it triggers
this read and then we basically re
propagate the state and that all is
monotonically advancing state it's all
logically time moving forward it
requires no synchronization if messages
are delayed dropped or reordered the
algorithm is correct and it works so now
it's just how you reason about
divergence oh man running low so anyway
monotonic design metadata to prevent
duplication so I'm almost done actually
i'll have to skip related work but you
can talk to me later about that so in
this design what we really like here is
that this is how you would normally
think about distributing it right we
would say server processes client
processes yeah an inch of client model
right but we don't need to do that we
can do this right because we can
guarantee that at these boundaries these
communications points we use these data
structures that allow us to reorder
things and component compose these
things reorder things handled
duplication handle repeated message
delivery handle all this great stuff so
all we have to do is ensure at these
message boundaries here we use a data
structure that handles this correct
metadata mapping and that's really nice
and this can be I don't know so why was
that dinner the other night and somebody
was like hey that's a micro servers and
I was like I don't know what Microsoft's
is our but cool like so yeah that's
great right um but so but so that's an
interesting thing so we can move this
state around so in our going back to our
internet of things we say that this is
the centralized server this could be
some edge routing node maybe or maybe
it's on the centralized server as well
if we go to this one this could be at
some core node and these could be the
clients or these good to be the mobile
clients and this could be the server
right the architecture allows us to
arbitrarily distribute the graph so I'm
running really low so there's some code
it's all on github it's in my slides
slides will be online you can look at it
you can bug me I'm happy to talk about
this all the time
it's all I think about and this is the
code to do the entire ad counter
essentially here we set up some state
except for the server which disables the
ads and the client which displays them
we say we make some ads we join them
together we start some servers we start
some clients and that's it right so
there's not a lot of time to work but
the related work is distributed oz
there's a we've written up a lot on this
so i can send it to you der flow was our
first work blue ml is related to work
that does logic programming without crd
tease l VARs this works on single node
kind of this architecture on a single
mode with threshold reads which assumes
a priori knowledge of state change d
streams is similar because it applies
kind of probabilistic techniques and it
can handle like duplication message
delivery and all this fancy stuff and
finally and it realizes streams and
batches of changes which is very similar
to the model that we use and finally
summing bird is a work from Twitter that
uses commutative mono aids which is very
similar to ours which are commutative
I'd impotent mono aids to basically
ensure that we can handle all these
weird delivery things that happen in
real networks and finally future work we
want to make it faster we want to use
Delta at crd T's we want to use the o.r
swat we want to use operation based CRT
T's we want to use deforestation to
basically reduce the amount of
computation we have to do with those big
massive tree structures in the graphs
the source is available on github under
my name there's an underlying workshop
paper there's a euro civ aper and
finally this work some of the members
doing this work have been funded under
the sink free European research project
so there's the EU flag and finally
that's it thank
45 19 no questions must have been really
good then right it's lot but yeah yeah
yes yes everything is there yep it's all
open source it's all available it's all
under the apache to license yep
absolutely yes he's a library yes his
library there was some worked at me and
Shaun have specifically talked about and
Peter's talked about where we want to
basically have like a higher-level
language that is more expressive for
doing like kind of programming of data
flows and then find a way to have a
compiler basically build the programs
and then distribute them so if you think
about Apollo so Impala is another
related work I forget to mention but i'm
paula has a similar design where they
basically use LOV em to compile like
portion of sequel queries and then it
distributes these binaries everywhere so
it's a similar model where we want to
have custom language go to an AST build
a bunch of fragmented programs and then
we ship the fragmented programs on the
wire so we have the fragmented program
piece working but yes
yes so the prototype does not so the
semantics hold under dynamic membership
the handoff mechanism doesn't hand off
all of the state currently because we've
added a bunch of new stuff and I haven't
got hand off working yet so while it
works conceptually I just haven't had
time to write the code yet right the a
stuff is a little funky too we have a
really really bad AE process so this is
why we want to extract a out of kV and
put it in core because right now we have
to like our simplified model just to
make get the guarantees that we want in
the prototype is like we'll just send
everything again right like that's a bet
it it's not great let it satisfies the
you know the constraints oh ok no ok
thanks appreciate it
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>