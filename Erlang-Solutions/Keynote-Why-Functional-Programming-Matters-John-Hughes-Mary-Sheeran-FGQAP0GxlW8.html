<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Keynote: Why Functional Programming Matters - John Hughes, Mary Sheeran | Coder Coacher - Coaching Coders</title><meta content="Keynote: Why Functional Programming Matters - John Hughes, Mary Sheeran - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Keynote: Why Functional Programming Matters - John Hughes, Mary Sheeran</b></h2><h5 class="post__date">2015-11-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FGQAP0GxlW8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so Mary and I are going to talk about
why functional programming matters and i
want to kick off by talking about
functional programming Alan 1940s so
back then functional programming was
pretty minimalist so you know think of
boolean for example who needs them all
you do with boolean is make a choice
right well we can do that with functions
so why don't we define functions true
and false and we'll let them make
choices to make a choice you've got to
have two things to choose between so
let's give them two arguments each and
say well true will choose the first one
false will choose the second one so
there we are now instead of bullion's we
can use these two functions or can we
well if I'm going to be able to use
these functions instead of bullion's I
need to be able to implement if there
else I can do that how can i define if
then else to take a boolean and choose
the then branch of its true and the else
branch if it's false well I could just
call the boolean and let the function
make the choice so that's great I don't
actually need boolean so i can use
functions instead and well while we're
at it what about integers I mean what
are integers for positive integers
except counting loops so why do we do
away with integers and instead use
functions that just iterate a loop so
we'll define to for example to take a
loop body F and a starting value X and
just iterate F twice and one will call F
once and 0 0 times and so on an
obviously Freddy integer now any
positive integer I can think of a
function that iterates a loop body that
many times and if I want to I could even
take one of these functions and recover
a normal integer just by iterating a
loop body that increments of normal
integer and starting from the lower
literature zero so if i take two and i
iterate the increment function twice
well i convert it to two of course so
that's great so i can take any integer
and represent it as a function this way
but that's only fun if i can do things
with them can I for example add them
together oh well hey if I want to
iterate f
m plus n times I can do that first of
all by iterating F n times and then M
times on the result that's m+ n great so
i can add two integers together i can
multiply integers by nesting loops if i
want to reiterate F M times n times then
I can just use an outer loop that
iterates M times and an in the loop body
I'll iterate F n times that's M times n
in total so i can multiply these things
does it work well let's add 1 to 2 times
2 that should be five right if I
construct 5 as a function and then i
iterate the increment function 5 x from
0 i get 5 wonderful now there's no
stopping me look here's factorial ala
1940 and i'm just using my simulated
bullion's and my simulated integers so
if i'm given n and it's 0 then i'll
choose one otherwise i'll multiply em by
the factorial of deca meant n there's
not a real integer or boolean inside
here it's all functions does it work
well let's take the factorial of 5 and
use that once it more to iterate
increment from 0 yes we get 120 it all
works hello there's a couple of
functions here I haven't defined I've
got to define a zero test that's easy
how do you tell whether one of these
functions represent 0 you just iterate a
loop body that returns false starting
from true so then if you integrate at
zero times you get true anything else
you get false and I also need to be able
to decrement what are these numbers and
the less said about that the better but
you can do it and so what do we get here
well we see that bullion's are integers
they're unnecessary we can do everything
with functions instead and actually the
same idea applies to other data
structures like you know pairs products
some types you name it any ordinary data
structure you can replace entirely by
functions so who wrote this code Alonzo
Church
these are Church encodings and it's more
than just a theoretical curiosity early
versions of the Glasgow Haskell compiler
actually implemented data structures
this way not integers of course that
would be crazy but the other data
structures it turned out there was a
time before pipelines we're so deep when
this was the fastest way to implement
data structures in haskell so that's
that's kind of cool before you try it
yeah I some of you I'm sure once try
this at home just make a confession if
you do you'll get an error message from
the type checker and it says okay cannot
construct the infinite type blah well
constructing infinite type sounds
difficult of course and don't worry you
get more information to help you debug
it the Haskell type checker will tell
you which type it was expecting and
which type you gave it and in other news
this is the first time I've used a three
point font on the slide so I I
appreciate it's a bit daunting to try
and figure out what's wrong from this
error message but don't worry there's
more
and you can perhaps get on there so this
isn't the kind of programming that
Haskell is most commonly used to do in
fact you need to give the type checker a
little bit of help you need to add one
line to the code I've shown you which is
to tell it what the type 4 factorial is
and the red bit here is what the type
checker canted firfer itself and it's
just telling the type checker what the
type of a church numeral ism apart from
that you can do it so the amazing thing
is the church could write this kind of
code without being able to debug it on a
computer but 20 years later you could
run this kind of code on computer thanks
to John McCarthy and Lisp and that is
the factorial function in the first
version of Lisp right from the start the
very first list paper also talks about
higher order functions so you could map
the factorial function down a list of
integers so functions as data was
important right from the start Matt
lists what we call map today and let's
got a lot of people very excited
including this guy Peter Landon who in
65 wrote a paper about the next 700
programming languages in the abstract of
the paper he says today 1700 special
programming languages are in use there
were seventeen hundred programming
languages already in 1965 that's kind of
a horrifying thought but peach be Landin
thought well if there are only 700
different application areas let's have
one language to rule them all with 700
different libraries that was his idea
really anyway there's the factorial
function in I swim his language and but
what I want to oversize is not really
the language but other idea that Peter
Landon really really stressed in this
paper and that was the importance of
laws about programs so what do I mean by
a law well here's a law about Lisp
programs which says that if you reverse
a list and then map a function over it
you'll get the same result as if you map
the function over the list and then
reverse it and that's nearly true it's
nearly true because of course those two
programs on each side of that
equivalence will perform the calls to F
in a different
so if earth has side effects that it
won't be true but no it's it's quite a
good law even so so Landon was a firm
believer in laws which were not nearly
true but true always and absolutely and
he even has a little discussion in his
paper when he thinks the reader might
doubt that the reader might look at an
equation like this and say what's the
point of having two different ways of
doing the same thing wouldn't it be
better if the two sides did something
different then you'd have two facilities
instead of just one and Landon thunders
no expressive power should be by design
rather than by accident I'm right you're
wrong I love that you can't disagree
with it can you and continuing on from
giants when John and I had a little bit
of marital strife about what to talk
about in this paper but there was in the
store but there was one paper that we
could just agree from the beginning must
be mentioned in this talk and it is
bacchus turing award paper the paper
related to his cheering award in 1977
called can programming be liberated from
the von Neumann style a functional style
and it's algebra programs this was a
hugely influential paper because Backus
was a giant among ordinary programming
language people he had he had developed
Fortran made a fantastic Fortran
compiler and he had also developed ways
to describe programming languages so he
was somebody with weight and he wrote
the paper now he got the during award
for all that in 1977 and he could have
written a paper wallowing in his the
great things that he had done but he
didn't do that he wrote a paper there
was another manifesto for functional
programming and if you haven't read this
paper you should do so it is an amazing
paper the first sentence of the abstract
is this conventional programming
languages are growing ever more enormous
but not stronger
and the rest of the abstract goes on to
list the defects that Bacchus saw in the
conventional programming languages of
the day so the next sentence is inherent
defects at the most basic level cause
them to be both fat both fat and weak in
this in this talk we're going to
concentrate on three of those defects
and his solutions for those defects and
then they're going to appear again and
again the first defect that he points
out already in the abstract is what he
calls the this programming languages
primitive word at a time style of
programming inherited from their common
ancestor the von Neumann machine so this
paper is the one that coined the term
the von Neumann bottleneck and but
backers explains that a computer has a
CPU and a store and a thin connection
between the two and you have to pass
words back and forth across this
connection and this influences our way
of doing programming and he is that one
of the theses of the paper is the von
Neumann way of designing machines also
had terrible effects on how we write
programs and he wanted to find a new way
of writing programs not by thinking
where does a time to go up through the
bottleneck but by thinking about whole
values and that's a theme that will come
back again and again in the talk so that
was the first effect word at a time the
second defect he points out is their
inability to effectively use powerful
combining forms to build larger programs
from smaller programs so it was the
second one what did he mean by combining
forms well he meant higher order
function what we would call today high
order functions I'm going to visualize a
couple of them now i'm going to
visualize them making use of bacchus way
of defining function composition so I'm
going to visualize programs as blocks
where data flows in and out of the
blocks so the date is going to flow from
right to left because his because of the
direction of his function composition so
this is as a kind of apply to all take a
function and apply to all elements of
enter he called that alpha this is what
he called construction which was to take
a bunch of functions and apply that
function those functions each to a
single input to produce so for four
functions will produce a vector of four
outputs construction so that and
composition again was another of his
combining corn so we could compose a map
with the construction for instance so
that was the second defect that normal
programming languages didn't have these
ways of building small programs from
larger program at large programs from
smaller programs defect number to defect
number three was their lack of useful
mathematical properties for reasonable
reasoning about programs so this is the
third important effect so he wanted to
develop combining forms and study the
laws that those combining forms of bait
as an as an way to assist the process of
developing programs let's look at a
couple of these laws so if we take a
construction and compose it with a
function that will be a construction of
F 1 2 FN composed with G that should
have the same behavior as if we move
that function along those inputs and so
that the function appear reappears at
the input of each of these colored
functions so this connection collection
of functions should have the same
behavior as the previous one and so and
this is described as a construction of
f1 composed with G f2 composed of G and
so on so we should have a law relating
those two programs so that was the first
his first example of an algebraic law
and the second one was if we have a map
composed with the construction if we
have this arrangement the functions we
can actually divide it up in two
different ways we can describe it as a
map combustor with construction or we
can divide it up in the other direction
and described it as a construction of s
composed with G 1 F composed with G 2
and so on
so this is an example of a law which is
here are two different ways to describe
the same arrangement of functions so
these are the first two algebraic laws
that Backus lists in his his during
award paper and then he has a whole
bunch of other laws about his other
combining forms and he gives a very
small exact his first program that he
shows is inner product he starts by
showing it in a Fortran like language so
we're going to you know a science ii to
be 0 then we're going to have a for loop
which gradually builds up the result of
taking the inner product of a and b and
he spends about half a page taking this
program apart and saying this is
dreadful we don't want to think words at
a time and the the things we need to
think about are spread out in the
program and this is not how we want to
write programs we don't want to have to
algorithmically sequentially say how to
make the result we would like to give a
kind of denotation of the result and
this is his inner product program we
read from the right we take our pair of
vectors we transpose it we apply to all
of multiplication and then we compose
insert + between all the resulting
values or fold plus we perhaps would say
now or reduce plus and then he borrowed
from APL and introduced APL like
notation for many of his combining forms
and this might have been a mistake so we
have trans composed with apply to all of
multiplication composed with insert a
plus for your inner product and what I'm
going to do next is not continue talking
about what is in the rest of access
paper but I'm going to move on to
another paper that I see as a kind of
bacchus paper light this is functional
geometry so i arrived in oxford 1980 and
peter Henderson who wrote this paper was
my supervisor and when i arrived in
oxford he was having fantastic fun with
bits of tracing paper
and drawing lines and drawing pictures
of fish and trying to figure how they
fitted together in order to construct
asherz square limit fish picture and he
wrote a paper about that that appeared
in 1982 and what he did was he studied
the ways to combine small pictures to
make larger pictures and he so he builds
the entire square limit picture out of a
single fish here's our initial fish what
we're going to do is develop a set of
combining forms that allows us allow us
to rotate it and flip it and then plug
them all together to make the final
square limit so we could compose two
fishes by overlaying our first fish with
a rotation of a rotation of that
original fish that's two fishes we can
compose three fishes by overlaying the
first fish with two other versions of
fish fish too and fish three which are
defined in terms of rotation by 45
degrees with flip or three rotations so
now we have one fish we have a two fish
and we have a three fish and you can see
that Asher was quite clever in his way
of designing the the blocks the the sub
parts of his picture because they all
fit together very beautifully we can
also fit together for fishes by
overlaying the original fish a rotation
one rotation two rotations and three
rotations of there is no fish and it's
still all fits beautifully together and
then we begin to think of so now we have
one two three and four fish and we need
to think of how do we plug together
larger collections of them so Peter
introduces above and beside for
composing pictures and then quartet
which allows you to compose for pictures
without any overlaying now but beside
and above and then cycle allows you to
compose four copies of the same picture
with rotated as you go around and with
that we can make cycle of rotate of our
three fish and then a quartet of that
and we're getting somewhere now when
we're getting closer to what the square
limit look like this is a good middle of
the picture and the
next part of the paper figures out how
to make the sides how to add some stuff
on the top on the edges so if we take
quartet of nil nil rotate about three
fish under three fish we get that and
then we take quartet of that twice so
that is we take two copies of that on
top of itself this all still fits
together so that'll make a fairly decent
side and then he considers how to make
the corners of the picture and again he
uses some quartets and he introduces a
sequence of corners that add smaller and
smaller parts along the edge of the of
the of the corner and finally he takes
nine different pictures and puts them
together and no net instead of a quartet
so we have the corner rotated in all
once twice three and three times we have
the side rotated three times that we
have you are original middle in the
middle and we're done so this is a
denotational description of of the
square limit picture but Peter had
another trick up his sleeve and that's
what even so you might have imagined
that he would just have a data structure
for these pictures and then he would
walk over them somehow and draw the
picture but no he has pictures as
functions so that the pictures of
function theme continues so a picture is
going to be a function from three
vectors to whatever you need to produce
to draw the picture so and the three
functions are going to point to the
origin the kind of bottom bottom of the
picture and the on the left they could
be parallelograms but we're going to
house them as rectangles here I wanted
made that decision that a picture is
going to be a function it becomes very
easy to define what these combining
forms are so over a P&amp;amp;Q applied to its
three vectors well it's just going to be
applied to its three vectors and you
apply to the same three vectors and
that's going to produce all the lines
that you need to produce to draw the
picture it up in the same pair of in the
same triple of vectors similarly we can
define beside for a B and C as p vectors
a B over 2 and C and Q and factors a
plus B over to be over to Z and rotation
if we want to rotate the the picture
that has three vectors a B and C then we
just need to move the origin over to
that corner so that's a plus B and then
it's it's a next next vector is going to
be C and its third vector is going to be
minus B and we need a way to produce
pictures from our basic pictures as well
so he needed a way to produce a picture
of the original fish and in this in
designing this set of combining forms
for pictures peter was very concerned
about the laws that they should obey so
here's an example of one of the laws
rotate of above and p and q is the same
as beside of rotate of p and rotate of q
and he remarked that having listed the
laws of his combining forms it seems
there is a positive correlation between
the simplicity of the rules and the
quality of the of the algebra as a
descriptive tool and so this is an
example of laws as a litmus test in your
design of your combining forms and so
we've seen the reason i call it Backus
light is that we've seen all of the
ideas from the three defects and their
solutions from boxes paper reappear
again we have whole values we're talking
about whole pictures we have combining
forms and we have algebraic laws as a
litmus test for your design of your
combining forms and peter has added one
extra thing which is functions as
representations because he has pictures
as functions
and at the very end of the paper he sums
up what is the important idea in this
paper he says the basic idea exemplified
in this paper is simple denotations of
objects are easier to understand than
algorithmic descriptions of how to build
as objects so Peters paper is a
manifesto for thinking about how to
describe things d notationally and if
you want to play with functional
geometry and pictures one way to go is
to look at work by Colonel Elliot who
has taken this denotational approach to
the very limit and talked and worked
about beautiful work about functional
image synthesis it's called pan and you
can go away and play with it and it's
got lots of very mind-bending pictures
that you can also look at ok so we're
going to skip ahead a little bit in time
I just what to tell a story that I like
very much from the mid 90s and so at
that time DARPA had a big project that
they were running in software
prototyping and at that time you
couldn't get money from DARPA to work on
developing Haskell as a real programming
language but Paul hudec got money to
work on haskell as a prototyping
language there is nothing to be ashamed
of in that Haskell was in here along
with other well-known prototyping
languages like Ada and C++ but they got
the money from this anyway and partway
through the project DARPA decided that
they would run an experiment to evaluate
how good these various languages where a
prototyping and Mark Jones got the job
of solving the problem that DARPA posed
constructing the prototype for
comparison with these other languages so
DARPA being DARPA it was a rather
military kind of application the
two-dimensional geoserver so you are
given positions and tracks of ships and
aircraft and you were supposed to
classify regions of 2d space into areas
with strange names like weapon doctrine
and slave doctrine and tight zone this
being DARPA
and and so mark began to prototype this
and oh you were supposed to out produce
output that would say a time forward if
the commercial aircraft will be here in
the engage ability zone in the tight
zone the hostile craft will be somewhere
else and so on so mark start approached
typing this and the first thing he
decided was he had to represent regions
in the plane and why not use functions
for that so a Reacher will just be a
function from a point to a boolean it's
true if the point is in the region and
false of it's not and he started
defining some simple regions like a
circle with a given radius is really
easy to define and the outside of a
region where you just negate the boolean
that's dead easy the intersection of two
regions the point is in the intersection
if it's in the first and it's in the
second so you just conjoined the two
bullets some very simple primitives and
then he could go on to define an annulus
that that's the ring shape that was in
the diagram which is just the outside of
one circle intersected with the inside
of the next and so on and he built the
prototype and when the results were
compared marks Haskell solution was 85
lines of code it was the shortest of all
of the solutions that were submitted and
it was an order of magnitude smaller
than the prototypes in ada or C++ so
when when DARPA got this they basically
didn't believe it they thought well yes
but if you use Mark Jones to build your
prototype then no wonder you get a small
solution it's also by the way it's got
the most documentation and one of the
shortest development times so DARPA said
okay without telling Paul or mark they
picked a graduate student somewhere else
I said okay you've got eight days to
learn Haskell go away and solve the
problem and that graduate solution
graduate student solution is the second
shortest
the annoying thing here is the result
could have been even better because Mark
had put in 29 lines that the type
checker would have inferred for him so
it could have been 56 lines of code
there so you would think okay this is a
great success Haskell has been very
successful so what did the evaluator say
too cute for its own good higher-order
functions are just a trick probably not
useful in other contexts if church had
been dead i'm sure he would have turned
in his grave anyway um going backwards
in time again a little bit now in 1976
there was two papers that describe
different aspects of a new discovery
lazy evaluation Henderson Morris wrote a
paper on a lazy evaluator and free bland
wise wrote a paper called con should not
evaluate its arguments to both they're
both credited with the invention of lazy
evaluation and that's really significant
for the themes we're describing because
it means that the whole value that we
keep talking about can actually be
infinite for example you can have a
value that is the infinite list of all
natural numbers or I started off talking
about using functions to iterate a loop
body well now we can iterate F every
possible number of times we have an
infinite list of all of those iterations
and you don't fall into an infinite loop
because when you write this code it
doesn't mean that you will compute
infinitely many elements it means the
consumer gets to decide how many
elements will be computed that's the key
idea of lazy evaluation so what you're
writing here is code which can produce
arbitrarily many list elements but the
consumer decides how many you want and I
saw this and I thought oh gosh that'd be
great for numerical algorithms which I'd
always had trouble writing so here's a
consumer function for that you might use
in numerical methods you give it an
infinite list of approximations that are
converging to the correct value and
we'll just pick the first one that's
within epsilon of its predecessor so we
just keep going until it converges and
if you write this limit
function and then you use lazy infinite
lists of approximations you can write
numerical algorithms very very prettily
here's the newton raphson's square root
function for example so you compute one
approximation from the previous one with
this next function that you see there
and if we just iterate that starting
from any value really I pick one and
then wait until it converges you get the
square root here's how you might compute
a derivative so to compute a derivative
of a function at the point X or you take
X at a point close to it and you compute
the slope of a you know a little line
segment between those two points and
then the gap h is something that as you
make it smaller and smaller and smaller
so the value you get converges to the
true value of the derivative so here I'm
just making a list of h's that's getting
smaller by having at each step using
each one to compute the slope and then
take you the limit in the same way and
what you see here is that the
convergence check is the same in each
case it's reused I would have to write
at once but I'm using different
approximation sequences and once you
start programming in this way you can
take it even further so differentiation
is done by taking two nearby points and
computing a slope but you integrate in a
similar kind of way you can use the
trapezium rule where you add up the
areas of a lot of thin rectangles let's
call that with H as well now the key
thing here is that in both cases the
smaller you make H the better the
approximation you get and it turns out
that whenever you're you're using a
method like this that's based on some
parameter H that's getting smaller what
you get is the right answer let's call
it a plus an error term which is
approximately something times a power of
age so now if you take two successive
approximations right we know and we know
H we've got we know these two values and
there's two unknowns a and B remember
school mathematics you can solve for a
but a is the right answer so if you've
got a secrets of approximations you
could just take the first two
and solve and get the right answer you
don't need to bother with the rest well
that's not quite true actually what you
get here it may be a better
approximation than many of these but
it's still an approximation however if
you take the following two which are a
little bit more accurate and do the same
thing you'll get an even better
approximation and so on so can you can
use this trick and just solve for a at
each step and you get another sequence
that converges much faster what you've
done is you've eliminated one error term
from the method and once you can do that
you can do it again look here's a really
really fast derivative first of all
we'll make the sequence of
approximations with a simple method and
then let me eliminate two error terms
that's given gives me a secrets that
converges at lightning speed and I'll
just take the limit using the same
convergys check that I used before and
so I really love this everything is
programmed separately it's easy to
understand and it's thanks to this whole
value programming where we manipulate
the whole value the whole sequence of
approximations in one go so these are
some of the key examples in by old paper
by functional propria matters they're an
instance of lazy producer-consumer so if
you have a producer and consumer and you
don't use lazy evaluation one of the
things that can happen is that the
producer can run ahead and keep going
faster than the consumer can keep up
with lazy evaluation then the consumer
demands each element and the producer
pries one at a time which also means
that when the consumer has had seen
enough the whole process stops and I've
just talked about using this where the
producer is producing numerical
approximations and the consumer is the
convergence test but there are many
other ways you can use the same idea
another way that I used it in the paper
is when the producer constructs a whole
search space as the value and the
consumer is the search strategy that
selects a value want from it in the
paper the search space was a search
space through a simple game noughts and
crosses
and the consumer was alpha beta search
but today I want to talk about another
paper that uses the same idea where I
designed a pretty printing library in 95
and here the search space is all of the
different ways to lay out something that
you want a pretty print all of the
different valid ways of lay something
out and the consumer is the selection
criterion for the best layout okay so
what is a pretty pretty to do well it
makes choices the whole time between
alternative layouts if you are printing
an if-then-else for example if
everything is short you might put it on
one line if it's a bit bigger you might
printed across several so a pretty
printer constantly has to choose between
a horizontal form and a vertical form
and in the vertical form you can see
here that there's some indentation but
of course you don't want that to appear
in a horizontal form so you're making
this horizontal vertical choice the
whole time and putting indentation in as
appropriate so how can we do that well
we want to work with whole values the
values in this case we're little
fragments of layout potentially with
some indentation attached and you can
put these fragments together vertically
in which case the layout is preserved
you get a bigger piece of layout and we
write that as a above be above see or
you can put them together horizontally
in which case the indentation gets
discarded and I wrote that as a beside
be besides seeing and if you think about
it okay and we also need to be able to
construct these little atomic bits of
layout and there's a function text that
converts a string to a little piece of
layout and a function nest that adds
some indentation so looking at these you
can see immediately that there must be
some laws that they satisfy I said we
discard indentation in the horizontal
form so if i put a beside something
nested well that must be the same as
throwing away the indentation just
putting a beside be of course we don't
throw it away
at the beginning of the line so if a is
nested then that's the same as actually
putting a beside be and then indenting
the whole combination with the
indentation that a had so here are two
laws that should hold about these
functions what you get start thinking
about and there are many more so when
you put three things together
horizontally it shouldn't matter how you
bracket it and if you look at the
picture and just imagine constructing it
either way you see you should get the
same result likewise vertically and even
when you combine them so if you put a
above be and put that beside see you get
the same thing as if you put a above be
beside see and that's because putting
things together horizontally in this
library put see beside the last line of
B so they you're kind of putting them
together like that but it's not true
that if you put a beside be above see
you get the same layout as if you put a
beside be above see because when you put
be above see that fixes their layout
relative to each other so on the right
see gets indented and on the left it
doesn't so you've got an interesting set
of laws here many things are true one or
two things aren't we need one more
function to write pretty printers and
that's the function that makes a choice
between horizontal layout and vertical
layout so set is just going to say I
might be horizontal I might be vertical
this is a slightly simplified
simplification but that's basically it
and now it's really easy to write pretty
princess here's a pretty printer for a
haskell tree type of binary trees so we
just have a case that says it's if it's
a lease we build a string and convert
that to a layout if it's a branch it
might be laid out horizontally or
vertically so it fits on one line it
will be horizontal otherwise we'll split
it into align with a branch on it and
then the indented left sub tree and the
indented right subtree with a closed
bracket added at the end that's all you
have to write and so as you can see it's
it's extremely simple the implementation
though has to figure out what layouts
you might get and what it does is it
uses the
laws behind the scenes to transform this
into the best layout and without
thinking about the laws I could not have
written a correct implementation of this
API or perhaps I should admit without
before I thought of the laws I wrote
very many wrong implementations of the
API I just couldn't get it right it's
it's tricky you need to understand how
these things should behave so then you
need a heuristic as well my heuristic
was to limit the output to the maximum
page width of course but then also limit
the length of the text on each line I
think if you only have a one line
document putting it all on one line it's
just because it fits in 79 characters
it's not necessarily a good idea it
might be more readable to split it so
that was my heuristic but because of
this separation between the consumer and
the producer you can use the same API
the same pretty printers with a
different layout function to get
alternative layouts so I know this was a
good idea because so many distinguished
people have improved on it afterwards
and that's always good sign so I want to
quickly bench one more thing I'm
probably best known nowadays for my work
on quick check which kun klassen and I
initially came up with it in two
thousand what does it do if you haven't
seen it well you write down properties
of your program so here's a property and
aired lag of the reverse function that
says for any list X's if you reverse it
twice you get the same this back again
and then you can test that and quick
check runs a lot of random tests and
says yes it seems to be true if you
write a wrong property then like this
one that says if you reverse a list you
get the same this back again of course
that's not true then quick check will
first of all say that's not true here's
a counterexample it's a randomly
generated one very hard to understand
but then it shrinks it down to a minimal
counterexample 0 1 which is much easier
to understand why is this minimal well
if you only have 0 or 1 elements of the
list reversing it does leave it
unchanged if you have two elements that
are the same in a list reversing it Lisa
done changed so you need two elements
they have to be different 0 and 1 are
the smallest two different values and so
that's the smallest countries
so why mention it now because it's the
same idea what's happening is that a
property describes the space of all
possible tests the consumer is quick
chek quick check search strategy but
quick check first of all does some
random search and then a systematic one
to find the mineral counterexample it's
the same its whole value programming the
whole value is the property and it bakes
quick check really simple to to use ok
I'm going to skip this in the interest
of time Mary there was just a teaser but
I'm going out of place right I want to
return to pictures now this is a book
that appeared in 1980 the same year as i
arrived in oxford and it was Bacchus
attempted to revenue revolutionize
programming this book by meet in conway
did revolutionize how we design circuits
because this this is a book that came
out in 1980 and that opened VLSI design
to ordinary people like computer
scientists and it has changed the way
that hardware is designed it has led to
the foundation of companies like Intel
and so on but if you look at the this is
a VLSI circuit it's not a million miles
away from square limit right so if you
can figure out how to just how to draw
square limit you can probably also
figure out how to draw these kind of
circuits so while Peter was having fun
drawing fishs I was having a lot of
stress trying to draw real circuits and
we had it we had a four pen plotter and
we used to go to the bottom of the prg
and watch the plotter drawing the
circuits and the reason why it's
stressful is that if you get it wrong if
you for example connect your power wire
to your ground wire then you send it
away to be fabricating you wait nine
months for the results to come back so
you have to get it right so my first
attempt to to produce circuits was to
use functional geometry directly to
design circuits at this level drawing
each of the transit
tourism and describing it and that
seemed like something we needed to
improve on so we need to add a
programming language about that and and
at exactly the right time Bacchus is
paper appeared and told us how to
describe regular thing so that the one
of the themes in the lead and Conway
book is we should describe circuits as
regular structures of small cells that's
how we should do it and Baxter's paper
could be seen as an explanation of how
to describe things that are regular
structures of small cells so I wanted to
think about in what way do Bacchus laws
help us in the process of designing
circuits so here's an example if you
have an orange circuit and you know how
to push to Cirque to blue circles
through it to have and have the blue
circle remain then this is also the case
that if you have a kind of block that
looks like this with the one of these
inserts or reduce at the bottom then you
can gradually push pairs of blue circles
through so that you end up with
something that looks like this so and
that has the same behavior as the
previous circuit so if these orange
circles for example are registers than
what you're thinking about here are
pipelining of circuits so what I did was
take FP bacchus is FP and turn it into a
language which describes plugging
together streaming functions and and
then it's possible to apply laws like
this so you get what you're going to do
is you're going to you can if you wish
to replace a block of circles composed
of the reduction by oops a triangle of
circles composed of the reduction of
something which is the composition of a
square circuit on the circuit and this
is exactly the kind of reasoning that
our industrial partners at that time
plessy we're looking for so they came to
the prj and they wanted to talk to
people about designing circuits and of
course I as the doctoral student was
wheeled out to talk to them and they had
of course red meat in conway too and
they were trying to design regular array
circuits and they're having trouble with
a regular race so what they were doing
was drawing the circuits on large pieces
of graph paper in a room and then they
were walking around on the graph paper
in order to try to figure out where the
data with me to the right places in the
circuit so what we did was provide them
with a little implementation of mu FP
and the symbolic simulator for that
little programming language and they
were then able to use that to think
about how data flows in their circuit
and to experiment with different ways of
doing things and they wrote a nice paper
about that saying that using mew FP the
array processing element was described
in just one line of code muf p has taken
the APL approach to Combinator's and the
complete array required four lines of
your fee description and USP enables the
effects of adding or moving data latches
within the array to be assessed quickly
so having a language describe what
you're trying to think about gave a way
to play with designs and to understand
designs they didn't then use them you
have P to generate the real circuit but
they describe that separately that was
nice unfortunately our other industrial
partner at that point bought Plessy and
close down the design team so we did not
look we did not go on two worlds
domination and but we still continue to
think about combining forms for
describing circuits I'm going to think
about whole values so we're going to
think about in those two circuits that
are kind of arrays the values which I'm
going to draw think of us read with
column first so first column second
comments on if we want to take a
function f and apply it to every second
element of the array we're going to call
that ill and two will be a function that
applies f to the first half of the array
and to the second half of the array and
if you think of a picture that looks
like this here's a law about to until
two of ill of f is the same as ill of 2
of f you can think of dividing this
picture up in different ways and once
you have combining forms like to an ill
you can begin to describe very regular
structures here's an example of a
regular structure a so called butterfly
network a butterfly network can be
described as an interleave up to half
size butterfly net works composed with
something which applies an F to the each
pair of its inputs and we can draw it in
by unrolling the picture so we have data
flowing through on these wires and these
vertical things are the applications of
F and the interleaves produce these
arrangement of wires this might be a bit
difficult to read so there's a kind of
standard notation we can pull the wires
so that the f's stretch and the wires
remain horizontal this is a picture of
the recursive butterfly network and the
butterfly network is an important part
of a famous sorting network by backers
by a patcher call it by tonic sorting
Network so he figured out that if you
have a by tonic sequence that is the
sequence whose first half was increasing
and second half is decreasing and you
push it through just the first part of
such a butterfly network you'll end up
with two half size by tonic sequences
and all of the elements of the the top
half will be greater than or equal to
all of the element of this of the next
half so if you keep pushing you'll get
from
tonic sequence to a sorted sequence so
this is a merger it merges two sorted
sequences to produce a sorted sequence
if these little f's are two sorters and
once you figure out how to make the
merger you can again figure out how to
make a sorter because what was the
bionic sequence it was a sequence his
first half assorted increasing and
second half was sort of decreasing how
will we make a sorter use recursion will
sort the first half using s will sort
the second half using s reverse the
output and put everything into the
merger so this is a doubly recursive
sorting algorithm which we can lay out
on in hardware or implemented software
and for 16 inputs for instance this
network it contains 80 of those two
sorters and bacchus invented another
sorting algorithm called back Assad even
merge so that the merger is just defined
using interleave again but the the final
part of the circuit doesn't apply the F
between the even pairs but between the
old pairs and passes the first under
last element through so this is the
odd-even merger which can be used to
make into make into a sorter it turns
out that that merger sorts a pair of
sorted lists or two sorted lists and
because of the use of the odds which
passes some values through this has only
63 comparators for 16 inputs it turns
out to that there's lots of puzzles
remaining about sorting networks so
having a language of combining forms to
describe them can be very useful if you
want to try to design sorting network so
i can tell you that the best-known 16
input sorting network has 60 comparators
and nobody understands it and we don't
know if you can do better or not so
there's lots of open questions
and I'm following on from this obsession
with combining forms we have made we
made a library in hospital lava which
you could view as a kind of functional
geometry for circuits it's based on
exactly the same kinds of ideas and
indeed there was a version of it that
used functional geometry internally to
give the programmer control over
relative placement of the circuits and
at that time satnam singh was employed
at xilinx so we had a great cat and
mouse game with sightings we would
invent combining forms lay them out with
relative placement get beautiful FPGA
layouts like this and then they design
links tools would try to lay out the
same thing using simulated annealing or
whatever and we would end up with you
know spirals and all kinds of things and
they would improve their tools and we
think of more combining forms and so on
and there have been many versions of
lava since then in various languages
this one called chisel currently in
Scala which you might like to play with
if you want to play with the designing
circuits and if you need a puzzle to
keep you going during the rest of the
day and you might not want to make a
sorting Network you might want to make a
network that takes an odd number of
elements in and produces the median
element at the middle output but all the
elements above and greater than or equal
to and all the elements below less than
or equal to so this for example is a 25
input median which is important function
in for example image processing this one
has 96 comparators the best kind of one
that you can find in the literature has
99 and I published a paper where I was
too embarrassed about the the code that
produced 96 so I showed the good the
code that produced 98 but we don't know
either how well we can do here so
there's plenty of opportunity for
functional hacking and search and so on
to try to improve on that and I just
want to say very briefly you're probably
thinking oh
it's just puzzles you know nothing to do
the real world well even at Intel there
is use of functional programming in in
their verification now if you're a
company like Intel you would like your
your processors to obey various useful
laws and in 19 I think 96 was it there
was a so-called Pentium law where you
got you know and minus M times n over m
equals oops 256 and they took a 500
million billion dollar loss because of
this they had to recall all the
processors and they became very
interested in formal verification and
hard oh heard all my friends and the the
formal verification system that was
developed from that time until now is
called 40 and it's based on a lazy
functional programming language called
FL and it has thousands of users so
there's a quiet revolution in the use of
functional programming that goes on in
Intel behind closed doors so it's a lazy
functional language with built-in
decision procedures and the symbolic
simulator like what we gave to the
Plessy people long ago and it's
extremely cool so they use the
programming language for all kinds of
things from design language to
specification language to implementation
language for theorem provers and so on
and there's another company that I will
mention only briefly called blue speck
so you might also be thinking oh but you
know vhdl in Verilog still dominate so
it's all very well that Intel are using
a function language behind closed doors
for verification but it is one company
called blue speck that is pushing the
idea of using a functional programming
language to do hardware design and
they've taken some of the ideas that
I've shown you about combining forms for
describing circuits and they've added
another idea which is to add the idea of
guard guarded transition rules gorgeous
atomic transition rules so you you
describe your architecture using the
same kinds of combining forms but you
could also describe ways of dynamically
you
in different parts of the architecture
and so on and it generates very long and
it's very explicitly about abandoning
the sequential von Norman legacy that we
have and and it's also got a kind of
secret weapon and that is that there is
a quick check now associated with blue
speck it's called blue check and it
allows users to write a synthesizable
test bench they just write their
properties and they get checking a la
quick check and there's this idea of a
generic test bench is apparently blowing
minds in the hardware community and
perhaps the coolest thing about this is
that the shrinking that John talked
about an iterative deepening can be
implemented directly on the FPGA so that
it will go very fast so that people are
generally using FPGAs to emulate
circuits and so they would like to be
able to very quickly do quick checking
of the circuits and they can do that now
using blue blue speck so this is a very
nice bringing together of ideas so we've
talked about four key ideas using
functions as representations programming
with whole values rather than a word at
a time using powerful combining forms
through base simple laws and those have
occurred again and again throughout the
talk functions representations that was
church and the other three are in
Baxter's paper so use these ideas stand
on the shoulders of giants that's all
we've got thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>