<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang and Deep Learning by Garrett Smith | Coder Coacher - Coaching Coders</title><meta content="Erlang and Deep Learning by Garrett Smith - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang and Deep Learning by Garrett Smith</b></h2><h5 class="post__date">2016-09-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/iMhBEVCgPdg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay how many people have heard of deep
learning
I hadn't heard of it last October friend
of mine called up and said hey have you
heard of this thing deep learning I said
have no idea we were talking about and
he said it's a pretty big deal and he
got into till why it's a big deal and if
you know anything about me you know that
I usually look at big deals and like
it's probably not a big deal but this is
a big deal and I'm gonna get into some
of that I probably to spend more time
with deep learning that I will Erlang it
maybe we'll see how the time goes okay
so let's get started with this deep
revolution this is a complete revolution
if you deep learning is a sort of a
subsection of machine learning and it's
very specific and I'll get into the
specifics of it but folks within the
machine learning field or artificial
intelligence refer to this as the deep
revolution and it's occurred within the
last four or five years I mean it's
really exploded in the last four or five
years it's not exploded just in terms of
popularity and and coverage but in terms
of actual what's being done what's
what's being accomplished technically so
it's folks who are in the field doing
research saying this stuff is getting to
be crazy so let's get into some of the
crazy stuff here who's familiar with
this match that occurred earlier this
year so this is Lisa Dahl versus a robot
the man on the left is not a robot but
he is playing on behalf of the room
robots are not quite as capable as we
like them to be alphago is was created
by deep mind and which is now part of
Google and it's it's some hardcore AI
and this was accomplished roughly ten
years before folks thought it could be
accomplished so that a machine trained a
trained machine could beat a human go
champion because the nature of go it's a
very very deep game it's very complex
game and the typical tree search
algorithms are just not efficient enough
there's just not enough computational
power so these folks at deep mind used
deep learning to to cheat or to help
their tree search algorithm along the
way and and lo and behold they got this
result which is astounding and
everyone's very very excited about this
in the field who recognizes this little
guy this
of course Google self-driving car I
don't think it's out yet people talk
about you know self-driving cars
happening you know later this year or
next year and I I'm a little nervous
about that if you've if you've seen that
the Tesla news there's there's probably
some bug's to work out but nonetheless
this is coming well there's begin to be
a lot of cultural impact and and
legislation involved here but this is
happening you have a completely
independent car that has been programmed
by teaching it very similar the way you
would teach a human so it starts out not
being able to drive just going all over
the place and the algorithms that are
being used are training and learning
algorithms this is machine learning and
over time these cars develop the ability
to drive I it seems I don't know if the
metrics are out but but on par with
human drivers if not a great deal better
ok this is a really interesting that's
kind of a vignette it's this is an
illustration of reinforcement learning
which is basically teaching a computer
to do something by rewarding it for
something you want and we don't really
punish it because they get very angry
you reward it for doing something that
you want so in this case we can train a
computer to play pong by rewarding it
when it makes contact with the little
ball we're rewarding it when it has a
breakout this pong right or a breakout
this is breakout same thing so it's a
very interesting type of machine
learning but it's one that is very
similar the way we learn so we have sort
of we try something at random
experimentally and we get some feedback
from our environment that's what's going
on here this is a specific type of deep
learning this was a quote from an
internal meeting from the Google CEO
sundar pichai machine learning is a core
transformative way by which we are
thinking rethinking how we're doing
everything we are thoughtfully applying
it across all our products and there's
coverage of this and if you get into it
you'll see that there is a revolution
going on within Google within the
engineering half of Google as
engineering within Google and sort of
training the mindset to now reevaluate
every problem they've ever considered in
light of what is
on machine learning in general but a lot
of that hits in the deep learning space
alright so what are we talking about
when we say deep learning so this is
this is hard for me because I like I
last October I hadn't heard of what this
is so and this is actually a really
complex field most people I know who are
practitioners in this are PhDs who've
been doing this kind of work in school
for four to six years and and our are
very very knowledgeable across a wide
range of disciplines not the least of
which is mathematics I'm gonna try to
keep this very short so the the core of
this is this this sort of mathematical
construct called a perceptron and the
the job of a perceptron is to take a
bunch of inputs assign weights to them
and then transform that transform them
into an output using matrix
multiplication so it's basically saying
the output can be either a 0 or a 1 or a
negative 1 or some continuous then the
output can vary but it is a single
output it's a way of taking a bunch of
inputs weighting them and getting an
output this perceptron in this case we
see you know the sum of weights x times
the inputs it's applied against some
threshold so this is completely
domain-specific and you get some outcome
out output and it is usually sort of
within could be 0 again 0 1 negative 1
it's some sort of there's an application
function that transforms that output so
that's at the core that's of the the
core engine of this part which is a
neural network so this is a 3 layer
neural network you've got 3 perceptrons
or
nodes in the front you've got 4 in the
middle and one single perceptron on the
output and this is just sort of carrying
this mathematical transformation through
these these different layers so you have
your inputs I can't do that that doesn't
make any sense I can't point it here
you've got your inputs they are
transformed or their x-values are
transformed by their weights those
outputs in turn go into the next layer
and these things go on and on and on
until you get to the output that is
fundamentally what role Network does the
deep part of deep learning refers to
what we call the hidden layers hit
the ones that are neither the inputs nor
the outputs so here we have two hidden
layers we have our inputs which we can
see those are the things coming in from
our whatever that our our
domain-specific data we have the two
hidden layers and then we have our
single that our output layer which is
the result of this thing the huge
transformation is very computationally
intensive
that's a neural network when we talk
about deep it's adding lots of those
hidden layers by convention it's you
know two or three but I'll show you in a
moment that the deep notion is getting
turned on its head two or three or four
would be considered what we're
considered deep just a for just a few
years ago that is not the case now part
of the training mechanism so the core of
this process of deep learning not
surprisingly is training and what goes
on there is we take a bunch of outputs
and we'd randomly assign weights say
we're just gonna guess guess at certain
weights there's a whole science behind
coming up with the initialization of the
weights but you get the initialization
of the weights and you run the
mathematical formula out to the result
and you look at the result and you say
is this thing close to what I expected
it or want it to be or not and that term
close there has to be measured
specifically and that is measured
through a cost function or a loss
function so it's like you know if we're
doing classification on images and we
say you know here's a picture of a cat a
cat is your input your data goes through
the neural network and out comes the
classification of dog we'll say that's
that's bad that that has so we have a
high cost associated with that and
there's very specific ways of measuring
cost and that's another field unto
itself or is everyone with me so far
neural networks are sort of big
mathematical formula you put data in
them you get an output you compare that
in this particular scenario you compare
that output to what you expected and by
that you can measure how good this thing
is doing and we can or how bad in this
case it's doing and that's called loss
or cost what we want to do the whole
purpose of learning is to drive our cost
to zero or near zero so you want my
thing make these things as good as
possible as actor as possible so that
cost function we want to take the cost
little flash loss and drive that thing
to zero and there's a whole field of
science devoted to that that's an
optimization problem
and here we have what they call a this
is a a loss function which is the true
loss function what we want to do is find
the minimum of that so we want to
minimize our loss and there's there's a
specific algorithm that's used for
that's called gradient descent and
there's different approaches to this
field associated with this but the idea
is that you kind of meander take
different strategies for meandering
around along this gradient until you get
to what you hope is the global minimum
once you hit the global minimum of this
true cost function your model is as
effective and as trained as it can be
that's the goal we never get there but
that's that's the intent and what we do
is we iterate over and over and over
again so we start with a bunch of
guesses we run it through we get our
outputs measure that and we say oh not
so good
and there's this very fancy algorithm
called back propagation which uses it
I'll get into that in a second goes back
and says based on these weights how can
I how should I change that gradient what
I'm trying to find this loss there's a
strategy for finding that loss that's
called back for the back propagation
allows you to sort of retro
retrospectively look at your weights and
figure out if I make this change I
suspect my loss will go down that makes
sense inputs outputs the outputs can be
right or wrong if they're wrong we
assign that a cost and we try to
minimize that cost and we train this
thing over and over and over and over
and over and over and over until we get
what we think is good that is the the
process of training a deep network okay
that's the cool that's I think I got
five that in five minutes whether you
understand it or not I mean this is very
very tough sort of entry level domain
math and and mechanisms and it takes a
while to sort of even remotely
understand what's going on a lot of
experimentation so I'm going to skip
through back propagation it's sort of
magic it just works
you don't really need to know these
points let me use an illustration
because that may actually help to
highlight some of these crazy things all
right let's go here
did any of that make sense I I got the
impression that none of that makes sense
it didn't make any sense to me and I
spent about a week just reading that
stuff over and over again and what got
me into understanding would actually
with this this process of training well
first of all the payoff is robots so
there's just like take a step back and
get some perspective if you can get like
super cool AI learning this stuff isn't
necessarily that bad so that's the
motivation so it's a steep learning
curve but I think the upside is enormous
self-driving cars that's pretty pretty
sweet and what people are doing is
they're looking at this and they're
applying this to their business problems
and saying you know we've got all this
data and we can use this mechanism to
Train artificial intelligence to
automate certain things and solve
certain problems but we simply couldn't
solve five years ago it's profound its
revolutionary so don't get frustrated if
you don't understand everything here I
don't I understand maybe point one
percent of this stuff so here's an
illustration of a problem that these
neural networks can solve through this
iterative sort of brute-force approach
very intelligent brute-force approach so
here's a problem we have if you look at
what kind of scan I can't really zoom
over there if you look over at the right
you see two types of observations the
blue and the I think it's orange right
that orange color blind so all right so
blue is blue and not purple there's a
purple blue all right all right I should
have checked that before okay so it's
blue in the middle and orange around and
if you were to sort of taking a step
back let's take image recognition how do
you know it's a cat we know it's a cat
instantaneously because this is how we
work we're very very good at image
recognition how does the machine know
that well it used to be that people
would try to figure out katniss and they
would say okay well there's an eye here
and I hear and a nose and a mouth and
whiskers and that's a cat so what we'll
do is program the computer to figure out
if there's an ear here and you're here
and nose here and whiskers then we're
pretty sure we have a cat so this is
were manually created features somebody
would study the domain and program the
features and that did okay but it didn't
do very well and that's sort of where AI
has been for a
long time this approach and this you can
apply this here well I don't know what
this thing is but it's it's sort of two
concentric shapes and they're
well-defined you can see the boundary
how would you calculate that well if
there's a circle there so you can find
the center and you can calculate the
circle and then you can plot it and you
can say there it is the problem with
that is it doesn't generalize so if you
have something that's slightly different
your model fails miserably
if you rotate something a little you
know a little bit if you change
something your model is done it doesn't
work anymore so as much as you are
confident that you can you know draw a
circle around those blue dots and get
that separation perfect it doesn't
generalize and that's the fundamental
problem and that's where deep learning
is very very good so let me illustrate
this this is a neural network so we have
three layers we've got our two inputs we
have a single what we call a hidden
layer well it says two so they're
counting the first one is a hidden layer
and then a sink this output layer and
what I'm gonna do is I'm gonna run that
iteration I'm gonna click the play
button up here let's do this fullscreen
all right so I'm gonna click this play
button up here and what is gonna do is
it's going to go through the thing I
just described we have our network we
have our inputs which in this case are
randomly assigned so I'm gonna if I
reset this thing we have sort of
randomly assigned scatterplot there and
what's gonna do is it's gonna push these
numbers through starting with a guess
and it's gonna iteratively train until
something happened until you minimize
you you you drive this thing to minimize
its loss or cost here we go
now that happened really quickly let's
let's let's uh that's not fun let's make
this thing super simple all right that's
a single node that's capable of drawing
a straight line so what we would expect
here is we're gonna basically randomly
guess in our network is only capable it
only has so much information to draw a
line through these things so it's really
bad but what we can do is
add more information to the network add
more sort of knowledge capacity so you
can kind of think of these things as
representing the abstract myth of
something and it's very it's very missed
it's very sort of mystical to see how
these things learn literally learn
abstract is miss the abstract abstract
features of a particular domain all
right so I've added two more neurons
here and let's see what this looks like
so now we have nonlinear functions
actually let's do let's do one less here
all right this can this mathematically
translates to a parabola so we have a
parabola that's the best this thing can
possibly do with two neurons and it
draws a male now it's sort of weird it's
pretty good it's pretty good from so
little information if we add one more
node we can get the full thing all right
there it is now what you can see here
and this is I have the link and you can
go on I encourage you to go on because
this for me was the big I use this as a
tensor flow playground and it's just
running very straightforward neural
network math through the browser
application so you can just kind of play
around and very intuitively get a handle
of what's going on here but this thing
this layer here sort of has captured and
the information of that dimension
separating the the blue and the orange
at that dimension this has learned in
that dimension and then that dimension
this one over here has learned this
shape and this one over here has learned
that shape the outlet there are there
are two now to the output is on the far
that is the shape that's the output
layer okay so the final thing learned
that particular shape that's pretty easy
though in actual image recognition we
have much much more complex shapes I
mean looking at a cat or a dog or
anything really that we see the shapes
are quite non-trivial it's complicated
by the fact that these things can move
and turn and occur in different places
in the screen so it's a very very hard
problem to program let's use the same
neural network on this shape which is
much more difficult to to learn see we
see the cost function on this little
this this time-series bar above the
image that's the cost it's really stuck
it's really trying to do its best here
and stuck around you know it's about
forty percent accurate so they're doing
a terrible job of predicting so let's
let's stop this and I could play around
with this and I and I have and tweak
things here and there and try to
engineer how to perfectly fit this thing
in it's frustrating because it doesn't
it there's really your intuition sort of
falls over at this point as a
programmers and engineers a
mathematician that's not what's will go
what's going on in the field is this
this is exactly what's going on right
now deep learning people are doing this
they're closing their eyes not quite but
they're just clicking that button and
they're clicking this button and they're
adding as much as they can to the
network to give it the ability to learn
as much information now is there's no
intuition to what I did there there's no
particular mathematical it's just like
I'm turning this thing up to 11 let's
see what happens and this is this is the
field it's a little ironic cuz you have
so much rigorous math and then you've
got people who are just like let's see
what happens now this is gonna take a
little while but you're gonna see
something fairly astounding that's
playing right to engineer this by hand
is you know you'd have to you'd have to
know the math behind it and the problem
with reality is it changes it you just
can't do that you it doesn't generalize
but this is the same algorithm this this
neural network is an algorithm all I did
is reconfigure it it's an architectural
tweak and and it is doing weird stuff
but eerily it looks like it might be
learning something very early actually
super creepy some of this stuff is super
super creepy so from a social standpoint
you've got to have a strong stomach but
but from a from a technology standpoint
mathematical standpoint it's pretty it's
pretty cool so if I let this go you will
see I'm really tempted just to sit here
and watch it all day I could just part
of the fun of it but you can see it's
sort of these lost functions above there
are spiking all over the place but they
will converge
and this is a really non-trivial shape
but it is starting to figure it out our
loss is already down two point zero one
point zero 2 which is phenomenal so it's
doing a really really good job and it's
the same stinking algorithm we just
reconfigured its capacity in this
particular case this is the essence of
this field this is what's going on in
the field as it is delightful as this is
I have to I have to move on you can go
online and play around ok so what we saw
it was a very very primitive neural
network in fact we already have exceeded
I think we exceeded that we had 6 so
this is back in the 90s was
state-of-the-art now and Linette which
is one of the sort of early stage
successfully applied neural networks was
in the 1990s the revolution and we
talked about really happened in 2012
with alex net and this was a model that
was submitted for the image net
competition and the team just decided to
go deep and went from 6 letters to 12
letters that might not seem like a lot
but this process is extremely
computationally intensive and we'll see
that shortly this sort of leap is people
are like whoa that's completely crazy
but it blew everyone out of the water
I'm sure the the the the dramatic
increase in accuracy of these models it
was you know people are used to saying a
point 0.5 percent improvement in
accuracy this I think was a full like 8
percent of some really huge jump and it
got the entire world's attention and in
this field so that's Alex net it's a
it's a milestone in this in the field
and it's set off this revolution so
everyone's like well how deep can we go
well in the next year folks were just
like let's let's let's let's tweak some
hyper parameters so then the the ZF net
in 2013 was the winner an image net but
it really didn't it didn't materially
change the architecture google annette
and slash inception this is sort of a
lineage or a category of models really
bump things up in 2014 with 22 layers
this is incredible and this is like
supercomputer requirements
very very few people then could even run
these experiments so people are just
like well like if we can throw enough
computational power at this stuff we can
do some real damage I don't get into it
but the flip side of that is the data
the more data you have the Train the
more effective the model and these two
things go hand in hand and what white
people say this is sort of you know this
this convergence of having a lot of data
through the internet and in from
knowledge exchange and that sort of
Advent in human history and basically
super computers that we have at our
disposal and I'll get into that is what
is enabling this thing that was to only
two years ago vgg net 2014 went the
absurdist who can skip that that's the
runner the runner up ResNet in 2015 this
is another lineage now we're talking
about 50 layers
a hundred and one layers 152 layers and
it's doing better now 2016 next week
we're gonna have the 2006 everybody
can't wait to see who's gonna win it's
really really a cool field now these are
really well-defined problems imagenet is
a particular data set that's very
controlled but it's a competition to
drive experimentation in these models
everybody's going bonkers over over over
this I mean just in a week so people are
gonna be covering this to keep your eye
out there's cost though so
alphago who won earlier today pretty
much custom I made a custom super and
computer built for this this particular
application 1920 standard CPUs and this
is not just deep learning
alphago involves a lot of other
traditional machine learning or
statistical algorithms but what people
feel tipped the scales here was the
injection of deep learning in a
particular model I'm not gonna get into
that could go on and on but it's
extremely computationally intensive 280
GPUs now a really high on GPU this is
the stuff that you use for games a high
end GPU will cost about $1000 so that's
an expensive investment this is just for
a computer to play a go to play go this
is insane dude doing the math here if we
conservatively estimate this is
conserved
200 watts at load 1920 CPUs the wattage
required for that add to it the watt
required for the GPUs began very
conservative now they they may use low
lower wattage here but but compared to
what we usually use this is conservative
440 thousand Watts 20 Watts
for the the poor sucker who had to fight
this thing and he took one game out of
five
I mean hats off to Elise at all here
22,000 these are estimates but it's it's
still dramatic so what we're dealing
with is this incredible capability go is
sort of emblematic of solving a really
heart what we thought was a really hard
problem using this approach we have to
throw a lot of power at this thing and
if you can imagine this supercomputer
you can't just put that in the back of
your car so there's I I'm a little
skeptical that you know this revolution
if you look at these automatic these
self-driving cars their trunks are
filled with supercomputer supercomputing
equipment so there's a big cost to pay
to get this functionality and you'll see
in the field a lot of people are working
very hard to get the computational
requirements down so it isn't all about
accuracy it's about efficiency and power
consumption it's a really really
interesting field okay here's our here's
our GPU hmm at the center of this from a
software standpoint is this is Nvidia so
let's go back a second Nvidia owns this
space
I mean they've they they saw this many
six or seven years ago and I hate to say
bet the company because I don't know but
they really invested in in building GPU
features for deep learning so it's like
yeah the gate the video game industry is
great you know video rendering is great
we're really happy with that but where
we see the the big future is gonna be an
AI and deep learning so they have really
invested and they've invested a lot in
this later the software layer and this
is a developer facing layer so it's not
just writing the code but it's building
fidella for relations and all of the
things that go behind getting adoption
and they've got adoption this is
essentially a monopoly of api's and I
don't say that in a negative way I mean
in Nvidia has no Nvidia's gotten some
some criticism from some
the open-source community and at some
points in certain videos those of you
know I'm talking about know what I'm
talking about
but you know I think they've done for
being a closed source company they've
done a very good job of acting I think
very reasonably let's throw those
politics out the side is it doesn't
matter this is the reality if you're
doing deep learning programming you're
you are almost certainly using CUDA or
qu TNN and I want to take a few slides
to get into we don't need to understand
this but I have two slides here that
will illustrate that because ultimately
I will get to airline that this is a
supercomputer supercomputing
high-performance computing problem and
and early and just give you a hint is
not necessarily and automatically suited
for that I mean there's this thing
called MPI which is still used but in in
the HPC field and there's a reason for
that the I'm not gonna I won't get into
that just look at that and say you can't
even see it so it doesn't matter their
GPUs they have a very specific
architecture they are very specific
memory management and different types of
memory memory speed and and the
bandwidth to transfer memory back and
forth quickly becomes a bottleneck in
these exercises so the computing
architecture is the bottleneck in the on
the on the hardware side and NVIDIA is
working with companies like IBM to build
really cutting-edge platforms to support
this the dgx one is an example of that
one hundred fifty hundred and thirty
hundred something thousand for a
supercomputer in a box that you can put
under your desktop for that small price
okay here's a really quick example of
the type of tweaking that's being done
let's move off of that one so I saw a
presentation by an engineering at
Nirvana and he was getting into some
assembler optimizations
I have apt the finer the foggiest idea
what any of this stuff is but these are
examples of the work that's being done
to try to just to wring out every little
last just whatever a performance in this
platform a lot of investment going on at
these low levels
okay so that gives you an idea of the
sort of the you know what we're talking
about with these neural networks and
what it cost computationally what's
being invested to keep up with the
people turning this thing to 11 and
getting performed these performances
this is a line up of the sort of the
usual suspects in the deep learning
framework space tensorflow was announced
last October I think and I think it
became like the number the fastest
starred open-source departure the number
of records that broke for being the most
popular it has to do of course with this
being a really hot and exciting field
but I think it also has to do with this
is a really mature framework it was
being used for a while within Google and
then they open sourced it so it sort of
landed with a lot of capability it
originally wasn't it wasn't performant
people in the field were like this is
not nearly as fast as we thought it
would be a read hope but they fixed that
none of the regardless of the history it
remains at the top of the leaderboard
and has done is managed to get there
basically overnight Cafe is a framework
that focuses on convolutional networks
which is a the image this is this is the
sort of dominating architecture for for
visual classification C NT K is
Microsoft's et cetera etc but if you
want to get into these things as
programmers
I think that it's very reasonable to
just just start playing with the tools I
found myself being sort of intimidated
by this space you you need to feel
intimidated if you don't you're not
paying attention this is a brutally
demanding field it's so demanding that I
think at first glance you think how can
I possibly do anything in it and I'd
like to use this example back when
databases were being difficult and
computers were the same thing you know
every computer had its own database
approach and gradually these things sort
of standardized and one of the one of
the format's or algorithms even was
relational was a relational database
underneath the relational database is
this thing called relational calculus
which is the math I never learned
relational calculus but I could do
pretty pretty interesting things with
the databases so the tools were pretty
got pretty good I didn't have to know
the math I just used the tools I think
right now where we
are in the field is you know we've been
you know the the the mathematicians and
the the statisticians the machine
learning engine PhDs have been working
on the math for many many decades and
we're now starting to get the tools to
build quote the databases so we're kind
of like you know here's it here's a
library for building a b-tree or here's
that here's a library for doing this
kind of index or this kind of file store
and then we're starting to see
frameworks develop and then we're gonna
start seeing tools so I think we're in
this transition area where we've we've
pretty good on the math and the the the
field is just turning out innovation
innovation but the tools are absorbing
this and making it available for
programmers so I would say do not be
intimidated just use the tools and get
into this thing if you're if you're a
programmer through the tools and don't
worry about knowing all the math I think
it's gonna be important to have
separation of concern they're the same
way that you don't worry about
relational calculus or I think most of
you probably don't okay I have a few
minutes to talk about Erlang Earling
strengths we can cover this quickly
fault-tolerant in long-running systems
concurrent process in i/o processing an
i/o system inspect ability these are the
things that I've cherry picked out of
Erlang that I think can apply in this
space our lens weakness is it's not seen
coudn't and Couty and n both C libraries
knurling is not C++ you can write C you
can interface the C and C++ and that's
where tensorflow is written it's not
pipe down most of the libraries are that
are sitting on top of the C and C++
lower-level tier
most of them are in Python Python is
really dominating this space right now
there are a few others there's Lua
c-sharp Java but Python dominates it has
literally no CUDA story that I mean it
just it doesn't and I don't know if it
needs to that would be very strange it
would be somebody I think who was just
really really wants to use Erlang for
every conceivable application and the
question I would ask is why if you want
that sort of iterative hype you know
quick
quick rapid application development
environment just use Python it's not
that bad it's not that bad just use
Python everyone's doing it okay it has a
it has an open CL story and I don't mean
weak as this tornado falls library and
nothing he does is weak but overall open
CL is not doesn't it doesn't play in the
space there are this is some things are
supporting but they're supporting it
badly or weekly I shouldn't be insulting
it's not as strong as CUDA that's a
non-controversial statement CUDA is
dominant in this space so this is a
problem for rolling if it wants to be at
that layer but that's not what Erlang
strengths are here's where I think we
can apply it now I say client-side which
is really strange your client-side
control system is a bit weird because
we're used to these things living out on
a server someplace but I'm going to show
you an example of a client-side control
system server-side supporting tools what
do we need you know we were passing data
back and forth we're scheduling jobs
were were we're monitoring things we're
restarting things this is where Earling
plays very well and interestingly this
is where the industry had doesn't have a
lot of there's not a lot going on right
now we're gonna we're in a very
Greenfield scenario at this particular
in this particular area inference is
where you take a trained model and you
use it to make an inference so is it a
cat what's Mike what's my confidence
that this is a cat now what do you do
with that information I don't know scan
the internet for cats we already do that
so maybe we were gonna go do something
who knows that's called inference an
inference server something that you put
in production and you run to do
inferences Erling is not actually
running any code that is doing the
inference but it could be serving the
data back and forth so distributed deep
learning I'm gonna get on that the next
slide completely deep field these are
some projects I think that we can look
at if we're interested as er lying
programmers to sort of weigh in and I
think we absolutely should these are I
won't get into each of these are just a
you can look at look them up later but
they're all tackling this sort of space
this these problems this problem area
and I think that Erlang programmers can
can take a look at this stuff and solve
some really interesting problems I think
you're going to have to get into
deep learning stuff that's it's a unique
beast distributed distributed neural
network training is not the same as sort
of general distributed computing it's
very specific there are Papers written
on it it's specific
there's architectures that work in
architectures that don't work and the
field is determined and investing
incredible resources to figure this
stuff out so it's sort of all in flux
it's not the same as just setting up a
bunch of servers ok this is a project
I'm working on I just put it up of a
link to it but this is an example of I
think a pretty good I think a pretty
good application of Erlang in the deep
learning space so really quickly you run
experiments sorry you run experiments in
these things and this gilday is
command-line tool that will collect
along with your training data system
statistic data a bunch of stuff and this
is an area that I thought would be
interesting to explore because it is so
bound and tied to the performance
characteristics of your environment
making good decisions about your perform
your environment is going to be
instrumental in being more effective it
help you be more effective in your in
your experiments with deep learning it
formalizes a prepare trying to evaluate
operations so it makes it easier to use
there's local ways to visualize and do
comparison analysis data sharing
collaboration these are sort of meta
features above the above the actual deep
learning Erlang in this case is very
good I'm gonna do a quick demo here I
want to get into system I'm not gonna be
able to finish this and I want to have
time for questions so let me do a quick
demo of it and this is this is this is
all open source I'll show you the link
so what I have here is I get rid of this
window alright so if you look at this
these are usually some type of script
that you run and this wraps the script
so I'm gonna say Gil train oops
alright so this is basically wrapping a
tensorflow program as that's running I'm
gonna launch a view here and where am i
all right so this is a an early out this
is an early web app that's being served
from a command-line interface
crazy so I'm doing a lot of things so
I'm actually demoing a lot of things so
let me let me slow down a second let's
go back to this this accuracy down here
is the core application doing the
training but what but what the guild
environment is doing it's tracking that
process and it's tracking a whole bunch
of other things and it's writing sort of
very efficiently to different data
stores and it's sort of doing as much
useful things around the core the
primary thread of training that it can
do I originally thought this this is
going to be Python because the entire
industry uses Python until I saw this
problem this is a concurrency problem
and I've got some experience going from
Python to Erlang a lot of experience and
I know the pain points so I'm not going
to use Python for this erling is better
if it is better for this even though
it's a super weird application for
Erlang a command so I even wrote a new
command line parsing tool because I
didn't sort of wasn't happy with what
was out there for this particular
problem
weird stuff or that just finished so
let's go take a look at the view it also
has a webserver built in and it's all
doing this that you can all do this at
the same time so what we saw here was
was it ran through 10,000 steps you can
see this is the accuracy so it started
out very badly because it guessed and
then a trained and trained in training
very kind of swept up here and this is
characteristic of this process it gets
good good very quickly and then sort of
gradually improves and then tapers off
if if everything is working as expected
in addition it's collecting GPU
statistics and other things so you can
correlate collecting the output etc you
can do comparisons across multiple runs
to kind of see oh I changed this
parameter and I got a better result this
is kind of a nice way to capture that
information that's an early app and I I
would I think that's a defensible move
there okay so that's the URL to the to
the project did the demo we can skip
this if anyone's interested in a
command-line interface in Erlang there's
now a second library that you can look
at Oh
finish this up okay so here are these
are all links so this will work online
once it's once it's up but
I would I've thought about this and this
is a hard problem this is another
problem is like how do I do this how do
I actually learn this and I would start
I'm gonna go through these because I
think it's important because I hope
everybody here as Earling enthused /
beam enthusiasts is interested in this
and goes and at least starts on this
journey I would start by watching talks
by Andrew Ning and I I mention him
because he is brilliant but he's sort of
directing a lot of his brilliance toward
communicating to folks like me and folks
like you and so it's a really good
starting point to understand and he's
very very technical so he doesn't gloss
over details he does but in a very
careful way very very good starting
point the second one is a book the third
one is tensorflow online course is an
online course by Udacity that is
outstanding he makes the point look
don't worry about the math so much just
go through the mech the mechanics of
this stuff and you'll gradually learn
how to use it you don't have to know all
the math tensorflow tutorials will get
you into actually doing the work and
they start with very simple things and
move up to very complex things so you
get a really good range of experience
there you're gonna have to use Python
but maybe you could use airline to
generate Python so you never have to I
don't know what you but I don't mind
Python at all for this kind of thing
there's a Depot online deep learning
book by really the center the the great
minds in the in the in the field that's
all free online and then I would suggest
this this this guild AI project is is
the only sort of project that I'm aware
of that's playing around in deep
learning space that's in Erlang so I
mentioned that only because it's in
Erlang so if you kind of want to meld
the two I mean that I'm sort of
describing my where I'm at right now and
I think it's a fun place because you
know there's a lot of interesting
problems to solve for folks who are or
have some experience with with their
line okay so let's I've got I've got
some time for questions but not a ton so
don't be shy
it seemed like alphago was using a big
machine to play the game itself surely
that would just be a very small machine
that replays the that that configuration
was the that was the pyro profile for
the inference side it was a non-trivial
investment of hardware the training was
probably may have been conducted on a
similar problems that's all real time
he's got it he's got to make his moves
within a certain time frame or does a
bunch of different things the neural
network is basically to give assists a
Monte Carlo tree search which which
without that would be impossible so it's
one component of an algorithm to
ultimately make the move but it's an
integral component and the way they
train that role that is incredibly fast
actually multiple neural networks
involved but the training mechanism is
incredibly interesting there's a nature
article on that and it's a great read
the trainings no no no if we go I don't
know exactly what I mean the the
training would be done on a similar type
of hardware it would be done on GPUs and
it may be a smaller profile or it may be
larger we I don't think that that
information is disclosed but the
training can happen expect some of the
networks that they were that were they
were trying to be training over weeks so
it not time constrained I mean they're
you know they want to go as fast as
possible but then it's not like a real
time where there's no game yeah I don't
so so I am completely unqualified to
answer this but I'll answer that the so
when they say that's like the way the
brain works hasn't as extreme
generalization it actually is not like
the way the brain works there's a whole
field of neuroscience devoted on to sort
of taking inspiration understanding the
way the brain actually works the
perceptron is called a neuron but
doesn't it's not like a neuron it's just
it's a name that it sort of remotely
resembles a neuron so it's a way to sort
of it it takes inspiration but it's
really much more of a mathematical
concept that it is anything like our
actual
brain but it's an interesting question I
don't know if you can if you could
actually say it's this it's this deep I
mean I completely unqualified to answer
but that's my answer
costas oh this is great
questions from John Costas in I'm
bracing myself here we go so I think
this is a very great talk first of all
and really fascinating stuff but I would
like to I would like us to tell us a bit
more about what you what you think is
distributed deep learning because to me
with this type of machines it's already
yeah I can answer this one um so there's
different levels of distribution because
of the the the relationship between data
and compute memory bandwidth is very
very important becomes a bottleneck very
early on so much so that the the djx one
is really a supercomputer has specially
designed buses that are brand new to
deal with the the you give the the GPUs
a freer access to a global memory space
high performance so that's that's
distributed certainly I mean they're
doing all sorts of things across you
know many many thousands cores of GPU
when I say distributed it's it's across
machines over networks and you can you
can break the distribution up
traditionally through breaking up the
model or breaking up the data and each
of these is like a separate field and
they'll have papers it'll say you know
here's here's an architecture for this
and they're very they'll have like a
parameter part of the model will be here
the parameters will be shared here and
you'll do that you'll calculate a loss
across a bunch of nodes
it'll funnel back up you have different
modes of communicating back up so
different depending on even in the
neural network architecture and you'll
have different distribution
architectures so it isn't just the same
as saying oh I'll do tensor flow here
here here and then just do round-robin
or you know some of our more traditional
go to distribution it's it is tied
intimately to the meant to the math side
of it which makes it very very
interesting so look at so I would just
say look at tensor flow distribution
it's very specific
and and it's it's all there in code so
it's it's it's a easy way to kind of get
your head around a specific
implementation of distributed training
and deep learning give me one more
I'm cheating because I've got the
microphone one more question
and I'm gonna stop there's one more
question out here yeah no no okay
thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>