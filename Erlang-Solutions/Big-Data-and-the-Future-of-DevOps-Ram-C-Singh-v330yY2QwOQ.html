<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;Big Data&quot; and the Future of DevOps: Ram C Singh | Coder Coacher - Coaching Coders</title><meta content="&quot;Big Data&quot; and the Future of DevOps: Ram C Singh - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;Big Data&quot; and the Future of DevOps: Ram C Singh</b></h2><h5 class="post__date">2012-05-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/v330yY2QwOQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody so I'm gonna talk about
Big Data in the future DevOps in the
command talked a little bit about what
we're doing at affinis eight under the
brand ten i/o so why operations like
what's what's the problem we're trying
to solve well in 2008 the average
revenue costs of unplanned outages was
estimated to cost about two hundred 2.8
million dollars per hour obviously that
depends on industry it's a lot of money
that's being lost by different
organizations different enterprises 59%
of Fortune 500 companies experience a
minimum of one point six hours of outage
per week the best of class of these
companies are losing about $75,000 a
year from revenues lost and the ones
that are really bad at this or losing on
average two point eight million dollars
almost two point nine million dollars a
year depending on the type of business
application that they're running and
that experienced an outage you can see
that you can lose anywhere from $11,000
a minute down to $700 a minute and
actually there's no there's there's the
upper bound on this is actually much
higher than that if you are entirely
dependent upon an opera operation of
your infrastructure for revenues then
every minute that you're down is
potential revenue lost potential
opportunity lost and the recovery time
the cost of that it takes to recover
from outages is extremely high what are
the types of unplanned outages well
there's the net there's obviously like
the acts of nature the acts of man
things that are that can be done
maliciously or not intentionally
threshold breaches or system overloads
things that aren't really planned for or
not noticed things like data connection
saturations or web server capacity being
breached there's actual physical or
hardware failures that can occur with
soft state devices and storage devices
actual power supplies can take down a
lot of lot outages come from power
supplies actually failing
and there's softer and logical failures
and then there's also will we'll see
that actually configuration causes a lot
of these unplanned outages about there's
estimated 80% of unplanned outages are
due to ill-conceived they're ill planned
changes in the environment now this
could be from a deployment of a new
software application or an upgrade of an
application that causes an outage and
unintended and unintended consequences
or it could be somebody logging on to a
system to tweak a configuration file
thinking they're doing something good
you know they mote shell in and
everything may seem like it's running
for a while that that change goes on
documented and the server crashes and
this kind of talks to that as well that
but some of those outages are going to
be 50% of of the outages are caused by
change configuration release management
issues which is why well so the goal of
ops or the goal is to provide the right
size capacity for your operations and
minimize or prevent downtime if you want
to be fast you want to Mott not make any
mistakes and you want to stay out of
trouble and so how would you do this
when institute changes quickly and
appropriately you want to maintain
consistency of software and hardware as
much as you can and you want to manage
changes from one place if you can try
never to log on to an individual server
and you want to monitor your
infrastructure operation and every
aspect of infrastructure operation that
you can a lot of this is the reason why
clad computing has become coming to the
forefront by with the clap with cloud
computing you are able to maintain
consistency at least other hardware so
even if you haven't consistent software
you're abstracting at least one layer
away of that you have to manage and
you're just deploying upon an
infrastructure that somebody else is
operating for you it doesn't take away
all your problems you still have to try
to maintain and consistency on your
software but you also now since you have
abstracted away the underlying computing
infrastructure
certain things are shielded from you you
may not know whether you may be trying
to debug a problem that's actually
underlying in the infrastructure I was
talking to a gentleman last night at
dinner and he said that they had spent a
couple hours tracking on a problem that
they're sure is that the switch in the
cloud service provider and not in their
application and there there was a lot of
finger-pointing back and forth going on
about how to about how to resolve the
problem and ultimately it did turn out
to be the switch but because they
weren't instrumented to get visibility
into the hardware that their application
was running on because they were
supposed to not have to worry about that
they weren't able to fully debug the
problem so why is it so hard to maintain
consistency and keep these
infrastructures operating well there's
two peer 2 entities involved in the in
this equation ones two developers so
it's the developers developers job to
maintain the software align the software
according to the business requirements
and that by necessity means there's
going to be change and they do this in
order to keep the business in business
on the other side equations to ops
now ops wants to keep the infrastructure
running they want to minimize the amount
of change because every change incurs
risk and they also want to keep the
business in business so what DevOps
seeks to do is is to bring the two
parties together so that the enterprise
software stays aligned that the
infrastructure stays running the
business days of business and that there
that were able to mitigate the risk
involved in doing all of these things
I'm not going to go into the detail
about what DevOps is that there's a
whole other track for that and you guys
have been reading up on that I'm sure
but at its core what DevOps is seeking
to do is turn infrastructure in the code
or treat infrastructure as code in order
to do this there's a couple steps one is
to actually take the the monolithic
complicated infrastructure they need to
get deployed and decompose it into
composable components
we want to also define a way to
configuration manage these components so
that we could actually define to find
the processes to build these components
and then automate that so that we have a
repeatable way of creating
infrastructure so we have that
consistency in the software compose
these automations in a way that allow us
to configure and deploy the actual
infrastructure and then configure
configuration manage all the
compositions and automations themselves
which in which is in itself code in
addition to the application that's
gotten developed so some of the DevOps
tools that are used
there's the operation system
installation tool pixie this is an
example one of them configuration
management there's a variety tools for
that cfengine puppet and chef for
composition a lot of people use vagrant
and there's some other other tools as
well and there's a whole slew of of
monitoring tools including one of the
sponsors of the conference boundary has
a new solution now so but is this
sufficient to do all the things that we
need to do in order to keep operations
operable I would maintain that actually
that's not it's not the case that DevOps
actually doesn't solve the full problem
because it doesn't really address
hardware it's really addressing the
application layer and things that touch
the application layer but doesn't talk
about all these things or maybe only
touches upon some of these things on
there on the on the left side here are
many of the things that DevOps addresses
things like caching some of the
algorithms that are used in order to
maybe define what how you do the caching
the composition of how you actually
create the application and even all the
way up into hardware spec but doesn't
really touch in most instances what's
going on over here in the cloud the
promise of cloud computing is that you
don't have to really do any of this
somebody else is doing this but that's
really just not that's just pushing the
problem onto so many
even down to something like which is you
don't hear much talk about in the DevOps
conferences of NOC management how do you
maintain physical security how do you
where are you going to locate the de NOC
and even things like power supply which
causes a lot a lot of the outages for
applications so ops is more than just
the apps it's just a conceptual hybrid
datacenter I pulled off the internet
just to show that when you're laying out
an operation data center there's
actually no where on here do they really
talk about the app this is all all this
stuff that has that the app has to have
in place in order to run this is
everything that's assumed so
infrastructures are actually more
complex than what DevOps seeks to solve
and because they're that complex it's
difficult to predict when they're gonna
fail identify why they have failed and
determine what has actually failed and
this actually causes increases at the
cost of an outage by by lengthening of
the time it takes to identify that an
outage has occurred or breach has
occurred and then the response time
required in order to address the issue
either circumvent it or actually fix it
so for infrastructure to really be code
all of this not just this has to be
decomposable definable has to have
automations that can be reliably
repeated has to be composable and
configurable configuration manageable at
least the pieces that you don't actually
have to plug in so things like putting a
new algorithm on your load balancer in
order to address a change in the way
that the users are interacting with the
system that again is not really covered
in an adopt scenario at least not in the
best practices as as they're discussed
right now and yet that's critical
to whether the application is going to
stay up and be responsive so some of the
other tools that ops people use have to
do actually with network configuration
device configuration the management of
the management of those device
configurations and the monitoring
there's a whole other set of monitoring
tools that usually comes into play
depending on the type of network devices
that you have deployed on your system
that deployed on your infrastructure
some of the some of the tools that that
were displayed earlier like a like
Nagios I think boundary as well
Zenoss and Splunk and collecti as a
daemon actually allow you to collect
data not just at the application layer
but down into the hardware layers as
well but they also have to be used in
concert with processes and tools that
are not being discussed in DevOps so I
want to switch gears a little bit and
talk to you about how we think about
infrastructure we actually think of
infrastructure as manager States so at
10 I owe and affinis eight we think of
infrastructure as states that need to be
managed if you know how your
infrastructure needs to operate you can
define that as a state so if you can
define all of this is code or at least
as parameters then you can define the
state that your interest you what you
desire infrastructure to operate in so
by taking all of this as your state plus
and adding your performance
characteristics you can define
transitions between the desired States
so what does it look like as a simple
example of what it takes to deploy a
simple web app we let's let's stop let's
start with the state 0 which is
basically the bare infrastructure and by
running a series by running our
infrastructure code infrastructures code
we can transition into a state unknown
State a desired state where we have a
web server load
answer and to database servers so now
assuming that we're in that state one
where everything is running well if a
DevOps operator is using his monitoring
tool using nagas using boundary and sees
that there is a issue with the database
performance they may choose at that
point to address that issue by
transitioning to another state meaning
they run the code that's required in
order to get from state 1 to state 2 and
to stay tuned they may determine this
this this operator may determine that it
looks like the load balancer is having
an issue so let me bring another load
balancer up on online and insert that
into the in between the the web server
and the database server database servers
so he brings the second load balancer on
monitors make sure that load balancer is
working well and then transitions to the
third state where that first load
balancer that was causing issue is taken
off offline so instead of getting into a
state where there's an actual failure
they just ran the code to transition
from state 1 to state 2 and to state 3
and now this infrastructure is running
in state 3 I'd say that that didn't
solve the problem that they're still
seeing database performance issues so it
may not have been that load balancer or
it may have been that load balancer in
concert with something else that's
happening on it on one of the database
servers or it may just be that the
database servers are saturated for some
reason so in this case they'll
transition from state 3 by bringing into
into state 4 by running the code
required to bring a third database
server online now this code is very
likely going to be the exact same code
that's required that was that was run to
run to bring database server 1 and 2
online it's a repeatable process the
infrastructure operator uses to bring
database server 3 online and now and
this is running at this point in May
the infrastructure operator may realize
that actually the problem was with
database server 2 and that 2 &amp;amp; 3 2 &amp;amp; 3
I'm sorry with 1 &amp;amp; 2 &amp;amp; 3 are able to
handle all the load and all the
performance issues goes away runs
another set of code to take database
server 3 database server 1 down and then
now we're in state a new state desired
state where we have web server load
balancer and 2 database servers running
it happens to be a brand new load
balancer and a brand new database server
from the original state what does an
outage look like when you're thinking
about infrastructure to state well
basically in this case we're this outage
demonstrates what happens when web
source trading what happens when web
server 1 goes away something happens
nobody noticed that that the web server
was about to fail or maybe just failed
catastrophically and you're in a failed
state this application is not going to
the application is not running and so
there was a transition here an
unintended transition into a fail state
so what would normally happen in in this
scenario is that if you're running
monitoring software and a learning
software and you're gathering data after
your infrastructure hopefully actually
before this happens you'd be getting
alerts dashboards would be turning red
on your on your monitoring software and
somebody can take proactive action to
keep this from happening but if that
doesn't happen all the time sometimes
things fail catastrophically without any
warning and you get into this failed
state and this is the typical case where
now a infrastructure operator is now
scrambling all the all the pages are
going off BlackBerry's are going off and
teams are being assembled in order to
try to figure out what happened well
first just to recover bring a web server
up online and then figure out why the
disarray gional web server fail in this
case again if they have infrastructures
code they could just ran run the
transition software it takes them out of
this failed state to bring a web server
back on line they can get back to this
state number 5 if they don't have
infrastructures code they're running
through a bunch of manual processes
running scripts trying to figure out
what to do in order to
to bring the web server back up online
so this is what a DevOps process flow
looks like it's find my pointer here
it's infrastructure creating sending
selected infrastructure what we call
telemetry through a bunch of tools that
provide visualization visualizations
alerts and analytics that far off
triggers to dev operators who are also
getting external triggers and deciding
to take actions to change that
infrastructure to manage that
infrastructure well if we remember well
so DevOps tools still require humans to
be involved and remember this statistic
humans are the major cause of the errors
so while DevOps does a lot to automate
the process of running infrastructure at
least the application part of the
infrastructure it doesn't solve the
problem completely so how do you
mitigate this you get autonomic in the
early 2000s IBM had a research
initiative called add an autonomic
computing in which case in which they
were trying to develop server systems
servers that would self heal basically
with the admin in the cloud a lot of
that initiative went away and they
folded a lot of their tools or what they
developed into tivoli and so there so it
kind of lives on but it sanics you have
to have ibm's suite of tools and it is
obviously very expensive but what an
autonomic computing infrastructure what
we're seeking to develop is the ability
to run diagnostic is a is to turn any
computing infrastructure into one that
runs diagnostics and checks all the time
and takes actions on its own to repair
and address any anomalies that it finds
so how would that work so all of this
can still stay in place because you
still want to have human operators
involved you just want to minimize their
interaction with this infrastructure
what we add here is what we're calling
autonomic
it's a rules engine that gets all of the
infrastructure telemetry from hardware
from the Bayer hardware all the way
through the application stack from the
network elements routers switches all
the devices that are on the
infrastructure including potentially
smart sensor grids and even sensors that
are in the NOC things like power
regulators power supplies cooling
sensors off the cooling systems the
engine itself does the decision-making
looks for patterns and anomalies in that
data and then takes the appropriate
action in order to manage the
infrastructure so what it does is it
ingest all the telemetry it identified
anomalous patterns and it triggers
transitions between desired states and
the idea of being you minimize the
amount of time you spent in a failed
state even if it gets into the failed
state there's still a chance that the
rules engine can figure out how to get
out of fail state so if a web server
fails and it's no longer getting data
off that web server somebody pulls a
plug off that web server it could it
would automatically know that a web
server is supposed to be sending data
it's missing let's reconfigure a new
weapon let's let's read configure
another web server to take it to place
and wrap traffic to that to that server
so we have no more failed States at
least that's the goal so instead of that
last day here where we had a web server
just disappearing and requiring manual
transition back we would in this case
ideally autonomic i/o would see that
this web server is about to die or has
died well let's say it's about to die
bring another web server up on line
really quickly by going through all of
that code that it's required to deploy
and configure that web server and then
take down the bad web server and then
far off alert to human operator let them
know you need to pull that server out of
the rack and replace it
so this is a infrastructure maturity
model that we're playing with it's still
a work in progress but the idea is that
there are a lot of organizations that
are still at a very basic level of
managing their infrastructure probably
nobody in this room but there where the
managing the elements of that
infrastructure at an individual level
the next step up would be monitoring
that infrastructure and the elements on
the infrastructure and using tools like
Nagios like boundary like Splunk in
order to at least get an idea of when
things fail and what they need to do in
order to recover from that a step up
from that was is what we call reactive
in which which we think actually DevOps
is where when a failure occurs there are
no there are things that are defined and
known that need to occur in order to
recover from those failures and the next
step back above that is proactive that's
where we are getting to with autonomic
i/o and where the infrastructure itself
can use all the work all the definitions
that occurred in a DevOps organization
plus patterns that are specified by the
devas in order to recover proactively
predictive would be the next step where
we're trying to get to which is for
patterns that haven't been specified
where you can't you don't you can't
specify every type of failure that's
going to occur so there are things that
are you know more interesting ways
they're more interesting ways to fail
than can be defined in those instances
we are we're hoping that we can build an
engine that would know how to respond to
those failures and at least start to
take some corrective actions in addition
to letting a human operator know what
has occurred and what actions have
occurred so they somebody is so human
intelligence can then be applied to try
to solve the problem if the engine
itself can't and the ultimate goal is to
have something have infrastructures that
are fully on an autonomic where the
operators main interaction with the
infrastructure is by setting
policies objectives and performance
metrics and the infrastructure then is
able to manage itself - in order to meet
those performance objectives so the
future is one where the best practices
from DevOps combined with big data
infrastructure telemetry and a rules
engine a smart rules engine can create a
autonomic computing infrastructures that
can for the most part run themselves and
that's my talk thanks yes
how much of it is no the what we've seen
is that as so Automation is not the term
that's used a lot which is why we don't
use it for our system the level of
automation that we see right now is one
where things like configurations are
managed in puppet chef or CF engine and
those configurations can be run but it's
a human operator who's determining what
needs to be run and when even when those
recipes if you will are composed and run
automatically using something like
vagrant that's still human that's making
a decision to run which composition to
run and there still needs to be human
involved to determine whether things are
happening the way they're supposed to
happen so just because you ran a puppet
script or a chef's recipe doesn't mean
that everything happened that was
supposed to happen so there's still
while there's a lot of automation in
piece and pieces there isn't the ability
now to just say bring up a web server
and have it be fully deployed and trust
that it's gonna that it's going to be
repeated that that's a repeatable
process is gonna run now some some
configurations are probably are simple I
mean there may be some reasons actually
what I just said is a blanket statement
there are probably some organizations
that are able to run you know where they
have they've these fully tested recipes
and they're able to run them there
haven't made a lot of changes there
doesn't need to be a lot of testing
involved or a lot of decision making and
they're able to do it touchless lee but
that's even a word but for the most part
it's not that's not that's not something
that I think even the organizations that
are running
things like puppet chef for cfengine the
ones that are dev ops practitioners are
are trusting that that's gonna happen
without them actually monitoring what's
going on one of the I'm sorry I should
let somebody is there or is there
another question right should I keep
expounding on that good know we've were
let's see we're a little less than a
year into the implementation we started
building the core of autonomic i/o in
August of last year and for actually for
a different purpose and January this
year we decided to tackle this vertical
and so we've we reaction we've actually
really engineered some of the key pieces
in order to be able to address the
scalability issues involved with trying
to deal with the massive amount of data
that comes off of infrastructures so
we're well into the process but there's
still it's still very early in the
development
any other questions okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>