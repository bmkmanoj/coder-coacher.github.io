<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Andrea Leopardi - Concurrent and Resilient Connections to Outside the BEAM (ElixirConfEU 2016) | Coder Coacher - Coaching Coders</title><meta content="Andrea Leopardi - Concurrent and Resilient Connections to Outside the BEAM (ElixirConfEU 2016) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Andrea Leopardi - Concurrent and Resilient Connections to Outside the BEAM (ElixirConfEU 2016)</b></h2><h5 class="post__date">2016-05-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/U1Ry7STEFiY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I heard whether we were around 300
people that is terrible we are 300
people more than I'm comfortable around
where you list your at least kind enough
to love every time we do something
slightly funny so thanks so the Erlang
virtual machine how long is a wonderful
ecosystem you can implement lots of
common functionalities that many systems
need using just built-in tools and
guarantees that are long provides for
example you have ETS if you want an in
memory storage you have nita if you want
to distribute a database you have
message passing built-in and it works
from across different processes living
on different nodes so these are
components are really nice to build a
systems especially distributive systems
the problem is that airline may not be
the only language that you're using in
your system so you may have other
languages so for example if you have a
service-oriented architecture Erlang may
not be the only language some services
may be written in other languages this
means that you can communicate with
between airline services and other
services using girl and built-in tools
anymore right so you need to generalize
the tools if you want to communicate
between the services so for example you
may want to use a key value stores such
as Redis or relational database or a
message queue such as Robbie thank you
to communicate and to share data between
these services using these external
tools though means that there is no
guarantee like there are no more
guarantees from Merlin there there are
no more built-in solutions from anyone
so you need to do more work yourself to
work to make this components work with
airlink so we need to you need to make
hair long talk to the outside world and
connect to the outside world the world
outside the virtual machine the problem
is that the outside world is really
scary so
like a lot of bad things can happen and
will happen so no notes will go down and
services will go down and the network is
will go down the network is really
terrible as a concept I mean and so it's
a it's going to be bad so you want a way
to deal with it keeping you sane
possibly and so this is what I'm gonna
talk in the in this talk which is how to
build connections to these external
services that don't drive you insane
basically so my name is Andrea that is
my username I started working with Alex
here I don't remember when but a
luxurious at a really huge impact on my
life so I got got me my first few jobs
and it made me move countries so I'm
from Italy when i'm living in gothenburg
that is reading of course i couldn't
find any vector map so i drew a drew one
is remarkably accurate
so now I'm living there yes the low part
of the and I work there had football
addicts which is this nice sponsor over
here and i were there full time and it's
really nice we're kind of hiring so
don't be shy so let's do a couple of
shows of hands to test that everything
works because we need to I will need to
know the audience a little bit so first
like set up test so who's able to raise
a hand
many people are not raising a hand I'm
very sorry so who would like to not
raise their hands now this is freaky you
raised it doesn't count so all right so
will so who knows what a gent server is
and how it works this is the real show
of hands great and who knows LT CP
roughly works so this great audience
alright Wilma gonna make some
assumptions to make everything easier
one if that will use only TCP to connect
to other services because we'll have
more concrete examples this way and it's
easier to reason about I think but this
most of this example applies with
connecting in other ways so your GP or
even ports for the most part I think and
we're going to assume that the service
we want to connect to follow the request
response cycle so it follows so you just
issue a Request inning gives you back a
response it is not very this is not very
general of course but it will make
examples so much more concrete will
still present the concepts very clearly
i think and lots of sanctions we're
gonna make we're going to make this very
very not general and talk about just
readies for now so how to connect to
read is because it's by far what I know
best because I wrote radix which is the
longer I sorry Alex your driver for
Redis and so it is by far what I know
best but I mean it will work with
anything else the concepts i will talk
about we work with anything else but
it's easier for me so there's a very
silly way to communicate with an
external service so in the case of Redis
we want adjust the way to reach your
comment Redis right so you want to issue
a comment and get back a response from
rice and the very silly way is just you
connect every time you want to issue a
comment so you create a socket
a TCP sockets and you connect to the
radius server you send the encoded data
to the radius server as a binary of
course you receive the response wait for
the response from the server close the
socket and return the data to the client
to the color sir so this is very very
silly way to do this and it works I mean
it gets the job done but it's a terrible
because opening new connections is
really expensive especially in most
cases for example TCPS is really
expensive to set up a TCP connection
because you have more network calls you
have to allocate resources so for
example rattus would have to allocate
resources for the client disconnecting
so it's not an expensive version and
often the cost of just establishing the
connection will be higher than the cost
of actually sending the commons and
receiving the response so you don't want
to do this every time you want to
initiate to issue a comment on ready so
the next natural step is you want to
keep the the socket open sockets in
anshun server right so you want to
encapsulate this socket in engine server
you want to leave it with the two you
want it to live with the zune server so
you want to open it when your initialize
the gen server you want to close it when
you terminate the gen server so it works
really well and you are we will keep the
connection open the socket open for the
whole life of the gin server so how do
you take advantage of the socket keep
kept in the gen server state I think
there are two good ways to do this one
is the I refer to as a blocking way and
when I referred to as a non-blocking way
we'll see there what this means so let's
just look at them so the blocking ways
block blocking way sorry what I mean by
blocking ways now we have the gen server
and in as the socket in a state and
clients want to use that socket to talk
to readies so what will happen is we can
basically check out to the socket from
the gen server so the client can ask the
agent server for the socket then use the
socket to send
data to read it and receive data and
then give the socket back to the gen
server so the gen server basically only
acts as a container for these sockets
you won't do anything to this socket or
through this sockets who will just hand
it to clients and they're asked for it
and this is the pseudo code but it's
like this is works this works is it's a
very simple implementation it will just
check out the socket then do this
sending a receiving stuff and check the
socket backing into the gen server state
the problem happens now when you want to
use this gently socket from multiple X
your processes because you can't right
now because if one process checks the
socket out of the gen server then it
will if another process checks that
socket out then they will conflict on
the data they're sending through the
socket and the response in responses
that they're getting back so what you
have I think you have two solutions to
handle this so the first solution is if
the client checks this or get out of the
gen server and then another client asks
for the socket you just reply error
check it out so you just don't check out
the socket to other processes you only
check out the socket to one process at a
time and this of course is very limiting
because you only can like your
connection to raley's can only handle
one client at a time but it works and
the other ways is to use a queue of
clients they want the socket so when I
client asked for the socket if the
socket is already checked out the gen
server will put this client in a queue
and then next time the socket is
available we will give it to the next
client in the here so it will just
implement a kind of a queuing system
anyway this is kind of works and it
works for multiple processes talking to
the same gen server because it will be
just queued and it kind of works with
ready in particular actually because red
is a single threaded so it will process
this process requests one at a time many
will reply to one request at a time so
it's it will not you will not lose too
much by doing this you kind of
reimplement the logic that is in red for
ending angling
clients already in your engine server
but both of these approaches the first
one its mandatory and the second one is
for performance you probably want to
have some kind of pooling to handle this
so you want to have by pooling I mean
you want to have a pool of gin servers
connected to Redis and you want to when
you want to when you want a socket to do
operations with readies you will first
check out to join server from the pool
then use the dead gin service socket and
then check this I'll get back in the
pool and this works fine because
especially with the first method of the
replying with an error when the Soviet
is checked out because now only one
client at a time will talk to the gin
server will it will have the exclusive
on the June server so it will be it will
work fine but let's see the other way
then so we there was the first way to
the advantage of keeping the sockets
antigen service state so the other ways
what I call unblocking way and so until
now we use the socket you know what is
called it's called passive mode so as
you remember we manually actively
fetched the data from the socket using
gently CP receive so when we were ready
to handle new data from the sockets we
will just ask the socket for a new data
and block until the socket will be give
data back to us this is called passive
mode kinda and there's not other mode
which is active mode for Jen TCP socket
which is means that you will not have to
ask this of it for data anymore but the
subject will send you data as an Alex
your message so basically a
synchronously so what you just sent you
just use the socket to send data and
then the socket will send you back the
data the response as an ally to your
message and it will send them back to
the controlling process of the socket
which is just that by default the
process that started the socket body
makes things more a synchronous let's
let's say we can handle the data when
we're ready to but the data is already
there in the nest
in the mailbox of the process and we can
combine this with no reply from jen
server because right now when we were
calling the gin server to do stuff we
were using to interpret coal which is
blocking for the client right so the
right now we were I mean when checking
out the soccer for example we were of
course waiting for a reply in the client
so we can do is return no reply from the
handle of code in the gin server and the
client will keep waiting for the respond
so we'll keep blocking for a response
but the kitchen server can keep doing
its work right and if we combine this
with Jen server that we apply which is a
manual way to reply to pending requests
pending Colts basically so if you have a
chance ever call you can reply to that
call with Jen server replay and manually
so if and of course the call will return
and it will not block anymore so if you
combine these three so the active
sockets and the returning no reply from
the handle cold so keep keep keep
working after sending the data through
red to red ease and then using mac reply
manually you have a nice flow so the
flow is now is the gin server the client
asked the gin server to send a comment
or a tease the gin server stores this
client in a queue it's state and since
the common to read is to through the TCP
sockets and then returns is no reply and
continuous handling client requests the
gem server ready at some point you will
reply and the gin server will be
notified with a message that contains
the reply and that gin server will just
forward that reply to the next client in
the queue so it's it's a very
straightforward way I think to reason
it's like this is this is the kind of
drawing of what happens you have a bunch
of clients that ask legend server to
send commands to raleys the gin server
will send common threads and keep
sending them until reply arise when I
replay arrives in the gin server has
time to look at the message that is the
response then we will take the next
client our next client
of the internal queue and send the
response to the client so this is
performed pretty well because you take
advantage of the fact that TCP is full
do books what it means is that TCP is a
protocol that that supports a pair of
white streams one flowing in each
direction so at the same time I mean so
basically what you take advantage doing
this is that you send the data to the
TCP buffer of red is basically while
your boy the TCP buffer of the gene
server is getting filled at the same
time even if the gen server is not
processing the message but the data is
still arriving to the gen server and
feeling it's TCP buffering it's much
faster to take stuff out of the buffer
than out of the remote server with
gentes video received so you take
advantage of this bi-directional stream
and actually there is a even more
performant way to take advantage of this
which is basically introducing a new
component which is now the old gen
server room I will not only the sender
and we we will spawn a new gen server
code they will call receiver so when you
spawn the sender that's the sender will
spawn it's it's own receiver and now
clients just talk to the sender and send
comments to the sender and the sender
will actually send the comments to read
through the TCP sockets but red is the
controlling process of the solids will
be the receiver so that raddest will
reply to the receiver not to the sender
and the receiver will just process the
data and send it back to the client so
the receiver is the one keeping the
queue of clients now and we can paralyze
this way the sending of data stratus and
receiving not only on the ccp actual TCP
connection but even on the program level
you can just one is responsible for
sending and it will not be blocked if
there's a huge response coming for
example and the other one is just
responsible for receiving so if many
clients try to send comments it will not
block alright so there are the two ways
I think that these are
two nice ways to take advantage of this
and both have growth pros and cons the
blocking way as a pro that is that it
covers less data so as you know when a
process sends a message to another
process in a luxurious aaj gets copied
right so if the regenerative the gin
server acts as a middleman so readies
replies to the gin server and the gin
server replies to the client then when
the gin server replies to the client it
will send a message to the client to
reply to it and then the data that the
radius return will be copied over to the
client so there's more days are coming
if you just take the sockets out of
legend server the subject is the ad
socket address is the only thing that
will be copied you will just the client
will directly work with the socket so
the data will flow directly from readies
to the your client so it will be less
data copying and you can do encoding and
decoding on the client this is something
you can do with a non-blocking version
as well sometimes but sometimes you
can't because the decoding the data that
comes requires some kind of state for
example so this or some kind of
knowledge of the request so you
sometimes you have to do this in the
server there's no way to this in the
client so if you're doing I mean if
you're doing a non-blocking so if
response is too many requests are coming
to agent server but if you're checking
out the socket and working you're on the
only process working with that socket at
the moment then it will be just your
solid so decoding and encoding will be
can be done in the client safely but
there are conscious as well so one is
that this approach needs pooling as we
discussed probably need spooling
otherwise you will not perform very well
and it doesn't use full the full duplex
thing about TCP so we'll only either
send or receive messages will not do
these operations at the same time and
the pros and cons of the other way are
actually the same diverse and just you
copy more data yes but you have to
encode anaconda service sometimes but
you don't need pooling you can use just
single connection and you take advantage
of the
duplex thing about TCP and when I say I
you don't need pulling as more
parentheses we're using readies in
production with radix which has this
exact architecture with the to sender
and receiver processes and we're using
this in production we're using just one
radix process in the whole system and it
preferreds nice it's not we don't have a
huge amount of requests going through it
but if you do have an huge amount of
rivers going through it you can still
pull the non-blocking version as well
you have you can maybe you can instead
of giving each gen server in the pool to
a client you can maybe give the chancery
in the boo to a bunch of clients so you
still take advantage of the full duplex
and being concurrent but you can handle
you more more load so we talked about
how to connect and to talk to external
services but the problem is that as I
said earlier the outside world is scary
and the connections suck and networks
suck computer suck so it's pretty pretty
bad so if you don't want to suck as well
you need to handle the fact that things
may go down so you need to be resilient
and then full tolerant right so how are
you feeling I feel like oops I'm going
and saying a lot of things too many
things all right it's good thanks
alright so so you have this connection
from the gen servers to readies and the
connection goes down I can go down
because there's a net split can go down
because the server ready server goes
down the reddys machine goes down the
city where the reddys machine is in
explodes aliens you can really look I
cool talk for 20 minutes about all the
things that can happen but like oh they
will happen at some point for some
reason but luckily you get notified some
way of these errors by John TCP at least
you get some kind of TCP close message
or TCP error message
and so you can react to these events so
the semantics of what message you get an
audi edits are kind of different between
active and passive mode but let's let's
go over that for a moment but you're
notified that this connection has gone
down so you can make this your
connection self-healing right so you can
react to this event by maybe backing off
for a little while so before
reconnecting or maybe not and then
trying to reconnect and while you're in
the back of period you can just say to
clients we're disconnected we're not
connected yet and it's the
responsibility of clients to handle this
they can never out or they can handle
these nice leads and this is very easy
to implement with there's a package on
xcode connection by james fish which I
really feel like Chicago connection
because it's very generic and it's
basically a textin server and extends it
with a bunch of callbacks additional
codecs and return values so it's a
superset of the in server that supports
all the code back surgeons or gin server
defines and it will define two
additional code books which are connect
and disconnect there are pretty
self-explanatory so that first will be
called to connect to the resource and
the segment will be able to disconnect
from the resource it's pretty pretty
straightforward and it will provide a
couple of new original values that you
can return from a bunch of these
callbacks that are back off and
disconnect so when you return back off
from one of these codecs then connect
and you give your return back of a
alongside that timeout then after you
return back off the gin server will call
the connection sorry will call the gin
connection sorry wilco connect after the
timeouts you give it so it's useful to
just do back off and then if you return
disconnect with a reason from the one of
these callbacks then disconnect will
because right away and it will just you
can disconnect and clean up with our
system whatever you want to do and this
this lens
self to a pretty nice pattern which is
you get a TCP error in and we'll info if
you're connected to if your agents are
connected to a socket right and there's
an error you get this error in endolymph
oh so you react to it by returning
disconnect from endolymph oh and if you
return disconnect from Emily info
disconnect will be called in disconnect
now you close the socket and then you
return back off so that it will try to
reconnect after a given time out so
basically you get notified at their you
disconnecting you back off and you get
notified again after a timeout period
and in connect if you connect then good
if you don't connect you just return
back off and keep returning back off
until you're able to connect and this
brings to a very interesting debate in
my opinion which is should i connect
synchronously or should I connector
synchronously what I mean is that money
goljan server does startling and you
start a gen server the PID of the gen
server will only be returned when in it
finishes right so if if you want to
connect synchronously what I say is you
connect inside the neat so that you only
get back the PID from the newgen server
if you manage to connect so if you
manage to establish the connection but
the alternative is so this may take a
while to initiate of course but then
you'll have the connection available and
it's okay but the alternative is
alternative is you call cert link and
then in it gets cold and from you need
you just return the Kinect double and
return right away and what this means is
it means that connection the library
will call connect right away so you will
Co startling then in each will get run
and it will return the pd right away
because the actual process is started
and it's working then the connection
happens later so it happens is the first
thing of course because you want to have
this connection available but it happens
in the gen server and the color doesn't
have to wait for the gen server to start
to initiate the connection in order for
the new server to start
and this works pretty nicely and so when
do you use synchronous connection and
when do you use a synchronous connection
so the idea is that if your application
heavily depends on the connection be and
being available you maybe want to start
the connection synchronously because you
want to be sure that if the gen server
returned then the connection is
available so when to use the thing then
like if your code is prepared to handle
for example errors in the connection so
connection not being available or
connection drops if it's prepared to
handle that then you can use it in a
synchronous connection right because
connecting the first time will be just
the same as connecting later
disconnecting later on if you fail to
connect on the first time so if you're
prepared to handle this you will be
prepared to handle this even well if the
chancery never manages to connect so
this can work fine and this is a very
very interesting debates in my opinion
because you get to talk about especially
if you're putting this stuff this gene
service in a supervisor supervisor which
is something that you usually want to do
so do you want your application to start
only when all resources are available
and we are connected to all of them or
do you want the application to start and
then if the researchers are available
good otherwise your application will be
able to end and all this I say I say
that most of the time it's better to use
a sink because your application should
still be ready to handle failures
because there will be failures because
networks suck so it's it's like there
will be these failures so it's better to
it's good to be able to handle them and
if your be able to handle them you're
able to handle the fact that you never
managed to connect as well so there's a
quote from Erlang in anger from ebert
which says that by moving from
synchronous connection to a synchronous
connection you now allow initialization
initializations of gin servers we with
fewer guarantees so now you the
guarantees or not the connection is
available so when you get a PID back the
guarantee is not anymore
next one is available now the guarantee
is the connection manager which is the
gen server is available so the process
is alive and available it's doing this
right thing is not erroring out sin
anyways it's doing its thing but the
connection actual connection is not
available or maybe available but we
don't care because the guarantee are now
is that the connection manager is
available and this is a simpler
guarantee so it's easier to deal with I
think yes and so we talked about
connecting to other things outside the
ER long virtual machine we got we talked
about talking to these components
outside of their willful machine we
talked about how to how to take
advantage of concurrency so for example
by a splitting sender and receiver
you're taking advantage of congruence
there because you do things in parallel
now instead of sequentially and we
talked about how to be resilient so also
handle failures in the connection of
wendell failures in the network and how
to be self healing as much as possible
and that was surprisingly eat it's
already over
writes all question receive a package of
some questions you can resize yes I am
no doubt
you still when the let's go back to the
when the client sends asked the sender
to send a comment the sender was first
and cue the clients in the receiver and
then it will send a comment or a tease
this they saw yes yes they're very
they're linked processes that if one of
them dies they both died there they can
be seen as a singular unit but yeah the
center willing and cue the thing in the
client in the receiver sorry and then
when reddy's replies the receiver will
just take the next client out of the
queue and replied that what do you mean
it's sorry I'm not sure what you mean
sorry so what do you mean like passing
the reference of the call to the club to
the sender yeah so that when you call
from the client to the sender it's just
a PID reference topple so you have this
idea of the goal you until this I this
call basically in the receiver and when
you get the response back from raddatz
the receiver will take this call back
and use gen service reply passing this
PID and reference to identify the
correct reply the clients reply to all
right is that clear awesome
it's already bad it's really really
complicated to check out the the sender
the just one process in a clean way
because for example what happens if the
is there's a timeout when I have the
socket and I didn't check it back in so
it's already a mess I think yes you can
try to do this to take advantage of full
duplex but it's still for example do you
still need pooling you still not that
it's not I can personally prefer the
non-blocking method but yes but the this
socket ownership method is used so
postgres for example uses this for it
I'll uses the DB connection library
which this is kind of what it does it
checks out the socket to the clients and
the clients will talk to through the
sockets and then check this off it back
in so it's definitely an alternate if
they're not no one is better than the
other they just two alternatives yes
yeah yeah
one wait if you mean a conversation
still made of small request response
cycles you still so this the so that the
resiliency part applies in the same way
because the connection will still
probably been Imogen server because you
don't want to initiate it many times
right so the that that resiliency part
can still work the same as for the
blocking and blocking thing you may you
may use the blocking away and you just
get the saga tense and this data through
the socket as a single client and then
get the data back i think it's I'm if I
understood the question question
correctly but there are for example one
example example is ready spam sub right
so this doesn't work as a request
response cycle because pops up will send
you messages when there when someone
someone publishes in the channel so you
don't have a request-response you just
have responses coming and that is then
the non-blocking way makes that makes
sense for your surgeon server will be
will receive all the message and will
route them privately to clients so it's
and in the resiliency part was to be
exactly the same radix has the exact
same code for handling failures in the
pub sub connection and the regular
connection for example so it's most of
the like a bunch of the things are
pretty pretty the same for all kinds of
connections to outside world i will say
imports like if you just disconnect from
a port or the program crashes you can
still apply the same like back off and
try to restart the program so it's kind
of same philosophy i guess
well you all know what to do them thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>