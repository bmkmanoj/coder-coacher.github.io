<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Centralized Counters in a Distributed World Event Based Realtime Statistics using eTally | Coder Coacher - Coaching Coders</title><meta content="Centralized Counters in a Distributed World Event Based Realtime Statistics using eTally - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Centralized Counters in a Distributed World Event Based Realtime Statistics using eTally</b></h2><h5 class="post__date">2014-03-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7vT_VlONlhc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yeah my name is martin kristen to now I
work for tigertext and this is
unreadable but if you look up my github
thing it sort of claims that I'm a
serious or ally encoder and I love
pushing code and I'm most active at
three or something and you can basically
look that up for any github you sure and
that's not entirely true what I am the
Earl I encoder but I sort of came from a
c++ background doing a medical work and
doing imagery in Denmark before i won a
green card in a green card lottery and
went to the states which is what
happened yeah so I work for a company
called tigertext in them santa monica
and we focus on health care and health
care provider messaging and secure
messaging for basically for anyone who
wants their messaging to be secure and
to be able to go away and that's what we
do and we have all these nice facilities
that sort of trust us with their data
and and yeah to sort of when I started
there I had a tendency to say to people
well what we do is we push around
strings we did it someone put punches in
a string on the phone and we send it up
to a thing and XMPP into our service and
sort of roams around and then it comes
out to someone else and it's not brain
surgery and then I started working there
and figured out that doing simple stuff
is actually quite hard and I have a
tendency to forget that this subpoena
film and probably watched by my boss so
this is quite quite hard when it sort of
comes down to it and sort of comes down
to the business logic of it and and and
it is sort of am yeah interesting and
I'm saying all that and so the pointing
out that is interesting and because we
are hiring and so anyone who sort of
interested send me an email and we will
be the judges of who shouldn't kiss &amp;amp; M
p.m. after I had been a tiger text for a
while my boss asked me so could you
figure out how many messages we're
actually handling and we had a system
for that that it and
bucketing and we could sort of see over
day how much went through the system but
we didn't have that much insight into um
yeah the inner workings of force
actually going on and which basically
we'd like to be able to spot changes in
behavior and we want to spot them now so
having data that's bucketed on a daily
basis is annoying and because if we roll
out a new client we want to be able to
spot the difference now or close to now
and yeah and the standard solution to
doing that would be to to either have
like a database of transactions and do
queries on that and or to do some sort
of bucketing thing and which M this is
buckling sort of annoys me because it's
because I see no reason why this data
can't be real time why it's what it has
to be in the bucket of an hour and yeah
I like sliding windows and I spent some
time throwing away my own money and yeah
trading systems and other things like
that so so I'm sorry in love with the
idea of doing sliding window analysis
and also I find these these query times
annoying the fact that it's log and to
look up something that should be simple
to look up and just because you need
indexes on things and yeah and it's the
same for the other one so the thing we
actually want to measure is we've got
these events happening I've got events
coming in coming in and basically we
want to do like so how many happened
some time ago and
oh yeah I'm reading it professional yeah
so we want to say okay so how many of
these things happened within like the
last five minutes over the last hour or
the last day and and we want to do that
for not only one metric like but for
millions of metrics because we want to
be able to do this for individual and
every kind of individual entity that we
sort of have so be it a user that's
important to as a or institution that's
a customer with us or a rollout of a new
client or yeah and so how do we do that
and and this is where it sort of comes
into play that I'm a philosophy students
who then became a mathematician who then
became a computer scientist and somehow
got employed to do this because I knew
nothing about what existed so I thought
this looks a lot like a queue it looks
like if you we can just put stuff on the
back of it and sort of have a traverse
through there and that seems like
something that would take a linear space
in the amount of events if we were able
to sort of enumerate the events yeah and
and the actual problem we were looking
at and when I sort of have to toss that
me half a year ago was something like 10
million events today we want to be able
to do our over our day / day week or
week month or a month so we need two
months the data that's about 50 and half
a billion entry points if you sort of
follow me on the fact that there's 28
days in a month just because so so how
do we do that and and once you know
these numbers you sort of again me with
the sea background says okay so that's
about 2 gigs of data that's that's
nothing I don't need a database I don't
need some big thing I can have this in
memory it's small and nice and easy and
so that was my idea that was what I
started out building I said okay I've
got an array I've got a counter for each
and type of events and yeah whenever an
event is sort of pushed on the thing
then I implement that and whenever an
events for the false at the end I
determined that so I know how many
events are in this this queue and I've
got these counters and querying it's
going to be looking at that counter
Scotty it's going to be 0 of 1
everything is 0 of 1 it's all simple
it's all fundamental and algorithms yeah
and so basically these components right
we need a 50 queue and we need a set of
counters and any and all operations are
0 1 which is nice if you're sort of
looking for something that's real time
it's a good sort of place to start at
least and yeah the space complexity is
is simple as well like it's going to be
number of counters length of your queue
and some sort of look up thing that
could be a hash table right so
everything is doable um and on our
example from before I've only I can't
add up numbers and but it adds up to
about two and a half cakes and plus some
counters but the counters really yeah
even with 10 mil encounters yeah they're
not important at all it's all about that
queue and so this is going to fit in
memory it's going to be fine so one I
sort of promoted this to my boss and who
didn't really like it and then I went
home one Saturday and made it just to
sort of test it feels so doable and I
came back and he said well fine if we
can use this if we can just sort of
build leaderboards on top of it so we
can have these events and if you are
able to answer the question which ones
are occurring most often within some
time frame then that would be a useful
tool because then we could see if we
were sort of counting errors we can know
which ones to focus on and it will all
be fine and so we thought we can build
some leaderboards basically lists of
these counters sorted and paginated
and and once again that is a simple
thing to do right because all we do is
we take our cue and whenever we touch
that thing that thing knows where it
belongs to the leaderboard and if it's
implemented by one then we just double
it up and that's at most going to be
locked to the number of things for the
same account so it's still sort of nice
ish um yeah and decrements is about the
same so now once again we've got we've
got peace and i got these counters got
these leaderboards we're able to do all
of this in awe of one rayville to that
in one ish and now we've got
leaderboards and and i promised to show
you an actual so that incarnation of
this in a second because right now it's
just boxes and yeah but let's say we've
got this thing how can we sort of make
it more general we can start by notices
noticing and this is all sort of simple
right we can notice that that counter
array could sort of be replaced by these
two counter array so that we count what
goes in and what comes out and we notice
that if we subtract those to which at
the counters 14 and because now we can
sort of daisy chain these things and now
we've now we're able to do what we asked
for we're able to say give me the
five-minute numbers give me one day
numbers and give me the one week numbers
all that's changed is that our updates
are now linear in the number of sodas
points we're sort of breaking that out
this out then and yeah and why is it
important because now we can do our over
our day / day we can do percent up since
the last hour and which is nice um yeah
so we're counting things people like to
call it metrics but I sort of just it's
counting and and we can expand that we
can say okay so we've got our counters
but let's say we've got a payload as
well instead of just drawing in
countless restore payloads so now we can
do the means if we just store the sum of
all the payloads do the same sort of
subtracting theme with them and we can
do the variance because that's basically
the variance write the sum of the
difference between the mean and the
payload squared over the number of
things and that turns into that and
that's it as to that which means that if
we've got sum of the squared payload
then we can do and standard deviations
as well and which means that we're now
basically able to do all the statistics
we would want to do with these things
and like now we could again in our
messaging setup we could have a client
that reports back how long it took for
it to get a specific specific message
and we could do the standard deviation
on that data and know if if we are
consistent in there in the service we
were writing which is nice yeah but
still simple nice um so we did that I
drew it up and my boss said so now we've
got these averages but it turns out that
when you're delivering messages there'll
be some sort of outliers that take days
to deliver and they'll destroy your
averages so he said we need percentiles
we want to be able to say how much it is
or what's the sort of the upper time for
the 99th percentile um so I went home
again and I said okay so instead of
keeping these counters for all these
sums we can keep counts for em
the sums in different buckets so and
basically we have a a bucket for
everything that's one to a hundred and
then we've got a bucket for everything
that's one percent of above that and one
percent above that one percent about
that so that we can sort of within one
percent give back a number of how what
is like what is the 99th percentile
number and and we can do queries into
that basically by again keeping these
counts and because if we've got a 99
percentile pointer pointing down
somewhere here we can just update that
to the right or to the left when we do
updates to these buckets again in oh of
one time and so now we're sort of
wasting some some memory if we want to
do percentiles but we can do them and we
can do them in of one but it's just nice
yes so this whole thing were supposed to
fit into our otherwise nice and clean
and quite complex infrastructure so it
was supposed to work with our Erlang and
production environment it was supposed
to be nice and lightweight and it was
supposed to be able to scale and
probably even be sort of a
fault-tolerant um and I can say for sure
that it sort of complies with the top
two and but it doesn't really scale to
the extent that it van saun on the box
and but yeah
yeah and yeah so we we had to decide how
to implement this and when I sort of
done my initial experiments and and some
of the things that annoyed me a tiny bit
about doing this when I was trying to
just select the right tool for the job
was I have a hard time getting around
the fact that a lot of things in Erlang
and are not as predictable as I like and
so how many ETS updates can I actually
do and so that how fast how much memory
is an integer going to consume if I'm
just counting is it going to turn into a
large integer at one point and actually
take up more space than I then I liked
and if you noted my my trick with
splitting up my counters into two and I
was only adding to those counters which
meant that they were going to grow
basically indefinitely so they were
probably going to turn into large
integers at some point and yeah and how
much memory is this Q gonna take up and
that i'm talking about again we don't
really at least to my now the funny
thing about coming to the airline
conference is that I get to meet all the
people who and correct me on Stack
Overflow so i'm going to assume that
there's someone here who's Claire
smarter than me and but we don't really
have an array in Erlang we've got
something called an array but it's not
an array it's some sort of tree that's
nice for the boundary and so if we were
to implement this queue in an array
inner lying how much space would
actually take up and yeah and my old
world things from C++ I know that
integer updates are fast memory
consumption of an integer is predictable
I know it's going to be four bytes if
I'm running
two bit integers and I know exactly what
the footprint of my queue is going to be
because that's going to eat the number
of elements times to it max if i use
doubling it at a race um so yeah I sort
of pondered this for a while and I even
asked out on stack overflow and someone
gave me a long answer and I basically
got to the conclusion that since I've
gotta grad I've got a I've got him and a
degree with like an honours in
functional programming I was going to do
this in C++ which is what Mike said this
morning one should never do and you
might be right yeah so how much space
four bytes plus a bit per event and four
bytes for in the queue four bytes per
events in our counters four bytes per
counter in the leaderboards yeah 2.2 18
makes something like 60 MX and that was
the memory one going to take up using
c++ and and i sort of wondered so let's
say I built this thing what would be a
good thing to compare to and we use
Redis internally and we sort of like the
fact that fact that Redis is fast so I
decided to compare to read us since it's
written in c plus or I see actually and
it's fast and it does increment
operations and so yeah um I went and
built that thing that I just described
with all those arrays and some hashes
and
and the question now is how does it
compare so I ran a test where I did one
fret into Redis and with one operation
per requests and one with them ten
operations I think it's called
pipelining in redford basically ten
operations in one request and reddish
was able to do 21,000 22,000 operations
per second with one thread and yeah
156,000 with 10 threats and Italian was
able to do a 1000 operations one threat
and 208,000 operations with 10 threats
so plainly this was fast which was sort
of what was expected um and that's
something like m56 16 billion requests
today right if they're shouldn't evenly
distributed wit or not and but this
means that this box went would in some
sort of optimistic scenario be able to
handle quite a lot just this one box for
those doing this one kind of statistics
so I consider that a bit of a success
yeah so the product we sorta or the
product I made kind the scenes and that
I got to roll out into our production
it's split up into two things it's eat a
liqueur which is this c++ thing and then
it's each alley which is a.m. which is
basically the code for sending messages
over to the cenote that's running next
to an erlang node and the interface for
using it is quite simple you just say i
want to send an event then you give a
list of the events you've gotten you
tell me which leaderboard this events
for long this event belongs to and you
tell me where the instance is running
and and yeah and you just keep doing
that and then you can pull the counters
from from the other side and I even put
like bubbles and and if you want to do
the metrics right you want to measure
something and then you do the exact same
thing except that you can actually
parameter here that tells me that this
is also going to be percentile data and
them and you add the the payload as well
and if you do that and afterwards do
that query for the event get a horrible
amount of data and which is basically am
like five minute dataone our data to our
data one day two day three a-four a-five
a-six a-seven a two weeks a month and
two months of data with the number of
things that happened the sum of the
payloads and the sum of the squares of
the payloads and then the percentage
data as well um so yeah built that and
it doesn't look like much when it's just
code so its way funner more fun to talk
about a use case so and this is our use
case we've got some cowboy servers
sitting out front doing something
handling a HTTP request in our case
they're getting updated when one of our
users and sends a message or when we
deliver when we sort of get noticed that
we've delivered a message to a client to
a phone or something so they'll be
sending messages back to this italic or
saying so Android send a message some
android client or iOS send a message or
if it's a Canadian some blackberries in
the message and and sort of telling how
long did that take and then we just
entrust eat al you to do the actual work
behind the scenes and those queries and
would get to look something like this
right so we're telling it that this
event is an iOS and it's some iOS
version and the iOS goes into all these
clients leaderboards and the iOS version
goes into the iOS client leaderboard and
we want to keep percentiles in there
some pelo
and and then we put a fancy fancy
javascript thing on top of that and we
have something like this right I've got
a dashboard where we can say so these
Apple devices sent this many messages
within the last five minutes this many
within the last hour this is a spike
chart for what happened over the last
seven days this is the volume of this
day week month and we can sort of
compare percentages see that and our in
this case one of our apple or okay so
for this product the apple clients are
gaining traction and the android clients
are losing traction and so we can sort
of yeah we can do all this and we've got
these statistics on the timing as well
so we yeah got a nice feet of water then
we made it clickable so that if you
clicked on the like the apple thing you
would get this where you could see all
the different apple versions and you're
good and sort of see them that the
different performance metrics on them
and and you can see again for this
product that that this one client that
might have been the big one has
apparently been replaced by something
else so the usage of that is going down
and some of the others are going up and
you can sort of see that but the clients
are sort of coming out there and and you
can do that form yeah all of them and
you can even dive in and say okay so
what are the percentile data for this
for these things and which i think is
sort of cool i like the fact that the
back functionality is so simple because
that means that i have little chance of
screwing it up and again it's
yeah simplicity yeah but that's
basically everyone nowadays is sort of a
expert in JavaScript gooey but this is
bootstrap right but we had some some
lists on it and it's fine and but one of
the things the funny thing about them
having to do this talk was that it made
me actually reconsider the project right
because we roll this out and then we got
some funding and some guy who actually
knew something about statistics got
hired and I got to do and other things
and but when I sort of looked at this
again and I realized that you can do I
sort of skipped some details right if
you've got this big to you and you're
putting events on it you want to know
when these events are expired and the
only way of knowing that if you're sort
of thinking like me is if you time stamp
them then you could sort of you could
just look at the time Steinman you could
just say is this too old and you know
there should i cannot be sorted so you
can just pop off and until until you're
good and turns out that that's going to
crash depending on your time resolution
because if your time resolution is like
for instance a second then once the
second the world is going to end and you
are going to have to pull off everything
that happened five minutes ago and so so
you have to sort of be smart about that
and and you don't want your you sort of
have to play around with your timers
looting and with your techniques for
pulling things off these arrays again
and but what I sort of realized as I've
been making for preparing this talk is
that there's no good reason for the time
stamp to be attached to the events right
it makes sense to basically have two
types of things to put in the queue it
makes tends to say okay I've got a time
thing and an event thing and then
visually I'd have it like a bit array
sitting next to telling me what kind of
thing I have on the cue and because that
way I can let my time resolution very I
can sort of just decide that
milliseconds is what I need for this
application and start working with it
like
that and and not have it crash if it
gets overloaded because yeah the time
resolution in seconds is not a good idea
here so um yes about scalability if you
wanted this to handle something with
some war load like for instance a
facebook product and what could you do
well you have to sort of realize that
you've got you've got these three key
components right you got we've got the Q
you've got some kind of counter you've
got some kind of leader board and what
can you do well it's easy to optimize
the Q you just say okay I just split
this out I just like do a round robin on
a bunch of queues and now I've got many
and it's not necessarily fault tolerance
but it's scalable you just have more
cues and what do you do about the
counters well you do some sort of
reactive thing you just slice up the
counter space in and shot them and then
you have like some sort of database at
the end to have the to have that the
beat 22 to half the M the lead of ocean
and and that thing would be scalable in
case someone built it and you could do
other things you could basically replace
this with with any kind of Q so any kind
of and any any nice kind of Q would
replace that and yeah and but we have
sort of or at least I have sort of big
plans for for e tally and because
basically the foam that it's that we get
some data in we put it into eat I and
then we get some sort of updates out
because that's the nice thing we know
when the counter has changed so we don't
have to Kroy this thing all the time we
know when things are updating so we can
put any kind of dashboard on top of it
that's sort of auto updating without
having to do queries into the database
we know exactly when things are being
here
and or we could even do some sort of
machine learning thing on top because
basically you can analyze your door your
your event space as neatly as you want
and basically do clustering of graphs or
it would be easy to do something like
k-means clustering on top of this for
grabs and and perhaps give them some
decent information from that about usage
patterns I shouldn't be thinking while
standing here and yeah but that's that's
sort of the the idea is that each aisle
is supposed to be this core thing that's
simple that you can build things on top
off and one one thing that's easy to
build is this dashboard and the
dashboard isn't necessarily open sourced
and each a yourself is open sourced
under the if you can read it you can
have it sort of rule it's not
necessarily pretty but it's stable and
yeah it's um it's I'm sort of proud of
it I like the fact it simple and I like
the fact that it's um it's scale of one
and I've even replaced there's I get the
default q implementation with like a
disk-based back to you so that I can
handle terabytes of data in my queue and
it doesn't really affect my performance
because they are Nightline mice
libraries for for doing that sort of
thing and nice and IO efficient times of
disk so yeah we can handle millions of
metrics and yeah billions of counters or
billions of events yeah and that's sort
of nice I was going to say something
else I don't know um yeah
questions this was fast enough expected
yes yes what do you mean if yeah then I
then I die then I replace it with
something larger yeah no that is not a
lot of this is configurable in the sense
that you can change it in the cook and
but yeah some of the counters are
actually a 42 bit and just just because
yeah and you don't want to have to sort
of take into account the fact that
you're actually counting on a ring right
because that is sort of the trick when
we do when we do the insert countess and
the the deep sort of the outskirt
counters we don't care about overflow
because it's going to happen both places
so the ring is going to take care of
that for us the fact that yeah integers
are sort of defined this ring and but it
does mean that the number is never going
to be higher than four billion yes now
so yeah that would if you wanted to run
this in an environment with and with
something bigger then you would up that
too I don't know 64 but that's not going
to really affect that the the memory
constraint here is the queue right so
just yeah yank it up
Ches so the implementation is a C++ poor
it's a say but it's a C++ it's a c-note
right so it sort of acts in all sorts of
fancy ways as if it's a yeah I'm
registering a c-note up against EPMD and
sort of yeah yeah oh yeah yeah that's
one of the funniest thing about that 256
that wasn't a number some the number of
requests i can do per second and because
you could say oh if you optimize this
it's going to be faster but I've
profiled it I know that half of my time
is spent decoding Erlang terms right so
this is never going to be more than
twice as fast in any kind of world um so
yeah um but yeah I sort of fell in love
with the idea of having a a thing that
acted like an erlang node but that I
could play around with so in my again
some of my more interesting ideas for
building on top of this would be doing
DP u GPU gvgv you computations and again
pretending that I was like an erlang
node and but being able to do these
things in the GPU and hence being able
to do linear algebra something Erlang
probably isn't the best thing for ya
yeah do you have any
no it's it's Sam if we crash we crash
and we were able to bootstrap from a
transactional database we've got on the
side and that's doing some marketing so
we bootstrap up and then we're sort of
correct until two months um but again
that would be a nice thing to em to fix
by for instance replacing the queue with
something more persistent Yeah right I'm
just really more like an attempt at
eliciting a comment right questions
intentionally vague but I am working on
the project now where I have reason to
think it's an early application that's
distributed by course but I have reason
to expect that there's going to be
portions of the problems that will begin
do you have any thoughts about like that
type of hair off like I would be non
obvious I think but again this is sort
of this leverage is my stack overflow
questions because I would have a
tendency to believe that anything that
was sort of computational heavy right
computationally heavy and to a certain
extent bounded to one process I would
think sort of belonged in the c++ domain
right in that in the close to two metal
domain right but then the interesting
question becomes so how do you get the
data over there because even though you
can sort of Liberty the messaging from a
line note or a line note you really
shouldn't be pushing package of two gigs
even though you might feel tempted but
but you and you your your system will
break right so again one of my ideas and
has been to sort of make a version of my
now tally without the Erlang two terms
just to have a thing that just took like
UDP packets and took care of them just
to get that whole yeah yeah but then I'm
probably going to have another decoding
thing yeah
oh yeah but we're using this this is
running in production and it hasn't
crashed yet since last time we started
it hasn't grasped for at least a couple
months so it's yeah yeah the dance again
talking to an airline crowd that's a
yeah that's a catastrophe waiting to
happen yeah so one of the things we
talked about was increasing the
scalability by shari yeah do you
anticipate that that would be on the
same physical piece of hardware or would
it be distributed on multiple pieces of
hardware or I'm guessing that one of the
things that I would run into should I
try to implement this in in am in a sort
of someone with through more throughput
or just having more data to shut at me
and I would run into network things
right so so that would probably be the
argument for moving on to multiple
machines I thought about how the fact
that increments or not oh but if you
have liked but if you have yeah yeah
that wouldn't be a problem with their
cue necessarily right because it
wouldn't be a problem until the cue
trying to update the counter in some
database yes but yeah at that point
that's like an obvious problem it's a
and it's bound to happen right it's them
because yeah you can act as many times
as you want but you're still going to
have some percent in general who doesn't
know what's going on and yeah I mean
maybe that's fine for metric like
metrics or something where you yeah but
one of you know this
you exactly store 10 million five
hundred thousand messages now you're
sounding like my colleague because one
of the reasons i did this this way was
that I would like to know the exact
number I would I I want to know I want
to I want to be able to win when our
product people come and ask so how many
messages did we send yesterday I want to
be able to tell them because nothing
worse than having some kind of product
version walk up to you and say so how
are we doing and having to say well I've
got four metrics and they're showing
four different things but they're not
off by too much right let's want to be
able to say uh yeah now want to be able
to do banking yeah
great thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>