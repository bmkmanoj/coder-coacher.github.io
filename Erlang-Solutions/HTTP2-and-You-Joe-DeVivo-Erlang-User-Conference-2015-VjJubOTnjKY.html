<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>HTTP/2 and You! - Joe DeVivo - Erlang User Conference 2015 | Coder Coacher - Coaching Coders</title><meta content="HTTP/2 and You! - Joe DeVivo - Erlang User Conference 2015 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>HTTP/2 and You! - Joe DeVivo - Erlang User Conference 2015</b></h2><h5 class="post__date">2015-07-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/VjJubOTnjKY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">wait um hi everybody i'm joe devivo i
talked about HTTP two and my erlang
library for it is the the coolest thing
i'm doing right now is I'm actually
serving up the slide deck through htp
too so we're going to refresh it real
quick we had a little lightning bolt up
there that means it's working and I've
got a bunch of log messages to show that
same thing so you can believe me or you
can download it later and see for
yourself see to do this right I have to
the one consequence of doing a full
screen browser-based presentation is I
have to drag it down there but I have
now so we're good alright so my library
is called chatterbox this link to the
code there's a link to the deck the deck
is can't see the red here but it is Joe
to vevo.com / you see 2015 so you go
look at this deck right now let's talk
about HTTP one before we talk about HTTP
two um it's huge everybody everyone ever
one of you has touched it today just in
your life that's it's everywhere and it
is a very very well defined thing the
the remix HTTP 11 spec that came out
last year is 292 total pages actually
six rfcs and you can find all the links
in this deck somewhere and it's it's a
big deal and everybody's really looked
at it um it's kind of not really
economical with TCP it keeps connections
alive which is good we don't to open
these things all lope and that's a big
improvement over HTTP one so that 10
that's something but eda sequentially
sends requests and receives responses in
order via pipelining and that can be bad
if you're not responsible that
introduces this idea of a problem called
hanap line blocking and what that does
is it said as many requests as you want
over a single connection but the first
one is going to respond first until that
response is served that's it we're all
just waiting and there are lots of
people that have hacked lots of ways
around it and I don't want to talk about
them because they're all terrible
they're okay but transfer sizes are
going up and transfer quantities are
going up so head of line blocking just
going to get a bigger and bigger problem
except that like browsers don't even
implement it so you know a lot of HTTP
11 was optional and
I caused a lot of problems when you're
developing software that's supposed to
work together that's where HTTP cook 2
comes in here's the abstract I don't
expect you to read it here and now but I
highlighted these parts and gold and
then turn them into bullet points so we
can talk about them the goal of the
protocol is to be more efficient with
network resources that wants to it wants
to reduce the perception of latency and
web applications it does this via a
header field compression allowing
multiple connections concurrent
exchanges on the same connection this
new feature which is this unsolicited
push of representations from servers and
it uses https existing semantics these
bullet points are verbatim from the spec
so this was the idea and Google tried it
with speedy and they pretty much proved
that it could work but it was all Google
all the time and nobody wants to just go
to the Google show and not to anything
else so the HTTP working group
eventually sort of you know God ideas
from google and people from google and
they did their own thing too and it
became this bigger open thing and HTTP
to the RFC came out was fully approved
and finalized just last month and what
it gives you is the ability to keep your
HTTP semantics gives you a path to
upgrading HTTP one requests or messages
as a whole and it lets you be more
efficient with connection and networking
and did i mention server push the the
new feature as it were but it is another
feature designed with these three things
in mind so you want to keep your
semantics and these are you know get
posts and all his friends and you know
headers request and response headers
request messages response messages these
are the things that a programmer uses to
use HTTP like API levels browsers use
them and we're going to keep using them
which technically means these five rfcs
for HTTP one and some of that sixth one
are all still valid so if you thought
you got out of reading that 292 pages
well you did because you're here when
we're talking but you know it is it is
quite a read from the earlier in
perspective that means something like
web machine we can take a like the
module that we use for web machine right
now is mochi web and mochi web will you
know does the HTTP serving and then web
machine does the rest part like you know
the resv not
the remainder but uh we can plug in
something like chatterbox to web machine
at a certain API level because the
semantics of HTTP have unchanged talk
about upgrading HT one request is
probably the simplest part especially
since I didn't do it my implementation
is not done so you know watch this space
as we keep going but um HTTP one request
can be upgraded one or two ways if it's
coming over HTTPS then it uses TLS is
either the next protocol negotiation or
the application layer protocol
negotiation and it uses NPN speedy uses
NPN and they say okay it's fine we'll
still do that but they don't really want
to and Chrome's dropping support for NPN
and speedy so everybody's moving to HTTP
two and a LPN I believe or like 17 s on
and pn + 18 will be on a LPN so I'm on
17 now so we're still using MPN but
future LPN if it's just the plain text a
TV HTTP connection first of all they
discourage it firefox and chrome are
both only doing HTTPS support for HTTP
two but they just couldn't quite
convince everybody that you have to be
SSL or bust so if you're doing a clear
text HTTP two connection and you want to
upgrade from HTTP one there's this 101
switching code which came out really
small on the slide but and then you can
go on to upgrade and that actually winds
up grading in second connection but
using two connections for your entire
session is better than like a million so
that's good so let's talk about
networking optimizations that a big one
is um you know comes from header
compression and one of the bigger things
that we have to worry about with HTTP is
that it's a stateless protocol and
stateless protocols are repetitive and
if you don't believe me I'll you know
stateless protocols are repetitive so
they came up with a whole nother RFC
it's like another 60 pages I got like
you know 20 pages into the HTTP to spec
and then it's like oh just see this
other RFC for header compression and
move on and then you get to that are see
that's another 60 pages but it's
actually really cool and it's it's a
much like smaller problem well it's a
subset of HTTP tues problem right but um
what it does is introduces that you have
a stateful compression context on the
connection
so let's talk about what okay what a
compression context is and it's
essentially i'm here at the center you
see it it's a lookup table for comment
and recently used headers and the
initial state for this thing is called
what they call the static table and the
static table is a set of 60 one of the
most common headers they did some
analysis over a bunch of web requests
and it basically said these are all
happening a lot some of them have
corresponding values like path and / for
example that sounds pretty common right
response 200 that that's very common
others don't have values at all like
user agent which is a very common header
but there's not really one very common
value for it I mean even if it's chrome
it's still chrome like one dot 37 9
million build 32 whatever so we don't
have one there but that's what the
static table looks like in every
compression context when it starts looks
like that of course inner line that
looks like this which is the 32 pool
it's got an index value in a name or our
name and a value sometimes about you
anyway you might notice these pseudo
headers you know method path scheme and
status aren't headers in HTTP one and
they're not really headers in HTTP two
but we're using this header context to
keep track of them so we're still going
to we're going to use these were to
treat them like headers at the
implementation level but they're not
really so yeah like I said the initial
context of this value is the static
table but there's more this is idea of
the dynamic table so like I said index
is 61 for 61 are all specified by the
spec and they never change but you can
add your own and they come in at index
62 always did index 62 everything
increases and it's a FIFO kind of thing
but we'll get into that right now also
this these the sizes dynamic table is
bounded by the HTTP to settings so the
connection sort of agrees okay this is
how but we're gonna let this thing get
and that helps prevent things like the
crime attack so what that's look like
yeah I have this idea of header names
and header values and then you basically
have this dynamic table which is just
you know that the three tool that I
showed you before a list of those and
it's got like sizes that we do the
security checks with and then we have
this encode and decode function and
there
the inverse of each other right encode
takes a list of headers and returns a
context because the context changes with
every header you encode and decode works
the same way you take you take a binary
encoded block of headers and out you get
a list of all the headers that were sent
over there so let's look at the dislike
this identity operation on a on a set of
headers if you put something in the set
of headers that's already in the context
it doesn't change you already have
essentially in an alias for this thing
so I've done something here twice I've
done it in code here on status 200 and
then I've done a decode on the binary
created by that and when you are done
these two values are the same so static
table is this variable that I've bound
up here to this new encode context none
of these none of these bindings fail
because it's all the same object all I'm
over the same data structure all the
time but if it's not already in there
things change see I'm trying to encode
this new status code 600 which i think
is going to be all the rage and I've try
and put it in this context and now the
static table and the new context are not
equal to each other however if I try to
use that new context to encode status
200-600 again now it is the same now
this thing does bind correctly because
once something is in the dynamic table
you look it up and it's there already we
don't need to encode it again the
context remains unchanged but there's
for context because why would just one
be enough right there's an encode
context on the outbound request there's
an inbound context on the on the server
side right so you've got headers going
out from the client they getting coated
then encoded comes in on the server they
get decoded we're both starting from the
same common static table so we all know
what we're starting at and as long as
they stay in sync everything's gonna
work out fine and I tried to make that
look like math and you can read this
slide later i'm not gonna splain it now
but basically as long as these two
things stay equal everything's great
it's like here's a basic case for that
you know you've got this context a one
and you've got your set of request
headers coming in they getting coated
and coated over the wire
they come in on the server side you
decode them based on the static table
and you have your new set of headers and
that's really trivial why would you want
to do any of that well in case we are
you sending multiple requests over the
same connection it gets more interesting
right all these sets of headers all go
through this one context and each time a
set of headers goes through the context
changes but the encode context in the
decode context are both changing like
lockstep same set of requests coming in
in the same order so these objects are
always going to be basically the same
representation on both the client and
server which allows you to say well I'll
show you what allows to say right now
I'm going to show you how H pack packs
there to data structures in H pack
numbers and strings numbers basically
represent indexed indexes that we talked
about in those two tables and strings
are everything else so let's talk about
that this is a single bite that comes
over and abiding coded a header field
and if you're sending something as
simple as like path / then you just send
the number 2 over the wire actually it's
going to be you know the first bit is
going to be one in the room age of the
bits could be 0 0 1 0 and you're sending
over one bite to represent that
represent this and you know this more
than one byte value now may have noticed
if that number is going to be more than
2 to the 7th minus 1 that we have a
problem here in H pack does a different
way of representing integers larger than
the space it has to fill but this talk
doesn't actually have the space to talk
about that so we're going to move on so
if you have something like user agent
where you need to send over a value
because there is no value set up by
default then you do you know you have a
different sort of byte prefix up there
or bit prefix for the first two and this
let's H pack know okay this thing is
coming over with an index for the name
of the header but the value is going to
be a string so then I sent over the
index and same thing if two to the 6-1
is too big to hold the index then we
have another way of representing it and
then we have the same thing here another
integer that says the string value for
this thing is going to be this much
longer afterwards and then a bunch of
octet that's that long and then the last
one if we do the custom header that's
not in any part of the context yet we
send over two strings I mean that's
pretty easy right we just have this
first bite that's all well defined
mostly zeroes and then just two strings
name value pairs just like the old days
when a literal header does come over
there's a couple different prefixes that
you can put on it just to tell you how
to route these things sometimes you
don't want it to add things to the index
so we just say without indexing
otherwise we say with indexing and never
index just means if you're a proxying
you're going to tell your friends all
about this request to tell them not to
index it either because you know we just
we don't want it indexed wees we were
never here but what's cool about these
things is that we can really just like
pattern match like all day with these
things you know all the specs specifies
you know if the beginning of the bite is
this bit then we do that if this bit of
bite is this then we do that and if the
first two bites are this or the first
two bits are 0 1 then we do this and if
it's 0 0 0 0 then we do that and it
makes really reading a binary protocol
really fantastic so bad a binary pattern
matching you know get into it but I saw
that like Huffman encoding was the thing
that we could do with with these string
values and we can we're not going to
hear but it's basically a statistically
analyzed way of encoding strings that
makes each character that is most
commonly used like in displayable
characters like take up fewer bits it's
all about economizing the wire here
there are tons of cool cool examples of
H pack in the h pack spec and I turn
them to the unit test so you can click
this link and go check them out but I'm
walking you through an example of like a
couple of HP a request just to show you
like how this thing winds up saving a
lot of space so I'm gonna send these
three requests over and they're very
they're all trivial there's three name
value pairs and we're going to go over
one by one so you don't read them all
now here's the first one it's a request
for path / the user agent is my cool
browser and I'm sending over a custom
header X custom header with some custom
value so when I send that over the wire
Wireshark understands HTTP two and tells
me okay well pass / we know that one
that's index for so we're just sending
over the bite for then we see user agent
when we know user agent is index 58 from
the static table but
value so we're going to send over the
string Michael browser and then X custom
header we can't find that in any context
we're going to go ahead and send over
both the name and the value so you know
pretty pretty bite heavy especially that
last header so as they come as these
headers pass through the context what
you wind up happening is first of all
you know you try to put paths in the
context and path is already there so it
doesn't do anything context remains
unchanged it's that identity operation
we talked about earlier user agent
Michel browser comes and we go okay well
this damn value pair is now going to be
62 in the dynamic table and that's great
moving on X custom header and some
custom value is now going to be 60 tubes
is another new value name value pair
that we've seen and so we bump
everything that's in the dynamic table
already up one everything moves out
towards the back because once you get
too big for the for the agreed
connection size we drop things off the
end so keep good stuff at the beginning
it makes it easier to find so great now
we're to do another request to the same
server and it's going to be you know
we're looking for some file HTML that's
our path the user agent and ex custom
headers have not changed we're going to
send over the same ones because it's a
part of our session we're in the same
browser ex custom header might be some
kind of cookie or auth token or whatever
so we Wireshark that and look how much
smaller the actual data we sent over is
path still matches up as a name to index
for but it's never we've never seen this
value before is we're going to put that
on the wire but then Michael browser and
user agent we both know both of us being
the connected client and the server that
that's index 64 and we both know that X
custom header and some comes to value or
actually indexed 63 now we're just
sending over 1 by 4 each of those second
new header field so already we're saving
a lot of bites a lot of bites being
saved here now you may have noticed that
I just said these were indexes 62 and 63
and now I'm saying their index is 63 and
64 what happened there well path and /
some file is a new name value pair
combination so as soon as that one set
headers came in we saw and went alright
that's a new pair we're putting it in
the dynamic tables in Des 62 everything
got bumped up one then when we look for
these other two they were already bumped
up so that's and we hope we all know
that so that's why they sent it all over
so then here's request three we got the
same
have some file HTML again user agents
the same and we've changed the value on
next custom header and what happens to
the context is while path and some file
HTML are now things that we've seen so
that's just in x 62 it was indexed 62 on
the last slide and it's the first header
coming in on this slide so there's no
index change at all same thing with user
agent and micro browser now another cool
thing that's happening here is x custom
header has this new value but we've
already seen the name x custom header
and we know that's index 63 so we're
already saving the bites for the string
X custom header we only have to send
over the binary new value and that's
what happens and eventually what winds
up happening is we see X custom header
and new value and that's a new thing so
it goes in the front of the dynamic
table everything else gets plus one and
we have actually have 2x custom header
name value pairs in the dynamic table
and that's cool maybe we'll see either
one of them again maybe we won't maybe
we'll get so big we just dump them off
the engine we never see them again but
that's okay too so that's H pack that's
how each bag works another real cool
thing about HTTP two is multiplexing and
multiplexing is pipelining done right
what allows us to do is just send
individual frames over the wire that are
interleaved and we just reconstruct the
strings on their side so what's a stream
there's one connection and streams are
logical abstractions across it they have
unique identifiers at most there's one
request at one response for that doesn't
necessarily have to be a request /
scream we'll get to that in a second but
client initiated streams varieties are
always odd except stream 0 which is the
meda stream for the connection frame
sent to it apply to the entire
connection if you want to negotiate
settings on the connection level how big
can frames be how big dynamic tables be
these are things we talked about on the
extreme 0 so um yeah every frame has a
stream identifier that's what we know
what to do with it well or where it goes
at least there's one stream ID per frame
and as these things come over the wire
we just reconstruct it on the other side
and we know what to do with them we can
reconstruct them in order why in order
well when we just all talked about H
pack and all those indexes and how they
change and how they process headers in
order well if they come in out of order
and you get it you get to
streams crossing like this then what
happens is you wind up with a bad header
decode at best at worst it just doesn't
even know what to do with itself in
crashes or it sends a protocol error
because we can send protocol errors now
so just to solve the jargon here a
connection has multiple streams each of
which can accept a single request
message and send a single response
message each message consisting of
multiple frames in order so how do they
handle them all the rules in the spec
about how many connections to be active
simultaneously and what kind of frames
can be accepted when and they gave us
this cool diagram in the spec I got
excited because I'm like oh my god it's
a never say I can make a jet fsm and I'm
in Erlang and it's perfect so don't get
your hopes up that's not what happens
but a frame does look like this east rim
is a 9 octet header the first three of
which is just length and that is the
length of the payload the nine objects
are not included in that following that
is a type there are 10 types of frames
and each has rules for how big the
payload could be or not some of them
don't well the papal it's in the payload
and what flags can be set so what am I
in flags well flags is the next byte in
the header and it's just 8 bits that you
can just flip for various reasons based
on what type of frame it is then there's
this one reserved bit that does
absolutely nothing it's in the spec it
says ignore it so ignore it but the next
31 bits are the stream identifier and
that means you can only have 2 to the
31-1 streams over a connection so if you
ever use that many streams we close the
connection on you sorry but you've
gotten you've had a really good run with
this connection so you should be happy
that you didn't waste all those other
connections and look it's so easy to buy
binary pattern match this thing and just
construct a record of a frame header I
mean look at that that that's it that's
all I do yeah so like I said there are a
couple of connection level type frames
and I'll talk about the real quick there
are settings and these are protocol
negotiations ready to be any of the
connection but they can be changed at
any time as well there's a ping which
from the spec says it's due there to
measure network latency but in
practicality when I was watching Firefox
actually serve up this thing this deck
over wire of shark I notice pings come
in
every so often and Firefox is actually
using ping to keep the connection open
for a while and then after like four or
five pings and it still hasn't gotten
anything responses then it closes the
connection it closes it with this thing
called a go away frame and it just
sending this is like by we're done you
know sometimes it's bad sometimes it's
good i mean you can just be done it's
sometimes it's time then there were
stream level frame types and these
things are going to comic-con look
familiar like headers right you send
headers we still have to send headers
headers aren't going anywhere because
HTTP one semantics aren't going anywhere
and we encode this block fragment with
the h-back encoding and we send this
frame over the wire and that's how this
thing sort of those okay we're starting
a new stream with a new request coming
in now we talked about frame size as
something you can set on the connection
level if your header block fragment is
too big to fit in in a header frame we
have this continuation frame and we just
put the rest in there so we break up the
header block into fragments based on
frame size and send continuations over
after the first headers blog so headers
frame basically says okay we're starting
here's a message we're starting and it's
got headers and then if it doesn't have
it and headers flag set then
continuation is like okay here's the
rest of it here's the rest of it here's
the rest of it once and headers is done
you can send over data frames and this
is like your your post body but at any
time if you feel like this connection is
just done and we've broken something we
don't want to wait for it to respond we
just want you to stop we have reset
stream so we can actually say okay we're
done and you don't need to spin on this
anymore which is which is nice so here's
a sample message right it's just a
headers frame couple continuations one
with the end headers bit flipped then a
couple data frames and an end stream bit
these are these are all flags and so as
these frames come in and you process
them you can sort of pattern match on
these things to be late all right okay
now I like transition it to this state
where I can only accept you know pings
now while we wait to serve up this
response so what do we do with routing
individual frames well I have this I do
actually have a gin fsm and it's called
HTTP do connection and this monitor is
the entire connection state and it
basically owns the socket and it owns
all these connection settings and it
does all these checks on that and one of
these functions in it is this route
frame for
here's a real simple example clause of
it what i'm doing here is I have a
receive setting that says this is the
maximum frame size I can take this MF s
thing here and if the frame headers
length l is greater than that then we go
away with a frame size error that's real
easy the spec says it's somewhere maybe
says it like eight times I don't know
it's a spec so that's an example how
high Dubrow something in the connection
level but we also have these streams and
this was that thing that looked like
that Jennifer salmon we were so excited
we're gonna have to implement that I was
excited too but a lot of being a
different kind of fsm I made this people
have done this before but I called it a
phone I state machine and I thought I
was brilliant but what it is the idea is
that it's a it's jen msn without the
chan it's got no pit it's not being
spawned and i'll tell you why we can't
spawn it later but this is a reminder of
what it looks like you've got these what
are we looking at seven states and you
can see they transition on sends and
receives of certain types of frames or
certain there's a there's a glossary for
this in the spec but sometimes it's like
send h receive h that's headers but
sometimes likes nds that's n stream flag
set that can be set on a header frame
with no body on it on a request or can
be sent on a data frame signifying the
end of the request body so yeah there
you go and these states exist on both
sides of connection right the client has
it and the server has it they keep track
of all every stream so I had this stream
stay and had it keeps track of those
state names that it has a stream ID and
it will grow grow over time as we add
more features but it has these two
functions for transitioning has a send
frame and receive Frank function it sort
of came out so we can model that diagram
that we had before so let's talk about
what happens when a headers frame
actually comes in what we do is we have
a oh no I'm looking at the futures live
but here it is so this route frame
function is in the connection level and
it gets a headers frame that comes in
and we have to check stuff like you know
what are the receive window sizes and
stuff like that why do we do that here
on
no that's the part of the talk but we do
here we check the frame header type as
headers we checked that it's got an end
headers flag and I use this is flag
macro thing to make that easier but it's
just a binary and with some other math
thrown on it but it's real quick so if
this is a header frame and it's the
entire header block we go ahead and we
each peg decoded we use the decode
context that's up there in the
connection state and then we create a
new stream based on the stream ID from
the frame because we know it's the first
frame in a connection so we've done that
and now we need this HTTP to stream
which is the state machine without a
process and what we do is we use this
new method just to create it with its
initial state and it returns a state
back to us then back in the connection
route frame function the next thing we
do is we pass this stream in along with
our connection state because some frames
that come over the wire actually will
affect overall connection states so we
have to we have to make sure we have
both of those things available to us to
transition when we we process the
received frame function so what does
this receive frame function do well when
it's a headers frame what we do is we we
check and see if the end stream flag is
set if it is we transfer we transition
straight from the idle state which is
the first state through open all the way
into what does it have closed remote and
that essentially means we're not getting
anything more from the roanoke
connection we're so going to send some
stuff back that's why it's half closed
and then we have another thing here
that's basically the catch-all if that
if that those flags aren't set then
we're going to store this header frame
as an incoming frame in case it winds up
having a continuation frame we just have
to keep track of all these states I
think it's very complicated so this is
the end stream case that we're
processing we know to run the content
handler which is what we're doing here
handler is actually a thing that we can
put in the state right now this is a
static content handler and it's going to
serve up a file but we could have
another kind of content handle that
might be like a web machine integration
point or something like that so once
that happens then we know that this this
request has been processed
store this particular frame has been
processed and the handler is off
handling its business so we we just
transitioned basically back into this
we're ready to receive more frames on
the connection level so that's cool
that's multiplexing like in a nutshell
there's plenty more to it but I want to
traduce this idea of flow control it's
another thing that's really cool we can
actually tell a client or you know to
stop sending us data we literally cannot
handle it right now so this only applies
to data frames and what's cool this is
like we can send control frames over the
connection and not have to worry about
these limits so if you need to reset a
stream to basically kill this stream and
and not keep going with it then you can
get around the data frame limits to do
that you can do connection level stuff
you can send go aways you don't want to
be blocked with any of this so that's
why that's available but each receiver
advertises how many bytes it can
actually receive and that's maybe that's
a memory constraint maybe that's just
it's just how you want to handle your
business that's fine and a sender like
honors that it won't send more than the
receiver advertises so we've introduced
this this concept and there's a new
frame type for that it's called window
update and it just sends a positive
integer over the wire that integer is
saying increase the credit that we have
I said I can receive two kilobytes but I
can receive one more kilobyte than that
so here's one kilobyte the integer I'm
sending to you and now between the two
of us we both know i can accept three
kilobytes this works on the connection
and stream levels you can have these
limits for both the entire connection
and just one stream so how do we
implement it well we don't have to worry
about data frames but at the goal to
construct the connection and stream
level so we have to add some state to
the stream state to actually keep track
of these limits so look at these static
type paintball and I just have a
hard-coded response types and to make
sure this presentation worked and what
are you in here reading the file we're
serving it up and then we're sending the
return burning the data to frames
and that's it why is there not more code
here can I scroll no I moved on another
slide after we have a set of data frames
that we're going to serve up pieces of
this file and some headers we're going
to fold over the whole thing and that's
what's so cool about this phone ID state
machine thing right is that we know the
state of it is going to be a tuple of
both the stream state and the overall
connection state so if we have a set of
a hundred data frames we can just fold
over that and just send each one through
this structure and it's going to return
as the accumulator my state for the
connection and my state am I or my state
for this stream and then my state for
the connection so that's uh that's
pretty cool and then the send frame
function since these are all data frames
it's going to go through this clause
which evaluates both the stream States
send window size and the connection
state sent window size and it's going to
just use this guard to say if they are
both greater than or equal to 1 2 L the
length that's coming in over the the
frame header for the data frame then
send them otherwise we're going to come
well otherwise nothing and we also have
to decrement each to the two straight
send window sizes right we you know the
client said you can send me to kilobytes
we're going to send a kilobyte now so
now we know we can only send one more
kilobyte so we do a decrement there to
make sure we can track of that so what
happens when that guard is false it
falls down to this clause which says we
can't send anymore so cue it up and I
haven't queued up yet I've concatenated
of the terrible list here but this this
works and I'm going to fix it later I
left it in this line because there's a
github tag to all the source that's at
this version so see yes so cute frames
that really only applies to the
connection level but we have these cute
frames and they're sitting here in this
state now they're in the state of the
stream what do we do with them they're
just sitting there in this state where
maintain we're just holding on to them
and we don't know what to do well the
window update frame comes over the wire
and it says hey I'm ready for two more
kilobytes now and we go gray so we wake
up you know though the window update
frame has a stream identifier so we know
which stream to go wake up and then we
start sending
we do the same fold again we fold over
this thing until it is no longer true
and the same window the send window
sizes have gotten too small again so we
stop that only works for the stream
level to do the connection level what we
have to do here is we get a connection
level window update and it's the same
general idea we maintain a send window
size in the connection state and we
incremented here when we get the when we
get the increment when we get the window
update frame but there's still us to do
in this implementation if you spotted it
I sure did up there there's nothing in
here that's waking up old streams if we
time if we stop sending frames because
the same window size in the connection
state has gotten too small that we don't
have a buffer to send now that we have
that buffer because we've increased the
send window size there's nothing in this
code that wakes wakes up the stream so
i'll do that dollar this tomorrow so
also here's um here's prioritization and
prioritization is another feature that
we've added that actually lets you
prioritize streams and you know it's
cool because you can request priority on
the client side so you know what this
javascript file is more important or
this HTML file is so important that
without it like we have no Dom so my
javascript file is worthless so give me
the HTML first it's a tree structure so
you can actually just have like multiple
dependencies on a single stream but the
most important thing is that a server
does have to honor any of it so i punted
and i'll get to it but the other one
thing i didn't punt on was knowing that
i have to do this in the future is why i
can't spawn a gen fsm for every stream
because i have to be able to enforce
some kind of priority on these streams
and when they were serving responses and
if i spawn off new processes say just go
nuts well I can't really tell them what
to do anymore but we do this with a
priority of frame it's a new kind of
frame and it's just um it says hey you
know here's the stream ID that I want
you to change the priority on and here
it's new priority and then there's some
cool algorithm inside the spec but
actually says okay well if this happens
then you shuffle this up the tree this
way shuffle this of the tree and you
reassign the children and it's cool
there's lots of little ascii art so you
know i like a let's talk about server
push this is actually really cool in
life that the new technology part of
HTTP
right the idea is that you can have
multiple responses per request you'll
send one request for like index.html and
your server so you know what's in index
HTML and maybe it's got all these links
to CSS sheets and javascript stuff like
that you could start opening up new
streams and sending those files
anticipating that the client will
eventually need them so each response is
on a new stream and that's what these
server push streams are certain issues
initiated streams have even identify as
we talked about the client streams
having odd that's how we sort of keep
track of the difference and what even
does that mean I don't know what with a
static content yeah this is what I was
talking about before you know you know
what's going out so you can just start
initiating all these outbound
connections now this is exciting for AP
is because we're that's where the action
is in my opinion yes anything that sends
links in its response body can start
queuing up things to be sending out over
server push and then the disclaimer I
have not done so for push yet it is the
exciting thing i'm looking forward to
but i have to lay the groundwork first
so push promise is a new frame type for
this and it is it is essentially if you
remember how the headers frameworks it's
just the first part that says a frame a
message is coming and then it's followed
by a bunch of continuation frames
probably push promise is the headers
frame for a server push it in it says
the thing is going to start it has a
header block fragment that is you know
can fit in a single frame and it is also
followed by continuations so
continuations are useful in both those
scenarios yes like that and then you
show disappointed now because this
looked a lot like that other slide I had
about a connection message and I must
have just destroyed it this morning even
though I said I was done with my slides
I was not but it's the same idea there's
a push promise frame then insinuations
in a continuation with an end headers
data data data and stream so a lot of
connection what can we even do we can't
do anything so I started making a
connection here's some RFC about how a
connection starts here's some RFC about
what settings frames need to go in
here's more RFC about what can happen if
we don't get a setting frame in time I'm
not gonna you read that I was going to
what they do you send this string to
start a connection then you must send a
settings frame and then you must have
that settings frame respond to do with a
knack which is just another flag on a
settings frame we must get one from the
client to because we need to know what
they think about the world and then we
need to send an act back saying yeah we
heard you so there are only six settings
most of them you probably figure out
front we talked about frame size
receiver window size whether or not you
can do server push or just going to get
through that quick because I'm running
out of time and then this part of
section 4 which just says once that's
all happened you can actually send
frames so the first part is easier right
we just do it handle info on the socket
we say oh did we get that string cool
then we go into the settings handshake
state of course there's a settings
handshake state what does it do well
what it does it is um it sends our
server settings frame and it's it waits
for a client frame and it sends a knack
and if any other type of frames come in
while this is all happening we just back
a lot of them so we can process them
after we're connected and that looks
like I was like this right so we enter
the settings handshake and we're going
to trivialize this code by removing the
case where we got more than more than
the preamble on this initial connection
packet because that gets a little bit
more annoying and I've code for it but
it doesn't really gold on slide and what
we do is we set up the queue for the
backlog and then we answer this loop
with this to topple and as the
accumulator here and this thing is going
basically saying we're waiting for to
target conditions before the state is
over that we've received a knack and
that we've received a client's setting
frame so we just start processing
packets of Jim we start processing
frames and frame by frame what's cool
with this is that you can actually read
nine bites off off the socket and go
okay there's a frame header and it says
that its body body is going to be X by
so read another X bites off and now you
have this package or this frame and
you've built it and you know what to do
with it and if it's a settings frame
then we enter this loop where we do one
thing and if it's a different kind of
frame then we essentially add it to the
backlog to process after the connection
has been established and so here's the
bit where we flipped the first bit over
we just check the guard we say when is
flag ACK we've got our act so flip the
first flag to true and then this is the
other one when it's a client setting
frame that means it's a settings frame
but it did not have an act bit set then
it must have settings for the clients
we're going to put those in our
connection state and now we've agreed on
what's going to happen
so in developing this you know I started
off with this minimum viable response
right at this ng HTTP to client for
command line it served a response and
that was great but now what well I
started serving this deck over firefox
before it was even done and I saw sorts
of things breaking my JavaScript didn't
compile because my frame size was too
small and it wasn't sending all the
JavaScript files I found a lot of bugs
that way but at the end of the day
firefox did an HTTP to implementation
right so I couldn't test all these error
conditions in the RFC so I made my own
client and my client can break things I
can send arbitrary frames over whenever
I want and see how they break so that's
the high level API is this you know
there's HTTP semantic API that we all
know and love and then his mid level API
is this just sending whatever frames
over i want so i have this other case we
can talk about really quick and blah
blah blah blah blah the tilter is once a
header frames received on stream X we
can only accept continuation frames from
stream X and anything else that happens
we close the connection in a huff why
because everything needs to come over an
order these are headers we're talking
about people and headers have indexes in
these indexes all increment they off to
stay in sync on both sides of connection
if we get anything out of order them
everything we know is meaningless so we
have to stop you know this bit of RFC
now I'll just brought to you by me joe
devivo who's been reading RFC so you
don't have to since 2015 so here's the
here's the bad frames I'm standing off I
got four frames here I got a headers
framing a continuation frame on stream
three then I have another headers frame
that's a big no-no and then a
continuation frame with an end headers
flag set and then I'm going to send them
all over my client and then I'm going to
serve all these things like did zero
frames come back over stream three hope
so did one frame come back over his
stream zero was it a go away frame and
did that go away frame have a protocol
error inside well to actually implement
this I need to create a continuation
state right the whole connection
translate transitions into this thing
where once we get a headers frame we go
into this place where we only take
connection frames so that look like
looks like this is the continuation stay
from HTTP to connection and all it does
it say did the frame coming in we read
in the frame is it a continuation frame
yes is the stream ID in that frame match
the stream ID that's in our connection
state yes then route the frame if it's
not go away protocol error we don't
serve you if we take out that bad frame
then we can change the test I have both
tests in the code you can click here I
think on this this is a link then you go
see the source of it yeah and um I check
for stream three now and I make sure it
did actually respond and I check stream
0 and make sure I didn't get any bad
frames over it didn't tell me to go away
because everything's great so we wait
like five minutes and everything times
out but that's fine that's okay it's a
connection it's supposed to do so I know
I hope you're getting into HTTP to like
I am because it's common it's common hc1
isn't going anywhere but it's coming so
thanks a lot there's a lot more
references in this deck and you can
check them out later</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>