<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Gregory Young - Querying Events | Coder Coacher - Coaching Coders</title><meta content="Gregory Young - Querying Events - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Gregory Young - Querying Events</b></h2><h5 class="post__date">2014-01-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BWOaUT9T-jA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so what we're actually talking
about today is at some levels complex
event processing we've actually
implemented a complex event processing
language for querying events trees
what's different with the one that we've
done is it's not just about them now
it's also about historically so when I
talk about how you can actually
structure your system so that you can do
historical CDP as well as current CV now
in general I find when you start
bringing them together ideas one of two
things is going to happen either you end
up happily pollinating both sides
better
it argues on
either you're going that now it's ugly
what so either what's going to end up
happening is you're going to end up with
a happy pollination happening between
things or the alternative that you can
end up with doesn't always turn out so
well and it may even come killed
semester but there's a lot of academic
back in when you start talking about
complex event processing
if you guys don't know this this has
become very popular lately it's known as
reactive extensions you can look at this
in JavaScript net Java they've been
bringing across almost all platforms
well there's when use reactive it's
about now and it's not the only way of
actually dealing with complex event
processing it took me a long time to
find this slide complex event processing
it's very very useful in a certain
category of problems and that's actually
a set of problems you start finding in
almost every system on the planet
they're problems that have to do with
time how many of you have problems
dealing with time in your system some
examples I might be looking for
real-time information and I'm looking
for situations where this happens then
this happens then this happens it's also
known as a temporal correlation query
there are systems out there that allow
you to do this for instance we did look
at stream databases and they've made
this sequel like language for me this
doesn't actually work very well because
what I'm dealing with is not necessarily
sets I'm dealing with facts that are
coming in over a period of time and it's
not really a good way of expressing this
to give you guys a kind of an idea of
the kinds of problems that we're talking
here we built our system with specific
problem in mind and I want you to keep a
sequel like language in your head when
we go through the problem so I as a
cliff as a doctor I'm trying to do a
clinical trial I'm looking for people
that were diagnosed with pancreatic
cancer within the last year they were
then given this treatment and they're
given it less than three times with a
dose based upon this mixture given their
body weight within having it three times
they failed with a lab result that said
their white blood cell count had gone
down by more than 20% which means you
actually need two lab results look at
that then within one month they were
given treatment T tooth they're given
this less than five times and then they
failed with this kind of lab result
because these are the people that are
eligible for my clinical trial now all
you have to do is run this across the
entire United Kingdom how would you
implement this in sequel select star
from where in select star from where and
select star from where and select star
from and you work in a five and at some
point five years from now you'll get
results when we start talking about
these kinds of queries languages and
they're set based up they don't actually
do very well at them and in general I
don't like this language because what
we're actually really looking for is
something more along the lines of our X
I want to deal with this in a functional
reactive style not necessarily through
something that looks like sequel so what
we've built is a functional reactive
query language over the top of events
trees now I've been talking about event
sourcing and how many of you have heard
of event sourcing before okay actually
quite a few if you haven't heard about
it before we'll go through it briefly
it's essentially a form of functional
data I'm going to store functional data
for my system and I've been talking
about this stuff for a long long long
time I
it's actually starting to get recognized
by people which is actually pretty cool
so in event sourcing I have my cart
created three items added one item
removed and then shipping information
this represents my cart instead of
representing a state I represented as a
series of facts that happen at points in
time now here we have our three items
added that's not actually one event
that's three events but if you try to
put all three events the boxes get
really little and nobody can read the
slide I have any point in time replay
those events to get back my cart I need
you can imagine what we're doing here is
we're saving function calls later we
define what those function calls
actually mean so in our storage we have
part created cart created has some
parameters associated with it
conceptually you always replay or log
from the beginning to the end again I
can replay these events to get back my
current state and this allows me to say
my storage I'm just storing events this
leads us back to the question of time
and how do we do these kinds of temporal
correlations if I'm storing this I can
actually go back in time and look at how
things were historically now every time
I actually start talking about events or
say I don't want to stick on it
too long today the main reason people
are doing this is because it doesn't
lose information as a CTO I have one
rule and that was we will not lose
information because I don't know how to
value it how many you have an update or
delete statement in your database today
how'd you decide that data was not
valuable how do you decide that you have
no future use for this information
now when we start talking about the
kinds of queries that we want to do over
these event streams they almost always
come back to let's say that clinical
example so I'm looking for people that
said the word Starbucks then within two
minutes set the word happy and within
three minutes either directions that the
word coffee this is the kind of query
and might want to run against let's say
a Twitter stream there's tons and tons
and tons of situations but our sorry
software systems out there where I can
do this and I can do it from now forward
what are this comes together the VINs
sourcing is I can now do it backwards as
well
I can run backwards the same kinds of
queries that I would do here moving
forwards with most complex event
processing systems this allows me to
have time machine I think back in time
with new ideas how many have been asked
for a report before brant a new report
looking at data in new and interesting
ways if I have an event source system I
can not only give you that report right
now I can tell you what that report
would have looked like on August 17th
2011 if we had come up with the idea of
that report back then all you have to do
is only play forward to that point in
the event stream event sourcing is an
append-only immutable model and the
query language we're going to be going
through today actually it's already
implemented it's about to come out of
beta so it's in the events store which
is a domain-specific database for
dealing with this kind of storage the
language itself is implemented in
JavaScript I know that sounds a lot
we'll talk more about why we did it that
way but the database as a whole
it's an append-only immutable model and
by the way it's all three clause bsd
open source so if you actually want to
go take a look at the source for all
this and how it actually
you can set the event store is a new
category of no sequel databases there's
only one other I know of that would
consider in the same category and that I
need to Tomic the ideas you're storing
events you can replay back over your
events and you can do historical queries
you can do complex event processing but
in a historical way so let's start ad
space an event is a function for any
event you can define this function as f
of state and you pass in an event and it
will return you state if I look at what
an event is actually in the storage
let's imagine JSON it has a name it has
some properties what is a function in
your code
it has a name and some properties when I
go to process it I'm always going to
pass in a state and the event and it
will return me the new state when people
start talking about event sourcing
snapshotting what they're actually
talking about is of memoization of a
chain of these functions and it's very
funny for me when I talk to
non-functional people and you have to
explain events sourcing them in this
really weird way whereas if you talk to
functional programmers you can start
saying well all current state is a left
fold of your past and snapshots are a
memorization of that and they go oh ok I
get it
if you talk to object-oriented
developers you end up in a 45 minute
discussion so we have our function
definition and what I will do is I watch
you try to map one of those functions to
each event as it comes through if for
instance we were to look at this we have
our cart created three items add and
what I am remove shipping information
edit what we're going to see is we have
created
created gets past null in this case why
because there's nothing older than
created that I have item added which
gets passed a return value of create
item and it gets passed the return value
of item and it and I didn't remove get
passed the return value of I meant by
the way it's anyone seen this pattern in
the floor and code there's also a high
order function that can do this it's
called a left fold I don't expect you to
actually write it like this every time
unless your enclosure in which case it
might actually look normal but we can
represent any event stream as a left
fold like this this is actually the root
of the query language the query language
is all about generalizing this idea we
can generalize what we first saw instead
passing no I might want to pass some
initial state to that function that
would be useful well if we're in
JavaScript I mean how annoying would
have to be to actually check everything
for null at every point along the way
during your folder so maybe I want to
pass an initialized object that at least
has this stuff at the fault values aside
from that we got our functions coming
through here and eventually we're gonna
have a method all the way out called
filter I'm either gonna want to filter
or transform the result of the whole
fold in order to give you your final
result an example of this could be I
want to do the fold but if it's less
than 4 then I don't care about so return
null because it's not really a result
going back you'll notice we have F f1 f2
the most important part of the query
language is how do we map a farm event
back to a function and the way we do
this is pattern match which everyone
should probably be familiar with you so
we do when then we have each event type
listed and map an event type to a
function again every function takes
state an event and returns state this is
what's going to come together that's how
we configure the fold there's some
special ones for instance we have dollar
sign any which is a function I want to
map to any event in the system dollar
sign in it is the init function that we
mentioned before from our generalization
everything that we're doing comes back
to that one specific generalization now
we have our fold
we need some way of bringing events to
our fold and for this we use what's
known selectors the simplest selector
would be I want to do from the stream s
in the event store we have a concept of
streams it's a partition of the overall
events so for instance let's say you
were bank you would have one stream per
account accounts are separated from each
other I don't need to look at the entire
Bank all together
I can partition them into streams and we
actually expect in most systems that you
will have millions and millions of
streams stream roughly equates to
document what you would put into a
document in a document database with us
you put into a string except beings it's
so state you would put the events that
represent that document so from stream
select all of the events in one stream
and bring it to your folder from streams
s1 s2 what this will do is it will take
all of the events in street
one versus X s one and s two and it will
join them together and it will produce a
stream that is all the events from both
streams overlaid based on their ordering
now when we say that we will give you
perfect ordering on that will
historically give you a perfect order if
you are running in a distributed system
with this it is entirely possible that
you will not get perfect order
why because s 1 and s 2 are different
machines when you start running in real
time and we lost network connection to
one of them so what you can do is you
can introduce a delay in this case and
we're willing to wait up to the delay
period to try to reorder for you and if
we get out of order will detect it in
the future and let you know that we went
out of order another one and this is
actually why we had to build a custom
transactional engine from all where you
can go over all of your events within
your replica set and you can do them all
in perfect order all right talk more up
from all it's actually a really really
useful selector other examples you can
do you might want to do a window so I'm
only interested in looking at things are
a year old or I'm only looking at
looking at things within this month you
can actually window in a sizes collector
in order to limit what's coming from
these other ones but these are all
really really basic selectors and we can
start getting into more interesting ones
all of those were returning to us a
stream a single stream but a single
stream isn't necessarily useful if I
were in a bank how useful would it be
for me to do from stream account 1 to
sum up the balance and then I can do
from stream account 2 from the stream
account 3 from stream account for and I
would basically want to do it for every
account in the system in order to sum up
their balances so what you can do is
you've got some other selectors and
they return you is a stream of stream
links so it's basically a stream of
pointers to other streams and examples
of this might be from category and you
can assign a stream to a category and
this will select all the streams within
that category you can also do streams
matching and pass a function your
function will get called on all streams
in the system and for instance you put
metadata onto the stream and then this
thing looks at the metadata to select
whether or not you actually want the
stream and this is where things start
getting fun because when you have a
stream of stream links you can say dot
for each stream now I don't know if you
guys can see is here at the bottom we
probably should have called this map
however we deal a lot with
object-oriented developers and they
wouldn't understand what that means when
I have a from category so I selected all
accounts in the system I can then say
for each stream and this will run in
parallel all of those folds across all
of the streams in the system that happen
to be of type account where this gets to
be really useful so if we were to look
at a normal fold operation most fold
operations need to be run sequentially
what this is saying is I don't have one
fold operation I actually have one full
operation per count in my system this
state that gets passed through the fold
is distinct per account now we have
another way that you can select states
that your fold gets and its state
partition by it takes a function so you
can basically say which state you want
to get right now in the folder but that
needs to be run when chily why cuz I
have no idea what you're gonna tell me
in the future when you do this you're
telling me your query can be run in
parallel and we're gonna talk more about
this but you can imagine
you now have n threads running one fold
per thread concurrently what I haven't
mentioned is that we're also distributed
we for instance offer high availability
clusters so let's say you have five
nodes in your high availability cluster
well I can have five no one's working on
these queries at the same time and the
reason we call high availability is if
you start unplugging nodes your query
will continue running it will
automatically get shifted from node to
node along the way this is a really key
idea inside of the query language and
one of the nicest things about this when
they compared this to most complex event
processing systems it's almost every
complex event processing the system on
the planet you take your events and you
bring them to the processor yes so I
have events happening I bring my
processor up in memory let's say an
airline and I take the events and I move
them to the processor and process them
on the fly what we're talking about here
is the opposite of this we're talking
about taking the processor and moving it
to the events and why do we need to do
this well imagine if your story events
for the last five years and now you went
to a historical CEP query do you want to
have to move 28 million events to your
processor or do you want to take the 1k
of your processor and move it to where
they live and that's exactly what this
is allowing us to do at the same time
it's a lot it's saying that this is this
can be done in parallel and basically
you can do a map on this now any time
that you do a query the result of your
query is a stream so I want to do a from
category account and go get all the
balances in the entire system my result
is going to come back as a stream of
results now we've only been talking
about querying historically so far one
of the beautiful things about this model
is it actually works in two ways if I'm
running historically it's coming forward
through my mÃ¼nster
when it gets to the end it can continue
going back to the clinical data example
I is a doctor run this query my output
in my query as a stream so it gives me
my results and then it keeps running in
the future we happen to expose this
stream as it happened feet so you could
take feedly and point feedly at the
result of your query and every morning
you might start getting new results to
your query coming through it's the
equivalent in sequel of adding a new
keyword I can do select count star
common name from table at 5 it's going
to give me back the results imagine
having a new keyword called continue or
now I run that query and then he goes
and inserts data my results start
updating inside my query window this
model allows you to do continuous query
and I can't stress enough that the major
difference between what we're talking
about whether we talked about reactive
or any of these CP type systems is the
concept of moving your code to your data
as opposed from your data to the code
and it's a huge huge difference now
there's a couple other things inside of
this query language one of them is known
as Amit Amit allows you to emit an event
to another stream there's some limits on
a mint for instance you can only have
one projection emitting to a given
stream and people always go well why is
that I don't want that the reason that
we do it that way is you can actually
reset a projection and then sitive
emitted previously will disappear and it
will rerun and regenerate all of the
events am it allows you to do any form
of CP so I can start listening to things
and when I come up with a circumstance I
can emit an event to another stream as
an example I'd be trying to detect some
as opposed to returning my state back I
can just start admitting events to other
streams to let people know about this
examples where you might want to use
this credit card fraud detection I'm
watching the streams of credit card
transactions come in I think I found
fraud so I am Nick to a possible fraud
found stream and there's some system
that listens to this to go turn off
credit cards there are a huge number of
ways you can possibly use submit and
wait way to specify is just the stream
you want to emit to and some JSON which
happens to represent the event you want
to emit because you're emitting to
another stream yes it is possible that
you can write a projection on top of the
the emit some another projection you can
also run a projection on top of the
results of another projection because
the results go to a stream themselves so
you can start nesting all this stuff
that we're looking at as well and then
there's link to link to is a special
form of emit and there's another one
here which we've added which is um it's
a emit a stream link so you can actually
do from stream of streams which is one
we didn't actually put up their link to
writes a pointer to an event out to
another stream now sometimes when you're
working with things you come up with a
really really simple solution to
something and you realized that it's
immensely powerful and then you know you
got it right link to is a dead simple
concept it allows you to emit a pointer
into a stream that points to an event in
another stream and this is how indexing
works inside of the database there's
only one index in the entire database
but using link to you can build up all
your own indexes inside of the database
to really see the power of it we need to
go through a complete example what it
allows me to do is to say that here is a
pointer to that event now if you try to
read this stream it will resolve the
pointer
to the other event if you're running
distributed you can either say whether I
want to pointer and whether I want to
copy so if it happens to be on two
different nodes they can actually do a
copy between them as well if for
instance you want to fry provide
physical locality for your data when you
read from this stream you're actually
pointing out to all these other streams
and it's hatin for me this is very much
a simple redirection where this comes
into play so let's imagine I have some
streams in this particular case we're
going to have some chat and what you
have is one stream per chatroom so here
we have Joe as talking John was talking
Dan was talking than John was talking
here at FC sharp chat we have Paul said
something that John said something that
dance it's something that dance it's
something here Paul said something that
Paul's it's something that Joe said
something in Joseph's something only one
problem you are given the query from
your business user of I want to see who
said the word Starbucks within two
minutes of saying the word happy within
two minutes of saying the word coffee
and I don't care what chapter they were
in I care about that as a person so now
you have two options here what you would
normally do is you come through and
you're right serial projection one that
does from all state partition by user
but when I do that I can only run at one
on one thread it has to be run
sequentially what this allows us to do
with the link two is to reindex these
streams so then I can come back through
into a parallel projection against them
where it can be distributed across many
notes as opposed to being to be run
sequentially so what we can do with the
link 2 we could do from all state
partition by and a function return an e
dot David a user when and now we do our
dollar sign any map our function and we
emit a link to the user with the event
this
we creates for me a link where it points
back this projection must run serial but
now any future projections I want to be
able to run against users I can now do
them in parallel basically this is
reindex in my data so now I can do
parallel queries again let's take a look
at what it actually looks like and I
know this isn't very nice-looking so now
what I end up with once that's run is I
have chat - Dan with pointers - all of
Dan's chats regardless of chapter I have
another stream chat Paul which points
back to all of Paul's chats over here if
you were to do a query from stream chat
- Paul you will get all of Paul's chats
but I haven't copied the events their
pointers back to the original events and
by the way if you actually look at this
and you're dealing with atom feeds from
HTTP level yes they point back to the
same your eyes by the way when does an
event change in a mutable model so what
do you set cache ability in your events
- in fact what do you say cache ability
in your feeds - the exception of head
every URI that comes out is infinitely
cashable which I here is nice for
scaling what this is allowing me to do
is to repartition my streams and do it
at a relatively low cost this is in fact
building an index once I've done this I
can now come back through and I could
say from category chat dot for each
stream and now fold across all of these
independently where each has their own
state and their independent of each
other a lot of the stuff we've been
talking about in terms of complexity
processing there's already systems out
there that do all of this this is the
one thing I don't think I've ever
actually seen in another system this
ability to partition and to map
your partitions for your folds every
index that you have in our system is in
fact another stream if you haven't
realized yet we're kind of stream
centric everything's a stream to us what
you do is you put links in a stream to
other streams and they will be resolved
for you when you actually read from that
stream now to be fair you can actually
tell us not to resolve the links and you
actually want the pointers back this is
a really low-level operation and most
people will probably never use it now
when we start looking at this model it's
important to remember that an event as
well as being a function is a fact that
happened at a point in time it's always
a verb in the past tense your query does
not care whether this fact happened two
years ago or one millisecond together
this is what allows us to do the model
where we query historically flip into
right now and then continue there's all
sorts of interesting uses for this
ability to query back historically in
the same model and then continue forward
one example we've come up with for quite
a few easy for quite a few problems what
about training a neural network
historically and then allowing it to
flip to now and continue forward for
example we could use simulated annealing
throughout history as it comes up and
then let it continue and it will just
keep learning as it goes off into the
future it's the same model for
historical data or for future data it's
allowing us to do complex event
processing historically and then when it
comes to now it flips and goes into
current data again this allows us to
have our time machine to be able to go
back and look at things historically I
can go back and tell you what this
report would have looked like at this
time if we had come up with it even
though you came up with
today had you have come up with it two
years ago this is what it would have
looked like on that day
this is immensely valuable from a
business perspective there's an entire
category of problems that this works
really well for how do you have been
asked to make a prediction about
something before and then you say but
how good is your predictive capability
well you have a new way of making a
prediction why don't you tell me what it
would have said about today one week ago
only feed it one week it goes
information and tell me about today
there's also known as now if they'd a
walk where alphas pretty beta and you
can do this basically betas along his
future and tie an alphas predicting beta
you run them through the entire stream
it's a great way of doing machine lane
then one question we get asked a lot why
on earth would you use JavaScript for
this why didn't you use closure well we
could use closure except I don't have
enough parentheses on the keyboard now
we use JavaScript for a couple reasons
I can tell you right now we are not the
fastest system out on the planet
nor do we intend to be how many of you
know how to program in JavaScript how
many have seen the what video there are
there are some problems with JavaScript
and it can be interesting but to be fair
it's standardized now the standardized
crap but it's standardized and everybody
knows it I can go to reasonably low end
developers and teach them how do complex
event processing inside JavaScript and
they can be productive within a day I
probably would not be able to do that
with closure all the pleasure would be
better choice overall on top of that and
this is one of the big things that I
really liked about reuse in JavaScript
so let's say I've got my five notes out
and I run a distributed query it's going
in parallel on 40 cores now cool and
something breaks
what will happen is the projection will
enter into a faulted State you can then
come in with Chrome and click debug so
it's somewhere in the cluster it entered
into a broken State
what do I need to bring back into Chrome
to allow you to step through it as it
was working in the cluster since
everything's a function that takes state
an event and returns state I would need
to bring the state and the event back
into chrome chrome runs v8 we host v8
likely they should have similar results
then I called debugger and now you're
stepping through your projection inside
of chrome as it was running when it
failed on node 3 inside of the cluster
now we made a lot of trade-offs where to
get this v8 is not the fastest language
when I start under the fastest runtime
when it starts coming to things like
memory allocations if I want to make
things
idiomatic for you I need to give you
your events as JavaScript objects
creating a hundred and fifty thousand
JavaScript objects per second it's
paying that the minute you're gonna
start hitting at the same time you've
made a lot of other trade-offs inside of
the model for instance I make your data
durable before I actually give it to
your query it's guaranteed to be durable
if you refer instance going to be taking
the logs of a data center and trying to
run CP across the logs of a data center
it's probably not the right tool to be
using where the sweet spot is is when
you started looking at teams that fall
in the bottom 98% of software if for
instance you're doing high frequency
trading this is probably not the right
tool for you then again
you probably are writing C code that's
dealing living inside of a GPU someplace
it's not going to be the fastest model
there's a lot of trade-offs that have
been made it to keep things easy as
opposed to making them as fast as
possible but it's important to remember
that if you try using it in places where
you know you want some microsecond
latency it's not the right tool in
JavaScript would never have been the
right language it's focused on being
easy not being as fast as possible that
said right now we can handle about
30,000 writes per second and projections
when you do a parallel can do 150,000
events per second per note and this is
assuming just like a normal piece of
commodity hardware and I'm sure if we
got nice servers they would do better
it's not that slow if you were to do
this and you wanted to make it fast
you would do your queries and see and
compile them and maybe I have LLVM
optimize them and you push them out but
it'd be hard one of them in JavaScript
it's very very easy for me to do this
now in general more functional
programmers need to be using event
sourcing and it's funny for me when I
talk to functional programmers and they
go then sourcing what's that well it's
functional programming the data it's a
natural model if you're in a functional
language current state is just a left
fold of your previous behaviour there's
a lot of advantages towards keeping it
that way especially if you're coming
from a functional language as an example
what happens if you change how you want
to look at your state does that change
your storage no because state is a
transient concept at that point which
changes more often how you want to
represent the state of what your system
is looking at
or the facts of what your system is
doing your use cases and we say event
event maps back to a use case it's very
common that I would want to refactor how
I want to look at my facts it's a lot
less common I change what my facts are
so you end up with a more stable cook
base because you're not constantly
having to deal with deployments with
sequel upgrade scripts and there's an
entire book that you will never have to
read it's called database refactoring
patterns it also makes it quite easy to
run two versions of software
side-by-side because you're not changing
your backing story since my current
state is in memory both of them can be
looking at it and coming up with two
different perceptions off the same event
stream if you're going through and
storing only your events in this way all
of these kinds of queries become
possible for you everything we've been
looking at now what we're not quite sure
of is whether we've created a
Frankenstein or whether we've been going
around dealing with a nice pollination
between different ideas we're taking a
lot of stuff from the no sequel space
and mixing it with a lot of stuff from
complex event processing overall I think
that the ideas are at least interesting
now there are certain situations where
they become very very valuable if you
guys want to talk after it I can give
you examples of where we've come in
taking a hundred thousand lines of code
and turn it into six hundred lines of
JavaScript why because the rest of that
code was building all the messaging gunk
and high-availability gunk around this
little tiny piece of business logic
instead you just put it into JavaScript
and you're done within a day along with
that you can be much more agile changing
that little bit of JavaScript and you
could be changing all the messaging duck
all of the high-availability stuff is
already built in and it is the point now
where you can just come in you can
unplug a node and your query will
automatically move to another node in
the cluster just continue running it
will be transplanted to you and I want
to be very clear about this and this is
not at least once messaging so it's not
like when that happens you will get the
another 25 results duplicated out of
your query it will actually move
transparently and you will not actually
see any duplicated messages anything
along those lines
that's all happen it's all going to
happen automatically for you if people
want to chat we can also talk about
forums and how the distributed system
actually works later again I'm hoping
that what we're doing here is
pollinating between two different
communities the no sequel community of a
complex event processing community when
we talk about the very language we're
looking at we need to understand the
complex event processing is not just
about now it can also be used in the
past and the advantage using it in the
past is when I go to use it in the past
I can basically have a time machine and
travel backwards and forwards through
time I am tell you this is a wonderful
new idea you came up with if you had had
it last year at this date and this time
this is what your idea would have told
you from a business perspective this is
really really valuable thing to be able
to get now there's lots of other
benefits you can get from event sourcing
I probably have about 10 videos online
talking about event sourcing um I
obviously don't have enough to go
through all the benefits today um if
you're interested in if you just google
my name you'll I should there on info
queue and I think this is actually
recorded on foq so just go to info cute
yeah with that I will see if anybody has
any questions
apparently this is not a good place for
microphones
thank you so suppose if you if you're
staying it up in some weird
while in some vehicle state and by
looking through the history of you
pendants you figured out okay this is
the event that caused a problem mmm scan
you then because it's a append only
store can you then insert event a
specific moment in time that has the
reverse effect to so I'm just going to
rephrase the question so I have a
mistake in my event log and basically
now what I want to be able to do is I
want to fix what that mistake was yep so
there's a lot of different patterns for
this and they mostly come back to
accounting so if I look an accountant an
accountant never races in the middle of
their journal instead what they're going
to do is they're going to add a new
entry to their journal and the new
entries going to undo the old injury if
I do that I now end up with two queries
so I'm going to have an ass of verson as
a query I need to be able to do both
those queries because I need to know if
I had actually looked and made a
decision at this point in time it hadn't
been corrected yet so that has at this
point versus as of this point and one of
those queries I only go forward in the
event stream to that point time the
other one I go forward to that point in
time and then they go all the way to the
end of the event stream to see if
there's any retroactive things happening
that's one way of doing it another way
of dealing with it and let's say that
you completely just totally screwed up
what you can do is you can read up the
stream change it in memory right back
down to a new stream with the
corrections in it and normally if you do
this you write the first event saying by
the way it came from this stream and it
was our migration process and then what
you can do is if you want you can delete
the original stream I only do that if
you've come
Wheatly totally screwed something up and
that's so bad you don't actually want to
ever even know that information and I
get this with teams all the time when
they said well what if he had a bug and
we were at some bad evincing well the
fact he'd had a bug is a fact and it's a
perfectly valid query for me to want to
know how badly did your bug actually
affect the system and this is one query
I can actually do when you start going
then another query I might want to ask
how long does it take my team to realize
they have a bug it's like when they're
fixing it how long is this period of
time in between there and this is
actually a really interesting query
related to these kinds of systems it's a
good metric that you start watching for
a team is how long and how much data is
getting corrupted or on the way because
of bugs before they actually get fixed
so it made sense thank you
hi I won't say anything about Clara but
it's not scheme so that much parent
disease but yeah I agree with you
javascript is great for that
that's really nice composition but the
link to example is this a persistent
view of stream so the chat tend stream
is moving forward when when the I teach
at stream they kick in my event or I
don't know so what happens is when you
write that indexing projection you have
your choice you can say I want this
indexing projection to index all of my
history and stop or I can make any
continuous query and that way you
continuously index into the future and
what will happen is your indexes will
run just like any other projection and
they will run asynchronously so when the
first thing runs then it will get picked
up and it would write let's say I want
to have now a new event get written
let's say for John then this would get
written
it'll get picked up by the indexing
projection then written to the John
string now if I have projection then
running off of these chats let's say it
for each one it would then see this with
a pointer back to there and it would run
into the next projection so you can
easily compose these along the way as
well does that make sense
that makes sense and then a mutable as
well so so really that's between yes
it's just a regular stream in fact the
pointer that we write is just an event
it's just a special event that we
understand to be a pointer thank you
these stream links are also just events
to be right in to ourselves that we
understand internally we try to make
them short so like prints at the pointer
is actually just like greater than with
a point where it actually points to
where that unique identifier
so if I've just looked at my account
balance and then I put some money into
it I just went and read the account
balance from the beginning and I added
all the events then I put another event
in presumably I'm not going to go back
and read the whole stream again and how
do I control that so we didn't talk
about it this is more of an event
sourcing concept very often I'll
memorize the results of the fold at
various points in time so I don't
actually need to go all the way back and
print if I have a memoization at version
97 so at event 97 and I now want to get
to version 103 I can take 97 don't need
to replay the 97 events before it and
can continue from that point forward
memorization is storage you can't store
it on one thing that we actually do will
be recommend to people is you can
actually take your memoization and just
put them in the streams as well and it's
just a memorization at this point in
time so let's say a stream called foo
and then I had a projection state - my
projection foo so now if I want to get
foo at version whatever I can read here
to get the last memoization out of it
apply it to hear and read forward from
that point in time only that make sense
it does in the event sourcing world we
call the snapshots because they don't
understand memoization
get some more about health industry -
the system works you mentioned you've
got the ability to put stuff in the
right order sort of retrospective lis
how does that work do you use time
stamps then assume the clocks
synchronized or I mean you mentioned the
quorum okay so we need to outline what
kind of distribution we're talking about
because there's multiple kinds of
distribution available are we talking
about single replicas set multiple
replicas or are we talking about
multiple replicas sets sharded so in the
first one it's absolutely no problem to
deal with ordering because a single
replica set the end of day comes down to
a single transaction log so I only need
to look at the position in the
transaction log relative to any other
transaction when we start talking
distributed is where things start to get
more interesting so on the historic
query this is not too big of a deal to
actually deal with on a continuous
queries where you start running into the
problems because for instance a I did
from streams stream one stream to the
big problem you run into is stream ones
on that server stream twos on that
server now they're both going to be
pushing things to me or in the case of
having a for each query its main
happiness it's going to be running on
both of them at some point I may get a
network partition between me and him
all I can do at this point is set
timeout now I will get that event at
some point in the future and I cannot
guarantee you pure determinism at this
point but what I can to do is I can
detect if I made a mistake so at some
point in the future he's going to give
me this event and I'm going to know that
I processed his event already even
though I'm supposed to process his first
now going historically in time I can
give you perfect order
but in real time I can't necessarily
give you perfect order
I can never detect once I've fallen I'm
sorry fit I can give the projection at
that point its choice about how it wants
to handle that situation doesn't want to
get replayed so if you want to drop your
state and go back and we'll start over
if you want to continue happily do you
want to write a log message I can let
you know about that other than that it's
not that difficult of a problem and I
believe we're supposed to move out of
here now I think we're actually over
time in terms of the HJ stuff in forums
if you want on crack me afterwards and
we can talk a bit about how that works</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>