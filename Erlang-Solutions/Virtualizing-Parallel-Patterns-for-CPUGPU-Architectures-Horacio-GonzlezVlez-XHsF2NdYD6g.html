<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Virtualizing Parallel Patterns for CPU/GPU: Architectures Horacio González-Vélez | Coder Coacher - Coaching Coders</title><meta content="Virtualizing Parallel Patterns for CPU/GPU: Architectures Horacio González-Vélez - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Virtualizing Parallel Patterns for CPU/GPU: Architectures Horacio González-Vélez</b></h2><h5 class="post__date">2012-06-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/XHsF2NdYD6g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good nearly good afternoon it's I know
it's a bit difficult to be between you
and launch so bear with me a second so
the idea of this I'm going to be talking
about how to produce a number of
programs that take advantage of patterns
and by using basically the new a
architectures okay so the idea of this
talk is to provide a bit of background
on the whole horizon of multi colors
what the programmers have been doing on
patterns and also on what a pattern is
what the skeleton is and then talk about
the project itself paraphrase so a bit
of background unless you have been away
in a desert island for the past five
years if you have attended any
conference on programming on computing
the first thing they will show you and
that's why I didn't want to be behind
its multi-core and everyone says it's
difficult we have we have been
increasing the different architectures
and we are changing the way we are doing
things and the reason it's it is really
complicated it's changing the way we
have been doing parallel computing for
the past number of years I've been doing
this hpc for longer that I want to admit
but certainly for the past 20 years
we've been trying to do that and the
reason it's the REE second hearing
challenge in doing that this is there
are two coats one from an Intel a
engineer and war he says that people
should be talking about tens hundreds
and thousands of course now so if you
are actually developing today you should
be thinking about hundreds of course and
possibly
thousands of course I mean any device or
computer that you get today it's
multi-core that's a fact of life even
I've got an 11 year old she always
challenged me to say but that's
multi-core right and I said I really
don't know it's just a mobile phone
right this but it has to be multi-core
otherwise is not cool anymore so it's
teenagers it's not someone who is been
there so children today are actually
being born to multi-core computers
devices and pretty much when we talk
about this is computers and things that
need to be thought and programming that
way and the important part is of course
in an erlang event is that we are
talking about mission-critical
applications that they want to run in
hundreds of course so today if you go
and try to cash a check or make a
deposit chances are that the back end
and then pardon my french he's going to
run in COBOL whether we wanted to run in
Erlang a weekend it's a different part
your mobile phone is going to be in a
switch which chances are it's going to
have nice Ireland solutions and that but
your check when you go to the bank and
when you do the next transaction it's
going to be running in COBOL I'm
probably in the mainframe okay with MPs
so the next wave of mission-critical
applications need to be taken into
account multi-course because nowadays
that the biggest challenge for real
developers okay so what can we do the
real issue here is when we talk about
multicores people thought it was
something that it was already addressed
and the reason being is in the late 80s
and in the early night is most of
of parallel programmers we're dealing
with machines that had multiple
processors so if you have a processor
with multiple cores it was simple to
assume that it was like multiple
computers with a single processor but
guess what it's not the same the base
analogy I can think of was given to me
by a friend of mine checking cam at Sun
Microsystems and he said you can think
of having two people having to
individuals or having twins joined by
the brain so when you have multi-core
computers they do share resources that
are not able to be partitioned okay so
if you have four course but they happen
to share parts of the cache parts of the
memory access it's like having twins
joined by the brain you cannot take it
in my way so talking about programming
in multi colors you can model probably
with two even with eight course but
nowadays if you go to frys here in the
bay area you can get a server sarin
liquidate course in any computer fairly
decent will have processors with up to
eight cores certainly the new ones from
AMD the alterans have 12 course if you
are into high performance computing this
x6 has 24 course okay AMD's so trying to
do that it's going to be really
difficult say qualify sequential work
modified sequential code may work but
the reality is that most people are what
I do in our just putting multi
programs and take advantage of
concurrency but larger systems are more
challenging so we think that if we
change the way we conceive applications
that's going to change and the idea is
we call it to think in parallel for them
we are not the only ones there are many
people doing this but the idea is to
have high-level parallel constructs and
talking to an audience of Ireland
programmers and developers this is great
because you guys are people who have
been doing this for a number of years
you know that there is an important part
in deploying applications that can
decouple the computation from the
coordination because if you talk to
traditional or typical parallel
programmers the idea is that you have
people who are application programmers
but also systems programmers they have
to know about the application but also
about the architecture they are
deploying on and there is no option in
having to abstract that it's almost
impossible to scale only the problem is
simple and even more it's very difficult
to change the fundamentals of the
parallel application typically
scheduling does a structure and
migration things that you take for
granted when you are talking about Erlin
but even more you talk about libraries
but not abstractions and clearly just to
make it even darker you will see within
the next five years but it's called
highly heterogeneous or daar silicon
processors if you buy again a $300
computer from frys today if it's got one
of the top Intel processors the actual
processor works
the course the dual core they work at
2.8 gigahertz and there is a turbo mode
at 3.3 which is only switch on when you
are using both cores at the top of
performance ut oh that's very green and
Europe everyone feels great and we're
saving the planet but there is even that
more important part if they work both at
the top of this pit your computer
switches off itself in about half an
hour because you can fry eggs on that
processor okay and that's going to
happen I mean there will be processors
in the future that they call it dar
silicon they will have many functional
units but it will be impossible to turn
them on at once the reason being the
processor itself will need to dissipate
so much heat that it cannot be done and
you will have things like CPUs which
that's a way we all think but now we
have GPUs okay your graphics cards are
now being used with hundreds of course
to compute really tough problems
floating-point problems but guess what
again people thought that is it's again
CPUs try that if you have tried GPU
programming there is actually a trend on
trying airline with GPUs and believe me
just transferring from the memory in the
CPU to the GPU takes a little take some
time then you have AP use a in fact a
couple of processor manufacturers namely
arm has developed this apu which is a
cpu with a GPU on the same soft course
FPGAs you name it so you have hundreds
of lightweight scalar refugee units and
tens of specialized units so everything
seems to be in terms of the hard work
boring
terms of the actual programming you will
have to have a way of programming even
within the chip so in the best case it's
going to be something like Numa don't
non-uniform memory access it's
impossible that you have different parts
of the processor and still assume that
they will communicate seamlessly it's
not not gonna happen you may even have
message passing on a chip so for
programming you will have heterogeneous
systems in an integrated way that's what
we want to have it's going to be
impossible basically to program each
kind of core differently today you have
to think if it's a cpu a GPU and apu how
you transfer from memory back and paul
there isn't a single way of actually
programming both without having to
consider the architectures and another
thing that it's very important it that
it's impossible to make pure static
decisions today you said I have compiled
my program it's been optimized and I can
run it when you talk about these sort of
processors and these sort of
architectures with multiple cores and
units there is going to have some kind
of dynamic assumptions so with all this
in mind what we are going to be looking
at is a pattern based approaches so the
idea is instead of using the traditional
coordination approaches read Linda here
or parallel stream based approaches
typical DSPs or yet devising and know
another programming language parallel
Haskell parallel Fortran policy remember
when I was doing my PhD at some point
after being in industry for a while I
thought let's try to find out how many
parallel programming languages are there
I think I stopped the count at a hundred
was a very interesting example of how
many you can do so getting more into
this it's we try to work on parallel
patterns and skeletons the idea it's a
pattern you probably are familiar with
the concept it's basically a name prosze
the problem can be solved plus an
implementation strategy there is a very
famous book the Gang of Four it's it's
there it's one of the best sellers in in
parallel programming in general in
structured programming and basically a
pattern in general is used for design a
parallel pattern by extension is that
it's used for design and the typical
examples of a parallel patterns is to
represent embarrassingly parallel
computations a stage computations and I
a complement to that is a skeleton an
algorithmic skeleton it's a programming
construct to implement a particular
pattern so in that respect the
algorithmic skeleton plus the design
features makes a pattern and the
examples to that is a farm which can be
used to implement parallel computations
embarrassing parallel computation a
pipeline which is used for a state line
a bit more on on the skeletons the
skeletons are higher order functions
basically they will conceive in the late
80s by mariko there is a book from MIT
press the references at the bottom and
the idea is this skeletons abstract and
implement patterns of parallel
computation communication and
interactions if you have seen non
skeletal base parallel programs the real
issue is that you have primitives of the
actual computation and then within the
same program you have primitive simple
and communication so the idea it by
using skeletons you decouple that you
just the application programmer is just
concerned about computation but it's
also known as the behavior what it's
trying to do and they underneath a
algorithmic skeleton framework does all
the structure typical examples of this
is data parallel you may be familiar
with a scan Map Reduce if you put of
course map and reduce together you will
have the maverick the famous MapReduce
part but certainly all of these for some
of you who have been a working with
other languages can be extended from
lisp soul is in a way uses all of those
skeletons or skeletal operations on
lists in terms of task parallel there
are a number of farm pipeline reviews
and others so they work on tasks at a
higher level and you have skeletons for
resolutions of problems divide and
conquer branch and bound dynamic
programming heuristic optimizations but
of course a talking about farms to
airline programmers is like trying to
teach my grandmother to suck eggs you do
that for a living I mean here you have
supervisors and workers and that's the
way you consume things there is no other
way I mean it's if you actually talk to
other people is is there a way to
actually do a supervisor work but here
it's that the only way you actually
conceived applications tab that part so
what am I trying to extend so the idea
it's not to reinvent the wheel and
that's why I'm going to explain more
about the project that's why in this pro
object we requested from the European
Commission 3.5 million euros to actually
work on something that has an impact and
one of our partners in that project is
Ireland solutions so it's actually
getting something not only conceived by
academics in an ivory tower but also to
have a real industrial impact and that's
what the idea is that we are want to do
it of course this is not airline this is
kaskell and I apologize for that but
it's this is the algorithmic skeletons
you have parallel maps or probably cheap
waves or reduce that sort of idea of
getting the skeletons and getting as
that resolution patterns to do on orbit
calculation or duplicate elimination
chain reductions partition backtracking
so a number of problems that can already
be solved but that you don't have to
specify how to solve it just describe
the problem so that leaves me exactly to
the project while I am talking here so
we went last year it to the European
Commission we put together a proposal
for a three-year research project it's
been running since October last year and
we'll be running this program until the
third year of sep tember 2014 it's
funded by the European Commission as I
was saying we have nine partners then
all of them are in Europe yes you Israel
is in Europe for purposes of the
European Commission in fact the company
that it's in Israel is mellanox
solutions mellanox solutions mellanox
has a the headquarters are here in
Silicon Valley about the R&amp;amp;D branch is
in Israel so we have a two universities
from the UK three actually a Queen's
University rgu and San Andres
we have airline solutions a couple of
universities in italy pizza and Torino
austria we have a network of companies
in Germany we have one of the biggest
super computer centers in Europe h l RS
the supercomputing center in Stuttgart
and clearly as I was saying we have
early solutions what it's what's the
idea of what we're going to be doing in
the project it's conceiving an
application here from design get it
parallel and once you have these
paralyzed applications getting
dynamically mapped into CPUs or GPUs the
idea to do that is to help us to think
in parallel by using patterns so you
cannot use paraphrase without using
patterns you have to use your force as a
programmer to use that it's going to be
an open source program everything that
we generate from here it's going to be
released as open source we're going to
use cause directed refactoring meaning
we will rewrite source to choose the
best pattern so possibly the application
programmers have decided that pipeline
can do but once the pipeline has been
laid down it happens to be a pipeline
boring indeed farming one of the stages
can be mapped in a way that it will
improve performance we will use
spiritualize components and I will try
to elaborate a bit more on that in
hardware and software and we will use to
standardize platform C and C++ an
airlock
no it's a it's a it's a good point 4-h
4-h pc in particular we have a number of
users that they want to use and they
have applications today running
important we have SC CH is running the
weather centers in in austria so they
are they are trying to deploy that
application and what we intend to do it
after all the fortran components can be
extended by using a rapper and by using
just a rapper as part of that you can
actually put it as a see part so it's
generating love or you can just end it
in another part so in particular is not
fortran but we are going to be using c
c++ on ireland and the code can be
internally a Fortran component so again
I use that part to develop so the idea
of what we are going to change is by
using this parallel pattern with a
couple the CPUs from the GPUs and map at
runtime what it actually means it's we
annotate the parallel pattern and we map
and remap the tasks to a virtual
hardware and it was great that Costas
gave a talk before me because that idea
of the llvm using an intermediate code
that can be statically annotated it's
exactly the idea that it's been trying
to exploit here the idea of you have a
single source code but you can have an
intermediate representation and again
apologies because this is a generic one
and I know the Earl and people are
familiar with that parlam with that in
turn intermediate representation but not
every platform
does that clearly Fortran or C or the
others are always used to generate for
that part so for the for the actual
platform so by using this idea of
virtualizing the hardware we can think
of this so we have the pattern the
pattern can be refactored that's why the
different shape change in the actual
pattern but the actual a functionality
is the same you have that implemented
into a software virtualization layer
meaning a number of processes that can
have different interactions and those
interactions are then dynamically map
and remap into a heterogeneous platform
so there are there my big components
that are more suitable for CPUs and
there are components or maybe soup more
suitable for GPUs in again in the
examples from Costas it was clear that
some of his examples the quicksort I
mean without having much to think about
it was for the CPU I mean comparing is
highly scalar so we knew it was from a
CPU without even looking at the code and
clearly Mandelbrot you don't have to be
a genius to know that it's
embarrassingly parallel you can use a
GPU and potentially a pattern that can
use a farm or something similar but that
has to be today map and owned by the
programmer if you were to use patterns
that could be dynamically map
potentially refactor and then down here
and ultimately the idea is to have this
to have a compiler okay which actually
can have a number of objects then a
mapping that mapping have an object
which can be deployed into hardware
platform
you keep monitoring what it's going on I
have some kind of dynamic adaptation and
back to the hardware platform once you
have that part of our adaptation you
keep some performance aggregation and by
using some analysis you go back to the
adaptation so there is a quick decision
the first time and then you keep
improving it as you learn how different
codes behave so it's a whole feedback
loop of course you cannot run markup
models online but you can keep them on
the back of the back end of your
framework and you just keep storing how
good you are doing and the ultimate
objective is of course integrate the
computational problems and they're
parallel patterns to improve their world
resource utilization so going from real
problems discovering the patterns in the
problems transferring that into Cove
which is deployed in different
architectures the long-term impact we we
want to believe that it's going to
change the way people develop it's going
to be accelerated it's going to improve
by using dynamic mapping code to
resources without the functional
properties help to virtualize and
abstract the coordination potentially
improve speed to market think in
parallel think and design in parallel
and use low effort and this is the last
slide you will be happy to know that
because it apparently launch is going to
be served soon and the idea its first of
all why patterns it's because you have a
number of them that have been solid for
a while they can be standard
can be domain-specific they can be
designed for heterogeneity clearly this
is a trend today even the Economist run
and special article saying that it's not
going to be just imperative when it
comes to parallel programming so it was
very interesting to see that actually
the economy's could spell well
functional programming and it was it was
a very important because it actually
changed the way many people thought
about it if you go into and talk to
scientists and people who are using
supercomputers they will say well then
whatever you want to do but as long as
it runs in Fortran right birth in the
90s he was interviewed by the I trevally
computer and they asked him what is the
the language of the future and he
replied in particular for scientific
computing I really don't know how it
will look like but it will be called
Fortran and that's it that's a factor I
mean you have to make sure and I'm
grateful for the question it's in terms
of big computers if you actually have to
to think about how to accommodate a
number of of applications so the idea is
potential to have these target less
programming using new virtualization
mechanisms abstract memory access
communications and the states using
monitoring information we don't know we
think that it's just execution time
memory and power but there can be more
historical versus predicted information
so you take a decision and then you keep
on improving and of course how much is
static and how much a dynamic mapping
you need to take okay so like to thank
you very much for your for your
attention if you want to know more about
this project is in paraphrase hyphen ICT
oh tu we have a small twitter feed going
on there a paraphrase underscore fp7 and
i will be happy to entertain any
questions you may have at this point
thank you yep yep it's a it's a good
point we have through acch the software
competence center gang member we are
getting a number of Representative HPC
applications those representative
applications i mentioned weather
forecasting so they have a number of
weather stations that are going to be
using that's as you pointed out it's for
embedded HPC type we have DSP actually
as well so digital signal processing
they are going to provide another one
they're going to provide another one for
neuroscience in particular for neural
network processing and but in this case
rather than the actual application that
you look first the idea is looking at
common patterns of interaction example
being you have there is a book that it's
called parallel computing works it's
probably 80 years old it's this work by
Mussina palma Cena and it's got probably
20 to 30 different applications that all
share embarrassingly parallel behavior
so the whole idea it's probably not
looking purely at application but that
common patterns for embarrassingly
parallel behavior I can think of mandal
world image processing and I can keep
going on they all have embarrassingly
parallel behavior meaning no matter what
you do they don't share anything they
have different sources of information
and they're right in different parts of
pretty much everyone is happy and you
can schedule anywhere but that you have
to minimize communication there are
numbered that have the pipeline again
you can have a linear algebra
applications or DSPs em so we are not
looking at application specific domains
we're looking at if we can add pattern
specific domains so that multiple
applications that share that and we are
pretty much interested in solving that
in terms of task farms pipelines a data
parallel and stream so that's what we're
looking and you're right in terms of
it's not size fits all but certainly
it's a hopefully a pattern fields oh
yeah actually yes I'm familiar with
OpenGL and certainly we're looking at
opencl as a possible a language for the
deployment of that the coordination in
particular can be done we're using
something called fast flow by using fast
flow to coordinate the skeletons opencl
can be the deployment vehicle but of
course there is always the debate
between opencl or cuda and we are look
if you ask to Nvidia they will say cuda
of course if you talk to Chronos and the
rest they will say opencl we've been
running some benchmarks and mixed
results for stl Cora a good as faster
more difficult opencl it's more
homogeneous and deploy able but there is
a performance trade-off yes so that's
what we are looking at
you have to you have to still a I'm
gonna probably go on exactly you have a
collection I'm going back to this one so
basically you will have similar standard
interface Erlang type of components you
have calls to those components and those
components will buy Joss parameterizing
those components you will have the
advantage of using the patterns exactly
the same there are api's in a library
exactly it's a library it's an API and
it's open source</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>