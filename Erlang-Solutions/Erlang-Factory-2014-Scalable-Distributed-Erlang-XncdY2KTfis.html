<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory 2014 - Scalable Distributed Erlang | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory 2014 - Scalable Distributed Erlang - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang Factory 2014 - Scalable Distributed Erlang</b></h2><h5 class="post__date">2014-06-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/XncdY2KTfis" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi well i'm metalia from the university
of glasgow i work in the release project
and this is a european project and we
have eight partners working together
these are three industrial partners and
five academics so the point of the talk
is just to give an idea what we do in
the release project and particular in
wp3 it's a work package 3 where we work
with language level and the work that i
will talk today about is mainly done at
glasgow university and university of
kent in the UK so I'll give a brief
overview of the release project or the
problems with the distributed Erlang our
design of scalable distributed along
then a bit about operational semantics
if I am I get time and about our future
plans so the aim of the release project
is to scale the radical act incarcerated
parodied to a reliable general purpose
software and we want to scale it up to
25 calls so the first question that
comes is a along already skills well yes
it does but at the time when we started
the project that was 2011 we had few
aspects something like vm aspect so it's
about synchronization of on internal
data structures and then this is
language aspects so maintaining a fully
connected network and have having
explicit placement there and then
another thing is a tooth support so the
why we peaked along for our project and
distributed along in particular well
first of all its of course reliability
it's if something fails then we pick it
up and restart it again and another
thing is scalability so this is a
benchmark of them Barcia bench we
started with 20 notes then within 20
second we just nine were killed nine
nodes and then we get into stable state
and then we restarted those lands so the
scalability really works and it's really
nice but what we want is that not only a
hundreds of course are working together
but thousands of course so distributed
along its if you look at the picture so
the blue ones are hosts then we have
yellow nodes and this rectangle is over
here cause and then we have processes
and we have transitive connections
because between nodes which means that
all nodes are interconnected with each
other and two main aspects of
distributed rolling is about having
those transitive connections which means
if we connect one extra node it
immediately becomes connected to all
other nodes and another thing is
explicit placement so if we want to
spawn a process to another node we need
to explicitly say which node in
particular and so the disability along
scalability limitations well without
your arm about few of them and that's
the reason we work on the project so the
first one is about global operations
first of course is using global module
and this is the picture that are we it
shows the number of course sorry number
of nodes and this is a number this is a
throughput and then we increase the
percentage of global operations and the
largest percentage is zero point person
and the smallest so the less global
operations we have the better with
and it's not only about the global model
because you can say well there's many
actual applications use global
operations but the RPC call is also
another example when we use the global
operations another thing I want to
stress here is here I will talk about
knows how many and by note Eminem and a
long vm so how many along the m's can
work together and here i'm not talking
about size of one vm that was talked by
kostas ago knows that his part in the
release project to scale or one vm so
how many cause how many cause of one vm
can work our aim is to make as many VMS
working together together as we can and
another problem is a single single
process water like something like rocks
process in our pieces and so this is
this is a picture of react this is a
bench mark whelan so we have from turn
two hundred nodes and then so it scales
pretty well until we come to 60 nodes
and this is react version 11 point it's
pretty not been us diversion because we
worked with russia and discovered it the
same problem together with this Rex
problem they solved it in in the next
version but we didn't do benchmarks up
with that version anymore and another
thing that we have we think causes a
problem is all to all connections we
don't have evidence for that yet because
we haven't run that large urban Schmucks
yet but over think it will come
the bench so the types of benchmark 30
years first one is de bench and this is
an artificial example and it's nice to
use it it's simple we understand it but
it's not really very related to the real
world another a benchmark that veranda
was react and that's nice it's large
it's real world but it's so complicated
it's so hard to understand immediately
what's happening there so we went
something in between and this is orbit
so y orbit its first of all it's DHT so
it's similar to react another thing is
its uses phop techniques and the last
thing it's quite small so we can
understand what's happening there and
it's sort of close to the real world so
orbit orbit just a few words how it
works we have a master node and we have
work innards and we start process on the
master node and it generates a list of
processes so where we spoon the next
process depends on the hash value of
that process and the hash table is
distributed between owners so we
generate an element we take a hash and
this has defiance to which a process
where to which node where actually are
going to spawn the process so if we have
just one node then we just spawn it to
just pull it and that's it and then by
the value define the the hashed value of
the table if we have a distribute it
alone then we need to define a node here
but that's actually the difference
between non distributed or line and
distributed home
so now I will talk about scalable
distributed airline and so before I will
explain what it is I'd like to say a few
words how we designed is how we came up
with the idea why it looked the way it
it looks so the first one is the design
principles and the first general
Prince's principles are about working on
along our level as far as possible then
we wanted to preserve the along along
philosophy which means and programming
idioms and then we wanted to make as
minimal language changes as possible
because language is nice it's it simple
it has its follows we didn't want to
introduce something foreign that program
is late or just rejected say no it's not
our way along we don't want to use it
and then about reliable scalability
design principles so it's about avoiding
global sharing as about introducing
abstract notion of communication
architecture and keeping a language
liability motor when we started we
looked at the following a few things so
the first one is about topical hardware
katek sure so what we think will be the
architecture that will be use it as do
all along another one is anticipated
failures so what's going to fail while
running an application and what we need
to scale so without that we need first
of all we need to scale persistent
storage and we think that react and
Cassandra can do that for us another one
is in memory so there's a head stable
and currently are our partners in the
release project an absurd University and
Ericsson work on that too
gay lads tables and our like our beach
is about computation how to scale a
computation so the first one is the
target of blood platforms so we target
our commodity hardware so it's general
purpose as a standard hardware and
operating system and not specialized so
we think without something like this so
we have clouds we have clusters within
clusters we have hosts something like
100 hosts per per cluster and then we
have this mode use something like that
have a shared memory and then we have
those modules around 32 64 course are
sharing a memory as well so it's about a
new market texture and SD Erlang and
it's scaling computation so SD Erlang is
a conservative extension of distributed
power and it consists of two parts the
first part is network scalability and
the second part is some explicit
placement so the problem with it is we
don't believe that all to all
connections scale so we wanted to change
that and another thing is some explicit
placement so ok if you have 100 of nodes
or we have something like a structure
how we named nerds but in general it's
just impossible to to know that the
whole structure to spawn processes to
particular nodes everywhere so that's
another thing so the first one is a
network scalability and here we have two
types of nodes so we call them free
nodes and as group knows so free nose is
these are notes from distributed along
they have the same rules
connect they have transitive connections
and they have the common name space and
s group nodes is the note that belong to
as group I'll explain the Minnesota to
Quatermain mother and nodes in as group
have transitive connections within nodes
of the same as group and non transitive
connections with other nerds so the
first three pictures is about
distributed airline so for example we
have two groups of nodes and then we
connects node 3 and note for and what we
get is a fully connected network that's
what i mean by transitive connections
and if we have s groups it means we have
one is group another s group we can
accent and those nodes have non
transitive connection so they connect
but first of all they don't share their
connections and the second thing if we
register name using global for example
then those knows it will not share that
information and here it's more about the
type of nodes we have and types of
connections so the black nodes are
normal nodes which I mean by normal
nodes they're not hidden and the grey
nodes are hidden knows so when hidden
nodes connect are they have non
transitive connections they don't share
connections and also and here we have as
groups and the feature of as of nodes in
as group they can belong to multiple as
groups that is if you look at as groups
you may say that well that's quite
similar to global groups all the
difference between global groups is that
nodes can belong to in global groups
node can belong only to an ask only one
global group and as groups can belong to
multiple groups right so the question is
why is groups so there are a few reasons
so we wanted to preserve distributed
along philosophy and that is any node
can connect to any other node we didn't
want to introduce restrictions there
then we wanted to that adding and
removing notes from his room should be
pretty simple and a node should belong
to multiple as groups and again the
mechanism we didn't want to overwork
over them so we are considered a few
approaches the first one was according
to hash value that's that's a pretty
popular idea and we thought about it but
then removing and adding nodes to groups
become pretty complicated and brings
more headache than it brings positive
things then was that about hierarchical
architecture but here it means that
nodes we can't connect actually any no
to any other node because if it's
hierarchical it means that nodes can be
connected to only within their that
their group and they can be connected to
the parent and to child nodes but they
we can't do interconnections over there
so we just decided to do are overlapping
and see what what will happen
so as groups as groups that we can start
them at launch so we can define a
configuration file and say here is our
configuration and please have those as
groups or we can start then done
dynamically using one New Year's group 0
right no it's a you as group 1 and group
2 i'm sorry these are those two
functions so in the first one we define
only a list of nodes and then the name
of the earth group is generated
automatically and in the second one we
also define the name of as group where
else I can delete his group add notes to
as groups and remove notes from as
groups and there are additional function
of course a list of all nodes that's
about as group information them we can
register and register no names in as
groups searching and sending messages so
we did run some benchmarks using de
bench here and we run from 10 to 100
nodes and the experiments showed yes are
having even point zero one percent of
global operations does it improve
scalability so as de young scales much
better than distributed along and now
looking at orbit again so we have this
orbit and we how we want to refactor a
program in distributed olin to SD along
and that is introducing our levels
actually so we have the same master but
now master is connected north to work an
old directly but to submasters and then
submasters actually connect to our
connotes
I will explain a bit how amateu beat
works disability along we have
masterwork a table credit and here we
add a few are more modules the submaster
and grouping and then for monster the
difference is that now it spoons not
worker processes but it will spawn
submaster processes so master nerd it's
no longer has direct connection or
communicates with working notes but
rather it communicates on loop with
submasters and workers now for example
when they want this this work I want to
send a process to this worker it first
check so we do not want hashing but two
hashes so the first hash we check
whether the worker that we want to send
the process isn't the same as crude if
it's in the same as group then we just
directly send a message if it's not then
the message goes to submaster to another
sub master and then to the world cup
process
and submasters so they will initiate
submaster and gateway processes start
work processes and do the so the
submaster they become something between
they take roles from woke up processes
and they take and work on it and take
all the work from masters they become
something intermediate that connects
masters and workers and grouping so now
we need to create a master group and
submaster groups that's about grouping
these are initial experiments that we
ran our own up to 160 nodes and that is
about 1200 cause if you see the
distributed erlang and scalable
distributed along so so go disability
along performs a little bit better but
the difference is pretty small these are
initial experiments so don't be too
scared by them but important thing I
want you to notice is this flick that
happens around 30 notes so for this
particular benchmark the difference is
small but it's important that this click
happens and then the distributed along
actually performs better maybe this is
oh and sorry um how can you see that
myself right it's a runtime ranter I'm
sorry yes so Stanton nodes and then we
look at at the speed up so it's this is
this is speed up and those are number of
nodes so again distributed so we have
this slick here and scalable distributed
along performance a little bit better
but em again these are the initial
experiments just to see because we did
the work and so the question is does it
actually work does it help us do our
lines so it shows that it does right so
another part of scalable distributed
along is sim explicit replacement since
an explicit placement is about our
processes placing processes where we
place those processes so for example we
have a process our processes that
communicates very often with each other
so it means that we want to place them
close to each other another thing is
that probably we have a process that
will run for a while and it means that
probably we don't want to run it locally
but who would rather to send it
somewhere to some cloud somewhere so we
want to make it not my hands but some
sort of automatically are sending into
different groups
and here we can imagine actually the
structure over our system something like
a tree right so for example this I rags
and those are clusters this is the cloud
and what we do is we work with a metric
system which is close to I forgot its
name so we're here yes it's
euclidean euclidean space so what this
means I'll get back to
to this one so it means that actually we
can define the distance and here we go
from the root and this research is based
on the research done at glasgow
university but some of the researchers
they worked with Haskell and so we
decided to take the ideas and try to
implement it in a bit different aspect
so what it means is that we look from
the route from the top we look at how
many of those links branches actually
two nodes have in common so B&amp;amp;C have to
it means that if their distance is
one-fourth and bng for example that they
have only one since the difference is
distances were are a half and when it's
no common links then it means it's fun
so the larger the larger this parameter
it means the fur them are nodes are from
each other and from this we can define
how far nodes located from each other
and here we can look at the Rogers so we
can when we define where actually we
want to spawn the process we can just
look at this radius and see how far or
close we won't respond and here we can
think about something something very
specific Christ we can think about
one-fourth or 18 but on the other hand
we can do it more user-friendly and
using some nearby very close far away so
this kind of parameters and this is a
work in progress and another thing that
we can use is using attributes and as
groups so first of all how we can group
as groups or how we can group nodes in
as groups the first thing that can be of
course that's LA Coliseum nodes are
close to each other we put them in our
scripts another thing can be well
probably those nodes have the same
hardware or they have the same software
and so we can group nodes in that
way oh we can group them according to
locality but then give them attributes
and these attributes can be maybe they
have some software maybe they have some
parameter there maybe just I don't know
somebody's Prince computers or something
so just using all those attributes also
helps we came up with a cheese notes
function and it's a list of parameters
and those parameters that can be as
group that can be an attribute or they
can be a distance for example close far
away and so on another thing that we are
working is operational semantics so for
SD along we work are on the semantics
why we need is well we need to be sure
that what we actually work with and what
we write is it's cracked right so we
want to check it and for this we came up
with nine function so they change their
state and six functions that don't
change that state so what so initially a
node has some sort of a state and the
functions that don't change that stage
so this day doesn't change but still be
a return some result so for example
where is the name or register name and
so on so the stadium is actually about
as groups set of five groups a set of
green free groups by a free group women
a set of normal nodes interconnected to
each other and then a set of free hidden
groups and free hidden group zips
actually every hidden node is a freedom
every hidden group because a group we
define as
having its own namespace and consists of
nodes are with which to guess transitive
connections and of course hidden knows
they have their own namespace that
unshared and they don't have transitive
connections with other nerds so the
property here is that every nude in SD
on is a member of one of these groups so
we can say that our nodes over here are
each node from over there belongs only
to one of those and here we can drive
all sorts of properties so the semantics
looks like we have a stated in the
beginning we have a command and we have
a nerd on which we implement this
command and then we have a new state and
return a value and this is just a very
very simple example the simplest that we
have I don't want to you to overload you
with this so we have we have an initial
state we have groups three groups for
hidden groups and nerves and we want to
register name in as group that has a
name that has a peed a node and I answer
we check so the first thing is that the
node should belong to the as group and
if the node belongs to the as groups
anode and the name is not registered and
the beat is not registered then we
register the name otherwise nothing
changes understood so and we verify that
and for validation we used a career week
this is a quick check sorry from company
quick and the way we did it is that so
we have a nice group command and we go
into two different directions so we take
operational semantics we take a state we
apply the the semantics that we used and
we you we get a new state and then we
actually run the the actual command and
then we get these two states and we we
check whether they fit whether they are
the same and if they're the same that
that's fine their function works fine if
not that something wrong and actually
identified a few problems with our
functions this way that was really
useful so just to give an idea what's
happening there so the precondition for
example for creating a new us group is
the set of Nome shouldn't be empty so
this is the precondition that we check
in the beginning and then our we have a
post condition so those two rechecked
way the rent each of them went through
their way and then in the end we check
those we get abstract state and we
checked them with them real estate so
abstract results we compare with the
actual result and abstract state with an
actual state
right so now about future work in the
release we go to earthly and half years
and we are two and half years just now
so we get up one another year to work on
so the same explicit placement that's
really interesting word that we are very
excited about and here we two currently
a water arm I showed is actually we have
everything region in configuration file
and of course we want to make it
automatic so that's one thing to do that
and we also want to look at our botanist
so adjusting parameters and looking at
the failures another work is continue to
work on the SD ealing semantics so
probably look at the other function
looks look what we can do there check
the the existing functions another very
interesting work that involves almost
all partners in the release project is
actually running simply Oscar on a blue
jean supercomputer with approximately
65,000 cause that's going to be an
exciting work with a lot of are largely
a mess and a lot of VMs actually working
together so quite slow to work just now
happening around similasan Jessica
simulation simulation engine that was
developed at EDF that was errors in
France we also would like we want our
work on it as you earn to become a
standard Erlin but for that of course we
need to add her on benchmarks to
convince the community that it worth
adding it as a standard thing and of
course in the methodology so the first
thing in the methodology is the vote
possibility so running are the same
application on different different
machine and of course here we'll look at
choose node function as
our main things just having parameters
extracting those parameters from the
system and adjusting them hoping the
system to decide where exactly to spawn
those processes just from some small
hints and scalability principles
mystical ability principles are first
about of course Erlang applications so
we developed a library and we continue
developing but it's but for developers I
suppose it's really important how to use
this library so what to do with it how
to structure the program so that's
another thing we look at and then from
the research point of view it's also
very interesting dinner what sort of
what things that we learned from our
line can be applicable to another layer
to other languages how they can use the
same techniques to improve scalability
of all sorts of languages yes
right oh it's right it's a blue jean i
think Costas Costas is not here I asked
him today but my focus was about how
many cause they're 64 something right
yes so I'll tell you it's I think either
16 or 64 call / / yes / note sorry 32 64
right yes it sounds like that but yes
here so I mean vm it will take something
like 62 so it depends 30 so as soon as
32 but we can actually put movie ends
right on one host so we can have
actually more VMs than just that number
right and scalability principe de these
are some sources other two worked on
some release project just some general
information or we do public did
available so if you interested do you
have a look then in github SD along of
course de bench and orbit the benchmark
that we worked on the sub 2 is a tool
that Kent university works on bench
where else we use that was developed at
Uppsala University and ICT year in
Greece and simply asked a simulation
engine that is the work of EDF
and that's it thank you and your
feedback will be very much appreciated a
stir and then a sub mask yes submaster
dies is there an election process within
the pool to elect a new one right well
just now we don't provide it from the
language perspective we rather leave it
just now to a programmers to decide
because for example that's submaster you
can think of it like creating musa
masters for example so you can alexa
this from the workers for example or
that can be that dies and you you may
want depending on the application you
may actually want to give all your other
workers and it starts everything from
scratch so just now we are don't focus
on it that much but probably that that
will be one of the direction when we
look at them methodology and portability
so what sort of patterns we actually can
because one of the patterns is grouping
because everybody can do grouping
themselves but actually when we ran
those benchmarks realized that we can do
grouping as just a library for just
because it's just reusable use it all
the time so probably that that can be a
part in this far
yes please
yes yes yes so I mean you can build your
applications such a way that submasters
will know so the node will be aware of
its surrounding so it's directly
connected and then you do the hashing
and you see that it's not in your
network so you just sent to submaster
and then submaster decides where to go
another thing is nodes can actually be
directly connected it just depends on
the application so the difference is
that just you know if you have
transitive connection oops I went to the
wrong direction if you have transitive
connections it means that nodes are not
going to share this connection so for
example if you if you connect this to
nurse it mean if you something
registered here it means that first of
all this to know they will not share the
connections they not will they become
fully connected and another thing if
something is registered here doesn't
mean that it will start replicating on
this network so but it depends on the
application but you can do that
yes
i right yes we looked at it and I think
that was we looked at it on for albeit
example and I think that was something
like some something like 20 knows I
suppose but i think it's very
application dependent and it depends on
how many global operations you're
actually using because something like
react it's good 60 notes so you can grow
your network up to 60 nodes and then
it's better just start but if ye in de
banjo think if you don't use global
operations at all then you can have a
network of 300 nodes and yo I mean
you're fully connected network will work
just perfectly so I suppose it's very
much application dependent
very very high stakes do you think
that's going to have serious robustness
problems in the long run or do other
esters seems like if you want that
connection those notes can discover each
other yes yes but i think it's it's very
much about reliability right so I mean
if yes you mean in the distributed along
if you just lose an hour one node and
then it comes up then it's enough to
connect to just one of those notes and
will be enough but on the other hand yes
I think it's very much about liability
so instead of having just one sub
monster you will need to have to sub
masters or something good think about
mechanisms to how to ensure that the
network is not lost
please
right that's very interesting point I'm
afraid we haven't reached that point yet
probably are we assume the Oscars
suppose is the one that will show us
quite a lot of interesting you know
problems arising there because
apparently with orbit it's quite small
and we didn't have many problems getting
those so but that lets interesting
really
well because this matrix is very much
about communication time yes
yes
yes right well I suppose it's because we
can have different different types of
connections right I mean we can have
something that for example for example
looking at two hopes for example if you
have if you don't have hopes it's it's
pretty easy but suppose that we have one
hope and we have two hopes and if
through one hope it's very busy and too
hopes are not then it means that through
two hopes it will be much quicker than
through this one hope right so it's it's
not actually very much about how many
hopes we do but how long how much time
it takes so I suppose our main concern
is about our communication time because
it's one of the bottle next rather than
just just counting Hobbs another thing
is that sometimes when you root things
right the the packets they can go
through different routes right to the
same point so I suppose the main thing
that we want is that to measure the
communication actually not exact
direction
yes we went to the suit more time how
long it takes rather than rich exactly
path it takes I suppose
no it just didn't hear you
yes yes that's that's one of them yes
please
I didn't identity sent the point about
yeah yes
yes
well um I'm not really grieve is a year
in terms of building internet because I
mean blue jen is just this box it's not
internet it's just this tiny tiny tiny
bit of
yes
yes yes yes well I think uh oh and talks
to you more about it thank you more
questions yes please special for you if
you're using hashing to determine where
this thing is located are there concerns
and a heavily loaded system out these
hashing the same
and creating hot spots right well I
think a hashing in this case was just it
was it was easy to implement i'm not
sure that hashing is actually something
standard that probably many applications
are going to use another thing is that i
think it's a bit hard to answer your
question because too many applications
but interesting point
put a 1000 s groups and have it still be
reasonable I suppose it's her I suppose
it depends on what you are going to do
with that if you're going to register
names all the time they're globally I'm
afraid that will be pretty pretty bad
um
I suppose yes I suppose it depends thank
you I suppose it depends on also how
many connections are now it can hold try
it so probably the the degradation can
come from there but other than that it
will take time for you to create those
as groups thousands of them
synchronization shouldn't be a problem
if you don't register anything so it's
only about actually keeping connection
you're not updating anything there if
you don't add nodes so I mean if you
just hold it I don't think it's going to
be a problem it's like having just
direct connections like with hidden
nodes and that's it more questions no
thank you
you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>