<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Future of Tracing by Lukas Larsson | Coder Coacher - Coaching Coders</title><meta content="The Future of Tracing by Lukas Larsson - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>The Future of Tracing by Lukas Larsson</b></h2><h5 class="post__date">2016-09-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/aPpzjfLAGV8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is a talk that I've given once
before in San Francisco so you might
have seen it online there's been some
tweaks and things because back then it
was like 19 was about to be released I
was it three months in the future now
it's been out for three months so it's
about the same talk only with that
perspective in mind so yes so I'm going
to go through kind of an overview of
what tracing is what the different
capabilities that the virtual machine
exposes to you so what you can do and
all of the different things just to give
you an idea of what is possible to do
with our line tracing today do things
the different ways that you do
introspection inside to gather
information inside the virtual machine
and then I'm going to talk about the
work that I did during winter this year
to make the tracing better faster more
scalable and easier to use more flexible
and talk a bit about my ideas and things
that I want to do in the future we're
tracing so tracing its kind of a way of
doing some kind of dynamic logging in
the system so you have a problem that
you haven't foreseen it's gonna happen
and you want to figure something out in
the system that you want to know why a
certain thing is behaving the way it is
and you didn't put a logger statement
saying that you want to log this
specific path according part of the code
into a fire or something like that so
you put on tracing to do that in a line
it's built into the virtual machine you
can trace on basically all different
kinds of events that you couldn't think
of you can try some function calls you
can iterate on message passing you can
trace on process States you can trade
song what's happening with the garbage
collector you can trace with the
scheduling ideas you can trace to see
how long different kinds of garbage
collection or scheduling events takes
there's a lot of different things that
you can trace on and it's the main way
of introspecting and looking at what's
happening in your systems when you're
tracing the normal ways to do it is that
you either tries to a file that
read somewhere else so you trace to some
IP port the you send over TCP or you
trace just to standard out and read it
in your console the basic way to get
started with tracing is that i use dbg i
love dbg so dbg just you start your
tracer you trace on all the different
processes then you say you want to trace
on a module the lists module the
sequence function and you want to do
exception tracing and then you call the
function and you see what happens very
simple to get to started and then you
get exactly what's happening in your
system and you can build on this and
make very complex traces and get exactly
the information that you're looking for
in a system we have a bunch of trace
receivers at different ways to what
happens with the data that you're when
you're tracing so you have two choices
in the current in the 419 you had two
choices you could also send the traces
to a process and that process could
decide what to do with the trace message
for instance it could print it to
standard out so the normal tracer that
just dumped everything to the terminal
that's a process trace so it receives a
trace message of some sort formats it in
a nice way and then puts it out into the
console or you can do some kind of
analysis in real time of these things so
you can say that okay so if I receive
this trace message followed by this tres
meses follow this trace message then I
want to do some kind of printing to
stand out in order to filter so that you
don't get so many messages printed out
to your console I believe this is like
to like read bargain recon uses this in
order to don't overflow your system so
they have some kind of state in that
process them or you can send it directly
to an island port so you have two
different ways of sending them and they
waste that the ports that are shipped
with the with runtime tues with the
other angle TP is that you can either
face the file or you can't rise to a TCP
socket and then all the data gets flowed
outta to a TCP socket or to a file on
disk and then you can do with that data
what you want
so trace events so there's a bunch of
different trace events that can be
generated so in a small example code
like this spawn phone here there's a
bunch of different race events that are
happening that you can trace on so the
first thing that will happen here is
that you will be scheduled in so when
you the message is sent go to this thing
here it will get a receive trace saying
I received this message you can trace on
saying receive when it gets received you
also get a scheduled in because this
process gets activated so you know that
this gets scheduled in and you can get
timestamps associated with it and then
you can get a call saying that oh
there's a function called happening to
this function and there's a return from
that function so you can measure the
time that that function called took for
instance and then you get a schedule out
so now you have an in and out events you
can for instance do a trace saying okay
so how long runtime this this process
add when it was running why and do
analysis of this and then it went in to
receive after so we're waiting for a
timeout and we get a schedule in and
then we get a timeout event that we can
also trace on and see that that happen
and then that the process exited so we
get an find 11 saying that the process
exited and then process actually
terminates so there's a bunch of
different things and we can track the
life cycle of the process using these
kinds of different tracing probes when
tracing we're talking about both code
and lie processes so when you're tracing
you normally set up a trace saying that
okay the intersection of the processes
that I'm interested in together with the
code that I'm interested in that's what
I want to know so if I only want to
trace only certain certain few processes
within one supervision hierarchy I can
say okay I want to trace on these
processes and whenever they call this
code I want to get a trace message so
you're always working with the
intersection of the different of the two
so you're working with the processes and
the code working in there obviously for
like sent racing and receive tracing you
only have the entity that you're working
with because there's really no code
involved but when you're working with
the code you're working with the
intersection of the different too
and you can also configure it so that
each process has its own trace receiver
so it's not like you have a global trace
receiver for the entire system it's each
process that has its local trace
receiver so you can have a certain
supervision hierarchy saying okay I want
all my crates message being sent to this
process and then some other processes I
want to be sent another port or
something like that so it's divided
between the different parallel entities
within the virtual machine so that's the
basics that you use so now we're going
to get into the more advanced stuff on
the features that we have in the virtual
machine so does this thing called meta
tracing which is tracing if you just
disregard the processes so you're just
tracing on code and code calls you're
saying all of the different from all the
processes when that code is executed
this meta tracer is run and some code so
you started as normal and you say that
when you set up your airline trace
pattern so this is using like the norm
the low-level trace Biff's we say that
ok so when Jenn Suhr the cost with the
arity of two is being called I want a
meta trace message to be generated so
now I don't have to enable saying what
kind of which processes for all
processes running in system this will be
true and now have a local trace are
associated with this code specifically
so when i call this gents of the cost
send a message to myself i will get a
trace of and saying okay so now this
gents of the call cost was done and i
get this trace message and i get a time
step and so on and this is kind of works
in conjunction with the other tracing
normally with meta tracing you try to
build tools and events in order to work
with the other kinds of tracing so I
there will be more examples of this
later I think went in a much based
occasion part yes so that's meta tracing
tracing on code and we first start
racing on processes and
code so much specifications is a way
that we have a description language for
us to kind of filter and analyze trace
events as they are happening so you
can't unfortunately you can't write a
line code in this part because it's
executed way down into the virtual
machine we cannot run a line code down
there so you have to write these match
specifications that are run within this
important it's kind of a separate
language that is used for ets and for
tracing so you can do lots of different
kinds of early filtering and triggering
on different events with mass
specifications so you can discard events
much earlier so you don't have to deal
with the load of them or you can change
the behavior of the tracing saying that
you want to all of the sudden start to
trace on sending or receiving or trace
on scheduling events or something like
that because a function was called so
when Jenn Suhr the cost was called I
want to start tracing on received
messages on this process or scheduling
events on that process or something like
that you can do this with match
specifications a general massification
might look something like this so
there's all of this kind of unhappy sad
faces and then a this specification this
is basically this code so it's a
function taking three arguments the
three arguments comes from having it's a
list with three elements in it and the
first one has to be a two pole with two
elements and then we don't care and then
we have a list and when the length of
the list is one we do a return trace so
well the functional arguments and then
we have a God close saying what should
be guarded and then we have what's going
to be happening and in the match
specifications that we use for tracing
we have an implicit message true so this
is going to generate a message for this
event and it will also apply a return
trace telling it that when this function
returns i also want to get a message
so if we do something more complex or
different anyway so I can do a chance of
a caster and I only want to have trace
messages when I send it to myself so I
set up the match specification saying
that when the function in the match
program self equals the PID of the shell
in this case that's when I want to
enable tracing of send on myself with
this specific tracer so enabled trace
would send myself and enabled as a meta
trace so then when I then called into
the cost it will execute this mass
specification and it will generate the
message for the meta trace and then it
will enable sent racing on that process
I will actually get also the message
saying they're so from that point on all
of the messages that this processor
sends will be generated trace event so
we can build heuristic algorithms and
logics into this saying that okay so
when this function is caused I want to
change the tracing behavior of the
process that called this function at
this point and do this kind of thing so
in a production system for instance you
might say that okay when this function
is called and the arguments to this
function is blahdy blahdy blahdy draw it
has this thing this identifier i know
from some customer or something like
that then i want to enable Colt racing
on this process for these different
modules and I want to also have send and
receive tracing on this process to see
what things is interacting with and I
also might do something like set on
linked tracing so that i propagate my
things that's happening with this
process so I can trace exactly what this
specific customer is doing and try to
track down why it's not behaving the way
he thinks it should be and you can put
on a message falster then it won't
generate a message then you will just
get saying that okay so i'm just going
to do i put on a trace for sending on
that process and you can enable disable
these kinds of tracing I find it very
useful
when trying to lessen the amount of face
messages and the impact tracing us on
the system so there's some other tips
and tricks for this with match
specifications and trying to control
tracing there's something called a trace
control word that you can use which is a
global variable that you can use to
control tracing it's set to an integer I
think it's a 32-bit integer that you can
just set and say and drive the behavior
depending on what that integer is set to
so you and there's all kinds of math you
can do in much specifications you can do
like checking if this bit is set to that
then you're going to add this behavior
not a bit is set to that you can do that
behavior or lots of different things you
can enable and disable tracing as you
won't go along as I show you and you can
also especially when you use it in
conjunction with meta tracing normally
you don't want to have messages
generated for the meta tracing so you
want to have a meta trace saying okay
I'm not going to generate the message
for this but I'm going to do the
behavior of the match specification for
instance enabling or disabling traces in
different ways so here we have another
complex or example even more using the
trace control word so you can get the
trace control word saying okay so I set
up a trace pattern of list sequence to
again and I don't care about the
arguments but when the trays control
word is one I enable tracing with send
using this tracer I don't want a message
but when it's not sent to one then I
disabled it so I can just go saying that
ok so now i want to have tracing you set
the trace control words you can do a
line call on trace control word and you
will set it for the yogurt machine and
then you will run all the processes
there you will all have send tracing on
them and then you disable it saying ok
so now I don't want anymore and then you
can get a snapshot of your of what
you're running so for instance here we
have a small fun running the list
sequence below about and if the trade
control word is from the beginning at 0
so there is no trace generated but when
I set it to one and I do the same thing
so I get the message
so I can control it in different ways so
that's the crash course to magical much
specifications not going to talk much
more about that there so there's another
way of tracing that's called sequence
tracing I'm going to mention a bit it
allows you to follow a series of events
happening in a system as messages are
being sent and received within it so
send say you're having something that's
coming in on the edge TCP socket that's
generating something that sends a
message of to some other process that
sends a message off to another process
and then with sends messages back stance
messages back and then you have this
chain of things so sequence tracing is a
way for you to say that okay this
specific message I want to trace this
message and all the messages that it
generates and sends back in your system
so that you can follow an execution path
and you can also use this to kind of say
that okay so when I'm following one of
these sequences I want to do call
tracing on specific modules or functions
along the way so that you work your way
in the system so that you can say that
okay I want to have this and then it
follows along in different ways and one
of the nice things about this is that
works over a long distribution so you
can send out kind of set I comes in here
and then it actually goes over to
another another airline node and then if
you have tracing running there and you
have a trace receiver on that side it
will continue collecting messages you
can see it in your distributor dialing
system how it's behaving and where
everything is going and hopefully find
why it's not working the way it's
supposed to and of course yeah the
sequence tracing is part of everything
increasing so you can use math
specifications with sequins tracing to
do the filtering and figuring out what
you want to do and so on it's lots of
flexibility there we also have support
in the virtual machine for some internal
probes using dtrace and system tab and
now in line 19 we also have alta TNG in
there so you can trace on using these
kinds of system profilers you can trace
on internal emulator events and
that are happening inside and also with
the airline code like some function is
being called a message being sent and so
on using DTrace assistant app so dtrace
on bsd or solaris and then system tap on
linux or now at the TNG on linux as well
so this is kind of useful because you
can use it to correlate with other parts
of the system that also uses DTrace so
for instance you can check like what the
colonel is doing because you did a file
right to a disk you can see what's
happening and why there are delays or
you can see what the tcp stack is doing
and correlate a send over TCP socket
from your Erlang application into the
kernel and see what the tcp stack is
doing and why it's taking so long and
which buffer it ends up in and what you
should tune all the way quite useful so
that's the overview part of the talk so
that's all of the different tracing and
instrument and capabilities that I could
think of that's part of the virtual
machine and what we do there so as I
said in the beginning during this winter
I was working for a couple of months
trying to improve tracing to make it
more flexible more and especially have
less overhead when you're tracing so
let's start with one of the first things
that I was looking at was to try to make
it scale better on multiple cores the
true the tracing that's before nineteen
didn't didn't scale where well when you
had moved to like if you had a 16-core
system all generating face events at the
same time it gone the performance got
poor very quickly so a brief description
of what the architecture kind of looks
like in before 19 so you have a bunch of
processes on one side sending generating
trace events of some sort so calling a
function sending messages and it's being
scheduled in or out garbage collection
events what whatever and all of these
got put into a single queue that was
protected by one single mutex and then
all of the events were ordered in that
order so that you
got it in the same way and then there
was another thread within the virtual
machine that consumed this queue and
then sent the messages to the
appropriate entity so I the report or a
process that wanted to receive them on
the other end so an obvious question in
this part why didn't the processes
themselves send this message immediately
to the receiver because the processes
know what which receive is going to get
the message and this is part of a
implementation detail inside of the
language machine that's called the
global lock order that we use inside the
word machine in order to guarantee that
we don't get any deadlox from our
different locks different things so I
think the next slide we'll talk a bit
about that yeah so the global lock order
the way works is that we have around 90
different locks of different types
within the virtual machine and all of
them are ordered so that we have one top
block that's the highest priority and
I'm where the second third fourth fifth
69 teeth look and you cannot take if you
if you're holding look to you cannot
take lock one without first releasing
look too so we have an order saying that
you cannot take a look above you without
first releasing the locks that are below
and then trying to take it the other way
around and the problem here was that in
order to send messages these processes
they needed to take what's called the
process message queue lock which is a
very high order lock and normally when
we're generating trace messages we have
a few of low-level low priority locks
taken and we don't know which locks are
being done like for scheduling events or
doing something like you're inside a
port your process being called in a port
so it's very complex so in the initial
SP implementation the easy solution was
just to say now we're just going to
create a new look that's very low
priority and put it inside the queue of
that part of that look and then let
another thread deal with it so it's a
common strategy to deal with these
things and there's still a few things
going around there so we have a problem
here saying okay so we need
to have this high order look which is
the message who look but we don't know
which looks we have underneath it there
so that's why we have this other process
where everything is proxy do I am so in
nineteen I did a couple of changes to
this thing so one of the things was that
it turned out that the only look that we
was kind of difficult that's lower than
the message queue lock was the stick
process status look and that wasn't
strictly needed in most of the places so
i removed the need to take that look so
we only had to lead a deal with the
process message key lock and in that
case we when we generate this kind of
event we try to do a try lock on that
lock and if that succeeds then we can
just go ahead as usual because we can
circumvent the law order by doing
Trollocs instead of doing forceful locks
so as long as we're not waiting for a
lock to be released we can't get a
deadlock so if we only try lock it then
we can go up the hierarchy of looks but
we still have to deal with the case when
the trilok fails and spinning is not ok
so we because then we could spin for
infinity if we end up in a deadlock
situation so I had to introduce a per
process q of messages that is protected
by a low-order look that I knew that I
could take so it's taken whenever you
generate a trace message to a process
and then if some different logic so the
basic algorithm now works that ok we
first take the process trace lock and we
check our own q because if we have
something in the queue we need to
preserve the order of trace events so we
can't just do a try lock and try to send
it if we then have something in our
queue we might get trace messages that
are out of order which will be very
confusing if the return of a call comes
before the call of the function so it's
we have to preserve the order of things
and and a lot of different things like
the reception of a mess
has to be able to correlate with the
call that that message actually
generated when it did it so that we can
think about things and this is a
requirement we have with a line tracing
if you use something else like for
instance LT TNG tracing they don't have
this so you get ordered events that say
like we I call this function that should
have caused this happened but that log
entry actually ends up before it because
they don't have this ordering guarantee
but we have that for the increasing and
it's very very useful when reasoning
about things so if it's not empty we
added to de três ease trace queue so we
just depend it at the end of the queue
we go back if the trace queue is empty
we try to do a try lock on the message
view of the tracer if we can we just
send it on and this this scenario here
happens normally around ninety nine
percent of the time so that's the first
path that we try to do and it almost
always succeeds that we can do this it's
especially if we're not if we not only
trace have a system where it's not a lot
of trace events happening it's going to
happen one hundred percent of the time
if there's a bunch of tracing happening
to the same trace process we may have a
problem but then we just buffer it in
our own cue and then send it on as a
batch later on and if it's busy we add
it to our own cue and then schedule the
Tracy for clearing of this as soon as
possible later on so so instead of
having this complex thing we now just
send it straight to the processes and
ports at the other end so some
functional implications of this trace
messages are more likely to be out of
order for things that you think that ok
so this these things should happen off
to each other some examples like the
guarantee that we have with tracing is
that trace events from a single
concurrent entity should be possible to
see at the same in the same logical
interval so you they are ordered but in
between different logical entities we do
not guarantee and
order as such so having a send and
receive of two different trace messages
we can't guarantee that they are in
order we can say that the send it's
going to happen and then we get to
receive afterwards so that we can
guarantee but we can't guarantee the
causality so descend and Anna calls
within that process together with the
receive on the other end so we and that
was a guarantee that was wasn't there
before either it's just that now it's
become more likely that you can actually
see this concert events and especially
if you need if you don't enable time
stamp on your faces you won't see a
difference but if you enable timestamps
on then you can see that things are
happening in an order that's not as cold
as it was before yeah and of course then
this means that time stamps can be out
of order so you can see that in the
trace log you will have trace events
where the time stamps jump up and down
but they are consistent with in all of
the different concurrent identities
tracing to report does not have this
problem so it is no ordering tracing to
port works as before it is just tracing
to processes that has this problem and
but porch works as before and therefore
some small reordering may happen so I
did some benchmarks on this new system
so i have 10 processes doing 1250 ace on
one end codes / process they generate
about 7 million trace messages per run
so and i measured time until the
benchmark is completed measured time
until all of the trace messages have
been delivered to the recipient and I
measure the memory that's being used at
the time so as a baseline running
without any tracing we can see that I it
scales with more course I use hyper
threads so it doesn't scale anymore when
I get over half of the course but get
nice scaling in the beginning of the
four first anyway for these different
processes running in parallel and it
takes about twenty five microseconds per
decode
on this part and then it takes about
seven microseconds per decode here as I
add more schedulers oh and another thing
is like c-19 faster than 18 of the bat
good stuff without any changes from my
part is just compiler in the virtual
machine it's gotten faster by to three
percent it's cool so tracing to a
process again this is measuring
completion time for the benchmark so for
running with one scheduler the actual
completion time went off the chart for
18 but with 19 we're running at about
three hundred microseconds so it's about
ten time performance loss versus not
tracing which is not really great but
it's still better than a hundred times
performance loss and we can see we have
about the same curve in the different
things and it's about three times faster
so that's good if we add how long time
it takes what it tries to be delivered
we can see a similar pattern so the
rightmost here is how long it takes for
the trace messages to actually arrive to
the other side so this is again tracing
to process and this is of the short and
then we see it's still faster faster
faster and it's about the same
difference in the different columns from
when the trace messages when the
benchmark is being completed to when
it's actually delivered a trace messages
tracing okay so this is arity tracing so
the other one was tracing with all the
function arguments so this is tracing
with aratus without the functional
arguments and we can see that it's a
quicker so it's about 200 microseconds
instead of 400 so about twice as fast to
generate with just our team and the last
one is even it's getting quite it's
getting closer to running without racing
so actually having those arguments there
adds a lot of overhead because you have
to copy quite complicated structures in
order to trace arguments tracing to a
port we have this nice thing saying that
okay so with one scheduler we are at
about
same performance as in 18 but in 18 we
have this beautiful curve going straight
up here saying that it gets slower to
run the benchmark and until the deliver
tres meses are there the more schedulers
I add so the more machine power I add
behind it the slower the actual problem
takes to solve which is not good but in
nineteen we can see we have about the
same performance gain here so that's a
great improvement and I tracing to port
is basically tracing to file so this is
great for this footage this specific
benchmark I traced to Devon all so the
disk isn't really an issue but I just
generate trace message as quickly as
possible and this is the lock this
system message dispatcher lock that was
there to synchronize before that's
playing haywire with the result which is
not good but this is good improvement
let's see yeah so this is for arity for
everything we don't have this same steep
curve but we still have the same kind of
general path saying that it gets slower
and slower and slower than more
schedulers we add memory usage about
half so have the memory usage during the
tracing so so far only good stuff and
when you do it with arity it's even less
so with here i was using about five
gigabytes of memory and then it's about
one so it's one fifth of the memory
that's being used in tracing it's pretty
nice for a port memory usage we can
actually see that 19 uses a lot more
memory but that's just because it has
some inkling of speed so it can actually
build buffers in the previous four ports
running in the old one it didn't have
this momentum to build any kind of
buffers so everything was just
synchronous and it didn't take it didn't
have time to build my buffers except for
the first two where we can see it builds
some buffers but here just slows down to
a halt the speed and therefore it uses
no memory which is a good thing but it's
slow as hell so not very good so that
was that about performance things pretty
nice this
but a couple of new features I want to
talk about as well that's there oh I had
running out of time sorry so tracer
modules I have to go quickly we have
trace modules that allow you to hook in
earlier to work with tracing as they are
happening so you can kind of instead of
a process or poor pincode you call a
module that takes care of the event you
set it up it's basically you write a
module like this enabled so if the trace
is Nabal not tracing what to do with the
trace unfortunately in 19 now they have
to be nifs so you have to be interpreted
as native functions all of them we have
written the new tracing implementations
that you just saw our tracer nifs so
they are written as tracer nips in this
part and processing ports and d tray
system tap at the TNG backends exists
for it yeah I want to add more stuff
here some benchmarking to show the
difference so doing porta file or nifty
file there so I did so sending it to
port that does to file its the leftmost
one and then just implementing in module
here goes around saying that is but what
is it about 20 times faster implementing
a tracer nif than to do the one that was
the quickest one that I had the form so
we are using this we can get another
about 20 times improvement on tracing
performance cool we added more match
specifications you can now add much
sophistication zon sending so the event
of sending a message so we can do trace
on other nodes only or receive messages
that are being done with the gen cost is
the first element and we plan to add
more of these in the future or we do
some other solution pulsing also added
port racing events so you can get event
so what's happening with the port us is
being traced so you can see when I Oh
formats rights to the file at the world
we can see what the port receives this
command thing and then it sends this as
a return saying I went okay
and then we close it and we can
introspect exactly what's happening with
the port this was not possible before to
do with ports paddle so you couldn't
trace that so the future so what I've
done what we've done is that we've done
more early filtering with along a tracer
modules match specifications DTrace LT
ng support we've dealt with the overhead
of performance the scalability we want
to work more with doing overload
protection and getting the throughput to
be even better so that you can shove the
data through and then in the future we
want to work more with the different
tools around these things because now
we're working with kind of the
fundamentals of everything that was that
questions please yes
so the first question is the scaling
does it will happen automatically yes no
change in the benchmark at all so I'm
running 10 processes on the one
scheduler or 10 processors on the eight
scheduler problem so it's the same
problem that's being solved in the
different parts it's it should be slower
with one skeleton at least with eight
and the other question was if I'm using
any kind of message bus to do these
kinds of events no that would be a great
example of how to write your own line
tracing nif backend for doing that kind
of thing all right thanks any other
questions director ender ok Dima so that
metart racing mode is it happening
implicitly at some point or do you have
to explicitly say meta in your tracing
call you have to say when you set up the
trace button you have to explicitly say
that this is a matter tracing point that
you're working with it kills happened as
a surprise to me no no you have to
explicitly tell the thing that is
working they're not questionnaire no I
think they retracted didn't want to do
all right yeah one more
yep basically how this global variable
effect on performance when say it
disabled does it run faster when say you
said these were able to to be disabled
yes I me so the match specifically so
the question is this trace control word
that you can set as a global trace
variable that you can dry behavior on
how does it affect performance so the
match specification engine is run very
very early in the event loop of a trace
message so it and it has to run that
specific night specification but when
that is done it bails out very very
quickly so it just reads that variable
and check that ok so is it the same and
then returns so using that has I don't
know the overhead percentages by it
should be around 50 75 percent overhead
just bailing out like that so it's
basically a kind of safe to have the
tracing patterns on on your production
system and being disabled by default and
it will want to affect the performance
it will affect it will how much is
depends as always what you do I I can't
I've measured this but I can't remember
the numbers I'm sorry if you just set it
up and do some kind of insect racing
should should be a I don't know 30 40 50
percent overhead per function call so
it's kind of and if you will see that or
not on your system I don't know it
depends ok thanks how this sequence
patient works I mean if the sequence of
messages all of them will be traced it
or I'll get one final message that says
that the sequence was muted sequence
tracing it works by saying that okay so
I i say i can say the next message that
arrives to me i want to start a sequence
trace and then embedded a kind of in the
metadata of all the message of the next
message that process sense a token will
be sent forward and enabling
sequence racing on the next process and
so on so it's I I don't know the
documentation exactly and how it works
by heart but it's something like that so
you enable it for the next thing that's
coming and then you trace for that event
or you can set up some kind of match
specification that says that ok so when
this happens then I want to enable
sequence racing on this process that's
in there so you have different ways of
setting it up in there you have a time
for one last question oh let's thank the
speaker than thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>