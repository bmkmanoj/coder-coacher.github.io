<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Lambda Days 2018 - Evelina Gabasova - How to look like a statistician (...) | Coder Coacher - Coaching Coders</title><meta content="Lambda Days 2018 - Evelina Gabasova - How to look like a statistician (...) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Lambda Days 2018 - Evelina Gabasova - How to look like a statistician (...)</b></h2><h5 class="post__date">2018-03-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qbIzE5xm_qM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I did this thought the tactile how to
look like a statistician so your first
reaction might be but I don't want to
look like a statistician because that
these missions are not actually famous
for being very cool or trendy it's
actually a very famous statistician
David Koch's needed quite a lot on
survival models so we can do model on if
you survive this talk or not so as I
mentioned statisticians are not famous
for being especially fun or trendy but
probabilistic programming is something
that's used a lot in statistics and a
lot in machine learning but to look like
a machine learning researchers is a bit
too long so I actually did some search
on in stock photos to see how a
mathematician should look like so this
is one stock photo that I found I like
two things about this photo first the
person is wearing a lab coat
I don't know mathematicians don't really
wear lab coats and the second one is
that he's writing on the know on the
glass basically in Reverse so this is
how you will look after this dog
probably sorry so let's talk about
probabilistic programming what it is
actually I don't know if you have ever
heard about probabilistic programming
but this is one stream in machine
learning that's gaining quite a lot of
momentum right now probably stick
programming and how does it even relate
to functional programming as well and
something that works well I don't want
to dive too much into mathematics first
so first I will have to talk about
probabilistic models because probe
ristic programming is actually a way to
do inference and probabilistic models
but what does it mean to actually create
a probabilistic model I will show you
some practical example of that
I was playing with some data from the
stackoverflow developer survey from last
year and they were asking about a lot of
things who filled in the developer
survey Oh quite a lot of people so you
probably know what it's about
they asked all the things about what
languages you use what languages would
you like to be using more functional of
course if you are using certain
technologies where do you live
and what's your salary and last year
they were also asking about tabs and
spaces if you use tabs or spaces and
they found that there is an interesting
correlation between higher salaries and
using spaces
it doesn't mean causation so I was
looking at the data they gave them for
download and I looked at salary
distribution altogether these are
salaries that people reported worldwide
in dollars per year and this is just a
histogram of the people and I noticed
that this looks a little strange why
there is like a bunch of people in the
middle who have salaries around $50,000
per year but there is quite a lot of
people in the beginning near zero that
are reporting very low salaries so
thinking okay that's interesting so I
split it based on some countries and I
looked at countries where developers
report very low salaries the ones around
zero the most common ones are from India
that sort of makes sense
unfortunately because in India the base
are not that large but the second one is
Poland what's happening do you guys earn
very little but these are developers who
report their annual salary there oh
three thousand dollars that's very
little you wouldn't be able to live in
Poland on such a salary
I'm from a Czech Republic and the
salaries are similar so
I can imagine and the third for the
workers report very low salaries is
Russia and then Brazil okay
Romania Pakistan Ukraine and Germany
this is weird
I work as a data scientist so I looked
at it and thought ok this is really
weird
I would expect India to be there I would
expect Pakistan to be there but Germany
so I decided to dive a bit more into the
data and I here I plotted distributions
estimated probe with the densities of
salaries from France India and the UK
and you can see that these are mostly
just one peak distributions centered
around the different numbers because the
salaries overall are slightly different
and in the UK the salaries were highest
on average then France was a little bit
lower
India was a lot lower but you can see a
nice bump there so then I looked at
Poland and Russia and Germany and you
can immediately see that there is
something happening there because the
bumps look very different for Germany
there is one big bump and one small bump
before that for Poland there are two
more or less equal bumps and for Russia
there is one bump at really small value
and then smaller bump later so I thought
okay I think I know what's happening
so what's wrong with the data why are
there groups of programmers that are
seemingly earning very little and then
bunch of data much of bunch of
programmers that are earning more I
looked at the question that they asked
in the survey and it was what is your
current and your salary in your local
currency please enter a whole number in
the box below without any punctuation if
you prefer not to answer please leave
the box blank they underlined the annual
valve my suspicion was that probably
quite a lot of people don't read
questions properly they say
okay celery okay bang I will put in my
celery and I asked couple of my friends
in Poland and they all confirmed my
suspicions that in Poland if you are
negotiating your celery or if you are
talking about your celery you talk only
about the monthly value in the UK in the
u.s. everyone talks about their yearly
salary but in Czech Republic in Poland I
assume in Russia in Germany everyone
talks about their monthly salary so
people just glance the question okay my
salary and then they put in their
monthly salary so that's my suspicion
and I will try to estimate it later in
my talk so this is actually zoom in on
the Poland so I actually looked at it
and I calculated
what's the small bump of the bigger bump
and really the small bump seems to be
about ten twelve times smaller than the
big bump and I will look at how many
people in Poland can treat questions
properly just there's something proper
and proper to work with so my theory is
that people reported their monthly
salary how do I formalize that as a
probabilistic model and how do i compute
that using probabilistic programming
well I don't have a look at something
called mixture distributions because you
saw that there are two bumps and there
are some standard probability
distributions but none of them real has
two bumps so I have to do something
called a mixture distribution where I
will take some standard distributions
and put them together to get one
distribution with as many homes as I
want so this is an example of something
called a mixture of gaussians where I
have two probability distributions one
is in red one is in blue and right now
they have equal values and these are the
original distributions and if I do a
mixture of them I will just get a
composite distribution that uses these
two distributions as
and I get the total value and I can
change the weights and this will change
how large the pumps are so this is
taking zero point to 20 percent of the
first distribution and 80 percent of the
second distribution and this is when I
do it the other way you can see that the
pumps change sizes so I can use this to
fit my salary data and now we might be
thinking okay why are we talking about
these distributions I didn't come for a
statistics class well that's what free
basic programming is about sorry so
probability distributions in
probabilistic programming become
basically first class citizens in the
language and you can use any kind of
manipulations on them and if I do this
bit more formally because you can't
really avoid with mathematics my
assumption is that salary will be the
probability that someone couldn't read
the question properly or could read the
question properly times one normal
distribution plus probability that
someone couldn't read it properly times
the same distribution divided by 12 and
this is mainly to scare you because I
don't really want to do these kinds of
computations and write down all the
probability distributions and things
like that so what can I do instead well
one thing that's very used in prolific
programming and any kind of statistics
where you are dealing with complicated
problem distributions
it's called sampling and in a lot of
progress tech models you can't really
compute values directly because the
distributions are really complicated I
have just two gaussians and one
probability that someone can't read the
question but if this gets much more
complicated then you have to do
something called sampling as I said and
just to show you an example of sampling
and how it can be used to infer
probabilities directly do you know the
Monty Hall problem have you heard about
it
yes some people are raising their hands
some people are shaking their hand do
you remember the solution to the Monty
Hall problem that's the question so the
Monty Hall problem comes from us
competition called Deal or No Deal
and it ran in 70s and there you had
three doors and the Americans came there
dressed as crazy as they could basically
and they could win a car this is a nice
Chevrolet from the competition and the
idea behind the competition was that you
have this is a simplified model of the
competition and it's called Monty Hall
because the moderator here is called
Monty Hall so you had three doors and
behind one of them is a car like a nice
night and 70s Chevrolet or something
like that and behind two other doors
there are some things that don't have
any price and in the Monty Hall problem
these are goals so maybe someone wants
to win a gold but you are supposed to
win a car in this competition and the
idea is that you have these three doors
and you pick one and then Monty Hall
opens one of the other doors and shows
you that there is a gold and now the
question is should you switch your
choice or not
who thinks you should keep your original
choice
does it matter does it not matter and
should you switch the door
majority people would switch the door
because they know the problem sir
and they don't want to win a goat but
you can either now write down all the
probabilities and compute use the
Bayesian theorem conditional probability
and compute the actual probabilities but
this is quite hard to get right because
when this problem was originally asked
in a magazine a statistician answered
okay you should switch the door because
listen this and they got hundreds of
thousands and gray letters even from
scientists and mathematicians saying no
this is wrong because it doesn't depend
on what does it change if you switch the
door or not because he picked it
originally well you might have heard
about air - which was famous Hungarian
mathematician and he only got convinced
that you should switch the door after
showing them some simulations so let's
do that
here I have a very simple program in F
sharp to do the sampling so behind every
door is either a goat or a car and the
game is just some list of doors and I
can either stay with the door I picked
originally or I can switch the door
after the goat is shown
so let's actually run things
generate some game and now here I have a
little function that will play the game
where I go first
choose one door then Monty Hall will
open some other door that hides a gold
and then if I decide to switch I will
switch to the other door
otherwise I will keep the door I
currently have
so let's run this and I will run this
100 times and now it tells me that if I
stay with the original door my
probability of winning is 0.35 and if I
decide to switch the door my probability
of winning is 65%
so if you haven't seen this problem
before this might be counterintuitive I
think the best way to think about this
problem is that originally when you are
picking a door you don't have any
information about which door contains a
car but after Monty Hall opens one of
the doors that hides a goat then
suddenly you have more information about
the other door that you haven't picked
the information about your car your door
that you picked say the same because you
had property of one third of winning the
car originally but when you switch you
are switching to a door that you have
more information about but I would just
talk about other things first of all
here I did 100 samples if I do 10
samples my estimate will be more of my
estimate that I will win a car if I stay
is 40% and if I switch 80% if I make
more samples my estimate will be more
precise so now if I stay my probability
is zero point it's thirty four point
nine and if I switch my property of
winning is sixty eight point one and if
I do even more samples it should
approach the theoretical value which is
33 percent in sixty six point six
percent so as I'm adding samples my
estimates are getting more and more
precise and I'm basically just sampling
directly from the probabilities and this
is something called Monte Carlo sampling
if I have the situation that I want to
know about
I just sample directly from it and get
the probabilities
this is a very simple scenario if you
look more into a probabilistic
programming you will come across
something called Markov chain Monte
Carlo which is an additional layer of
complexity above the Monte Carlo
sampling where you don't have the
probabilities directly but you sample
from things and you gradually approach
the probabilities that you are
interested in so this is Markov chain
because it's chaining the probabilities
together and getting into something that
you actually want to sample that you
don't have access to directly in the
beginning but here we have access to the
properties directly so we could do just
direct Monte Carlo
so can we do something like that for our
mixture distributions as I was showing
you we get a mixture distribution like
the ones I was showing using some normal
distributions that have some mean and
variance and some mixture proportion the
probability that someone can't read the
question correctly so sampling from the
situation is very easy if we knew all
the parameters if we knew the values of
the means what's the average salary for
the person who answers the question
correctly was the average salary for a
person who can't answer it correctly and
what's the proportion between these two
but I don't know the actual values so
I'll have to do it slightly differently
I'll first have to infer the parameters
and this is something that you can do
once you have something called the Pro
ballistic programming language all I had
was that salary is some kind of Gaussian
and I'm interested in and the
probability of a mistake is basically a
probability that's between 0 and 1 you
can imagine it as a coin toss okay can
someone answer the question correctly or
can someone read the question correctly
yes or no and using differently biased
coin and that's something called a
Bernoulli distribution because
statisticians can't call it to a coin
toss distribution it's Bernoulli look
more fancy
ah my observed value then if someone
made a mistake then I will just divide
the salary by twelve and if some
answered the question correctly
I'll just take salary directly
this is basically how we can sample from
the distribution because now if we had
nice probability probabilistic
programming language we write this and
then the compiler does everything behind
the scenes because it knows what
distributions do variables have and I
can operate with them directly so if
something is a mistake that's a sample
from the distribution and the salary is
a sample from the distribution as well
and then my progress stick language will
give me estimates ok what's the mean
what's the variance or I can do more
computations afterwards so here you can
see two things first I'm just using the
distributions directly I'm not actually
writing out how to sample the values
from the distributions and second I can
then manipulate the values as if I had
them directly even though they are
samples from the distribution
so let's have a look how we can actually
do something like this and I have very
simple implementation here and F sharp
there are some helper functions now I
have a few types I have the type for the
distribution value and my samples will
be afloat so that's a float and then I
have two distributions that I'm
interested in and that's a Gaussian with
some mean and variance and a Bernoulli
which is some probability
and now this gets more interesting
because I'll have almost a moon out here
so here I have slightly more complicated
type for probablistic computation
and if I have a distribution and I want
to do some computations with the
distribution I can either take a sample
from the distribution or do something
with it
sample it behind the scenes and then
continue with the computations or if I
have some value I can just return the
value and then I will use if you know
f-sharp this will be a computational
expression where I just return define
the return and bind values and define my
computation expression here and now this
model is basically the thing I was
showing you before in the slide
so now my probabilistic model will be
wrapped in my probabilistic computation
and I will just take the yearly salary I
will make the take the probability that
someone made a mistake and now like I
was showing you in the slide I can just
directly manipulate with the values from
the distributions even though these are
samples somewhere behind the scenes
so here I basically just go into the
distribution and I can either sample and
then continue with the computations with
Bernoulli with another sample etcetera
or I can just take the value so this is
my program that I can just run if I
implement all the other bits behind that
so how do we actually do the sampling
for the mixture distributions or for
more complicated distributions how do we
get to the values of the parameters if I
want to estimate them well that's simple
you just define the proper distribution
and then you just write down how to
sample from it right it's easy oh these
are actually screenshots from my PhD
thesis because this stuff is really hard
and I got a PhD from Cambridge for it so
this stuff is hard and you don't want to
do this you really don't want to do that
and that's why progress the comp you
think is a good idea because it's
basically abstract all of this you leave
this to programmer to the author of the
language and it's done in the compiler
basically all this complicated stuff all
the equations sounds integrals
everything because that's what progress
the computing does just write down your
distributions write down what you want
from them and bam everything is done so
I will show you in the program I
implemented the word slowest probability
inference engine that I will create this
is my
slowest progress thick programming
language
because what you can do if you are
really really lazy you just want to know
which parameters are the most likely to
generate the data so you can go through
all the parameters you can examine all
the possible means you can examine all
the possible variances you can examine
all the possible values in my case I
have just three parameters I have the
mean salary I have the variance of the
salary and I know the probability that
someone made mistake and it's already
taking ages on my laptop so you really
don't want to do this this is a really
bad idea but it will show you how you
can then abstract it and basically leave
it up to the compiler to do all the ugly
stuff somewhere else because in real pro
ristic languages I was showing you the
computation expression before and what
this gives me is complete control over
the execution of the progress stick
program and a real world from ristic
computations they usually involve
derivations and differentiations of the
programs and this is very easy to do if
you have an ASP of the computation and
this is what you can get in functional
program or function language is very
easily compared to something more
complicated so there is for example for
a stick programming language written
enclosure called Anglican which is also
quite popular and it operates on very
similar principles just more complicated
because you don't have to deal with all
these things so as I was saying I will
do a complete enumeration but I'm
dealing with continuous distributions so
I will basically just discretize
everything this is my histogram of
salaries so I will basically take all
these bins and treat them as number of
observations in each vein and I will do
the same for the theoretical
distributions for the original gaussians
where I will discretize them and look at
the percentage of the value that fell
into different bins and then I will just
compare the two so the slowest
probabilistic language ever
so what I'm doing here is that I
basically just vary the parameters and
get all the possible parameters that I
can get for my Gaussian and Bernoulli
distribution this is a discretization
and here I will just basically enumerate
all the possibilities vary all the
parameters and then I will compute the
histograms for all my probability
distributions theoretical ones and you
can see that even though it's fairly
easy there is quite a lot of code
involved and here is my function to
actually compare histograms and compute
the most likely distribution so I will
just run everything I have here and
you'll see that it already takes quite
some time because it's calculating the
discretized theoretical distributions
for all my possible values of parameters
and now we wait and wait and wait that's
actually fairly typical when you are
dealing with any kind of reduced ik
language because these things are slow
even though you might have a very
efficient implementation it usually
takes a really long time on real-world
problems in my PhD I had to implement
some of this stuff myself and it took
weeks to compute I want to open them run
it on the stack overflow data
so I would just load the actual data
some things I wanted to mention you
usually don't work with the
probabilities directly but you work with
them in logarithms because otherwise you
have to compute products of a lot of
probabilities which will get really
really small very easily so in my first
attempt I was getting probably 0 for
everything because it just went really
really low so you work with them in
logarithms because then products of
probabilities turn into sums of
logarithms so I got my Stack Overflow
data loaded and let's get the results
that's the most likely distributions
that generated the data so now it's
basically just it created a histogram
from my values that were observed and
it's completely comparing them with all
the possible combinations of values in
the theoretical distributions so now it
tells me that the most likely value well
this is the log of the probability so
I'm getting a very small value in
negatives the probability that someone
made a mistake is 25% so that's quite a
lot and this is the distribution of
salaries in Poland so this is the mean
it's $24,000 per year and this is the
variance and if you take the square root
of variance you will get a standard
deviation which tells you that if you
declare normal distribution that about
97% are plus or minus 3 standard
deviations from the mean now you're
thinking oh what's that this is how it
actually looks so this is my estimated
distribution of salaries in Poland I was
looking at this and I was thinking okay
maybe there is another source of
mistakes in the data as well because do
people generally talk about their salary
before taxes
after taxes there is nothing about it in
the original question so I think that's
another source of noise in this but this
is my estimate if I try to fit two
gaussians to the data that I was showing
you before this is how it looks and my
amazing prolific language gave me the
most likely distributions but really you
could see that there is quite a lot of
work involved to actually get the
probabilities right etc but all I want
to do when I'm actually dealing with
something like this is to write the
setting write the model and not align
more because then the puristic language
will just take care of the rest
so how does something like this look in
the real world unfortunately there is no
progress tickling which written in F
sharp but what I'm using at work quite a
lot is called Stan which is it's written
in C++ sorry I'm not actually using
closure and Anglican although I should
there's also one language written in
JavaScript cetera but this one is fairly
efficient for real-world cases and here
you can see this is just my model
specification where I was actually
modeling more groups than just two with
properties of mistakes and these were
like prior probabilities for my normals
and it look it's bit uglier than my
formulation before but this is how it
looks in the real world and all I need
to do is to just specify the model
specify what distributions do individual
variables has and because this is I was
writing this in my statistician persona
I was writing I was using Greek names
for all variables because that's what
statisticians do and then I can just use
it by compiling the model it compiles it
into C++ and then just run sampling
that's all I need to do I won't be
actually running it here because it we
would be here for a bit but
is how it looks in the real world when
you actually want to use it on something
practical and I hope you can see that
I'm here I'm just basically defining
distributions of variables and then just
giving some data and running the
sampling because I don't want to do that
myself
so that was my slowest ever
probabilistic inference and gene and now
I think we have ten minutes for
questions
thank you
so I hope your you are looking like this
right now
so anyone feel like they want to do
write some probability distributions and
run some pro basic programming now hi I
had question about you generative
probabilities from the samples yes then
do you have to write a metric for like
fit for saying how close it is to the
histogram data how do you decide like
how close you are how close are the
histograms from afterwards to the spirit
equations well what I did yeah when I
have a histogram like this I can treat
this as something called a multinomial
distribution which is basically just the
distribution of values if you have a set
of discrete categories how probable it
is that someone something will fall into
that bin into that bin into that thing
so my coin toss distribution is a
simplified version of that for only two
categories how probable is it that
someone makes a mistake or doesn't make
a mistake and once you have a
distribution like this for let's say 100
different categories
that's the salary fall into zero to
$1,000 $1,000 to $2,000 2000 2 3
etcetera then you can use this
multinomial distribution actually
compute how likely is it that you will
see five observations in the first
category ten observations in the second
category 15 observations in the third
category and you do that by you can just
go to Wikipedia
and you get this by looking at the
probability mass function and you
basically just compute this thing and
you can do it in logarithms so you just
take number of observations
thanks logarithm of the probability and
you sum it across all the data and this
is how it looks in cold okay so here I
basically took all the data
it's my function to compare data
histograms I basically take
probabilities for each bin and here I
fold it over the data where I'm just
taking the observations X and
multiplying them by the algorithm of the
probability and summing it over all the
data so this is the probability that ten
people reported their salary in this
range that we reported their salary in
another range okay thanks so this is a
principled way to compare two histograms
in a probabilistic way but as I said if
you actually want to do with prolific
programming you have you don't have to
care about this there are only two
microphones I would have a two very
short question one technical one
slightly less technical do you consume
Stan from our because it is too hard to
consume it from f-sharp
- how do I consume Stan from our because
it's too hard from F sharp no it's
because I didn't write a wrapper in F
sharp yet maybe okay because the rippers
around Stan are from all different
languages there is one in our Python
Java Scala I should write one ear share
but I didn't yeah okay first and the
second is that in your model did you use
Gaussian for the sake of simplicity
because it has one less parameter
because none of the payment
distributions looked like gaussians at
all they are all longtail distributions
that's actually a very good question why
did I use gaussians because they are
easy normally if I was doing this in the
real world I was using I would use the
gamma distribution it has two parameters
as well shape and scale this is how it
actually looks you can see that this
models the salaries a bit better because
it starts from 0 and goes to infinity
the bad thing about gaussians is that
they are symmetric so even for my
observed data if I if I go to my final
distribution it assumes that the
salaries go into minus as well into
negative values which doesn't happen in
the real world but I can say I did this
on purpose because in any kind of if we
are dealing with probabilistic models
you quite often see people using
gaussians even though the data are not
really Gaussian and that's because now
seems are easy to work with
negative salaries I don't know if
someone in Poland reported negative
salary though so I would normally use a
different distribution but I thought
that everyone is familiar with gaussians
and I didn't want to add another layer
of confusion but the thing is
gaussians are quite easy to work with
and they are not that bad if I look at
the estimated this if you close your
eyes it looks a bit like a Goshen yeah
you can see here in the UK this is more
of us yeah it doesn't really fit Gotham
very well it would be more sort of the
gamma distribution but gamma for larger
values of scale and shape parameter are
fairly close you can approximate that
and as I said Gaussian are easy to work
with and all of people use Gaussian
where they shouldn't so we included any
other questions I have a question
because you will propose the model with
with the three parameters and I've seen
in the table the parameters could change
a little without almost no changing the
goal function and my question is about
confidence intervals for the parameters
are you able to find it out if I was
looking for confidence intervals I
wasn't looking for confidence intervals
in this case in general in general I
wouldn't be looking for confidence
intervals because I'm a Bayesian
statistician I know how to go into this
whole debate of Bayesian statisticians
and frequentists who are looking for
confidence intervals I would I'm looking
for the complete distribution and if I
have the complete distribution I don't
need confidence intervals because I know
how to complete distribution looks I
don't want the probability that mean
falls into some kind of interval because
I can even get a complete distribution
of the mean and that's because I have a
Bayesian and Bayesian super elastic
models and use for
programming so I think we have time for
one more question
did you I want to ask two also quick
questions yes one is there a reason why
except for simplicity why you didn't use
Markov chains in this example and second
is if you're looking for maximum
likelihood in your model
shouldn't be isn't faster to treat it as
an optimization problem rather than
sampling everything Oh
so the first question I answer the
second question why I was treating this
as an optimization problem it would be
easy because these are Gaussian and this
is a fairly simple model but I was
trying to show how something like a pro
stick computing system might work and
this was very easy to implement of
course you can then go and do some
optimizations create better algorithms
underneath but this is really not that
important this was just showing you how
you might do something simple and the
important part is that you can write
your pro your model in a very simple way
and then use fairly general engine
behind that to actually compute values
from the model so in reality you would
be using very complicated algorithms
behind that using Markov chains and
things like that I wasn't doing anything
of this here because yeah well my mind
would explode your minds would probably
explode that would be I can make another
talk about that I can talk for a year
about that because the range of
algorithms you can get behind that is
almost an infinite number but what's the
important point of altruistic
programming is that you just write your
model in a very simple way and let the
compiler and like the libraries deal
with the rest and they will be using
Markov chains of the using all of
different methods for sampling some of
them are inspired by physics and some
are not we can discuss that a bit later
but yeah you can do anything behind the
scenes but functional
on progressive programming is about just
writing the program and letting the
engine behind that to deal with it okay
I think it's time to finish that for a
break so I will take more questions here
if you have more questions or find me
around and thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>