<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Wojciech Turek - Agent-based Evolutionary Computing | Coder Coacher - Coaching Coders</title><meta content="Wojciech Turek - Agent-based Evolutionary Computing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Wojciech Turek - Agent-based Evolutionary Computing</b></h2><h5 class="post__date">2014-08-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rDeRIzeel6g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you very much welcome everyone I'm
glad to see so many of you over here and
this may be not a mainstream talk but I
will try to make it as interesting as I
can i come from a goof it's in self in
poland i work at the university and i
really like your anklets that's the
reason I'm here we are working with our
lunk more and more finding kind of new
applications for it I'm currently
involved in the paraphrase project which
is one of the European Union seven
program project ending next year and I
don't know how many of you is familiar
with paraphrase this is a project about
building design patterns for concurrent
computation on multi-core architectures
so we will focus on building our gern's
that work on multi-core I mean really
really multi-core computers not eight
core or four core as we have them now we
are lucky to test our solutions on 64
core machines and later on we'll do it
on super computers as well so in this
talk i will try to introduce you to
agent-based evolutionary computing which
are two definitions will try to explain
this is the agenda actually I try to put
it one under another but it's hardly
possible so i made it a bit more
complicated starting adductors that
processes i will try to explain what's
our agents what's are they used for what
where they used for what's the history
of free lagged agent white can walk and
what's evolutionary computing and
getting from this to our implementation
of agents in evolution later on to
something that you are probably most
interested in which is application of
airline in agent-based evolutionary
computing this is our task in paraphrase
to test results of paraphrase project in
an application this is a kind of
computational intensive subject
computationally intense
application this evolutionary computing
we use agents to do it this to solve
particular computational problems i will
get into details it later okay so
starting at the very very beginning and
with a little of a history just to
introduce you to to the agent paradigms
everyone knows probably what is actor
model as this actor model is somehow
considered basis of airline processes
and basis of airline concurrency model
which is not totally true but to some
extent it defines an actor a universal
primitive which can send messages
provided it knows the address of the
actor which can receive messages and
react appropriately and it can create
more actors it was proposed by by Carl
Hewitt back in 73 and well further
development of this model will evolve
over the years but the basic assumptions
are remain the same actually the model
was a bit premature you might say at
that moment in Erlang I'm not explaining
the details of our long because all of
you probably know it so you might say
that those assumptions of actor model
are very similar to what processes in
Erlang do there is almost set of
identical assumptions besides of that
actors do not assume single-threaded
execution as processes in Erlang do in
Erlang if you executor single process
you have a single stream of instruction
and actor can be parallel in execution
itself inside ok so it was 1973 when the
actor model was defined and officially
991 when the first airline was released
and the work started in 1985 so of
course later on the airline supremacy
and hopefully it will last for long time
after the symmetric multiprocessing was
introduced to the evm and after
multi-core processors were made popular
and and well more and more coarse are
becoming available but what happened in
between what happened in the meantime
there was a model for computation and
actually there were some implementations
but all this time you could call a dark
era of shared memory concurrency this is
the time where single threaded cpus were
made faster and faster we faster clock
with smaller smaller size and more more
and more transistors in it so the shared
memory concurrency was kind of
sufficient for this for this model later
after introducing frets and multi
threading on a single core it started
showing big problems and right now in
multi-core architectures it is obviously
insufficient however this dark days the
universities were kind of carrying on
with the ideas of actor model defined in
back in 73 starting in 70s even a little
before the girl whose first paper and
actors and in 80s the theory of actor
model of sorry agent model of agent
paradigm has been developed this agent
paradigm defined an agent as a universal
primitive which which the definition
starts a similar way as an actor which
is a computer system situated in some
environment that is capable of flexible
autonomous action in order to meets its
design objectives you might say it's not
very precise and you will be perfectly
correct saying that because this is only
one definition of agent systems of
agents there were many many other
definitions and those agents weren't
were never actually defined formally to
one common definition but many people
worked on
this idea of actors of their further
development of further applications of
this actor model too well variety of
domains to model interactions between
autonomous beings the multi-agent
systems have been defined these
multi-agent systems well simply sets of
agents that could coexist in some way so
the assumption was that these beings are
independent they do not share state they
do not share data they do not have a
global control system they do not even
share the aims of their existence so
each agent had only knowledge based on
observation whatever the observation was
and it had the ability to communicate
with other agents with a synchronous
messages as in actor model so a bit more
added to actor model as in terms of aims
and a bit more a bit more like scientist
like doing make it more complex it will
be better so different different things
were added to this model a synchronous
computation so we needed autonomy and
this autonomy of agencies probably the
most common term for all the definitions
of agents very a huge amount of work was
put into defining new versions of agent
system multi-agent system in different
domains in different applications
solving many quite complex problems like
for instance heterogeneous systems
integration the agents back in the 80s
actually were able to communicate
between heterogeneous systems so we had
a virtual machine connecting different
systems even with agents written in
different technologies these agents were
able to communicate that was one of the
of the aims of the assumptions another
thing was agents mobility there were
experiments with agents written in a
shell comments and
agents able of sending themselves to a
different computers over the network
executing some code over there and
finding way to move somewhere else this
included code and state migration so you
could imagine a code going to your
resources your computational resources
to your data with stage to perform this
computation more efficiently and then go
back so this kind of stuff was
considered interesting later on the
scientific world added even worse things
to agents like pieces of artificial
intelligence so knowledge representation
understanding in exchanging and
knowledge using so basically the worst
phase of AI the anthologies ability of
understanding spoken language written
language of human beings ability of
communicating with human beings of
simulating behavior assume of human
beings at this point this paradigm has
become such a huge thing that it
couldn't work it couldn't be practically
applied in any domain so this created
this free lacked creature with free
basic assumptions the conferences in
80's and 90's on agents world is divided
into three parts actually one after
another one was about model of
computation so the parallel a rather
concurrent computation one was about
heterogeneous system integration which
was rather and still is rather important
issue in distributed systems there was
even something and still is called
foundation for intelligent physical
agents fipa organization which defines
standards for agent communication they
managed to define standards of
implementing protocols of communication
and over these protocols a language how
agents should communicate went to
another so this
this was a huge amount of work to do
this and to make it work and later on of
course this distributed artificial
intelligence was all put all over it and
and well this creature couldn't walk
very far so actually this is a shame
that this amount of work somehow passed
unnoticed you can find this term of
agent in different papers right now used
in many random situations you can even
tell why this this notion is used but
that's what was left in the 90s there
were several quite good implementations
of this agent paradigm including fee per
standards which mean that the agents in
let's say Jade which is the most popular
agent platform could even migrate with
the code and with the state to a
different note there was a virtual Jade
machine connecting heterogeneous nodes
whichever whichever computer could run
Java could run Jade and it could be
interconnected into one single virtual
machine and it was done it was working
very inefficiently only hundreds of
agents could exist on a single node well
we actually made an experiments to show
you how inefficient these
implementations where we convert some
features of these of these platforms to
20 rank because we like a rank this is
the first two dimensional chart i will
show you today I'm from a university so
I have to have this kind of stuff in my
presentation okay so this is the
creation time of agents compared to
airline process creation time the blue
one is something called magentic the red
one is Jade and the ER long is yellow
and this scale over here is not literal
actually both of them died about 1000
below 1000 agents this is the limit of
system threats you could start on this
machine we didn't tune JVM we didn't
tune our language real machine before
this test so that's the limit
actually quite important quite
interesting how many processes we could
start in airline that's 1 million
processes still 002 second per process
to start so quite efficiently that's
that's what we like right another test
involved messaging this is messaging on
a single node were in Java based
implementation you had well we didn't
wait it be above 1000 you you can see
that the Jade implementation is rather
correct because it doesn't depend on the
number of agents the magnetics
implementation is a sport as it causes
well it takes my way longer if you have
more agents this doesn't make any sense
but this is the way it was implemented
and of course in her lung again you you
have several orders of magnitude better
solutions and even in a distributed
configuration where you have up to 20
nodes this was number of messages
exchanged between randomly selected
agents or processes on different nodes
and round trip time measured so as you
can see both java-based implementations
depend on the number of of computers so
the bigger the cluster the worse it
works and up to 20 the airlink well kept
pretty much the same we know that there
are some issues with really really big
clusters of our long BOTS we didn't have
a chance to to verify the basically
that's it was also another point okay
actually there is one thing in common
already done between airlink and agents
this is called exit hour-long
experimental agent tool this is an agent
framework HIPAA compliant engine
framework implemented in Erlang and it
turned out that this implementation
which integrated some AI libraries and
all the protocols defined by this fib
organization cost Erlang to work slow
this is not probably to step into
correct direction so just to sum up the
this agent part a huge amount of work
huge amount of specification and
implementation that really worked which
never almost never been applied in the
industry which is a shame because those
standards were pretty good at that time
but the implementation was based on the
JVM or sometimes C++ and the performance
was simply not not enough and the huge
problems with with memory those
platforms experience just made it
useless in industrial applications okay
nevertheless we like the assumptions of
of the paradigm so the set of autonomous
beings doing something on their own
being selfish can be used to model some
bio-inspired environments as we for
instance a kind of selfish we have our
own aims we have some common goal if we
are organized but we tend to do some
things for ourselves and it kind of
works so we didn't drop the idea we
dropped the implementations and the idea
of these agent systems can be
successfully implemented and used in
many different in many different domains
like for instance the one I'm going to
talk about today which is evolutionary
computation I don't know how many of us
familiar with this this idea maybe with
basics mostly okay so just briefly tell
you the story what it is about this is a
group of computational intelligence
method that's they call inspired by the
mechanism of biological evolution and
they are suitable for solving some
particular optimization problem not all
optimization problem but there are some
more suited to the particular
optimization problem I will focus on
genetic algorithms today
which is actually the last one you would
use coming across a real-life problem if
the problem is as hard that you cannot
think of any better method any
analytical solution or any better
heuristic to solve the problem you can
always almost always use and genetic
algorithm so it is pretty much universal
because of that it is often used when
it's not necessary but because it's also
very simple to implement this is very
very popular in many domains you can
find implementations heard about
implementation Australia in scheduling
wine production using this kind of
algorithm glass so that you can get as
much as you can from a big sheet of
glass and things like this I know
scheduling trains and planes and things
the different optimization problems ok
getting briefly through the classical
version of this algorithm you randomly
select a set of solutions you have to
represent what what a solution is so for
instance if it's I don't know finding a
path from one note to another in a graph
this will be this list of notes getting
from one place to another and you're
trying to find the shortest one if you
want something like this or this is
simply the the schedule of trains one
schedule schedule of trains and you want
to somehow find out the best one for for
your needs so you have this initial
random set then you have the general
genetic operations that take this random
set or this set in a next iteration and
somehow convert it modify it so that it
can generate a new set this new set can
contain some solutions from the previous
set and some new solutions some some are
removed and repeat until some condition
is met for instance good enough solution
is found these methods are applied in
situations where you actually don't know
if you found the
final best solution because you have no
way to determine if the solution is the
best you probably have a global optimum
but you cannot tell if it's this one the
only thing you need to know you need to
have to use these methods is a way to
actually evaluate a solution so if you
have several solutions you need to be
able to tell which one is better and
which one is worse so this is typically
something you can tell if you have a
schedule than the one that's the
shortest let's say if you have this
glass cutting problem the smallest the
drop of the the butter dissolution so in
the first stage of the algorithm you
remove some subset of worst solutions
later on you do the crossover so you
create purse of solutions and use their
genotype are actually the pieces of the
solutions to create another correct
solution using this this crossover
operation creates a new solution and
later on there is also operation of
mutation defined to slightly modify the
new solution it is done from time to
time with low probability just not to
have a you know close population which
will never generate anything from
outside so the audience is as simple as
this these few lines of code is what you
need you need to define the selected
function and the transform function and
this top condition once you have this
the this this will work that's why
people love it that's just
very little to put into it to find out
what it will get kind of optimal or just
good solution all right this is the
version which you can probably find on
Wikipedia so it's as any very well known
algorithm has some drawbacks this one
has quite many it is inspired by
biological evolution however it is
sequential so you do not have
interactions like in real population
from time to time between randomly in
randomly selected moments of time you
don't have actually the method to get
out of local minima which is the
probably biggest problem if you have two
solutions located in a local optimum
which is let's say over here then it
will take a very very long time to get
out of this the this local optimal
infant find the global one only
typically only using mutation operations
so actually randomly selecting something
different so these problems were the
basis of our research and our
implementation which we finally get in
there like I will get to our luck in a
moment okay so we have those eight we
have ideas we have evolution we created
something called age this was an idea of
how to use the agent paradigm to
overcome the drawbacks and the problems
with disgust classical evolutionary
algorithm so we define as simple as that
a solution agent it will be an hour not
just a vector of numbers or something
like this but this will be an autonomous
being let's say we define a set of these
agents so we have a population of agents
and we can define their behaviors what
they can do they can meet they can
multiply they can die and we let it live
and we shall see what happens right so
we needed a synchronous the problem is
that it's if you want to do is in non
synchronous way without stopping and
seeing who's good who's bad and removing
those bad ones so we filed any points of
synchronization you need to well solve
the issue you don't want to them to stop
and still tell some central system who
should die and who should cross over
again so we define something called
energy in the system which is split
between the agents so each agent has
some amount of energy and depending on
this energy the agent can do particular
things and can't do the other and the
operations the interactions between
agent cause the energy to pass from one
agent to another and in such case we
have the first the most significant
difference we have the wrong number of
agents in the population in classical
solutions you had just an array of them
and the only assumption is the total
energy is constant so that we have some
control on this population its will not
explode to infinity or it will not die
out so in such case we also define a
solution on how to overcome the problem
of local minima and we found something
bio-inspired again so we defined this
concept of islands this is actually this
same thing done several times for
different populations so we have
evolutionary algorithm in parallel
actually with very small interaction
between between one another but from
time to time one agent can just learn
how to swim and get to another island so
they can migrate and this actually
solves very well the problem local
minima because if these two islands are
in local minima and the global optimum
is somewhere in between then if one I
agent moves from
into another it may eventually find the
better solution okay so the algorithm
independently and autonomously and in
parallel decides what to do with the
based on energy so if the energy was
high the agent could could reproduce and
the reproduction cost passing some
energy to the new agent so the newborn
agent had some energy at so you know
starting point if the energy of agent
wasn't high enough to reproduce the
agent had to fight for energy so had to
find another agent and decide which
one's better simply calculating fitness
function and then some piece of energy
was transferred from one idea to another
and once the energy was reduced to zero
then the agent simply died so was
removed from the system there was an
action of migration with very low
probability as the action of mutation of
new agents okay so this was like maybe
10 years ago right and we implemented it
sorry in Java and this was the small
improvement in what we had in a
sequential version so it was impossible
to implement a huge population of
autonomous and concurrent agents in Java
because of Java so we only implemented
islands as fully as synchronous so
inside an island this was still almost
sequential algorithm but going along
these rules i showed you before and the
islands just evolved according to the
cpu power applied to a particular java
threat okay so this gave way better
results than the classical solutions for
many benchmarks with it but that was
still not what we want
we wanted to have it fully a synchronous
and the only way we could do it without
wasting your life waiting for the
results was in Erlang so that's where
the air like really solved the
scientific problem and nothing else
couldn't actually at at that point so we
made the implementation where each agent
which solution was a long process and
these ere long processes decided what to
do when they had their their CPU time
and the scheduler actually decided
somehow which agent could take action
when so we somehow pasts to the
scheduler decisions and what will happen
next so we didn't have any point of
synchronization in this in this
implementation to implements this in in
practice we needed we needed a method to
meet two agents agents need to meet to
reproduce on the right side and to fight
on the left side so we define a four
processes of fight death migration
reproduction and each agent once it had
a time to decide decided on a based on
its own energy what to do so if it
wanted to fight it send a message to the
fight the process that it wants to fight
with information about its energy and
its fitness once two agents applied the
fight was conducted and the messages
were sent back which one survived which
one got energy which one lost energy and
once the agent is noticed that his
energy is zero would simply send a
message to the deaf arena arena to to
remove it from the system migration
arena quite obvious and the reproduction
airing I could create new agents by the
reproduction operation okay so actually
all the computation was done in the
processes themselves because what costs
here is messaging
and calculating fitness function I know
the dialogue is not well suited for a
computation but it turns out not to be
the biggest of our problems we had a
rather simple function i will show you
in a moment so each agent once is was
created in a process of reproduction the
first thing it did was calculating its
fitness once it new its fitness it could
send this fitness to fighting arena to
decide whether it wins will conquer
someone or not so the conch computation
was quite distributed here and the
messaging is what's left ok so talking
about local minima this kind of function
is what we took as our benchmark this is
quite simple rhetoric in function
there's the equation the a is exempt to
be 10 and the X changes from minus five
points something to five points
something the thing is that you don't
have a strict definition of number of
dimensions so this is the actually
two-dimensional one and we tested it on
1000 dimensions you can have as many
dimensions if you want so this
optimization problem gets kind of
complicated in such case we tested it on
64 I islands so 64 simultaneous
evolutionary algorithm art where we used
and the hardware we use recently was the
one note of our supercomputer in
computational center in Krakow we have a
zero supercomputer which has 25,000 400
something course computational course
available these are not uniform course
there are some GPU cores some FPGA
course and about 17,000 of
general-purpose CPUs and the single node
of this of this computer is 64 core of I
think 88 CPUs this is one hardware note
with as much memory
you may need ok so we run it on a 64
course getting actually what we wanted
so we got new evolutionary algorithm
which is better than we used to have
this might be a bit of confusion there
are results 48 264 course these tests we
ran on a hybrid and concurrent version
the concurrent version is this fully
concurrent solution where each process
which each solution was a process the
hybrid version is the sequential islands
versions so if you had a hybrid eight
this was 64 islands calculated
sequentially implemented in Erlang on
eight core machine and this diagram
shows number of reproductions so number
of new agents new solutions created and
the fitness of solution so how many new
agents have to be created to get the
solution you want to make it a bit more
clear i will show you just two of those
curves for 64 core and what we got here
at the first the algorithm of hybrid and
concurrent are pretty much the same but
at the end it turns out that this
concurrent version can be up to twenty
thirty percent butter which is quite
significant this Argan behaves totally
differently than the sequential version
because airlink provides something like
fully concurrent evolution this is the
the only way we could do it in at any
time and actually right now this this
solution is presented in Australian
evolution computation conference when it
got award of the best papers this is the
this is something big in the evolution
word in the airlock well yet another
application of of this this jeweled is
this great virtual machine to something
totally different
we like the way it works but we also
found a huge issue here and well this is
the issue this is the reproductions per
second depending on the number of course
on our 64 core machine and non-current
EVM 16 something we have the improvement
so it scales up until a 48 course in
concurrent version and in hybrid version
until 40 course above the limit we have
a reduction in the total number of
reproductions in the total performance
of whole system so we are adding more
course and we are getting lower
performance I'm glad to be here to
discuss it with the guys implementing a
vm what's going on I don't I know that
there are tests on this kind of machine
this is quite unique because this is a
uniform machine this is not a
distributed system you can have erlangen
hundreds of nodes each eight core and
this works one on a system with 64 core
this is what we are interested in
paraphrase this kind of doesn't scale as
we would expect it to and well this must
be solved because if we're lying is
supposed to rule the multi-core then
this cannot behave like this of course
you probably can tune it that's what I
expect to learn here but this is not
good enough if you have to tune it to
every single application it should just
work no shelf and handle this this
number of of course and even more
preferably we kind of think we know
what's going on but it needs to be
verified the problem is with message
passing so even have a single EVM then
the message are passed in a blocking
manner so once the messages sent the
whole virtual machine freezes for a
while of copying memory if we have a 64
core this is lots of core to stop for
copying memory I need to confirm it with
we've guys implementing it but it looks
like this is the reason okay further
steps we are planning to do we have to
implement paraphrase patterns into this
into this solution of our sins and make
it more general to solve many different
problems of course this function i
showed you is just a test that we we
have test with many different function
functions and of course some more real
life scenarios like the job shop problem
and this glass cutting and things like
this so we are aiming at some real life
applications as well but first well we
need to develop tools develop methods
that's that's what we're responsible for
so that's the that's the aims for for
future and will definitely work on this
and we hope to get really nice airlink
tools at the end of paraphrase so i
encourage you to check what's going on
in paraphrase project you can have a
very nice design patterns which you use
in a one single line of code which will
do all the concurrency for you that's
the aim and we are working hard to make
it work this way okay that's that's it
thank you very much and thank you
if you have any questions I will try to
answer well before i head over the tons
of questions I must say it's really nice
to hear that not only companies can
build their products on airline be sold
for thousands of you can dollars but
also that Papers written in working with
airline in new communities can get best
award papers in other conferences
outside outside the community hardly a
product yet but sadly you won't get
thousands of millions of euros in
research but yeah I was wondering if you
find that our line is suited for as a
general framework for implementing
agent-based simulations and so on in a
more broad term I mean now you're made
one in kind of indefinitely we're not
limiting this implementation only to
this kind of evolution we are building a
system of out of the sand blocks and it
will be available for different
applications different agent-based
simulation actually we're working on
simulation right now as well and I think
airlink is kind of good for that the
problem is that it's not very efficient
in computation so if you want this is
something that often happens in agent
systems at least those we are working on
so if you have computation intensive
applications and some agents in it it's
probably not the best choice but if you
want to have a massive multi-agent
system it should work rather nicely
right but you showed that it has some
improvement over was it Jade over Jade
some improvement a few orders of
magnitude again but this is not far this
this comparison because in Jade once you
create an agent you create a system Fred
it's obvious it will be a slow operation
you are creating data structures to
initialize this agent you're creating
several behaviors of all hooks for in
different places of the system this is
very heavy operation because this agents
of shelf offer many many services they
register under
I mean some global and local registries
and prepare some knowledge base and
stuff like this so they are just not
suited for a very simple operations
right so it's it's a it has a it's an
improvement in in terms of process
creation mainly our long has exposed her
to create the process definitely I think
yes you see us it's probably three
orders of magnitude faster so if you
need something lightweight like we do
here these agents are primitive they
have a vector of numbers they perform
computation once to calculate the value
and then they just match their energy to
some rules and send messages to
different processes that's all they do
there is no AI inside a single agent
over here there is no hardly an
algorithm there is just the 11
computation one function call and then
just one pattern matching and that's all
so in this kind of application there
long is perfect this is can have one
more question that a short one that you
sure that it improves performance for
evolutionary algorithms have you made
some performance with other search
algorithms like Nadia trees well or we
didn't compare it yet and you know in
most cases in other search all going so
you have to design the agent system to
do this search over here we spend some
time to find out how to define an agent
system that will implement evolution we
come come with some this energy this
distribution the energy passing and
these rules for that in other algorithm
ization algorithm's you need to find out
how to convert a sequential optimization
of whatever kind to an agent system to
fully concurrent implementation which
will not have any synchronization points
because that's that's the aim oh it's
quite a hard task but it's kind of works
so we'll probably try
yeah very very interesting work I have a
question regarding the evolutionary
algorithm so as I understood you're
applying the fitness function to
individuals whereas in there's a theory
that in natural evolution the fitness is
more attached to the gene and some
people say that this is actually also
the reason that there is death by H in
higher animals so they wouldn't they
wouldn't compete for the energy with
their own offspring yeah is there a
concept of an agent dying of H in India
types of algorithms you know the this
could result in getting worse scenario
since worse solutions instead of better
solutions if you found a good solution
you want to keep it and you want to find
even better and if you kill this good
solution then you will just be left out
with something that evolved out of it
but is worse if we had it before
reproduction excuse me if you kill it
before it has a chance to reproduce well
but the reproduction does not
necessarily mean that the new solution
is better in most cases it will be worse
so it in really most cases you notice
this diagram over here shows the number
of reproductions in this in this process
this is in hundreds of million of
reproductions so this process takes a
while to to finish even as though this
function is pretty simple to calculate
so we have computational power we do it
this way without getting I was just
wondering because that's the way it it
works well in in nature we actually
considered it once but well you have to
pick some from the nature it's not
necessarily true that our generation is
better than the previous one
thank you I i wonder how does this
perform compared to doing it in like a
low-level language like like just
writing and genetic optimization
algorithm you see or or with in our or
whether whatever is it actually
performing better or is it you know the
the point we're trying to make here is
not about the actual time performance
but about the quality of algorithm how
many reproductions does it have to make
to get the solution get the proper
solution and over here you don't have
time actually you don't have the donor
how much it took actually looking at
this diagram you can see that sequential
version here in airlock is almost twice
as fast in the in the number of
reproduction generated right so it will
work faster this sequential and so far
because we have overheard of creating
new processes and of communication if
you don't have it you simply calculate
the fitness that's all you do and over
here in this in this blue implementation
you have to send all those messages and
and handle creating processes handle
memory by EVM and so on so we don't know
how good could you implement it in in NC
or in assembly but that's the point here
is that we introduced a new algorithm
fully a synchronous one you probably
could do that in C but this was be
rewriting ever log and see right once
more okay thanks
you introduce the concept of islands and
you also said that the energy of the
whole population is constant so then the
islands themselves they have a sum of
the energy of the agents living there so
different islands have a different
energy in total did you do anything
based on the most feat islands and well
the even a high-energy island can be in
a local Optima not a global one and so
what's interesting in this all going
that is that island can die if every
single agent on this on this island this
goes down to zero and the final agent
will migrate out then the island remains
empty and of course a new agent can come
to this island to see what's happening
there just finding no one well it will
simply lock waiting in one of these in
one of these arenas and wait for someone
else to come to this island so this can
happen measuring the quality of violence
this was also one of the ideas like the
people from Poland right now migrating
to UK right in why they do it and so
will they create better children in UK
that's that's actually the sort of
question so the idea behind it is simply
to have several algorithms run
separately and from time to time just
try to mix them so currently we do not
evaluate islands as a whole any other
question well thank you very much thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>