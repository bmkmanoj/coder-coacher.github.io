<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Reactive Design Patterns - Roland Kuhn | Coder Coacher - Coaching Coders</title><meta content="Reactive Design Patterns - Roland Kuhn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Reactive Design Patterns - Roland Kuhn</b></h2><h5 class="post__date">2015-11-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/r4bJqgqpsIQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">that I can cover in the remaining time
so my name is volant call i'm working at
typesafe which is quite awesome because
I'm paid to do open-source work that's
fabulous I really love it I'm leading
the aqha project at typesafe but today
I'm not talking about acha I'm also
doing something else namely I'm writing
a book called reactive design patterns
this is currently available in the
Manning early access program and
hopefully soon finished it has been
going on for quite a while but that's
what happens if you write a book next to
a day job I'm in chapter 14 of a planet
number of 16 so shouldn't be too far off
you can use this code 39 k UHN to get
thirty nine percent off if you want I
will talk in this presentation I picked
a few things that are in the book but
just a very small selection to well give
you an introduction of what is it what
this is all about so reactive design
patterns this reactive prefix um isn't
that just a marketing gimmick that's
what I mean people usually say or ask or
assume well sure I guess some people use
it that way but for me it's actually
something quite serious I'm a co-author
of the reactive manifesto and the point
of that is not to do some marketing buzz
worthy thing but to establish a
terminology to set the stage in which we
can discuss the problems that we are
facing today and that we will face for
the foreseeable future so a short
introduction into what reactive is all
about imagine you write a service you
come up with a brilliant new app and you
try it out and then people start using
it and at some point you reach the
capacity that one machine can give you
you deployed it somewhere
it's on one machine that is handing all
the requests but this has a limit it has
finite memory it has finite CPU at some
point you can you cannot serve more
users on this one box what do you need
to do well of course you buy compute
power you you buy all the resources from
the cloud which means that you will now
not have one machine that the systems
are running on you will have multiple
machines sounds good in theory only it
completely changes the game in some
respects you cannot write the same
program the problem in the same way and
expect to be able to use like all of ec2
magically that's not how it works I
guess most of the people here in this
room know that so we need to think about
how we structure our program because if
an incoming request arriving at a at a
host which handles it triggers some
actions at that host and in order to
answer the request we need to coordinate
between all the nodes that we deploy to
let's say we scaled up to a thousand
nodes and we need to ask all of them for
consensus on something then this
coordination overhead will completely
kill our performance will completely
negate all the performance gains that we
hoped to achieve by paralyzing onto
multiple machines this means that we
need to partition our problem such that
we do not need to share state we do not
need to coordinate between these hosts
so we have a distributed program that we
will need to write in a different style
than we wrote it before what we gain by
that is elasticity if we do that we can
dynamically add and remove resources to
our application deployment if we just
double the number of nodes that we have
in the cluster then we should see
something like double the performance if
we did it right and if we don't need the
performance like you might know netflix
has an enormous fleet of servers that
they
to run the the video streaming but there
is a difference between different times
of day in in the bandwidth that they
serve the difference is a factor of six
so it's it's like a curve like that and
if they kept the maximum deployed at all
times they would waste roughly half the
money so scaling down is as important as
scaling up if you want to also have the
cost-effectiveness that is promised by
the cloud so that's what elasticity is
about and this is the first pillar of
what reactive is all about the second
one is resilience resilience talks about
if if you have something and you deform
it how does it have the ability to get
back into shape can it be repaired or is
it completely broken afterwards we of
course do not want our applications to
fail in the face of failure there are
various things that can go wrong we can
have normal programming errors that stop
our program but we can have machine
failures we can have network outages we
can have power outages any sort of
failure it that can bring down any
machine in our network now if you want
to have an application that stays
running that keeps running when failures
occur you can defend against certain
kinds of failures by managing them on
the machine by trying to catch them and
repair them but there are always cases
that you cannot catch for example
someone unplugs it from the power
nothing you can do the only thing you
can do it in order to subvert survive
such a failure is well to go beyond a
single machine it's the same thing again
we need to distribute the problem we
need to distribute the program we we
shall not put all eggs in one basket and
that again means that we are
distributing we're doing distributed
computing again we need to write our
program in a different fashion than we
did before in order to fully benefit
from it
in this time it's not that we need to
implement share nothing for performance
reasons this time we do not want to
share things because we want to minimize
coupling between components so that
failures Don't Ask Don't cascade if one
component goes down due to a failure it
should not affect or infect all the
others so that they go down as well so
that's the second pillar of what
reactive is all about so these are the
two main characteristics that we want
our programs to have we want them to be
able to scale up and down and we want
them to be resilient to failure result
of this is responsiveness that's the
trait that a reactive manifesto puts on
top of the image that is in their
elasticity leads to responsiveness in
the face of the Ryan load so by being
able to scale up and down the capacity
of the system we can adapt to the load
and stay responsive serves user requests
even when there are 10 times as many
users for example and resilience makes
it so that we can stay responsive under
failures the system responds so user
user makes a request and and there will
be a response back from the system
because it's resilient this response
might not always be the successful one
because a crucial component might really
be degraded or I mean a transatlantic
cable is down you just can't talk to the
u.s. right now from Europe yes that that
can be but it's then still better to
respond with a failure because you have
properly decoupled the components so
this one can still respond with a
failure if even if it cannot contact
that one anymore so that's
responsiveness we give users of the
system feedback on that things are
happening and that makes them a lot
happier there were studies this morning
someone showed studies that this
improved
so responding faster and giving people
better feedback responds in more sales
and more I'm like four words anyway so
the second one well I said we need to
decouple things for elasticity we need
to share nothing if possible so as
little as possible in order to minimize
coordination and contention and so on
and for resilience we need to decouple
components such that bad behavior
failures do not leak from one to the
other but what this also achieves is
that we have clear boundaries between
these components now that also contain
implementation details much better than
before we can segregate the system along
the dividing lines given by what
responsibilities I have in my system I
have a component that has the
responsibility to store files and it
does only that and I have a component
that has the responsibility to interact
with users and modify these files may be
and they are completely separated from
each other which gives us all the
runtime benefits resilience and so on
but it also enables us to split up this
task such that two teams can work on it
without stepping on their toes they are
also decoupled during development this
by the way I think is is the core of
what microservices should be about it's
the single responsibility principle that
we are using here which leads us to
another result which is maintainability
by decoupling we have enabled all these
components to be developed at their own
pace so that we can yeah well have teams
working independently of each other
without so we don't really not only
reduce the runtime coordination we also
reduce the development time coordination
between the teams this is all mirrored
then last on the reactive manifesto
there is a fourth straight and that is
message driven i present it last here
because the others so we have elasticity
and resilience as the desirable
properties of our implementation we have
the high level benefits but all of this
needs a foundation on which it is built
and well as we've seen these systems are
distributed the serrated systems are
characterized by the need for
communication you have components that
are not local to each other so you
Wilson need to send messages from A to B
and this is in your face I mean you see
it everywhere messages can be lost
messages take time to travel from A to B
these are characteristics that are
different from making your local method
call so communication between components
asynchronous communication is at the
core of these systems and this is why
thinking about these is vitally
important if you design such a system
and it really concentrates on the
communication protocols on the
conversations that happen in your system
you need to optimize the communication
paths just like you do it in a human
organization it's really the same
problem if you have too much
coordination over had too many meetings
and so on your projects don't make
progress so it's the same thing here
software components also talk and
shouldn't be too chatty and so on it
doesn't really matter how you do this
communication I mean there are many
different ways to do this people say you
can use our PC well I don't personally
really like our PC rest is something
close to our PC it's also request
response but the focus is more on on
transmitting a request and then
asynchronous getting something back I
like that a bit better but well you can
have message queues message brokers that
send things along or you can use actors
of course I mean I'm architect late so
i'm a bit biased here I admit that but
it doesn't really matter the import
point is that you need to be aware of
how messages and how information is
flowing in your system and you need to
model that explicitly so this is the
summary of how I'd like to view this is
what reactive is about the values at the
top row that I mentioned are not the
only ones you can you can find more I
think these are the most important ones
at least that I could identify so far
and we have these two pillars elastic
and resilient and we need to think about
the messaging that happens in our system
so so far for an introduction now in the
rest i will show you some patterns that
are useful when implementing such
systems that can be really helpful first
we look at an architecture pattern so
this does not contain code this is
really about how you structure the
application and as I already mentioned
microservices the rest of single
responsibility principle I call it a
simple component pattern a component
shall do only one thing but do it in
full this means it has a responsibility
it does it and it does all of that
responsibility this is of course not
knew not new at all that the earliest i
could find was this book by demarco from
1979 where he said max the goal is to
maximize cohesion and minimize coupling
to find your components so you need to
find those pieces of responsibility that
really stick together and that that
cannot easily be disentangled so you
have one piece over here and you have
one piece over there but between them
you have clear boundaries this
responsibility is only on that side and
the other responsibilities on this side
so if you have a text editor with a
spell checker for example the text
editing is a responsibility the spell
checking is a responsibility but they
really don't have anything
do with each other really you might want
to combine them in one program in a text
editor overall but the editing
capability can run well the spell
checker is down it's not really needed
and you can also run the spell checker
on the finished document without being
able to edit it anymore so these are
completely different responsibilities
that you separate and then you have a
dividing line and everything you do
afterwards you know exactly in which
pocket it goes because you sorted it by
responsibilities let's look at an
example of applying this applying this
pattern the example will be a batch job
service batch job service or is
something that I had quite some contact
with and I was still making doing my
physics PhD at a certain experiment so
that was like big data before big data
we had like five thousand computers and
it was there was a system on which you
could submit your jobs they would be run
it was called open PBS I think I don't
know who knows it here and there were
several interesting aspects so you
submit jobs um could be thousands of
them and then there is a second step
because it's not so it's quite
contentious I mean you have these two
hundred physicists and everyone wants to
do their analysis to get their data out
to write their publications and so on
and they depend on these jobs running so
there needs to be some fairness between
what individual users do there needs to
be quotas validation rules like you
cannot really request to run on one job
on 100 CPUs you're only allowed to to
use like maximum eight at a time stuff
like that and then once you have
validated and applied the constraints
the result of a planning run should be
well you execute the the jobs that were
submitted that are currently in the
queue in this order the top of the queue
is ordered such that these 5,000 5,000
worker nodes over there I have a queue
to pull
work from ya then that's the third step
so we execute these jobs on some elastic
compute cluster nowadays I mean back
then we built that ourselves and
nowadays you just buy it or use ec2 or
whatever then the fourth point users can
later come back and see how their jobs
are doing so this is the example use
case and we see well there's one
responsibility that like we can cut off
immediately where we Rick recognize this
this is clearly separate from the rest
and that's running the things on the
computing cluster so I draw a picture
like this we say this execution this
concern here that's that gets an ordered
list of things to do and it does them
that that's a job that is a
specification that is sufficiently
precise for a team to start working on
now on the left hand side we have the
clients making requests submitting jobs
and so on and so between this and the
execution there is some sort of
coordination that needs to go on which
needs to do complex things and if you
tell someone write some coordination
that doesn't work that's not specific
enough nobody can really work from this
description so we know that this
coordination box here that is not yet a
simple component we need to split that
up so which part should have the users
that connect from the left-hand side
that will be network connections so
there should be some like network server
listens on some port and which is
accessible and that can take these
requests that's good so we need some
sort of client interface now when you
submit a job to this system what were
you what you expect to happen when you
get back the reply yes I have it it's in
hued you expect it to be executed at
some point this means it needs to be
ensured that it happens even if someone
just switches off the power right that
moment and this means that there needs
to be some sort of persistent storage we
need to put the
batch job descriptions to some storage
in order to recover from outages and so
on now this storage will also need to be
used by the execution component it will
need to retrieve the jobs so if we just
use a shared database or distributed
file system or whatever you want then
this client interface on the left hand
side and the execution on the right hand
side not even speaking of the rest of
the coordination they will need to
access the same information they will
need to make modifications to the same
data they need to update the status of
jobs and so on this means that there
will need to be coordination at runtime
between them then need to be some locks
or transactions or whatever you have but
it also means that the teams in
developing these aspects will need to
know how this space is managed there is
a big possibility for these to step on
each other's toes so this is not good we
need to split this out this is why the
next step looks like this we have this
client interface we have the execution
component and we have some storage and
we know this storage is responsible for
handling the status and so on and we
have clear interfaces for in queuing
things for asking for the status and for
the execution component to query the
thing as well and put back the results
and then well so these three things we
could let some teams start work start
working on that there's a piece missing
which is in red here and that's the the
job scheduling so you notice when you
say do some job scheduling well if you
have a really good team that knows what
that means they can maybe start working
but it's it's still a bit fuzzy so we
apply this process recursively this is
quite important we might want to
separate out different parts one part of
this is the job skeleton scheduling
needs to present this ordered list of
next things to do to the X
cution so this is a really important
aspect of it it also needs to validate
incoming requests whether they match
selection criteria rules whatever quotas
and it also needs to do planning runs
and well they are quite independent from
each other doing a validation of some
job is completely independent of of
planning the things so these are
separate responsibilities so the image
evolves like this now you've seen that
there were two steps of recursively
breaking down things and now we've
reached something that yeah starts
feeling a bit more concrete and so on we
could start working on it this is a
process that you need to do recursively
until you have reached simple components
but one word of warning it's easy to get
carried away I mean you can you can do
that too far as well if you split it
down for further and further you will
not end up with simple components we
will end up with trivial components that
have no reason to exist and then you
just create more busy work I guess there
are people who like that I don't think
that's the goal so you need to keep in
mind that there is a limit to this so
this is um the single component simple
component pattern and the example for
that in the remaining like 15 minutes I
show you some well I have not yet found
a good word for this they are not
architecture parents they are really
like code patterns that you use when you
when you when you implement things there
are some that are really well-known and
people have covered them in the past for
example the circuit breaker pattern I
just named it here because it's so
useful and this is and to show me that
you to show you what the kind of
patterns are that we're looking at
circuit breaker it's kind of an analogy
to electrical engineering that does not
quite work it's more like a shunt I
think
protect services by breaking the
connection during failure periods so
what you do is if you make a request to
an to another service and the response
does not come back in time consistently
over over some period that's a good
indication that the service is
overloaded or if it comes back with with
failures five times in a row that's a
good indication that there is something
wrong that is just it's not that kind of
transient that it's going away right
away there might be some failure that
just takes a few minutes to resolve so
instead of hammering that service with
even more requests which would be really
detrimental in the overloaded case
anyway we just trip the circuit breaker
when a circuit breaker opens we do not
actually make the request any more to
that component and that frees the
component to recover more quickly and
especially if it was an overload
situation and it also means that we get
back the negative responses that we
would have gotten back with a large time
out later anyway most likely we get them
back immediately so we can respond
earlier the system stays responsive
under failures this is the primary tool
for decoupling one service from another
service that it uses so if this fails
this can still stay operating it can
stay up and still do useful things maybe
not to its full functionality but it's
at least it can tell its client i'm
doing a degraded job here or I'm
temporarily not capable of performing my
job but it's still it stays responsive
these circuit breakers are available in
some libraries so you don't code them
yourself typically acha provides one
which is this circuit breaker thing here
in the lower middle part you just
configure it with the parameters how
many failures trip it and so on and what
the time constants are so after which
time it goes into half open again and
then
how long it stays closed and so on and
what the expected maximum service call
time is and then you just need an API
that returns the future this is crucial
you need to make it asynchronous
otherwise you cannot really use a
circuit breaker because making circle is
called is not something that you can
really interrupt that you can really
work with there is no decoupling that
you can achieve if you use synchronous
calls this is why I don't like RPC
because our PC usually focuses on
providing synchronous api's for things
that are in fact asynchronous so once we
have this center storage function that
returns a future we can just execute it
with a circuit breaker here and this
circuit breaker will monitor the
situation and when things take too long
or when things fail too often circuit
breaker opens and we get a circuit
breaker open exception instead of a real
answer from the service and then we will
turn that back into a response that we
are going to give to our client so
circuit breaker so nice I think Martin
Fowler has comprehensive articles on
that as well so I'm not claiming that n
any of this is new the next next pattern
is probably too simple to be interesting
you might think I still find it
interesting to to realize how this
pattern works the request response
pattern is the simplest possible
conversation that two parties can have
that there is no conversation if there
is just one message so there's two
messages a conversation request response
that's simplest possible and it also
make that work we need to include a
return address in the message so that
the response can be delivered to the
right recipient in a diagram form this
is these are the two participants a and
B a sends a request to be and this
dashed line means it includes its own
address and that
gives be the power the possibility the
the ability to send back the second
message to a because otherwise it
wouldn't know where or who a is well
this is very logical everyone who has
written a letter has done that but it's
easy to miss in most of most of the
modern protocols that we use because the
request response pattern is the single
most frequently used one that we have
today it is the most primitive
conversation but it's also one that has
some compositional properties if you
want to combine more complex protocols
you run into real really difficult
academic problems but request response
is reasonably simple to understand so
it's usually modeled implicitly for
example if you have an HTTP connection
the HTTP request including its headers
does not include the return address it's
nowhere in there because the return
address is implicit in the underlying
TCP connection the TCP packets each of
them has the source port and IP address
of the sender and this is how the
responses get relayed back so HTTP is
really cheating in this regard well for
good reasons and and so on but it's easy
to overlook that the return address is
actually included in acha we found in
versions one and two that it is so
useful to do this that we have this
automatic sender capture when trying to
develop acha typed I ran into real
problems and had to remove it so in
archetypes you have to be explicit about
including the return address in the
messages that you send so that's yeah
that you could call it a technicality
maybe but if you look at message queues
like if you want to do this using amqp
then there is no such thing as a return
address that is automatically managed if
you want this component to sin to that
component it will need to know the queue
name on which that is listening
and if it wants to receive a reply it
will have to own a cue itself on which
it is listening and it will need to
include the cue name in the first
message and then the second comes back
over the other q in order then to
correlate that this is actually the
request that triggered that response you
also usually need a correlation ID
because usually these components that
you have are long-lived you could have
this this email sending service and and
the invoicing component and they are not
created per invoice they stay up and
running so they need correlation IDs to
figure out what has been answered and
what not there are ways around this if
you use actors for example you can just
create a short lift child actor that you
give that you use as the return address
and then in the identity of this actor
the correlation idea is basically
encoded that's how it travels back and
forth but that's just a short touch cut
it does nothing else but model a
correlation ID so this is request
response but the last pattern that I'm
talking about is probably the most
interesting one unfortunately or
fortunately I should say it has been
covered this morning already by mounting
clip one I think better than I can cover
it here so the saga pattern says divide
long-lived and distributed transactions
into quick and local ones with
compensating actions for recovery this
pattern the formulation of this pattern
and and the inclusion in my book is a
result of speaking with people and when
we talk about macro services or any sort
of reactive systems people really run
into these questions we have a market
Micro Micro service architecture where
knowledge is distributed but these
participants these micro services are
supposed to own their data exclusively
this means if I have a business level
process or a transaction that is going
on that affects more than one micro
service we would have to have
transactions
span multiple might repair services but
for various reasons it's it's really a
bad idea to to implement that and it's
in its classical form distributed
transaction managers are not as reliable
as they should should be in order to be
theoretically safe to reason with and
their worst of all I mean performance is
not release it it's not really there
they're strong part let's just say
because of all the coordination overhead
that's clear if you need to reach
consensus between these 10 micro
services are about something that will
completely kill performance and as
Martin mentioned this morning it also
spreads the possibility for error if
just one of them is down then they will
not reach consensus and things will fail
so we cannot have these transactions so
what do we do we have use cases that
currently are modeled like that and that
use them so my hero in this regard is
Pat helland the first paper life beyond
distributed transactions goes into
detail about why distributed
transactions cannot really work and how
you should do it instead and the answer
is you need to partition your data so
that all the all the things that you do
all the operations that you perform
remain local so you partition it into
pieces and no transaction can span these
pieces or everything stays within one
realm and these realms are local things
and the second one memories guesses and
apologies talks about how to basically
implement atomicity in the absence of
these distributed transactions and the
idea for this I mean this is all not new
the same reference was in the talk this
morning sagas form elated by
garcia-molina and solemn they're already
in 1987 I start with with an example of
explaining how this works if you have
bank accounts x and y and what you want
to transfer money between them without
locking both of them how do you go about
this well
spend it up into two transactions t1 and
t2 t1 will transfer the money from X
into a local working account this can
preserve are some local database and
variants like the money is not lost
right it's just shifted from X to the
working account and then t2 transfers
the money from the local working account
to why again preserving invariants and
so on now the new thing because we have
broken broken up the process if
something goes wrong after T one commits
and before to t2 commits we need to
somehow roll back and the database
doesn't have doesn't know how to do that
because well t1 has committed so there's
nothing that database will do for us so
we need the compensating action c1 which
will just transfer the money back into
the account of X in this case what the
authors of the paper note is that
writing these compensating actions it
has the same difficulty or complexity as
writing the well the real transactions
that you want to write so this is not
something that's really worrisome or
black magic or so yeah so of course
there is one drawback or important
property this has if you have
concurrently running sagas they can now
so if they are only aware of accounts x
and y and do not know about local local
working account then for them it might
look like money is missing while it's in
flight so other sagas can see
intermediate States and you need to be
able to break your transactions up in
this way that that does not really
invalidate you your business case so it
is sometimes difficult to do that
sometimes it's not it's not even
possible and then well you cannot
distribute that's the simple conclusion
so in a bit more formal terms we can do
backward recovery if we have for
transactions the first three committed
then we run the compares compensating
actions in rivers or as C 3 C 2 C 1 the
other possibility described in the paper
is for what recovery but for that in
each save points
so you do t1 and then as part of t1 most
likely or it would be appropriate if
possible you store that you have done t1
that's a safe point after doing to t2
you have a safe point that says okay I
have done that and so on and when the
Machine crashes and comes back online it
sees that this saga is not yet finished
and it sees which part of the saga has
been committed already and it can then
start from that point onward and
complete the sequence that's for what
recovery so yeah as I said this needs to
be persistent the paper was written in
87 they didn't really have distributed
databases or yeah lost something the the
main problem that the paper that was
dealing with was long-lived transactions
and making the database more performant
now we're doing it for the fault
tolerance resilience and so on reasons
so we will need to make the sorrows
persistent anyway so in order to
probably yeah I should probably ask
other questions for that if not I can
show you some code but i am not sure
whether whether the remaining three
minutes I enough to show all of it so I
have implemented this process in a car
using acha persistence as an example and
here are just the message types and
event types defined and the general
principle is that this saga is a
persistent actor and it will do things
exactly as I wrote down when it gets the
transfer it persists that it wants to do
the transfer that's the first safe point
so to speak then when that has been done
it does withdraw money so it does the
first transaction this is a method on
the account that returns a future in
this case and it maps it to money
withdrawn when that is done it persists
that that's the second safe point the
important point here is the included ID
field because here the safe point is
committed as part of the transaction
it's done outside this means that we
might crash between committing the
transaction and doing the save point and
this means we need to make the the
transaction idempotent and well for this
I have foreseen this ID in this
implementation so that the withdrawal
method can see oh I have done this
already I won't do it again I will just
say yeah it's done oh yeah and so this
this just goes forward with all the
steps until until the process is
finished and then during recovery you
just need to figure out so you see all
the safe points that you have done as
events that come back from the log and
you figure out where to well restart
your process where you were the
interesting thing here is when I read
this paper it felt really like this is
like reactive going back full circle
search for natural divisions of the work
being performed that's the single
responsibility principle it is the
database itself that is natural
partitioned into relatively independent
components these are micro services that
own their data exclusively so it felt
reminded of many of the things that
we're talking about now in a paper from
87 which kind of makes it feel good so I
think I should come to the conclusion
reactive systems I hope I convinced you
that I mean the values are not just
marketing both there is something that
we really need to solve and these
problems that we're solving well force
us to go distributed and this requires
some new architecture patterns and tools
and so on most of them are not new most
of them are really old but well well
none of this is really dead easy and you
need to keep thinking for me this is
this is lots of fun because it's so
close to how we operate as a society it
has all the same problems of
coordination conversations and so on so
it's I think it's just fun to work with
thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>