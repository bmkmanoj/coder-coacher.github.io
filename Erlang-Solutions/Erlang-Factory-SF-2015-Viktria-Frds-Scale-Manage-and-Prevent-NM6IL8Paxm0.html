<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory SF 2015 - Viktória Fördős - Scale, Manage and Prevent! | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory SF 2015 - Viktória Fördős - Scale, Manage and Prevent! - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Erlang Factory SF 2015 - Viktória Fördős - Scale, Manage and Prevent!</b></h2><h5 class="post__date">2015-03-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NM6IL8Paxm0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so hey there before we start the quick
change assume that the same task is
given to the to develop teams
nevertheless as you can see the first
team still working hard by the second
seems to be ready and parting hon that
makes the question what makes the
difference between the two cases no so
we're these guys definitely use one but
the one that is an operation and
maintenance too for all and also might
have child so I'm victory a further the
leader of the von Bach project and today
I'm share our latest experiences with
you the experiences are related to vomit
and gain in context of the EU founded
release project the aim of the release
project is to introduce radically news
of the development technologies that can
exploit multiple heterogeneous clusters
consisting of multi-core machines in a
reliable scalable way in the context of
the release project the main task of
foam one is to provide the scalable
infrastructure for deploying thousands
of or nodes in this talk i will tell you
from what secret that is how room but is
able to scale out to thousands of nodes
to detect anomalies prevent incidents
understand your system and be your best
friend ok it sounds good but well what
kind of incidents and animal is actually
I brought you some illustrative examples
to highlight home but Kavya can help you
in real life well half a year ago we
were on site at the customer helping
them in polishing the new product just
before going on live well one bus was in
hand and pointed out with some real
problem here you can see
the first problem actually some early
nodes belonging to the same or long
cluster use different version of the
MongoDB application consider how big
would have been the surprise if this had
turned out online and actually
considering that detecting the root case
hose is not straightforward well thank
you what actually boom but had this
problem to us as an alarm well another
example I like to show you is another
alarm it says that the atty ETS count
exceeds the limit of the ETS tables on
an erlang node actually when it happens
the vm crashes in advance moombata
raises an alarm that is definitely your
last chance to prevent the antigen cool
so I guess everybody is curious about
more mad secret then let me tell us the
story so the story begins when we were
preparing for the final evaluation of 11
in the context of the release project
there were wrong question what is wrong
but limiting practice our or to rephrase
how how does one but behave on the
massive load for a longer period of time
is it reliable well actually so testing
can answer all of the questions so
testing is the testing technique that
helps you to determine whether the
system can sustain continues expected
load well this is exactly what we were
looking for so we design and develop the
socket and also development process that
had us to utilize the outcome of each
execution and to improve 11 so let's see
first the development process so it the
development process was consist of crazy
sprints
at first we started the soak test and we
left it alone at least for a week of
course we checked periodically whether
it has already crashed yeah and then we
in lies the results to find errors
anomalies and their bad signs we brought
the log files of the system and
collected the errors next we analyzed
the collected metric data by studying
the graphs river looking for signs of
overload you know when when you can see
large message queues and we were looking
for serialization problems it is very
likely to a cure when few running
processes are in the system and hundreds
of waiting processes are still there and
we also pay special attention to spikes
and repetitive patterns we check the
raised alarms and we also paid attention
to was it was the arm clear if so the
system was able to recover automatically
then it's okay otherwise we need to
improve it and next we compared the
result with the previous runs to decide
whether we improve the system or not
yeah after the collection after we
collected the problems we examine that
so actually for each other or we try to
detect the root root cause and then we
were thinking about how robot could get
in such a state was it the timing issue
maybe a serialization problem over use
of transactions global logs maybe we we
were sent to much messages or yeah and
then we quickly address as many issues
as possible actually France appears
weren't mean as the improvements need to
be validated by the next soak test at
first you know all the glitters on my
god
and next we set up a new soak test once
the system we can stable we increase the
load and let it crash again again and
again so and how we so tested one month
of obviously the subject of the so past
is 11 but as one bot is a monitoring
tool of course it monitors some wrong
note and actually the earning notes
should do something that exercises
wombat van so we employed partial bench
that commanded the Erlang notes how to
behave with this approach these are long
notes became the ninth marathon but
actually if Barcia wenge commanded the
notes divert divert became extremely
crazy so for instance thousands of
processes were being spawned within each
node and each process send huge number
of messages to each other and then they
crash because of various reasons you
know boombot monitors node by in your
injecting agent into the urine nodes so
in such a bad air in such a builder long
road this agent still needs to function
and and and provide the input Wamba yeah
but it is only one point of view
actually consider the users perspective
the responsiveness of woman must be
maintained even if it is being flooded
by huge huge amount of input from the
managed nodes so we employ mega load to
simulate users that is load testing tool
developed my own solutions yeah megaload
queried data from home but so mega load
was the one who simulated the
the Ituri tree was and actually it seems
to be ready but not because we had an
extra one but for observation purposes
it recorded everything what happened in
the soak test and we used the used its
data to improve for money so how could
one what helped us to improve boma well
so here you can see the total memory and
the process memory that are related to
the so tested one bot collected by the
monitoring mobile here you can observe
the repetitive pattern as as it's it's
it's like to be a little bit dangerous
actually we investigated this problem
and found out that the root cause was 14
scheduled activity yeah here what we did
is that we decrease this memory usage
and improve this schedule actually the
activity is an Outperform less
frequently to prevent possible outage
consider that the outage could happen
when two scheduled activities over love
with each other okay here comes another
example this page displays arms in the
system usually an alarm is your last
chance so ignoring alarms can easily
result in critical situations actually
don't take the chance react so here we
can see two and arms on the first
highlight that the cpu load is extremely
high wise second tells us that there are
more than 10,500 messages in the mailbox
of a process large message queues are
harmful as they consume a huge amount of
memory so actually we investigated and
found the root case that was a process
actually a process crashed then recover
perform any operation
and send a huge amount of messages and
finally crashed again and in an infinite
loop of course yeah so we fix this bug
and here you can see a more extreme case
of large message queues actually such
message queues predicts that the
internet slow put of the subsystems are
greatly different in this case the
weaker subsystem can be easily
overloaded so you need to find balance
ok now you can see a very very short
video that presents a great feature of
home1 that is the live matrix line
matrix can give you an insight what's
happening on your system at the moment
here we can see the cpu utilization of
of the soap tested moombah and what i
did here is to switch on and off the
matrix that is related to one of the
core on the machine on which the robot
was running ok now you can see see still
bond between where we are querying some
eggs meter and for some matrix and now
we are querying the gauges of one of the
managed node yeah now we are going for
the log files and we will request to
present old logs that is related to one
of the managed nodes we can bro
visualize the detail of a log file of
log entry and then we can go for the
alarms here you can see that I theatre
the alarms that is related to one
managed node and then I extended the
scope of of the presentation ok oh and
and went I need to note that the last
video was about the soap tested robot so
actually the soap tested warm but
was under a very very massive load but
nevertheless it was very very responsive
as you can see as you can you could see
okay but so the autumn of the sock
testing was was a big win actually we
stabilized the tool we improve the
performance reliability and
responsiveness we increased it's a
capacity and that is how many nodes can
be monitored by one more robot but
unfortunately we were still very far
from our Wars 11 but can manage between
150 and 200 notes reliably but our goal
was to manage ten thousands of nodes hmm
so actually further analysis was
essential so but here what we learnt
that we really really need to analyze
our system to know its limit okay so we
went for further analysis and we found
out the root cause was the warm at Saudi
architecture it was actually the initial
prototype and when the guys were
designed the initial prototype actually
they dedicated themselves to two tasks
the first task was create the first
proof of concept and the second task was
to ensure great scale ability to manage
thousands of nodes okay let's see so the
old architecture was a layered
architecture consisting of three layers
the the top was the rest layer that is
the main interface to communicate bit
Wamba and then there come the master
layer that provides topology services
and it is it acts as a router between
the rest and middle managers Oh
the bottom layer our middle managers
they were communicating directly with
more but agents you know they are
running on the managed node actually
multiple middle manager can exist and
they can be deployed to a set of your
landlords it seems to support the
scalability or not but the result is
about so because of some consistency
reasons the architecture was too
centralized or request went through all
the layers including the master layer
that managed the centralized data store
so the problems were request versi
realized the centroids datastore was a
single point of failure and also
bottleneck so we concluded in that we
had think about moments aerotek sure
again we dedicated ourselves to the
following goals we should not introduce
again battle next single point of
failure and then over sunrise
architecture so actually lessons learned
however yeah it was quite expensive
nevertheless good advice do not overtake
your system in advance so okay let's do
it rear high-tech trauma so here comes
the key observation grab your prop
popcorn so actually ramen wat can manage
200 nodes then 61 beds can manage 1200
notes okay but they are separated from
each other what to do well let's be the
vulva tree why not so actually this is
the new a lecturer form one where the
old one bots are the building blocks of
the new system the managed nodes are
believes and are the children of worker
movement
and as I said work on home but sadly
Osborne BOTS so we avoided the
completely implementation of the tool
and these workers on bots are the
children of the root node the root of
the van battery is the so-called methyl
on man okay so let's roll the examine
the overall system at first observe that
workable bots are not aware of each
other they exist in their separated
world so in the word of a worker woman
there exists metal robot and end it's
managed nodes this word restricts and
defines the responsibility of workable
but at the same time as not all the
nodes are visible to a workable model it
is only responsible for the nodes it
knows about well by limiting the word of
a robot we also limited the information
now it's it at first sight it sounds as
a problem but actually it is a benefit
because by this we control the maximum
amount of information with which one
worker from but can deal and now it is
very very unlikely to overload von ver
programmer ok but as you can also
observe methylone but is not directly
linked to nodes to managed nodes yeah
this is first-rate matawan what cannot
be overloaded but what happens to the
managed nodes of the dying worker formal
they shouldn't be left alone without
supervision so madam on bot knows
necessary information about all managed
nodes I mean the host the node name and
the cookie so in case of work Obama died
it realized it's managed node to another
work of alma cool
and what about matter Walmart so as I
said it is the main and point of the
system it it is also the coordinator of
the system as the vomitoria strands
plant from the users users only interact
with metal on body so metal on what can
be considered as a big router between
the users and workable much it routes
the risk requests and responses between
the users and working on bottom it is as
I said the coordinator of the system and
it's also responsible for managing the
one battery actually it's only start new
worker one but when they when the actual
capacity of the system is not enough to
fulfill a new request and it also
distribute the task among the worker one
was so I mean what kind of task can be
given to metal on but it can be please
monitor for me an extra load please
deploy ten thousands or long notes ok
cool so these are the task and this task
are distributed among the work of all
mods and as I said it also supervised
and managed workable mods so it is aware
of the free capacity of a worker woman
it is aware of the informations about
the managed nodes monitored by work of
robots and well matawan but also stops
working on what when there is no need
for die but when can it happen actually
when all the managed nodes of a working
on what was removed or or yeah so when
there is no need for a working woman
mater alma stops it yeah
and Matamoros is actually a purely
parallel approach that is the
cooperation of concurrent processes okay
and how our nodes can be deployed using
the improved system okay here you can
see a simplified flowchart and I promise
I wanted your own on details so user
sends requests via rest interface of
course it arrives to metalman metalman
bad checks whether the capacity of the
system is enough to fulfill the request
the free capacity of the system is the
maximum number of nodes can be assigned
to workable but without overloading the
system if the capacity is enough then
matawan will do nothing otherwise it's
done starts new workable but to be able
to fulfill the request then it this
route tasks among the work of Ahmad and
initialize the deployment after that it
requires the vocal robot to deploy the
subset of the wrong notes that are the
responsibility core and then metal but
wait for all the work programme wats to
finish the task and then Mohamed or cast
orchestrate the newly created our own
cluster after that of course it informs
the user what happened and and what is
the result of of the request okay so
with the improved system our go over
reached this is a distributed
application Eun in terms of persistence
the approach makes worker wombats
independent from each other that they do
not affect the scalability of the others
the reliability of the system is
confirmed by soap testing
thanks to the built-in recovery
mechanisms added to matawan but it can
recover itself and the rule number three
after any failure cool so we evaluated
form one on a toast cluster in the
course of the release project actually
here we were ordered sorry we were able
to use more than two hundred multi-core
machines to deploy instances of the end
colony optimization release well at
first we were interested in the time
required to deploy and crony to build
the van battery sorry and then to deploy
the nodes so well here you can see the
deployment time that that is based on
our experiences and here the main
observation is that the required time
can be expressed linearly with the size
of the input for instance 100 of nodes
can be deployed in two seconds let's see
a concrete example so we deployed 10,000
nodes within two hundred ten seconds
using 67 worker 1 but 2 139 machines and
besides this we observe other
interesting thing that is related to the
construction of the one battery actually
that requires 10 seconds regardless of
the number of youth worker moments so
Madeline what is beautiful approach ok
and the second thing that we were
interested is the effect of the
monitoring actually the overhead of any
feature not contributing to the result
of the execution needs to be very very
minimal so we wanted to make sure that
the generated overload the format is
money laughs so we measured how much
time there's a certain computation task
takes man boombot is only used to deploy
and measured when warmuth overhead is
minimal and measured when vomit also
used monitor denotes the difference of
the two is the overhead well we found
out that warmuth omer has minimum for a
few schedulers but it is very serious if
the number of schedulers exceed 16
actually vomit was not behaving nicely
it was very similar to the one but in
the video so it it actually not allowed
the managed node to do its actual duty
the management must played with the one
was yes so we investigated this problem
because actually it was a problem and we
found that the root cause was calling or
lung system monitor to monitor long GC
actually it's sends messages for us when
garbage collections takes too much time
well yeah then we go then we went to the
vm school and we found that this
statistic uses Erlang now actually what
you need to know about along now is that
it puts global log on the wall vm it
means all the schedulers our blood so
our solution was that we extended it
monitoring long GC with a condition that
is if the machine is really multi-core
we disable monitoring long GC with this
improvement the overhead vanished so we
measured than the execution time of the
end colony optimization algorithm with
and without monitoring the difference
between the measured values is the
overhead of the monitoring the blue star
depicts execution time when the
monitoring was turned off vies the
random we depict execution time when the
monitoring was stirred on so the maximal
overhead was less than 1.5 percent so we
consider
but that it is non-intrusive okay here
you can see a very very short video how
we performed experiences on the ata's
cluster actually it's taz yer it
presents deployment of 5000 echo notes
followed by running the algorithm itself
so we owe my fault but I have some time
so we sent a rest request to robot and
then it it is performing the request now
you can hear that the echo nodes are
coming up and up and up then we are
waiting for all the nodes and after all
the nodes and up meta moment starts
orchestrating actually in this case it
means that it's set up the master at the
echo algorithm start than all the echo
releases in each node and then with to
terminate and collect the results who so
in conclusion the erection process
establish the following characteristic
if robot the effect of the money of the
monitoring only managed nodes is is very
very minimal so one that is
non-intrusive robot has the ability to
dynamically scale out on in size and it
has the ability to deploy thousands of
long words with linear deployment time
so to concluding the conclusion i can
say that distribution is your friend
good so actually besides this moment has
many other attractive features it can
help you to deploy and manage thousands
of Everlong nodes even in heterogeneous
superclusters even in the cloud boombot
can even help you if your system usually
if usually a regular load is put it on
your system but sometimes this load
increase max very very greatly in this
case mohmmad can notice that your
cluster is being overloaded it rents
extra machines and distribute the load
on these machines after that robot can
notice that the cluster is underutilized
so it's it's removed some machines from
the cluster and release the machines
back to the provider so it helps you to
minimize your maintenance costs actually
well what can help you to prevent
outages using your arms actually our
alarms are customizable and we have more
than 25 built-in alarms we also has some
special arms for rear and in Asia and
not a good thing that these alarms can
be directly connected to page or
you-tube II and as robot the aim of
robot is to provide an hour-long
specific view of your system and its do
not want to compete with existing too of
course we support the integration of
robot to another third-party tools for
this reason we provide ready to use
applications that can channel the data
collected by one but two to these tools
and well we also automatically collect
eggs emitter and for some metrics and
lager or SAS or log n fries this all
leads you to to understand your system
better to provide visibility of your
system and to help you in detecting its
weakest part and and and improving your
system so today I told you a story about
format and I shared lessons Lord I
emphasize the importance of the so
testing actually I presented an approach
that I think can be easily tailored to
any system and can help you to to know
your systems limit it is very very
important actually the soak test is
running at the moment still so we really
like so testing I'm also presented a
counterexample about over architecting
systems so be agile in mind focus only
on one big task at once address issues
if they occur and not in advance and
finally I presented you the new era
textual format it is parallel
distributed reliable and scalable it is
able to deploy ten thousands of a long
nodes vomit is non-intrusive the effect
of monitoring is very very minimal and
we created this new architecture by
avoiding the complete orientation and we
use the old system as a building block
of the new system and actually I ask you
to remember that developing massively
concurrent large-scale software's
requires this route
really but actually all of us are very
very lucky as Iran provides me up in
support for distribution and last I
lightest brand message of home but one
that says you would love to have the
verbs who wish to focus on real
challenges rather than repetitive task
who like to understand and improve their
system and sleep tight during the night
rather than firefighting so yeah thank
you very much any questions ah ok this
is a very very good question so the
question is about what happens when
matawan but fails I guess ok or either
format itself ok so actually when Matt
alone but crashes we haven't seen it but
of course it can happen so when metal my
precious it is first restarted by the
word mountain ism that is the ER long
solution to restart systems that are
terminated unexpectedly next meta moment
and both swarmbots are i use persistent
data bases there are these these are
distributed databases but use them to to
store the actions being performed and to
store the planned actions thus if an
execution is interrupted when met alone
but recovers it can continue from
exactly the point where he where it was
and also when metal on what recovers it
actually checks the heads of the van
battery it tries to connect to all of
its work for Maude and if some of the
work of robots has died or or something
went wrong then meta moment is aware of
the information that is related to the
managed nodes belonging to the dive
worker robot and can reassign that the
orphan managed node to a new worker
moment so met alone but II so mental
home but actually not only construct the
van battery but maintain the Roma tree
thank you
yes yeah thank you very much so the
question was if mantle amba dies virco
robots can continue or or value yeah and
the answer is yes metal unbuttoned
worker robots are loosely connected and
and when metal mud crash is actually
working on but are still operates
nothing happened they do their duty they
you tease to monitored managed nodes
nothing else yeah yeah vomit on rich one
if a workable mot crashes yeah so what
happened and work of all mad crashes
actually went to work on more mad
crashes metal on what is aware of it
immediately and at first it start to
restart it's workable mod but it can
happen that it cannot be completed for
instance maybe there is a net split
between metal on button worker bombass
or or who knows and in this case it
start a new worker room but in another
node yes please
ah so the question is whether Erlang
distribution protocol is used for the
communication between the wombats and my
answer is very simple yes it is used it
is cool we do not like the rim and we
use reuse what is good thank you
so you just have had custom learning for
a few years
the
another question
okay it is a good good question actually
when we are able to restart for comet
than nothing happen when the data is
very very critical to the business then
using another built-in along mechanism
that is employed take over and failover
nodes we is this is how the problem
solved in this case so and in the most
business critical parts we can of course
use rear clusters with multi data
centers yeah any other question yes
please yes
uh-huh okay so the question is a well it
is a long question so usually we use a
one week for soaked testing or we use a
longer period of time or or or why we
use at least one week is it okay cool so
actually so there are many many problem
that can only turn out when when the
system is used for a longer period of
time I mean with the empty databases
many application can work but if the
databases is very very full then yeah
then then can come then timer woods can
come and and the internal communication
became much slower and so on and of
course so at the beginning of the so
testing each one was I think less than a
week but now actually we are able to we
cannot overload boomba actually the soft
estar terminates because we are running
out of this pace so yeah I think so
thank you and any other good question
yes please
use cases where you'll be spending of
six certain metals
yeah so for what kind of application ah
I see okay so we usually set up along
clusters where the nodes are connected
to each other in the context of the
release project we deployed ant colony
optimization algorithms these angry
terms are distributed and parallel
algorithms this is something about the
end the small ends they are trying to
curb really solve one problem and so the
communication between the nodes are are
very happy
I'm sorry for ya so how you know how the
clusters you monitoring is meshed about
mesh the long as there's a hidden node
so it will just monitor right but when I
what use cases who actually see
so ad serving for example serving at
thousands
that spurred a real-time bidding
it's a comedy wizard
and so mobile doesn't really care to
know how much I understandably one part
where are you episode so yeah
yeah so it doesn't really matter how
systems are done it's basically Ramesh
know each other what makes it easy if
they are mesh is that will have a
discovery mechanism when you connect to
one we'll go in and we'll walk its way
through and discover Thanks it's the
scary dark justice out there
okay thank you any other know then thank
you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>