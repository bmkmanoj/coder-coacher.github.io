<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory SF Bay 2015 - Mark Anderson - Push Jobs: A Scalable Remote Execution System for Chef | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory SF Bay 2015 - Mark Anderson - Push Jobs: A Scalable Remote Execution System for Chef - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang Factory SF Bay 2015 - Mark Anderson - Push Jobs: A Scalable Remote Execution System for Chef</b></h2><h5 class="post__date">2015-03-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AvHAVyk6Dx8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so my name is Mark Anderson work at chef
we're a configuration management
software company if you're not familiar
with us and the talk is about push jobs
which is this tool we built to help
solve some problems we were hitting with
chef it's the configuration management
chef there is the chef the company to
chef the configuration management system
we use chef a lotta our names is a set
of recipe it basically takes a set of
recipes to converge a note into a state
the chef client configuration management
system uses a pool model which is great
until you want push and for some things
you really do want to have a push model
SSH doesn't scale well for a lot of
people back when we started this product
search from about twenty twelve there
weren't many other systems available
that did this since then a number of
other ones have sprung up and become
popular but we didn't have the advantage
of them being available that orwell
worked out and we had some sort of
particular things objectives we wanted
so what we wanted was a remote execution
system it was robust under network and
client failure which everybody wants we
wanted execution to be gated on when a
quorum of nodes was available you want
to be able to say require ninety percent
of the nodes in a job to be available
before you started execution which was a
feature that wasn't it available in the
other systems we looked at we wanted
press in this information as close to
real time is available about whether
node was present and available to
execute one to scale initially to about
2 K nodes and that was sort of a hey we
felt we could hit that goal let's start
out with that we've been pretty happy
with that oh we got but we'll get to
that in a bit and wanted integrated with
the chef's authentication and
authorization systems chef already
distributes a RSA key to its clients as
part of provisioning so we felt that
just leveraging that was going to be
helpful because one of the big problems
of the quota system is how you do key
distribution and rather than create our
own key distribution system
why not leverage what we had and we kept
in mind through the whole thing that a
lot of our customers have somewhat
complicated networks they may have
firewalls they have may have Nats then
they have a whole bunch of stuff between
the mode under management and the chef
server so we wanted to make sure that we
support that supported that use case and
as we've deployed push into places we
discovered that customers have even
stranger networks than I ever imagined
people would create so just going to go
through a beer than just a few of the
design choices we start out when we
start working on this so our core design
falsities will took straight from OTP we
had some experience with Erlang already
it have been really successful but what
we've been building had been actually
that or Lani mostly web machine based
things so still rump somewhat new to
full up Erlang distributed systems we
decide this to still run with the
principles so don't try to be clever
with errors you can go crazy enumerated
all the failure modes in a distributed
system we decided to not even try and so
our error handling is really if it's
under supervision monitoring if it
deviates from the expected state we hit
it with the big hammer and reset it to
zero now there's still a lot of cases
that mrs. but by and large this actually
covers a lot of the cases we've seen in
practice and it's really keeps it real
things really simple which has been a
real win for in terms of implementation
for us I had a really good relationship
with a colleague whose constant question
was do we need this feature can we throw
this out I'm always the one who's the
magpie for feature so we were rescued
from my designs so we had a couple of
initial conditions at the time we were
doing this the client was assumed to be
in Ruby they're a bunch of reasons
largely we're Ruby shop with summer
lying people in it having most of the
thing in ruby was helpful we had already
had Ruby on our machines because the
chef system is written in
movie so it made for a much simpler
distribution system if you can just load
another chef check server is an erlang
one we already had some good initial
experiences with Erlang we've been
started rewriting our server from Ruby
into Erlang and there was a chef comp
talk if he hears about go about that
from South Falcon and that had been
enormously successful we've seen real
products when are laying it scale and
frankly this was the actually the
problem that was the most Earl ie to
coin a word of anything we've built to
date so just seemed like a natural
choice the other question is okay we
have the client we have the server how
do we wire them together we one's rapid
prototyping one of this reliable message
delivery we wanted it portable we needed
to have both Ruby and Erlang versions
unfortunately because of previous design
choices had to be able to brown on
Windows had a laundry list of other
possible operating systems we had to
support we wanted heart beating and we
want to sign messages and eventually
full encryption of communications so at
we looked a bunch of things we
introduced essentially again going for
simplicity zeromq and jason messages it
turns out it is portable it was very
easy to get started with it's like
tinker it was like Tinkertoys for
networking I've never built the network
thing so fast we had prototypes running
within a week or two eventually ended up
with a sort of a momentum of its own
when you're trying prototyping and one
just starts working you kind of have a
motivation to stop looking we did end up
some things we didn't get with zeromq we
ended up building her own heartbeat
system we just zeromq had a crypto kind
of in discussion and design and we felt
like we could wait a little bit for
crypto and only sign our messages but
otherwise not encrypt them the other
thing is I'll be honest we were a little
bit optimistic about the which I say
reading the label on 0 and Q
there are a lot of things in zeromq
which are outlines of how you do things
but in some cases they're not fully
worked out and as we dove into them we
discovered some of those outlines like
some of the heart beating protocols
there's some subtleties that we didn't
take into account but in general was
pretty successful we did look at a
couple of things we considered and
rejected doing this as just a giant
distributed or lying nodes the clients
aren't really trusted in our system and
we're uncomfortable with that some
concerns about 8k connected nodes maybe
that wasn't really a worry but we had a
lot some reservations from people who
had said no I hadn't this is this would
not going to work for us thought about
role at raw sockets we wanted quick
prototyping this didn't feel that like
that and you know avoid premature
optimization so you know a few other
things we looked at me and 0 mq ended up
with a lot of momentum simply because it
was simple quick to get started with and
it just worked learn if you want to get
a system started quickly zeromq was very
nice so we kind of ended up on a
communications model between the client
is server so the things on the
right-hand side are all on the server
the left-hand side is the client the
client does three basic kinds of
communications with the server our model
it gets configuration information over
HTTP from the server it's a rest
endpoint the client only needs a key and
a URI to get started everything else
which ports to hit what configuration
heartbeat rates network topology
information like what nodes to use for
what all come from the server again
trying to keep the client as simple and
stupid as possible we listened to heart
beats from the server over a pub sub
socket pair and everything else goes
over dealer router to a message switch
in the server so that includes we
heartbeat from the client to the server
command and control messages of running
this job I finished this job here's the
output from this job all that runs over
this connection so the job model again
keeping things as simple as possible all
job is is a list of clients to run it on
and a command to execute the life cycle
is very simple we notify the clients of
the job gather votes to see if we have a
quorum if we have sufficient mean
machines available to run the job
sometimes that might be a hundred
percent just to be clear but sometimes
you want just hey if i can get fifty
percent of my machines to take this good
if the quorums made tell mall to execute
so there's sort of a commit execute
cycles of the way we run jobs just to
walk this through there's a more visual
description of the server accepts a job
from the user sends a command way to the
axe if we get the quorum we start
execution and we collect results again
this was focusing on simple and if we
couldn't justify needing it immediately
we didn't put it in so I'm going to go a
little bit into the internal details
here what we built so though here's a
little bit more of the architecture so
you've seen the left hand side here with
the clients and the rest api so on the
right hand side is some sort of the
internal structure the heartbeat
generator is very simple again just
generates heartbeats sends it out of
socket don't really need to say much
more about that I think rest api is all
the user interaction and then the
message switch handles the message flow
and there's some reasons for that
particular design choice I'll get into
in a moment this lit the client be
really simple it just monitors
heartbeats generates heartbeats back to
the server and listens to commands and
sends things back ended up being about a
thousand lines of Ruby most of that is
things like options parsing dealing with
configuration stuff like that the actual
code to
run the execution is tiny it's kind of
cool the server as I talked about before
has this rest endpoint for control we
used web machine generally when machine
worked very well for us for this the one
thing is we went when they started
adding server set events with web
machine we discovered that if you want a
permanently open service sent event
machine socket it's a little tricky to
do a web machine because it kind of
expects there to be endpoint that the
rights to stop and so we had a event
feed which is all the jobs on the system
and that created a little bit of
weirdness with lip machine we're able to
make it work but it took a little
finagling the other other part of this
is this client configuration in point so
how we set up the crypto for the rest of
the system so we configure things like
heartbeat rate and what address to
actually connect to the server because
the HTTP and point may be going through
proxies and other network things and so
you need to give back some information
on how actually to connect to the server
so that may be a different address than
the API endpoint there's also some
things around how we do the topology of
our systems that make it a little more
complicated to find the server so being
able to do that
so one of the course design decisions we
made is we have a central message switch
so we have 0 m qu dealer router dealer
connection pattern so the dealer side of
the socket yeah the dealer side of the
socket I always get these bad words is
gets all we advertise you know port ten
thousand connect here to the clients
that's the dealer socket zeromq really
wants that socket to be owned by a
single processor thread it is very picky
about multi-threaded access to sockets
generally you don't want to go there so
we ended up with a message switch
process in Erlang that basically handles
routing client messages to the
monitoring processes starts new
monitoring processes and transmits
outgoing messages to the clients so we
used jeep rock extremely heavily here G
Brock is the glue for our system we have
a process for every single job in
execution in the system we have a
process for every client that's
connected to the system we have
processes we probably went a little
process crazy but we have processes for
just about any autonomous object you
have jeep rock is how we find them and
so the message switch uses jeep rock for
just about every message coming in some
protz messages come in with a name so we
use the name of the client to find the
client process jeep rock handles that we
use there's a 0 mq routing tag that gets
prefixed to a message coming in when
some of those messages don't have a
client name on them but the routing tag
lets us identify what client it came
from so we want to reply we know what
address to use and we have the client
manager process indexed by that jeep
rock and i'll say the jeep rock was an
absolute champion for us that worked
super wells in architecture
so the client monitoring which I
mentioned a moment before we have one
process for connected client it's
basically the state machine the traxxas
state of the client so the client
monitor and the client or essentially
pair of state machines that are in sync
if they get out of sync the client
monitor resets the client so a bunch of
stuff gets centralized into the client
monitor incoming message decoding and
signing his signature check is their
outgoing message signing happens there
we track heartbeats from the client and
you decide when the client has died on
us if we don't get heartbeats after a
while we shall decide the client has
gone away and shut down things and it
tracks the general state of the client
as I say if it deviates where it should
be we reset we really took as as simple
as we could possibly conceive of his
error handling here and that was pretty
effective I'll mention that we later
moved when we move to 0 mq for
encryption and message signing went into
0 mq and so some of those functions went
out so just to sort of reiterate where
we are here so we have a command switch
which is essentially a message
forwarding system and then we have these
client monitor processes which do pretty
much everything else with the messages
both on the stand and receive side the
other processes we have is for job
execution we have a fsm process per job
and again handle the global flow of
execution and then if a client execution
gets out of where it should be when
executing a job if the two state
machines don't look like they're synced
this is the thing that says you you're
you're wrong go away die it's a kind of
a brutal error handling scheme and you
could certainly imagine being more
sophisticated in practice this has
worked surprisingly well
I kept on being surprised with how often
really stupid simple solutions worked
for us here so that's architectural
recap that coverage is really a give
some motivation to what we talk about
what we do is scaling and I advertise
this as a scalable system for mo command
execution it's somewhat correct we got
around 8k connected nodes a bit higher
in them with some tuning so there's a
couple different axes of scaling number
of active quants you ever should
um I guess so the question was is if you
have all this software on the client why
do all this monitoring on the server
rather than the client decide there are
some reconnection scenarios where the
client the server can get out of sync
and we took the simple model of the
server is always right in that if the
client say is midway through job
execution or is waiting for quorum vote
to command and the server dies and goes
away and somehow loses where it was we
decided to come back and have the server
say nope this is yeah you might have
been right but the new state is dis
rather than try to handle some of these
stranded client use cases and other get
fancy with it so that's most of the
monitoring and the clients do monitor
heartbeats from the server and reset
themselves but they don't have a global
view of the job execution state in the
same way so it just kind of flowed into
the server and as I say the client we
tried to if we could take something out
of the client we probably would we
really tried very hard to keep it simple
that answer and yes feel free to ask
questions I happy to answer them so
there's a couple of scaling axes that we
were interested in number of active
clients the heartbeat rate the number of
and the number of clients that you can
run in a single job and those are
somewhat tied together the number of
active clients and the heartbeat rate
really are a trade space because the
resource limiting the sort of the late
rate limiting resource is throughput
through the command switch and so you
can either send you know have a thousand
cart clients heart beating once a second
or you have 10,000 clients heart beating
every 10 seconds and the trade space is
pretty linear in that zone and i'm going
to give some numbers but i really want
to give sort of a don't trust my numbers
past one sig fig because all the
measurement was done an easy
too and it's like you know you have to
check the weather and easy to sometimes
before you run a performance test
because on a bad day I think the whole
software package had failed and then I
started up on a fresh set of nose and
discover know what's running now guess
we you know this is a pretty
communications intensive and getting a
bad switch layout or noisy neighbor
seems to be a thing so as I say my
numbers trust them to one sig fig but
don't don't don't quote me on anything
finer than that so as I say follow about
810 k connected clients it's a pretty
linear trade-off heartbeat rate versus
can connected clients we ended up for a
lot of our testing just shooting four
heartbeats per second as the metric that
that that gets mix that can simplify a
lot of our testing thing one thing we
discover is as the heartbeat system
expert system is a linear walk basically
we had started having trouble around 8k
clients no matter what the heartbeat
rate was just simply we hit that linear
walk and we generate a stampede as we
discovered things were expiring also you
rent a large job jobs are net most of
the time we go to a lot of effort to
dither and fuzz our packet arrival times
between clients so they don't get a
natural stampede and then we create this
natural synchronization method which
method which is called a job so we start
a job and yes everybody reports and
everybody starts the job near buddy
answers back and so there's a bit of a
stampede factor that happens around that
so what we're hitting is around 1k
clients in a single job we started
hitting some things and there's some
obvious steps to take to that that we
haven't gotten to them we'll get to
where we are
the other part of scalability testing so
we use this Ruby client which is great
except that every client needs its own
Ruby processes and Ruby processes can
get kind of big doesn't eat much CPU
eats a lot of ram a client on the doctor
vm it's about 50 megs so you can end up
buying some relatively expensive servers
to run your test machines on don't make
the mistake of setting up 10 K nodes and
going on vacation or your boss will have
a nice chat with you about easy to bill
so our basic unit testing ended up being
about 500 nodes in this and that was
valuable he can't really replace testing
the real client running real jobs in the
end but for a lot of her testing we
ended up building a simulator basically
that was that was one of the smartest
moves we made and if if I was going to
do this whole project again I would
probably write the simulator before I
wrote the client it's much more
efficient we get about 50 k / simulated
client it goes cpu-bound long before it
goes memory bound and lets you do some
reasonable scale simulations on the
laptop the other downside is to do this
we ended up replicating most of the
clients behavior in early remember how
we said we were doing that client Andrew
because it would be easier we ended up
duplicating a lot of the work once we
built a simulator still wouldn't
wouldn't wouldn't regret it a moment it
makes the testing process a lot simpler
but it does beg the question of kind of
well why did we write a ruby client
since we already kind of have an erlang
client built into the simulator and what
I call a simulator it's a pretty high
resolution of simulator obviously we run
the exact state machine of the clients
simulate actually executing a job
basically the only thing we don't do is
actually execute commands on the server
and the idea is to try to get as
realistic as possible
behavior through our state machines and
really be able to stress the server
exactly like the real world does so talk
about some of the issues so I wrote this
so I can take the blame so the client
monitors basically the client monitors
are sort of self clocked they get a
packet get a heartbeat packet they look
at the timestamp decide that the packets
are arriving at a good rate continue
except that when you don't get packets
you don't get messages and that process
never wakes up so you need a watchdog
timer so I rather naively just put a
watchdog timer in the process with
Erlang start timer that did not scale
somewhere around 500,000 client monitors
started getting really bad behavior out
of the beam this is about Erlang our 15
or earlier 16 just to give you a sort of
time stamp on that we replaced that with
that periodic sweep I mentioned earlier
basically again simplest possible
implementation we made a linear sweep
through all the clients and if they
hadn't had a heartbeat in a while to
clean them up and in a lot of ways lazy
is pretty ok for this because an
inactive client isn't using much
resource all you really lose by sort of
deferring that sweep is a little bit of
precision and detecting when a node went
down it's that's more of a what I call
quality of service or it's less of a
performance issue and just more what
kind of standard do you really want to
provide your users on that so I keep on
talking about this message switch
message which we found it kind of got
which I say zeromq sort of natural
idioms kind of led us into choosing this
message switch the message switch
probably has caused us more trouble than
any other part of the system in terms of
scaling so the score to go of this all
messages both incoming now going go
through this message switch it's kind of
the shape of a dealer router socket is
you
a message with a tag on it from the
client you can reply to the same tag but
it all has to go through the same socket
to end up winding going back to the
client it also had the job of when we
get a first connection from a new client
it started up the monitor process did
the initial package validation made sure
that someone wasn't trying to do a
denial of service attack on us or
anything like that so it had a bit of
other things it wasn't just a message
switch so again this was forced into us
because zeromq shape wants one thread to
have control in one process and because
it's sort of the dealer router we did
improve it a little bit by adding a
broker splitting the process creation
work from the the message forwarding
work it bought us another 2 X 3 4 k
heartbeats a second the big win was
stability because we'd have forward
forward forward forward and then we go
off and we'd create a process and do
some other work and we'd stop forwarding
messages so we have these bubbles and
our message flow splitting those two
it's kind of an obvious step and we
probably should have done it sooner but
then we edit 34 k we're trying to figure
out what to do one thing was trying to
get multiple message switches we started
hitting some bottlenecks and this is
where some of the stuff got interesting
with the NIF we used active zeromq
sockets every active socket goes through
the same inner ozium qf tune if every
active song every active message goes
every act of sockets messages go through
a single thread whether it's not just
every every single sock in system so if
you're forwarding if you have your
message switch and your fault being
having processes forwarded from the
broker you send stuff through that
switched to that process twice that
thread twice ended up being a bit of a
problem moving to passive sockets fixed
it at the cost of a somewhat uglier and
cpu burning proxy because now we're
ping-pong me behind to check if they're
erling messages check at the zeromq
messages so this passive socket thing we
took this tune this a bit um a lot of
this work was done by Steven Grady of
Erlang solutions by the way proof
throughput somewhat hits some ball mix
around lager because we were trying to
log every state transition and once you
start throwing 10 10k messages a second
at lager we started hitting a process
cues backing up with lager so we need to
find a better logging solution turning
off lager got us pat that some things
that look like 0 and Q throughput
problems but we're running it's about 68
k messages a second then we hit the sort
of Gobstopper party ends when zeromq
throws an assert and there are about two
or three points of assertion that we
kept on consistently hitting with zeromq
so with a step testing roseum kuhn if
library with URLs IAM q2 worked out
pretty stable something happens when you
move 20 girls IAM q4 it seems to be a
bit thrust the seer about threading i
know there's something around closing
sockets that's a bit stricter but we
kept on seeing it throw certs and you
know with an if your part you know your
days over we added locks around some of
the stuff i'm not actually clear whether
we are the actual rules of using the
zero and pew library are not exactly
well defined so adding locks helped but
i'm not actually sure if i fix the
problem by adding locks or I just
delayed things enough so it randomly
worked and it was a frustrating
experience experience I find myself
asking before we head down this rabbit
hole is there a better approach as the
most you probably know the communities
kind of been moving away from earls mq
last year there was the cesium q
presentation of one approach there is
easy mq which is an erlang native thing
and I don't know if the authors in the
audience or not but it just not to
denigrate what they've done but it
doesn't seem like Earl's iam q2 is the
active focus of much development anymore
so I had kind of stepped back below that
when I hit this because there's a bunch
of rat holes you can dive into with nifs
and didn't really want to do it I kind
of was tempted to rewrite the whole
thing using the dirty scheduler nif
stuff and it would have been cooled it
would have been simplifying the code and
it would have been fun to actually use
some of those features but and if I
ended up going back and doing it a v8
kind of cool but yeah sometimes you just
have to step back and ask why you're
doing things so I'm going to talk
through this the lessons learned here
and I'm running I guess I'm okay on time
we hit very few real Erlang bottlenecks
Erlang by and large was not our biggest
problem Jeep rock at 10k processes and
more worked really really well the model
using one process process per client was
really in general pretty workable and
boy did the lytic crash approach
simplify our code just about every time
we remove moved an error handling case
our stability just went gotten better
you never really are able well-pitched
outage it's really hard to test your
error handling well and I've had more
bugs in my error handling code than just
about anything else I've ever written
alright I'm going to switch tracks here
for something just an ode to system tap
system tap has become one of my favorite
tools during this process when you have
an if is acting up and you have a lot of
threads in flight and a lot of other
things going on being able to track
things with system tap has been it's
been a godsend so I used it to figure
out that hey I'm hammering this one
thread that I don't get to see it from
the Erlang side but this nif that
everything goes through became pretty
obvious immediately with a little bit of
system tab monitoring it there's one
thread and that's what that thread is
doing this is actually from an Earl's
iam cute test whereas managing to
replicate one of the air oudhia mutex
errors i was getting i had made some
changes and hadn't quite gotten to
things right and this one to highlight
what what you can see with this that top
highlighted region is a user inserted
trace in the test code or line test code
the middle one is monitoring out of the
beam of that case this is the ab return
from the NIF call URLs IAM the euros IAM
cute closed call and the final one is a
see entry to the mutex destroy a
function in this case i noticed that the
mutrix destroyed never exited and that
was a really vital piece of information
that made it a lot easier to find out
what the heck was happening with this
failure and the ability to get
visibility across our line code beam
interpreter and Rossi is really
wonderful it's not yet you can't get
there with gdb at least if you if you
can I'd love to know how so here endeth
the 02 02 system tab I think I'm going
to try to get us to be shipping our
future systems with system tab built as
part of the executable because I also
use this as a debugging tool for a
customer problem in the field recently
oops one thing we hit tracking 10k
processes in any meaningful fashion is
hard getting a good visibility and
what's happening when every one of your
process clients decide to drop dead and
you don't really know what happened and
there's no for during never really got a
good sense on how to do that and people
have suggestions that love to love for
you to grab me and tell me what you know
logging weed saturate the longer message
system we have this problem with a
number of our others are other Erlang
based projects where we sometimes find
ourselves having to turn off logging
just when things get really hairy which
is we may be doing it wrong I don't know
transient transient node state exactly
where you are in a job a lot of these
very fine-grain things we originally
tried to log this to the postgres again
the rate at which those changes happened
was very difficult to do effectively I
hinted about this earlier the one thing
I regret we should have written Erlang
client the client we list sort of took
the Council of our fears and wrote it in
Ruby their simulated ended up having
about 75% covert op with the with what
the client would have had
we do some really strange things where
we're running multiple reactors in the
same Ruby process to be able to simulate
concurrency testing when we're doing
function tests for the system if we'd
written that an erlang we could have
commanded the processes through steps
much easier original reasons we did this
is that we didn't want to have to
require people to have her lying on a
system we got on route under that boot
because at the time we made the decision
originally we were shipping chef as a
ruby gem mostly and we switch to sending
things as an omnibus package where we
sent build it with Ruby and everything
in the kitchen sink so when you're
shipping a 70 megabyte installer package
to people stripping the Erlang vm was is
it not thought of that bad and on the
bright side the client added ups so
simple that it can be rewritten easily
and one things your mq really helped
with is that kept that client very
simple again 00 muse is really great to
get something something going and
written it the client is small enough
that I joke about taking a weekend
writing it and see I think it's pretty
feasible to do but if first choice we're
doing again would have written in Erlang
I guess the message I'm giving to people
is you know don't write off writing or
lang for user side tools and things like
that we we kind of had a mental barrier
to doing that all right here's the
here's the fun zeromq is easy to get
started in its abstractions and Erlang
are a bit of a pain to reconcile it it
goes this great effort to abstract away
things that are hard to do the router
dealer pattern combines thousands of TCP
connections into sort of one logical
socket and hides all the details of
connection this connection which is
great when you're starting out and you
especially if you're writing
writing in something like Ruby this can
be annoying you pay for the simplicity
if your language has trouble with
concurrency this is great that's not one
of the complaints have heard about
Erlang so in many ways you read the
zeromq discussions they love our life
they've loved Erlang so much that
they've essentially implemented Erlang
throne and so we kind of ended up with
Erlang in front of Erlang so thinking
about this if you you know for familiar
with the jenti Suki non-blocking server
pattern you can end up with a one-to-one
binding between the client socket and
the client monitor you don't need a
command switch the command switch which
is the source of so much for our pain is
really just an artifact of the libraries
abstractions and yeah you can open up
more than 10 and Q socket with that
socket consumes a port and ports can be
a pain to add now your system ends
asking why do I open have to open 40
ports in my firewall and you don't have
a very friendly answer to them the other
thing is that disconnect reconnect
information the zeromq hides from you so
carefully we actually kind of want to
know that that's part of presence that
tells us something about presence if the
socket disconnects then we may actually
want to start paying a little more
attention to whether heartbeats are
there zeromq kind of hid that from us
I'm not saying that zeromq I mean to be
clear the performance of zeromq was not
our barrier here with the stability of
the libraries barrier but the sort of
there's an impedance mismatch it we kind
of became increasingly aware of so what
are we thinking about doing with this
talked a little bit looked a little bit
at the Erlang cmq it has a lot of
upsides and after experiencing with
seeing asserts out of 0 mq dropped the
Erlang server dead I kind of really
appreciate the focus on stability the
problem is when we added encryption
using the zero Arizona cool I the
zeromq libraries the sea libraries to be
clear we moved the encryption state in
20 Mule so when the thing crashes we've
lulu's all the negotiated session
information that vanishes with it so
yeah Erlang cesium q would protect us
from the crashes except that we would
have to renegotiate every single
encrypted connection for the clients and
that really isn't that much worse that
much better I'm sorry than the server
crashing in some extends and yes
performance is a concern we really felt
like we were beginning to push the NIF
hard and going backwards to something
that wasn't as focused on performance
was a concern also mentioned is a minor
thing licensing often becomes an issue
with these things the dreaded
three-letter GPL where it appears in the
license and that becomes something you
have to explain to the lawyers wouldn't
be the deciding factor we've kind of
grandfathered in 0 and Q but that was
something at flag is the other thing
we're looking at is easy mq and just
started playing with us recently right
now it's really it Earl the 2 point 0
protocol and we'd have to put some work
into getting it for the Mozilla licenses
a bonus though for us and it's kind of I
don't know I have an emotional
attachment to it i'm not sure if that's
the right choice for us or not because
we probably have to add most all the
encryption functionality of zeromq for
to it but not having any see libraries
to crash after my past month of banging
my head against nif i can't exaggerate
the appeal of that so the other option
is all right it's the zeromq option why
not just not use it they say the dealer
pattern doesn't really model map to
Erlang that well we don't get much
pub/sub pattern has all sorts of
functionality to let you enable multi
chaos and do a lot of cool things we
don't use it
message structure we're using Jason for
a message structure a lot of the framing
features don't actually add much value
big thing mrs. the crypto protocol and
the client sighs implementation might be
a little or less fun I'm going to
mention that a saltstack which is a has
some very</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>