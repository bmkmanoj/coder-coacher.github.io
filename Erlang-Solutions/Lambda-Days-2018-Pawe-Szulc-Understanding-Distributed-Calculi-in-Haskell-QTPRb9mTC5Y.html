<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Lambda Days 2018 - Paweł Szulc - Understanding Distributed Calculi in Haskell | Coder Coacher - Coaching Coders</title><meta content="Lambda Days 2018 - Paweł Szulc - Understanding Distributed Calculi in Haskell - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Lambda Days 2018 - Paweł Szulc - Understanding Distributed Calculi in Haskell</b></h2><h5 class="post__date">2018-03-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/QTPRb9mTC5Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I recently joined this company pyro
effects basically two weeks ago and what
we do is we we sort of try to create
this third generation blockchain
technology or our smart contracts and
all that buzzwords and we do it in Scala
and we provide a language for smart code
contracts which is called the rolling
and to have for me to understand rolling
I had to read like arbitrary something
around ten papers so I thought to myself
two weeks ago since I have to do read it
anyway what's the better way to motivate
myself than just to create a
presentation so I contact the lambda
these people I said I will redo my
presentation from the scratch and that
it was a stupid idea but we are hiring
so if you're into Scala and you write
functional programming and blockchain is
something that just froze you then you
know that's the email you should
probably send your resume anyway you
might be thinking all right so you do
your stuff in Scala and but the
presentation is titled understanding
distributed calculating Haskell
so Haskell I don't know I think I just
maybe I enjoy pain I don't know whether
that's basically what it is so it's
gonna be gonna have a presentation about
calculate but we will see some examples
in Haskell how many of you guys
understand Haskell sometimes you see
like awesome overview so I can just skip
the tutorial so I had a tutorial because
I had a tutorial about Haskell I know
how to learn Haskell right you learn
about functions and functions
composition and then you learn
everything else so we will focus only
that that first obviously that's a joke
right because like if you think about
Haskell the haskers really easy language
it has like what 20 keywords
everything else is paradigm but since
you guys are here on this conference I
guess the language shouldn't be really
too hard for you I have this very quick
tutorial with Haskell is but since the
majority of people raise their hand and
if you if you weren't lying and I hope
you were lying out just I will just skip
it because why not so we have ability to
create a function we have ability
function that takes one argument and
also we have ability to define type
class in if you don't know what a type
classes then I leave the room and and
also so we have this data type here and
it was supposed to be a character for a
game and I was supposed to have
constructors player and NCP for whatever
reason I named it user and no OPI I
don't know it wasn't midnight so anyway
so you have a since is deriving the show
you can call this this you can create
this user and you can call this function
and it works that magically nothing
really special about classical I'm just
skipping those slides because everybody
raise their hand I understand hassle so
here we have our functional greet that
takes a greeting and takes some
arbitrary a which has an instance of
show and we'll just greet that whatever
that is so for example we can greet
ourselves I like agreed with yo wassup
Pato and we'll get back yeah what's up
battle so all that works for you all
until we reach a point where we actually
have to you know reason about the
outside world which has effects and all
that for that we have in famous I all
type I know type is just giving us a
value at this point in this hello world
example it will give us a unit but that
only gives us the unit also can do some
effect phul things however io if you get
an instance of a yo it's not really
doing that thing whatever that thing
will be contacting your database calling
your mom or I don't know launching
nuclear power weapons it just gives you
a recipe to do it this gives you a way
to launch those nuclear missile strikes
but doesn't necessarily do it at that
point it will do it at some point but
not when you call this function and you
will have a main method that will
eventually run your function so here we
have an example of it we have put string
it's just a function that returns us it
will gives us an idea of unit and what
once we eventually at some point
evaluate that recipe what it will do it
will give as a unit back but it'll also
internally somewhere out there into the
console print that little string and an
example will be good line which is one
more time a recipe that gives us a
string back but also has the effect of
reading stuff from the console now the
question would be how we could combine
those things together and obviously
there's this little bind operator here
so I have my first IO of unit and then
that gives me a value which I
immediately
ignore and I get a line
now this looks a little bit weird from
starting point wait till you see a
little more complex example like I want
to read an input get an input back read
another input and then do something with
it and it's already looks bizarre but if
you do a little trick and that is
formatting your code and you format it a
little bit of that like that you
slightly see that even though we
building this calculation even though
we're creating a function we sort of see
those imperative steps that we first
print something to the council then we
read line and get the value here on the
right-hand side after the arrow and then
we print something else ignore the value
and we get a line and add values over
here and then we do something with it
then they recognize that pattern and
that's the do notation because the
notation is exactly the same thing
that's that's that's the main difference
so awesome yeah all right so this should
be the process so this written process
is a very cool framework which I learned
a few weeks ago and it allows you to do
one crazy thing right airline programs
in Haskell and you might be thinking
this is stupid but the cool thing is all
the airline people are now in the other
room right so that person so if you are
guys from Scala thing akka if you're
guys from airline thing it's basically
based on this paper from Microsoft but
as well there were little changes and a
pretty much we're influenced by by
airline people so they're the main idea
being the news to be the process is this
concept of a process so the ye program
in this ability process is he happy you
have processes you have ability to send
message between those processes and then
you prove then you create your your
distributed system so a process as in
just finger the process of ice as IO
it's another effectual type that will
build up the recipe for your process and
eventually at some point in time it will
run your thing the rich process is
identified that my process ID so for
example if we have a send method you
will see that it will take the process
ID to which you want to send some
message and we'll take that message as
long as a message is serializable and
give you as a result a recipe to do it
closed over this process so that recipe
returns a unit here that's also
equivalent method called expect which
will gives us weights for the value on
that man
such queue somewhere out there and and
what you know for the value and give you
once it eventually is brought to you
from some other process obviously there
are other methods in the API however
this is not the distributed process
tutorial this is sort of like an example
and if you if you find it fascinating
you can actually you can actually google
it and then read the tutorials or
whatever if you were interested in a
phillips warner talk yesterday when he
was working my ability to work for a
company where he works this is one of
the tools that are actually using their
so what the were sort of discovering so
let's have a simple example let's say we
have a process called master master will
spawn two sub processes called pink and
tongue and master will send two pink two
things it will initialize the
calculation saying this is this is this
is my ID master d also i have a notion
of pong process ID so there you go and
now ping having that will send a message
to pong saying hey pain and the pong
will be like yo pong and the phone will
die and ping will say i'm done and he
will die and master will die okay so
this is pretty much straightforward so
on this is a little gold haskell using
distributed process so there are bunch
of inputs that you need this is like
tree that's boilerplate but sorrow just
pretty much ignore it
so this is this is what we need we need
our protocol so we have the initial
thing the pink big process spam punk and
dumb and they need to derive some
instances but those are details of the
implementations which i don't want to
cover because that would take another an
hour alright so we have a master so
right now master we create a function
that will return a process of unit as i
said that this is exactly the same as
i/o so it builds up recipe for your
process and eventually somebody will run
a recipe somewhere out there once you
actually run it so what do we do we we
take our our master takes its own ID by
using a method get self get self bid
that gives him his process ID that he
spawns two sub processes ping and pong
he sends two ping AAA message in it
where he provides both his own ID and
home Spidey and then X and then awaits
here for message done after he's done he
returns and
and execute so ping process is doing
what it's supposed to be doing so now he
expects that in admission in research
expect will block the calculation right
it waits for the cue or for that message
to arrive once we have it then it takes
it's o ID sends ping to to Punk with its
own ID and expect compound message back
and if it forget it it sends to the
master I'm done so the last thing
obviously we'll be paying we're paying
expects a message ping and sends pong
back to the color does that make sense
more or less it's a pretty
straightforward program I'm so you know
if we are obviously need to have a
notion of how to run it it's pretty cool
how they did it because they have a
separate layer for transportation so
like the layer that you will send
messages through so you can have two you
can have that implemented over TCP but
if you for example want to play around
with failures failing nodes different
kind of weird stuff going around in your
network you can pretty much change the
data transport layer and and plywood to
see how your system reacts with failures
so that's pretty cool but that's that's
again a boilerplate not for this talk if
you're interested tutorials are awesome
there's actually very cool book which I
think I will show at the end of the
slides that in the reference section
which describes how the whole thing
works
we will also like to have ability maybe
to lock something to our program to
actually see what's going on so there's
a little function here rugged which
takes a string and return to your
process of unit back but underneath on
the console level it will just you know
long those new messages so so for
example thing we can lock things like
that we are waiting for input and we're
sending thing and we're waiting from
pong and stuff like that we can do the
same thing for pong but we're waiting
for ping message and we're sending pong
back now we can do the same thing to
master once we have that we can build
our program and I'm using stark and half
of you will be like yeah yeah whatever
now we run it and yeah the program works
all right and so this is a pretty
awesome now I've been creating a little
bit more complicated program than this
using distributed process and when I
started I was thinking oh yeah Hospital
this will be like compile and works but
it didn't and if you think about it
basically there are two reasons
behind it so first of all we were using
an ISO we are in the high school
language who is supposed to be pipes F
and all that you know cool things and
features from the language but we never
actually used it like those method mess
yeah cool I like you know we're like a
box we can program but it's a trap it
doesn't really work and the reason for
it is that for example the expect method
whatever it is over here for example
weights at this point it pattern maps it
will pretty much undone so it will light
only for that one single message nothing
is stopping you to send to that process
a message which here's an understand
that message will that will not adhere
to the protocol so at this point is sort
of pretty much screwed because your cue
may grow and it might explode out of
memory issues and all that craziness
it's like we we lose a little bit of
nice features from airline which I'm not
going to talk about but we lose a lot a
lot of features from airline at the same
time we don't gain anything back that's
pretty stupid right fortunately there's
another API which I will show later on
do in those slides then that api takes
advantage of having types in your
language so there are there's a thing
called type channels which allow you to
send messages only of a given type and
receive only messages only of that given
type i was an implementing at the time
so try to implement the lamport's
logical clocks paper which I eventually
did but at the beginning I after I had a
whole implementation everything compiled
it didn't work and only there were two
places where it didn't work one because
I didn't necessarily understood the
paper straightforwardly I was like one
little mistake on my site but he I
wouldn't anyone was I was not adhering
to the protocol I was expecting messages
of a different type and and and and like
they did arrive but were never really
they were never really covered in the
code so I thought to myself okay so I
would probably should use that that
other API that use type channels but
also I tried to reason like is there an
a way to formalize my my thinking about
distributed system there's a very cool
look about distributed system by name of
I think Nancy Lynch she she looked
covers everything about distributed
system and then dude is this huge right
but so basically everything and one of
the reviews I've read
behind it book that the guy was saying
like this book is pretty awesome because
all those papers are available and you
can read them but every single author
will use a different notation with
different symbols and just putting and
one in through your brain is just
impossible and and what she did she sort
of directly you attract at least unify
the examples so so you read the book
from from a billing input from the
beginning to the end and you sort of get
an idea what's going on but a cool
question to ask would be is there is
there a way is there a capitalist it
would allows us to reason about about
our about computers obviously if you
think calculus you you might think
lambda calculus right how many of you
guys know how that goes all right also
so went really really quickly for people
who didn't raise their hand or there
were probably some people I will just
raise my hand because I was sound stupid
so so this is pretty much all this tool
under calculus
there's nothing else and those are
valuable so when you define a syntax you
have a variable you have a way to define
a function so that's the next line is
just a function that will take ax and
will do something and with an M and you
have the last thing that you can do is
you can apply in an argument to a
function so you will have something of M
and you will apply it apply the argument
and to it select few definitions here
the ax is something that we code bound
variable and what do we mean by that is
that there's this equivalence between
those two lambdas that you see over here
it's called alpha equivalence it means
that they are pretty much the same thing
they are only the ways they differ is on
is on the axis and under wise so the
things which are bound so if things have
a function if it's in nine name doesn't
really doesn't really matter what what
name you choose it's still the same
function right and this is this is what
they show here and see this alpha
convention this is a little bit more
formalized so lambda X M is exactly the
same thing as lambda Y M the only with
only old which that you for every
appearance of ax with an M you
substituted with Y and they are pretty
much the same thing now in this this
kind of definition you will see right
now that X is bound but you also see
this little Y variable and you might be
thinking about the hell that is and that
is something which we call free variable
so it's not balanced
it's freely available for anybody to use
and the most important thing in lambda
calculus is better reduction so whether
better reduction is nothing else as
applying functions to apply arguments to
your functions is just consider it as a
computation step so you have your huge
lambda and now you want to run it the
way you run it is you apply better
reductions so what the reduction is
pretty simple if I have a function which
looks like this so it's a lambda X with
an N and I apply it to M then I can
reduce that to just n so I drop my X and
every occurrence of X I will substitute
with M so example so if I have something
like that I can take my zet and
substitute that with and for X so I'm
only left with that little thingy here
and I will do the sake the same thing
for W and which gives me at the end
setback and I cannot reduce any further
and that's it
same I'll be thinking is that it under
lambda calculus like it's supposed to be
you know if you if you if you see any
all the Philip Soler talks in the past
on YouTube you will be like this is
rabbit that's supposed to be AB give me
ability to reason about any temptation
right turing-complete and all that like
it's just too simple well everything
single thing that you can think of
number billions values multiple
arguments like functions it's all that
have its own encoding which are defined
just based on those little things here
so don't worry about it's a little
encoding sex for example there's no such
thing in lambda calculus our as multi
pull arguments function right something
like that doesn't exist it's not in the
formalism but you can pretty much build
something like that by saying a function
that takes two arguments is a function
that takes one argument and returns a
function that takes a second argument
and gives you that final body M right
you probably know it by name by a famous
mathematician what is a one person whose
sine is actually correct that's the guy
because Harry did a run single paper
which Kerry read and he fell like but
this is awesome
and then he popularized the idea but you
know if you think about it would you
like to call whatever you're doing with
your function something killing your
caring should think I'm sorry I don't
know German so I guess we're good with
with carry the same thing you could do
with boolean values so you can you can
have encoding for true and false and we
will not cover this because if I were to
do that we would need yet another hour
which we're not going to do what I'd
like what my professors used to say it's
this is an exercise for the reader so
this is exercise for you but you can
pretty much see that if you haven't
going for true and false things like for
example and function or if will will
work you just apply better reduction to
those things and you will see that if
you call let's say if with true it will
give you an back and if you will false
if you give you an and an and function
will apply like zero and zero so forth
and false is false and true and true is
true and false and true is also false
and there's a yet another thing and you
could read about like charge numbers so
how you can encode numbers natural
numbers in lamb Mikado's all those
little features you can do and they are
available in the language and the
formalism is sort of complete now we
might think all right so is there a way
to have such a formalism but for
distributed system because lambda
calculus was created for sequential
programs whatever since we have multiple
computers running on the network we have
multi processor architectures lambda
calculus is not enough and apparently
there are the only problem is does that
we've loved our calculus it's pretty
straightforward because you can reason
about your calculus very easily you have
your input you have your output and set
up in this constructive manner you can
reason like those two lambdas will be
those two programs are equivalent
because for any given input they give it
exactly the same output with with
process calculus it's a little bit
different because right now your that
doesn't mean that to prod to distributed
systems are behaving the same way like
if I have two systems that's sort of
actually the same bad one reacts to
failure a Treo doesn't is that the same
system
what everyone is using shed memory
because one is working on a on a
multiprocessor machine and the other one
is working somewhere on the network and
it's passing messages over the over the
network so that all those little
differences that we have to reason about
and they spawn a number of calculus
which try to cover different areas and
whether this talk is focusing on on
calculus that sort of deal with message
passing so the concepts of of a process
running are somewhere on the system and
messages being exchanged with each other
so there are two papers which sort of
spawned the discussion there were they
were all created similarly in the same
time one is by Raman Milner the calculus
of computing communicating system and
the money and the second one is Tony
Hoare communicating sequential processes
and they were pretty much the same day
today they sort of created this notion
of a process ability to send messages
between process but they were a little
bit too immature they were lacking some
features which essentially the people
prove that they are not enough they are
not strong enough to to sort of
formalize calculation that if you can
run on under security sauce system so
few years later Raymond Milner creates
this calculus called pi calculus and
that PI calculus a synchronous calculus
for distributed system as a foundation
for the beginning of the beginning of
our talk
so calculus gives you ability to reason
about computer computation in
distributed system and it gives you a
concept of a process it gives you a
concept as an other message that you can
send off a channel nice one nice feature
about this and that's the difference
between the previous work of urban lunar
is that right now channels can be also
messages so you can have two processes
that process can have like grasp this
channel here and send that channel to
the other process so that other process
could start reading messages from that
channel as well so that was that was one
little feature that they added to this
calculus so so it gives you a processes
give you a channel it gives you all the
ability to reason about replication
about sending channels over to each
other also for reason about non
determinism which is actually pretty
cool and we will show that in a minute
so have the whole syntax
it looks scary but it really isn't so
you can have a nothing process zero is
just doing not doing anything it's just
it's just that it starts and ends and
it's gone you can have an input input
traffic so this is what we are saying
here is our process right now we'll wait
on Channel X for a message to Y and once
it receives that message it will behave
like P so like P is a continuation it
will start calculating whatever is in P
and that's synchronous it waits for a
message
the other one is output graphics so it's
sort of sands and message Y over channel
X the important notion here is a
synchronous so it waits for receiver to
grab the message before it continues
with P we have another sorry
oh yeah so there's an example here
actually show you so we have a we have a
program process speed that sends a
message hello on channel ax and then
receives message hello on channel X and
let's try to model it so it looks like
this so I send message hello on X and
then I receive some messenger on ax and
I finish my execution so I have my
process I send that message and the
notion that we see here we would like to
see like this message was being sent
over that channel and this goes back to
the process and then it's done and the
process finishes execution however
that's not the thing because as I said
both of those calls both sending a
message and receiving message are
synchronous while waiting for a message
for it to be blocking computation makes
sort of sense but the fact that sending
a message is also blocking is
counterintuitive if you ever work in
distributed environment but pipe out was
the original pipe Ronis by practice is
synchronous and you have to be aware of
it that this program will block at this
point it will try to send a message
hello but there's no other process that
will listen on channel acts before
because the continuation here only
happens after this thing is received so
that that guy will not receive that
message and this thing will not work now
we have also an ability to run to so we
can create a process which will have two
sub processes running in
so here we have a construct that will
give us a process P and Q sub processes
which will run in parallel we have also
a thing called restriction so
restriction gives us if you see or
something like that it will give you a
new channel X by name channel X that
will be unique to the rest of the of the
continuation so we unique for the P now
this is a new letter grid like you know
lambda you know PI do you know how to
pronounce this letter it's me if you
have problems to remember it
think of Monte pilot of a hologram so
this is basically yet and the last bit
oh yeah and you can yeah you can see how
that restriction works so so we have
here a a process where we have two three
variables Y and X both of them are 3 3
in this in this in this syntax but once
I create a new I will say nee acts it
creates a new channel for P we and at
this point it bounds that X 2 P X will
be healed will be no longer free because
it will be bound that value so those two
processes the SU equations here are
equivalent the same are they we could
have a little lambda calculus the last
thing so having all that before we moved
into the replication we can now finally
create our program that will actually do
something so here we have a process P
that sends a message the other one
receives a message and under the final
one just use them all to run in parallel
and most of the time if the process is
answer of zero we just are me that it's
just like it doesn't really matter
shouldn't be there so you know like we
can try to execute that we create a
process R which I like which spawns to
sub processing which run in parallel
that they have a unique channel created
for them and now we send a message hello
over that channel then there's the under
process that will receive it once that
is done P finishes execution and so
queues and since of two of them executed
and they are done then the R is done as
well all right it works now the last one
replication al aliyyil see may be
replication in a minute but think of it
that if you have a
elimination mark P think of it that
there are like infinite copies of P
running in parallel it sounds bizarre
but it will make have some sense in
animated let me show you an example now
there is one important concept of strong
structural conference and what it means
is that you can have two processes which
behave the same even though they have a
different structure so you can swap one
of one to the other and the other way
around even though they look differently
in terms of structure they became the
same way and there are like there are
maybe I will just put it out there the
way to reason about it so for example if
I have P and Q running in parallel it's
exactly the same as Q and P running in
parallel or if I have you know two of
them running as a see processes and
parallel to air this is exactly as if
those two were sub processes of some
process which would run in parallel to
2p stove extrusion I think interesting
because it's saying that if I have some
process which has a unique unique
channel ax and it runs in parallel with
Q that uniqueness is can be also full of
uniqueness for that for those two
running in parallel and now you can see
how applications works if you see
exclamation our marked P it's pretty
much the same as just P running in
parallel with another exclamation mark
so it can you know recursively till the
end of the world replicate itself oh
it's it's just how it is so the question
is could I say a little bit more about
scope exclusion because that's not not
intuitive it's it's just how its define
within the formalism so if you if you
create implementation just have to
adhere adhere to that that's a good way
of weird you can think that if you have
if you have a channel which will be
unique to the process that grunts and
sort of if that process is running as a
sub process somewhere in the bigger
process and the other process are
running in parallel but that will thing
they will have ability to communicate so
we can extract it that that uniqueness
outside of the of the bigger circle
right that's that's the general idea so
now we also have right now because it's
the same thing as in if we've learned a
calculus lambda calculus doesn't
actually that didn't have any meaning
until we have the
to run it so we had better reduction in
under calculus here we have reduction
rules as well so one more time we think
about them as computation steps so those
are I think they have three or four so
one of them would be a something which
we call communication and it's also good
distant words like what if we have two
sub processes which were on in parallel
and one tries to send a message and the
other one red tries to receive the
message and we can think of it as jazz
we get P and Q running in parallel only
we have to substitute any occurrence of
Z with y because we say we send Y over X
and it's being received as Z on the
other side so this is one reduction rule
the other one is saying if P already is
being reduced to Q then it will happen
even if P runs in parallel so running in
parent change the fact that it can
reduce to do some Q and here we're
saying like if P is reducing to Q it
will reduce to Q even if there's like
new channel up in front of it and the
same thing applies our said last thing
sort of takes advantage of the structure
conference saying if if P is is the same
as that P Prime in terms of structural
conference and Q prime is the same as Q
in those terms and dos you can reduce
the P Prime can reduce to Q Prime
then we can say that P can reduce the
cute more or less it means that if I
have to process this and they look
differently but they became the same and
and they already Rito those different
ones are reduced one to another than the
originals ones will reduce as well so
here we have simple example thing and
punk right we send a message and we send
a message back and we can see how that
works so so well what kind of rule we
can use here a first role would be
communication hi this is the the rule
and we're saying that if I somebody is
sending a message over that channel and
somebody else in peril is we're trying
to see that message we'll just remove it
and substitute nice but here I'm using
the same name so there's no substitution
but you but you can see that the same
thing will happen one more time right
because one more
time somebody's sending a message and
somebody else is receiving it so we can
might as well just remove it and now we
have two zeros running in parallel
now can we can we reduce that even
further a good Syrian tuition was the
final state it should be zero right I
couldn't find a single paper that would
reduce it to a good that would say
something like if P and 0 then P I found
it on Viki pedia so I make my claim that
it works okay yesterday somebody told me
that in the original original CCS paper
rebel nooner has this rule in that paper
and that's probably like maybe he forgot
it or something but I was in the
original paper and also you will see
either calculus in a minute that that
rule is explicitly there but that were
intuition like like ask I asked my boss
about it and and he said like without
this rule all hell broke loose so like
we have to like it's there like we
assume I call it Wikipedia equivalence
and like I let's write I said zero the
other one is just it's a very simple but
very pretty similar to what we've seen
before
but this little important notion that
you will see that I'm at this point what
I'm doing is and I'm on channel X I'm
sending a channel so why is another
channel that I send and then somebody
else will receive that channel as a
message and then use it as a channel so
we will start listening for messages so
we we like one more time communication
rules that channel is being sent and now
this channel after being sent is being
used as a form of communication this is
this is this is what was unique in PI
calculus and given more power and it was
like sort of a closing the theory to be
the whole calculus and and there it
within the paper if you actually read
the paper they show that you can go from
PI calculus to lambda calculus so so you
have the whole completeness of
describing any arbitrary algorithm so
and that reduce to zero
that yes so now we can have an example
ping pong one more time but we're not
right now we have a thing and two prongs
running so we can if we apply those
rules that the communication rules so we
will see that actually two different
things might happen
I can either I can either reduce those
two guys or reduce those two guys and a
pending of which path I will choose we
will get the other reduction will be
canceled will be completely removed so
these are choose one of them essentially
what I get is this I get a process which
never terminates right that's it's like
it's it sort of might be an important
feature to notice the other one would be
what if I have a ping pong and they run
in parallel so so I could see that they
will never finish the calculation
because they will always always
duplicate himself with that with that
replication rule over here so we we
exchange pink with just ping and one
more time ping with exclamation mark and
we already know those ping and pong will
reduce themselves to zero with one more
time we get we are back to square one so
we can just replicate one more time and
it will run through the end of the world
so this is not a bad thing because we
have obviously programs that's run till
the end of the world like service
receiving messages and all that stuff
but you can with that calculus reason
about those mess those those systems and
last examples our ups are also from the
paper and it shows you that they also
have gives the ability to reason race
conditions so I have a have a situation
here and I have two messages that try to
send some message over X and there is
one guy who tries to receive it and now
depending of who will win the race I
will either get this or that so I have a
calculus calculus that allows me to
reason about race conditions within my
system which is also I think pretty
pretty pretty neat
and yet this side should be removed with
this there's a notion of bias by
simulation but all right so really
quickly just because I want to reach
some cool things there is a notion
at some point obviously like when I
created this stock I reason about the
slides it told me that they're going to
be free hours so I was like oh we have
to cut some stuff but I but obviously it
wasn't good enough but in this immediate
process we have a notion of the channel
so we have a notion of a cent port and
receive port and a couple of those two
who gives us a channel back so gives
ability to send over channels and
messages of type a and receive messages
of type a as well and so you hear you
have a method sent channel so you give
him a sent port you give them a message
a and gives you a process back that send
that message over the channel at the
same time if you have received port you
can say I'm on that receive port I'm
waiting for a message of type a which is
brilliant it just exactly what we found
in PI calculus so yeah we could we could
make this stuff work right so so this is
our little ping pong written in that in
that PI calculus and now we try to
create something that will look exactly
like that and in distributed system so
we have a master which will create a
channel X and we will spawn two
processes ping and pong and we will give
them that channels a day so they have
ability to listen on that channel and
then we just we will wait on that
channel X for a message done okay so
what ping can do well pink will do very
straightforward thing and we'll it will
send a message ping over that channel X
and then we'll wait for a pump we will
try to receive message X on a sari
message upon on that channel X and once
that is done it will send message done
which master will receive and punk was
supposed to just wait for a message pink
and sent pong back this is easier to
reason about and it's like we have that
type safety we wanted really really
really to have the only problem is this
will not work and the reason why this
will not work is that we are giving
we're sending the other process a bit a
channel a receive port which is not
allowed you can send a send channel so
you can give some other process here's
your channel here's my channel there you
go you can use that
channel as long you gonna send messages
over this channel but you are not
allowed to receive messages on that
channel and why is that that's the same
thing you like if our people here from
scar community the same thing is not
implemented in naka typed and exactly
for the same reason Renault Kuhn had had
a presentation about pi calculus and how
he tried to apply PI calculus for
archetype at exactly the same thing he
said if I were to allow receiving
messages on the channel that was sent to
some other process that would make me to
implement taxes or whatever disability
consensus protocol over it which would
be just bizarre too complex and wouldn't
really work in in production and the
saying the same things those guys are
telling for distributive process library
in Haskell it's do I know five minutes
don't worry about it they saying it's
it's doable but it will complicate the
system and it would just not work so so
we are screwed like if you want a recent
still a reason about our our distributed
system a synchronous PI calculus is not
enough because by its nature is
synchronous and we and distributed
systems are not we have this
implementation issue of receiving
messages on the channels and the theory
itself it's not closed because we have a
notion of a process process we have a
notion of a channel but names are
arbitrary things name can be anything
it's like it's a detailed left for the
implement a tur like there there will be
really nice if we had also a theory
which would be closed over the notion of
names like we would know how to define
names and what the names are so we would
have a formalism so if somebody would
just implement that that formalism
directly everything would work out of
the box there would be no additional
cognitive work that they're implemented
or had to do so given that a half five
minutes I will not cover what I want to
cover I will just give you a notion of
what what are further research and what
further in time was being made so there
is a notion of a synchronous calculus
and and like in that calculus the guy so
the problem is we want to have a ability
we still have a bullet
to wait when we will try to receive a
message we can block that's fine but if
we send a message that should be a
synchronous that just I'm German wanted
to give you a message back and I can
continue with my calculation so the guy
behind the paper he he created this like
he used this chemical abstract machine
thing for some other paper and I think
it just makes things a little bit more
complex and it's just really hard to
reason the bar like I tried to read that
paper it was obvious but it was weird I
liked like molecules and like the heat
and they connect and they cool down and
look at all this craziness the idea
basically like it's it's fun paper to
read but the main idea here is that
while in a synchronous populace you you
sort of wear before continuing with P
you have to wait on that little thing to
receive that message a synchronous PI
calculus just this allows it so that it
pretty much looks like it's not really
how it is defined in the paper just so
you like so we clear on that but the
idea is pretty simple like if I'm
sending a message it's a it's a thing
that does it and that's it so if the
process is doing anything else it will
do this thing in order in parallel or
this will be some sequential step but
this will be the last step because the
only sends a message and it has accused
the calculation and and as I said it
allows you to have this ability to
expressively sort of reason about your
distributed system one notion there is a
paper that they at least sort of they
sort of proof that there is no way for
you to describe everything from
synchronous by calculus in a synchronous
populace so you have to be aware of that
but as I said those those healing rules
and cooling knows it's all really really
complex there is another paper which
will not cover right now obviously
they're the slides will be online but I
just want to give you like a few few
hints here that people is called rock or
or calculus raw is from reflecting
higher order calculus and that
reflective part is actually pretty neat
because if you know Lisp
you know lists have has M expression and
that's expressions right we have ability
to take your coat and that's sort of
like lift
go as a structure right so Lisp itself
will not have higher-order functions but
you can still take any arbitrary
function lift it to a structure send it
over to some other function and then
sort of drop it those do different
languages and they apply the same so and
that that notion of quoting a
calculation and and dropping it as it's
called sometimes reflection and they
prop that notion to that to the calculus
of distributed system and at a pretty so
that I will not as I said obviously like
we are finishing finishing this
presentation but I just want to say it's
really cool paper to read it's probably
the first paper paper that I read that
had emojis in it like wings and like
stuff like that so it's really cool
funny and it's like but it's it's
actually is written by Greg Meredith the
guy who's behind our chain and it's a
really cool person and you can see it
from the paper that that guy is pretty
cool and I will skip all that craziness
here we have we don't have time for it
what important thing is that the
language that we yeah a lot there was
more slides right there really so the
language that we use in our chain to
describe smart contacts it is called on
rolling and rolling is based on on or
calculus it has all those notions that
that craziness is a little bit hidden so
don't worry about it
but there's a reason about writing smart
contracts and in this calculus is really
really awesome and one of the things
that they actually dealt with as they
dealt with ability to receive a so to
get a channel from some other process
and receive messages from that channel
and the way they'd use it is they use
something called topple space now what
papal space is I don't know yet
hopefully I will at some point so yeah
so if you're interested like if it was a
little bit interesting and would you
like to do that still crazy stuff in
Scala and using functional programming
you know where to find me we didn't
cover a lot of stuff but sorry those are
the reference all those papers are
actually readable is not really that
hard to read them I would just encourage
you to read from bottom up by calculus a
synchronous calculus and row calculus
not the other way around because
otherwise you'll be just crazy
that's it for my slide we are hiring
thank you much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>