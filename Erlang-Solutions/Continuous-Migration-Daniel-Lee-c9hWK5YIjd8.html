<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Continuous Migration (...)  - Daniel Lee | Coder Coacher - Coaching Coders</title><meta content="Continuous Migration (...)  - Daniel Lee - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Continuous Migration (...)  - Daniel Lee</b></h2><h5 class="post__date">2014-06-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/c9hWK5YIjd8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">right so just a little bit about me
clara was actually my first professional
software engineering job everything
before that was rather academic research
related to functional programming
particularly statically typed functional
languages like standard ml I came to
Clara in 2011 and so at that time I was
on what they called then the core team
if you were at Mike Williams talk this
morning that was roughly via the
chimpanzee phase of the spread project
currently among the real-time core
platform team which would be one of the
the tiger teams of this project with an
analogy and my interests are eating out
and cooking very very large piece of
meat for people who coincidentally have
joined my team in the past 3-4 months I
don't think that's at all related klarna
I'm sure you've heard a lot about them
this week or if not at previous
conferences so I won't go too much into
that we've been an online payments
provider since 2004-2005 the high-level
business goal there is you know the
value we are offering to merchants is
that through the simpler paying
experiences for their customers they
would increase conversions what we get
out of it is that since we are actually
extending the credit risk the so we do
the invoicing so unlike say payment
provider that is just built on top of a
credit card system where they're just
trying to take a slice of the fees we
are actually extending the credit so if
they do not pay the losses are on us but
if there is any interest to be earned on
light things or they're on pay plans
then we take the profit or our selves
there and we are in all the Nordics and
germany netherlands and we moved into
austria last summer so klaren
engineering we are young attractive and
during lots of gloom atif the department
as a whole has about 200
people the main office is Stockholm we
also have sort of a Java big data
shopping uppsala and a sort of a ruby on
rails GUI team in Tel Aviv so the
Stockholm office is probably the biggest
airline shop outside of Ericsson and
just for some context and this in the
story about this talk two three years
ago there were about 10 20 developers
and then over the next 2-3 years it sort
of has just exploded to over 60 so a lot
of what we need the challenges we face
is going from a system where you have
this core unit of people who are you
know pretty much salty you know blue
tail alums going from lots of young
junior people who don't know the system
as well do not understand aaralyn as
well and sort of just the adaptations
we've had to deal with one them just
contributing to such a complicated
system the other factor that really
complicates how development works at
clarinet is that we are a financial
company we are pretty much a bank in
sweden i think there's three tiers on
this and we're just one level short in
norway we we are a bank and so we are
subject to these swedish financial
regulatory authority and so compliance
is a big deal there be live system is
under a lot of scrutiny and it's very
important that any changes to the
production business flows are documented
have business approval and the code must
be reviewed so because of this we want
to have very very strict control about
anything that changes the behavior in
the live system so we can't accidentally
release a change or if some dependency
implicitly changes this could be
potentially a very very bad thing or
possibly even illegal so you've probably
heard a lot about our legacy system so
this is some core component of it
roughly unchanged from the system we've
had since 2005 just the nature of the
company is when it was small you have
one production system
it's kind of well monitoring things
takes you know mental overhead people so
anything we do we just put it in here
and this is sort of this grew and grew
and grew so two years ago when the Fred
work started all the business
functionality was not only running in
pretty much this master slave set of
servers but all the business logic was
virgin controlled in the same repository
which actually had then just moved from
subversion to get and a lot of what's
going on these days is to split these
things out in two independent services
so shiny new system Fred I hope some of
you or at least that months compass talk
so I won't go too much into the
architecture of this at a high level
though it is a masterless distributed
system running on top of react and it
replicates data with the legacy system
over a database abstraction layer built
on top of rabbonim cube so this the main
purpose of this is to be the termination
point for our real time estore ap is so
eventually this will include the Carnot
check out but the current ongoing work
focus of current ongoing work in this
talk is about bringing over our legacy
xmlrpc API onto it and so just a little
bit about legacy business logic you know
so it's the case so Clara is a different
from a lot of software companies in that
we do not sell software we sell a
service so it's it's these ap is that II
stores integrate against so we are
selling the fact that we service the API
for their functionality so that means
you know we don't ship updates to the
users and expect them to upgrade their
code it's well they're integrated
against us but they're expecting to call
our web service so we are in control of
that and but the Conte and the the one
of the difficulties arises when we
upgrade we upgrade the entire system at
once for everyone and a lot of the
history of the company is that you know
to make those early sale
that have allowed klarna to double every
year for the past six years is that
there's a lot of funny code in there for
biggie stores and there's a lot of
special cases and you know there's just
the little things where you know
developer get to fix it ticket and you
just hard codes that little things so
there's a lot of these things and a lot
of this no one really understands why
some of that is there anymore or whether
it's safe to remove that and when you
break something like this it's
potentially very very expensive you get
a call it's you get unhappy merchants
you may even have to settle with them if
they if they lost for you because you
broke something so when a when the x
mark capi breaks for emergent it is not
just klarna not taking those purchases
for itself it's actually which is you
know fraction of the total ticket prices
the entire ticket that the merchant
losses so it is very very costly for us
to break an existing integration and so
it's part of the ski know we've had to
refactor a lot of the system so I just
I'm not going to read this entire thing
but it's just a quote from an just a
newsgroup thread with linus torvalds and
so the context years there is some guy
and his sound card driver something
breaks and he just pokes at it changes
some magic number and it works for him
he submits a patent looks like what are
you doing because it pretty much broke
anything that was in this guy-- system
and and we're really goes on is just
this development thing where you know
this happens with a lot of inexperienced
developers where you have a problem and
you just keep poking at it until it
works for you and it works for you and
you don't know what you break but the
fact is when you're factoring something
that a lot of people relying there's
really only two ways to do this right
one is to really understand the problem
you are solving think hard about it and
have a solution that actually works for
this or to use what people are using and
not complaining about and there's really
no there's really no alternative you
either actually do really know what
problem you're solving and solve it or
don't mess with it because it's just
going to be expensive and costly if
you're just twiddling around with this
because you don't know better or just
you know for your own satisfaction so
to make so the Fred work has actually
gone under multiple migrations one the
first one was actually just a big
refactoring of the East or API on the
legacy system without any new servers or
anything in place and this is just a
line things up such that it was even
comprehensible to move things over and
and the current work is actually moving
more of that onto the new servers and
whenever you do any of this kind of work
migrations are dangerous you are
changing legacy business behavior that
you were making a lot of money on or
sort of the long-term benefit the
country company but if if you didn't
have any reason to do this you would
never want to touch this the other issue
is if you do too big of a change you
might have to run both versions at the
same time and when you have to move code
to a new system while still running some
version of us on the old one the only
real safe way to do this is to actually
share the code in some repository that
both systems can use as a dependency
because if you copy and paste this from
one to the other it works just that day
and if any maintenance goes on on for
one of them and you don't remember to do
it to the other side then you could have
some very very bad production problems
so the so the entire continuous
migration you know buzzword really is
that we are it early growing the new
system it's so you know even the old
Lexi crafty thing at klarna has a weekly
release cycle which is extremely fast
for any financial services company and
because of this the sort of general
pattern for much of the development is
that the bits of business logic or
functionality or even just useful
utility code that was version controlled
against you know this big huge legacy
repository is moved into sub module sub
repositories which we update in the new
system so just for a line of code count
there's close to going to be little
rough here but close when we started
this close to half a million mail lines
of code in lexis system credit
and in Fred there is actually you know
after only about a year and a half
development there's actually about 500
million lines size 5 2000 so about half
million so a huge chunk of this has been
shared and in order to make this work
and it's really the fact is you're
having the logic run in two places but
they're actually somewhat different
systems you need to reorganize just the
legacy code which you know when you
version control everything in one place
but your dependencies get really enter
tangled into just a system or a family
of software artifacts that allow you to
compose these things better so one of
the keys to doing this is using
frameworks so I'm using this in a very
very general sense in that i will call
framework any kind of code where you
hand it a callback module you handed
code that it calls back as opposed to
say some big system platform framework
where you just stops so I don't mean
framework in the rail sense i mean
framework in more of the gen server
airline supervisor sense where it's the
small little utility where you give it a
call back and it handles the boring
details of the control flow or managing
certain resources and the callback is
where the lot where the interesting
logical bits happen then so frameworks
just shared libraries of those two kinds
where there's business specific ones and
this it's not specific ones and then
there's the system specific code and
then this last thing will just call
stubs which is stuff where it's not
really quite implemented on the new
system so frameworks so this is sort of
in the Hollywood model where you are not
calling the framework from the
application in the control flow you are
giving it something and it calls your
callback and for something where you
really need to separate the concerns of
what is important in terms of the flow
of things versus what is system specific
or what is sort of you know instant
specific it's extremely important to
sort of divide this up and these are
actually things that once you
how the control flow goes it's actually
very nice to program against because new
instances new features are often just a
new call back instead of having to do
that unpleasant thing where you were you
kind of feel I'm sort of copying the
control flow here and it's not quite
right and the nice thing about
frameworks is there sort of usually
general enough that don't really need to
change them it's very if they work for
the sort of initial general case they
tend to work for ninety percent of the
instances and like a good framework if
you have the right interface there it's
really hard to actually get it wrong if
it works for sort of the common case so
the shared libraries months this is
absolutely also code we you know just
get off the internet from get up we use
quite a bit of Bosch of stuff like web
machine and lager we use multi web a few
of the leaf awesome things from boundary
we have some our own internal like just
system generic things like the tulip
library which is just sort of general
libraries for things that perhaps should
be in something like the OTP standard
library but aren't then you have some
funny things like just weird legacy
specific business definitions so this
example here of currency I think we've
added some acts like yeah sure but
initially this thing was just you could
go to integration at Clara no com you
see that we have this funny quirk where
currency codes on our API don't
correspond to any real standard it's
just sort of been incrementing up of
currencies as clarinet supported new
ones so the Swedish crown is 0 or 1 or
something like that and
and crown and it's a sad thing and it's
something we'd like to get rid of but
you know we have you know you know 15 20
thousand e-stores integrated against
this and as we tap new systems they
still need to understand this definition
and yes it's only five defines or
something like that and you could just
copy it over but that will be wrong and
you really want to be able to share the
definition and it's this and it's rather
tiny interior but it happens to actually
exist both in Fred incred and in the new
implementation of the payment
termination for credit cards then there
are other sort of more pure business
libraries where they have some klarna
business logic in there they're not you
know nothing we've ever want to open
source but they're still general and
they still give the business meaning to
how Clara interpreting so this example
here is for the Swedish for just not too
sweet what coroner thinks it as a person
number so if you're Swedish you know
that this is a rather sort of
fundamental part of how you interact
with Swedish customers due to our legacy
this is someone overloaded for other
context and so this is the coroner
specific meaning for what we think of as
personal numbers and this logically has
to be shared between whole system and
the new system so then and then another
sort of style Abra is something where
it's not really a library and stuff as
more of a family of callbacks because
when you use these frameworks you have
these callbacks and you want to just
share the difference so this one thing
our pap fe it's really just the
definitions for the types or our XOR
picea guide and also the methods
specifications and so the shared ones we
want to share between the systems we put
in the separate repository the other
thing is a system specific code some
that's awesome some it's terrible so you
can consider sort of anything in the old
thing that no one's really looked at
much thought much about the source you
know cred specific system specific
database clients so the legacy system
has this replication layer on top of and
nisha then
you know Fred system uses react and we
have some client layers on top of that
the logging and monitoring is sort of
system specific and answer to make this
work out nice the way you want to
actually do this is your frameworks
should orchestrate the general things
and for for the bits where you have to
call system specific things you give
them the system specific call back and
then there is sort of stuff so on the
new system where maybe you have entirely
refactored out all your dependencies
into some nice nice place to put it and
call it you know you just sort of punt
so the nice thing about one of the quote
about nice thing about la is that you
know if your if your module just says
I'm going to call this function in that
module and you want to move and this is
moved around and it really just needs
some module with a function of the same
area so we are kind of exploiting this
to just say okay well this super cred
specific call and we're not actually go
we don't actually need to do it maybe
it's only done on credit for side
effects so on Fred here's this wrapper
information and it just returns ok so
obviously this is technical death where
you know we are putting off actually
figuring this out and cleaning that up
for just having a little wrapper and
fast but of one event this is this is
actually a version control to do list
every every function in one of these
stubs you know some point in time
someone is going to at least want to get
rid of these so at least it makes it
very very clear what is not on the other
system what doesn't have a real
implementation ok so and the way this
really goes because fred we are not
actually trying to it's not a new
product in that we're not selling any
new API calls it is the same old legs
API we've done before but it's a massive
change in how this is implemented and so
there's a couple standard terms for how
this goes so one is sort of the thesis
thing which is this sort of this Greek
paradox where you have this ship and go
was on this long voyage and you just
have to repair it you know you have to
replace the boards and you've changed
everything and by the time this ship
ends its journey every piece of wood in
this thing has been replaced twice so is
it still the same ship it acts like the
same ship but it's not really I mean so
everything is changed but there's a
certain sense where this is the same
thing another version of this is via is
the grandfather's X where you know this
is my grandfather's axe the head has
been changed twice and the handle has
been changed three times this is my
grandfather's axe and it's that it
spiritually is the same thing it does
the same thing but you may have changed
every component there two or three times
and this is how much of the code
migration is gone we've refracted many
of this multiple multiple times
functionally it's still supposed to do
the same thing the way it's organized
actually looks much much better but in a
certain sense it's just both completely
different but it's also the same and in
particular it must be the same to the
outside world and so having these shared
dependencies is extremely important for
this because you clean things up you
move it into the shared place and then
it's there and then the work goes into
both places so for the cases where we
are actually able to share the
dependency this works out rather nicely
because anything to move from the legacy
system into a shared place is business
value which you presumably could share
into any new systems perhaps once we
haven't even thought of yet and also any
maintenance if someone needs a new
feature you know to extend something if
it goes into the shared place any system
using that library get take gets the ax
man of that whereas if you had a forked
version then you have to do the
maintenance multiple times or you might
even forget in one place and bad things
would happen so because of these
dependencies we run into the just a
source control problem well you have the
system and has many sub dependencies so
subversion at something called sub trees
and how do we manage for legacy reasons
because the old system is not completely
moved on to
rebar dependencies but it does have
dependencies that build with rebar that
is actually using get sub modules and
for the new system Fred it is using
rebar configurations and one nice thing
about Fred actually the top-level
repository has actually just test cases
a rebar config and build in
configuration settings so there's no
actual business logic at the top level
think it really is just the most
important thing there is a rebar config
and there's nothing in there directly
about how klarna does anything it's all
in these separate sub dependencies so
cred users get sub modules I don't know
if you've used them or not they are sort
of a funny feature in that the developer
experience for them is extremely
extremely unpleasant the commitments
messages and this are totally non
intuitive and not useful because it's
really you are just updating the sha-1
references and so it's not exactly what
you want you developers prefer to think
about these terms preferably in branches
we're left with everyone they would just
track master and everything will just
work out nicely or short of that like
some kind of tag or at least something
with a name whereas get some models it's
just the sha-1 hash is the one advantage
of them is that they are extremely
consistent and predictable as long as
you understand what they're really doing
which is they're just concrete pointers
there at least predictable so they have
that little advantage but in general I
think if at all possible you do not
actually want to use get some models for
anything so Fred new system and all
other new systems new airline systems
that Clara uses rebar for dependency
management sort of and but we've
actually had to flatten our rebar
configuration file and the top level
builds with a patch rebar to not
recursively look into dependencies and
this is just because well remember at
last year's you see you know Dave Spence
that
you know has anyone run into issues here
and so I think for the general simple
case where yours you know where your
project might only have four or five
dependencies it's not so bad your if the
likely of you having nest dependencies
sort of low and you might these things
like jigger around the order and then
you get a relatively consistent thing
for us we have close to a hundred
dependencies in there most of whom when
if you actually were to flash things
that would have rather nest dependencies
and they're not always updated in tandem
and it's actually not a tractable thing
to update everything so if you have a
low level dependency and everything that
uses it if you would about everything
that uses it you would have just had
these trivial changes for saying minor
revisions so you can't really have
everything up to date with these so Fred
uses a flattened one and our patch gives
us this rather important thing where
it's rebar get my dependencies but do
not recursively do this sort of um you
know this unfortunate wording and the
more we go through this would kind of
worked around this and everyone I've
asked about this is we just go some way
to make it work i know i think component
is are really good about lining things
up to make sure that they don't really
get hosed but every now and then they
get a little surprised i talked to jared
at bastyr about this and he's like yeah
you know when we get close to release
candidate people sort of freeze things
but secretly i'm running this shell
script that takes to shop everything and
if it depends who changes i get really
mad we don't we don't do this we just
keep everything point at the top and
it's a little painful it's more work but
we at least get a consistent results
from doing this so more to that
developers would love to just be able to
track master be so nice if you just were
trackmaster you get the updates from the
outside world I don't know how many
times I've heard master should just
always work but it doesn't mask Master
will break if you're tracking a branch
and someone from the outside world
change the branch you will get screwed
especially if you're tracking say the
get up master you don't know why anyone
and they could have completely factored
something they could have broken back
with the valley and the right thing to
do this that's but it's in the main
system they worship the master you do a
fresh clone you haven't changed anything
you might not have changed anything in a
week system stops working so if you want
any kind of reproducibility tracking a
branch is bad flow for a while so at so
far a rebar config you know we switch to
tracking just tags quite some time ago
in one of our test Suites we actually
were just downloading rioc building it
from source and we're as you know we
kind of don't want this moving target
react so we're going to attract a tag on
that but we actually got screwed by that
too because within so we get this tag
version rebar and but it's tracking the
Masters of its stuff so our bill breaks
and we actually can't even reproduce it
because we don't know what rebar master
would have built for us yesterday so and
so that our problem is a little
different from companies that are a bit
more open source in that the
requirements for strictly knowing what
goes out are you know so we have much
stronger requirements for this and also
you know there are a lot of companies
where you know they only need things to
work before they package something they
sell to someone so things only to work
then whereas for us we release on a very
very high rate and are things need to
constantly work so tracking moving
targets and Len these changes implicitly
happen is very bad so if you're any in
this situation where you really need to
strictly control what is actually going
out
tracking the branch is going to burn you
eventually so we use tags internally you
know we try to have everything semantic
version cember org and so this is just
the standard three sometimes four number
versions so major minor patch and high
level a major change means you have
broken backward compatibility in some
way minor means well say API has been
extended but everything that was exposed
previously is still there and should
behave the same and patch is well we fix
a bug and there are no interface changes
and so one thing is so everyone knows I
once read the seventh heard but I think
in general people are actually rather
afraid to commit to actually tagging
things appropriately the cember standard
actually has this clause where and you
know you kind of heard this in the
elixir talk earlier if you read its like
before you go one point 0 it means
nothing so you can brake back or kapab
you all you want and so this never go on
point 0 and we actually have started to
just you know as soon as you've done
something internally just go to one
point 0 this you want to uh you will you
want to be able to have the ability to
bump your major version because your
major version going up tells the rest
worlds hey hello if you use me and you
update check that nothing's broken
because something might be deleted
something might be gone see how the
interface has changed or even minors and
even within chlorin it's somewhat
inconsistent I've seen I've seen people
tag huge back probably things as as a
patch and it's if anything's a lack of
confidence for saying this is actually a
major change or I'm not ready for this
to be one point oh and so for a product
you sell to the outside world yes your
business people probably care that you
you're running that you've gone from you
know Java 15 to java 6 it's it's cool go
up your major you want to so you can
sell it or there it's like you don't
want have committed to a big change but
it's just an internal software
dependency you should not have an
emotional attachment to any of these
version numbers if you've broken back
work about really bump your major
because your users will want to know
that so testing we have a fairly
standard setup we will rely on Jenkins
for just our standard continuous
integration testing we use both unit and
common tests so there's also this new
sort of mode of use of me unit called
common a unit which is just a parse
transform that allows you to write test
cases that look like common test test
cases but run as a unit or under ye unit
and so you get the advantage of your
tests have the nice setup and breakdown
in the common test style but you get the
speed of unit and there's also some use
of proper so something a bit more
experimental going on but rather
important is our system verification
tests so for klarna this is something
new because previously we have one
system it has its test suite it doesn't
really care about anything else because
it doesn't interact with any other
internal systems in any way whereas now
that we have both cred and fred and
rabbit brokers in between and the Fred's
running on react nodes which aren't
necessarily in the same vm there's a lot
of different agents going on and we
would like and and so we want to
integration test how these go so this is
the verification tests right now it has
sort of two modes of use one is the
single developer setup where it just
fetches everything and tries to run it
on one place but it's configurable
enough that it can run on multiple hosts
and there's a lot of ongoing work to be
able to do nice things like spin up a
bunch of virtual machines have
everything set up for you run your test
cases against whatever this is and then
report back your results on Jenkins so
hopefully we'll have
a nice you see talk next year when this
is a more mature so right now fred is
actually in a beta state we are
continuously now on we are taking
traffic right now all of Florida's
xmlrpc traffic goes through the fred
machines and for the call that it can
handle which is this identification
called get addresses services that
completely except for a few cases that
we still proxy on and we are planning on
rolling out the purchase taking
capabilities in our reserve amount and
adding voice functions over the fall and
winter so right now fred is currently a
developer operated there's source so
we've been in production full-time for
about two months now it's and so right
now it's a rotation of four people we're
adding a few after the summer and yeah
so the buzzword for this is DevOps his
heart i don't actually know what that
really means but it's developer operated
and so my teammate malcolm likes to tell
us anecdote about you know these
helicopters in the vietnam war where
they were having lots of problems they
would have mechanical problems when
they're down missions and stuff and then
some genius general realized well you
know just put the mechanics in the
helicopter and suddenly they became
magically much more reliable another
another way to look at this is this
observation by james hamilton where if
you have operations people you know
responsible for a big problem you end up
getting a lot more operations people
they will just hire more operators
whereas when you have developers thrown
out a problem they end up automating a
lot more stuff and so in the standard
dev ops you think we do our
configuration management in chef which
is a standard tool so it's written in
ruby sort of the other big alternatives
to this or puppet and ansible so chef we
more or less inherited
and so our production servers for all
the new things are configured and
managed with Chef so this is the Fred
react notes the RabbitMQ servers we also
use the chef cookbooks to bring up these
testing machines in a in a you know in
the appropriate configurations so this
is a bit different from the previous
model where you know someone installs
the system on some server they compile
the code on that one by hand to a hawk
coat load upgraded and if they ever need
to make another one or two replace the
machine you've got to hope to Alaska who
did that remember is still of the
company so this internally we have
developed this tool called organic
there's some relationship between this
and rebar overlays and also this library
used in some of the bash Oh chef
cookbooks called the airline term helper
and it's so these configuration
management system there most of them are
Ruby so chef and puppet are Ruby and
they have this notion where any
configuration file that you might want
to go out with your system you should
have some template in there and it is
generated as part of your recipe and
this is a relatively nice standard thing
for react because their sis config
changes very rarely this is sort of
propria eileen configurable just as a
matter of practice the artist config
grows weekly and if you have a template
in your chef cookbook which is separate
from your main code base this they you
have to do a lot of work to make sure
they stay in sync with each other
because here's the official thing well
here's the one where your developers are
having the defaults here is the one
where your cookbook is generating this
file and if you add one if you add
something to the one with a source then
you need to remember to put the defaults
and values into the
template and for us we found this to be
rather just intractable because it meant
for most updates to Fred that we want to
release we would have to make a cookbook
change just to add some defaults so
organ odd is this little tool where it's
rather general you give it a Jason and
the keys are airline well and the it's
so just message trucks and the keys and
values or airline terms and this sort of
translates out in two things you would
like to override or delete in something
that looks like an airline sis config so
as a result of this we've we've have a
minimal number of sis cookbook changes
so now our cookbook only changes when
things about how we deploy our chains as
opposed to having to add these defaults
to it every time we want to roll out a
new release so deployment Fred and cred
are both able to handle Exmor R PC
traffic and in most situations the
functionality that Fred cannot handle is
proxied to cred and so we have a load
balance in front of this guy so if say
Fred needs to go down for maintenance we
can still just send everything to the
old system so Fred's or upgraded
independently of the legacy system it
happens multiple times a week and so we
are actually not using rel up or
anything like that they are independent
say listen off that well we want to
upgrade them we just take down the VM
and then start a new version of the code
ok I'm actually going to talk about
frameworks more because they're pretty
awesome and it actually goes a lot
towards the fact that when you have
developers also doing the operations
they do a lot of stuff to just be lazy
about things and the real point here is
I think the just when you have
frameworks it really gives you the
ability to add new bits of functionality
or the common call patterns with a lot
of ease
so I think one of the most important
frameworks that's really really made
this migration possible is so bucks this
is on our github and this is the
framework we've used to re-implement our
RPC api and at a high level it's got two
things one is the soapbox types which
are somewhat general it's a way of just
specifying little input validators for
things and then there's the soapbox
methods which is really multiple
callbacks for separating checking your
arguments and converting them adverse is
actually taking the call on the
converted arguments so I you know you
keep hearing about how klarna you know
how we are taking the call on Fred and
just decided whether or not we can take
it a lot of this is based on soap box
method routing it is implemented with
parameterize module and so it's at a
high level where it's a really really
basic Combinator it's that here's a call
back well so here's this here's the
behavior you have you specify
implementation for how you type check
the thing and how you do the call and
say you have two implementations and you
want to decide which one you use so
really you they're just three inputs to
this thing you have one implementation
the other implementation and something
that decides how you go in between the
two and because the soapbox interface is
all these a method is a callback which
is a module then having parameterised
module where you take two of these and
round and watch it gives you a module
with the same interface is the natural
way to do this it's about 15 lines of
code works perfectly and so yeah so
using this we have what's called the
Fred custom routing and what this is is
that using some more parameterised
modules
we we take the call we parse it and type
and check the types of the inputs on
Fred and then we actually inspect them
so for get addresses there's certain
corner cases which have not been ported
over to the new system yet and based on
whether we know Fred can handle this or
not on the input we either take it
locally on Fred or proxy it to credit
and so there's actually theoretically
several thousands of permutations we can
do this on and using several layers of
parameters modules it's actually very
very little code so another nice
framework we have is our log r smtp back
end this is a little different from the
one out in the wild on github so lager
itself is the back end so Jenna benzes
it's you know it's a framework you give
it event handlers and so what we like
about ours is that the smtp back in
itself just specifies taking this log
message and sending it out to this gen
smtp implementation so the details of
who the message from to subject body are
all oral in a call back so there's a
dummy one which really sense it nowhere
but it's this notion that well how you
know how the user of this wants to
format their subjects how they want to
format their error emails is probably up
to them the fact that they want to take
a log message and send an email is a
rather general concern but how they form
at these things is system specific so
the details of that should not be part
of the of the you know male alarm
implementation but there should be a
hook to be able to provide this in and
actually someone in chlorin I thought
this was a pretty reasonable idea for
his system forked it modified it a
little and roughly the same same
principle but for SMS back in so in this
the you know the 160 character message
and the end the recipients or specified
by a call back sort of a more general
thing where we love call back so much
with pests call back store call backs is
our rate limiter back end so this is
sort of a generic rate limiter for lager
backends and you can install something
and have different rate limiting based
on severity and its general enough that
we have we can use multiple versions of
this instance of this in the same system
so Fred currently uses the rate limiter
back end twice once for SMS and once for
emails and so here's another this is
kind of the craziest lager back and we
have I don't even think half the
Clarenville person about this one it is
serving so we have these message brokers
anyway one of our backends is to send
the log messages over the message broker
so officially we are using this very
nice paid solution called splunk for
aggregating blogs but there's a certain
and there's certain instances where you
really just want to log into a machine
and Talia logs for all five of them
there are however many and there's
certain logger backends where you want
to evaluate them but you really don't
actually want to install them in your
production machines so you so we have
this separate thing and this sort of
relies on the fact that there's a nice
ADT for the notion of a logger message
and it just sends the message over the
message you instead of some
serialization of it and on the other end
we just get a vent and notify this to a
logger running there so we can use
logger back in so the logger message is
generated on one you know on the actual
Fred notes but there's a handler for
them on an entirely independent system
that's it and I just this is everyone
who has ever made a commit on Fred
master so questions
thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>