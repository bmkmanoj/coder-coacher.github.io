<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Lambda Days -  Kevin Hammond - ParaForming(...) | Coder Coacher - Coaching Coders</title><meta content="Lambda Days -  Kevin Hammond - ParaForming(...) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Lambda Days -  Kevin Hammond - ParaForming(...)</b></h2><h5 class="post__date">2014-04-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yheKUGtnlgk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I I'm Kevin Hammond I come from the
University of st. Andrews in Scotland
what I'm going to do is to to show you a
better man smoke that i'm using with
colleagues of mine this is chris brown
and Vladimir Yannick as part of a
research project that we have running
which is to do with looking at how you
can exploit our refactoring as part of
the functionally inspired approach to
deal with the problems of parallel multi
core programming so if you want to know
more about this you can follow along
with our project or you can follow me
this my email this is our project web
page lots more stuff few to to find out
about their and if you want to please do
asking questions during talk if you if
you like that I'm going to have to keep
that's very quick because I have 15
minutes less than I originally planned
for but I will have the answer any
questions and please do send me e-mail
or please do get in touch so it can
hardly be sketch your attention that
we're in a new era of the more tech of
the multi-core so in to roughly 1985 we
had the Intel 386 this run at 12 to four
hundred megahertz I in 1993 we had a
huge leap we have the Pentium processor
running at six hundred to 300 megahertz
in two thousand internists the Pentium 4
Ronnie 1.3 up to 3.6 gigahertz and then
things changed 2006 we have the first
dual core processor Intel's and core 2
duo running at one point eight to three
point three gigahertz and today we've
moved up to a period where we have
things like this ivybridge hexa-core the
sixth scores are 2.5 to three point six
something dramatic happened at this
point in time you'll notice looking at
the looking profile after this point in
time cause we're getting faster at
roughly that's point in time roughly
between two thousand and two thousand
five that stopped happening rather what
happened is comfy sack Intel started
givers multi-core processors they
started to develop parallel processing
systems as mainstream activities and
today what we have our beasts like this
this is the Intel Xeon Phi it has 40 or
60 cores running in a single package
okay so this is the the current state of
the art in parrot in prose technology
and the reason why this happened was not
just that Intel ran out of ideas well
maybe they did but the reason this
change happened from ever-increasing
clock speeds to increasingly parallel
computers was one of having to deal with
an energy barrier in two thousand Intel
had our oppressor running at about 4
gigahertz very interesting device they
had it running in the lab so on got any
idea how much power it drew over 200
watts yeah bout 300 apparently 300 watts
so this thing it was the fastest press
from the world it ran at 4 gigahertz on
an intel intel core intel cpu and it
drew 400 watts it ran for apparently
about second at a time before it
overheat it in tow realized that
unfortunately this was never going to be
practical even under desktop and
certainly not in machine like this so
you imagine carrying around 400 watch
processor sitting in my desktop I would
get extremely burnt whenever I try to
use it on my on my lap and this why
you've moved to these devices now this
device is very interesting have you had
it having seen this before the Intel
Xeon Phi No
so released last year 2013 there's a new
one coming out this year which is even
better so this is great 40 or 60 cause
in a single package you can plug this
into your desktop machine it only draws
about 120 watts and you have 60 cords in
this device this is quite a miracle of
packaging there's one downside anyone
got any idea so I oh um well that's
gonna be a big problem but software oh
right it runs linux sorry price by
setting a thousand dollars for 60 course
that's not much temperature it is
actually actually the clock speed so the
reason you get advice like this running
at using only 120 watts with 6 40 to 60
cores in it is because the clock speed
has been cranked down all the way to 1.1
gigahertz and this is a trend which is
happening at the moments of trend which
is accelerating there's a trade-off
precisely between how fast you can make
calls run between the amount silicon
they occupy and the amount of power they
draw a roughly speaking the amount of
power the energy budget that we have
available for any processor at this
point in time is fixed we can't draw
more than two or three hundred watts and
a desktop machine it's not desirable to
draw more than probably about 30 or 40
watts in a laptop machine and it's
definitely not desirable to draw
anything like that in my mobile phone so
this is the state of the art so this is
what's known as a the Intel Xeon pised
examples of many core machine what I
project why predict go into the future
what we'll see is something where we
have hundreds of thousands or millions
of course as part of a CPU design and I
am calling this the megacorps computer
that anyone heard the term before good
as any does anyone have a Wikipedia
entry
it writes I would like you to please go
into Wikipedia now edit this and
attribute me with with a name I'm trying
to make my mark on the world so what
will make a call computers look like
well they're probably not just going to
be scaled versions of today's multi-core
the program have many many of these very
very lightweight courts of what we'll
probably see are lots and lots of very
very small cause he's growing running
even slower than perhaps from one point
one gigahertz that we can see in the
Xeon fine but what they will have is a
huge number of different types of course
GPUs things to do authentication
possibly once you can program soft coors
field programmable gate arrays fpgas in
Central et cetera they will be highly
heterogeneous you'll be able to afford
to have lots of specials cause to do
particular things because the problem is
not going to be your it's not going to
be fitting a number of gates onto a chip
it's going to be how many of these
things you can actually fall to power at
given time very frightening Lee for most
of today's programmers they are probably
not going to be uniform shared memory so
non-uniform memory access is likely
pasti even hardware distributed shared
memory or even message passing systems
on a chip and big arrays are not going
to be a programming a good programming
abstraction in fact shared anything is
not going to be a good programming
abstraction we can already see this
today current architectures the Xeon Phi
already is shared nothing even AMD
designs even the latest Intel designs
these are showing aspects of reducing
the amount of sharing so shared memory
is supportive today it's becoming
increasingly hard for computer
architects to sport it in the way that C
programmers for example I would like and
this guys is where we come in so fast as
computing world today this is as of jun
2013 the zen one have any idea where
this is China yeah it's the Chinese
national university of defense
technology it has 3.1 2 million calls so
the idea that megacorp computers are the
future is actually not true they're the
present if you can afford them well I
wonder what they're doing with this
defense technology hmm and even in
Europe in the project that I'm running
with a gh with Erlang solutions we have
access to a reasonably large scale
system so equal access to machine which
has 113,000 Intel course this is a
supercomputer of course but it's not
just about large systems you even move
our phones today are multi-core the
Samsung Exynos 5 octa has H cause very
interestingly you can only run for a
time why power consumption yes so why
have ate half is faster so we have four
fast chords which we use when we're
playing flappy birds sorry when we're
doing serious work and we have for low
power cords which we use our when we're
doing things that don't matter like
email and spreadsheets and that kind of
thing right so you can see what the
priorities on so this idea of having
dark silicon silicon which you can't
actually afford to power is becoming
increasingly common but it does it means
that we have to be able to do ads with
our head genius system with systems
where the available computing resources
are not fixed that's not the program
which can vary during program execution
we need ways of adapting flexibly to the
available hardware resources we have to
deal with the multi-core and many call
challenge and if we don't deal with
their
then all the other cool things that
people like doing fun user interface etc
are just not going to matter because
we're not going to deal with and Intel
is shaky concerned by this because they
would be they want to say you chips it's
all future program all future
programming is going to be parallel so
but if I have a megacorp computer does
that mean that I need to have millions
of threads it is that going to be a
problem well yes of course do here is an
example profile from one of the
applications that I've had running in
st. Andrews and if you look down here I
don't you can read this number it says
33 11 6 15 to 20 k that is not my phone
number that is the number of threads
that are running in this program okay
331 million threads created in about six
or seven seconds of execution time does
anyone run Java is your system going to
cope with that probably not this is
Haskell by the way okay if you look very
closely what you'll notice is this
natural running on 16 core machine so
you've had 331 million threads
creational 16 core machine the trick is
to is this converted figure down here
which is 20,000 what's happened is I've
taken my 331 million threads which is
what I would need to run on a very large
scale megacorp machine and I've filtered
out from those 331 million the 20,000
that actually matter allow me to run on
a 16-core machine and that's part of the
trick having scalable flexible
parallelism but lets you go to really
large-scale parallelism but equally can
be scaled down to deal with relatively
small scale machine 16 cores 64 cause a
thousand port relatively small
yeah I get to teach you how to build a
wall okay now this is basically situated
in your mind some of the issues to do
with parallels so it's giving a talk in
the University of Manchester and
speaking to ian watson his data flow
going and he said to me yeah your talks
very interesting Kevin but there are
some things that can't be parallelized
okay fair enough such as well building a
wall so how do you build a wall well
we've got a bricklayer polish bricklayer
make it local looks like a parish
bricklayer so how do you build a wall or
you lay a brick and then you lay another
break third one and now go row bricks
and then we lay a brick and another it's
still standing yes in Britain we build
like this then you lay the next day of
bricks elay another brick and second one
and so on naval second row of bricks and
now we do the third one no go to war
okay so clearly this is completely
sequential or is it well let's imagine
we have four super polish bricklayers
how can we build a wall well you've got
more than one of them so they could
their break and then make it lay another
brick and now we've got our first level
and then we could do the same and then
we can do the same and now we've got a
wall that is clearly functionally
equivalent to the previous fall you can
see that it's exactly equivalent to the
wall that i have before but we did this
in parallel using four amazing
bricklayers amazing polish brick
so how much faster were these
bricklayers using the Polish technique
3y3 slightly more than 3 so roughly 3
because although even though I have four
bricklayers I can only lay three bricks
at a time to make the passion work so
there are things that are fundamental
even if you had an infinite amount of
bricklayers with this pattern you still
couldn't run any faster this is a
fundamental limit on the speed up that
you could achieve with this particular
problem it's about factor 3 just over
fact with three great here's how not to
build a wall brick brick brick brick
brick that is a concurrent programming
problem is ridiculous why is it
ridiculous so dependency it's perfect so
there are implicit dependencies in the
brick structure what I've ended up with
is functionally equivalent to the
previous wall you can see that however
the dependencies mean that it's not
going to work in practice understanding
recognizing the dependencies is
absolutely critical to getting a good
parallel execution so task
identification is not the only problem
we also need to consider coordination
communication placement which of the
brickies does the work scheduling which
order they do they place the bricks and
so on can anyone see a another way to
get anyone see a way to improve what I
just shown you yeah
due to other and two on the left side i
could put four bricks yes and then do
and so I introduced some so this is
actually example a very common problem
with people dealing with parallelism
that we see for example fact that I
built it a layer of time we think that's
necessary I have to build a layer of
time what we're proposing i think is
having placed two breaks i can place one
on top of them so in fact although this
layer level of bricks looks like a
strong dependency if we think it's
officially carefully I for example if
we're hostile programmers what will
realize is that actually what we got
there is very weak dependency that soon
as you've laid to these two bricks you
can lay one on top of it as soon as
you've laid three bricks we can lay
another two and so on so actually you
can do quite a lot better than my factor
of three even though I said it was
theoretical limit yeah typical
concurrency approaches once we see in
C++ Java etc require the programmer to
solve these problems okay we need to get
away from that we need structure we need
abstraction we don't need another brick
in the wall what we need is think in
parallel using new high-level
programming constructs avoiding issues
like deadlocked etc without fiddling
with communication etc this is very
contentious by the way besides very
contentious and also including
performance information for too long
we've got away from the idea that you
need to know what your program how your
program runs in order to write it
effectively with the new era of parallel
programming we can't forge ignore issues
like performance and particularly energy
it's part of our design said modified
design in the future so how are you
going to deal with that well obviously
functional programming this is Bob
Harper from Carnegie Mellon you can
check you can verify this quote it's on
his facebook page
so nice thing about parallel functional
programming particularly in a language
like Haskell is we have notes listed
ordering expressions which means you can
for example debugs closely to run in
parallel but no locks deadlox or race
conditions this gives us a huge
productivity game and it's just site say
and don't think the parallelism is just
concurrency it's much more than that if
I've got 331 million threads I have to
think of them on maths with typical
concurrency approaches it's like having
my children I can tell each my children
what to do I can name them individually
I can know exactly what they're doing if
I have 331 million children on the other
hand problem is much harder you can't
know what each of them dance
individually you have to treat them and
program them or mass and that's what
we're trying to do in the project the
paraphrase project are that I'm working
on with agh airline solutions and other
people so the approach we're taking stop
bottom-up think about patterns parallels
and structure the components into a
parallel program restructure if
necessary and use a refactoring approach
to do this so to situate the work here
are some common patterns of parallelism
so for example a pipeline hopefully
people familiar with a map is another
kind the pipeline a parallel pipeline we
have several stages each of these stages
can run in parallel with a map there's a
data parallel pattern we have a number
of workers each of the workers can run
in parallel over different data items
and there are things to a reduce is a
full or a fold basically collapse things
down a tree structure and divide and
conquer essentially combines things from
a reduce and map and Google Map Reduce
you might have heard of combines two of
these patterns generally we need combine
or nest several I've been working with
my colleagues on something called the
scale library for Erlang are this is
fully Nassif festival gives us kind of
dsl parallelism
please feel free to download it and play
play around with it from here it's
actually what we're trying to do is
we've got something called run this is
something in scale library what we do is
we provide a skeleton that is one of the
patterns I've shown you so far and
implementation one of those patterns
give it some input items and that
produced as I said about put items these
things are streaming they work over
several streams so here's a parallel
pipeline skeleton where there's picture
of it I sensual jane is providing a
tagged structure in erlang got pipeline
remembrance of nested skeletons in the
same form given inputs and watch the
scale run does is to interpret our
parallel structure and execute that in
parallel how'd you can do this other
things a task form basically has a
number of workers running in parallel
reflect the results and what happens is
again we passed it inputs and we we run
them as before you need to get the
pattern right so this just an
illustration if you choose a naive
parallel program so the blue line is
what happens if you paralyzed Erlang
using the obvious approach of creating
lots of processes if you use the scale
approach and you choose a form or to
notice is you get much better not quite
straight line but much better speed up
and this is all know 24 core machine
running the University of teaser so what
we're trying to do taking sequential
code Erlang c++ java haskell got pattern
library we run our sausage factory here
and outcomes Erlang C++ Java has stopped
map this down to our her shyness
architecture now I'm afraid if you give
me erlang you don't get Haskell out
we're dealing with the program structure
and this is refactoring so refactoring
changes structured source code using
semi using well defined rules
semi-automatically under program of
guidance so for example you can do is to
use refactoring transform we take
a component and we can turn it into farm
with a farmer and a number of workers
have a very simple example here image
processing or jeggings are reading an
image in two images in so here is a
picture of Joe Armstrong here with a
picture of viking helmet and what we do
is your client price is called white
straining screening blank out the
background emerged the two images
together write it out so this is
conclusive proof that Joe is actually a
Viking here's the Erlang structure for
that what we're doing we've got a
pipeline which basically reads images
convert murders them right amount and
the convert image does two things if
white streams and emergence and so on
the parallel the program structure so
the squad structure basically says that
right convert read what we can do in
parallel is to have a form over the
reeds pipeline that interconvert
operation and farm black or we can have
other ones too so refactoring lets's
convert between them in a bi-directional
way now go little jello here but i think
i'm going to have to skip it
unfortunately five to six minutes I
don't can you see this anyway barely
okay one gonna have to do I think it's
too this is this this point it's quite
neat good go ahead what a problem at
hand doesn't quite be many pattern yeah
if it's like a just social match or you
can find any pleasure can you somehow
wiggle it or it's very very good
questions the questions if you've got
near pattern can you can make it fit and
thus interesting research question it's
one that we're hoping to look out in the
near future so the answers I think so
but not in all cases there'll be things
that you can't things that aren't place
enough so you can't always make things
match
it's just actually show what we're
trying to do Betsy what a tool here are
this is everyone's favorite refactoring
tool that is Emacs what we do is we
select for example a rule from here
which tells us we want to introduce
pipeline I've done that on the top level
gives us with feedback about what's
happening and then what will happen is
once I say yes it's okay to do that down
here it will automatically rewrite my
code so that I've now got a pipeline
built in here and we complete that for
these other stages so what we do is to
for example select two now I've got a
three stage pipeline with the different
functions reeve convert right if we
select one of those after the first one
what we'll see is that we can turn that
into a farm and it will do that for it
let's just show you how the idea works
it's pretty neat you're getting
automatic program rewriting taking into
account performance information that
gives us new parallel code structure now
you may think that was quite simple we
try to do this to you try to tell a
group of experienced Erlang programmers
about scale and get them to do it by
hand it's amazing how many mistakes you
make the tool prevents all of those
mistakes guarantees the program
structure and moreover can take into
account performance information this
shows you some feed op results we're
also applying it to large-scale
demonstrations these are from an
Austrian company that we're working with
so I'm going very fast now they have to
cut the talk down this shows you that
the performance results with our
approach are solid lines are very close
to the ones you get using manual
approach it's they're almost as good as
doing things by hand or equally good so
you don't lose anything from doing this
but what you gain is to trance transform
development times in days interested
times in hours for the parallel
component she think is kind of neat so
factor 24 our performance and
productivity improvement one thing with
a moment is to build an automatic
pattern discovery tool so it's kind of
what you were asking so we think this is
a bit like googling your program looking
for patterns so what you get back is a
hit list the ranks the patterns in terms
of the order of performance then you can
choose which refactorings to apply or
you can hit the i'm feeling lucky button
and it will pick one for you so to
complete I i guess a set social patterns
so to include the many core revolution
is here and we have start worrying about
megacorp have stern energy both
important most programming models are
too low level often based on concurrency
we need to expose mass parallels and
patterns and functional programming
really help with abstraction their help
us introduce the means of threads and
help us easily control it isn't this
just wishful thinking this filled
wobbler and Hank barendrecht instant
Andrews well no we don't think so
because even more conventional languages
are C++ 11 Java 8 as used by silvio
berlusconi have lambdas and other
features that will help us deal with the
mass parallelism and in fact we have a
version of our tool also working in C++
basically reflecting functional ideas of
passions into C++ code okay lots of
things I can show you further reading
I'm working on a new book at the moment
talking about parallel Haskell and this
pattern based approach we need to thank
our funders for those of you who are in
research in the universities and in
companies there's lots of money out
there this good area please come and
join us
and lots of companies are interested in
what we're doing of course please come
and join us thank you so questions
whether I've heard a fortress and yes
yes I have and I've had dinner with guys
steal so I'm not I'm not that for me I
haven't used any of the perils and
contacts in fortress and I think that
they what they're doing there I think is
is basically a sort of loop parallel
level they're exposing implicit parallel
code relatively fine grained what we're
doing here and that's done more or less
implicitly the entire conceited approach
we're taking is one that keeps the
programmer in the loop so approaches
that are implicitly parallel they're
quite attractive however up to date
they've only been successful in very
very restricted areas so if you've got
something essentially nested loops you
can automatically parallelize it what
we're trying to do is go from much much
bigger things so that's the objective be
I've shown you i hope that what we've
done here is very generic so it's not
just Erlang it's not just c++ it's not
just Haskell it's not just Java it's not
just Python it's all of these things
this refactoring idea code
transformation you can do on any
language all you need is that all the
performance information and the
underlying constructs so we think yes we
could you we could explain that
importance to
that's correct yes yes so again it goes
match my previous answer which is are
you trying to keep the programmer in the
loop so the questions about can use
scarlet mac raised to example to hide
some of these things as the question is
to what extent do you keep the program
in the loop and we think that the
programmer is still very helpful in
terms of defining top-level parallel
structures but certainly techniques like
just-in-time compilation like macros are
to do object writes code sorry
particular it's a code translation are
going to be very important in fact one
things that we're doing in the project
is I didn't get time to talk about it is
to use machine learning technology are
to basically allow us to automatically
adapt run trying to things like
different parallel programming workloads
that that kind of thing and interfacing
then with macros or just-in-time
compilation indeed will be very valuable
we've been looking at my next project
proposal the machine learning is
extremely generic but the tool the tool
is very generic essentially all you need
to do there you need information about
the program structure they provided you
have the right information about the
code structure and performance
information in the right form then the
tools we'll work on it so yes it's it is
very generic it doesn't need very much
to support it
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>