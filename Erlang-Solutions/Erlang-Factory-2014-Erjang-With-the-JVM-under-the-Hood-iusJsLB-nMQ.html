<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory 2014 -- Erjang With the JVM under the Hood | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory 2014 -- Erjang With the JVM under the Hood - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang Factory 2014 -- Erjang With the JVM under the Hood</b></h2><h5 class="post__date">2014-03-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/iusJsLB-nMQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you um I was actually a
replacement talk for somebody who
couldn't come so you know several people
in the audience here that probably
haven't seen a previous version of this
talk before anyway so um I'm Kristin as
I said as Tom said I'm CTO and try fork
and I I'd like to to hack every once in
a while I go on a hacking spree for a
couple of weeks and four years ago I
found myself with some spare time I
finished the project and I wanted to go
work on something else and I did the
first version of of this girl Lange on
the JVM and it was a big there's a lot
of comments on Hacker News back then and
this was actually last time I did this
talk and just before Christmas it was
exactly four years ago so it isn't that
long since and and lots of people were
quite skeptic about whether this could
even fly and whether this was a good
well this is a good thing to do etcetera
etcetera and maybe I'll come by some of
these issues and questions as we go
along that popped up back then but I'd
say the most intriguing thing of course
was that some people said that this
couldn't be done and of course that
really triggered needs to say of course
you can do this and I didn't I didn't
stop before it worked the other thing is
whether this is something that's really
desirable because generally people
choose Erlang for reliability and and
having beam as a rock-solid VM even
though it's pretty slow might be more
interesting than other options so I was
arguing back then that you know at least
in Java space we have lots of
applications where we're a throughput is
more important than
the next little agencies and stuff like
that so there's most likely a large
class of applications where people are
accustomed to to those prioritizations
rather than you know the latency kind of
things that typically been built with
Erlang anyway so just um kind of the
highlights off of the features were
Jiang is actually quite complete it does
actually run a relatively recent release
also older releases I'm working on
seventeen and maps and stuff but that
doesn't work quite yet
it runs Java 7 so I've done quite a lot
of refactoring recently to bring it up
to a newer JVM there's some stricter
code generation requirements and stuff
the basic operation of this is that it's
a dit so it just in time compiles beam
code to JVM code and for from the Erlang
program's point of view it really can't
see a difference it works just like beam
loading beam files and and is the suit
in principle p-please be completely
transparent so on the upside you can
imagine you can do all kinds of
interesting Java integration you can run
it inside a Java program you can imagine
calling out to all kinds of interesting
Java libraries and in a very efficient
way like Lucene was up today so it runs
all kinds of Erlang things it's a net
all async IO Misa compiler shell Erlang
distribution you can run all that
recently we added support for nips so
you can just take an existing Erlang
release and just run Erlang on top of
that it'll load the nips right out of
there you don't need to recompile them
or anything like that and it it's pretty
complete so back to the question why and
you have to keep this in mind you know
this was really started as some as a
project for me to learn Erlang
so I I've done this before I also did
the Ruby VM and and an objective-c
compiler that Apple ended up using other
things so I liked I like this I'm a
language guy I'm compiler guy like many
people here and you know it's just a
good way to understand things is to
build them so it's kind of from a
high-level point of view when you run an
Erlang program it gets compiled into
these beam files just like Java code
gets compiled into Java class files and
they could run on a beam emulator and
there's some built-in functions whoops
it took there the Nate that's the native
code and run all this on top of whatever
favorite OS you have so what urging is
is just a reimplementation of this
middle layer in Java and all the bits
are then written in Java and all this
gets run on top of a JVM so the next
level and in that struction here is that
everything gets run as java bytecode and
that should really give you all the
advantages of the push that's constantly
happening in JVM world so as the JVM is
really quite amazing piece of
engineering effort that's been going on
for the last close to twenty years now
where it's constantly been pushing the
compiler technology the runtime compiler
technology and that was definitely one
of the things I I was I was
disillusioned about when I came to to
Erlang world was you know why don't
anyone have a dynamic optimizing
compiler that does cross module inlining
and dynamic optimization etcetera
etcetera so that's one of the pros and
being in the Java and JVM worlds you
know it's socially acceptable it's
provides integration to a lots of stuff
there anything we can connect you can
connect to it in Java but most
interestingly you have this constant
push and
and VM and put in pushing performance so
from an early in perspective there's
also some kind of flip sides of the coin
here's some of them you know first of
all it's actually quite a challenge to
implement it because because Erlang is a
dynamic language that JVM is the static
language which is it's really very much
types of the Java language that JVM
bytecode and it has to has to pass this
runtime type check when you load code
there's all kinds of arbitrary
limitations for instance functions are
limited to 64 K by code size and
actually if you just take a standard
Erlang distribution and compile all the
beam files that are in there there's
some of them they're bigger than 64 K
bytecode and there is some very clear
energies like it's not very easy to
encode Erlang process model because
inner life in Erlang this is a very
lightweight processes those don't can't
come around in in Java there's threats
and then probably you know it's probably
a quick critical thing that I often come
across is the garbage collection is
global when I talk to people about it
they say but what about garbage
collection and of course garbage
collection in Java is something that
every once in a while more or less stops
the world for like maybe a couple
hundred milliseconds so you know if
you're into these low latency kind of
things that's obviously the one that's
an issue so very well maybe it's it okay
I run let me let me just try to run a
little thing here just to show you that
it works right
here we go
right so so when I um I just like date
Earl here that's Java Erlang you've run
use run the Gerald command and you have
a shell just like any other show you can
do one plus two and it oh there you go
come choose three now this was pretty
fast I saw this did you see the start of
time it was my singly fast right now is
that so let's try to stop this and then
I'm gonna what I'm gonna do here is we
moved that cut my coat my I'm gonna
remove my coat cash I was tied to start
it up again now it starts somewhat
slower because now it's actually did
compiling to Java as we load here the
core modules of of the Erlang
distribution gets at this point I
compute 1 plus 2 I can do 1 plus 2 much
faster let's see if we have oh it didn't
find a foo let's see
here we go
CP
I don't
okay
that's a bit it's a bit of a hassle here
let me see I can compile an airline file
here
now he's loading the Erlang compiler and
compiling it to Java bytecode and then I
took awhile but we can compile you again
and now it's a lot faster so basic stuff
works but also more complex works Compaq
stuff works anyway let me get back to uh
if I can find my slides here ok so if
you're one I mean
costas obviously has this very complex
and nice big performance thing I have a
really modest performance the
performance thing I found somewhere in
Ossipee distribution which has some some
basic numbers for comparing sequential
Erlang mostly between beam and an or
jiang and these are some kind of the
coarse grain numbers for for it
sequential Erlang that in general is
like quite a lot faster it's like
between 2 and 10 times faster for lots
of things and you can look at these
various numbers and explained what I can
explain various things for instance you
see working with some generic server the
timeout is a slow one where it's only
about as fast as beam that's because my
scheduler sucks
I really didn't put much effort into the
scheduler it's an interesting project
that could be done if somebody want to
help out there's probably lots of
low-hanging fruit there another thing
which we'll get back to why that is is
float arithmetic for instance is a lot
faster than beam and that's because our
gen can do type inference it does type
inference and the beam code and can turn
it into essentially in many cases plain
Java floats that dengue turns into
native code so for this particular test
program it actually worked quite well
another little classic example is the
bring example there's 10,000 node ring
10,000 size ring 10,000 processes so you
can actually run 10,000 processes quite
easily if I run it there's some various
graphs here for how many mm nanoseconds
per message so smaller one is better
so beam with one scheduler is pick one
you can see actually the fastest or
Jiang version is actually one that only
runs one schedule I see up here beam is
faster with two schedulers this is run
just on my mount mayon machine here but
or Jiang is actually faster with just
one scheduler again that's back to the
scheduling I end up getting memory cache
contention and all kinds of issues
because it's just fussing forth them
back fussing memory for a time back so
if you see one of these runs here here's
another one with 100,000 processes
running on beam it has various times but
the interesting are the numbers in the
parenthesis there you see I between
seven and eight microseconds per
iteration and in our Jiang you see this
numbers starting out quite big but then
falling it starts out at it starts out
at 12 and then falls down to like two
point eight microseconds per iteration
so that's actually the JIT the Java JIT
kicking in and optimizing the particular
behaviors of this concrete Java program
so that see that's the interesting
interesting thing about the JVM is that
it it actually constantly adapts to the
particular behavior of the program as
it's running right now it might be that
you're running batch drops at night and
other
online things during the day and
actually dynamically over over time a
JVM will it caches the compiled code and
and manages the hotness so if if the
code hasn't been used much it can throw
out did compiled code and decide that
something else needs to be compiled
right now so if we could bring that to
our Jiang there could be really
interesting in terms of throughput and
stuff so the bulk of this talk will be
on will be on kind of the internals of
how the how the the virtual machine
works so here's to some bullet points on
think so I'll go over are we loading
beam files some on the float flow
analysis and type inference after
approaching a little bit about code
generation and then some things about
housing how were encoding tail calls
possible calls and other very special
cases
so the did compiler hooks into of course
you do loaded beam file you first
problem was to even read a beam file
because back when I was doing this for
years ago there really wasn't a spec for
how to either beam file it had to read
the source right then I do various type
analysis and stuff and to Jaden Cochin
and that every module like that gets put
into a file it just has the same name as
the module and then a hash code over the
module so I can that's how I catch them
and kidding these jar files can then get
reloaded so it hooks in just like the
beat just like beam does into the air
handler the air handler aptly-named
it should really be the unknown module
handler because it gets invoked whenever
some missing function is there so
there's an undefined function and then
that calls the BIF called Erlang load
module
and then in our case Erlang load module
well uses all the same OTP logic for
loading the modules from from OTP paths
etc and eventually after after could
them compiling that it didn't uses the
Java class loader mechanism to to load a
Java class called urging dot m dot foo
which is then living inside that jar
file eventually so haven't eats module
in his own in its own class loader like
this lets us do also do code reloading
so code reloading also works you can't
throw away code in Java but you can make
sure it gets garbage collected by
removing all references to it so some of
the core kind of difficult complex
encoding things as is how to encode
processes and messaging and that's
actually by building this on top of a
framework called Coulomb that code
rewriting framework that rewrites the
Java bytecode so I generate Java
bytecode and then pass it through a
bytecode transformation system that then
encodes a co-routine mechanism on top of
that tail calls i encode myself using
this trampoline encoding and the state
encapsulation and the immutability of
data is just a nature of all the data
structures being immutable so it's all
all things like tuples and lists are of
course just java classes and instances
of these java classes and they're just
all persistent data structures in fact i
used quite a bit of closures data
structures for some of the things we see
all just just persistent data structures
so let's look at how a piece of code
here gets encoded so here's a module
that has two functions
bat and foo and it has all the kind of
recursive nests
features the
so we'll start by looking at the first
function bat which is the first first
class is self recursive and the other
class just returns one of the arguments
so when this gets compiled to beam code
it looks something like this this is
like pseudo beam code I cleaned it up a
bit for presentation purposes but
essentially actually OTP has this beam
disassembler that you can just invoke to
get it print out somewhat like this so
dumb so the the self call the self
recursive call is that there's a special
instruction for that called call last
which this essentially gets interpreted
as a go-to by by the VM there's a bunch
of labels moving around x and y
registers etc when this gets compiled
into Java actually if you compile it
into Java and then D compiled that coat
with a Java bytecode decompiling I'm
pretty printed and clean it up a bit
then it looks like this
I don't generate Java code i generate
JVM bytecode directly because it's not
all constructs that are like go-to
doesn't really exist in in Java so this
cell precursor function turns into
something quite quite simple and quite
readable where it's essentially a loop
where they continue its really a Java
bytecode go to instruction it's
essentially a loop where all the type
tests are done in this way that I call
some virtual function and if it returns
null then the type test fails and if it
returns something else then it that
particular thing coming back this of the
right type so I see the first argument
here is an object which is a generic
super type for all Erlang terms in my in
my world and I can say test non empty
list and if that's really is a non empty
list
see before it there was this beam
instruction is non empty list
so when I call test non-empty list
either it returns a non-empty list of
the correct type or I'd return to no so
that's how pattern matching gets encoded
quite straightforwardly a list has to be
decomposed in a head and the tails like
this blah blah blah the second clause
here if it is test nil then I get a and
no value back and if that is no value is
not null then it is a nil and then I can
return them see there's a this special
may be block thing that one that's bolt
right there that's because otherwise so
it does so this is a place where I'm
encoding this as co-routines
but every time there's a backwards
branch in the code generation
I always insert a a check whether this
process has been killed right did
somebody say exit to this with some term
because then this would cause an
exception to happen at that point so
this thing gets cleaned up correctly so
these may be blocks could be are the
things like inspection if it's if a
process is suspended you can also ask if
stack trace and that gets created lazily
also inside these things
yeah it's like an yeah I mean all
backwards branches I insert this so but
I mean to eventually this is like a safe
point or you know a place where it so I
can can be sure I can always get in
contact with the process because it is
cooperative right maybe we'll have time
to come back to that the other function
down here is is two things that are
different one is that there's an
external call and also it's also
tail-recursive
the call to list reverses until the
Christian position and there's an
external call so let's look at how that
gets encoded now this foo function gets
encoded into something like this where
yeah I have the original foo function up
there so the first thing is to invoke
the plus plus function in Erlang module
that's plus plus is really just a normal
exported function is it's in Erlang
module so we'll assume we have a static
global variable called Erlang append to
that we can call invoke on okay welcome
back to how that comes about so that's
just an invoke it so Erlang event 2
refers to a function object that we can
invoke on the next one is the tail
recursive call to list reverse which
gets encoded because by see all all
functions have an extra argument the
epoch which is abstraction over the
current process this is this independent
of threat the current process is this
lightweight process and it has some
special positions to store to tell
recursive calls so what we store in that
in these special variables tail and arc
tell is the function that should be
invoked in tail position an arc is the
argument to that and then we return the
special value and assume that whoever
called me we'll make sure to make that
invocation right so every time you call
a function that could be in tail
position you need to make a special
all it in a special way and that
particular special way
is this actually I'm going to do a
normal call that's in line that's not in
tail position we call the Dalek call
version here which calls the tail
version that's the one you saw before
and if that returned the tail marker
then we have to iterate on this function
object and say do one step of the tail
recursion and you just do this all over
the place and it falls out as a tail
recursion really working well at the top
level there'll be one loop at the very
top level of a process there'll be one
loop that essentially boils down to all
the tail recursion going on
so these magic global variables I talked
about they're actually injected by using
some Erlang or some Java annotations so
this module that these functions get
compiled into have static variables like
this that have these urging specific
import annotations so when were Jiang
Jiang VM loads in this particular class
it looks for these annotations and make
sure that filled them out with that ef'n
object that corresponds to whatever was
declared here so um there was just a
couple of recursion things so there's a
there's a lot of different types so as I
said II object is kind of the generic
top-level term of everything there's
numbers integers
big small floating-point numbers there's
like a type hierarchy like this and this
type hierarchy is one of the aspects
that gets exploited by the JVM because
it can do its runtime type analysis and
do more precise dispatches based on on
runtime type type and and feedback
information so there's a hierarchy of
different kinds of lists consoles ESX
are well-formed lists that we always
know are well-formed
they're more efficient in various ways
Lizza where is it the basic types atoms
references pits etc a pit is not the
same as the process the pit assistive
reference to a process yeah well didn't
I tell you it was broken okay I'll tell
you about that so there's some various
types here so there's some of the type
I'll get to jump to it some of these
types are a runtime type generated like
tuples there's a I generate a specific
triple class for each area T of tuples
up to the points and likewise for
functions there's a function type
generated and illicitly for each area T
of functions so let's see I'll skip away
this yeah so there's some there's a flow
analysis so it does a complete abstract
interpretation of the entire beam code
extracting as much type information as
possible out of the out of the abstract
abstract code interpretation and that's
actually combined with overloading of
the building functions for instance
here's some of the definitions of the of
the Biff called plus right so it says
post is actually overloaded depending on
the types of the arguments so the more
precise the type inference can be can be
combined with these overloaded versions
of the bits and actually that's the
combination is what makes the type
analysis even more precise so when you
call something with a double then you
always know that the result is a double
for instance if you pause two numbers
like that so there's some support for
that and that's this whole thing is
really the reason why this float
arithmetics ends up being so fast
because floats are one specific
whereas numbers have two types
introduced of two types there's the big
and the small ones so let's see an
encoding processes that's what is that
what you want or it's really the
scheduling that you want okay
so Java doesn't really have lightweight
threats or some je viens actually do
have some pretty good lightweight
threats but in general context context
switching is quite expensive and it
doesn't have Co routines either so so we
really completely rewrite the Java code
to to turn to to enable code routines
and I'll show how this works so assume
that you have a sequence of activation
records under stack these are Java
normal Java activation records that are
under stack and you then you hit receive
some kind of block and call receive is
really more or less the only blocking
call in in Erlang right yeah
yeah when you're in an infinite loop
yeah well if your infant bald as I said
the infinite loops always end up calling
this they always end up or any-any
backwards branch always end up calling
that maybe then that checkpoint that I
said and that one also checks the number
of reduction so you could write there is
a reduction counter but it doesn't
really count function calls it calls
like kind of interesting yeah
so here I'll explain how the co-routines
works okay so you have a set of
activation records like this so so
what's the time limit by the way five
we're supposed to be finished five
minutes - yeah okay so I have a set of
activation records here plain Java
activation records and they're not
really easy to get rid of right and say
for each of these activation records
they represent some method and there is
some instruction pointer position inside
that method where this given call was
made it's not always the same of course
so so if we hit a blocking call like
this a blocking operation then
essentially what the code rewriting does
is it injects code for this case to save
some logical program counter and the
state of all the local variables it's
stored to the size in an object and a
Java object to create a Java object that
has this information this is where we
are and these this is the value of all
the local variables we allocate a new
thing and the heap to store this and
then we return to the caller in a
special way but make a normal return of
course because that's the only thing you
can do in Java land but you set a global
thread local flag to say where
right now we're suspending so because
just when I returned from this function
you also need to save the PC in the
state and likewise every time we go back
save the PC in the state and all this
gets collected up in an array which is
which is really the suspended state of
the current process right and then when
we need to resume this function or this
we need to resume this for the process
you are I was actually one step behind
in my slide I was looking at when you
read to resume this process we can do
that actually quite efficiently by
creating an empty frame with
uninitialized Java local variables we
only grab the program counter to figure
out which nested call within that given
method that needs to get executed so all
the way up to the actual frame that
needs to run again here we need to load
the house of the state of the local
variables so now we have this kind of
very shallow stack that has really no
information in local variables there it
just has activation records with with
default values and all the notes and all
their local variables and only
meaningful local variables in the in the
top frame so this is a typical pattern
that happens actually that we then
suspend again right away because often
you're sitting in a loop receiving
messages right which is probably not
with an empty stack running a gen server
and you have a couple of stack frames
before you actually go and that looped
it sits there receiving message the same
so avoiding to load and resis load and
save all the local variables of the kind
of outer stack frames is it's actually
quite a big win because you don't have
to move this data around you don't have
to reallocate it so if we suspend again
at this point
we'll just save this current frame up
there and jump all the way out we don't
have to we don't have to save anymore
all right because all the all the
variables further down are the same as
last time so if we can keep track of
this if we're just careful in there
looking at the code and the way we
rewrite the code and doing suspense we
can see we don't have to even have to
save all the program counters and all
the states because they're exactly as
they were before and this is this is the
key to actually making these context
switching be really fast this often
there's just a single frame that you're
sitting in the loop receiving messages
so so there you run end up running
through a lot of instructions to do a
context switch but actually very not
much data is moving around to do a
context switch so if you do instead of
suspending here you just return then of
course as you as you return you can load
the local variables because we keep
enough infrastructure in place to know
that when you return here you actually
don't have the local variables so you
need to to put them in place so it kind
of unrolls like this so all this of
course imposes a lot of extra taxes on
the undercoat gen so if you have a call
to this if you have a foo function that
calls bar as we saw before it actually
injects a lot of coats around it so
running it so whenever you enter one of
these you end up in our case statement
essentially it switches on the current
logical program counter the cult site
counter you could call it so it could be
that the logical program counter was one
that means we're actually inside this
call site one so we need to jump down
there do some housekeeping with the
current stack frames that's the down and
up function calls that do the
housekeeping
then we call bar with this special fiber
abstraction which is equivalent to the
this process lightweight process and
then whenever you return there's four
actually four different ways to return
they can and that's the every time you
return from one of from a function call
you actually have to be essentially this
fit that up essentially takes this
process local variable saying how are we
returning are we returning because we're
now suspending and this stack frame that
we're in now should be saved
you take the local variables and put
them in the reified stack representation
are we now suspending in this fast way
where we've previously been saved are we
if that's the case then we just you know
return null because the values and in
the stack representation are already
there are we really actually performing
a return from the bar function and now
we need to restore the local variables
because we were previously suspended
then we go into that restore local
there's worst case otherwise we have no
return normal so all this is of course
extra instructions but it's just
instructions it's just instructions and
instructions are amazingly cheap
compared to moving data around and it's
all the data access that happens here is
data access to hot memory which is
processed lower thread-local it's all in
a hot memory cache and probably level
one cache anyway so it actually
amazingly doesn't cost a lot it just
kind of bloats the code so this in in in
java land all these functions that can
suspend that can ultimately call message
receive i actually marked by a by a
checked exception called possible so
this can pause
all right so that that means it makes it
kind of convenient and when writing Java
code that this possible exception you're
never supposed to catch it but you it
kind of it's a marker that means
anything that can throw this possible
exception should have this
transformation applied so it functions
that are not possible don't have this
all this bloat apply to it solely
functions are are nice because they
don't they don't need to be bloated this
way and then there is part of the flow
analysis of a compile time is exactly to
figure out to reduce the amount of this
bloat also because because the flow
analysis figure it out if given function
it could could be could be suspended if
it called something that could be
suspended so there's kind of an
implication there so quite recently so
that's end of the code gem stuff quite
recently I spent some time actually
getting elixir running and it works
quite well so I really think elixir is
an interesting case for jjang because
you know in many ways it's a better Ruby
but in particular the Ruby community has
quite good vibes from JRuby which is a
Java Ruby implementation and I think
because of that I could make both it
could make elixir more interesting maybe
to some people and this could be a way
that also or Jang could get adoption and
get some interest once elixir picks up
so I'm hanging my hat on that because of
course right now it's a one-man war or
actually I have one of my employees
who's also hacking at every once in a
while you can't stop so just like with
so every time I pick up a new Erlang
application and try to run it on a Jiang
find some new corner cases that I mean
that's the case every time I pick up a
new application there's new corner cases
that you know it doesn't work or
whatever I don't have a huge six tensive
test suite
that's another task if somebody wants to
help me make the OTP tests work for a
long time there was the bar for just
even getting the OTP tests to run was so
high that I didn't even try but now I
think I it could could probably be made
to work if somebody want to help with
that but for making Alexi run kind of
duh the things I had to look at was fix
the name mangling Alexia generates some
weird Erlang module names that have dots
and weird things in them that I didn't
catch names of modules that I mean in
principle Erlang should support any atom
as a module name I that didn't work I
had to work quite a bit to reduce code
and stack size in particular erlangs
compiler is pretty bad for when running
Erlang the Erlang compiler on top of
elixir generated code which probably
also is quite big kind of just those
sheer levels of recursion was really
pushing the limits so in urging has a
fixed stack size right when you when you
when you start JVM you say what stack
size you want threads to have and that's
it of course I made that big did various
code generation rewrites to reduce this
exercise and then Alexia's test feed
it's actually very very picky with all
kinds of error conditions and make that
stack traces should be exactly the same
all kinds of boundary condition is its I
was I've really been impressed with
elixirs test suite there's a ton of work
being put into it so super high quality
this week so
if I actually can run quite a bit like
98% of Alexia's tests of more than 2000
unit tests there's still some
improvements and like areas like file
systems and Unicode and files that have
junior code names in a corner case
corner cases these are like but every
application tend to have these corner
cases they do an intern so the newest
thing I'm hacking on now this is the
last light there's a new spell called or
GFI that you can cast on a release
because how do you how do you make
people useless right because you could
run the Jade Earl and then you get a
shell running on top of an OTP release
and blah blah blah with Jiang if I spell
you can take in some existing Erlang
release an application and make it run
or Jang Swiss lling around startup
scripts and arguments and stuff and I'm
hacking hour 17 right now and if
somebody want to help out with any of
these things or write a new scheduler
you're almost welcome to help so that
was it
just ok let me show you let's see have
this so so if I want to call a static
function that's very easy I just build
into the air handler that if if you call
a module that doesn't exist then that
happened to be a module that you can
load then I'll just load that Java class
and call a function like that so you can
run the garbage collector for instance
like this so that's very straightforward
and very simple then if that thing
happens to return a value that's an
interesting thing if it returns an
integer of course it just gets an
integer or other primitive types if it
returns an object then things get tricky
if it returns an object then it becomes
a thing which is like a resource
immediately it looks like a resource an
if resource so it prints as a binary but
you can match it as a number of
different things you can you can max it
as a list for instance and then I'll see
is it does it implement Java util list
and then it magically kind of decomposes
as a list so this is kind this is like
how closure also does integration or if
you have an external Java object then
you can try to match it in different
ways and if it kind of implements a
behavior that could reasonably be
matched against a list then it
decomposes as a list or it's a string or
whatever and you can also use that as as
kind of the left-hand side here in front
of a colon so you can do and what looks
like if an external function call on one
of these things kind of like
parameterised modules so it looks very
much like
pretty straightforward object-oriented
programming so that's that way the other
way there's a there's a Java API that
you can use to send messages into or
jjang
you can't call straight into our Jen
code because it has this because it
needs to run and with its own co-routine
encoding stuff but you can send the
messages into so there's an RPC server
whenever you run and Jiang VM it also
has a RPC server in there that you can
use to call from sometime okay okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>