<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Made in Heaven: Erlang + VoltDB - Henning Diedrich | Coder Coacher - Coaching Coders</title><meta content="Made in Heaven: Erlang + VoltDB - Henning Diedrich - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Made in Heaven: Erlang + VoltDB - Henning Diedrich</b></h2><h5 class="post__date">2014-05-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qYMruyq5PQE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I guess in a nutshell that's that's what
my toe
alvord is something I created and I
would love you to try it and it's very
simple it's basically just those four
lines and I'll be coming back to those
four lines and maybe in the end of the
talk you find it worthwhile to try to
yourself so first of all who am i I'm
handing deeply I'm the founder and CEO
of a small but very ambitious game
company actually I'm also working at the
technical director for an event agency
where we're doing all sorts of
programming that has to do with shows
and events and I'm also the maker of L
volt so L bald as you saw on the
description is a driver for volte B
which is a high-velocity database and
the reason why I got into this was
because we were looking basically for
the perfect game server now that's a
probably something that'll never exist
but it's where it comes from that's also
why i started to learn Erlang because i
had some experience with java and i
found our line that gave the promise
that this problems that i experienced
the shaver might be a thing of the past
and same with vol TB because i had some
experiences of my sequel and i looked
around for the best possible option to
try to avoid these kind of problems in
the future so there was no driver for
using well TBH knurling and I said about
actually three years ago to ride one and
I came up with one quite some time ago
and it was already used in production by
also by a game company but it was a
purely synchronous driver and basically
you can can do a lot of stuff if you
have a synchronous driver but it's not
really what this database is for so
we're going to look at balti be what is
that is it worth your time then at the
driver itself and how you use it and
then we're going to look at a small
sample and a benchmark so last year
basically I came here and had the
opportunity to talk about the game
server as a whole
and wall TB is just one part of the game
server the others along in Lua and
that's year I had the announcement that
there was an upcoming asynchronous
version of the driver and now this year
I'm happy to come back and focus on that
stable asynchronous version that I have
meanwhile managed to put on get up so
what is multi be in a nutshell i would
say probably many of you have programmed
for bread is and red has had this
promise we're going to have a red is for
clusters well that never it maybe it
will never be true in the way that you
hope but volte be with a kind of a
different approach but with a lot of the
same things like Redis could be in my
view called a red is for clusters plus
they also kept many of the good things
of sequel waltp has a tail and this is
Mike Stonebreaker and the points that
he's making he's very disruptive he
likes that word and he's very strong as
presentations but I think what's really
important to know is that he's round in
this database world a long time he's the
guy behind ingress and he did post Chris
and he kind of knows what he's talking
about and what he's saying now is the
time of the one-size-fits-all in
databases is over and he feels that we
are in very exciting times that are
reminding of the 70s when there were the
database wars and now we are seeing new
database is coming up and vol TB really
is his proposal for an OLTP database so
ball TV is create as is made by volte
being that was founded in 2009 and was I
development out of MIT in berkeley where
they had experimental horizontally
scaling charting databases it is open
source it's important to know it's
created estic tutorial as early
you won't have a saying necessarily but
you can contribute it's explicitly made
for oltp it's not made to replace every
anything that you can do with my sequel
for example if you look at cap we talked
a little bit about that later it's
probably see a it has some simple subset
of sequel it's in memory but it also has
a very good disk persistency and it has
acid and that's probably what was most
important for me looking at it because
for games you often need egg form of
double bookkeeping that is very hard to
do if you don't have acid so in a more
general view if we're not talking about
games we're not talking about the in
signs of the creature itself from the
business best perspective how they're
positioning themselves as a product they
saying basically and I think that
reverberates what we just heard vol TV
is about big data and instant answers so
it's different than hadoo it's not so
much about the the way that you work
with MapReduce but you do have sequel
queries and you do have materialized
views but are pretty good pretty fast
and you let them run all the time and
that's why even if you have a very high
data p coming into the database you'll
have your answers really fast from
technical point of view what eb is just
taking a pain out of scaling because if
you're not Twitter and if you're not
facebook and you start out with my
sequel it might very well be that you
won't have enough funding to overcome
that moment when you have to have a
cluster because we have so much data the
one server is not going to be enough
anymore so the use case for vol TB
that's really high throughput and that
means not the fastest latency not the
fastest answer possible but they'd
rather sacrificing a little bit of
latency but as much through good as
possible and we still talking about
Layton sees that you don't feel on the
web so what they saying but it's very
good for is real-time analytics that
are used for real-time results I find a
lot of similarities between volte B&amp;amp;L
Lang and this is why i called it match
made in heaven they're both made for a
concrete need they're not the results
like some competitors of probing around
and then now maybe it fits for this or
maybe Oh what fits better for that for
that no there was a concrete research
before the product was even started to
be created and experimented for wal TV
is really made for distribution it's
really made for multi-core not just
trying to cope with a new situation that
we have in the hardware market no it's
made for that like Erlang was back in
the day and it's also a truly different
approach pretty exciting approach and
that also something that hasn't come
with Iran and what we as I said is
corporate created and still open source
which is important there is a full pay
enterprise license and you do get some
very good stuff and if you're a big
company you probably will want it that
and you will pay for that license but
quite honestly the open-source edition
is so good and so complete that it's not
a trick to just get you into buying it's
more like if you really use it on a
professional level at some point you
going to want to have support and
additional monitoring that you want to
have on a professional level so I think
the main features of all to be are
probably as I said before it's acid it's
still sequel and that that is pretty
important in some cases and gives you
some flexibility that you lose if you
lose sequel it's also about high
availability so that you don't lose your
data and you can always be online and as
I said it's about scalability how they
position themselves was pretty
interesting with you you look at the
competitors in the market and and what
is well to be good for if i decide to to
look at a new database then if you look
at different use cases of the age of the
data like on the left hand side you
would look at very very new data just
came in on the right
inside on aging data and view if you
look at the value that is in the data
how fast you can react to that new
information that just came in and the
resulting value of all the Greg
aggregate data that came in so that you
can get a big picture reaching back in
time then waltp is positioned on the
left-hand upper side where velocity is
marked high-value data that came in very
recently and you want to have a fast
answer for you see like i do and data
warehousing and traditional air dbms are
positioned and in other areas they're
mostly has there on the market for three
years now I guess not their business
picking up they were quite some
customers now but it's like Erlang it's
not well known and the mainstream yet
that every IT student would know about
something interesting that this pie
chart shows is that where vault of you
really did something new and really has
something that is making it a different
creature from say my sequel is that they
get rid of everything that you usually
have to have in a database engine to
write to disk and that is a conscious
decision because Stonebraker who as I
said was around when these databases
that are now mainstream were created in
the 70s and 80s back then you just
needed a disk to have all the data
stored somewhere that comes from a
normal ordinary business but today the
data that really comes in business and
that's in the area of gigabytes fits
into memory and that was just not the
case like 30 or 40 years back and that's
why all of the traditional and
successful database on the market who
are now changing into something that is
also highly caching and in-memory have
kind of the wrong architecture for the
hardware that we have now and by getting
rid of most of the overhead that is in
the internal
architecture of most databases they were
able to get rid of as they save 75% of
the usual workload within a database and
run a word about sequel sequels are
often derided but if you look at it it's
only as flaws and the syntax might be
awkward sometimes but essentially what
sequel is about is math it's about
raising the relational database model
and that's pretty sound math and the
advantages that have been found are not
tied to the syntax are so sequel but you
don't want to lose those advantages and
that that isn't at the core of it why
was to be kept sequel if you I don't
know if you ever work with no sequel
databases in the beginning it it's a
interesting promise what you can do with
it but as I had on a previous slide the
strategic flexibility of then changing
course is something that you might lose
when basically all that you have to do a
search or a query is your key and very
soon if you really get down and have a
project that you use the no sequel for
you will find yourself programming keys
into a programming indexes into your
keys so that you have multiple ways of
accessing the data and then after a
while you realize what what I really
would want to have our indexes so that's
why successful no sequels also offer new
ways to index data and that's why sequel
is something you might be missing
in general if you look at the database
market and try to get an orientation
about okay what databases with it that I
look into it and then what fits my needs
then cap can be a good starting place
and you can group the databases in
basically three groups where the idea is
that out of those three things
consistency high availability and
petition tolerance you will have to
sacrifice one now that's highly debated
even the inventor brewer is meanwhile
has revisited that topic and stone break
is also very heavily protesting some of
the conclusions that are drawn from that
but it gives you an orientation and as I
said wall TB is on the CA side not
entirely sacrificing but being weaker on
the petition tolerance side so it's not
elastic yet there they say they're
working on it but it's it's a really
consistent it's not eventually
consistent and it's highly available in
that it has a built-in replication
mechanism acid as I said before why is
that so important to me well in games at
least if they're a little more complex
when you have that threshold when you
pass the threshold where players
interact with each other that's really
it then you have the main data sets the
records at the player records
interacting with each other and then
what you what you almost can't live
without is double bookkeeping because
otherwise money gets lost or swords get
lost or duplicated if you have a crash
and you would think that acid is really
something that's for branded but of
course it's not the new sequels the
companies that are pushing the nose
equals explain to us why base which is
or eventual consistency can for many
business cases be a more interesting
choice for example Amazon where dynamo
came from might care more about the
other
features that come with with their
dynamic structure and there they don't
care so much about how fast the
consistency has arrived that is
something that you have to look at with
your application view for example
storing images and each individual
images images images one data point and
the images are not interconnected then
you probably don't need asset but if you
store some form of data that has whether
it has something to do with each other
what the individual data points the
major data points are going to do then
you might find you need a real asset so
if you have base and or eventual
consistency and if you go through it you
might find that it's really hard to
emulate on a database that's not giving
your acid to have an asset behavior
because in a way that's really what
databases are for to give you that so
how does house multi be achieving what
what it can do for one they are
compiling queries into the database core
I come back to that in a minute then
they have single thread execution they
call it a transaction completion that is
something that is really close to what I
find in Erlang where to have a lock
basically you create a funnel by one
individual process and that process is
going to be the only thread that is
going to access a certain resource and
that's how you make sure there is no
race condition possible one process is
going to run over this code only and
that's it and vol TB does in a certain
way pretty much the same they are they
need a little bit more information
upfront about how your data is
structured and what can be expected how
it can be used later and then it's
charted in a very intelligent way so
that really what what's happening is
that per cpu core one transaction is
done complete incomplete
with all the data in place with all
information in place the one cpu core on
one machine of the entire cluster can
complete the whole transaction and
that's kind of the magic ingredient how
they achieve the speed because that's
why they can leave all the locking away
because one processor core cannot raise
itself and how they achieve that is in a
pretty intelligent way I find that they
are just looking at how does data really
look like real data is there's a common
structure there and that is that most of
the time it has a kind of a snowflake
structure underneath now remember the
times when this guy was cool it's a bit
that's a little bit of for me the dirty
secret of balti be that underneath to be
able to compile the store procedures
into the server core you have to do a
little bit of java and this is how it
looks you can see in orange you can see
the actual query of this had a world
query and this is the bit of java you
have to program around in this case
pretty clearly it's boilerplate and i
would think that volte we could go down
the path and just generating that for
you and doing all transparently and i
kind of appreciate that they don't do
that because the driver around your
queries will stay simple but it also
gives you a very high flexibility when
you need it because really you have a
number of Java classes and you can do
pretty much anything with it that you
need and the trick here so to say is
that this way you have program in your
anti stored procedure and like with sore
procedures you're kind of moving the
calculation to the database server and
you're moving the calculation to the
data so you have them close and that's
why it can be so much faster and an
entire transaction with maybe four
operations or more is this way executed
right into the server it's compiled into
the Java server and the junior they are
of the server
and it is executed right where the data
is with all the data in memory already I
had that these are the petitions and
this is the information that multi we
will need you to provide about your data
before you start and usually it's pretty
simple if we take for example an
ordinary business might have customers
and those customers are the basic need
of the database and the customer numbers
probably what you would start to have a
hash and that's all and then the
individual slices are put on the
individual clusters cluster servers and
K safety is basically provided by
putting slices EE on different service
so one server node goes down there's
still a copy on another server node
interestingly historically well to be
started out with a leaderless
architecture where each node and the
cluster was equally right about what
what is true and they found and practice
that would make more sense for them to
go back I say go back to a master
architecture because in practice and the
idea seemed to be very nice and
philosophically beautiful but in
practice it can be a lot faster for
writes and reads there's a lot of
performance that you leave on the table
especially for reads in a way if you
don't have a master now the snowflake
structure that's something if you
imagine the snowflake is one customer
and everything that is stored to that
customer and basically all the data and
all the tables that you have are
pointing back to the primary key of the
customer and even if you have an order
and then the items of that order and the
items point to the order the auto point
to the custom and that's what they call
snowflake and these snowflakes are
usually the majority of data
if you take a real problem but then you
also have some non-aligned data that
doesn't fit into that snowflake for
example that could be your portfolio
your customer your product tables now
typically those product tables are not
as big as your customer table I mean if
you start out maybe it's Weiss aggressor
but if you're an established business
you would usually grow and will want to
scale most of all on the customer side
now what's happening if you store that
data with baldy B is that those
snowflakes are distributed over the
individual nodes of the cluster and that
could be the customer number would
probably better than in my example here
the idea is you use the first letter of
the last name of the customer but by
whatever criterion those snowflakes are
distributed and the non flakes are
replicated and that's not one of the
other pretty intelligent tricks that
waltp does if you have your product
portfolio replicated transparently for
you as a user across the entire cluster
then that makes sure that individual
transactions are much more likely to be
completed within one core because every
core has direct access in its memory to
the entire products table and whenever
you update the product table which is
something that would usually happen much
less than updating a customer somewhere
in the system maybe if you think about
it could be 112 a million times less so
it's it's a much slower data flow there
then vol.tbd does that transparently for
you and make sure that all the tables
are replicated across the cluster have a
consistent state again before the other
transactions are kicked in again and
that is something that in a certain way
makes well to be more sequel even than
sequel databases because of you go about
designing a database very often I find
that in the back of my head I already
know what I will optimize by doing in
the application
set up in the queries because certain
things I know is just going to slow down
the query and I can do them much faster
if I have a look up table in the
application for example the product code
and this ball to be that optimization
makes no sense anymore because it's so
fast on the server side and it does
exactly what you do to optimize on the
application side that you can write it
into the query because the product code
is going to be a see table in memory in
vol 2 B 2 and you can't even optimize
that what happens is that your sequel is
going to be cleaner and that's something
that we found doing a real moderately
complex data structure we found well
certain optimizations don't make any
sense anymore and the tables look
cleaner that was a fine that was kind of
an indication that they're doing
something right there for me so yeah
what do we meanwhile has drivers for a
lot of languages and now it also has an
erlang driver and actually I'd like to
sort it like this I guess and this is
how it looks that verse is an insert
call that's actual Erlang using the
functions of all TB it's pretty easy
pretty straightforward and it's not more
complicated than you would otherwise
access your data there's a select down
there that's also going it's it's
modeled pretty much after the java
reference api and this is a hello world
that's actually the complete HelloWorld
it's actually get exactly the hello
world that you would be executing if you
executed those four lines whether I said
you can install and try it right away
what you see here is simply just the
application you started up then you have
to create a pool and a pool of
connections and ball TB is something
where every server of the cluster has
its own line to your client and that's
important for distributing load also
right from the client so that's why you
have the concept of a pool that would
usually have you connect a cluster there
would be a list of the IPS or the domain
names of the individual servers in the
classroom instead of local host then you
create their result and actually select
in this case is the name of the store
procedure it's not sequel but it's what
we what we saw in that example about the
Java a little bit of Java that was the
Select stored procedure and that's
called here by name and then we get a
result back and well TBH there is no
idea of this stream of a result coming
back because usually in LCP you'll have
short apps you have short requests and
short answers and what's coming back as
a complete structure and that is then
analyzed using functions that el valle
provides and in the end you close the
pool so it's really easy I did a
benchmark using that driver and I get I
was super happy to find that the driver
that is native Erlang doesn't only
perform as good as the other drivers was
actually I had done the benchmark before
for the nodejs driver that's programmed
in c and for all i saw the other driver
is in a lot of places faster so it
really shows how good air lange is in
bid map pattern matching and bitmap
decoding on the lowest wire
level so what I did there I think the
most important number is probably that
you have around 25,000 transactions per
cpu core if you use Amazon's Cloud now
Amazon Cloud is really slow for some
things and I think this benchmark would
run a lot faster if I had as many course
to use and really have them installed
somewhere as real machines but this
benchmark is what you could very fast do
yourself I actually I listed the prices
here so if you sign up to Amazon and
just do this benchmark yourself and then
maybe play around a little bit to make a
closer to what your application might be
it really doesn't cost a lot and you can
really try it out on a real cluster and
the benchmark I use is like that example
that you would find scattered all over
the vaulty be blog posts and and and
manuals and it's an example where we
play American Idol or any TV show and
then users all phone and within a couple
of minutes so we have a huge peak on the
database and then you want to have the
result really fast and that's exactly
what this example is made for it's
exactly we've all to be its positioning
themselves and what's actually happening
is in the benchmark the emulation goes
like I'm just fire hosing the server
with a lot of clients and millions of
calls are going in so to say and there's
a small set of candidates like a half
dozen and there's once transaction
basically per vote this is the table
structure for that benchmark very simple
it's just the contestants then the votes
are counted the contestants are six or
so and the votes are millions and then
to make it a little more interesting
there's an area code edit where where
there's a look at what state American
State and certain American area code
would belong to
and these transactions that I listed
there are really four operations and
that's not a cheat or so it's really two
valid up for operations where first they
are looking up okay is the it's the
content sense that is in the call named
in the call is that even a valid
constant number then they're looking at
if a person has voted before so that's a
real read across the entire database
theoretically and then they're looking
at the error code and then when
everything's fine and they found that
then they store the actual vote so
that's happening per transaction and and
that's why the numbers if you look at
them of 877 thousand transactions per
second that's actually 3.5 million
operations per second so yeah these are
the resources if you if you're
interested you find the slides in the
internet I've listed where you can
download Errol bolt I've listed where
you can find more information about the
benchmark I've wrote up a post about it
and that's something that I hope anybody
could just use to just as we did in the
tutorial just sign up for for ec2
account and just try something out
yourself in a real cloud cluster
situation to understand where could this
be going what I'm doing and again this
is what I'd love you to try out drop me
a line if you run into any troubles and
the tunity of the driver right now is
I'm giving it a 0.3 so there's some way
to go I guess but we are having very
good results during the bench Marcus was
very stable and I'm very happy that
Robert voting is said he's interesting
looking at it and will it's already
given you some feedback where we can
improve it so yeah I think this could be
a very exciting thing there and if
anybody feels like he wants to look in
that to that more it's on github and
please don't hesitate to contact me and
right after the talk
talk more about it and if you can become
a contributor that would be wonderful
thanks a lot brilliant thank you very
much any questions so in the example the
do you show with the Select query yes um
the row object that you then struck the
column information from what is that
this is it a port or an open port or a
socket or or or what is a you were
talking about the otic a length code or
the Java code example this one not this
one no what's this one okay and the
question was which I've if you like a
row variable there right get a row and
then you start strutting stuff with this
jet stream from the row yes so what is
the row I am assuming you are actually
streaming data out of the role or the
road just snare long term with
everything on it pardon can you say it
again it's a racket row it's already an
air long term with all the information
on it or is it a port that you're
reading from stretching the info
dynamically yeah thanks for that
question so as I said there's no concept
of streaming here it's a record with all
the answer so it's not very good to
return big answers of huge lists you can
do that to a certain extent but not
reading out the whole database like this
and that's because all the views really
is made for that and like the voter
example you have very short pings of
very short rights and you also have very
short answers they're complex but
they're short in the result yes okay I
have two questions the first is about
you said you mentioned memory it's fast
it's hundred times faster than my sequel
because of memory and then the next
slide you said that's fully persistent
to this so how does that work that's a
very interesting question too and I
think volte be my personal opinion is
they were very lucky they found
something really great and the original
architecture of all TBH was
lyrically said that they had some kind
of rhythm in that they were
synchronizing their system and I worked
a little like this every core kind of
takes in transactions and then waits a
while until it can be sure that no
transactions will come in that are
earlier then what it in the moment has
in its list and then they were executed
as a chunk and that created a kind of
rhythm in the system where there was
always a stop and that is also what
creates a latency of a couple of
milliseconds because they're always
waiting to make sure that all the cores
are synchronized without the chorus
talking to each other and then they
found that during those wait times
that's a great opportunity to write the
stuff to disk that was not planned for
at all in fact i spoke with us this
pharmacia of all TB and he told me yeah
they were really insisting on being an
in-memory database right just like big
table that's all I don't know if that's
even true of a big table but it's like
it never goes down you have replication
across the individual clusters and you
really go by I don't need a disk I have
it all in in memory and I have it
multiple times and that's my safety and
for a whole data center to go down that
was said to be not so lucky but that was
absolutely not bought by the customers
everybody hated that myself included it
I thought it was really stupid to
develop something this way because you
always have to ramp up the database
again instead of evidence Kenai sleet
and so they understood they have to
change that and they they had
snapshotting from the start so it wasn't
based they didn't really start from
scratch but they found that they have
this opportunity there and in those
stops that are there for the
synchronization that without losing a
lot of performance they losing a little
bit they can write it all to this now
that's not literally true anymore
because they changed the heart
architecture at the architecture in the
center of it but as a metaphor so to say
it's still true
and you can you can either get it okay
back if it's stored in memory or when
it's stored on disk but what's important
to know there is that I Oh controller
will very often tell you stuff that's
not quite true and if you don't have a
battery I oak controller that is going
to be able to write too hard disk even
when you have a power failure then even
they okay from the i/o controller that's
on disk now is not gonna save you so
it's a tricky area there where does that
mean that the size of the database is
limited by the size of memory you have
you can't have a DP bigger than memory
yes and no and and the third part is I
don't really know very well what they
are at now they started out like that
and as I said memory now is so big that
for most use cases you don't need more
than fits a new memory and you have a
cluster don't forget you have a cluster
right so it's and also this benchmark
was I used several computers for that
like 10 or so we all had tens of
gigabytes and for real application at
least for what I would do there that's
all I need really but they are I know
that they were working on being able to
store more than fits in the main memory
and what I don't know is how far they
are cool thank you very much probably
outside thank you probably hungry oh do
you know any or which support will to be
for example hibernate maybe 10 or
hibernate can you repeat just do you
know any or RM which support won't be no
I don't know you know in rom or 10
Lester normal ok thanks and have you
thought about a create a norm for a long
maybe is it good idea actually I'd
appreciate if you just shout the length
I can't reveal his religion mapping yes
if that exists not that I know of
not that I know of which really means it
may it may be it's just something I
didn't look at obviously looking at our
language it cool thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>