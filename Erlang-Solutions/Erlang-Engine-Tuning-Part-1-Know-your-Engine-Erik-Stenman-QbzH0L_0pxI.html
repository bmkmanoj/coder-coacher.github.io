<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Engine Tuning: Part 1 - Know your Engine - Erik Stenman | Coder Coacher - Coaching Coders</title><meta content="Erlang Engine Tuning: Part 1 - Know your Engine - Erik Stenman - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang Engine Tuning: Part 1 - Know your Engine - Erik Stenman</b></h2><h5 class="post__date">2013-04-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/QbzH0L_0pxI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so this talk is entitled Alan ending
engine tuning part 1 know your engine so
hopefully there will be other parts
later where we actually get to tuning
the engine this first part is just to
sort of start to learn something about
it this is the engine of my car and
basically there is nothing I can tune
there it's just a big book and I have no
idea what's in there and this is the way
for most people I think the airline
runtime system is also it's just you've
right Earl
and it starts up and you have no idea
what's actually in there so we're going
to try to look a little bit more in
detail inside the airline VM so I've
been programming since 1980 and in 94 I
found our line and then I wrote the
first native code compiler for a long as
my PhD worked and that's now a hype
which comes with a line OTP platform so
a long time ago I worked a lot with the
internals of the airline VM then I
actually went over to the other side and
worked with Scala for some time and
helped mark and ask you to get Scala 1.0
out of the door and then I got back to
airline in 2005 when I joined Lorna and
I've been CTO for Colonna for some time
and actually most of my time was just
been making the system scale because we
our traffic increase every 10 months to
double the size that we had before and
then we have Christmas traffic that in
just one month runs up to the double
size that we have the month before so
it's been a constant run to just
increase the performance of the system
now when I say chief scientist Astana
does it really mean anything other than
that I can go to conferences instead of
managing people
and I'm currently writing a book about
art what is art well it's the airline
runtime system this is the heating
coming of my house simplicity is for
simpletons so the airline runtime system
is the inner coming of so we can look at
the Ellen runtime system in several
different ways one is the source code so
if you go into your OTP directory you
find one directory called and then you
have the emulator and there's beam and
height and then there's the all the seed
code that so how many in here has
actually looked at a C code of the
emulator some of you okay good another
way to look at it is as components so
robot has been talking about some of
these we have the bean interpreter we
have processes we have the scheduler or
several shelters and garbage collection
native code combination and i/o we're
going to look at processes and garbage
collection in a little bit more detail
today so basically a process it's just
for many memory areas a pointer or
actually it's an ID that paid but you
can see it as a pointer so you have a
stack a heap and mailbox a process
control book and the kid so that's one
way of looking at a process
we're going to look a little bit more on
the process soon but first let's look at
the whole Alimentum system in another
way also it's actually when you're
running the system it's just a bunch of
memory areas so we have the code so this
is what you find when you go into
directory the directory structure and
you look at the C code let's get loaded
into the system you have a C stack where
actually the beam emulator is running
you have many many cues you have miners
in a separate area and one queue is a
queue of processes and then processes
has a memory and then the pin code that
the processes are running storing so one
good thing with these different types of
memory areas is that they are the system
knows exactly what type of memory you
have in different places so it can
allocate this memory in predefined
chunks so there's something like 14
different memory allocators inside
airline the delegates memory for
different needs in this talk we're not
going to go into the details of that
I'll go through it in my book so a
process well I like to you it isn't for
memory errors the PCB message queue
stacking heap actually the stack in the
heap is the same memory area so by doing
this it's much cheaper to check when we
run out of heap space and stack space so
the pointer to the top of the heap and
the point into the stop talk of the
stack or two registers so they are kept
very very high up in the memory
hierarchy and you guys can Paris
they are going to overlap then you know
that you run out of memory for that
process so you save two pointers that
way by having it in the same area and
that also means that if you do recursion
and eat up the stack space what you
actually do is oral to eat up the heap
space and if you eat up the space you
eat up the stack space and if you run
height there's a separate native stack
so here you actually use the same stack
pointer as you do when you run the bean
code you use the C stack pointer or the
stack pointer of the real machine for
your stack so the PCB that's the process
control book this is actually sort of
the heart of a process here we keep all
the information about what this process
is doing whether it's waiting or running
we keep the pointers to the top of the
stack and the beginning of the stack and
the heap and so on so when the process
is not running all these values are kept
in this process control block when the
process is running these some of these
are actually kept in registers in the
machine you have the continuation
pointer which tells you when this
process is going to be woken up and
start running again this is where it
will start running you have the F calls
which is basically how many reductions
that you can do the number of
productions that you have been doing
with this process in total so that's two
counters for how much work this process
is doing you have the ID so this is the
feed of the process basically and flags
say telling you things like trap exit
these kind of things that you can
and there's lots and lots of more things
in the process control ball but these
are the ones that we're going to need to
look at garbage collection which is sort
of the topic of today so if we go back
to the code of the virtual machine we
have this code block with all the parts
that actually runs the system and deep
down here we will also find the tag
scheme so this is how you in a line can
know each term that you're looking at
exactly what term it is so Elling is a
dynamically typed but strictly typed
language so when you for example try to
add two things together you have to know
that both things are numbers otherwise
you get a type exception so you cannot
find this out at compile time because
it's dynamically typed but a trying run
time we have to know that these things
are actually numbers so the way that the
runtime system does this is that it tags
every term or object whatever you want
to call it when you when you're talking
a line source code and a line you
usually say turn when you talk about
implementation we usually call it
objects but it's a line term so I will
use those for the same thing so the
timing scheme tries to use as little
space as possible to actually different
say between all the things that you can
find in a line program so it uses a a
stage timing scheme
where we have a few objects that only
uses two bits and then we have some
objects that uses four bits and then six
bits and so on so some objects are so
small that you can actually fit them
into a machine word but most objects are
larger and have to be put on the heat so
on the heap you will have a header tag
which will tell you what object you will
find and on the stack this tag 0 0 is
used for return addresses so that way
that's exactly the way that the machine
code wants returned and is to look
aligned for consoles that is list 2 tags
are used 0 1 and this doesn't actually
take away any address space because in a
32-bit machine every word is aligned on
a 4 byte boundary so that's 2 bits so
the rest of the word can be used to
appoint it to anywhere in the memory and
bit pattern 1 0 means that this is a box
to object so this is on the stack or in
the register it says that there's
something big and it's out on the heap
and then there's a pointer to the heap
and you don't really know what it is
until you go to the heap to look what it
look at it with and then you will find
the header pointer then you have some
other immediate you have feed sports
atom catch and then nil is a special one
and then you have small integers so all
of these are actually stored in one
machine word so if you have the integer
42 for example
it's just in one machine word it it
never needs to go out on the heap unless
you put it in a list or put it in a
couple or something like that it will
just stay on the stack or or in a
register and with this one one one tag
it's really nice you can add two
integers together without needing to
untag both of them Adam and then tag one
of them so you can gain a few operations
in the real machine code with this tag
for integer arithmetic so that's the
immediate ones and then we have the
things that it can be on the heap and if
you have six zeros then it's irritable
and that's actually a topple but in the
beam code it's called parity well just
to confuse you so if you see this it's
at Apple and then it says how big the
topple is there so you can have really
big tuples if you want to and then there
are binaries big noms reference
functions flow noms exported stuff
reference counting binary binary sub
binaries oh there's space for a new type
in our nice external pins ports and
references oh and another one you see so
this we're not going to talk about today
that much but lots of stuff that need to
be recognized all done by just using a
few bits of the machine work so if you
have this program and you create a
string hello which is just actually a
list this list will be a list of small
integers so in memory it will look like
this you have the top of the stack here
and somewhere on the stack
you actually have a pointer to memory in
this place in this case to the memory
address 1 and 28 she's here
and then there's the 0 1 tag which says
this is a list so if you have to
traverse the stack you're doing garbage
collection and something like that
you will see that okay there's a list
and it's over here and on this place you
will find 1 1 1 1 and that is actually a
small integer and then you shift the
small integer 4 steps to the left and
then you get the binary encoding of 104
which is H as in hello and in this case
we know from the pace that we came from
that this is a console this is a list
the console is always 2 words so if this
word and the word here and here you have
a 0 1 tag again so it's another console
so the list continues at this address
120 so each list cell is one machine
word so in a 64-bit machine it is
actually 1 2 3 4 5 6 7 8 bytes so a
string with hello for example for each
letter it will use 2 machine works so in
a 64-bit machine it uses a lot of space
yeah and then we can follow this pointer
and you find another letter and another
pointer and so on so the whole is hello
ending with nil which is just a lot of
ones in the 0 this is actually minus 5
also so there you can see that list ends
do you don't have to go any further
now
the nice thing with a lying and this
Tigers team is on is that you can
actually share these team terms so if I
create this list and then oh what a nice
placement of the logo I put this list in
a couple so I used to list twice all I
need is this pointer to the list I don't
need a whole list so what I get on the
stack is arity well and you remember
that was actually topple topple of size
two and then two lists and they point to
the same place in memory so this is nice
until you send it or do I you or do
anything that will actually do a deep
copy because then this sharing is
expanded so with this piece of code you
create a list you put it in two places
nice it's still only one list only
treated process you send this term over
to that process now actually on the heap
you have a couple you have two consoles
and one point to list hello and the
other points are not released hello
so by sending a message to another
process all sharing will be expanded and
are you for example you will have to
send it to another process that actually
does the iron in the end and then this
list will get expanded and used up twice
the size can actually write write a
really small and not so nice program so
share it creates a couple with a value
shared and in the base case and in the
case of n here it recursos and also
creates a list of these tuples okay
so we just run this code with ten
recursos
oh and at least ABC has the value so in
about one second we create the structure
we're done and since I did actually
write comma okay here I'm not returning
this structure it just thrown away and
garbage collected so everything went
fine here but if I try to turn this with
list to binary then actually list to
binary we'll do a deep copy and it will
expand this term and then it just
trashes with huge size so I can create
this and as long as it's as long as it's
keep kept shared the structure is fine
and Ekta pass it around and so on but if
it has to expand it gets huge and one
problem here can be that you have one
process that for example that's XML
parsing and it have this huge sharing of
an XML tree lots of pointers into it and
that process crashes from for some
reason and so they crash down to another
process and that process then dies
horribly taking down the whole system I
wouldn't say that it happened to us but
it happened to us yes
so sharing nice dangerous stuff but
let's go back to the other parts yeah so
there's lots of stuff I could talk about
and in the abstract I actually told you
that I would tell you how to get machine
code from the compiler for me so this is
how you do sorry I'm going to talk about
the coping generational garbage
collector instead
yes so here we have a nice little stack
and heap we have a console at the top so
this console points to lists hello you
recognize this it's the same list at
some point we have traded a couple with
two copies of this console so you have a
tag saying that this is console and you
have a value which is a pointer to
memory address 2032 and so on
and now the stack and heap has grown
together and you need to do garbage
collection so this is a copying
collector so it will trick clips
allocate another space in memory just as
big as the space that you had before and
you will have a new heap pointer and a
new heap top pointer to this space and
then you will have a root set which in
this case is just one place on the stack
but it can be part of the mailbox and of
course you could have a larger step so
the first thing you do is you look at
your root set and you see that you have
a pointer 2032 here so you follow that
pointer and copy this element and you
know it's a console so you copy both
these elements to the new heap and then
you overwrite the first word with just
zeros and that's a special type saying
that this console has now moved so if I
find this again some time
I know that it's already moved and then
the second word of the console I write
the new address of the
so as a forwarding pointer and in the
place where I copied I write first
console and then the second one will
still point to the list the rest of the
list on the old heap but now if I were
to follow these pointers doing the
garbage collection I would see that this
has already moved and I can just ignore
it
because it I can just use this
forwarding pointer and rewrite these
pointers to this place so then I'm done
with the route set and then I start
looking at my new heap and as long as
the new hip pointer hasn't caught up
with the top when we did this we
increase the heap top where we can have
free space then we keep on forward
things so we look at the pointer on this
heap and we found the backwards pointer
to this console we copy it to the new
heap and overwrite it and write a new
forwarding pointer to the next word
should say 3000 eat there and then we
keep on doing this until we have
actually copied the whole list to the
new heap and marked all of the old 1s
move and now we're done and we can just
free up this memory area and copy the
reset to the stack to the new area and
we're done
so that was the details of the how the
garbage collector works so it's a
copying collector and one question that
often comes up when you talk to are big
garbage collection in a line is that
well in adding there's no updates so you
cannot get any references circular
references you cannot have a topple
which includes a tuple which includes
the first couple or anything like this
that's a big problem for the reference
counted garbage collector so in
languages like Java you can have objects
that actually have pointers to objects
that I pointed to the first object and
so on and then you have a circular
dependency in references and you can
really never find out that this whole
pair of objects are dead because there
are references back and forth between
them but this cannot happen in a line
because you cannot actually update in
couple so you cannot put a couple that
already existed in a tuple that that you
can only put tuples that already exist
in tuples we cannot get a reference into
the future to topple that doesn't exist
yet I'm sure you get what I mean
anyway still a line uses a copying
collector so one thing that we found in
the hype team when we measured this was
that 75% of everything that on the heap
in a line secretary consoles this is the
most common thing that you have you have
list of stuff and lots and lots of list
of stuff and then there's 24 percents
that are not actually consoles but still
the most of the words that you use their
small tuples and there's other stuff
they are smaller than 8 words
so there's only about 1% that is larger
than 8 words and having reference town
means that you need to actually have a
rather large memory area for each object
on the heap to count how many reference
you have to it also when you have a
copying collector you get better
locality so if you have reference
counted objects and you see that this
object is dead and you just freed up put
it on a free list this object could be
anywhere in memory and then you get
places in memory here and there that are
free and pasted in memory here and there
that are used and you can just spread it
out all over memory with a copying
collector you take all the live data and
put it tightly together in one place on
the heap and that means that you get
Patrick locality so that's nice also the
storage collector is generational so
this robot already to talk about so the
idea is this most object I John so
usually you do operations on lists and
tuples and you break them apart and put
them together and you do a lot of these
operations and then you end up with a
final piece of data that you strip out
somewhere and all these small temporary
things that you create they are not
really needed after that and they die so
you want to get rid of toast and keep
the ones that live for some longer time
so in the beginning you have a from area
and you have some data that has survived
a previous garbage collection so you did
the garbage collection and you fill up
your memory to this point and then you
keep a high watermark pointer here so
that you know that anything here
actually survived the previous garbage
collection and then when you do another
garbage collection you actually create
two new memory areas one we have D
stacked and the new data it's called the
nursery and then you take all the live
data and put it into an old generation
another thing is that you don't have to
look at the data in the old generation
because there can be no pointer from all
generation to this new data here since
it's rated later so when you want to
reclaim this area this is uninteresting
so then you have a smaller set to
garbage collect and then you can do
several small garbage collections only
do looking at the data here moving some
live data to an old generation and then
when this fills up you have to be a
major collection and look at all your
data and see if it's
let me ask
so the screen resolution here wasn't so
great for my presentation
so this also Robert talked about the
advantage of having one keeper process I
don't think he mentioned this though so
if you just have one keeper process or
not not one big heap which all processes
use the same heap when the process dies
then you can actually just reclaim the
memory area that the process used the
stack and the heap you don't have to do
a final garbage collection or anything
you just get that memory are back for
free at once so one nice trick when you
need to do a compilation that he knows
will create a lot of garbage and a small
result is just spawn off the process let
it do the computation send back the
result and then Dianne and onto garbage
collection and then you actually start
it up with a minimum heap size so that
you've got a lot of space to do the
computation and you don't do any garbage
collection at all you just used up that
space and freed so that's manual memory
management within an automatic many so
that's a good thing
also small route set you only have to
look at one process get the improved
cache locality and since you only have
that you have one heap and one stack per
process and you put them together you
get this advantage that you actually
have the pointers for the stack top and
he talked to check whether you're
running out of memory or not if you had
one heap per process you would still
need one step or one heap for all
process he would still need one stack
per process and then you couldn't do
this little trick and the problem is of
course that you
get more expensive message-passing
and you use more space because if a
process has actually grabbed a piece of
memory and uses it but not the whole
part of it it will at some point
actually shrink the heap and stack but
that's only when it's like 20 or 25
percent of the stack that is used so
usually you have a lot of free space for
each process that you need so it has
space to run on and you have a little
bit of free space for each process so
that uses up a lot of memory if you
would have just one he then you just
would need one set of free space for all
the processes copies to a bigger book so
also with the copying collector while
you do the collection you need twice the
space so if you would have just one heap
for other processes another disadvantage
is that and you would need to use twice
that space to actually do garbage
collection but with smaller heaps for
each process you just need small space
for each collection
yes yes binders are reference counted
good question yes let me tell you about
that so they are reference counted and
if they were larger than 64 bytes they
are kept in a special memory called a
binary heap or the binary area or equal
asleep binaries so for each process it
keeps a separate list of all the
binaries that it has seen so as soon as
the process is done a garbage collection
it goes through this list and for each
binary that it has seen it checks
does it still live is it still is it
moved to the new heap or not and if it's
not alive anymore
the reference count of that Piner is
decreased and if the reference count
goes to zero the binary is freed so
that's great but there are two problems
with this so one is that if you create a
sub binary so you just pick out a small
part of a binary you still have a
reference to the large binary so that
will not get freed until the sub
binaries free and every process that has
seen a binary actually needs to do
garbage collection before it's free so
here we have strangely colorized cool so
this little module beam file actually
reads all the chunks of a beam module it
does file read of a file and it pattern
match for one which
the tag that says this is a beam file
then it gets the size and then it
actually says that this is a beam or
this is the format that it's using and
that it's a beam file and then it gets
all the chunks as a binary and then it
reads the shunt and the read chunks
there's a name of each chunk size of the
shank and then the binary and it aligns
them and pattern match shunt on the
shank length and then it reads the rest
of the binary and in the end it returns
all the binaries so imagine that you
just want to get the atom chunk from all
your beam files so you get all your beam
files and it will get Adam chunk which
reads all the chunks and then just takes
out a ton and return that nice but now
this is the atom chunk for each beam
chunk you get a list of atoms and
pointers but as long as we keep these
atom shanks pointers I want to do
something with them actually the whole
binary is kept so we're keeping all the
theme files in the system in memory you
know copy depending on what you're doing
this can really become a problem because
they will not be garbage collected as
reference fortunately there is a simple
solution to this there's a binary copy
so instead of just taking a chunk you
can call the function binary copy on a
shot and then it will actually move that
part of the binary out of the big binary
and create a smaller binary
still if its larger than 64-byte is on
the both heap and reference counted but
now when you're done you can actually
free up all the larger binders so binary
copy will get you out of the problem
that you only needs a really little
small part of the binary and don't want
to keep the rest hanging around so
problem two is a little bit more subdued
so you have your server architecture you
listen to subject and you have some kind
of load balancer that sense of work two
different processes so basically you
just received some big binary from
someone you parse the big binary to get
the request type and the workload and
then you send this through load balancer
the request type from and you're smart
you do a binary coffee on the workload
so if it's just a tiny be piece you will
be able to free the big binary and then
your dispatch a load balancer receives
this message and it looks at the request
type so this is just an app term in this
case a or b and then it sends the whole
message to a and b and it hasn't even
looked at load here it has no idea what
this is
it just receives the request and passes
them to another process and then it
loops now the problem is that in that
message there was actually a reference
to binary so now we have reference to
this binary from the listener from the
word pool and from the dispatcher now
this one doesn't work and it will free
this up at some point these processes
maybe they die they are just pulled off
and do some work and then the die but
this reference
never ever disappears because if you
look at this code it doesn't allocate
any memory at all it does the tail
recursive call it doesn't use any stack
at all it will never ever do a garbage
collection but every time a message
passes through it gets a new reference
through binary which will be kept in
memory so it's not that it will take a
long time as Robert said that long time
is well until the system crashes so
fortunately this is easy to fix you
always add in your little server loops
after thousand when I haven't had any
real work to do for a while I do a
garbage collect and then it will throw
away all the reference to the binaries
and all is fine yes so you could add a
garbage collect here after zero here
depending a bit on your how your system
is working this usually work if you have
any quiet time in your system if you
never have any quiet time in your system
you can tune this but the idea is you
have to explicitly say garbage collect
because this process doesn't create any
garbage possibly so it depends on what
you do to the binary I mean the the beam
is quite intelligent so if you just pick
out some course of it it might even not
create any garbage so ok
so these are the parts of the system we
talked about the garbage collector today
and yeah we're done so I didn't say it
but Robert said it process started out
with small heaps only one and 33 words
or 32 words Mike's words words confusing
string takes a lot of space
sharing is nice but it can explode
copying garbage click use twice the
space - or reference counted and if you
have seen a binary it won't go away use
garbage collection and binary Cup copy
to get away with that yes lots of
questions
yes but it's possibly a more complicated
solution to send messages back and forth
but if if it doesn't get the binary of
course then it's not a problem
it explodes
now internal between processes yes oh so
if you send a shared list within the
same video to another process it does a
flex mode so in this thing there it was
actually binary so it gets a message
with the binary so it will when the
message is copied over it will know that
it will actually use this space
so as long as you don't actually treat
anything in on the heat the VM is
usually quite smart when it receives
these things so the messages can still
be on a message queue and not copied to
your Heat it will just know that it has
to look at a part of it so you never put
anything on your heap it's only coming
through your message queue and you put
it out on another message queue but part
of that message contained a binary when
you send it it will add the character
saying here is a pointed to a binary and
then it will never actually find its way
through this so it will never see that
it goes away because doesn't do garbage
collection if you send the process that
doesn't exist you don't send so you
either you you get the message to that
process and then you increment so so it
is the same operations it's it's atomic
descent operation so either process
exists when you do the same operation
and it managed to do the whole thing
putting it on the other process or it
doesn't exist and then it will do
nothing
yes I pretty sure not having potential
so it depends on how big it is
so if it's smaller than 64 bytes it will
become a heap binary sorry
when you do binary copy yes when you do
an extraction yes because it's a sub
binary so as sub binary just works by
having pointers inside the big binary so
as long as we do a sub binary of another
binary then it's just pointers so that
you don't use any extra space so any any
money pick out any part of the binary
you just get pointers saying that I
picked out this part of it
and when you do that it doesn't really
check the size of victim but if you do a
binary copy and it's smaller than 64
bytes and it will become finer I'm
pretty sure okay so one last thing
writing a book on this I sort of just
started but if you're interested please
let me know hopefully there will be a
book out next year so it's 22 chapters
fine now on everything about this
O'Reilly yes so I hope it will be
available soon to get comments on it and
so on
so the the garbage collection on that
one is completely different everything
is completely different in this respect
because it uses Java it's so I will try
to touch some of the other
implementations in this book also but it
will be</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>