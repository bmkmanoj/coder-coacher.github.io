<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What we Found in the BEAM Code -  Melinda Tóth - EUC17 | Coder Coacher - Coaching Coders</title><meta content="What we Found in the BEAM Code -  Melinda Tóth - EUC17 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>What we Found in the BEAM Code -  Melinda Tóth - EUC17</b></h2><h5 class="post__date">2017-07-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JlGhZ8_wDzY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so first of all this is a joint work so
this is not just my work we factor out
the group of the factor L is not just me
of course
but a couple of PhD students and master
students are in the project so this is a
joint work with one of my master student
Daniel actually he's here so if you have
done really the technical questions then
you can ask him after the talk of course
so this talk is about recovering or lung
syntax tree from the bean bytecode and
why we're saying is that important is
not really as general decompiling but we
wanted to improve our system refactor
with information gathered from device
code so what we have basically is a tool
that is able to analyze different or
long source code so if you have another
long source code then the factor is able
to analyze it and get lots of nice
information as syntactic of course and
deep semantic information about dynamic
structures and cool graphs and data flow
and lots of things but when you have a
file and a software component that is
not available in source level you just
have the beam version of that code and
you are just calling functions then the
analysis of refactor simply stops and
say that okay I can see that there is a
function call to that module that being
but I'm not able to analyze it because I
don't see the syntax tree I don't see
the source code so that's why we think
that if we can gather some information
from these red boxes then we can improve
the information provided to our users in
refactor so for example we can see that
these
you'll cause different black box modules
so we know that there is a function
called because received in the source
code but we do not really know that
there might be some connections between
the black boxes and maybe there are some
other connections as well so we wanted
to explore this kind of information and
edit to the defectors syntax tree and of
course then run some semantic analysis
on that so this is our main goal
enable refactor to analyze not just the
Erlang code but also the beam byte code
what's refactored I do not know how
familiar you are with refactor could you
please raise your hand if you heard this
name okay
most of you so just a few words we have
some developers here as well X
developers and currently real purses man
so this is a static analyzer framework
having lots of nice features of course
refactorings because the names coming
from refactoring or long programs that
was the original goal of the project but
later we switched to code comprehension
support so it has lots of features the
support code comprehension like
dependence graph visualization semantics
we're is also in building level and in
user level so ad developer s and along
developer can ask some information about
the source code like I have a function
here and where I am calling this
function in a way that the first
argument is an ADA or something like
that or a specific value so you can ask
you can build your own queries like that
it's really helpful for example in
debugging when you find that there is a
wrong value somewhere in the source code
and and you wanted to debug that where
this value is coming from it has the
code metrics
source-code the complexity and quality
metrics lots of interesting static
analysis and we wanted to extend this
framework what you see there is the
dependent graph of the media library of
Verloc so what we have is that we have
an hour long code or at least we think
that there were an or long code
somewhere and then the Erlang compiler
compiled it to a beam code that looks
like looks like this and we wanted to
analyze the this code what we assume is
that there's no debug info in the at
this level there's no debug info in the
Indicom five in code
I think usually it's not available we
done research and refactor already has
add a component that is able to analyze
source code compile to being with debug
info because if you do this then
basically you have the abstract syntax
tree or that kind of abstract format in
the compiling code and it's easy to
recover it's a bit harder when debug
info is not available then you have a
basically imperative register based
language describing the functionality of
your own code and we wanted to recover
something that you see on the left hand
side from from this code so what is the
beam byte code look look like so it is
an it compared to a machine code it said
it's a high-level language so okay it
really looks like an assembly code and
and it's basically a register based
imperative language describing the
operation the sequence of steps that the
Erlang virtual machine has to do during
the evaluation but it has some
high-level constructs as well so for
example it has special language elements
for blocking statement and expressing
that I'm I'm waiting for certain time
and then I'm jumping to another to
another label what as it has special
construct for timer I said picking up
some messages from the message queue so
it also has an e and and language
element for that this is usually not a
standard assembly like operation but it
has registers it has jumps and lots of
other operation that is usually in
machine code as well but enhance the
gloss of a long specific information and
what we wanted to do is basically try to
extract these high-level constructs and
list it to an or long language level I
think it's not so and the main it's not
so important is just a refinement so we
try to add it to refactor and basically
we want to get to the syntax tree from
that code it is easy or is it hard to do
something like that I think the answer
is it's not easy to do it because we
have and long as a really nice or long
syntax and we have a not-so-nice
imperative style representation of the
same code and basically this code what
you see here is expressing at the
control flow of the of the year-long
function we with different crossing
edges
and some kinds of ugly structures that
is not really fits to a functional style
so the question here is how to transform
a control flow that looks like this to
add to an ER long syntax that does not
have real jump over go to operations for
example so have to do it you can see
that there are different conditions from
the shape of the controller graph so
there are different conditions and for
example from if this condition holds we
jump to this statement and if this
condition holds
we'd run to the same statements or if
doesn't hold it yet now in both of the
cases because here we have one okay but
how to express it in your long maybe be
duplicating the code or something but we
have exactly this structure in the
Erlang code if even is okay then I'll
return done if even these something yes
then I'll return done as well so the
compiler does some optimizations so
these code blocks that are exactly the
same are not present twice in the in the
beam code instead of that there are some
special go to operations that are
pointing to the same label in the beam
code and and makes our analysis a bit
harder and not just that this is just a
simple example there are not so many and
not so heavy optimizations in the beam
code like unusual machine code
but but there are some and we have to
discover them and try to build in into
our analysis so how is it working so
basically we have a beam code we using
bu Long's
the disassembled modules to get the
disassembled version of that beam code
and we wanted to be able to the syntax
tree so basically this is
pipeline we go through and I will
details each of the steps so we have
different intermediate representation
where we try to shape the interactive
style register based language in
different steps to be more functional
and finally get the Erlang code the
amongst industry so we use as I
mentioned in this assembler module to
get the beam language the Erlang closed
reasoning the beam language and if you
just recognize some strange contract
there are some some registers and you
are referring some positions in the
register so x0 somewhere you have x1 you
have some test that is equal exactly
what makes there are of course labels
return statement and labels are
different operation and the first that
was to discover exactly that what the
semantics of these operations so to do
that we've introduced a a so-called
intermediate representation for the beam
code because what you see in the beam
code expresses basically lots of
operations so let's assume that we have
a function call it's two down I may try
to be it's a bit up so if you have a
function call in the in the beam code it
looks like like this that call exact
only exact function or elongate module
in so one and and what happens so from
from this kind of operation you do not
really know what happens
that the background so we have to
discover it and to make it explicit we
introduced our internal representation
where we are describing the exact
sequence of steps that are introduced or
evaluated done by the Erlang virtual
machine when that instruction is
evaluated so for example in case of a
function call it is described as what
the name of the module the function name
and the argument name and we are
transforming it to exact operation so
for example that in this case the
arguments are copied in TDD stirrers and
then finally the result of the arguments
are copied to the registers as well
for example if here we have not just one
so that just one argument but the
function has more than one argument for
example 2 3 then not just 1 register is
filled with data but other registers so
X 0 X X 0 X 1 X 2 and so on and so on so
we have to copy all of the data into the
registers and then finally we have to
set the return value into the zeros
register so in case of as more complex
function call this is not just 2
instruction but having more instructions
as a sequence of steps that the has to
be done so this is why we need to use a
new representation what not just for
that the other reason is that we do not
have control over the being the
semantics so it may change if some new
constructs appears that may affect the
Devine code as well so if we have a that
kind of intermediate representation
and if wanted to upgrade our analysis we
just at least we hope we haven't tried
it yet but at least we hope that we just
have to modify this this layer or
disconnection between the disassemblers
beam version and the intermediate
representation so this is basically why
we are introduced a dis representation
so we create an exact model of control
flow from the Erlang code and I think
I've already solved this one so I'm just
jumping to the next slide and now we are
able to create a controller graph from
that intermediate representation and
this control flow graph will be the base
of our analysis this describes that how
the Erlang function is evaluated in the
beam level using the instructions
introduced in the intermediate
representation it consists of some
blocks of of nodes and some edges
describing sometimes simple connections
just moving to the next block or
sometimes conditional connections
between the blocks when some condition
holds then we go this way otherwise we
go to the other other way so this is how
we represent the source code we go to
operations and the different
instructions from the beam code or from
the intermediate representation and the
next step is is to try to restructure it
to make it more functional so what we
are doing is the first step is to create
a static single assignment version of
this control flow graph why is it
important because along with a single
assignment language this is one reason
and this is really good for us but this
is not something that we
are invented this is usually a technique
that is used in Indicom piling and this
is really good for us as well because
along the single assignment language so
we we can benefit from this
representation so what we are doing is
that basically we are creating unique
variables from the from each control
flow passes and whenever we found the
two variables where different values
assigned to that variable then we are
introducing a special function this is
called the key function that is
basically a conditional functions
function
containing the information that which a
control flow path were executed so
basically you should I can explain it in
a way that if all of the conditions that
match to this control flow graph holes
then we return the variables from the
left hand side path otherwise we read if
these conditions for the return the
arrival from the right hand side path so
basically we are using these represent a
sort that we just modify and create a
static single assignment form from the
from the control flow graph but it's
still not enough
because in usually this SSA form can be
used to define some regions in the in
the control flow graph in the SSA form
of the control flow graph so we have
some regions and then we determine some
entry and exit point for for these
regions and then we can transform it to
two real code or or whatever the next
step of the analysis is depending on the
target language the problem is
that the version of that contour program
VI using is not structured so we can't
structured me that each block has
exactly one entry and exit point and
it's it's not - you can see that for
example this block has to this block has
to you as well so this is not a
structured control flow graph so we
cannot apply the rest of the analysis on
this graph and create a new long syntax
tree from it so we have to somehow
eliminate this construct and there are
different techniques to do it also from
the literature and for example one of
them can be to use code duplicates so
whenever you find something where to
think two different control flow at this
point then just simply duplicate that
block for example here and then you
won't have this problem anymore if we do
it in this way then the resulted code
may not look look like similar not the
same because it will never be the same
as it was the original one but it may
reside completely different code that we
had originally so we do not use this one
instead of that we try to identify some
patters in the control flow graph and
and try to restructure it to a longish
style or something like that so what we
are doing is that we are using graph
rewriting techniques so we are applying
lots of grass rewriting rules on the
control flow graph and try to reshape
restructure the control flow graph the
unstructured control flow graph to a
structured control flow graph I do not
want to go into details but basically
when you have a
a free writing tool you have a pattern
that you wanted to match on the graph
with some conditions and you replace
that part with some new notes maybe one
or more and wings with some edges
between the nodes so we are expressing
for example one interesting question was
that have to identify the branching
statement case the result of case or
function closes or each statements in
the control flow graph or D we cannot
really identify that which one one was
it originally we just see that it was a
branching statement and we can apply
different graphical I think you do with
to try to structure this control flow
graph and what act is needed is that we
can apply this simple rules to reshape
our control flow graph but not in a kind
of brute force way we we need some some
kind of context analysis so it's not
really applied in a way that every
pattern is is matched and then it's just
simply simply return something because
we know from some exact contracts that
have they are look like so for example a
received expression from the Erlang code
is compiled to a kind of loop function
into the in the beam code and we can
identify this context and and try to
improve our analysis based on that so
after if we do this graph or we applied
these graphs rewriting rules we have to
identify the
leaders in the control flow graph and
create the so called a normal form of
the translated static single assignment
form just to show you that have the
sorry I forget it that from this the
result of the rewrite rule is a sub
third control flow graph so from these
crossing edges we create a control flow
graph like that and then in this graph
we can apply a transformation that
creates the functional representation of
the source code this is called a normal
form which is really similar or can be a
base of the CPS the continuation passing
style analysis as well this is usually
used by the compiler desportes because
it allows different optimizations on the
on the source code so we can create a
bit more functional and best why it's a
bit closer to the yearlong syntax so we
have as functional representation now
from the from the bean code and then
from this bean code note 3 this a normal
form representation of the bean code we
can create the or leung-sing dr e it is
now a much more simple transformation
than to do it directly from the
unstructured control flow graph so
another way can be to apply some
high-level analysis domain-specific
analysis on the on the control flow
graph exactly and trying to identify
some specific Erlang constructs but in
this way the the transformation is so
hard coded really hard to modify and and
you cannot really do small fixes on it
because it's so we're over
systems so that's why we choose these
small steps to introduce the functional
styles in the indian in the beam code
during the transformations and it
doesn't really looks like so functional
at this moment but it's much more closer
to another lang syntax and we are able
to create the Erlang syntax tree from
this code I'm not showing the syntax
tree instead of course I'm showing the
bigger the representation the string
representation of the syntax tree of
course the source code so you you can
see maybe those who are sitting at the
back can see but that was our original
module so we had the handle even
function that used a case expression and
based on the value of the event
variables done different things this was
the original code and what we are able
to do is to create a conditional and if
statement from this expression and and
of course the conditions sometimes may
be overlapping and and some parts can be
replaced with pattern matching of course
it's much more nicer to have an exact
pattern matching instead of having
having that condition that whether it's
at Apple and if it says as well whether
it has two elements of course if we
write the code we write something like
that but we cannot create that version
of the source code because directly from
the beam because these kinds of pattern
matching are translated to conditionals
checking's during the compilation so
this is what we are able to produce from
the beam code and of course some further
optimization or shape
being refactoring transformations can
make it a bit closer modified to be a
bit closer to the original syntax I'm
pretty sure that you never wanted to
work with this code later on but this is
not the purpose of our research we
wanted to get the information from the
analyzed code so let me show you a quick
demo that yes we are really able to do
it
so the basic scenario is that we start
to factor simply and this is a pretty
freshly factored out having nothing
analyzed at the beginning then I'm
adding a new file so I have a file
simply a I'm adding it to the database
just stop it a bit so you can see that
the content of the file is just really
contains two really simple functions one
through one bar and and we are calling
so fucose bar with some values and we
have some variables and tuples inside
and that's all okay so this is basically
what we have and I'm starting the very
interface of the tool just to have a bit
fancier interface to show just to
promote refactor that we have a nice of
interface and it's not necessary to use
this command lines of the year-long
shell interface so we are starting the
web interface you just press any name
what you want and and you can login and
you can run some queries as I said in
refactor so for example you can type
your own queries in the indy query box
executed you have the results you can
see the source code related to the
result of the query at the right hand
side and we have some
these walls the user defined for the
user-defined queries but of course for
certain entities in this source code we
have some built-in queries so for
example for add variables you may want
to know that what is the variety
references to the variable which is the
binding point what is the origin value
of the variable which means what are the
possible values of that variable so let
me continue and if you run this query
now without analyzing the beam code you
see that okay let me stop it a bit ok
I've asked the original values for this
one and I can see that this variable
presents here but I cannot recognize
that what are the dependencies for
example between the values the arguments
of the function that returns Y and then
I'm extracting some values from that
variable I can't do anything with it
because the return value of bar depends
on a function that is not available at
source level so what I'm doing is that I
will analyze this code and try to see
whether we are able to determine more
information so before that I have
another demonstration that tries to
demonstrate you can see that I'm
switching to the dependence graph step
now so you can draw dependence graph for
example module and function level
apparently the function level dependence
graph and you can see that okay we have
functions we have two modules we have
functions in the module and we can see
that these function refers to this
function but nothing more we can see
that what are the dependencies or
this function so that's why we are
moving forward and try to analyze ah
sorry it was a mistake during the
recording so this shell is your long
shell so we try to analyze the beam code
so the interface now basically just you
have to provide the name of the beam
file it's really simple now of course we
can later do some more accurate
interfaces and so I've done the analysis
now I'm running again so generating
against the function call graph and you
can see that now I have a new function
that depends from death fun 3fast to
quick ok so I have a new function here
that depends that my old function the
simple funk depends on so one new
element introduced by an L analyzing a
simple graph now I'm running the query
again this was a box that shows that the
database changed which means that I've
added a new file so all of the results
of the previous queries are not accurate
anymore so I have to rerun the query so
I rerun the query and you can see not
the same result because I have one more
function so I know I can realize that I
have one more function in the beam
module and this is my old foo function
and let's run the query the origin
clearly again and see whether if we run
the origin query we will have more
results than we had before if you see
that lots of X 0 and some never seen
variables appeared and there is a
constant value there
this 42 that expresses that basically
the value of my reliable is the value of
this the exact value of the function
call so we do not know what's happening
inside but some how this 42 flows
through this function and returns here
to that variable I think I have a
version of these beam code I have an
other demo just let me show that one
because it shows the code let me start
this one okay sorry it started okay so
this is the generated version of the
code and if you check then you can see
that this is the input the input
argument of the function it flows to the
Y variable then it's just back to a
sample and then basically this value
assigned to another reliable and it's
returned so basically this is really
there so the value that is used to call
the dysfunction that was the same value
that we used to call the bar function if
simply flowed in the return value in a
couple and what we are doing in the
original code is that we've unpacked it
from the tuples okay so this is the
result it's really ugly because there
are lots of variables and I have the
original version sorry of course I have
the original version because I've
created this example so this is the
original version
you can see that the indy original
version we just apply the funk to
function and compounding this value the
return value and the original argument
into a topple this is basically what we
see it's really obfuscated if you are
careful enough then you can determine
the same contact or you can apply some
refactoring transformation to reshape
the code or make it more cleaner you
have some variables like X 0 3 each one
one - these are generated variable names
of course and you can simply eliminate
these variables because it's not really
they are not really useful so what I'm
doing now is that I'm eliminating all of
the introduced variables and finally at
the end I will have a really similar
code that we had before the only
difference will be that the function
there is clarified and here is not it
can be improved in the current state of
the implementation we are introducing
qualified function names so function
calls so this is the only difference and
of course the variable names it's not
possible to get the original variable
names
neither macros or record syntax of
course so there are some concepts that
we are not able to identify from the
original source code but we try to
create add version a syntax tree version
that is close to the original one what
we wanted to do i left only one more
slide is no 32 we've done some
experiments on not so small examples but
on the code of of the media from the
Erlang go TP so we've select
some modules and and compile it and try
to get the syntax tree from that code
you can see that it's it's a bit slow
now so it's not really the same speed as
we can do when we are analyzing simple
or long source code so it's much faster
we wanted to improve it
the time of the graph applying the
glossary writing tools is a big part of
this total execution time we will try to
do our best to to improve it because and
you do not leave one or two wait two
minutes to analyze a single module even
it has I don't know a few hundred or
thousand lines of code okay so it's we
know that it's slow at the moment we
will try to make it a bit faster and
other things that we wanted to do is
that there are some tricky
transformations in the beam code for
example you will never see your original
list comprehensions or fun expressions
in the beam version of the code because
local function definitions are created
from the head of the list comprehension
and from the func fun expressions and we
see that there are in the beam code you
can see that there is a function called
air to a special local function so now
if you have a fun expression then we
just simply create the beam created
local function from it having this funny
name with fun and having the original
function name and I do not know exactly
what in it and some some indexes and so
on so we are creating the local
functions and then we are introducing a
function call when you apply this fun
expression so it's a bit different than
the original one but as I mentioned that
we can apply some some kind of pre
structure
so before applying the graphic writing
rules we can apply some context analysis
and for example based on the name of the
fun expression we can identify because
they are so special then we can somehow
and and from the context we can analyze
that it was originally as an expression
and then we can transform it in a
different way and so do we do this
comprehension we have some issues with
binaries and get better we should refine
our graph rewriting rules to handle them
properly and the most interesting stats
are just ahead that try to apply these
techniques and see what's happening with
other languages compiled to the beam for
example a sphere but this is just one
example we can we can try LFL or or
other languages as well and and try our
architecture whether it's appropriate
whether we can use it what should be
modified and one interesting question is
whether we can create an hour long
syntax tree from an ellipses compiled
bytecode but this is not the case then
we can refine of course the syntax
regeneration as well and and create some
some food some Alex you like syntax tree
as well so we will see this is not
started yet but when we fixed the other
issues that will be the next step to do
with our analysis I think I've used all
my time so maybe if you have questions
quickly or if you wanted to have a lunch
just go ahead I do not want to be
between you and and end your lunch but
just feel free to ask now or later we'll
have time for at least two question ok
thank you
look did you look at a compiler and the
hype compiler which is inhibited you can
compile to SSA form from being directly
so it's already imported no no we
haven't but we can try
of course any more questions but an SSA
form but this is not structured am i
right
it's unstructured its its structured but
if you want to do take it to the airline
level you would have to do the graph
reduction but everything it's all the
steps before you have in the high
compiler okay but the end are you
eliminating the go-to operations as well
so is it is the high compiler
eliminating the go-to instructions and
structure the control flow graph as well
we have to look in it so I'm not quite
sure that because we we can have an
unfiltered version and and Destructoid
version and the rest of our analysis is
based on the structure control flow
graph so the the syntax tree creation
well everyone's eager for lunch I guess
so let's speak again thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>