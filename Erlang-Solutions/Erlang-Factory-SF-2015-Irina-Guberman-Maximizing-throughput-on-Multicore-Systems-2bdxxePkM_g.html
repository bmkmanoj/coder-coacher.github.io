<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erlang Factory SF 2015 - Irina Guberman - Maximizing throughput on Multicore Systems | Coder Coacher - Coaching Coders</title><meta content="Erlang Factory SF 2015 - Irina Guberman - Maximizing throughput on Multicore Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erlang Factory SF 2015 - Irina Guberman - Maximizing throughput on Multicore Systems</b></h2><h5 class="post__date">2015-03-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2bdxxePkM_g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone so what I'm gonna go
through today is there a business case I
was working on at my company ubiquiti
networks it's a wonderful company that
gives me money to code in my favorite
language the one language that i fell in
love at first sight it never happened to
him before as much as I walk programming
and so what I was working on is a
restful HTTP server humbling audio
configurations so our server gets an
audio configuration that looks something
like this this would be a text gritty
and the audio formats that it needs to
be converted to so our HTTP server is a
restful server that does the usual are a
small stuff like an updated it fetch if
we won't be talking about it we'll be
talking about the fun stuff it does with
the audio conversions so this text will
get converted to an audio and the audio
will be converted to other audio formats
and this audio files will be saved to
as3 and as they are saved to a 3 will be
saving the audio IDs to to our database
to indicate they are available for
upload from is three so that's in the
nutshell what our server is doing
so a couple of things we need to
consider implementing such a server what
your audio conversions are very CPU
intensive saves to us three on the other
hand are easy on the cpu but my taken a
very long time and a basic white very
long time but unpredictably
unpredictable amount of time also
considering that this this request can
be fulfilled very quickly it will have
to take some time so it will be an
asynchronous request we will be
responding immediately to our to our
client and I synchronously proceed with
fulfilling the request so as a
particular audio is being processed we
don't want another request for the same
audio to another update request for the
same audio to be processing so how do we
approach this problem in our way we
create a finite state machine for every
audio request that comes in it could
have been a gem server we just decided
on finite state machine at that time so
a request concern we spawn and you fsm
and another request comes in we spawn
another after Sam and another request
comes in use for another after Sam and
you're going to spawn an up separate
process for every single request that
comes into our HTTP server so you'll be
getting tired of these of a samsung I'm
going to be spawning on the screen here
but our server will be getting hundreds
and thousands of such requests will be
creating a spawning a separate process
for every single one of them and if you
think it's a crazy thing to do it is not
for an airline developer it's perfectly
normal to spawn as many to spawn hundred
thousands of processes as long as it
makes up as long as it's may makes
business sense and
that is because our lying processes are
cheap and as a developer you just have
to you don't have to worry about how
it's going to work airline vm will
distribute the load evenly across the
underlying OSS threat and you as the
developer just have to you can just
spawn as many processes as you want so
next audio conversions it's not an oval
problem converting text to voice or
converting various audio formats it's
already been done before us so we use
existing see executables to perform
audio conversions so for text to voice
conversions we used our sub strong
service and for converting the resulting
wave file to other audio formats we use
sucks however if you if in your
situation you need to run some kind of
am in computationally intensive task and
you need to write your own it is a good
idea to write to write it as a single
unit of code and see because
manipulating large data structures and
are lying running computationally
intensive tasks is not such a great idea
considering that data structures are
immutable in Erlang so you should
consider writing a single unit of code
and see and then have our laying manage
the conquered manage them running
concurrently and i would like to quote
or very famous Garrett Smith think over
lang as a manager not a worker
next the problem sale sold as three so
we are this finite state machine we are
they are pretty busy doing audio
conversions and it's saving to us three
and saving to the database and
orchestrating the whole audio
orchestrating processing of this audio
request so we have these three URL we
have our audio binary hi it's Jim we
can't afford sending there's three
requests and sit there waiting for it to
complete so naturally as an erlang
developer v what do we decide to do we
just spawn a child process that will do
this instead and so the a child process
will send a 3d quest and wait and do
nothing but wait for it to complete and
to get the result to get notified of the
result when the s3 request completes we
equip this process was our own press ID
and let's take a look at the child code
so all the dolls it sends this 3d quest
and when it gets the resolve it's done
the results you ask and ceases to exist
now back to audio conversions as I
mentioned they are CPU intensive so it's
perfectly okay like I said to spawn
hundreds and thousands of processes but
what if those processes will be all
performing audio conversions at the same
time while our length am can distribute
the load it can't give us more CPU
powers on our machine has so what we can
I what's going to happen is that audio
conversions potential who eat up all the
cpu power there'll be no resources left
for other important things like
accepting HTTP requests saving to
databases to the database sending is 3d
quest or your conversions will eat up
all our resources and you'll end up in a
situation commonly known as overload so
what can we do well very simple answer
we can limit the number of simultaneous
audio conversions to number of CPUs
minus one and live while one cpu
available for our other important work
how would we do that we can always it
seems like a pretty trivial problem so
we can of course write our own code to
do it on the other hand it seems like a
pretty common problem which probably
other people already addressed Oh nope
nobody here
Oh
so this problem has probably been we are
not the first people to think about this
so we should look for an existing
library that already does something like
that and considering our tight deadlines
and complicated business law business
requirements we decided to look for an
existing library and the library you
used is the jobs framer by figure it's a
job schedule scheduler for load
regulation and its purpose in life is to
prevent overload
um
so I would like you to take a quick look
at this article that that is the instead
is the inspiration behind the jobs
framework that will float in August of
2010 it's actually very interesting
article if you want to know everything
about overload you might want to read it
and you'll take a look at this diagram
which shows the failures in the US
public switch telephone a network outage
minutes by Quoizel as we see this the
largest reason for over four failures is
overload and i hope this diagram is
convincing enough for you to consider
preventing overload in your system
before it goes into production so how
did we use the jobs framework was our
audio conversion was our CPU intensive
audio conversion situation we use the
jobs counter based regulation what it is
is it limits the number of simultaneous
jobs of a certain type to a predefined
number and everything else gets queued
up until the job's the other jobs
complete this is kind of demonstrate
what it looks like
and now I'd like to I would like to take
you through the entire process of
setting up the jobs framework was our
was our HTTP server
step one we need to add jobs to our
rebar rebar config dependencies step 2
and this is important this is how we set
up jobs and being our app that config so
we create a queue called audio
conversions and a psionic counter
regulator to it was a limit of 77
because I have eight I have eight core
so it would be seven eight minus 17 and
next I'll I just wanted to take a sneak
peek at our very complicated business
flow and without we don't need to change
the flow to actually regulate our jobs
we just simply wrap our audio
conversions in a call to job server and
our audio conversions are regulated and
I just here is my code that does text to
voice conversion so instead of just this
duty to underscore TTS just calling that
a function I just wrap it in the call to
Java server you may be thinking okay so
to have for help for this magic to work
I need to start a server with my
application and if you're an airline
developer it's perfectly okay it's
perfectly normal but if you're not you
might be actually concerned and if you
so there is no need to be concerned as
an under engine airline developer it's
perfectly okay to start any servers with
your application and you don't have to
talk to your boss or your ops team both
for permission on that and i would like
to quote Garrett Smith again Elaine is
think of our line is an operating system
for your code so to have jobs set up a
running with our application will have
to add it to our application startup
list
so that's that's it that's that's all we
need to do to get our audio conversions
counter regulated so next I would like
to go through this little video to show
what else what else jabse framework can
do for us for our HTTP server so let's
say let's say that this two lovely
ladies are HTTP server and the
chocolates coming in on the conveyor
belt on our HTTP requests so as the
requests are coming in and a steady pace
and that our HTTP server can handle
everything is great
but one starts happening when the
requests are coming in at a much faster
pace is really really funny unless it's
a your HTTP server and maybe it's your
HTTP server in the middle of the night
so to deal with a situation I like this
job framework offers another great
playing its rate based regulation so
what
so what rate based regulation does is
given a frequency effort ensures that
the rate of accepted jobs does not
exceed up F and this is how we so we're
going to have the request coming into
our HTTP server reg reg reg away that
this is how we set it up in the episode
config you cannot create a cue called
HTTP requests and you're going to assign
a rate regulator to it with limit of
thousand requests per second so this
number of course is not something you're
going to use in order to come up with a
good number you need to measure the test
and measure your system and decide what
is they are optimal maximum pace your
your server is you can accept a request
at so now we have our system County
regulated and rate regulated so now we
can I guess have peace of mind while not
sure about you but all sorts of products
are creeping in it for me what if we get
denial of service attack well well then
you say that our requests are regulated
so we shouldn't be too much too worried
about it too much should be well
remember that because that are being
pasted are actually getting accumulated
in our HTTP request queue to just watch
that Q inflates and eventually it will
blow or servers memory so what do we do
about that limit the queue size and this
is how we do it with the this is what
this is how we do it in the jobs
configuration our HTTP requests will
have a max size of 5000 it's an
arbitrary number i just came up with
another what they thought of our
requests have a strict timeouts or
absolutely no point keeping request that
turned out in our queue so for instance
if your real-time bidding depending on
the provider your request timeout wasn't
200 milliseconds or on the other hand if
you have some kind of a payment
processing request coming into your
server that may not time out at all or
just about anything as a reasonable time
out so maybe 10 minutes so just any
request whether it's a it's a very
short-lived requester won't running
request it will still have some kind of
time out so what we can do is limit the
request wait time in the queue and this
is how we're going to do it so per hour
it rtb request we're going to give them
a max time of we're going to create a
new queue cold Ltd requests to give it a
timeout we need to create a new cube and
you're going to give it a maximum of 200
milliseconds and they're going to create
a new cube payment requests and give it
a max Time of 10 minutes so now the
question is okay but what if i want my
request we pace that a certain pace
regardless of what type of requests they
are and this is not a realistic scenario
of course that I just wanted to take
some extremes as a good effort was a
good example so let's say we want the
request coming into our server to be
pasted that a certain regulator rate as
a certain limit but there would be kind
of different types of requests was
different max times so for that the job
framework has a group rate regulation
there's kind of similar to rate
regulation now but now we're going to be
known arrogantly actually applying it to
a group of different hues so the group
rate regulated let's just put a cap on
how many jobs from a group of q's cannot
recruit per second so now you're going
to look at some code or how we can I set
this up in our environment so we're
going to create a group rate regulator
we will call it HTTP request right with
the limit of a thousand just like we
like just like the one we had before and
now we're going to assign this group
rate regulator HTTP requests traitor or
TV requests and you're also going to
assign this HTTP request straight to our
payment requests so regardless of which
one of these requests are coming in and
our server they're going to be only
coming in 1000 per second now back to
what your conversions what if we decide
to avoid a firm sorry what if ours our
assumption that cpu minus one is good
and office is not good enough but if
what if our server is all of a sudden
running some other jobs you are not even
aware of their not part of our code just
needed some kind of maintenance job and
all of a sudden we started dropping
request on the queue we can't update
database because we don't have enough
resources so the answer to that is
sampler framework that comes with jobs
and sampler framework allows us to it
actually sends you back from CPU memory
and we can get load factors from a local
end of also remote nodes what that local
load factors are going to do it's going
to be a percentage by which to reduce
the predefined regulated limits
and I quick note on the remote nodes
when we get multiple feedbacks we're
going to eat we can either take the
maximum value or we can take the average
value so this is how we set it up so
when you start our jobs are we are also
going to start on our sampler samplers
and let's say we decided to sample the
CPU allowed to sample cpu load a job
trailer comes we'll stay out of the
boxer sampler it's called job sampler
cpu then we are going to take our audio
conversion skill it has a counter
counter regulator limited to seven but
we can apply a modifier to it and that
modifier will be feeding from that cpu
sampler so if the cpu are if the cpu
gets more busy it gets busier we are
going to get a certain percentage of
that increase and you're going to apply
it to our to our limit and this will
decrease the limit and if the system
goes back to normal the limit is going
to go back to what it was originally
so next what the f just a quick note
about jobs and water aren't you it only
works on it only works on linux and unix
because it uses OS mom CPUs up which is
which only is working on that OS and
let's say if you so let's say you want
to run the sample framework on your Mac
you won't be working so what we're going
to do to get cpu sampler working on our
map we're gonna we can create our own
sampler plugins and Java America are is
very probable and you're going to take a
look at some of those features so to
measure cpu on my mac i'm going to take
a temperature sensor and turn off the
fans of my expensive neck and attach the
temperature sensor to it and i'm going
to write my own module called my thermal
sampler and it will implement job
sampler behavior so now instead of using
the out-of-the-box job samples in cpu
sampler i will use my own sample instead
that's how we configure it
another what if what if we decide to
what if we decide to accept pre-recorded
audios and those can get really big and
really a wire can get really big and
they can be of very different sizes so
we get this post request with meringue
sighs files that get killed up and now
we're kind of back to the memory problem
we had before because limiting the
number of requests so specific number
almost doesn't help us because if this
file to get really huge you know that
having you in there not we don't know
how large they are having a limited
number of things in our q1 help us so to
answer this question we can write our
own cute it's perfectly it's perfectly
easy to write your own to write your own
key with the jobs it provides so we're
going to so we cannot it provides jobs
sorry Q behavior and you're going to
write our own q called puts a memory
from the queue so that one's going to
have max size in bytes instead of just
not just sizing items in the queue and
we can even do some if we would say it's
necessary for us to not drop any
requests on the floor we can do stuff
like save the request to this conduct
you get full we can do we can do
anything that our business to cater to
our business needs so to create our
memory family pew we write this module
that will implement jobs q behavior and
you have to implement this all of these
matters we kind of call of course still
most of them from they are the queue
that comes with the jobs framework and
this is how we set it up now this time
we didn't actually have this mod module
parameter before because it's by default
was using the jobs view the default you
but now we are actually going to use our
own q instead
so now we have max size in bytes and now
we're going to have so I'm going to use
our memory friendly cute next thing
would be really nice if our cues we are
reacting to the memory situation in our
system so for that we can write a free
round sampler and let's say we want our
we want our q2 to change the size as the
family situation changes in our system
so we're going to write our own sampler
called free round sampler we can have
you we can use OS magnums up process to
feed the memory information this is how
we do it again we create a the implement
job sampler behavior and now i'm going
to now we're going to take a look at how
to implement the sample method you're
going to get the information from the
moms up get system memory data and feed
it into this structure that's what it
returns we only care about free memory
and this by the way is a annoying
pattern matching we'll do it with the
arrowing pattern matching
so now now the question is actually how
do we adjust max max Q size on the fly
this is all we can do it they call jobs
modify Q and we'll modify our memory
from like you to have a different mac
size than they have in the in our
configuration if you remember so now Lex
is going to be something different we
can change it on the fly based on the
results we get from our free ram sampler
but how do we actually do it on the fly
using the jobs framework so the answer
to that is not is a little less
straightforward than before the reasons
really a very straightforward way to do
it so we can either ask with the add
this functionality to the Japs format
framework and I actually should have
asked in a long time ago but I didn't
follow through since my last
presentation and so it's still not there
but maybe we go ask him after this
presentation and the other thing we can
do is we can write our we can actually
expand the Japs framework by and help
the airline community grow and add this
functionality consider adding this
functionality ourselves will fool mind
he's very busy was developing other
projects and if you don't want to do any
of the above two things we can just use
the existing back door in the jobs
framework it can be poor it can be done
today so this is how we do it in our own
process we can subscribe to the job
sample so we can use the jab same
example of framework in a in a variety
of very flexible ways so this is what we
do just called job sampler subscribe and
now our process will be getting this
sample of feed book feedback in its
mailbox
and now that we get the feedback so we
know what the sampler framework is
giving us we can simply adjust the
memory friendly few sites on the fly
hope that makes sense so far
so to to kind of go over what I talked
in my presentation I would like to go
through this very simple short quiz and
some true or false questions so spawning
processes in our line is very cheap it's
phone only one to the tour falls
your artistic
fun large response
expensively papi
a natural product the actual airline
process is pretty cheap because if
you're talking about some more
complicated situation like when you
actually have a process that what is it
copying
so you start linking process get smart
so it really
yeah and actually that that's kind of
going to come in the next question yes
you can plain if you need to spawn
processes like I was doing it was the
request sec so the request they're so
independent processes that I was talking
about right so he's phone you near the
process you can spawn processes to it
can spoil a separate process for every
request that comes let's say to your
server that's going to don't know how
many you can have thousands of them
coming in and you just spawn a new
process and it's perfectly okay but
there are independent processing really
not copy any information between them
because you know web requests are
independent in a completely independent
in nature and you can just dedicate a a
specific process to your request it's
actually try doing that in Java that's
crazy that you can you're not going to
have a thread for request just not going
to work but the stratton process in the
airline process are not the same thing
so it's true that in mind it that's the
way in the situation that I was going
through so now the question is you don't
have to worry about what kind of work
these processes are doing and when we em
we'll just make sure everything
automatically works so you don't really
have to you don't really need to show
your phone these processes and you don't
really have to worry about what they're
doing is that true or false
Barbie yes sure you can always do things
and not worry about what's going to
happen later so as far as I'm concerned
it's false we really need to as you
spoon like like we did with the CPUs us
use phone thousands of processes which
is perfectly fine you have to understand
where these process is going to take up
all my resources what are they going to
actually do and as far as price phoning
processes is one thing consuming
resources are completely different I'll
probably actually have to understand
what are those processes doing and what
resources they are consuming and what
are you going to have a new resources
reasonably all located the next question
is load regulation is a pretty trivial
problem you should just consider writing
your own library and not you know depend
on some other people's bugs
sorry and it's false of his mouth
actually well considering this present
in the context of this presentation it's
false but if you have a lot of time on
your hands you want to write your own
your own library but then it's done in
22 but no but the load regulation is not
trivial it's basically you might at
first we were thinking oh just limit the
number of requests to certain number
that's very trivial that actually could
be done but as you go but as we go on
you realize oh wait a second is but we
need this and we need that you might
actually discover a lot of other
problems as you go on and then you will
be regretting that decision because if
all you want to do is write a framework
that's one thing but if you really need
to solve a business problem and you have
deadlines you might not want to be
reinventing spending your time
reinventing the wheel and all the last
question is right your CPU intensive
computations are can see and let our
line manage concurrent execution is that
your pulse
anybody disagrees you want anybody wants
to write a compute engine
computationally intensive as if you
advance reputations in LA no all right
all right that's the quiz is over
everybody got an A regardless of the
answers is that the time for questions
so the AMA you have a
limiting and then you have Hugh size
limiting what what does jobs do when it
can't service a request so God has
yeah so basically it depends it depends
on what you like what's your business
situation is so if your requests are not
important like for advertisers yeah just
drop them on the floor right but if
you're some kind of financial
institutions and the requests are
important you still want to flood your
server right you want to control the
pace so you can write your own cue that
will do something it what you will not
down the requests on the poor drop the
request in the poor you but you you're
not going to be overflowing around
either so you can just like actually had
the L&amp;amp;O of that stick like the best
thing to do what you can write those
requests to disks or to deuce deuce
could do something else like maybe send
them to another servers I don't know
something you can with your own cue
implementation you could it could do
anything because it's fully pluggable
that's the great thing about jobs that
it's very possible you don't have to do
any of the you don't have to use the
existing behavior the existing behavior
is drama yeah it's just basically won't
allow overflow it won't allow overload
in your server and that's what it's
doing but if you if your concern was
requests and not being served or
completely lost you should implement
your own if you'd implement your own our
cue
um
Wow
results more about
I don't think you can create cues the
whole point is you probably won't need
to create so many q's just I I can't
think of a business case where you would
be creating J'Accuse on the fly ok now
it's interesting I good it cannot do it
it Q has to exist and you register it
during / me
I'm not sure if I got the question how
you need thousands of kills tens of
thousands of kills but you need two
different types of kills Oh different
cues okay but they're gonna be at the
same kind of cue right I'm just so with
the Q's you it was the jobs you set a
type / q
no jobs is not that jobs is not let's
start with jobs yeah that's not what
jobs is for it's more for regulating
your surfer than you know creating haha
actually experience it's a very
interesting question it's quite possible
that the jobs you could be expanded to
do something like that it would be a
nice thing to explore
aha
if we call them from you are calling
them from our line yes
ok
actually I think that if I run that if I
run a process that just became
unresponsive it's going to just get
killed by the supervisor that by the
airline supervisor I can have the
process just get if by airline process
is running for too long other line
processes are always always said it
they're not always supervised by default
but if you're following the standards of
if you're following proper standards
you'll have your processes in your
server supervised so if your process is
running for too long it can just be
killed by a supervisor now we don't
didn't do no we didn't use nips or poor
drivers we actually just call the arm we
just call the external program the
external yeah bit be used see empty but
your question is that the process that
just transferred too long can be simply
killed by the supervisor
yeah the beauty of our line is that it
doesn't matter what you quote from your
process it can be just killed and you
cannot do this in any other are you
cannot do it another like if you can you
can do it and airline the app you cannot
do it in JDM for instance we can't kill
a process that's actually doing
something and that somehow doesn't
register too many people they don't
understand like some like a lot of Java
developers don't understand that they
cannot kill a Java process that's busy
that's you know that's busy doing
something it just can feel it you can in
our line
so for example by a poor job ABC
and I want jobs ap
d to execute after they has um can I
actually set up
look into jobs I can handle holdback not
know that when I hit the result he
executed parallel opened in some kind of
so the question is whether we can have
free prioritize the items in the queue
yes you can by writing your own cue
implementation that's jobs doesn't have
that out of the box but you have to
write your own a few implementation and
your requests will have like a priority
on them and you basically will order
them by priority or something like that
but yeah that you'll have to write your
own plug-in for that
yeah we just we were kind of looked at
other than we just decided to use jobs
jobs jobs is actually more it has more
functionality though we ended up using
only the counter based and rate based
regulation and it just works you can
solve a lot of problems with just that
but if things get more complicated the
thing is that it's nice to have a
framework that's pluggable that's
extensible because you know very quickly
your situation might get much more
complicated than you realize it happens
all the time so you were we ended up
being okay with just those two
regulations but very often you realize
oh that I need this on that and if the
framework is flexible and pluggable you
can always add to it you can write your
own code and plug it into existing
pieces so that kind of gives you a warm
fuzzy feeling that okay if I need more I
can always put it in without completely
changing everything I did before if that
makes
any more questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>