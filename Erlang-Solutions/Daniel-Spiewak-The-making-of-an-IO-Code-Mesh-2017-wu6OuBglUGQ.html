<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Daniel Spiewak - The making of an IO - Code Mesh 2017 | Coder Coacher - Coaching Coders</title><meta content="Daniel Spiewak - The making of an IO - Code Mesh 2017 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Daniel Spiewak - The making of an IO - Code Mesh 2017</b></h2><h5 class="post__date">2017-12-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wu6OuBglUGQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so this is my talk mercifully not about
RMS but about the IO monad and and
specifically what it is and why we want
it and what that means on the JVM so if
you're if you're like me you've probably
done something like this at some point
in the past which is you know sort of
made the claim that the IO monad is just
boilerplate from Haskell it's there's
sort of this unnecessary thing that we
do mostly because Phil wobbler just says
we should do it and we there's no other
purpose behind it and I I have come to
realize over over many many years as
much sort of bloodying my nose against
this that this is so nothing could be
further from the truth the IO monad is
is really actually about effects and and
it's really actually profoundly
pragmatic an important thing it's it's
very very very useful it helps us solve
these these problems and hopefully by me
relating this you will be able to bloody
your nose somewhat less or at the very
least bloody you don't your nose on
different walls than I did so effects
what is an effect well in effect is
something that you just can't do twice
right so writing to the database reading
from standard input incrementing a
counter etc etc etcetera right anything
anything was sort of state that you
mutate in place these are these are
things that you really care about you're
doing it exactly once when you're doing
in exactly this place effects are
tremendously hard to test ok now I guess
I found this more and more as my
apparently five year career has
proceeded is that like testing really is
kind of the heart and soul of like
writing decent software right if you if
you could write good tests then you've
probably written relatively reasonable
software and if you've written good
tests then your software is probably
comparatively bug free effects make this
very very very difficult effects make
concurrency very very very difficult you
you have a really hard time like the
hardest problems in concurrency are like
oh I've got this like shared resource
that two things are trying to change
something about at the same time and I
on like you have to coordinate between
them but simultaneously like if you
don't have a
then concurrency is kind of pointless
there's really very few things that are
concurrent problems that do not involve
changing some sort of state just think
like folding at home is like probably
the best example of like a non effect
full concurrency but everything else is
is there and effects also make
refactoring hard they make it very
difficult for us to change things about
our code and so what I mean by that is
something like this
so so if you take this fool 42 plus vux
42 we would we would sort of want to
factor out the method call here because
it's it's redundant and we want to
change it into something like Val X
equals foo 42 X plus X but we can't do
that right because we don't know what
foo is foo could be something nasty like
add to gauge or something like that
right we don't would actually know if
it's modifying things about the system
the these two could in fact be separate
programs which is actually if you think
about it like if you put aside sort of
the biases that we all have from being
indoctrinated by systems like Java it's
it's actually profoundly weird that
these are not the same program right
they really should be the same program
and effects are the reason that they're
not so so really we should find a way to
get this property back because like I
think this is this is something that's
pretty intuitive and we can do it by
controlling our effects by making them
more constrained more confined turning
them into data so that we can work with
them on the traditional way of doing
that is with the i/o monad right so we
take this ad to gauge function and
rather than having it return an int if
we haven't returned an i/o event and
we'll get to what this means in a bit
then we can sort of replicate our
example from earlier where we have like
this for comprehension with sort of like
to add two gauges and we can factor it
out and these are in fact the same
program right like the one on the Left
does the same thing as the one on the
right that seems like a good thing like
they're making code that's easier to
parse all up and move around and things
like that without worrying about the
definitions changing yeah that seems
that seems like a benefit so what the
i/o monad does is it allows you to
safely manipulate effects and and safe
is not in quotes there like it's
actually safer right and it does this by
allowing you to build a description of
the program that will be run okay you
build a description you don't build
running program and later on it will be
will be evaluated for you
critically descriptions can be changed
right so we're ratifying the effects in
our program into some sort of data
structure and then we can manipulate
that data structure before it gets
evaluated if any of you come from a list
background this probably sounds a lot
like code as data surprisingly that's a
really good idea and the i/o Mahad is
one of the ways in which we can achieve
this in languages like Scala or Haskell
the i/o monad
allows us to separate the composition of
our program from the declaration so we
can declare what it means to perform a
particular effect like what the
definition of an effect is separate from
how we declare how it is run and how
it's composed with other effects and if
this sounds like concurrency then you're
on the right track this is exactly what
concurrency is right like as soon as you
separate these things out concurrency
becomes very easy it also sounds like
dynamic scaling and other things that
systems programmers care very very very
deeply about back pressure and you know
dynamic you know load recalibration and
things like that all of all of these
things are separated composition and you
know you're controlling the composition
of how your program behaves under load
and you know in batch modes and things
like that by separating that out you can
get some really really really either so
profoundly important properties for
systems sometimes actually for free now
the the obvious question to ask here is
like what do you know we say the i/o
monad why why does it have to be a monad
like why does it why what's what's
monadic about it it doesn't look
anything like list or option or anything
like that and the reason basically comes
down to the fact that programs have to
be sequentialized right program actions
have to be sequential eyes we care very
much when we say print line hello print
line world we care very much that it
doesn't come out world hello right like
that's kind of important and monads it
turns out are the essence of doing
things sequentially like literally
actually the definition of sequentiality
is a monad and so if we want to say well
you know hello happens before world we
can't even speak that sentence without
having a monad and this is what Philip
Wyler's contribution to the space was
right like we all sort of remember him
as introducing monads to Haskell
did but he introduced them to Haskell
precisely because of this realization
that the sequential ization property was
so powerful and so intrinsic so here's
here's basically what it looks like and
why we know that this is true so this is
the monad type class in Scala after
coming from Haskell you're probably like
why are there twice as many characters
as there need to be and the names you
can quibble about the names right like I
called it pure and flatmap you could
call it by engine return it doesn't
actually matter the interesting thing is
that we've got two functions one of
which puts a value into the monad and
the other of which composes two monads
together and we know that the
composition of two monads must be
sequential because of one very very
specific thing inside the middle of this
type signature so everybody see it it's
right there the a right the a where does
the a come from there's only one place
the a can come from inside the F of a
right and the a is the only place where
we can get an F of B which is the thing
that we return right so we have an a we
don't have an F of a or like some other
thing like that we literally have to get
a bear a to feed to this function in
order to get the F of B that we finally
returned and this is a very very
powerful thing because it means that the
F of a the first parameter must have
evaluated before the second parameter at
the F of B it can even be considered
because the effort B doesn't even exist
until the F of a is done so this is a
strong sequential ization guarantee it
basically means that all monads have
sequential composition monads are
sequential composition they are nothing
else and this argument this this sort of
style of analysis is called parama
tricity so if you hear that word like
i'm hacker news or something like that
this is what they're talking about is
arguments like this and when you take
this kind of reasoning to the extreme
you can get some very variance deep
insights about your code just by looking
at the generic types and and saying well
this has to come from there and this has
to come from there therefore like random
property X holds and that's a very very
powerful way to reason about software
but we were talking about the i/o monad
and so we know the vimana is sequential
um what is it what does this actually
look like in languages cuz like we're
interested in what this is gonna look
like in Scala maybe we should look at
what it looks like in Haskell and it
basically looks like this okay so this
is a trivial little Haskell program
we have a main function which is a type
I Oh of unit and we just print line
hello world and this is a pretty typical
thing in Haskell right all Haskell
programs come back to IO of unit right
like all roads lead to IO and when
you're going around and manipulating
things in Haskell right you're calling
out to network functions or you're like
interacting with the c FF I like all of
that is going to be encapsulated in IO
for you so like you're you already are
given effects inside of IO the only way
you can get in effect is like inside of
the IO monad and then conversely like
the only place for effects to go is like
at the end of your program you hand an
IO to the Haskell runtime and the
Haskell runtime will evaluate that
description you cannot construct a new I
oh except using return so this is just
kind of like restating what I just said
right return takes a pure value and puts
it into IO that's the only way to
construct an IO in Haskell unless the IO
has been handed to you by a function
like print sterlin concurrency is also
in Haskell managed through the IO monad
so this whole notion of like
manipulating threads and things like
that is is handled inside of IO the
platform does it for you more or less
and and similarly like concurrency as a
whole and this is gonna be an important
point for later but concurrency as a
whole in Haskell is a little bit
different you basically have sort of
green threading right so like Haskell
doesn't even give you primitives for
manipulating threads it instead gives
you primitives for sort of like forking
things off and then joining at the end
like working at this very very
high-level abstraction right and that's
basically the the notion here right
GHC is a very high level runtime does a
lot of very high-level things for us it
encapsulates things and I oh it
evaluates IO for us you know it deals
with things like threads and sort of
encapsulates us from the nature of
callbacks and such and and because the
runtime is so high level of Haskell's IO
monad is really really very simple
it basically only has to save functions
bind and return Scala is a little bit
different though right because the Scala
main function looks like this which is
not like you can't really do anything
with that right like it returns unit
what it what is unit even mean but I
mean I guess it just means it runs
side-effects so like we
make any parametrically arguments other
than like it exists so that's that's not
really helpful and and Scala and Java
like sit very closely together right
there's no Fi between them so even if
Scala gave you the ability to
encapsulate your effects quite easily
Java certainly doesn't and you can call
it two dining Java function you want and
it might like manipulate the gauge and
you you can't you can't control that we
can run any effects we want at any time
even effects that we don't want right
and the evaluation is eager so if you
say something like print line HelloWorld
it's printing like right the heck now
and you can't do anything about that
right by default you'd there's no way
for you to get in the middle of that
process and say hang on just a second
maybe we should talk about what it means
platonically to print HelloWorld Haskell
gives you that ability Scala does not by
default and also Scala has these very
low-level concurrency primitives like
synchronized and atomic reference and
callbacks and threads and other things
like that that are really really really
complicated to get right and very
actually like really low-level right the
resources that have to be managed pretty
carefully if you look at sort of the JVM
notion of concurrency versus housecalls
notion of concurrency it's it's a little
bit like the difference between C's
notion of memory and Javas notion of
memory like they're they're just
completely differently layered worlds
and so again because the i/o monad is
really about runtime and about the
nature of the runtime and abstracting
over that and providing descriptions to
the runtime clearly the i/o monad on the
JVM is going to have to look pretty
considerably different than the i/o
monad on GHC so scholar runs on the JVM
it has native threads it has explicit
asynchronous i/o with this callbacks
things and and we can't block things
right so this is kind of an overall I
can often overlooked property of GH sees
green threading model is that like you
just basically block things kind of all
the time right you've got like the
fundamental primitive for bringing two
threads back together in GHC is like an
n/bar where you literally block and wait
for some other thread to give you a
value
that is that notion is entirely
antithetical to the jvm where threads
are a very limited resource you could
only have a certain number of them
they're all GC roots you you can't block
them you can't throw them away like
there's a lot of very very expensive
things going on there so we have to be
much much more careful about this stuff
and finally again this is another sort
of difference in the runtime the JVM
doesn't have tail call elimination so if
you've been around the JVM for a while
you probably know that this is the thing
that everybody wants that everybody on
the JVM team wants to add but they can't
because of a feature and Java 1.1 and
now we're sort of stuck with that for
the rest of time but because GHC has
tail call elimination and we don't that
means that we have to care very deeply
about the stack in a very explicit way
in a way that GHC does not and so we
want people to be able to write programs
ideally their entire program via
composition inside the i/o monad by the
end of the world most interesting
programs run forever so clearly we're
gonna have to care about the stack in
some explicit way because we cannot take
anything more than constant stack space
it has to be constant no exceptions
because if I'm running a program for six
months you can't accumulate stack at all
in that time
so there's give me a lot of things that
are different about the i/o mine out on
the JVM but there's a lot of things that
are gonna be the same right so it's
still gonna be a monad great it's going
to manage stack safety for us it's gonna
have to have different evaluation modes
so you know in Haskell there's only one
way to construct an IO monad with a pure
value and we should probably have that
way in in Scala
we should have it sort of be some sort
of strict pure value that we've already
computed because strict computation is
faster on the JVM the lazy computation
but at the same time we still need to be
able to get in the middle and of like
the whole print line HelloWorld thing
and capture that effect up so that we
can evaluate it later so we're gonna
need a way of constructing these things
lazily right so have a lazy constructor
to wrap effects up in IO
and and finally we're gonna need an
asynchronous constructor okay because
callbacks right you know in a super dis
programming everything interesting
that's going to happen with with any
real IO framework and
yeah I'm just going to involve callbacks
we want to be able to bottle that up
inside of IO just like Haskell does for
us with with green threading and all of
this is just going to turn into sort of
different constructors that produce the
i/o monad so so this is definitely going
to be considerably different than what
we've seen before so what what possible
candidates are there in Scala for
implementing this style of construct
well one obvious one that's just baked
into the standard library is future
right but future like I mean we've all
used it like there some of us still use
it it has a lot of problems if you're
trying to use it as an i/o monad and the
most obvious problem is that actions run
eagerly right remember that whole
problem with like we say print line
HelloWorld and it's already printing
before we have a chance to stop it right
like future does that right futures run
eagerly by default and stopping that
from happening is actually quite
difficult to do future also memorizes
results so you can't take an action
define it and then run it multiple times
like the whole ad to gauge thing that's
actually a really really really serious
problem that also can lead to memory
leaks if you're not careful but at a
minimum it certainly prevents us from
you know having the you know the sort of
program that we had before right so I
could we take our example from earlier
where we have like X's add to gauge and
then you know sequence the X twice this
is only going to add to gauge once if
this is defined as a future that seems
wrong so so future future just isn't
isn't good for this right
it doesn't encapsulate asynchronous
execution really much at all which is
funny because this is kind of the whole
point of future right but the problem is
that promise is a really leaky
abstraction right you create one of
these things it's hanging out over here
it's completely separated from the
future maybe the future doesn't exist at
all have you fulfilled the promise yet
how do you not fulfilled it yet god only
knows ask a function maybe it'll tell
you like it's it's really like they're
just kind of like these completely
separated things they're not tied
together very well at all
and I can lead to a lot of really weird
bugs in your in your code it's not it's
not very directly encoding the callback
model and finally and this is really
freaking annoying future will rewrite
exceptions
- wrapped things some of the time not
all the time and so if you're using
future you you basically have to like
get exceptions back out of it and then
look at those exceptions and see are you
wrapped are you maybe wrapped two times
I don't know ask and then maybe you're
not wrapped and then like try to kind of
deal with all of this weird
non-deterministic boxing that may or may
not happen depending on where an
exception came from in your code so this
is this seems just sort of like
unambiguously bad and so if you're using
future as an IO monad stop it doesn't
work very well but there are some other
options so scales at seven has something
conspicuously called IO which one would
think would more or less satisfy our
criteria but unfortunately it suffers
from the limitation of being directly
ported from Haskell in an extremely
naive way and it really doesn't support
the features that we need at all so
scholars at seven IO it doesn't support
a synchrony like in any respect there's
no support for callbacks whatsoever
which is kind of a problem and and
because of this it encourages you to do
things like block threads right so
remember I talked about M var and in
Haskell like m VAR if you naively port
it to the JVM you're just gonna like
block a thread like you're literally
just gonna like block a thread and and
wait for a value from some other thread
and unlike on GHC that is not cheap so
and scholars at seven just kind of
pushes you to do this
it only has a lazy effector capturing
constructor so you don't have the
ability to lift a pure value strictly
into the i/o and remember strict
execution is much much much faster than
the lazy execution when you when you
actually already have the value in your
hand so you know not having a strict
constructor is kind of a pretty
significant emission for for something
that you're purports to care about
performance and and so as a consequence
scales at seven I always very very very
very slow and finally it just basically
provides no abstraction whatsoever
so it's ironic so for a framework that's
basically all about abstraction this is
a very very very concrete thing
and the only type class that it provides
that characterizes its behavior is lyft
IO which is basically this right so lift
io is like this super trivial thing that
basically says I don't know what your f
is but whatever it is it has an IO
inside of it that's not that's not that
helpful in practice it seems like it
would be helpful but it's it's actually
not and there are no laws about it
there's certainly no attempt to define
what it means to be an io in in sort of
an abstract sense or any of the sort of
operational laws that that would
surround that so scull is a like the
skulls at seven IO was written like
eight or nine years ago so quite quite
some time and in you know about five
years ago they decided oh well let's
take another crack at this IO the thing
and we'll call it task
okay so skulls at seven has tasks which
is also an IO monad and then the name is
longer which is actually really really
annoying when you have to write this
thing about four hundred times a day so
that's I don't know oddly frustrating
but it does it does despite the name it
does actually have all the constructors
that we want so it has now which is this
sort of strict value suspension delay
which is lazy async fail fail is
basically you want to put an exception
inside of your task so that's that's
basically functionally that's it seems
like it's trending in a good direction
but because it was written five years
ago back in the Stone Age
it has a really weird implementation
based on actors and like other curious
things that we don't touch anymore and
it's very very very slow therapy very
very slow and inefficient so it gets a
justifiably bad reputation because of
that implementation and it still doesn't
provide any abstraction whatsoever it
actually provides less abstraction than
i/o because there is no lift task so
like you literally just have tasks and
and it's a task and and this has led to
a sort of systemic problem in the scala
ecosystem basically for the last five
years where everybody has to use tasks
and like if someone else comes along and
has their own task that's better than
the scholars that seven tasks you you
you're kind of stuck because all the
middleware frameworks had to choose one
for you so this is this is
just a problem and finally it has really
unsafe concurrency like really really
really unsafe concurrency and it carrots
you to do things which are actually
broken and we'll see some examples of
that in a second
but first off a program so this is this
is what a program looks like with tasks
right now remember we said tasks has all
the constructors that we want like now
delay async etc so it sort of feels like
this is on the right track we should we
should kind of see how it's working so
here we just print out like enter list
of names we read from standard input
we tokenize those names and then we use
this Traverse function which is like a
completely generic function that doesn't
know nothing it doesn't it doesn't know
nothing that was like incredibly
American it doesn't know anything about
lists or tasks or anything exciting like
that it's it's completely generic and
for each name we print out hello and
then at the end of the world we call
unsafe perform sync because we have to
run the effect we can't just return a
task to the runtime and sort of everyone
moves on with their life right but this
is this is kind of a trivial program
because it's not only is it just like
reading from standard in and things like
that but there's no asynchrony here
right like most of the stuff that we do
now that's actually somewhat interesting
is probably going to involve
asynchronous i/o
because that's how you write things at
scale on every runtime ever so so how do
we do that with tasks right well it's
gonna look something like this so here's
a function that reads from an
asynchronous socket channel this is the
Java 7n i/o library which we use because
the job of for an i/o library is
inscrutable and no one touches it and
we're gonna construct an async task and
good stretchy and async task gives us a
callback in the body of that that
constructor that we can then use and
invoke and when we invoke that callback
the task will be completed this is sort
of like promise but lexically confined
and we just read from the buffer
register a completion Handler and then
complete the callback with this sort of
like arrow right thing that you know if
you've used Scala Zed it's like burned
into your soul and if you haven't used
Skelos and you're like why did the
scylla programmers use so many ASCII
symbols and writing to writing to the
socket channel
it's basically analogous right we take a
bite vector and like we sort of turn it
into a by buffer and put it out on the
channel and complete the handler and you
know life is good this is completely
asynchronous right like this is not
gonna block any threads but it will
block the flow of computation block it
will suspend the flow of computation
until the callback is completed and then
when we use these things right so we
call the read from channel function the
write to channel function we can just
sequence them into a for comprehension
and everything is basically isolated
from we we don't see the difference
between synchronous tasks like the one
at the top and asynchronous tasks like
the reads and writes so here we're just
like reading presumably a version from a
channel that we connected to nothing we
decode that version and if it's valid
then we read a syn write an ACK if it's
invalid we just close the channel right
so basic network i/o stuff right there's
there's a bear trap kind of hidden in
this though right and this is a bear
trap that like has infested a
surprisingly large percentage of the
scala ecosystem because there's actually
a surprisingly large percentage of the
ecosystem that is built on task because
it's really useful and the problem is
that no one really asks themselves this
question and therefore everybody's code
has bugs so if you've used task or a
framework that uses tasks you probably
have this bug and the bug is this what
thread are we on like at this point in
the for comprehension what thread is
this schedule done does anybody know the
answer the answer is the niño event
dispatcher thread why wouldn't you want
it to be on that thread and this is
horrific
like this is terrible like the niño
event dispatcher thread is not a thread
pool that you want to do anything with
like you want to get away from it as as
quickly as possible but task is just
gonna like lively leave us over there
and it's because of the way that async
is implemented so this doesn't get said
enough it talks or or in like blog posts
or in just so a fact that so I'm
literally just gonna digress for two
slides and we're gonna talk about what
the heck do you do with threads on the
JVM because no one knows how to do this
so thread best practice number one
divide your thread usage into three
categories
CPU bound computation that has no i/o
whatsoever blocking i/o so legacy
stone-age frameworks like Java IO that
you have to use but you really don't
want to that's a separate class of
computation and then event dispatchers
this is your third category and then
allocate a single thread pool for each
of these categories okay where the the
computation pool is gonna be a
work-stealing pool you pre allocate it
it's numb CPUs in size right because
you're just doing computation on this
right you're literally CPU bound
allocate it to the number of cores
unless you're on Travis in which case
don't trust the number of cores but
that's a digression blocking i/o
blocking Ohel has to be an unbounded
thread pool which sucks right like if
your systems programmer the word unblock
unbounded should kind of send shivers
down your spine but you you have to make
sure this is bounded at some higher
semantic level because the problem is
that blocking i/o is going to eat a
thread you can't put that on a limited
thread pool because you'll starve so
unbounded and caching and really try not
to do it very much and then finally
event dispatchers which are gonna be
really small thread pools like one
thread works really well for most
applications don't go before high
priority daemon threads and and and just
basically like you're gonna try to keep
your computation as confined to the
appropriate pool as possible right so if
you're doing some CPU computation read
doing computation of any sort it has to
be on the CPU pool if you're you know
doing blocking i/o put it on the
blocking i/o pool and obviously when
you're receiving some event you're gonna
receive it on the dispatcher pool and
then you're gonna thread shift off on to
one of the other pools the problem is
that skeleton seven gives us basically
nothing to make this easier right now
this is this is an important thing right
this is exactly why you deployed your
application into production and your
throughput was like 40 percent of what
you thought it should be is most of the
time like thread stuff tasks doesn't
help us solve it in fact like I said
nearly the entire Scala ecosystem has
this bug task does even worse give us a
function which seems like it would solve
this problem because it's called Fork
and it takes a thread pool as a
parameter and it doesn't work it's like
literally a trap it does not do the
thing
you think it does and so that's bad it's
it's like worse than nothing and this
use case of like moving things around
between thread pools it's like literally
the most common thing that you're gonna
do when you're doing asynchronous
programming like you have to be able to
do it very very easily and like I said
before scholars have tasks like while
all of this is going on is encouraging
you to do really really really dangerous
concurrency and it's really really
dangerous because in Scala tasks there
is no functionality for resource
management
okay so resource management and
concurrency oh really inextricably
linked concepts if you're doing one you
have to get the other one right and
scholars add tasks doesn't so the skull
is a task basically gives us some
functions that look like this right so
we've got both and we got race both
takes two tasks at a and a B and gives
us a single task that returns a pair a B
just runs them in parallel right race is
kind of a little bit weirder and it
takes two tasks a and B and it races
them against each other and the first
one that completes its going to return
that result so these are these are kind
of the core primitives other stuff gets
built on top of us and these are both
broken because and they're broken
because in Scala is a task
there's no way to safely do something
like this so here we have a task that
acquires a resource and then we run it
through the both function with a task
that just immediately produces an error
right you can imagine this is something
more complicated we're like the task on
the right does something elaborate and
then accidentally produces an error
right like something like that the task
on the right is going to shut down the
task on the Left when when it produces
that error and it's just gonna
immediately return the error but then
the question becomes where does the
resource go right so if you happen to
actually acquire the resource where does
it go
the answer is into the ether where
presumably it will be garbage collected
the the the the race also has a similar
problem right we acquire two resources
right and race them against each other
one of them's gonna lose and it's just
gonna leak right you just not you're
just not going to be able to do anything
with this so so these these are what
scholars and tasks encourages you to do
with concurrency and it's wrong it's
really really wrong and and because it
doesn't give you any ability to hand
the resource management perils that come
along with this you you get yourself
tied in knots
so it's a step in the right direction it
doesn't provide us with thread control
it's the the concurrency is broken
because there's no resource management
in the algebra there's no resource
management in the API whatsoever so you
can just like build yourselves into
traps has a terrible implementation and
no abstraction whatsoever like no no
type classes no no way to abstract over
your definition task so are there any
other options right well maybe we could
do like Conti of free of function zero
unit a which thanks to Brian McKenna we
know is actually tasks but no one would
ever want to use that like this is this
is a very confusing type to look at and
it's it's sort of surprising that it
works so clearly this is well that
semantically does the right thing it's
not actually what we want to do other
frameworks have kind of stepped forward
to try to fill this this problem space
so FS two and monix are to streaming
libraries in in Scala they both provide
tasks implementations with resource
management with abstraction this was
kind of FS two's contribution to the
space as they show for the first time
defined what it means to be in effect
what it means to be you know
asynchronous things like that in a very
very general way and they also like both
of these provide performance which is an
order of magnitude better than scholars
at seven
monix in particular has a really really
really fast task implementation but both
of them are kind of tied to this larger
streaming library right like you you if
you're gonna use Monica's task you're
probably gonna have to use Monica's
streaming and that's that's probably not
what you want and especially since these
abstractions that they define are very
specific to those frameworks they're not
this general standardized thing it's a
little difficult to to take advantage of
them in a cross framework way so this
was why basically at the beginning of
this year I created the cats effect
project so so cats effect defines an IO
monad which we're back down to two
characters and and the IO Mona has all
the constructors you know and love I
biked shaded them a little bit
because I'm like that but it's basically
all the same things as in tasks right we
have pure apply async and raise error it
is much much much much simpler on the
inside like much much much much much
simpler the implementation has no actors
it's it's really very straightforward
code aside from like one data structure
and it applies it defines a set of
abstract type classes and laws so we'll
talk about what laws are in a second but
basically this gives us the ability to
talk about again in a platonic sense
what is an effect like what does it mean
to be an effect type like IO and and how
can we be sure that it's that these
effect types are behaving appropriately
and there is no concurrency whatsoever
so this is maybe like a controversial
choice but Kats effect basically makes
the argument that the IO monad should be
a primitive on which you can build
concurrency stuff that's safe on top of
it but concurrency like IO itself is not
an appropriate type to be doing
concurrency with you should be doing
concurrency with something else that's
that's the contention right and so in
that vein IO doesn't provide any
concurrency it doesn't provide any
resource management and it doesn't
provide any preemption so every IO
action is atomic either runs or it
doesn't one of the two and there's
there's no sort of intermediate state
and so that provides you with a sort of
a same building block a simple building
block that you can build higher level
things on that take care of these
problems for you such as FS 2 for
example so here's our example from
earlier using tasks now we use IO things
are a little bit more concise because
that's nice but basically it's kind of
the same idea right we haven't actually
done anything different and we can
replicate our asynchronous program from
earlier and again it looks exactly the
same
we constructed these read things using
the iota async thing but you notice
we've added one line to this and it's
this shift function so we shift
explicitly to the CPU pool and we can
just do this wherever we want and this
actually completely solves the thread
shifting problem right as the name
suggests right it just basically gives
you an effect which
you from one pool to another
specifically what it does is it
relocates computation following its
sequencing everything after it in the
for comprehension we'll be on the pool
you give whereas everything before it
might be on some other pool you don't
actually know it is the only thread
related function in the entire cat's
effect library and we did this because
when we started doing prototyping with
cats effect we discovered that nearly
every real program needed this function
which is kind of the argument I made
earlier right like you always always
always want this so we just baked it
into the library it's not actually a
primitive though you could you could
just define it yourself it's it's
literally just there for convenience the
definition of this function is like six
lines so I said I'm running out of time
but I said that cats effect defines some
abstractions it defines what it means to
be in effect and it does this through a
hierarchy of type classes with very
small font and the the type class is in
red at the bottom are things that are in
cats effect and so we have sync and
async and effect and then we have the
lift IO thing that we saw from earlier
but sync synchronous effects
asynchronous effects and just regular
effects right and we basically make the
argument that you know synchronous
effects are fairly common asynchronous
effects are a specialization of
synchronous effects so like every every
asynchronous fact is also could be a
synchronous effect and regular effects
like total package effects down at the
bottom are this runnable thing that's a
very tight specialization so it's
relatively easy to be a sync like
basically actually all you need to be
this is laziness and arrogantly like
those two things you're probably gonna
be fine
so like if you're familiar with cats
there's this type in the library called
eval eval is not a sync because it
doesn't have error handling but if you
do either T of eval it is a lawful sync
a sync requires callback support
okay so callbacks are kind of difficult
to handle correctly especially if you
care about stack safety so there's a lot
fewer types that actually fall into this
category and then finally the effect
type type class like if you have an
instance of the fact you are literally
as powerful as i/o like you're basically
an i/o monad right there but there could
be many different instances of this
right so like monix is task the scholars
at eight I Oh like all and of course
cats effect i/o like all
these are different instances of effect
but with all of these things parama
tricity like that argument that we made
about monad earlier isn't strong enough
for us to you know sort of constrain the
behavior of these type classes right
because the types are actually really
general right you just like take a thunk
and like put it inside a thing that
doesn't really tell you how that's
supposed to behave so what we mean in
order to prevent people from writing
incorrect implementations is a set of
laws okay and I don't mean the set of
laws that you like right in LA Tech and
then put on the haskell wiki I mean like
actually a testable set of laws right
like actual code that you know basically
produces a TCK for implementers of these
type classes and then once we've got
this users can rely on lawful behavior
because as long as the implementers
aren't doing something nasty the the the
users know the implementers had to pass
the TCK they had to pass the laws and so
every instance that they receive that
claims to be in effect is actually going
to behave same way and implementers
meanwhile can use the laws as like a
free test suite right like it's a bunch
of tests we worked very very hard on it
they're actually somewhat hard to
satisfy if you're doing things wrong and
you can just toss them in your program
and make sure that your implementation
works so here's kind of what they look
like
this is st. Claus or a part of sync laws
rather we've got some some relatively
straightforward laws here right like if
you delay a pure constant that you
already have it's the same as pure that
seems intuitive if you if you throw an
exception inside of delay it gets caught
and sequenced as an error that's the
last one down at the bottom so these are
all these they're all laws and there's
several more and and each each of the
type classes has its own laws associated
with it and if you're an implementer you
can like for example this either T eval
thing you can take these laws and you
can put this in your test suite and when
you run it like a whole bunch of tests
are gonna run with a bunch of different
property checks and they're gonna verify
that your implementation is not wrong so
you know this is how we can be sure that
the instances are valid that the
instances are safe to rely on it's how
we can prevent invalid instances like
future for example remember we talked
about how future is not really a
suitable I OMA IO type and the laws will
tell us this if we try to implement an
effect for an instance of effect for
future running the laws will fail like
the tests will find all of the flaws
that we pointed out at the beginning
there's also some other ones that are
kind of surprising like the Monad reader
type the reader monad transformer cly's
Li has some issues as well specifically
it's not stack safe right and you know
we said that stack safety is an
important property of these things cly's
Li doesn't have it
therefore cly's Li of some effect is not
in effect so anyway
several frameworks already are using
these abstractions and getting really
good value of them so fs2 for example we
already talked about basically if you
use fs2 you don't have to use my io type
with it you don't have to use scholars
Ed's IO type you can use any I hope you
that you want monix is tasks for example
anything that satisfies the laws and
that is that is a very very very
powerful concept HTTP 4 s which is like
the only web framework you should think
about in scala Dubey and several other
frameworks are also taking advantage of
this so it's kind of becoming a standard
definition for what it means to be an
effect and Scala and like I said you're
just you're not if you don't like my IO
which I completely understand you don't
have to use it you're you're free to use
someone else's so finally in conclusion
effects are scary like always scary all
the time terrifying the IO monad is
really really really helpful and and
being generic about it is you know
allows very strong ecosystem effects all
of the options in Scala were bad before
recently they were really smart in their
day but they're like their day was past
and now we write on paper rather than
stone
so Kats effect yay anybody have any
questions do we have time for questions
we don't have time for questions
angry Bodil is angry gives them up for
this thing</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>