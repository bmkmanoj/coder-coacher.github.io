<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Couchbase Performance and Scalability: Dustin Sallings, Matt Ingenthron | Coder Coacher - Coaching Coders</title><meta content="Couchbase Performance and Scalability: Dustin Sallings, Matt Ingenthron - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Couchbase Performance and Scalability: Dustin Sallings, Matt Ingenthron</b></h2><h5 class="post__date">2012-05-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_z-cUaJ0Ds0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm mad ninja through compact places
and my colleague Dustin songs we're
going to bring clip
a little bit so I'm up first oh go ahead
cute go right ahead so I don't know how
many people are aware just to kind of
walk through a little bit so a couch
case we really have a combination of
number of the people that had been
working a patch of couch TV and then we
had a project that does not work working
on that was called my base we brought
the standard a little over a year ago
shouldn't some plain since then so by
the way can everyone hear me in the back
and a mic up okay so who are we were the
makers of a high performance document
database so I supposed to be controlling
know you can okay you can see if i run a
spicy so we we built a database that
sort of in that no SQL category and
there are a lot of different ways that
you could sort of break up know it to a
lot of different ways that you can look
at it so we really what are we were
where they distributed we're a a
database in a more specific way in that
no SQL category were distributed across
many systems many bm's designed to scale
quickly design and this is actually
we've leveraged a lot of airline
specifically Aurelio De designs that we
don't have any special nodes in the
cluster nothing special that yet have I
won't go into lots of theory on things
like cap and so forth but by design
couchbase is consistent and we think
that that was a right approach for the
kinds of applications that we're
building for by design we're actually we
have a managed cash as part of touch
base so we very carefully look at how we
manage system resources we very
carefully look at how we can get the
information people need who are
operating applications we will
understand to do capacity planning
that nature a lot of that was driven by
some of our early deployments is that we
just ran into these issues early on so
we need to be able to get a lot of info
and that's actually where airlines work
very well for us is we have this I
always use it as sort of this we have
this control plane layer that we use
within airline to understand as we build
out the cluster and understand what's
happening within the system and we've
built all of that clustering so who uses
it that might be another way to talk
about the where does it fit in the know
SQL continuum or so or whatever term you
want to use so just a couple examples ad
targeting this is someone targeted that
ad speaking of enter the ad targeting
was actually not a use case that we
anticipated early on but it turns out
room does ad targeting I'm going to give
a really pedestrian definition you have
to display a little you know
advertisement you have about typically
from one of our customers about 40
milliseconds to come up with that answer
to display it so the faster thing you
can get that more time you can spend on
all of your logic on which is the right
ad so because we were super fast because
we're because we we had a good way to
grow these things people like AOL
advertising abused us social gaming was
another one this was partially zenga was
one of the original cofounders of the
one of the fortunes of projects mem base
we start doing a lot of work with xanga
early on and then just last week
actually we had a
kind of a little success story that we
will talk about few weeks before that I
think about a month before that actually
company named OMG pop who have game name
draw something so draw something when
they put it together they deployed it on
couch base and then it went viral so
it's been out there and deployed across
lots and lots of she invert these were
no so we went it went viral and now it's
a bit I can't remember the number of
users but they just had to continue
growing growing mustard the good part is
that with the clustering that we built
on top of airline OTP we were able to
just continue adding systems the
clusters into you growing it out still
to make continue to add people so since
since there's kind of this vague sort of
you of it might be worth mentioning that
the the clustering that we use is very
much the OTP clustering and we use the
OTP supervisors throughout the
application with some small differences
the the thing that we're doing for the
really small response times we actually
had a customer who was asking us for a
hundred micro second to SLA they said
that we're getting that most of the time
but they wanted to make sure they never
got that below 100 microseconds on the
95th percentile we do that with
dedicated processes that are you know
crazy tight C code that shouldn't you
know exist in this modern age and those
are extension of OTPs concepts of
supervision in that we built these
supervisors to run those specific
processes so they they act very much
like any other process that would be
inside the early system but their
external from that correct actually my
presentation underlying peccary last
year went through some of that and some
of the things that we built that just
watch that one this year we're talking
about creating the the other example of
Plymouth
things like all recipes concur we have
news travel monitoring lots of
situations where people have a social
appleton content that kind of combined
together so just a couple things this I
actually think this is pretty cool but
part of the reason I think it's cool is
because I was pretty involved in there
at least the first version of it so we
use a use this is this UI is actually
really just jQuery making calls into
airline through mochi web and so it's
really just any node in the cluster can
serve up this UI and it's really just a
matter of going and asking the cost or
four different kinds of statistics from
the overall cluster and then the browser
does the rest so it's just to overload
the term literally rest browser does the
rest browsers receiving these rest
responses and then rendering so what you
would see if you're running clusters you
would see a set of those that are out
there running within the cluster and you
can drill happening with them and it's
even as simple as if you want to add
another one boot it up install the
package at the ad server go tell where
the IP is and under the covers we do all
the OTP ping pong to get everything
worked out between the two nodes so the
users abstracted away from all that
they're at the senator config files or
anything like that it all happens and
randomly generated cookies and all that
kind of stuff yep so as I mentioned
earlier we spent a lot of time thinking
about how we can get these get the kinds
of metrics we need out of the cluster to
be able to run this system and
understand what we need to do for
capacity planning be able to operate it
in a really large environment and an
environment that's scaling really fast
so this is just one example where we
actually use the Earl and muscular to go
out and understand the processes that
we're managing under set of Supervisors
will get statistics out of them pull
that together do whatever aggregation we
need to do we actually keep it for
history if you sort of an r rd round
robin database where you
resolution as you go back in history
because you know two weeks from now you
don't care about what happened between
second 34 and 35 so review things like
that will keep the history and then we
have just a huge number of kind of
metrics to be able to understand what's
happening with the system and that way
people who deployed or mobile set a plan
accordingly see how a new application
pusheffect affects the way the database
is deployed things of that nature so
with that I want to turn over to Dustin
who's going to talk a little bit about
some of the problems that we'd run into
the way we handled that which addresses
kind of this is DevOps back okay we're
developers we have these operational
issues what do we need to do to try to
understand so the the interesting sort
of thing that that happened as we
transitioned into the sort of thing that
we described earlier to what we were
doing with with couchdb is that
historically these processes that were
you know really insanely optimized see
code we're dealing with all of the i/o
on network and disk and all sorts of
resource management an erlang was
basically OTP as a service that we could
spread across all kinds of things and
and you know benefit from then we
started adding a lot of features that we
inherited from CouchDB and started
bringing that into the management layer
and that's where we started running into
these issues where some things weren't
meeting in our performance expectations
as they were and the general response
I'm sure all of you have seen this
before is we'd have a lot of developers
who you know we'd go back to and say
this you know isn't fast enough it
should be at least you know to 10
whatever times faster for this type of
operation what's your estimate on how
you'll be able to get it to go faster
you know if do what's the problem
analysis and all that kind of stuff and
the response that get back which is
literally this is response I got back
from you know some of our like core
developers on early is I don't know they
just scream it's Erling who knows it
could be anything we can't tell what's
going on in the box it's just magic and
if it doesn't work we need to rewrite
everything at sea and you know I'd sit
through tons of meetings like if
anything's
long we have to rewrite it and see
because it's early we don't know what's
going on of course you know that's
really frustrating for me because I'm
like we know what's going on we have
data we have tools and if you are just
telling me that you don't know what's
going on then you know that that's kind
of your problem and I need to get
someone else to do stuff so then you're
not being me and I like to you know look
at actual data and say what can we get
out of the system it is fundamentally if
you tell me that you can make this work
in C and you can't make it work in
Erlang I will tell you that the Erlang
vm is written C and if if you can't you
know extrapolate from there then you're
just kind of in my way so the first
thing we did was we started looking at
some of the some of the stuff that we
could get from early so f prof you know
we had someone went racing ran through f
prof and i got i got this right so first
pass on f prof was actually i got 60
megs of this and the guy who just came
back and said well you figure it out all
i got was this giant text file so i took
60 megs of text file and said I'm a
programmer I can program so this thing
is kind of self-describing it's it's
fairly well documented I can kind of
figure out what's going on for that so I
built the tool that could eat all that
and spit out this so this is pretty
helpful it I have a bunch of these
things or big giant complex pictures and
they would draw these little red boxes
with red arrows saying this is sort of
where most of the time was spent in this
area and I could say well this is the
stats aggregator but occasionally go
completely insane start eating lots of
CPU and we could we can start looking at
that but the the general result of that
wasn't terribly useful before you notice
that the big boxes yes right so what we
did is a whole lot of like two percent
and sometimes a five percent and you
kind of look at that and go well I mean
if I like to ignore am doll because
there's another guy the company's always
saying his name so I'm going to fight
him but you know yeah we're not going to
get very far kind of targeting that but
the very least you can we have something
that we can kind of look at we can start
following kind of the things down so
what we did start looking into other
tools because there's other tracing
stuff right it's not just f prof
but it's hard and I actually didn't draw
this to say it's really funny it decided
to just throw them all in a big pile
that's useless because that's kind of
what I experienced there's all these
tools that can do various types of
tracing and every one of them that I
would find would have like a DSL for
defining trace points all this kind of
stuff and they would all say but if you
do something wrong you'll done lock the
vm and and if you do something right
it'll just run too slowly for me to
actually run my tests so I could kind of
get an idea of particular bits of code
taking too much time but what I couldn't
do was say what is this system that's
that's running spinning its time on
without stopping it from running or
having more information than I could
actually log to work with and then even
even if I got that working there's solid
stuff I don't know because one of the
first things that you know we got was
well it looks like we've got some memory
pressure because we have competing
processes on this box like actual OS
processes that appear to be suffering
memory pressure because one of the
things that is fairly highly optimized
see starts to slow down quite a bit when
erling starts to kick in and we have
available CPU but it's not kind of using
it very well so we're trying to figure
out how these two things that are
otherwise independent or affecting each
other also dislike some simple stuff
that's kind of hard to trace I mean you
kind of do it with a tracing like
scheduling events but then you get into
like OS device interactions I can ask
questions you know for for other parts
of my system like when am I you know
actually touching this device driver
code because I want to know when I'm
actually doing rely ops not just you
know doing right sis calls or something
and some of those are surprising because
you get them from like swapping or
whatever there's internal messaging
cross phone messaging various things
that you can kind of do but not in not a
sort of holistic way on a running system
without being you know excessively
invasive so this of course going back to
the developers meant that you know they
say I have an excuse again you can't
answer any of these questions so that's
when I started fine i use DTrace for all
the rest of the stuff I'm doing
let's get dtrace into into early and
that's its it sounds kind of like yeah
we've got this giant list of tracing
tools why do we want more we already
have tracing this doesn't seem like the
kind of you know thing that would be
terribly beneficial but the thing to
understand and this is this is really
hard for anyone who's not actually used
it is a detail script is not something
that you placed into you know your
program it's not estrace it's not any of
those sort of things it's an actual
script that your kernel runs so it's
it's your your program is the entire
operating system that you're working
with and it sees everything from like
little tiny user probes that you decide
to place in your application that say I
have started this event I have ended
this event all the way down to device
drivers and lines of kernel code if you
really want it so i can go literally
from tell me the function that is
running when this you know the scuds eid
device kicks in or something bizarre
like that so it's very very far-reaching
but also when you have your kernel as
the scripting language a thread has no
sort of distinction across processes for
example so I can trace things that are
coming in through my little C program
and then feeding data into early and
where it goes into erling before it
comes back out to the sea program I can
see the entire world so it seemed like
it was worth the effort to kind of to
kind of get in there although you know
there's still the question you know
what's the point and it is that my
program is more than what's running in
the early in vm and in particular it's
how it's affecting the operating system
and as much like very simple things like
this is one of these were you know the
other way to do this would be just pull
up a terminal and just have people ask
questions go because i can say which
cpus are not getting scheduled how is
how is my SP laying out across cpus
anything like that that I want to do but
there's very specific erling stuff I
wanted to get in so I could I could
understand what's happening in the vm
little bit better so function entry and
exit that's something that's that's
really common stuff I want to know when
a function starts when a function ends
Biffen if are actually really simple
functions are kind of hard because
conceptually you know when does a
function get entered and when does it
get exited in a system that's like has
mutual tail recursion on on the other vm
it's really really hard but when we're
looking at like memory pressure there's
object coffees which are completely
without context a function might cause
an object copy either by doing a message
send or allocating one or something but
the object copy occurs without context
and that's where we start to get into
memory pressure so when am i moving a
lot of data around and memory that that
would be affecting other parts of the
system process is starting and ending
lots of stuff that you can see on your
unix system happening here i want to see
it in here and i want to see it in
context with the rest of the system but
in addition to the stuff that i'm
getting this erling specific i want to
see the rest of the system so i want to
know what's triggering heap expansion so
you know early occasionally has to go to
the operating system and ask for memory
and get it back when am i doing that
what's causing that what's which exact
thing is causing it to actually grow the
heap what's causing actual I ops am I
using the file system cache effectively
that's that's a big thing that we have
we've got this you know append only be
tree that we're writing to disk
theoretically the head of the b-tree
stays hot in practice does it I can tell
because if I'm doing read and write
syscalls and they're not actually
leading to I ops through the device
driver then I know that the file systems
taking care of of cushioning all that
for me but if I see every one of those
reads and writes actually causing an eye
out than I know that I'm not actually
using the file system cache effectively
and most importantly I know this on the
system while it's running I don't have
to like take it apart do instrumentation
put it back and do all this other kind
of stuff and just from my mac here when
i was typing this line is 230 9446
points that i can trace on each one of
these has context a lot of them are
things like read enter with
this file descriptor this buffer this
size so I can say this read is beginning
its going to move this much data across
this file descriptor I can watch it open
the file descriptor so no of its network
or file or whatever I know when it
completes that reads this call I can
take the nano second time between them I
know whether it succeeded or failed I
know how big rights are when they fail I
know how much rights all that kind of
stuff and you know quarter of a million
other things so it seemed like a pretty
good thing and of matt is the expert in
this so i'll let him describe kind of
more of how to use it i just made it
work I don't know they historically
expert so I know we're moving I think
we're moving like super super fast we've
taken ten minutes and I just had a whole
lot of tea yeah so we've gone through a
whole bunch of material so I may
actually pause for a second and see was
that reasonably comprehended do you
understand at least the problem domain
will give some examples any questions at
this point when you're using f-prot
since it has really high impact on high
overhead winner who is taking
measurements were you trying to do any
of those in production or was it all you
like anyone know this is totally lab and
this is one of the big differences in D
trace the success of d trace is I am on
your production system already fully
instrumented for everything when you
need it and then you get the the razor
thing you're looking for and you can do
it interactively so there is no overhead
there is no like needing to change
something until you actually start
firing probes and then you're fairly
limited in the overhead that you can
introduce at those probe fires so you
may see impact to some degree but you
can be very specific about it for
example if I'm looking at I ops I can
say I only want to know I ops if I'm in
the middle of a function of this
particular function so if I start the
you know a pinned to be tree function
then I want to track the I ops and
accumulate it back to that until it
completes and then stop tracking the I
ops so you can be very very precise and
you can do that on your production
system yeah it's not
sarily clear from if you see some of the
details of how to eat races implement
you lose sometimes like the copy and
stir the reason you do that is that
sometimes there's information you want
to grab in a context and while when
you're writing a script it looks like
it's all happening whenever that
interceptor happily happens but
realistically it's grabbing some
variables and then its own context some
time later it's dealing with the rest of
the aggregation work the other thing
worth mentioning with DTrace is there's
a Deadman switch sort of saudi trace
determines that it's creating too much
impact changing timings on the system
it'll kill itself you can override that
you can go back and say no I really do
want the data but it's it's intended for
that just brief background so it came
from and I suspect a lot of people know
this but they're probably a couple to
tone it really came from solaris built
up for solaris 10 and at the time i was
at sun it wasn't part of the solaris
organization but i know people who work
on it and the problem they were trying
to solve this they'd already built a lot
of observation tools and
really good modular debuggers and things
of that nature to be able to understand
what was happening but you'd still have
these problems actually it goes back to
what was mentioned this morning you'd
still have these problems like I I'm a
financial services company and every six
months you know this unix mainframe like
thing will halt so I want you to send a
kernel engineer to sit in the data
center and and wait until it halts again
so that they can go through debugging so
that we can spend 20 minutes and
understand what's happening before we
send information back and they said the
Solaris team sort of recognized that
they needed to build the next level of
tools to be able to go understand that
next level of problems all the really
basic bugs in Solaris up to that point
has basically been solved and needed
another Center well and that's that's
living today at Joint those guys are
still doing that they had a bug recently
where they would find that systems would
continually get slower overtime at this
at something related to TCP that they'd
never seen before they went out there
for a couple minutes just sort of poking
around with DTrace like what's this
what's this word sitting it's time built
this this beautiful flame graph thing
you should should see some of these
things and then said oh there's this
piece in the kernel that cleans up
connections after they die and it kicks
in when it's like a it's a small hash
table they ends up being a 256 arrays
with chains off the end the chains are
getting really really long because
nothing's pruning them because it kicks
in on a memory condition which we don't
have because we put entirely too much
memory in the box for what it's doing so
they just kind of like you know they
spend 15 minutes on this and go this is
why you've never seen this before at a
kernel fix and throw it in place and
they couldn't reproduce it on other
systems because it pretty much had to be
in production for a month before it ever
occurred now they can just go oh it's
right there clean it up move on so any
other question cool okay
or so where do you start usually a knot
with dtrace actually so you usually
start by having some sort of question
the reason I always try to say this is
the other tracing tools and even level
tracing schools are usually the place
that you will frequently start so you'll
start off maybe with something like an
iostat or something like that you'll
have an interesting question you look so
you know what the system is doing you
might be able to see what's happening
with processes and cpu time and you know
what the behavior is but you don't
necessarily know what's causing that
behavior you know what the acting sense
you know what the applications are you
can kind of look at the starting point
you know what the behavior is and maybe
it's a slow i oh for instance and then
you want to be able to correlate those
two so that's usually where you go into
the system a little further and you have
a question for example in one case this
is actually where your your analogy fits
pretty well oh yeah so there's I have a
colleague who would always talk about it
as I so let me just toss it to the room
what's the best debugging tool huh
exactly try statements right throat ray
statements into whatever it is printing
out and so the cool thing is with DTrace
you can basically insert a printf into a
running process or into the kernel
associated with a running process at any
point in time dynamically even even on
conditions even on the even on
conditions because frequently with with
a like a printf right you potentially
end up in this situation like we were
talking about earlier we have the 60
megabyte file and now i'm going to go
troll through it i really want to
traditional burnt down and so usually
with me Trey still end up in this
situation where you insert these trade
statements and then you start iterating
so you do it the first time you see it
really doesn't tell me what I want you
really want to see what's happening in
this
arranged I'm going to add some predicate
stew it and then from there I'll be able
to work things out so one example is
Mustafa by the way huge props to the
bachelor guys who had been doing some of
this work originally then Dustin went
back and added on to it this code is in
the current OTP code base but we'll talk
more about that actually did kind of
kind of separate thing on the I have a
thanks at the end for that specific
elements to say that yeah but I don't
want you to think that this is all stuff
we've done so we're working within the
community lit a bunch of other people be
Morgan's well so this is a this is a d
script this is a really basic d script
and I'm in the walk through briefly if
you're at all familiar with awk at least
to me it always reminds me a box so you
have you have these things that when
processing this thing is going to run
right so when I get in alignment matches
here we're defining a variable that
we're going to use later and we're
saying with in Erlang and we can use a
wild card so this in this case we're
saying all processes well I think it's
important to point out that that's a
threadlocal yeah well I am later ok
actually so the so the with this will
actually trace across all our line
processes running on on the given system
and I could narrow down to a particular
pin
later and basically we're saying anytime
we do a function entry function return
or process schedule any of those within
our like what we want to do is set a
threadlocal variable and we're going to
copy into the string r 1 and r 1 is the
function name of that yes so mfa yeah so
the NMA is going to get copied into a
threadlocal and so that that's going to
become important because we're going to
want to only fire additional probes
later based on that threat local so
again the question we're trying to
answer is who's copying stuff so we then
we can look into the Erlang bama and we
can say ok we never copy struct fires if
that threadlocal is not an empty string
I went to add I want to keep track of
that information I want to put that
somewhere so this this thing here with
that symbol is a DTrace aggregation that
means magic so so that means that within
this running d script we're going to
start collecting data and we're going to
put that data together and then we're
going to print it out at some point
later so that we just named it copies
and all we're putting into copies is
this same thread local self current that
i'm fÃ¡ that we captured earlier so when
the process was we would function entry
or function return process scheduled we
we copied that into a variable later
we're sticking that into an aggregation
within that aggregation we're now going
to do a summation of the number of times
that thing is called so no it's that's
actually the amount to data copied r0
some of this goes but sometimes you
actually have to read a little bit of C
code or understand it what this
documentation understand that you are
you sir so we get to the coffee struck
our dessert copy struck is the amount of
data copy so the one thing that I want
to point out because it's it's
completely amazing to the point of not
being obvious is this at copies thing is
a global variable at the extreme it's a
global variable across all processes on
your computer and if you're running a
jail system that's across all sub
operating systems and everything else so
its global as a variable
possibly be whereas this is a
threadlocal that means if you have like
300 erling VMS running with you know
each with 3,000 processes every time a
particular function is called with it
with an exact you know signature we add
that to the global so when we go in and
print out the results from that it's
it's really that function across
everything and that's just how this
particular scripts written but on that
that allows us to say all the stuff
running on my machine this is the thing
that's moving the most data yeah and you
can certainly go into like syscall type
things and you could just you know
answer individual questions like who's
allocating memory how much memory
allocator in this case we're digging it
early the other one to show you here is
that there are sort of built-ins in this
case we're using tick for a really
boring thing the other cool one is
actually a there's there things like the
profile provider so you can do things
like run on a regular basis and do
certain kinds of profiles some of the
built-in providers this is the tick
provider and all we're saying is every
10 seconds fire this and all we do in
that one is we're going to truncate
actually yeah truncate a cookie and 25
biggest yeah we're going to get the 25
days and we're going to print that out
so what does that actually end up
looking like well so when you started
off and say oh there are seven probes in
the of the 200 and when was it 200 it's
like quarter of a million something at
239,000 probes in the system the ones
that you've requested are these seven so
instruments for those seven and then it
is going to give will see that the tick
ran
cpu 2 and then we'll see the individual
mfa's are called along with the amount
of day and 25 days so now now we can see
that the one that's largest is genu call
to call yeah we gotta get rid of gen
iphones killing us this was a this isn't
useful production data this was me last
night going oh I want to screen shouted
this running so this is whatever my
computer was doing at the time which
apparently was replicating data and
couch TV yeah so but it just uh you know
imagine in some other way of being able
to get that data every 10 seconds in a
regular basis be really hard to do that
kind of instrumentation another question
so you start with different questions
this one came from a developer in inside
catch me the the the Kirk one from
before just this is one of the things
that this was an assertion you can't
know this and that's why I can't make
this go faster after we're I didn't see
yeah so the question was how long does
it take for a message to be receiving
this because so many things are
happening with the message outside the
individual function in early so the way
this one is kind of neat because it's
not actually a script so I know this is
a looking looks pretty terse but it does
actually you do find after you use it
for a little bit much like you would use
awk that you can kind of just play with
these on the command line and sort of
iterate that probably should have put a
command line in there because that was
the you can't do this and then yeah and
then it's start off like well let me see
if I can do this and
came down to in this particular case
we'll walk through this briefly what we
have we have the dtrace man line a
couple frode's the sin and then we have
a process schedule and so and you have
just know what the arguments are again
so r 0 is sender arg one is recipient
yes and what we're doing is were were
yeah gathering the current timestamp and
putting that into an aggregation and at
some point later we take the timestamp
and figure out when it was sent put that
into an aggregation so the actual thing
this is saying is how long because I
didn't have one for when message was
received so this is sort of we had to go
with so this is what is the time
difference between winning message is
sent from one process to another and
that process gets scheduled on to a cpu
because that's what that's what i had we
don't actually know receive so there is
probably a little bit of slop in there
but it's enough to know that the process
was getting but we learned from the
previous talk that send is 40 times
slower than receive so this should be
approximately the answer so the oh I
probably call out with the aggregation
aggregations you'll do this quantized
and quantize is either but quantized
with that as hell in front of it is
powers of 2 quantization so that way
it's really easy to just kind of see
what buckets things fall into you can do
linear quantization as well and you can
play with a different quantization but
this is a man line you know let me find
out what's going on in this particular
case as you can as you can't see if you
were to walk up here what you would see
is there a fuse you're welcome here
actually yeah you the king
negative which is probably we're not
sure if that's a bug in OS 10 was
multi-core stuff but it's probably a
little bit of sewing lot there were
something the time so it's like negative
512 nanoseconds once we can kind of
ignore most of that and we can see that
right here this is 8192 this is
basically 8k 16k so these are the
different different quantization powers
of two quantization so now we know you
know how much time is it taking for a
message to be sent well on average 88
millions i think or is it eight thousand
nanoseconds think it's eight so remember
the exact value but you and then you can
even take that quantization if you want
to do your own printf something like
that make it a little prettier you can
do that sort of thing that's just an
example of got a question let me go see
if I can work out what the answer to
that question is with a little bit of
iteration get there pretty quickly
another question is anything allocating
currently inside the system so to look
at another example we have another
thread local we're going to deploy them
to Clara product again which is probably
a copy and paste from the previous
script ah yeah plus that one thing at so
we in this in this particular case
you'll see it's taking this dollar one
that's the pit so we're even though
we're looking across all pigs we're
inserting this predicate say well we
that's where I could have done in a
different way yeah I've been up here but
anyway the idea is that we're going to
track based on the pit we're going to
take that current in order to copy
answer art one here is again the MFA so
I can get into why this copy and paste
happens a lot but it really comes down
to the it's it's really difficult to
tell because erling doesn't use the sea
stack what the current function is so
what this allows me to do is set a
threadlocal that says what the current
function was so like the last last
function I'm in because I'm going to go
off somewhere else and do something so
what what function am I doing this on
behalf of so when it's like copy struct
copy struct doesn't have any concept of
Erling processes near it but it happens
a lot on behalf of an erlang process so
when this process calls a function and
then does ascend or whatever from inside
of that that would cause a copy struct
and go or in this case I actually pulled
out this thing called Alec region just
from one of my quarter million probes
and that's what we're looking for so
this is exactly the printf example yeah
in this case you'll notice that it's
actually doing a leaf region so this
probe is firing anytime something has
Alec region and across all processes on
the system but because we have this
predicate in here that's checking to see
a self current is set what's wrong
equally visors that I always have to
look up what these things are but
provider or well this one has a pig
because that's that's a user space probe
yeah this man from that users of a
provider but there could be things that
are like sis calls and so forth that
live in there
a lot of detail there in a good way good
structured way of that falling out the
other thing that Dustin I pointed this
out earlier that doesn't didn't do it
could is this actually could have been
Alex splat and then you could say cross
all anything that starts with Alec I
want to go ahead and fire that and then
you just fall into you know checking to
see if that threaten local set and
design if it's not sent and it's been
it's apparently not important because we
it was not her laying and we hadn't been
there before should all the other Alex
just go right past on all the other
processor or if I started the probe and
it was in the middle of a function I
can't know what its name was so i don't
really care about hearing allocate yeah
and so the way you would normally run
this script you'd give it an argument
which is the process that you want to
look at and you would see as a result in
this particular case allocating near and
going back really quickly just more
clear we were pretty of allocating here
and then we're going to print out what
the heck do i I didn't do quiet so so
you get junk and then the what was it a
specific princess we're so back to where
we're talking about earlier if you can
stick a printf in it and in this case we
stuck a printf in it not without not by
compiling a beam and shoving a demon or
anything like that but just by telling
the system I want to do something well
the interesting thing is i put a i put a
printf in essays own malik should clear
Alec region which is something OS 10
internal ish I don't actually know what
it is but there's my printf yeah and
it's because of that erling function
that I called we set up a whole bunch
more time okay yeah we sucked a bunch so
just to give a couple I'm gonna turn
this over to Dustin he's got a couple
other creeks yeah so there's there's
there's other non-print Fe things the
really fun thing about this one is I
didn't make it this is uh I hand it off
to one of our developers who was trying
to find some performance bottlenecks and
stuff and he built this thing and
unfortunately there's a source code in
one of these little things I can't quite
click on but you can build this is
instruments with OS
in case anyone hasn't played with it
it's it has a bunch of built-in things
you cannot read this at all but it's so
there's like basic CPU counter so you
can see cpu utilization across the top
but then you can also drop in a DTrace
provider and in particular he had one
that was looking at read and write
syscalls and another that was looking at
erling function than tracking that so
what it's showing here like it's pretty
much say anything on be able to confirm
or deny but here's like you see reads
and writes occurring at you know at the
level of the provider that was that that
came with instruments and here you see
the Erlang kid well I don't know why I
say see you don't see that but here's an
early pit and the function that is
leading to those reads and writes and
then you can see the increased volume
here and you can track that down and say
what's what's happening differently
across these sort of things so he just
kind of threw that together said hey
look what I did but that thing so it's
cool people are kind of looking at stuff
this is one of those flame graphs tells
talking about this is not erling but on
it so could be and this this is really
quite nice so this is about what you'd
expect on a profiling tool right I've
taken this this window from here to here
this this sort of time slot and then
these are stacks of functions that are
kind of coming out of that the really
fun thing about this one is it's nodejs
okay that's not the fun part the fun
part is that like you see a really clear
boundary where this line right here is
illegible it's it tells me the name of
the javascript file the line in that
file and the function name that's being
invoked before hopping into lib PNG
which hops into libs E and then you can
go back and say well clearly this thing
is is where I'm spending much of my time
and sort of track that down and just
dropping these things out is that this
is the type of thing that you know they
used to find that Colonel brought bug
and stuff and just x-axis is long time
yeah but
you together these visualizations you'd
see things like and see this little
things doing this and you go back and
look and say oh yeah look somebody's
walking a hashmap yeah so the tallest
thing that you find that's that's wide
just go fix that so well just skip right
over that ignore that so yes dtrace
everything this this is a particularly
fun one Bernie gragas is amazing
magician this is a graph that he did d
tracing joint that's all of it or though
that's that's one of their data centers
so they those big blue bubbles there are
people who need to pay them more so they
can really trace down exactly you know
everything which is awesome everyone
should trace everything all the time
except we have this problem a lot of our
customers run linux mostly the ones who
have problems and asked me to go look at
them and that this is the issue right so
oracle announced yes we have DTrace I
don't Leventhal said no no you don't if
you if you do the de tres like list of
probes thing it tells you you have 574 I
have a quarter of a million on my Mac
this is not useful like there's not
enough parts there and this is after you
by Oracle Linux who actually kind of
owned all that stuff if you're on a non
Oracle Linux you're just kind of screwed
but a problem there's their system top
right it's actually really cool it's
compatible to dtrace they actually have
a command-line tool called dtrace and it
spits out the right kinds of probe stuff
and does all the the right junk to get
your user probes into your application
so getting Erlang's probes building on a
system with system tab was actually
pretty straightforward I don't know
anyone who's made it work it's it's it's
it's horrible and it's amazing because
I've actually talked to people who care
about that sort of thing I'm like why is
this terrible why won't they fix it and
they have they have good reasons they're
basically of D Trey started with an API
and said we'll build to this I'm system
tap started with a will just give you
all the
symbols in the kernel and the kernel
developers like that's not an API you
can't you can't do that so they won't
take it and you get all these sort of
issues from there rushing through it's
like I have you know anything that's not
linux so everything's cool except of
last night I found that the current
master branch is broken if you try to
turn on the tray stuff you don't get
billed work and all that really means is
see I would be great because whoever's
doing builds is not not actually running
that code through their compilers and
someone's changed an API and now nothing
files it well of time somebody actually
faster than normal this is great you
guys must love this but but we do do
this and we we solve a lot of our
problems by not having them happen on
linux and then you know reproduce them
somewhere kind of more sane and then you
know the solution sort of flies over
Linux it would be great to you know be
amazed by dtrace and let people know so
that we can actually kind of keep it
alive everyone else Dustin's done some
work fasho spend some work this is it
all interesting to you we'd love to get
you involved in it so let us know so I
just figured one way is sent a tweet or
something the other thing is let's try
to figure out how to build maybe this DJ
stuff in ODP more regularly yeah doesn't
end up getting broken and then finally a
mo better probing things like function
and there are some things that we've
been pretty pragmatic about what we need
add yeah we added stuff we needed da
Shaw added stuff they needed actually
the bathroom there this is what my sort
of thing section he really took over the
work and really kind of pushed it
forward I did I did the thing in a
couple days that solved my problem sort
of or at least pointed out my problem
was it going to be solved that way
because people were like no I still
don't know even though you told me so he
really took that work and got it
together and got it into erling proper
we just need to get people to compile it
now and running Greg is the guy who made
a lot of those really amazing tools and
I don't fall kept me from having to
download oracle linux so that's much
more time than we have
thank you thanks buddy</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>