<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>RabbitMQ Best Practice | Webinar with CloudAMQP | Coder Coacher - Coaching Coders</title><meta content="RabbitMQ Best Practice | Webinar with CloudAMQP - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>RabbitMQ Best Practice | Webinar with CloudAMQP</b></h2><h5 class="post__date">2018-02-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HzPOQsMWrGQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello and welcome to the erlang
solutions monthly webinar my name is
Vlad I'm Alexis and I'm the VP for the
AMIA region here at erlang solutions
today's webinar represents a
continuation of a series of webinars we
have been running across topics of
interest in the world of our lang and
elixir and dealing with solutions based
on the beam in general now today
specifically we will be talking about
RabbitMQ best practice with cloud AMQP
and we will put specific accents on how
RabbitMQ systems can be designed to find
that elusive combination of performance
and availability now as with any live
event please excuse any technical issues
that we may face today but to start by
telling you a bit about erlang solutions
we are a products and services
orientated company we devote ourselves
completely to Erlang and the liquor
programming languages we work with
organisations and individuals who use
Erlang and elixir and we help them we
help the community both the language we
support people and companies working
with these technologies now we are
headquartered in London we have offices
in Stockholm Krakow Budapest and San
Francisco we work on projects that span
the globe and span industries as well
and we develop Erlang based products in
some of those you may have heard of for
example our Mongoose I am messaging
platform and wombat OEM which is our
monitoring and management technology for
Erlang and elixir systems now I'm really
pleased to say our speaker today is Carl
hawberk the CEO of AMQP and please allow
me to finish by saying you are most
welcome to ask questions throughout the
duration of the webinar you can use the
chat facility on the webinars interface
to post questions our speaker call will
answer as many questions as the time
allows at the end of the webinar
now if any questions do go unanswered
then you're welcome to raise them by
email you can use my email address which
will be posted on the final slide of
today's webinar and finally to say if
you use Twitter have a look at the
following hashtag so hashtag erlang
solutions talks
that's erlang solutions talks our team
will be tweeting quotes and highlights
live from the webinar as we progress and
you our esteemed audience are most
welcome to add to that and participate
in all of that I would now like to hand
over to Carl who will be glad to start
the webinar off thank you very much
ok so rep thank you we are well I can
start with I'm Carl Kyle Hulbert I'm the
CEO of hitter / codes one of our
services is cloud and Kewpie and it's
one of the largest or actually the
largest fleet of repped MQ servers in
the world we run a couple of thousands
rep thank you note since it's 6
different clouds I think in 60 different
data centers around the globe I started
this company six years ago and today we
are 12 employees we have headquarters in
Stockholm Sweden but we also have an
office in in in the US as well so
throughout the six years we have
gathered quite a lot of experience we
have seen a lot of of different usages
of rabbitmq things that can go wrong
things that works well well and we have
a lot of practices that we want to pass
on to two other rep time few users so
there are of course tooth I decide to
rep MQ it's the client side that the
client is
doing something wrong doing not things
not optimally and then of course we have
the server side of things we can
optimize the configuration of rabbitmq
to get more performance give higher
availability more predictable
performance etc etc depending on the use
case but I want to start we're talking
about the rep the rep dunkey versions
and Alain version says you know read MQ
is built on owling and there's been
great improvements lately in in repped
MQ and the the new three point seven
branch this house has a lot of new
features that were really excited about
before that we have wrap thank you three
six and that branch had quite a lot of
problems up to three six fourteen but
but with three six fourteen and later
the the memory performance that
clustering all that is really really
good and very very stable before that we
have three five and three five seven is
a real workhorse you still run a couple
of hundreds of service with three five
seven it's also really stable and good
version but I would suggest the
recommend that you always try to run as
a new version of RabbitMQ as possible
because a lot of things happening all
the time and work thank you and if you
have experience with say three-year-old
wrapped MQ it's a completely different
server today I would say you will have a
very different experience although I
really want to push that backward
comfortable compability is really really
good in rep thank you you can still run
a client built like eight years ago and
you can still connected or later
stripped MQ server there there's no
backwards income abilities that we've
ever
experience which is kind of rare and in
this kind of industry but but the
backward-compatible is really good but
also not not let's not forget to a line
the a line VM also has to has done a lot
of improvements lately a lot of
performance improvements clustering
improvements etc etc so we also
recommend always using the latest web
Allen version today that's 20.2 and
while you still can use a very old
client library we do recommend you to
upgrade the read the client libraries
too because the client libraries opening
up or after but they can have bugs in
them that is making you having problems
it can be that doesn't reconnect
automatically it can be these weird edge
cases that and that are it ruled out
really until the the client library has
been but a battle tested tested for a
long time so so also make sure they use
a recent client libraries as you can and
connection channels let's start with ads
and that's a common problem or something
the clients have problems with is that
either they create a lot a lot of
connections and each connection uses
first most tcp buffer space and also it
uses RAM in in the ally in repped mq
itself and then the Revd mq management
face also collects a lot of metrics for
each connection in each channel so if
you have a lot of connections then then
that can be a performance give a pretty
big performance penalty
what we typically recommend is that you
reuse connection and you reuse one
connection per process that you have and
then you use a channel for each thread
that you have in your process and you
reuse that but use please use different
connections for publishing and consuming
and the reason for that is that if you
are publishing really really fast and
the server can handle the load that
you're putting on it it will use TCP
back pressure that means that it won't
accept more TCP packages and if you're
consuming on the same channel yes are on
the same TCP connection that connection
won't recede the acknowledgments that
you are sending to the server and now
you get even worse problem because the
server can the server can't handle more
messages and you can't consume messages
because you're publishing too fast so
it's like a catch-22 problem there so we
recommend use different connections for
publishing and consuming and reuse
connections for in the process and we'll
use one channel per thread another
problem some clients have is that
they're opening and closing channeis
repeatedly and then they have problems
with latency and that is because the
Revd MQ protocol is not really optimized
for fast or opening and closing
connections the thing is that you
opening and closing a connection uses a
lot of TCP packages that have to be
communicated better back and forth it's
the first his key connection you have to
and say who you are which de hosts you
want to connect you et cetera et cetera
then you have to open a channel you have
to the server has to acknowledge it you
open that channel etc etcetera so all
this adds up to a lot of packages and if
you're using one channel and/or if you
if you are opening a new channel
publishing a message and then closing
again you're actually using up to 19
packages CCP packages if you are using
TLS and 14 if you're not if you're only
if you're reusing the same channel and
just publishing on that then each
publish will only use one tcp package if
the message fits in one CSP package that
is if it's less than 1500 bytes but
still it's a huge difference between
opening closing channels most clients
does this by default or tries to you
unless you explicitly open the closest
it but if you're using PHP for instance
this is a problem and then we have
developed proxy which you can use on the
server side that keeps the nqp
connection open and but your local
process can connect to this local proxy
and reuse the connection that way and
that will decrease your latency a lot
let's move on to cues in RabbitMQ queues
are fat here's a fast if if they're
short and that's because the messages
can then be cashed in in the in the
memory of the offer up tempo or you
might not even have to hit the disk at
all if you if you publishing and you're
consuming and at the same time and the
and the queue has zero messages in it
the the rep 10k doesn't have to write
the messages to disk at all which can
give you really really fast throughput
but if you happen to have long accuse
and you're expecting to have long
accused then we really really recommend
lazy cue mode which is a new feature in
wrapped fq3 six and it allows you to or
it it tells the server to not
to cash all these messages and you will
have much much better memory performance
if you're using LASIK use and you're
expecting long queues but in any case
you should try to limit the queue size
in one way or the other so many times
you you can set a TTL on either the
older messages in the queue or on
specific messages because messages not
are not always interesting after X
amount of hours or days etc or you can
set the max length on the queue in total
because if you do not then there can be
some follow-up errors or errors
de-escalating because repped mq keeps a
message or a queue index it stores all
the messages to disk sequentially but
you know to which queue that when the
message comes into a web thank you
bright sit down to disk but then it
keeps a queue index for each queue as a
reference in this - - the message that
where it came in and this queue Enix is
kept in memory at all time and if the
queues get really really long and we're
talking tens of millions of messages log
then the queue enix actually also gets
pretty long and with 3/5 and later the
queue index can actually be paged out to
disk before before 3-5 it was a huge
problem that you can't even page that's
this but even now the performance gets
really really bad if you have long
extremely long queues and we're talking
about tens of millions of messages and
often when this happens it's an error
like your consumer stopped and you
haven't noticed or something and then
it's often better to set in max length
it could be really long so I did - tell
me a million's or something
but it's this insurance that your server
won't go down because your CUSO too long
now this is also improved in later
versions of repped mq and i'll give will
give some more tips on how to survive or
hand a really really remote use another
problem with real long queues is that if
you're adding a node to a cluster and
you have enabled queue mirroring we're
coming to that layer later then
that's the time it takes to synchronize
these queues to than you know take
through a long time and while he was
synchronizing to another node in a
cluster all publishers and consuming is
stopped for that queue so that's a big
problem too and if the server has a lot
of messages things queue and it's being
restarted it crashed or or you just
restarting it doing an upgrade or
whatever then it will also take a long
time to start to sever because it has to
read through all these messages when it
starts so that could take a long time
and performance wise queues are single
thrilling it's in red thank you and that
means that they often have a maximum
throughput of about 50,000 messages per
second but if you if you need more
throughput to that then you have to
split up the queue into multiple queues
so that you can you utilize multiple
cores in your in your server and it's we
we don't see that very often that people
actually have to do this it's kind of
rare at least among our clients that
they use more than 15,000 message per
second but if you do then you can use
these two plugins listed here is
consistent hash exchange plug-in or the
sharding plug-in and the there are links
to them under here as well that you can
look into how to actually work but it
allows you to scale out
a queue over a virtue of our multiple
physical cues so you can utilize all the
key of course well often you have many
cues already they're doing different
things so you're already utilizing many
course other things that people do wrong
sometimes it is that there are using get
that of consume and with consumed the
server is pushing messages to the
clients and you're not pulling for
clients
I'm sorry pulling for messages and it's
much much more efficient to to be
consuming or having the server push
messages to you and also if you want
performance you have to either outer
acknowledged messages or you have to
acknowledge every X message instead of
every message well of course in some use
case or many use cases you really want
to be sure to only process one message
once and then you actually have to
acknowledge each individual message but
if you want performance then you can
cheat and only acknowledge every
thousand message or only acknowledge
every second or just ignore
acknowledging completely it's also good
to keep the number cues relatively low
and then we're talking about less than a
thousand or at least less than 10,000
over 10,000 often it comes with overhead
so the rabbitmq especially web time too
many management interface has to collect
and store stats for all these cues and
if you have tens and thousands of cues
or one hundred or thousand cues then
this come can become problematic often
when we see clients that have say a
hundred thousand cues and starting to
have problems then they have configured
the cues wrong like
they're not declaring them as how to
delete it for instance so a lot of like
temporary queues are piling up so we
haven't seen many really use cases with
that many queues another problem people
sometimes to you or have is with
persistent messages so for a message to
be persisted and survived a server
restart you have to do three things the
exchange that you're publishing to has
to be durable the queue that the message
is retrieving has to be durable and the
message itself has to be persistent and
you have you have to make sure all these
things are completed on the client and
sometimes clients forget one of these
maybe they haven't set the persistence
flag their delivery mode to flag on the
message or the queue hasn't a bit Claire
that's durable and then they're
surprised when all the messages are lost
with the server restart or or if server
crashes to something so all these three
things has to be in place but if you
want throughput and don't care about
persistent messages that the survivor
restart maybe they are not interested if
the server is down or if they're not
interesting after a few seconds or or
something like that then you have to
then decay use temporary queues then
mark the most non durable and maybe even
out to delete or exclusive make sure to
look up all these different flags you
can set on a queue because they they
help you a lot and temporary queues or
nonverbal queues are much faster than
another
or than durable queues acknowledgments
and confirms so when you're publishing a
message and you want to make sure it's
delivered at least once to decline to
the consumer you have to use publish
confirm and this is something a lot of
clients are missing these two things you
have to do if you want to publish in the
with publish confirms and publish
confirms is that the server is
acknowledging that it has received your
message often we see clients or customer
of us that are publishing messages and
then call it a day but what happens when
the published confer of the published
method returns in your client code is
often only that the message has been
submitted to your TCP outgoing or send
buffer it doesn't mean that this
messages has actually reached the server
at all so for the server but the server
can send a confirmation that it has
received a message and then you have to
enable publish confirm on the channel
that you're publishing and then you have
to wait with this acknowledgment from
the server and some clients are really
good at doing this but then they don't
try to republishing it if they do not
get the confirmation or if the
connection died during the the publish
or in other case so if you're using
publish confirm and you should then make
sure that you have logic in place also
for re publishing the message if the
publishing didn't go well
same same thing at the consumer side but
a lot of customers do this well and
they're actually acknowledging messages
when they're processed the message not
when they've received it but when
they're posted processes it and the
difference is that if you if you receive
a message and you have to do some kind
of work with this message and that
process person exception then maybe you
don't want to throw away the message you
still want to process it maybe you have
a bug in your clients or on their
consume code you but you want another
consumer to do it then you have to
reject the message or publish it into
another queue but at least you have to
acknowledge it they also very good if
your client is disconnecting while
you're processing the message for
whatever reason or your server crashes
but then you want to reprocess the
message at a later time and then you
have to enable consumer acknowledgement
and we're using consumer acknowledgment
let me enable that you have to set a
parameter on your channel that your
consumer from that is called prefetch or
quality of service and some clients if
you don't set the prefetch limit then
the server will send you messages from
the queue as fast as it can and this can
cause two problems
because all the messages that are in
flight or unacknowledged they have to
reside in the RAM of both the server and
the client and if you're having
gigabytes of messages on the server that
has to reside there it can cause an out
of out of memory exception
so make sure that you limit the prefetch
or the quality of service parameter and
the optimal one is often a lot lower
than anything but theoretically it's the
round-trip latency divided by the
message processing time +1 or rounded up
and it's optimal because then the client
doesn't have to wait for deliveries but
of course the round-trip latency can
vary etc setters
maybe want some Headroom but it's a lot
lower than you think I would say tops a
thousand or so messages but of course it
depends on how large your messages say
is or etcetera etcetera so but but it's
absolutely forbidden to not set it I
would say that's this recipe for
disaster if your client suddenly stopped
acknowledging messages for whatever
reason it got stuck on something the
other than all these messages in flight
or unlock knowledge messages will pile
up and you will have a huge problem so
yeah also make sure that you're
rejecting or or rejecting or acting the
messages at all times even if you your
code throws a message or an exception in
the while I was processing a message
make sure to acknowledge it or reject it
don't don't let them pile up otherwise
you will also wonder oh why I'm not
getting any more messages it's because
you're you have all this you have your
prefetch limit filled up already so the
server won't send you more messages it
means that your client has it hasn't
acknowledged the messages ok clustering
you can do clustering for two reasons of
course you can use it for a high
availability and or for scalability and
in rap time cube
you you can have you can join up you can
cluster those together it's using Alex
clustering functionality we don't create
clusters larger than three nodes because
you won't get very much more high
availability after three nodes at least
not in our experience and Scout bill
scalability is not that trivial would
repair rep it and queues current
clustering and never come to that later
but to enable to use clustering for high
availability that means that you have
two nodes or three nodes and if one goes
down you can still consume because all
the messages were mirrored to the other
nodes so you can continue consuming or
publishing to that node then you have to
make sure that the queues are actually
mirrored just by clustering a lot of
nodes together doesn't mean that queues
are actually mirrored and that's a
policy that he said or you can also set
it on her queue basis we enable this as
a default policy in all our multi node
clusters but we also see that some
clients create their own B host and then
forget to add this policy to it and if
the Q isn't mirrored then that queue is
not available while that node that the
queue was living on is unavailable so
make sure your queues are mirrored the
ones that you care about but don't
overdo it like only mirror the ones that
actually has to be mirrored the ones
with with turbo our persistent messages
because it has pretty big performance
impact if you're mirroring hughster
doesn't have to be nerd the second thing
you have to think about reliability is
that your client actually fails overs
and there are three different failover
methods you can either specify all the
notes in the clusters II at the client
side when the clients connect you give
the given an array of hosts they can try
to connect you so if one connection
fails it would we try the next one in
the array etc etc where another way is
to use DNS load balancing which we're
also do then you can give the client
just one single host name and that DNS
with will will resolve to the different
nodes in the cluster and then we remove
the nodes from the DNS records when it
fails and then with short TTL and the
clients try to reconnect it will get
only IP addresses for nodes that are
still available in the cluster another
way of course using a traditional load
balancer is be load balancer and now
finally in repped mq 37 we have support
for the proxy protocol which makes this
a lot easier before if you try to use a
load balancer in front of prep time
queue you would only get the client the
the load balancers IP in the connection
list right thank you so make sure also
that your clients actually tries to
reconnect if it loses the connection
which is not always not always the case
especially with the older clients and
yeah for for scalability scalability IOT
you actually have to control which node
a certain queue is created on and by
default a queue is created on the queue
or the node that you're connected to you
but you can configure this through a
special H high level P parameter as a
policy so you can control which node is
actually the master for for for
q but otherwise you it's kind of hard to
scale Q's over multiple nodes in the in
the cluster so it doesn't really make
sense to have you know a 50 node cluster
or so cuz it's it's hard to control
where the Q's actual living and where
you are actually connecting then you
have to make sure you're connecting to
the node who's actually master for that
Q in rep time q is really nice because
you can connect to any node and you can
connect consume from na q and the
clustering will transfer the messages
through your servers to you but it means
that you won't get super good
performance if you're trying to do this
on a large scale so for scalability we
recommend using Federation instead or or
just using independent clusters or
independent nodes instead or or just
doing vertical scaling that is a larger
instance a larger node with more RAM or
CPU etc etc that's often actually easier
still in Revit mq that's about to change
in in later versions of wrapped mq but
but for now create a bigger node if you
want better performance and long tried
to add nor more nodes so common mistakes
here is to not configure mayor cues and
not understanding petition petition
handling modes because rep time queue is
a bit finicky when it comes to petition
it's not complete the partition
tolerance and I think next slide will
show that and also make sure your
clients out of automatically reconnect
and yeah
so repped mq does not handle neck splits
very well it's because it's built on
airlines clustering functionality and
when Allen was designed they their
premise was to that all nodes would live
on the same network and it will never
experience that's woods but that's
please can actually happen for other
reasons then just the network is being
down between two nodes it can be if one
of the nodes are heavily overloaded if
the if the CPU or RAM is very very high
then the node won't be able to send
these pings or net takes between the
different notes and then the other nodes
will consider that node as down while
it's actually up and working but just
heavily loaded and when that happens
yeah you have to handle it in some way
and and that's where that clustering
petition strategy comes in so you can
ignore the situation you can outer
handle it but then you will loose match
it or you could lose messages and that's
better etcetera so it's really worth
reading up on the difference q petition
strategist I won't go through them here
cuz Browns have time for it another
problem that you can experience is the
the sync batch size and we normally
decrease it a lot and yeah it's it's
it's when two nodes try to synchronize a
queue then we have wrapped up here
something called a batch sync size and
that's how many matches is at a time and
will transfer to the other node and if
that size is too long if your message is
a large and there's a lot of messages
that can add up to a gigabyte of or a
substantial amount of data that has to
be synchronized and if that's not done
with aim the neck take time that can
cause the net split in itself and that's
that's real Annoying cuz then you're in
a kind of a loop because then they
thinks it's in their net split
and then the net splitter solved and
then it's right to sync again but then
it's I thinks it's a net split again
because they get the net tick again side
etc well I think rip thank you
they're actually in ripped mq4 point X
they are actually working on a new
consensus algorithm that will make this
a lot better and more pleasant to work
with okay five systems we have tested a
couple of different file systems that we
have concluded that XFS is the best one
as far as we've benchmarked I don't have
the numbers here I would try to make a
blog post about it but XFS was really
really good actually
for read thank yous type of workload
it's actually had a huge difference to
export for instance on ecq in in Amazon
we use keep it to instance drives EPS
drives or i/o one drives and that's
because for most of our clients that
workload attack it is actually i/o bound
and not sequential poor performance
bound so it's not about the megabytes
per second you can bright but how many
operations per seconds the drives can
handle and that's because of these queue
indexes that Tripp Tempe has so there
are a lot of rights to those so if you
have a lot of queues then often your eye
ups down and not sequential possible hi
hi pizza is how I perform uh selling
it's a it's a way to compile repped mq
so you get a lot better components we
typically don't enable this because this
increases the boot time a lot and we we
have seen problems with with when you
enable hype and you get some exceptions
for certain type of workloads so we
don't enable 18
general but for some customers we're
about three percent of our customers
uses hype and it can increase the
throughput substantially as you can see
20 to 80 percent difference in in
through boots so if your yai problem
throughputs give hyper try but really
try it out with your type of workload
because it can seg faulting in in rare
cases and but also keep in mind that
hype is improved for every airline
version so now in the airline 20 I think
it's a lot lot better than it was say
just a few years ago I'm sorry I don't
have more data on that but yeah it's
it's something to try out if your CPU
bound ah now some tips and tricks here
for resilience the first one is a flag
that you should set before you start rep
them cube Allen crashed on seconds if
you don't and your rep dempke crashes
due to out of memory that all that data
memory that Ellen was using will be
written down to disk and that will take
a lot of time if you have big RAM or a
lot of RAM so if you have 64 gigabytes
of RAM and you try to dump that to this
yeah it takes some time so that can be
disabled with this environment so
variable the next one we also found
makes the wrapped em qs memory usage a
lot lot more predictable and better and
it's the way how internal messages in
Rev des in in a Lang are stored if
they're stored off hip or unhip
and if we set this flag which is an
Allen flag the message will store off it
I really really recommend this flag it's
made a night and difference for a lot of
our customers that have memory problems
before especially if you're doing dead
lettering and that kind of stuff
um oh other interesting things here q
index and bad messages so Reb thank you
has to perform as an optimization it can
do it's embedding messages that are
lower than 4k it directly into you do
the Q index any last web Thank You only
bright the message one time instead of
two times but the RAM usage is way worse
if you use this option it's that the the
food is poor okay but we actually set it
down to zero so we disable this future
feature for for our clients by default
we can enable it if they have problems
with with disk i/o but most most people
do it so another common problem is the
channel max if your client is
misbehaving and opening a lot of client
channels then this you can actually
limit the channel max on the server side
so we recommend doing that
another thing we recommend or enable but
focus TCP keep alive and not relying on
nqp heartbeats because some clients
don't implements heartbeats that good
that well oh yeah but if you enable TCP
keeper lives you have to optimize it in
the on delay on the server side you have
to set down keep a lot of time a lot and
the interval of the probes we use these
settings it means that if a connection
is not active for two minutes then we
consider it that and we think
much better way to detect the dead
Pierce and keep TCP connections alive
then you say n QP heartbeats because
some clients doesn't implement heart
beats very well and they say there's
single-threaded and the working on a
message for a very long time they won't
then they won't send the heartbeats at
that time etc etc so we recommend not
relying on keep heartbeats but these
peekaboo eyes
we recommend disabling our keeping a
limited list of shippers if you're using
TLS as you know or may know if the RSA
key exchange is now not very secure
anymore or so we use this list for now
oh and if you're using a lot of we're
expecting a lot of connections you
probably want to decrease the TCP buffer
size this is a pretty extreme setting
that is in this slide here but it allows
you to have a couple of tens of
thousands or or even after a hundred
thousand connection and without it you
will probably have a lot more problems
with memory way before this if you don't
limit the TCP buffer size so summary if
you want high performance make sure you
choose a short limit your queue size and
don't enable LASIK use because you but
then of course make sure that your
queues always will be short use
transient messages it's a lot faster
than the brides doesn't have to go that
it just doesn't have to go to disk use
multiple queues and consumers because
queues are single threaded the simple
manual acts and don't use publish
confirms and this is only if you want
really good throughput performance don't
use or well you can use multiple nodes
but don't sink
or mirror the cues enable rep temp you
hype and of course the stable plugins
you're not using for high availability
also make sure your cues are shorts
because during synchronization that can
take a lot of time otherwise yeah I
naval LASIK use it's it's it's safer the
notes are not that prone to crash if
you're they would become really really
long make sure your clients failover
use persistent messages in queues and
then if you want really good are even
higher availability use Federation Q
Federation or Exchange Federation and
then you can use it over even between
clouds different data centers if one
yeah that was that was my my
presentation for a very inspiring talk
and I'm sure the audience is going to
join me in thanking you I can tell you
we know when we've heard a particularly
good talk simply by the amount of
questions we receive on this occasion I
can tell you that we already have a
number of questions we cannot possibly
hope to answer in remaining time so
you've all read directly caused a lot of
interest now to our audience thank you
for all the questions without any
further delay we'll start asking them in
the order in which they were received we
will try and answer as many commissions
as we can
the questions we cannot answer due to
lack of available time we will answer in
writing so Carl
without any further ado I'll start with
my further question so first of all one
of our audience members members are
asking are there any key configuration
items to set up when message reliability
is particularly important yeah no not in
the in not in the server not in the
server its it's on the client you have
to make
or that you're publishing with the
persistent flag and the queues is
terrible and exchange is durable and
also that you are publishing with
publish confirm enabled then if you have
done all these steps then then you are
very very safe you don't read thank you
safe out of the box in this regard
fantastic thank you for that let's move
on straight to the next question which
is coming from Jared Jared is asking if
you have a deep queue of small messages
is it better to tweak the config so that
they do not get stored in the queue
index yes yes I would say yes it's the
queue index if you have a lot of or deep
queue a lot of messages then the queue
index on the server we use up a lot of
resources a lot of RAM on the server so
if you expect a long queue then disabled
queue index embedding and enable the
LASEK you and the thing is if you're
using this if you're not disabling queue
index embedding LASEK you doesn't do
anything it's only if the queue is
actually or the message is I actually
stored on in in the indicating this in
the message store wonderful thank you
for that and again to try and honor as
many questions as we possibly can
we'll just move straight on to the next
one so andrew is asking for DNS load
balancing how do you handle partitions
how can you identify the partition node
to be able to remove it from the LVS
given the node is still up yeah we we
rely on route 53 and
and right through to 53 thus helped take
checks from a lot of different endpoints
to identify if any or none notes are not
available and then it's taken out of the
rotation but yeah that is a problem if
you have an exploit because some clients
may still be connected to that node and
still some of the health checks are
failing so yeah it's a non optimal way
and partition handling is a weak point I
would say in repped mq it's not that
trivial and especially when you then try
to join the queues again it's a problem
because when you have a minority that
has to join the majority again the
minority will be all the state on that
server will be thrown away say it
doesn't yeah it doesn't really matter
what type of load balancing solution you
use that's always gonna be a problem
and unfortunately a rep team queue
doesn't have a very good solution to
that yet but that's coming in rep thank
you for point O which has a real
consensus algorithm and we'll make sure
that excuse our our that queues are
consistent even after that's quit okay
Kyle thank you for that just like to
thank the audience once again we're
receiving about five questions in the
time it takes to respond to a single
once a lot of questions so thank you for
that I'll just move straight on to the
next question so Carl one of our
audience members is asking have you seen
any issues with network partitions where
to can't talk they see sorry I'm just
reading the question here they see that
the other two can talk to each other so
they both think they're in the they're
in the minority
did that make sense yeah yeah that's yes
and that's when you have configured the
wrong partition strategy then you have
to if you heard you shouldn't really do
a clustering of only two notes because
then this can happen
that's one if you still want to do that
then set a partition strategy mode to
ignore and do not try to use partition
what's called minority minority
partition strategy that will not work if
you only have two notes start seeing
each other only so of course yeah don't
try to do that okay Karl thank you for
that let's move right on to the next
question and the next one is coming from
Phil Phil is asking is that exodus just
for the Misha database no no it's for
the message store and that's what's
actually so yeah common misconception is
that wrapped MK uses amnesia for storing
all the messages and the queue index but
it does not it uses a like a custom file
of formats on disk for the message for
the message store and acute indexes we
put the whole of our labor at MQ on a
known disk which is using X of s so it's
for amnesia is for the message store
it's for the queue indexes for
everything
excellent thank you for that call now
again to try and answer as many
questions as we can we'll just move
straight on to the next one again all
the questions will be answered apologies
to those who will not have their
questions answered verbally you will get
a written response now says Ari is
asking you mentioned that short queues
are fast queues and he's basically
asking is there some sort of a rule of
thumb for deciding what a short queue is
for
example less than 1 million messages
less than a hundred thousand messages
what would you say to that the fastest Q
is zero and if it gets slower if if so
if the queue is has zero length and all
the messages are being published or
consumed directly then no messages has
to give to disk if the rep tempo has to
write the messages to disk then the
performance would plummet as opposed to
it is only in RAM and that happens
differently depending on how large your
messages are and how many they are but
rule of thumb I would say is when when
you have oh it's it's a hard to sell but
ok let's say a short Q is less than
thousand or 10,000 messages after that
often you get problems with with
throughput if you're relying if you so
there is only a problem if you're you
normally is short and then suddenly you
go over say 10,000 messages or a hundred
thousand messages and wrap time to start
to cat or write out all the messages to
disk this was even a bigger problem
before in early versions and now read
thank you is starting to write out the
messages pretty soon before it kept I
don't know exactly how many but X
megabytes of messages in RAM and then
suddenly if you reach over that
threshold it started to bright messages
to disk and then you're publishing rates
plummeted now you will get a better
consistent performance over a longer
queue but shorter is better
I would say a short queue is just to say
a number 10,000 messages or maybe
100,000 messages no 10,000 messages but
I also depends how large the messages
are yeah thank you for that call now
we're going to try and do the impossible
and answer for more questions in the
couple of minutes we have left straight
on to the next one
Carl are there any plugins you would
recommend that do not ship with RabbitMQ
by default yes well no no not that don't
ship with RabbitMQ there are plugins
that not enabled from starts one
interesting one is the event exchange
plug-in the advantage change plugins
allow you to see who created the queue
which connection creative queue we
deleted the queue who opened the
connection who opened the channel etc
etc this give you great insight and also
auditing capabilities and it's I think
is another underappreciated plugin by if
ships were damned prepped mq-1 there's
none of the community plug-in style like
generally recommend to everybody to
install now okay
thank you for that we have a member of
our audience roman asking well you
mentioned during your presentation at
RabbitMQ keeps a lot of statistical
information he's asking what exactly do
you use to monitor
rabbitmq clusters what we use this or
that you in general use well we or
everybody else I guess two are using the
red temple management interface you can
also use some CLI tools come online
tools called RabbitMQ CTL but you get a
lot more stats and information from the
management base that collects
and it has an HTTP API that's pretty
good
the keys you can pull all kinds of stats
their cue lenses and through thirds and
yeah everything if you can see in the
management space you can also pull or
get from the HP idea so that's what we
are using at the monitor of course we
have other things to monitor too
we're using SSH to and and running
vmstat and free etc and all the notes to
monitor CPU and the RAM and disk free
and things like that
thank you for that Karl so Roman just to
try and answer your question from my
perspective I mentioned at the start
that we develop technologies based on
Erlang get the mix here and one of them
is called wombat OAM wombat om is a
monitoring system for a lung and elixir
tech specifically modified towards
things like rabbitmq and other airline
based products it offers an extensive
insight in terms of monitoring into a
RabbitMQ system and we do offer a free
trial on one bottom so if you're
interested please get in touch and we
will give you a free free trial of one
button you can test it out in monitoring
your rabbitmq cluster now just moving on
to the next question
Matos is asking Karl what would you say
are the biggest advantages of rabbitmq
when compared to AWS sqs I would say one
there general thinks is that it's open
source it doesn't give you a locking
effect like Estes it allows you to run
wrapped MQ locally on the development
machine for instance you also kind of
sense like I at least before sqs was
only HTTP which meant that your
performance will probably pretty lousy
also before and this might have changed
in the last year or year so there was a
long time I actually looked into the
technical detail excuse
but it meant that you have to pull for
each message that you wanted to receive
you also had problems with
acknowledgments and when a message time
out and etcetera etcetera becuase web or
HTTP is a stateless protocol rabbitmq is
a is a has a stateful protocol a
multiplexed protocol and it's really
really optimized and made for sending a
transactional messages in high
throughput
with high reliability so no lock-in and
much better protocol is the two things I
would say is biggest benefits Thank You
Carl and here we come to the final
question we're already over the kind of
regular time but to quickly ask you so
Edward is asking in relation to your
previous answer for the number of Q's
recommended by you so for example
keeping it under 10000 does this apply
to non-durable exclusive auto-delete Q's
no you can't you can't have more just
have control of it and have a if you
have a properly use case for it's it's
it's normal not a problem and if you've
sized your your server for that panic
use no problem at all it's just a
problem we have seen is that client
sometimes creates a lot of cues but
they're not say out to deleted or not
cleaned up properly so all these queues
pile up and then you have a hundred
thousand two hundred thousand queues and
now you start to have RAM problems but
ten thousand queues or even more is
typically not a problem if you have a
proper use case for it but if you have
extreme amount of bacuse yes a hundred
thousand queues or or half a million
queues then I would recommend to
disabling the rates mode in the Revd mq
management phase so it doesn't collect
stats for all these queues
because then a lot of CPU resources will
actually go to that and rep them to you
and not they're actually processing
messages wonderful Thank You Carl
now I'm sure that everyone will join me
in saying a big thank you for the talk
and for an exhaustive Q&amp;amp;A session we
will answer all the other questions
we've received in writing so be sure
your question will be answered now many
thanks to all the members of the
audience who have joined us for the
webinar can I invite you to please join
us again for our next monthly webinar
and I'm particularly glad to say that we
will have Heinz Keys who is a wonderful
speaker joining us from project fifo and
he will be speaking about Andrea Corr
and how sometimes the parts can be
greater than their nominal song so we
will aim to explore react and distort
and see how much more it really is than
just a database now this webinar will
take place on Thursday the 22nd of
February at 5:00 p.m. GMT and just to
say that following today we will send
you a very short survey to make sure
that we capture your feedback of today's
webinar please also note that the
recording of the webinar and the
presentation that were shared will be
available for you to collect on our
corporate website which is a line -
solutions comm so www dot a line -
solutions comm thank you once again
everyone and we look forward to seeing
you at our next webinar thank you very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>