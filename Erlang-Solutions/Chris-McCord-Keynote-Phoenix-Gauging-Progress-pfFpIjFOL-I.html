<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Chris McCord | Keynote: Phoenix - Gauging Progress | Coder Coacher - Coaching Coders</title><meta content="Chris McCord | Keynote: Phoenix - Gauging Progress - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Chris McCord | Keynote: Phoenix - Gauging Progress</b></h2><h5 class="post__date">2017-06-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pfFpIjFOL-I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right we're talking about Phoenix
obviously I'm going to talk about
gauging progress where the framework
started and where it's headed and before
I get in too deep into where it's headed
I want to talk about Phoenix 1.3 it's
just a little bit I know you've watched
my last couple talks that you're
probably tired of hearing about the web
directory moving two levels in on the on
your editor hierarchy so I'm going to
touch on some of the confusion a little
bit around some of the new ideas and
what we can learn from that but before I
get started I got to plug Dockyard
dockyards pays me to spend a
seventy-five percent of my time on open
source development okay so this mic
needs to be closed I'll just look
straight down open all right is that
better all right so I have a problem of
like looking down during my talks and
like I'm supposed to I tried to like
focus rehearsing like looking at the
crowd and now you're training me to to
abandon those efforts but okay someone
holler out if it's if it's hard to hear
but doc yeah yeah dr. I pays me to spend
the majority of my time on open source
development but we are available for
contracting now we do licks or
development we have a team of elixir
developers so if you're interested in
our help please get in contact but let's
talk a little bit about Phoenix 1.3 and
I promise it will be a review of my
previous talks if you haven't seen the
previous talks we move the web directory
and we have now we have new generators
actually it was a bit of work to get
this in place but we don't have any big
new features found with one three it was
really about a new directory structure
in new code generators for people on
getting into the framework and starting
to build a real applications but we
found out a few things not us personally
but I think the community at large
we've learned that programming is kind
of hard actually
and thinking about programming and
thinking is actually harder than not
thinking so I think that we we put a
little bit of
sure back on newcomers and developers in
general to actually think a little bit
about the design of their application
and this has caused some people to like
like physical pain I think about like
they kind of get stalled and like oh my
gosh this is so hard but it turns out
it's not so hard it's just you have to
design with intent and we've seen mostly
good reaction so I think I've been
really encouraged by the discussion and
the positive reaction to r-13 changes by
and large it's been great from both
experts in the community who have
complained about us not pushing
newcomers in a better direction for
maintainable applications but both it
from newcomers as well because if this
is a big balance of strife where we want
to you know have a great out-of-the-box
experience for people that have been in
the community since its inception as
well as people that maybe it's the first
week trying elixir out and they're going
to try something up at Phoenix tap to
build something real so we've had some
good feedback like this user said that
it as a junior developer they're really
thankful for the new changes that were
consciously like pushing them towards
better design and kind of helping you
know gently guide them in the way that
we thinks going to lead to to a better
solution but it hasn't been all positive
oh this is another person that said it
had the best time to be writing in
Phoenix 1.3 so it's like I was like
rollercoaster like you read through like
the route you know you announced the
release candidate and everyone's like
yeah this is the best but then you hop
on YouTube comments and you're like oh
so if you go to youtube just just go for
the comments that's why I go just like
Acker news I visit just for the comments
so we had this is like my lone Starr key
note came out about Phoenix 1.3 and this
was like the first comment on the video
and I normally don't engage like really
negative youtubers because that's not
really a positive improvement to my life
but this was like the only comment on my
video and had like a couple felt like it
was getting thousands of views so I was
like I didn't want this to like devolve
into you know people thinking this
person was right so I decided to engage
with them I don't they may be here I
don't know they are here
but so yeah this person you know it's
just you know it's a thought the idea is
totally won over their head and they
said that this is like we removed we
removed the only magic thing which is a
root level web directory and they said
oh this is just another case of magic
folders forcing you in a specific
directory structure so tragic Rails
never dies and like I don't know this is
just I don't know if this comment
doesn't make any sense so anyway I was
like I've got to respond to this and I
think I was talking with Josie and I was
like I'm I responded to this guy on the
internet but on look at the bottom like
I actually won an argument on a youtube
comment on the Internet
he apologized and said I was right yes
so now the key thing is like it's good
to take negative feedback not not all
people are worth engaging with but I do
think discussion is around programming
everyone has their different tribes and
get intense but it's better to like you
know be respectful and like try to
educate people which is what I did here
and this guy actually appears to have
change his mind which is which is great
but from the most part the negative
feedback hasn't been like this toxic you
know ignorant comments it's been more
like I feel more difficult to work with
in x13 compared to one too in fact some
person said they they were no longer
going to be able to develop our youth
Phoenix because of the 1-3 changes that
they were going to use I think PHP or
Java instead which is funny because like
literally it's just the generators a
suggestion of like a directory structure
change like there's no API engine or
anything so like you can do whatever you
want but but for the most part the the
constructive the people that want that
actually want to provide a positive
feedback say that it just feels more
difficult and you know furthermore you
know someone said that it's just context
with smooth ideas just playing that idea
and it's interesting because
you know there's two sides where people
are like yes this makes total sense
and then people hear about this in like
this individual thought that you know
Phoenix is just a web layer why is it
trying to have influence what my
application looks like but it's funny
because like Phoenix 1.3 was made
exactly to accomplish that goal like up
to enforce that Enix is just the web
layer so I think that there's just some
confusion around these changes and I
don't know that it was avoidable
necessarily I think for by and large
it's been positive and resonated with
people but I think there are some
misconceptions that we can that we can
fix one is just to reiterate we've said
this from the beginning but our
generators and Phoenix are just learning
tools like this isn't like us
prescribing of like this is the way that
you have to write your code this is us
saying someone new coming into the
framework this is a way to gently guide
them into what we think is it'll lead to
a more maintainable application so so
for people to come in and they see us
generating a module with certain
functions they think that this is like
an anyway the only way they can write
their electric code within a Phoenix
project it's just not true these are the
starting point of your application not
the that's the end of your design so I
think that's another problem where
people see this module is generated and
they suddenly think they can never want
to create a new module so a common theme
is some people are concerned with this
context idea that it's just like dumping
ground for functions that they're going
to have thousands of lines of code in a
module but we'll walk through I guess
we'll we can guide people to you know
away from that here now because really
this idea of context some people will
have asked like why did you name this a
thing like why not just say hey it's a
module and you write functions because
that's the way we describe it like
anytime someone says you're you
introducing this this new idea and
pushing it on the community I always
fire back with like literally we're
asking people to write modules and make
them well named and put will name
functions inside them and then maybe
think a little bit about the
relationships between these modules but
the reason we decided to call them or
give this thing a name is because if we
just told people hey the best way to
write an application is to write
and functions while that's true we
wouldn't have improved anywhere from
what we had with web models right we
would ended up with people just writing
a module putting some functions in it
and anytime they had a new feature they
were you know create a new module write
some more functions that's not bad but
now they have implicit relationships
across your application they're not
thinking about the boundaries in their
system necessarily so I think there is
an idea here whether we want to name it
or not about thinking about the
boundaries of your system whether that's
across your across separate applications
or within your application the more we
can think about boundaries the more
minimal code we're going to have in the
long term so it's not just a matter of
death module rights and functions it's a
matter of actually thinking about the
boundaries of your domain and this is
kind of a hard thing to do and what's
even harder is some people hear us say
write modules and functions think about
boundaries and one thing we emphasize is
that if you have this boundary in your
system that the boundaries talk to each
other through a common public API and
that you shouldn't reach into some
nested module in this content so people
hear that and that's when they think
okay I'm going to have a thousand Lyon
module but I think again this is like
just like if you're coming from
an OLE and like when you read like a
suggestion like don't you know don't
write 100 line don't have a class over a
hundred lines and then people like take
that too extreme right where they just
like they hear a suggestion and now
there's just like this golden rule that
you follow you know that's not what
we're pushing it's just we're giving you
a starting point and suggestions to
think about designing maintainable
applications and that's it so if you it
doesn't mean you're never going to call
into a module to levels do than call a
function as a public interface
it just means think about reaching in
across the boundary and maybe if you
were able to encapsulate that instead of
having callers reach in maybe you'll
lead to a better design so here's just a
basic example of that so this is just
lifted out of a project I was working on
there's a notification system that is
going to subscribe to platform events
across this entire product whether
that's Alex replication Ruby application
whatever other platform is people are
subscribing to know
and they also want to be able to send
emails from this boundary so I have a
notifications module that I expose a
public interface of hey any caller in
the system could say they want to
subscribe to platform events whether
that's like a user being created someone
just registering that you're going to
get the event and they can filter based
on message passing or if they want to
send email in system they can call
function right this is very basic but
the question comes up then about this
whole Nessen module thing is you know
why that at the top why another patient
subscribe notifications send email why
don't I just call this nested module
directly and the answer is like one is
better to encapsulate these things that
first of all we're using Amazon sqs for
this platform but the colors don't care
right they're just good good message
that said hey the chooser was created so
it's better from a design standpoint to
have this boundary here saying I just
want to get a message when something
happens in the platform right if we
abandon sqs later because we rewrote all
of our Ruby code now we have to go find
everywhere in the application that
happened to know it was calling into sqs
you know just this with me much better
code to put this at the boundary and the
same with sending an email I could
configure an email client in different
environments and just have an email sent
like from the caller's point of view
they just want to accomplish something
right they don't really care that
they're going this is going to rest on
TP or going over mailgun or any other
service so having said that that doesn't
mean that you will never ever call a
module dot some other module right like
if part of your requirements are like
hey I just want to soon an SMTP email
like that's what I need to do that's
what my caller wants to do then you
publicly module dock your SMTP module
and in collars call it right so we are
giving suggestions to people to think
about designing applications but they
should be thinking about it the same way
they design any recollection or
structure right just like we have mixed
like you know mix has a mixed task
module so it's not that like mix has to
just expose every public function at the
root level but we want to think about
the boundaries and peek when it makes
sense to expose the public api's that we
do sometimes it does but oftentimes it's
a better
gaba collars not care they just want to
accomplish a task in the system they
don't care that it's going over a sq sq
right so again we are giving suggestions
or people to think about we're not
prescribing you to adopt some holy grail
of you know 100 lines per class for our
and it's perfunctory
what we think is gonna lead to a proper
design in the way to think about
designing the application so that's one
point three it should have been out by
now but it would be out real soon
no I said so I have to finish the
Phoenix guide so it's blocked on me
personally as well as the a Phoenix
channel protocol there's going to be a
second version of it that shouldn't
affect anyone up in userland but there's
a there's a race condition discovered
that I think is rarely run into but the
only way to fix it was to make a second
version of the protocol I have it fixed
on the server and now I just have to
write I have to rewrite the JavaScript
client so once I get that out and the
Phoenix guys rewritten we can get one
three final so that's what I wanna talk
about what stinks 1.3 now I want to talk
about kind of history of where the
framework was the goals that we had as
we built each release and kind of where
we're going where we see the framework
growing in the future so if we walk
through the releases like phoenix 1.0
you know we had this category and
productive reliable fast it's still our
tagline if someone saw the there's a new
crystal web framework that has a tagline
that's remarkably similar I forget the
words but it's like I don't know it's
like fast productive reliable it's
remarkably similar but anyway we we
wanted to pitch this idea that that we
can give users a you know no compromise
on speeding attainability that we could
provide kind of this perfect mix of
qualities that people weren't getting
out of existing solutions usually it was
kind of one of the other and we were
also advertising that we had microsecond
response times which is a big deal and
so the goal with this was when we first
started out was like that we were trying
to get me it's like you you all here you
the
- bet your job your own personal company
or your free time on the framework right
like early on in the evolution of elixir
like I was in IRC and weekly I would
just watch like to see if the IRC active
users like in the afternoon were like
growing and it was like yeah we got like
10 more here than last week so like our
goal earlier on right was like just
convincing people to get involved to
check this out and trying to convince
them that we had some qualities that
could give them big success and this
continued so with Phoenix 1.1 we had two
million channel connections so we were
able to get some really amazing
performance optimizations some books
started coming out so this is some
really exciting times for us and we kind
of we're living up to the hype of hey we
have this amazing game we're running on
we can give you the productivity without
sacrificing performance to know by the
way here we can prove it so this was
really exciting and but again this was
like you know we wrote blog posts we
made the front page in hacker news and
our goal is still convincing you the
developer like hey you need to bet your
job and your free time like you have a
few hours a week and you know that we
can scale to millions of connections per
server like this is going to get you
interested at least checking it out and
this is what's going to say that we
weren't interested in you know getting
this in the production that companies
our goal is to get developers interested
and then have them sneaking in you know
the back door or have been go to their
CTO or their boss and say hey we have to
use this and in Phoenix 1.2 we still
like took a deep dive into like
leveraging that platform right like we
were melting people's minds like
distributed applications we were playing
cutting-edge GS research so it was
really exciting like we were for me
personally was excited because we were
able to kind of showcase through the
world what the beam in that liquor could
do so this was awesome from a personal
achievement I think from a like a
technological achievement it was a neat
way to to use like key Rd T's and PS
research in a practical way but the the
theme was we were still like telling you
the developer like hey we were applying
these amazing things to and utilizing
this VM on
so we've Connor on this trajectory of
like how
you know how much secret like beam soft
and we rel long to the framework to get
some some cool features out of it but
then we started to make a little bit of
a more it's a practical route here like
so we melt the people's minds with CRT
T's and in like Linux 1.3 we're like hey
the web directory moved like design
think about your design it's good and
most people have been like yeah that's
like this this is that sounds cool so
we've been focusing a little bit more on
like okay like we went and develop some
some really interesting innovation but
how can we improve developers day to day
life about just writing software right
like programming is hard so whether or
not you can leverage CRT T's doesn't
help you if your application is a
disaster in a year right we want people
to look at their application five years
from now ten years from now and be able
to say like okay I can actually I can
actually reasonably systems bill so
we're still focusing on you though right
we're telling you we can relieve your
pain right if you if you think about
your design a little bit a few years
from now you're actually going to still
enjoy your application you're not going
to try to rewrite it for you know
crystal that's still our tagline so so
this is a good thing but it's a little
bit less of signing the CRT T's so this
is where Phoenix 144 comes in because we
want to focus on monitoring and metrics
so this is going to be like production
level robust insights into your running
application and if you're using the web
has includes things like health checks
something that's pretty much every one
needs like every client that we have a
Dockyard and plataforma tech like the
first question is hey how do i monitor
this how do I get metrics out of it and
it's doable and you know we can point
people towards like hey read this blog
post okay this person publish the blog
post like you can kind of stack these
tools together throw X ometer in but use
the elixir wrapper and it's so it's like
attain wavy right so I think we can do a
much better job but most critically what
we realize is that our goals have
shifted a little bit it's shifted to say
like okay like we're actually trying to
convince your boss in your stakeholder
that they need to bet the product on on
the framework in the platform and this
is actually a pretty significant
in a pretty significant milestone for us
because our marketing has always been
about like how do we just get people
interested and now it's like we got
developers interested like I think
anyone they may not be using elixir
using Phoenix but they always I would
say we're still pretty small but they're
at least aware of our existence in our
technical prowess so now we want your
CTO or your boss to come to you and say
hey I heard about this thing that can
save us money and they've got all these
things that provide great business value
like monitoring your metrics like all
these things that we can take advantage
of so we want to target more of a
production level feature set to solve
something that pretty much everyone
needs anyway in the ecosystem
and I made this like terrible draft but
but this is what I do like just like my
last talk with like the Phoenix in the
umbrella like when I'm procrastinating
it's like oh I got to make this thing
it's taken so much time but I got to do
it I don't know and I feel accomplished
but I wanted I wanted a way to show like
you know it's not that we're going to
stop working on innovative features in
the platform it's that you know with the
100 release it was just a matter of like
you know we were just trying to get
mindshare developers right
we can't just we can't launch a product
and target stakeholders unless we're
like you know an enterprise but for us
it's like we have to get developers
involved from the beginning and we did
that by you know touting the benefits of
the platform and then we did it by
showing that we're off scale right and
things started to get you know uptick
like you know people were getting
excited because first it was skinny
queneau they were like wow orlÃ©ans
amazing and here's a framework built on
a look sure that runs on our longing
that claims it's going to be Ross scale
but with 1.1 it was like okay millions
of connections per server so developers
were getting more and more interested
and then we were like CRT t distributed
application so we were like at like peak
hype and mine share of like we're doing
amazing things on the platform and with
phoenix 1.3 it was like there's a new
directory structure so so it's not that
our might like this not this is a bad
thing and not that our mindshare is
dropping right it's just not that we're
we're not like keeping the highest
robust Wow new innovation new features
but what we think we can do and focus on
is like ok it's not that we have to like
blow everyone's mind every three months
but we can say hey now we have metrics
we can actually provide these really
interesting business values and I think
that stakeholder interest in mind share
is now going to increase right so I
think it's kind of like the sinusoidal
process of like notice how the end of
this graph we get back into a hype cycle
so I think there's still some really
interesting things we can do especially
around service discovery distributed
programming that I've talked about in
Prior talks so it's not that like it's
boring futures from here on out but it's
that we can take this cycle of how can
we leverage the platform to do things
that really no one can do or no one is
doing but then we need to also leverage
like how do we solve the practical
problems and provide business value to
day-to-day users right so I think
there's a good balance here where we can
kind of go back and forth and then we
can trim towards world domination so
that's the goal so let's talk a little
bit about the plans and again these are
super early like very very early I've
been trying to focus skinning tanks 1.3
out but we've been thinking about these
problems for quite a while so the API is
that I show here and the examples are
prototypes we're still in a research
phase but I do have a demo that of
something at least a working prototype
here but the question is like you know
what is the current landscape look like
for monitoring and metrics and it's like
we have all these software or service
solutions they're often called like a
PM's application and performance
monitors and a lot of them are
announcing a look search support which
is great because these companies that
are out there making money are like wow
we see a big uptake in adoption of this
platform and we think that we're going
to have a competitive advantage by
getting involved in a lick cert which is
great but the side effect is what we're
seeing is everyone is reimplemented
their own data collection and
are often doing it really poorly like a
lot of them have their own agents
running but they're calling them agents
like a a collection agent a lot of them
are going to be implemented as ports
because they wrote them and see so they
can use them across all platforms and
everyone's doing the same data
collection in different ways and often
poorly or they are just collecting like
web metrics and they're ignoring the
wealth of information that the virtual
machine adds for them so the treating
the VM is just like this dumb web
language if they want an instrument
Phoenix when really there's a wealth of
information that people can act upon
that no one's collecting so we want to
be able to provide some common interface
for data collection and reporting you
that you can still report to all these
services these services provide really
great value but we want we want to solve
the hard problems for them so that way
you can just wire these up easily so
this is like the preliminary plan and
first of all I should note that this is
going to be like a standalone library
and highly decoupled from Phoenix so we
want the goal is to have this be like
the V library that you know the elixir
projects use if they want to have
instrumentation and this is good to be
extracted from and generalized from the
instrumentation work that we have in
Enochs now people may not be aware that
we actually do have endpoint
instrumentation as of like Phoenix 1.1
that's there and Elijah tins instrument
Corbin's as the framework is is making
requests and it's actually really neat
we're gonna talk about how it works but
we want to generalize that because
there's no reason that you should have
to have that coupled to the framework
right this should be a boring little of
a library that EXO Phoenix any library
in the ecosystem can leverage and then
people that care about intermediate can
hook into it and one thing we want to do
is have robust VM level information
again I think there's a wealth of
information there that people either
aren't collecting don't know exists or
don't know they know exists they don't
know what it means so I think we go to a
great job by surfacing this information
actually saying like hey we think you
know this you know you have 2000 s
tables like that's kind of weird maybe
you should look at that like there are
some things that we can look at system
limit wise in the VM and highlight and
say what may be going on
in the next place to look and again we
want to be have extensible reporting to
third-party services like we don't want
to replace data dog or New Relic we want
to allow you to collect data and report
to them but in the most efficient way
possible but if we think about like you
know what are the essential things that
a monitoring metric instrumentation
system needs is like one is it it must
not take out the application under load
like in an effort to do performance
analysis like it shouldn't actually take
the application out and I've seen that
firsthand like I'm not I'm not going to
name the library but this is the problem
with some of the elixir agents that get
added for a service where they'll be
like Oh Jim server is concurrent to me
so I think just do a cast for every web
request to this single process and I can
get really awesome
performance modern so I've actually seen
this I was doing some performance flow
testing for a client and I hit the
application with some load and like the
application completely died and it was
like whoa that's some things going on
there and there was code very much like
this and the problem is like in an
effort to enact an effort for them to
monitor their performance they reduce
their application to you know a single
thread and proxied everything through a
single single gem server so this is the
problem and these are the kinds of
things that we're seeing with people
integrating these third-party services
so our goal is to take care of a data
collection for you you say what data you
want to collect we'll collect that the
most efficient way we can and then you
can report it to these services and then
the second part is I I really want to
see the being treated as a novel
platform it is again we want a surface
critical VM information like the elixir
is way more than just the web web
metrics are extremely important right
like what requests are being tied up
whether our slowest request what's
hitting the database the most like
that's important we have to collect that
but then we also want the wealth of
information that we have on the Erlang
like how many processes do we have in
the system our new process is growing
with undoubted memory growth like there
any processes doing the process appear
to be how to um down a message key these
are things that are so helpful when
you're trying to do performance analysis
but almost none of these services
collect or care about and we also think
data collection must be trivial to
define right it should just just
just write a function should be the
answer right there shouldn't be some
advanced thing that you have to do to
hook into the system it should just be
if you care about a specific metric in
your domain that we don't know about
like we you know we know that you
probably want to track CPU or memory
usage the VM stats we can provide helps
for you know helpful functions for that
but if you want to see what the active
user count is for the last hour like
that's something that you need to write
and we should make that super easy and
then again we have all these third-party
solutions it should be super easy to
interface with them like we want to
reinvent the wheel for everything we
want to be able to have everyone stop
dreaming in the wheel and share some
common core API and then do what they're
good at and that's having you're
charging you for money and providing
value and then lastly like my personal
goal is like that we need to make
metrics easily accessible and actionable
for non-experts and Daniel visualization
talked yesterday made some really great
points around this and I think that
again we have this wealth of information
and I have gone on site with clients
that they have a team of you know
several ixr developers they're getting a
ton of value out of the platform and
they don't know when the next table is
and that's not their fault that's not a
problem they're actually like they're
seeing great great performance great
business value but they're having
problems and if we could just service
this information right like there's no
reason like it'd be trivial is to write
a function to say like hey given this
process if there's 10,000 messages in
its inbox maybe we could tell the user
on a webpage like hey you should
probably look at this process it looks
like it hasn't got a message queue like
there are obvious things that we can
surface and give actual insights for
that I think would be immensely helpful
to people so if you're not familiar with
monitoring and metrics it's just pretty
basic as far as like the kinds of
instrumentation you want so if you want
to have like a gauge metric it's just an
interesting instantaneous measurement of
a value like what's the CPU usage and if
you notice like a gauge here do you see
the really really awesome title of the
talk gauging progress that was easily a
day of work so
I made that one the frontpage slide I
was like alright I'm done for the day
but no so a gauge is just like an
instantaneous value it's the easiest
thing for us to collect because we just
call a function and whatever it reports
is the value and then we have meters and
timers which are more complicated just
to do in a performant way and this is
what we see people doing incorrectly
where they want to do like requests per
second like give me their rates of
events that something happens over time
you want to make sure that you do this
in a efficient way because if you have
10,000 requests a second coming through
the app you can't just call a single gem
server and say hey calculate this and
then often people want like a physical
distribution over that like I just I
wanted to the requests per second but I
also want to know like what are my
automatic percentile response times and
then the last part of this is in
instrumentation where we want to have
compiled time hooks into application
events so if XO is doing queries it'd be
nice if we gain just a spec they like
hey anytime you do a query please tell
me how long they took that way I can
report it to data dog or New Relic
and that is what we want to include in
this library so this is a canary API
that I put together and this is kind of
things we're thinking about like I've
named this project metrics but it's
actually a knurling OTP app so I have to
find him to come up with a new name X
metrics
that's what Jose Jose suggested so we're
not sure we're going to name it but the
goal is like this isn't going to be some
like a third framework right this is
something that ultimately is going to
enable some neat features up in the
Webley and in Phoenix which I'll show
you but low level this is something that
we want output we want
packages an ecosystem to rely on and
it's just going to be like a boring
package right whether it's named metrics
or metrics IX I'm not sure but the goal
is you just write functions that provide
that collect data and it's checked out
of the system so in this example let's
say like I want to have a gauge for like
what's my CPU usage in the system like I
can just set up a supervision tree with
this gauge function that just builds a
worker that says hey every one second
I'm going to call this function and you
should report a value to me and then you
write a function and you can hook into
Earling CPUs up to pull out the CPU
usage and this is the way you can sample
any data you want and collect it in an
efficient way
especially when we
two meters right I'm sorry one more
example let's say that you want to
calculate something that is specific to
your domain well then you can just set
up a gauge for like active users say
every five minutes I'd like to know like
how many users are on system and this is
going to pin on your app like if you
have a channel application like maybe
the number of sockets that have been
connected but if you have a rest API or
some person logging in with a form like
it's good to depend on your app so I can
just write a function that I said hey
echo give me the users whose last
request is in the last five minutes then
return that value so you can surface any
kind of data you want by writing a
function and that's the whole goal like
we want to empower you to collect the
data that's important to your platform
and likewise for meters if I want to say
like hey I want to track requests per
second I can set up a meter and say hey
every second I want to get a rate of
this value on being marked and I can
hook into Phoenix instrumentation today
so like this works the way Phoenix
interpretation works is there's a
callback that happens when we start to
call some instrument instrumented code
and then we stop the instrumentation
gives you how long it took so you can
hook into that today and say hey any
time Phoenix had a request come through
I'm just going to mark the request meter
with the time difference and that way
it's going to track the requests it's
going to use its counter internally it's
not going to try to do this and the most
efficient way possible that way I'm not
worried about hey I want requests for
sucking I actually have to have my
throughput right this is going to be
something that's very very fast and I
want to talk a little bit about like you
know metrics is such an overloaded term
and then the things like on the left are
the things that like all these solutions
and on the web today New Relic
a dog like they're good at like hey if
you just spam like a UDP port or you
have a T agent running we can give you
requests per second we can do
statistical distribution we can tell you
hey here's how long this plug took in
your controller and if you want to refer
active users to them they have a pH can
you do that but what I'm interested in
is more via mobile metrics is like we
want to provide system limit information
or make it easy to get this out of the
system right like if you can graph the
atoms over time
and or say like hey this Adam table
table looks like you have a memory leak
like that'd be something extremely
beneficial to the user or you can say
hey you relative up against the process
utilization limit like so maybe your
system limiting to be up there maybe you
have a leak somewhere like this is
something that we should be able to
detect in report to the user so now
we're gonna talk about an opponent
instrument which we want to extract and
generalize and kind of use this as a
base to make this library and I think as
Andreia here I'll put them that can make
a cameo areas in the back so Andre
actually wrote the Phoenix in point
instrumentation and did a really really
great job and it's actually some some
fun code to revisit because we were able
to leverage elixirs metaprogramming
quite a bit so let's say you want to
instrument this piece of code here you
wouldn't do this because it would be
almost almost instant right like I don't
I don't know if anyone's ever had a slow
render time if you have please let me
know but let's just say for simplicity
like I want to know how long it takes to
render my templates that way I can brag
to all my friends that my render times
are like microseconds all the way you
can do that to day is you can just say
in your controller like instrument
render you give it some name so this is
the render time and then you provide
some kind of runtime metadata like hey
here is a view or here is the template
I'm rendering and then you just wrap
that in a function so very trivially to
wrap a piece of code and instrument it
not that impressive but the cool thing
is what we're doing under the hood to
make this efficient for people that care
about incrementing this it's just going
to be a callback knowledge that we saw
earlier where they get like whatever the
name of the event was they define it
start and stop event match for it and
then they get that runtime data so they
can say oh you're rendering this
template and then I'm just going to log
like hey this simple it took so long to
render like anyone that cares about this
or any module that cares any number of
them can hook into this event now so the
goal is like if X I wanted to say hey I
want people that care about the repo
query instrumentation any number of them
but again into that event and then have
this callback run and this is what
connects is doing today so this is from
the Phoenix controller pipeline every
time and controllers in boats we hook
into instrumentation and say hey we're
going to
minguk's controller call events and then
we run that code and then someone cares
about instrumenting this like I can
write my own module like I want to just
make a demo vlogger I can hook into that
instrumentation and then I guess the dis
of how long the controller functions
took and I can log it so this is all
there today and this is actually how the
Phoenix logger works today and anyone
here that has a think that's been put
into this so we want to take this idea
and generalize it to me so that any
library can use it and one thing we're
making taking advantage of is some
pretty interesting compile time injected
code which josÃ©e fortunately crushed my
dreams earlier today that we're going to
have to change this a little bit so we
can still take advantage of compile time
information but to generalize this
across basically any library we'll
probably have to turn some of this work
into run time but the way this works is
anytime you call instrument in your app
let's say that you have no
instrumentation module that cares about
the my event or the render event
you're not going to incur any cost like
we're basically going to compile that as
a direct function call so it's almost
like the the logger calls and elixir
were able to intelligently at compile
time say is any instrument or module
actually care about the specific event
the fact that we're saying that we can
instrument it doesn't mean that we're
incurring a cost if no one cares about
it likewise if we have tenure mirrors in
our system we don't have to call all of
them to say hey please instrument this
if you care about it we actually only
bacon-like literally these lines of code
we don't even do a map it's just like
the first one is the result zero the
second one is going to be result one we
run the code and then call you those
again at the bottom with the result and
we return the final value so we're doing
some really interesting compile time
work to make instrumentation as cheap as
possible because the goal is like in an
effort to do performance analysis on
your code like the worst thing that we
can do is actually really hurt your
performance because when people are just
going to like be like well I hope it's
fast but I don't want to measure because
in production is getting a file it was
like we're going to do the hard work for
you so you can get insights into these
things and actually act on them so now I
have a demo and again this is like a
couple days of
of channels work so this UI is not what
I am going to ship but the goal is that
anyone that cares about metrics in their
system is going to add their supervision
tree so this is the actual running app
let's say I have this metrics demo
application this is the code I showed
you what say I care about tracking
memory CPU and processes and requests
per second like it's literally very
similar why I showed you on the slide
I'm hooking into Phoenix instrumentation
to do request for a second so let's see
how this works let's a scope and running
the channel code on a client is going to
pick up like it's just it's hooking into
the instrumentation as a reporter and
saying hey please tell me everything
about gauges and met and meters that you
have and it's just going to display them
so anything that we care about would
just pop up here and I'm going to hit
this app with some load and we should be
able to see in real time like the
requests per second for this node and
the goal is that when we're done with
this that you can fire up an web in
point and you can see all nodes in the
cluster what the request per second are
how each of their health is doing in
real time without taking out the system
which is important so if I throw some
load at this we can see we're at about
5500 requests per second and this is
just reporting in real time using that's
behind the scenes to count using Phoenix
instrumentation you can see it maxed at
about 5,300 and then workers reporting
about 5,200 so accurate and pretty fun
to watch and the cool thing is if we
turn off instrumentation there's like a
very negligible impact maybe a couple of
percent to to med to monitor request for
a second so every request you know six
thousand per second is running through
that instrumentation block marking that
meter and it almost has you know no call
which is pretty fun and then they're
like we can get more information or like
system limit level events like the
number of processes in the system versus
the maximum that we have configured for
being like let's say you know we want to
go through like a couple hundred
thousand processes here and respond them
we can see what happens to our system
woman's so let's say I'm going to spawn
a process and then I'll have it just
randomly sleep for
let's see up to 20 seconds what is it
random uniform and this works it'd be a
miracle someone saw that immediately and
then they were just waiting for the play
ultimate fail okay so the cool thing
here is like you know in real time
people can start seeing like whoa
something's happening to my system
either I'm exhausting resources or I
have something that needs that something
take a look and then as these things are
dying we're just to report those being
stats right and this is like trivial to
surface like this the beam exposes like
all this it's kind of like when you
first discover at tables and you're like
this is just here like it's kind of like
the API is kind of weird surface like to
use but it's all here like they just
call function this was kind of like what
happens when you get into these like I
can just ask the ruling for like give me
the system limo give me the system info
for the process count process climate
right like these are things that we can
hook into and just show the user this is
what I want to do like this isn't going
to replace your your metrics from you
relic or using info Stevie in grief onna
this isn't going to replace that but the
goal is to have you at least be able to
have actionable insights out-of-the-box
in the framework with no third party
dependencies and then we can do more
intelligent things like hey like here's
the top 10 processes by message queue
you know we can develop heuristics like
hey if there's 10,000 messages in the
inbox like there's probably a problem
here and we could tell people maybe
where to look or at least them to a
guide on bullying so there's all kinds
of things I'm interested in is you know
we can get these metrics out of observer
and it's been really important to have
our metrics collection be you know
production levels so we can have these
advanced services to be able to collect
and report them for you but we also want
to give users actionable insight into
what's happening in the system in real
time and then you can provide any kind
of logic on top of it that you want by
writing a function it's about to go like
I said this is early on
I won't have to have something pushed
soon but the goal is eventually we'll
have a metrics project that's build on
top of this metrics library that lets
you do something like this so the final
goal is like I said standalone libraries
that anyone can use and then a Hynix
metrics project that's going to use
channels that anyone that has the
current Phoenix app you can just add a
dependency and say hey I'm going to
forward slash metrics to Phoenix metrics
and oh by the way here's some sources to
pull pull data from and then you can
visit slash metrics and then I college
the wealth of information and insight
into your system so that's the goal and
I think we can accomplish it and it's
neat that like we can leverage Phoenix
to give you a new interface in insights
into this data but internally we can use
a library that everyone can take
advantage of outside the context of
Phoenix entirely so laundry metrics not
coming soon but coming next first I have
to show Phoenix 1:3 like I said the only
thing I have left to do is to finish the
channel protocol which is just
JavaScript and the inks guides which is
good to take a bit more work but we
should get that out I don't know I've
been saying by the end of the month for
the last four months so I'm just going
to say soon when I get back from this
trip I'm going to start rewriting the
guides and then following that we'll
have the Phoenix one three book updates
and then we can continue researching
monitoring metrics especially around
existing beam solutions CX ometer is out
there there are several metric libraries
and we want to see you know what's the
bill in the ecosystem and how do they
integrate specifically with their party
solutions because that's the most
important part it's how can we develop a
common interface to all of these systems
that way everyone can hook into our data
collection and then you could report it
to whatever system that you're that you
desire so then again a metrics package
with a different name release it to the
world standalone and then build a
Phoenix metrics package on top that just
kind of gives you a nice channels
interface that you can hook into
in existing Phoenix out so that's it
thanks for the
and I mean I'll be around if you have
questions I don't know if we're doing
questions or not I'll take questions if
you belong not to want to out code so if
you have questions those please just
come up down here and ask any questions
we got a few minutes it's a nice one so
you're obviously a busy man is there
things that people can help you with
with Phoenix yeah so definitely I know I
think I mean I tried to hopefully
mention the we had the paparazi project
the web server folks I forgot to mention
we definitely wanted to collaborate with
them because they're doing some neat
data collection visualization right now
and see where there's some common
efforts going on but for everyone at
large what I tell people is a lot of
people asking me I'd like to get
involved is there anything I could help
with I get that question counseling and
which is great but my response always is
like usually people feel I I've been
through this myself so people feel like
they want to get involved but they need
to be allowed to get involved so I tell
people is like kind of like break down
any barrier that you feel that like does
it make you worthy until someone says
yes please do this and just start
getting involved so like there's an
issues list on Phoenix or Phoenix
pub/sub or any project that you care
about and see what's going on if you
find a point where you can contribute
however small I just start sending poor
requests and then the maintainer could
be like wow this person is great this is
this usually helpful and that's kind of
how you can get a jump-start into the
ecosystem so I would say yes we could
use help and my answer is always check
the issues list but I think it's
important to let people know that like
just jump in because it's like three
years ago that's what I did where was
like I'd like to get involved in open
source and then I like oh I will write a
web framework and now I'm up here but
but for a while there was this barrier
where I was like I didn't feel worthy
like the world could consume my code or
I could release a project so I would say
first break down that barrier and if
you're interested just just get involved
and people will happily accept your help
anyone else will to come up and ask a
question
all right let's give Krishna the round
block
I want to thank your won again for
coming to elixir company you and I
really hope to see you again next year
we don't have a location exactly yet but
I'll say this we're leaning a little bit
towards Prague so hope to see you next
year
take care</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>