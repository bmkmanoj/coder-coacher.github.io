<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building RiakCS on Riak - Bryan Fink | Coder Coacher - Coaching Coders</title><meta content="Building RiakCS on Riak - Bryan Fink - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building RiakCS on Riak - Bryan Fink</b></h2><h5 class="post__date">2014-05-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/tan0PN6iSuU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">as joe said i'll be talking about reacts
yes and I'm not going to talk so much
about how it works
some techniques that we use to make it
easy to develop easy to change easy to
you know debug etc stuff like that as
you said I'm Brian I'm hobbyist on
Twitter and that will help you if you
would rather have the PDF slides I just
tweeted a link to them so you can go
download them but you can also feel free
to feel free to throw tomatoes at
hobbyist so I will give a little bit of
a description of what reacts es is
because it will help you understand the
rest react CS is it is patch to license
but it is an erlang application that
sits in front of a react cluster to
expose an interface that is almost
exactly the same as the interface to
Amazon's s3 they're distributed cloud
storage system we developed this partly
because people really like s3 and they
really want to be able to host their own
so they're not reliant on you know
Amazon's infrastructure beholden to
Amazon's pricing whatever but also
because react itself without react CS in
front of it doesn't do well with really
large blobs so if you wanted to store a
four gig for terabyte file you would
need to break it up to store in smaller
bits of react objects and that's exactly
what react CS does is it takes a large
file breaks it up into small bits by
default I think there are a megabyte in
size and stores those in react but then
presents an interface to the user that
is just the file so the actual end users
the consumer of the s3 interface doesn't
have to know about this as I said it's a
patch to licensed we open sourced it in
March so everything I'm about to talk
about you can go to github and read the
code and you don't find out whether or
not I was lying or learn do it in your
own application some of the dependencies
we use our web machine we use web
machine for the HTTP interface because
it's vaguely resti we use logger to you
know tell what's going on
we use react syriac see is a Erlang
client for react it speaks to react over
protocol buffers we use pool boy to pool
those clients says that we're not
spawning you know infinite number of
clients to do stuff druid is a uuid
creator it hooks up to a native package
to produce you you IDs which we use and
i'll explain in a minute node package
packages Erlang applications really well
so you can deploy them in places with
nice start scripts and debug scripts and
that kind of thing folsom if you went to
the tutorial is all about gathering
stats it's really handy and it does much
better stats than what you would do on
your own you know instead just moving
average or whatever it has geometric
averages and kurt wha and all this kind
of it's great sext is a it's like term
to binary but the binary you get out the
other end sorts exactly the same way as
the term would have so you can have a
pile of binaries and sort them and they
come out just like sorting those terms
would have done and then e / is another
way for us to look into a node and
figure out what's going on inside so
that may be useful to other applications
you might be developing but as far as
react CS goes this is kind of the
high-level view so if you view all of
those orange react CS or i'm sorry all
those orange react boxes as a rioc
cluster those nodes are all talking to
each other all the time just like a
regular react key value store the yellow
react CS box is up at the top all
operate completely independently from
each other so each react CS node does
not need to know about any other react
CS note as far as its concerned it's the
only one it does not store any data
locally it stores all of its state in
the react cluster and what this means is
you can start up a react CS node take
out a react CS node at any time you need
to you don't have to plan the deployment
or anything if you need more you know
front-end capacity you spin up another
reacts as node if you need to save money
you take
on the react CS node and let people hip
the ones you already have up the one
other box on here is that green box that
says stanchion on it there are a very
few pieces of data in react CS that are
have a global name so across all users
only one users allowed to use that name
at any time that's user names and bucket
names so when you're uploading files to
react CSU put files in buckets that kind
of like directories but it's it's a one
level hierarchy instead of a nested file
system so we use stanchion to serialize
the creation of those objects such that
we can guarantee that only one user
claims any of those names at any time
stanchion is just like the react CS
nodes it does not store any data locally
so despite the fact that it is a you
know single point of failure if it fails
you just throw up another one and it's
all good you don't have any transfer
over time anything like that it's
despite the fact that it fails you can
or it might fail you can just bring into
one online without any you know hot swap
failover problems so some general topics
I'd like to talk about that you know
really affected how react CS was created
and an operand you know is malleable and
that kind of thing our immutability
backpressure web machine in general EQC
503 and records and just very briefly
immutability you should all be familiar
with if you write our length that's that
thing where once you've created a data
structure you don't change it you create
a copy back pressure is just you know
preventing some thing that is sending
you stuff from overwhelming you web
machine like i said is the HTTP tool
what i'm going to talk about is how we
had to modify it a little bit because we
presenting the s3 interface is just a
little bit awkward through web machine
eq c stands for Erlang quick check which
is an awesome testing framework that you
really consider using and I'll show you
why 503 is the HTTP status that says the
service is not available and you might
think it's odd for me to talk about that
but it it relates to back pressure and
we'll get to that momentarily and then
we're also going to talk about records
everyone's favorite subject despite the
fact that maps are coming soon which
will be a lot of fun so we'll start with
immutability like I said you should be
familiar with immutability this is the
thing where you know once you create an
erlang data structure a tuple or
whatever you don't change it if you're
going to change some element in it you
create a new tuple with the new element
and you we use this in Erlang right
because it prevents certain kinds of
bugs well we wanted to use it in reacts
yes for the same reason we wanted as
much react CS data data to be immutable
as possible just to avoid the bugs that
immutability could bring in so I was
talking about how react CS breaks up a
file and stores all the chunks of it
besides the chunks it also stores what
we call a manifest the manifest is sort
of you might think of it as the root of
the tree of chunks it stores the name of
the file and the length and who created
it and the access control list it's
basically all the metadata of the file
the other thing it includes is a thing
that we call the version the version is
a generated uuid that's what we use that
druid tool for every time you start
writing a reacts ES file we generate a
uuid that uuid is what we use to name
the blocks that you have written into
that file so you start writing a file we
generate a uuid and every block you
write contains that uuid in the key of
its react object so the first block is
that uuid dash one the next block is
uuid dash 2 3 etc what this means is
when we start writing if we overwrite
the file we generate a new uuid so we
start writing completely new blocks what
this means is when
you go to read a file you look up the
manifest and it has one uuid in it the
most recent right so when you go to read
the blocks they're either there or
they're not you don't start reading
blocks and get some of the new version
and some of the old version you're
either looking at the uuid you're
looking at and the blocks are there or
you don't even know about the other uuid
this presents prevents all of those
failures random corruption of you know I
started reading this file and someone
else started writing it and now I'm
reading what they're wrote or the other
way around or whatever whole class of
problems completely off the table
because those blocks are mutable it also
means that we can cache those blocks
forever we don't have to worry about any
sort of right through caching or right
back caching once we have read that
block we know it's not going to change
so we can hold on to it until the cache
decides to eject it for you know memory
performance whatever reasons so what
we've ended up with is ninety-nine
percent of the data that we store in
reacts yes is immutable there's those
manifests that we change we change which
uuid a manifest is pointing to we change
what time it was written that kind of
stuff but the manifest is a few
kilobytes maybe usually a few hundred
bytes and all of the data in the file
that four terabytes is completely
immutable so we don't have to worry
about all of those mutability problems
on the data in the file really scales
back all of that you know surface area
that we would have to worry about bugs
in otherwise so back pressure there's an
entire track about back pressure and you
should go watch all of the videos from
it because so far the talks have been
great about things you should consider
when thinking about back pressure in a
system in reacts yes we're specifically
thinking about you know how a writer
might overwhelm a react see a snowed so
it would send a file so fast that that
node couldn't write it in to react to
keep up with the problem that would
happen would be that all of the data for
the file would have to be able to fit on
that reacts es node
that doesn't sound too bad if it's you
know a gig file whatever we have servers
with you know terabyte of memory or
whatever but if you have lots of people
connecting the same server and they all
decide to upload for terabyte files you
wouldn't be able to store all of those
terabytes and memory at the same time so
what we've done is on the right side we
have an FSM and the fsm decouples
reading from the client and writing to
react if writing to react is not keeping
up we stop reading from the client so
TCP back pressure tells the client to
stop sending data this means that we
never have to worry about memory
pressure on the react node we can say
you know we know that we can hold four
blocks in memory outstanding right to
react for a thousand clients or whatever
and send tune the settings to that and
say never allow more than four blocks
outstanding in an f72 time and that just
prevents overwhelming the system you
might think that you know we're slowing
down that client he's going to have a
worse time uploading but it's actually
kind of the opposite in a really
parallel situation since people are
sharing those resources you actually do
kind of want to slow down the really
really fast one that would overwhelm
everyone else's operations otherwise we
also do the same thing on the get side
if we have a really slow reader that you
know we're sending data to and it's
giving us TCP back pressure we just stop
reading blocks from react for a while
you know we read ahead such that we're
not waiting to finish sending to this
slow client before reading another react
object because that would give us you
know some bit of latency in the middle
of the file we are reading ahead but we
read ahead only a certain amount such
that we're not using up all the memory
that we would use for another you know
request or whatever so talking about
requests may as well move on to web
machine web machine if you're not
familiar is sort of a a utility for
easily describing correct HTTP you might
hurt clack a dis rest earlier in my
opinion he was talking about a thing
that his hips
rest it's not real rest and so I'm not
surprised it existed because it is kind
of a hoax but if you really want to do
rest web machine does this really great
you know abstraction for it where
instead of sitting instead of like most
things that say this is a URL and it was
a get please read from the socket and
write out to the socket web machine
dispatches on URL to a what we call a
resource module it's an erlang module
that represents a resource at that URL
web machine then asks that module
questions about the resource and the
questions or things like does this
resource exist if not web machine
automatically sends a 404 so that
function would have returned false the
returns true we proceed on and says what
kind of content type does is what does
this resource have and the resource can
say actually i can send these three
types web machine handles figuring out
what type the client wants if you're
familiar with HTTP the client can say i
only accept these types but the resource
provides these types and there's a
negotiation web machine handles that so
basically it's a bunch of functions that
are properties of the resource web
machine figures out how to send the HTTP
response that says this is what you
wanted in the correct format so yeah web
machine is great if you have a restful
api dispatch is very nicely on urls
users get and put in identity manners
uses post when it wants to go outside of
things unfortunately s3 is not quite
restful to fit web machine really well
in particular its urls are a little
strange so you know you have this
concept of a file and the URL to the
file is kind of the bucket name prefix
in the file but then there's also access
control lists for the file and it's the
same URL with a little query parameter
on the end that says access so it's you
know that ? and an access this makes web
machine a little difficult to expose s3
because it wants to route both the file
request and the file
access request to the same resource
module so you would end up with a module
that has kind of two sets of logic and
every function it's the set of logic for
the file and for the access it just
makes things really dirty so what we do
now instead is we rewrite requests so
kind of like Apache rewrite that's what
we named it after when we get a URL a
request for a URL we give the
application that started the web machine
an opportunity to change the url so
reacts yes it gets a request for a
bukkit bukkit foo it rewrites it two
buckets foo this is important when it
gets a request for the bucket policy at
foo query policy it rewrites it two
buckets food policy this means that web
machine will now dispatch those resource
calls to two separate resource modules
so we can keep the logic for the bucket
and the bucket access completely
separate and it's not you know
interleaved in the file and we do the
same thing for files you know we rewrite
the buckets objects bar and bucket
object bar akal funny enough this
actually kind of gives you the inverse
problem where now they're worth some
things that are common between you know
files and file access policies so if you
imagine you know a very high level view
of the file you might have had the
authorization step the same for all of
them you know who is it that's sending
this request you might consider that
like the green part at the top so now
instead of you know we have these
separate modules but there's repeated
code and all of them and yeah you can
you know define that in a function in a
utility module elsewhere but the way web
machine works is it it has defaults for
all of those properties that it's going
to ask your resource about and if your
resource does not export the function
for that property it doesn't call it and
it just gives the default answer instead
so for things like does this resource
exist the default is yes
so you don't have to say you know this
resource always exists what we ended up
doing in reacts yes was building a way
to do custom defaults basically what we
wanted to do was say these are the
things that every react CS resource is
going to say in the same manner but
these are the extra things for this
particular resource so you might think
of it as kind of like a dictionary merge
of the functions in our specific
resource with the functions in the
general defaults resource in fact there
is a module in the repo right now it's
called something like our react see swm
default or something or custom default
what it does is it exports every
function that web machine might call
inside that function we look at the
other module so when you're dispatching
from web machine you have the URL and
you have the module name that you're
going to dispatch to you also get an
argument that you can send to the module
at an it time we use that argument to
send the other module name so basically
all of our URLs now dispatch to this
meta module if you will this custom
default module and then we'd
parameterize it with the argument for
the you know specific resource module
and we just use module info inside that
that custom resource file it's exactly
what web machine does we just do it
again so web machine is always seeing
that our you know meta resource module
exposes this function so we can override
the custom default I think there might
be an outstanding requests to just build
this into web machine so you would say
you know as one of the options when you
start up use this module as the custom
default I haven't been watching closely
enough so I don't know what that's named
and I can't tell you where to go look
but it's a useful thing it means that we
don't have that duplicate you know
authorized step in every single module
it's in one module we don't even have to
have a one of the call a stub that calls
out to the other module we just have we
do it the other way
Oh testing something that you have to do
and everything you know I was talking
about how we want as few mutable places
as possible as much mutability so we
don't have to worry about what's going
on but those manifests those are
beautiful and if you know about react
you know that it's possible for two
clients to write to the same manifest at
the same time you know two people might
decide to over to overwrite the same
file at same time and you'd end up with
two manifests so when you read them back
you get both of these manifests react
doesn't just you know throw one of them
away it says hey there was a conflict
here you try to do two things at the
same time which one was right we didn't
react CS was define a function that
takes two manifests and says this is the
correct one it you know uses a time
stamp and and the state of the file
whether it's still being written or
whether it's finished or whether it's
being deleted and that kind of stuff to
decide which manifest is the correct one
but trying to decide whether or not this
resolved function was right required
some testing and what we really wanted
was this resolve function to be
deterministic and give the same answer
no matter how it got the requests it
needed to be both associative and
commutative we needed to know that if
the list of manifests was manifest a
manifest be and it chose manifest be
that even if we gave it the list
manifest be manifest a the reverse order
it would still choose manifest be
because you don't want you know one
react node to reply faster and get the
opposite order and thus have one client
see one version of the file and another
client see a different version of the
file if you remember math class
associative and commutative is basically
you know you can add a string of numbers
in any order grouping them however you
feel like if you're thinking about it
functionally it's the same as folding
left through the list and folding right
through the list being equal so I was
talking about or than quick check what
airline quick check can do is generate
those manifests for us it can generate a
few of random manifests and we can just
have it generate that we've you know
coated in like this thing's a timestamp
and this thing's a uuid and this is how
you generate those they'll just generate
matter random ones and then we in the
property just say assert that fold L on
all of these manifests with our resolve
function is the same as fold are on this
on all these manifests with our resolve
function yes it means that we're not
testing specific corner cases but
actually thinking of all those corner
cases in a large application that has
many knobs is a really hard thing and a
really annoying thing they have to sit
and type all the time so we just have
EQC generate tens of thousands of rounds
of you know two manifests in one
manifest and five manifests and etc etc
and we just let it you know run for 10
minutes an hour whatever you know it's
kind of it's just it's random testing
and it works really well actually it's
found some good bugs and we've fixed
some stuff so back to back pressure I
was talking about HTTP 503 and how it's
sometimes okay to say no you can't do
that right now we were talking about
slow writers and fast writers and fast
writers and slow readers back then but
we also have the case where we're going
to have many clients connect same time
and you know a cluster can handle 10,000
clients connect a the same time might
not be able to handle 20,000 clients
connecting at same time if you let it do
20,000 you might get really slow
requests for some of those and you might
get really fast requests for some of
those we kind of pride ryokan being
extremely predictable so we'd rather
have you know the case where maybe not
all 10,000 are going as fast as possible
but they're all getting about the same
rate and you know from 8,000 to 10,000
it's still about the same rate and you
know you don't suddenly get to the point
where your rate is much much slower you
know five times slower we'd rather have
it slow down a little bit and that's
fine and we definitely rather not have
you know some requests be much slower
than other requests
so we learn to say no there's too much
going on I can't service your request
right now and the easy way we do that is
to pool our connections to react so
instead of every request connecting to
react itself and asking react for what
it needs we have a pool boy pool of
react connections that we use over and
over and over and over and over again so
when a react CS request starts we try to
check out a client from the pool if we
can't get the client we just say no you
can't do that right now getting the
client is the first thing we do and we
just returned from that web machine
property that says no this service is
not available and web machine
automatically sends 2503 like i said
this helps a lot and the thing we do
that is a little bit extra is that we
have separate pools for separate kinds
of requests so in reacts yes we can
write a file we can read a file or we
can list all of the files in a directory
or a bucket reading a file is you know
pretty lightweight we can just plow
through that writing a file might be a
little more you know resource intensive
it takes more time to get stuff on to
distant off disc listing the files in a
bucket is something that can be very
expensive we kind of have to ask most of
the react cluster instead of asking just
a few nodes for some information and
waiting on all of them takes a long time
and all of them doing stuff means that
there's more load on the cluster so what
we've done is we've made one pool for
reading and writing data to data to
react as the you know files and one pool
for listing those files from realloc so
when we get a get request we check out
from one pool and a list request checks
out from a different pool and we can
change the sizes of those pools so we
can have a really large get input
request pool so we can have lots of
those going on at the same time and a
really small list pool so those are
automatically you know held back so we
don't have a whole bunch of those active
all at the same time means that we get a
little bit more predictability we don't
have
suddenly a whole lot of list things
keeping anyone from reading any files at
all last epic I'd like to talk about is
record versioning I know people kind of
dive into Erlang records and then
realize they're not what they thought
they were and they're kind of a pain but
it's really great because you can
pattern match on them and you know that
makes your code really clean really fast
in reacts yes you know it's a long
running app people don't start up a
react CS cluster and store some data in
it and then throw it away and start with
anyone I mean they do during testing but
once they're in production that reacts
es cluster stays around for months years
whatever so we end up every time we have
to roll out a new react CS version
there's a chance that we might have to
change for instance the manifest object
and our manifests are stored as firm to
binary Erlang records so if we read
something that an old or lang-cs
application wrote we might get an old
record version and if you know how
records work that means our pattern
matches will no longer match you know
didn't you change the name of the record
and that tube will no longer matches or
you change the size of the tuple no
longer matches so what we have to do is
upgrade those records before we can use
them we could have you know all over the
code base this is how you deal with
version one of the record this how you
deal with version to deal with version 3
instead we defined an upgrade function
that takes version 1 and upgrades it to
the latest version it looks basically
just like this version 1 you know
upgrades it can either upgrade the
version too and that's why it calls
itself recursively and then version 2
can upgrade to version 3 or we can write
the code to upgrade version 1 directly
to version 3 I think we've done both at
this point I know I've done both in the
in other applications in the past and
basically you know once that upgrade
function sees the latest version it just
returns it it's really simple so then in
the read path we just immediately call
upgrade as soon as we get
result I was talking about how we might
get multiple manifests back that
conflict with each other we upgrade all
of the versions of the manifest and then
run the resolve this means that not even
the resolve step needs to know about
other versions of those records it's
only in the upgrade place in the upgrade
function that we need to know about all
of the versions of the records resolve
doesn't need to know about it and
everything downstream from for from
resolved doesn't need to know that
there's any sort of conflict on the
message we have this nice path that just
narrows down what we might get and all
of the rest of the code is dealing with
one manifest that is the current version
makes it really easy this is a list of
people that bash show that have
contributed to react CS so far this
slide was made just before we open
sourced it so it's missing all of the
people outside of betcha that have
started to contribute to react CS and
we're really excited about those but I
didn't have time to do this this is
actually read Draper slide deck and I
thanked him profusely for letting me
borrow it because it meant that I didn't
have to make to slide next for this week
but these are some people you might go
harass if you want to know more about
how react CS works but that's actually
all I have and I'm happy to take
questions if anyone has any ID here in
front a couple years ago I was making a
homemade system which is very similar to
what you do did you consider using sha
hashes of content as keys to file pieces
so we did heck yes you have to ref count
to garbage collect them but you you get
nice property as saving space that's
absolutely true we actually did have an
old version some of you may have heard
of a thing called luoc and it did
exactly i didn't use sha it used scroll
which was a contender for the latest on
losing the acronym right now but yeah we
tried that out and it was exactly the
problem you described that garbage
collecting when a file went away meant
that we had to do ref counting
ref counting and react is hard because
we can't atomically change that ref
count we might have a new file being
written that's about to reference that
object whereas we might delete it out
from under you could add a little header
to each piece and then use regular
conflict resolution on those little
headers I it doesn't work that way I we
we spent a lot of time trying to figure
this out and it it's just not possible
to atomically change that ref count or
to bring something back from the dead if
you accidentally deleted it so there's
there's inherent bit rot in that kind of
system so yes it would have had space
savings but outside of the data
warehouse where you want to be able to
store as much data as possible and you
have a lot of people storing redundant
data it's really not an issue most of
our users are storing you know things
that every file is different so they
wouldn't get much utility out of that
anyway a great question thank you
anymore okay give up for Brian thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>