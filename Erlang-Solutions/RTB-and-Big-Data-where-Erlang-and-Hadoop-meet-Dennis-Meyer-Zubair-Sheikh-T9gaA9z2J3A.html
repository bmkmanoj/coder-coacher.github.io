<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>RTB and Big Data - where Erlang and Hadoop meet - Dennis Meyer, Zubair Sheikh | Coder Coacher - Coaching Coders</title><meta content="RTB and Big Data - where Erlang and Hadoop meet - Dennis Meyer, Zubair Sheikh - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Erlang-Solutions/">Erlang Solutions</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>RTB and Big Data - where Erlang and Hadoop meet - Dennis Meyer, Zubair Sheikh</b></h2><h5 class="post__date">2015-12-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/T9gaA9z2J3A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everybody welcome to the presentation
standing in prison where she quickly
here today but there will begin dealing
with often teachers who were to listen
to my colleague of me is Dennis Meyer
Dennis will take over compatriot
presentation to the two hours
what I go to talk about today is what
Israel and Eric context of online
advertising it on how to look at the
real-time betting exchange architecture
and then we'll continue on to look at
the data handling into so what is we're
all familiar for going on the internet
and getting some nice content of course
is all free for us to live-graft mostly
but someone asked is paid for delivering
that content and this is most intent for
by advertising today and traditionally
advertising that done with both grunt
agreements between publishers and
advertisers so this is this means in
this case here we've been a banner on
display to the top Verizon Verizon might
have come along and said we want to buy
one hundred thousand impressions of this
banner on his webpage card day for the
next month that's very inflexible it
doesn't really help if you only want 300
hours to split you'll have sort of
legends the horizon might have as well
for the publisher I dare later the
publisher might find out somehow either
want to actually pay a lot more than
what Verizon did to get there at least
we're there but you're locked into up
front to bring me more that's that's too
bad so this is where real-time bidding
comes in real-time bidding is the
violent selling off of impressions in
real time while your page is loading so
we have 22 players in the real-time
bidding architecture where the SSP or
supply side platform on the left
they represent publishers so each time
your browser is making requests to the
publishers web page yes teensex of an
auction and invites DSPs or demand side
partners to take part in the auctions
and those demand side partners
represents the advertisers who want
their ass with on your webpage if we
take a look at the different components
involved and actually doing the work
flow in stocks off when your web browser
next request to the publishers website
so we download the HTML there on inside
that HTML there is a request which gets
fired off to an answer this ad server
does some decisioning part that is it
decides whether this publisher wants
real-time bidding on their webpage or
not they do want real-time bidding the
request is for long the real-time
bidding exchange this is the part we do
in their life the real submitting these
jeans then gets to decide well which CSP
should be hot in this auction and we can
move buildings and East he requests
there Jason encoded data enough to the
DSPs the DSPs will hopefully respond
within at a certain time limit has been
predefined ahead when they respond back
there getting back a big price which is
how much they will pay to get that are
displayed on your web page and also a
JavaScript snippet which represents and
the JavaScript that they won't fit onto
the web page so once when I get selected
the requested back via the ad server and
then off to the web browser and that
jobs connected at that point then fires
off requests to the advertiser
delivery and the artist is Claire on
your webpage so we'll have a little loop
about the real-time bidding exchange
want the architecture that looks like so
what starts off in the answer affords
this request the real-time bidding
exchange the requests actually a thrift
and quarter message and it sent over a 0
q interferes to a zero MQM point on our
real-time bidding exchange see our human
very flexible for us so as well as
connecting one our server to the
exchange we can connect multiple hard
servers I'm in addition to that we can
add in as many real-time bidding
exchanges we like connect us back to the
ad servers what it means for us in
practices you can add or remove our
servers or real-time bidding exchanges
the easier and Q layer then is doing the
route or dealer pattern and it's mr.
should be distributing the load equally
across those real time in exchanges so
you can take any one of those are the
service at any time so once the request
is gone to the CNT process it spawns
another airline process for the auction
we don't use OTP behaviors for this
we're just using properly to spawn
process we do use going TP everywhere
for long live processes but often
processes should be should be very
quickly
for a few milliseconds and if it's
something did go wrong with an auction
process there isn't really time to
respawn it and try sending another
request again but that auction process
for a look at the requires which comes
in it's it looks at things like what IP
address was it from and Kamat
opportunity location kenapa did it come
from a webpage that was how secure
content only client and could also look
maybe it didn't come from a desktop
browser maybe came from a mobile app
instead so there's lots of lots of
different categories information for her
to look at and then it must decide and
what Campion information maps what mass
what came in on and request so let's
campion information stored in ETS tables
we use these quite heavily with great
currency set up so we can have lots and
lots of different auction process system
all apparently accessing the campaign
information eks tables
this is how you actually get the data
into the ETS here so the real targeting
exchanges are the ones in the bottom
here but on the top left we have an
airline's config service this airlock
config service text configuration for me
Jason documents from populates my sequel
clusters with the Jason documents so
when a real-time bidding exchange notes
starts up that has a hashing algorithm
there without which hosts are the my
single cluster should connect to because
we want to have all these connections
distributed evenly and at startup it
will just redone all those chasin
dolphins decoding from story natively in
the ETS kills periodically it has to
check it hasn't been any new conflict
added to the database so polling
continually goes on on my single cluster
there while all these options are having
happening at the same time
so in addition to getting getting that
so the static information for my sequel
database with a cockpit cluster it's
being populated with information from
the different days pains that we will
connect to so our auction process does
have to connect a car space cluster and
we found a nice application on get up
lmc are not implemented the binding
protocol we needed to connect the car
chase on it request once you've received
all the figuration information and the
user mapping information from koch base
then we need to decide who can actually
take part in the auction so so in the
DSPs might be disabled for a certain
period fun may be so nice you go on all
of them some of them might be throttled
because they're going handle so many
requests per second some of them might
not be able to handle requests because
they don't handle to secure us and then
somebody's maybe only handle ads for
mobile applications so there's a lot of
different filtering and decision-making
ass be done figure out which tsps can be
in that option
so finally we'd like to build an oven
our TV protocol message and send it over
HTTP to the DSPs but to do that we need
a connection to the DSP so we're using a
an application and the holes for us
pools of sockets toward each DSP so each
socket is looking after a long live HTTP
connection it's been a tricky part of
system to take care of if the ESPYs are
working normally then the idea is you
can't stop it on the field send a
request get the answer back and then we
can put the socket back in the field for
them to reuse but we get some of the sps
it may be how too bad deployment someday
and many stopped working as they expect
they might start closing all these
sockets on me and then that leaves you
with lots of time made connections on
your system so so looking after these
pills and you know deciding how many
sockets you want for courteous begin
there is something quite important to
look after and then finally we get the
responses back to the ESPYs the response
is going to the auctions what we still
have lots of filtering to do on what the
some advertisers might be whitelisted
some are blacklisted they're much buyers
representing different advertisers which
can be white considered blacklisted PS
PS can respond with a maybe a deal ID
which is something they set up with a
publisher not really in our control
without the moment in a certain
advantage with a particular publisher so
we have to take care of all these
different events in the auction and then
we decide the winner
and send it back to the answer so as
well as the auction which goes on me
this exchange has nice user interface
where we come connected seasons working
see it's God's configuration data and
Ally connections we're exporting stats
and via SNMP we also false Mike running
so we're exporting a lot more metrics to
that there so we use pravana a lot for
developing different dashboards with
Cortana we can look at seeing are
different ESP their beginning and we can
see a lot of different farmers with the
auction process I think time about 10
different sections of an auction process
so we argue software or configuration
changes a lot we can easy spots where
are we spending more time in which party
option you spend more time not compared
to say last week and one of the new
additions to our to the system is
created scanning so when Leah's PS do
respond with her proud Marco as well as
doing the auction on that we're taking
this odd Marco sending off the third
party for scanning for checking as it is
really secure HTTPS does it have an hour
what kind of industries advertiser
associated with that kind of scanning
also influence the auction decisioning
process as well so we rolled the system
I'd about three years ago in reduction
and with one DSP you may be doing a few
hundred requests per day we've got up to
blog where we're standing run 60 billion
HTTP requests
poor dear to all the DSPs over there on
a single whole set I think what we've
seen a maximum production is hanging
like Turkey thousands requires two psps
per day I don't know if that's a good
number or a bad number but it says it's
okay it's not it's not just one or two
and I think I think we're quite pleased
but I think we've had worse we're still
trying as much as we can to squeeze as
much arted system as we can this kind of
shows a high note does scale of the
different requests it's it's almost
linear but it's even fence Ted to
flatten out as we get toward the end on
this particular day there were 12
thousands request sent for DSPs in a
second each point here is that is the
maximum cpu load on a 10-second interval
so it's quite this is quite interesting
look up there's definitely a lot of them
white space around around the line so
people got quite good performance IDF
cosmic quest for second sometimes were
like sixty percent cpu load and
sometimes the 70 and its problems like
this that we're really dealing with
every day and trying to and trying to
figure out what wife and up to all the
requests six percent cpu but another
thing we're quite pleased is it's it's
really it's on an idol buying system
where we're having requests coming in
and we're doing a lot of waiting for
requests coming back from his piece so
actually being able to get our cpu up to
the seven beginning
percent range it's something to find
airline was really good for if we look
at a single request I says I said this
part system we're not using low key
indicators for but we do spawn not a lot
of processes but a prayer request you
can c0 mp message handler will spawn
requests for them the threat request
hundred assists according the thrift
message then it will delegate the
auction the auction process and then the
auction process fans on to DSP processes
which uses HTTP client processes so to
make sure using processes for fault
tolerance and also for planning on
system together to work comprado this is
just a quick quick demo to to worry if
you can't read this writing and what it
is each each blue dot is a as a probe is
a process user in single request I uses
one single request the processor joined
together by lines because there's links
between the processes and if we better
resolution people see process IDs
against that so typically at any instant
we will have hundreds of these auctions
going on getting on time on what we're
trying to show here is it's just good at
a picture in our imagination what
hundreds of auction process is going on
look like underneath one time it's just
a little application called paragraph
you can get us off the l github account
just out of desire oddity remark on fig
and started up and then you just point
your web browser you'd be able to see
all the processes that are going on your
system and don't travel is too many
processes credits it steams bjs force
directed graph and the browser will have
trouble rendering this once you can ask
a few thousand processors so I'm going
to hand over to
hi that's working perfect so my name is
Maya I'm chief architect especially on
the data side so as we've seen we're
working kinda with have a seder 60
billion who saw as a number so data
handling in data handling size matters
right I think there's kind of a big
difference between small amounts of data
and big amount of data so it grown kind
of bigger and bigger and the challenges
are kind of getting more complex
especially when you're reaching a
certain threshold because you're kind of
entering a certain limit we're not many
people are working with and it's getting
kind of a little bit of a metre touch
sometimes so what is big data so we're
talking about no sequel we are talking
about new sequel which is more
relational databases which are enhanced
like polymer data stores like clustering
paralyzation linear scaling case safety
eventual consistency magid use and warm
right so just to give you some ethics
what when you're dealing with two times
hundreds no that's kind of the size of
our to do plus a sense a moment that's
kind of our current setup with two
clusters just of how our data centers
are distributed we are creating like two
turbines hi ok so we're doesn't work
yeah perfect ok so we're creating two
terabytes an hour so just as a fun fact
so we're writing not files out more or
less kind of is contrasted but it could
be kind of if it was readable just
unwritten out text from fact this would
kind of equal to 500 million pages so
it's a 50 kilo meter high pile of paper
if you're all a full paper so kind of
everybody kind of talks
paradise but doesn't know what it really
is about whatsoever okay okay now it
should work okay so the trend terrified
stores in our data store in the
background so that's a reporting
database so that's tragic trying two
terabyte of data so that's kind of a
paper pod which would reach formal into
the stood guard so how do we enter kind
of the data world in in that
architecture that you saw saw a raid so
that's kind of the same page that you
saw before and in here we are simply
hooking kind of into the xserver saw on
the way back that we know who has won
the auction we're giving back that
information to a component which we call
it or collector in here we've got
multiple different iterations in logging
out the data so it was different
implementations and we ended up writing
our own because we have a lot of
scalability issues we're using flume and
as we're logging out so many data we
were kind of pity we're pretty unhappy
recent performance and we used a lot of
resources that we didn't need to so what
we ended up with written our collectors
it's written in java based leonetti what
we're using is kind of reusing ring
buffer so we don't allocate data
multiple times so that's me so it's a
contrary picture of immutable and
respawning so we're just allocating once
and reusing a trial tom so if everything
is coming in we're simply using it
guess we don't have any memory
allocation we just musing stuff right
recycling another thing that we are
doing and that's also important to the
data for the US because before we have
talked about optimization of the
database I'd about blocks databases so
we're using zero coffee so we don't kind
of copy all the data ones from one point
to another we've seen that this has been
a big issue a lot of logging frameworks
because sometimes you have to take a
decision between low level and
performance or high levels which is more
stable and a usable more feature-rich
and invert that's kind of disconnect
sometimes so in here we have got some
possibility to tune in to kind of also
the benefit is that you could also kind
of contribute to maximize the TCP layer
so often here we saw a lot of issues
where tcp buffer were limited we are not
reaching kind of the reals report on
kind of a large-scale networking issues
all of that is kind of a funky compliant
perspective small project it's not as
feature rich as for example flu or
whatever Kafka but it's kind of pretty
performant and has a lot of scruple what
are we looking out really so we're using
a binary former so binary has got the
benefit that you've got kind of a
compressed format and it's not eating up
so much space as you're using kind of
plain jaisa XML or whatever format you
are seeking off its supporting
structural data so arrays trees etc it's
using compression it's kind of
self-descriptive which makes it really
handy to work with so for writing out a
file so first the first part of the file
is a human readable header it's not only
human readable but also machine readable
so it's Jason so this is look this is a
real life example how can one
that hair does look like and after that
is common area right so the rest of it
it's not even readable but that makes it
really easy to handle those files
because it's got bought them with
different versions on the disk and the
Machine and differ between the two and
human can as well for debugging purposes
and there's not a benefit that's not on
the slide you don't need to pre compile
it so in comparison to Google protocol
buffers you don't need to be compiled
also it's used kind of and do pretty
much so it's kind of finish on Ian so
partners in crime element MapReduce so I
think you see in a slide that LM is
producing a lot of data and we're using
ton of the scale of is a horizontal ye
to reduce a lot of data and we were
doing now here is that that we're using
kind of MapReduce and to do to process
that data so that's just out of
Wikipedia right so what is MapReduce
really so it's a framework for
processing penalized problems and I
don't even want to continue so we're
talking about cluster and separating
data and paralyzing stuff how does it
really work out oh okay so not only if
you kind of look into into some of the
Hadoop tutorials hope they talk about
work out so one of the problems that is
not only kind of ask here is just take a
book and count each and every word how
often does it kind of the pier in here
and then of course you need to count it
and as you need so it's contact problem
it's pretty serious for paralyzation so
that's kind of really nice use case so
what is happening here's the left hand
side you have the input file then
there's the splitting so that's how the
data is represented in the room so a
muscle different machines it's got
different data so that's one line
through boxing then yours the mapping
happening so the mapping is
the first processing step in here so
you've got a counter and each kind of
each and every word has got account one
so it's pretty simple so you're just
kind of transforming the file to kind of
map then the shuffling happens so in
your kind of your kind of talking data
across kind of different machines right
so that's also a costly operation
because that's also kind of writing
files of the original implementation
you're writing positive machines so
there's a lot of data going on the
network and also the system on disk so
come read write operation and as you see
in here it's kind of orange so that kind
of the same day tour ends of the same
machines we can process it so the next
step that kind of jewy juice so mad good
use right so we're coming into the end
in here the reduced staff is really
processing right the reinforcing is not
really true so you can kind of have a
business logic on the mapping and
reducing side but in this case we're
having kind of important in your side so
what we're doing is very kind of simply
summing up for getting kind of the
overall number right so if you look at
the bike three bucks it's simply summed
up and that's happening on all the boxes
in parallel then we are sending it back
to one central Central box and we've got
some of the results file the interesting
seniors that we're kind of maximizing I
or throughput right so if we're looking
into boxes everything can run in
parallel and the better we kind of
organize that so better the stupidest
and that is also kind of up to your
parallel systems so the batteries of the
different boxes work independently on
their own the better it is if you've got
a lot of network communication right so
problem is kind of drawing is
potentially so the more network
communication we have the worse it is
right and in your seat kind of the
shuffling for example that doesn't look
that nice right buttons so the second
thing that we are using is kind of um we
talked about 220 terrified in the
database right so 20 terabytes longing
not
we have in this database so we're using
how to vertical which is calling the
data store anybody if you're using
column data stores if you okay perfect
so those those of you are familiar for
the for the rest of it is pretty simple
so just that's kind of the table example
in here about some some raw later so
this is how look like if you just do a
select star in a traditional data store
we are talking about those those blocks
right which is written out this I don't
want to go to two down into database
Erie that how it looks like on this is
on a roll store you've got all the data
kind of side by side right so if you can
roll all the data resides next to each
other inside one block and file system
at the end and that makes it of course
easy to read the complete record if
you're just accessing the block so one
reads one blob read and you got all the
data but not only what's happening as it
we don't agree all the data so we could
optimize some robberies if kind of we
would only have the data that we need a
block and that's the real idea so what
we're doing is instead of kind of
writing it out all block by block right
we're kind of only focusing on the
college so what column is written out
completely then the next column is
written out and so on and what's
happening if we're kind of accessing the
data we have kind of nominees imagine is
that we have kind of some instead of
using an index where we're having kind
of sorted if on this and normally we're
using compression so that it doesn't
grow too big and we're using handle
normally a smart indexing like that I
research on top of that and we're
jumping into the data are so example if
you select for Germany we know it is
hurt one so we also know that chocolate
is a certain one so that's show me
the served sales is also kind of 4,000
so depending on how many theatres read
so more selects you need to do so if you
just ask for what is kind of preference
for Germany and on a product side you
just excess those two columns so it's
defecate excess but it's it's it's it's
raining a lot less blocks and it's more
optimal on on the assessing so if you're
talking about notch data it's outrageous
kind of the additional storage jetta me
too because you have some application on
start site that's it outside of it when
we are talking about the aggregations
inside to do so the pre-processing the
number crunching and all of that is done
in MapReduce jobs a MapReduce jobs are
you can write them your own like in Java
normally tunnels at sea original idea
you can also do it in Python and then
has been a project and we're also using
on was also running on my Mac not
reproduce but only do so they might have
also used sad so you can look in
whatever language you want you but you
need to write up your own and as you see
it was I always creating a map creating
reduce phase so what about a traditional
relational database system it's a select
count whatever do join so you guys are
used to kind of sequel if you want to do
right kind of a joy on MapReduce it's
free and complex you need to do a lot of
stuff a lot of steps doing that your own
you don't want to write so there's kind
of extraction script languages like pick
on top of it which take part of that and
is creating those MapReduce jobs for you
so it's a crypt scripting language and
the alcohol is a MapReduce job a native
Matthews job hey is kind of a data
stream oriented just a small example on
it I don't want to go into the details
just that you have in kind of impression
how it looks like and it is kind of see
polished right but it's the other
outlets kind of data stream related
there's also other prayer it's like high
who create a MapReduce jobs who is using
sequel you're also using that up 99
or ninety five percent is impaired
that's the architecture of our reporting
systems on the left hand side you see
the app server is a lot of collectors we
talked all that ends up going to do in
the doobly using pick some pic results
are kind of ending up in s3 markets so
we a naval yes so those results can also
be easily either consume our clients so
a lot of our clients ask for anything
the data set aggregated in a straight
way we can do it and you can simply grab
it on an s3 interface that makes it
pretty simple because it's a simple HTTP
access to the files with all of the
control that we have on it for our
internal reporting which use under the
left lower hand side that is kind of
using vertical the dimensional data is
that kind of the campaign configuration
data this is friends what's the campaign
name what's the advertisement name so we
are logging out only integers only kind
of numbers for optimization so we need
to join that information so that's
happening in here so what's next we're
kind of looking into getting more into
the locked architecture we already have
some real time system which we have
built alone they are not that flexible
as you want you so we're looking into
getting a little bit more speedy singhs
going on also smart overcome some of the
limitations on writing out fives on this
and reading them again sorts it's
streaming there's also some effort done
in the group itself which is cuddles a
young framework so you can have you can
leverage streaming a little bit better
so then everything not all the exchange
data between nodes you need to hit this
directing also spark is using kind of
Stalin so it's going a little bit more
to the director
elings also kind of our class should be
familiar with most of you guys so it's
kind of a carbon copy on the scale
outside of a line and they also say that
they used Ellen as a template so it's
looking pretty much the same and you
know we're hiring so we're doing not
only online so we're using Java C++
along where the advantage that we're
kind of in the advertising business with
the huge Gator and we're using a lot of
new technologies because we need to
write need to keep pace with industry we
are not a financial company we need to
have limitations or no we're not giving
you day away so that questions coming so
we're more restrictive than you sing off
in that sense but on the day the subway
not so we're using a lot of fancy frame
on skazal canals bread is out phase all
of that is somewhere in our architecture
and if you have a lot of firings out of
all the different technologies also
different places join me in dublin us
with any questions go on thank you much
you can f it yes hurry up you use thrift
and a broke why do you both of them so
indeed we're not using kind of thrift in
here one of the walking side so that's
kind of a plaint is yuki message where
is the payload already is operable
contrast so if you're when where the
exurbs getting the information back it's
already trading the a pro forma as
binary and then we're kind of sending
that all the while using a tcp message
with the head and having got some meter
information that we know where it ends
up diving a booster
at some point you you have the zeromq
process creating thrift there's a temple
listener so that's because you're using
thrifty or outside deputies that's a
outside interface that were you doing so
so you're talking about the protocol
between the app server and the selection
engine and that's the couple because the
extrovert cells getting in the request
doing some parsing magic and then
transforming it into some already
machine readable protocol and that is
kind of that's kind of the part that
you've been referring to so that's not
happening on the long side but on two
different machines which are kind of
handling different parts of the load so
it's kind of 20 separate but they're
both serialization mechanisms right so
why did you decide you different ones
because there's different means the one
doesn't need to get locked look how to
describe so if you're talking about
hours there's some compression and then
handing needed that would be overhead if
it's just kind of one machine already
has it as a object in memory it wouldn't
eats until civilizations United
civilization magics we would get around
that that processing my last wish on the
on the handling of the the ads getting
kind of the DSPs sending messages back
you have time constraints are those kind
of handled by using the soft real-time
in our line or do you have actual real
hard limits that we reason soft
real-time so we just so you know we're
using the timers we get from airline so
buildings Halloween how long are those
times those times can become configured
so so different publishers might have
different needs work we're talking
figures in milliseconds for for some
people there if they're small
milliseconds and other people it could
be hot as many seconds so it's entirely
configurable and it spans no customer
using that what what they want to get
from the systems on</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>