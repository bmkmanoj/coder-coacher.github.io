<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Apache Spark Tutorial for Beginners Part 7 - Using MLLib - Frank Kane | Coder Coacher - Coaching Coders</title><meta content="Apache Spark Tutorial for Beginners Part 7 - Using MLLib - Frank Kane - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Udemy-Tech/">Udemy Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Apache Spark Tutorial for Beginners Part 7 - Using MLLib - Frank Kane</b></h2><h5 class="post__date">2018-03-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/I2L_J4l6YbY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so our spark examples so far have been
pretty straightforward finding the
average ratings for each movie and you
know honestly we could have done that
probably just as efficiently using pig
or even high fright because both of
those can run on tez which gives you all
the advantages of a directed acyclic
graph really probably about as good of a
tool as anything so let's do a little
more complicated example here that
actually drives home the power of spark
what we're gonna do is actually use the
movie lens data set to recommend movies
for a given user so what we're gonna do
is actually look at the entire 100,000
ratings data set and use that to
actually predict the rating for every
movie for a given user based on the
other stuff they they watch so just like
when you go into Netflix or something it
shows you recommendations for movies you
might like or maybe if you go to Amazon
and you see things like recommended
products for you same idea here and what
we're gonna do is use something called
ml lip the machine learning library
that's part of SPARC built on top of our
core and it contains something called
ALS which is a recommendations algorithm
I don't really want to get into the
details of how that works but it is the
basic idea behind the winner of the
Netflix prize several years ago where
they offered a million dollar prize to
anyone who could actually produce better
movie recommendations than they had
already and ALS is one part of how that
was done so let's see just how simple it
is to use something like ml Lib to do a
very complicated thing using spark now I
mean if you were trying to try to
implement ALS recommendations just using
MapReduce forget it like that would be
incredibly hard right how would you
actually boil that problem down to
mappers and reducers it can be done
obviously but with ml live it just
becomes a whole lot easier and that
opens up a whole lot more possibilities
to you as a developer so we're going to
do we're going to do this in the spark 2
style again using Sparks sessions we're
going to import from alan alda
recommendation the ALS package and again
we'll have ro and something called lit
that just lets us put a constant value
in those rows same as before we're going
to load up our dictionary that map's
movie IDs to movie names so we can print
those out when we're done and let's
again skip ahead here we're going to
create a spark
just like we did in our previous example
we're going to call this app movie Rex
and we are going to load up our
dictionary that Converse movie IDs two
movie names we will then load up the raw
data and this time notice that we're
doing it a little bit differently than
before we're actually using spark read
text directly on the sparks session as
opposed to using the underlying spark
context but we're loading the same input
data file you data from HDFS and this
actually returns a data frame but we
want an RDD so we're going to call our D
D to get the our D D in two lines now
from that just like before we can
convert that into row objects of our
choosing and we have a parse input
function that does just that what we're
doing this time is returning rows that
contain the user ID the movie ID and the
rating so since we care care about
making recommendations for specific
users we do actually want to keep the
user ID along for the ride this time
okay so at this point we have a ratings
our DD that contains row objects that
contain user IDs movie IDs and ratings
for each individual rating we can then
create convert that to a data frame like
we did before and we're going to call
cache on that because I'm actually gonna
use that data frame more than once so by
calling cache I can make sure that spark
doesn't do something stupid like try to
recreate that more than once so we now
have our ratings data frame that
contains rows of user IDs movie IDs and
ratings so now what so ALS sort of a
machine learning concept in general it's
a concept of train test so the idea is
that you build a model that makes
predictions on your data and you train
that model using some set of input data
where it has a known result in this case
we know the ratings that each user gave
for each individual movie and once we
build a model based on that training
data which is our entire movie lens data
set we can then test to that model by
giving it user IDs of people that we
don't necessarily know the predictions
for for a given movie rating and use
that model to predict ratings for movies
that maybe a user never even watched
okay so that's the basic idea here now
to do that you know I don't want to get
into the deep meaning of all
different parameters in the ALS
algorithm but the point is you can do
fancy stuff like this with just a few
lines of code so we're gonna build an
ALS model okay using these parameters
and it's gonna say that I'm gonna feed
it a data frame that contains a user ID
column a movie ID column and a rating
column and those correspond to user
identifier item identifiers and ratings
ALS knows what those concepts are and
then I can just call fit on that model
with that ratings data frame so this is
basically saying train my recommendation
model on the entire movie lens dataset
and give me that model back and I can
now use that model to predict movie
ratings for a given rate given user now
what I've done here is I've actually
fabricated a new user so I can sort of
have a persona that I know about so what
I've done is I've gone and edited the
UDOT data file and I've added three rows
at the beginning for user ID zero which
didn't exist before so user ID zero if I
remember right gave a 5-star rating to
Star Wars and The Empire Strikes Back
but a one-star rating to Gone with the
Wind and you can look up those movie IDs
if you want to that's what those mean so
what we've done here is create a persona
of someone who really loves science
fiction but really hates historical
dramas okay
reminds me of someone I know but anyway
that's all we know about this person so
just given those three ratings we're
going to ask the ALS model to predict
that users ratings for every other movie
okay so first we're going to print out
what those ratings are just to make sure
that we read them in properly so we're
going to print out ratings for user ID
zero we can then call filter on the
ratings data frame to just filter out
any given expression so remember our
user ID column was named user ID and we
could just pass the expression user ID
equals zero to only filter through
ratings for user ID zero and that should
come back in the user ratings data frame
that we can then iterate through and
print out the results mapping the IDS to
names as we go now we're going to
predict our ratings for other movies now
just to you know prevent any spurious
results I'm going to restrict that
analysis to movies that were rated more
than 100 times
so things where we have a reasonable
amount of data on what people rated them
and the things that they rated them with
so to do that I'm going to make a new
ratings counts data frame by grouping
the ratings by movie ID counting them up
so now I have an RDD of every movie ID
the number of times that movie ID was
rated and I'm going to filter that see
I'm kind of like chaining things
together here so that only movies that
have a count greater than 100 survived
into the final ratings counts data frame
so at this point I have a data frame
that contains movie IDs the number of
times that movie was rated and it only
contains movies that were rated more
than 100 times and now what I'm going to
do is create a test data frame that I'm
going to send to my ALS model so what I
need to give ALS our recommendation
model is a data frame of all the movie
IDs that I want to recommend for every
given user so I'm going to create a new
data frame that contains two columns
movie IDs all the unique movie IDs that
have more than 100 ratings selected for
my rating counts our data frame and I'm
adding a new column called user ID that
just contains the value 0 all the time
so what this is saying is that I want to
go through every movie that had more
than 100 ratings and predict the rating
that user ID 0 would have had for that
movie ok and if I wanted to predict
values for more than one user I could
just keep adding you know more user IDs
basically right so we then pass that
data frame into our model we say model
dot transform popular movies that's
telling it I want you to predict ratings
for these movie ID and user ID pairs and
that will come back as recommendations
and to get the top 20 recommendations
for the Caesar I can just sort that by
the predicted rating so that's what I'm
doing here I'm saying taking the take
the final list of predicted ratings for
user ID 0 sort them by the predicted
rating in descending order so the best
ones are at the top and take the top 20
and at that point I have my final
results all I have to do is iterate
through them and print them out so let's
see if it works
you can just watch if you want if you do
want to follow along though make sure
that you make those same changes to your
you data file that I did
and upload those into HDFS using Ambari
under the user Maria dev ml - 100 K
folder on HDFS a little bit of extra
practice for you they're using HDFS if
you're so inclined so if you do want to
follow along copy those three lines into
your u data file and upload them into
HDFS on your little pseudo cluster so
hit pause if you need to do that but
moving on let's go ahead and I've
already done that on mine
so let's go ahead and open up a session
and from the previous lectures you
should already have the script that we
need here that's the movie
recommendations ALS py script and go
ahead and take a quick look at it and
yes that is indeed the same script we
were looking at and let's go ahead and
run it sparked a submit movie
recommendations ALS DUI just like that
kick it off you'll be surprised at how
quick this goes up oh I forgot something
remember we need to set spark major
version of spark 2 since I'm using
Sparks session objects I can't use spark
1 with that and it called me on that so
first we need to do this export spark
major version equals 2 just like that
and now I like showing you when things
go wrong cuz you know things go wrong in
the real world let's run it again now
we're cooking again we can ignore these
warnings about hive context because
we're not actually using hive so relax
spark it's ok now we're asking you to do
some pretty heavy-duty stuff here aren't
we you know predict recommendations for
you know a hundred thousand movies
potentially but it's gonna happen pretty
darn quickly look we're done oh that's
awesome
so let's look at the results here so we
are just echoing back the ratings that
we plugged in for our fictitious user ID
0 again he loves Star Wars and The
Empire Strikes Back hated God with the
wind and this is what it came back with
now there is sort of a random element to
ALS recommendations so your results
might not be exactly the same but you
can see they're pretty reasonable so
Star Wars the original came up pretty
high well obviously we didn't filter out
the movies that we already
grated so you know an exercise for the
reader would be to do that but some of
these others there are pretty good
recommendations the Fifth Element also a
good sci-fi movie my Python or the holy
grail of close shave you know these are
both sort of like irreverent English
comedies and well speaking as a science
fiction nerd myself I can say those also
appeal to me as well so I think there's
some truth to that Empire Strikes Back
of course showed up again Blade Runner
sci-fi science fiction Return of the
Jedi a movie that we didn't explicitly
rate but obviously a good recommendation
given that I like Star Wars and Empire
Strikes Back some of these are a little
bit questionable you know but who knows
maybe I would actually like Jackie
Chan's for a strike if I went and
watched it terminator alien these all
make a lot of sense Mystery Science
Theater love mystery sighs love me some
mystery science theater big fan of that
too cool so you know we got some
reasonable results here out of ALS and
there you have an example of doing
something pretty complicated using spark
and a great example of using the
libraries built on top of spark did
perform complex analysis with just a few
lines of code across an entire cluster
on massive databases so there you have
it ml lib recommendations using spark
kind of showing you the full power of
what spark can do cool stuff</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>