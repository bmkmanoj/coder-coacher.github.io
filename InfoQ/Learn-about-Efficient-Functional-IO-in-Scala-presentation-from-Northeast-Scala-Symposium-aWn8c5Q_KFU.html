<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learn about Efficient Functional IO in Scala (presentation from Northeast Scala Symposium) | Coder Coacher - Coaching Coders</title><meta content="Learn about Efficient Functional IO in Scala (presentation from Northeast Scala Symposium) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learn about Efficient Functional IO in Scala (presentation from Northeast Scala Symposium)</b></h2><h5 class="post__date">2012-04-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/aWn8c5Q_KFU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome my name is John Dee goes I am
presently CTO of a company called Precog
and what we do is essentially produce a
big data analytics engine and the scio
is extremely important to me personally
I am a committer and also the original
author for a web framework for
developing restful api s in scala called
blue eyes and obviously a web framework
is predominantly concerned with IO and
here at Precog where we live and breathe
I oh all the time one hundred percent of
every day for the purposes of doing
analytics on large amounts of multi
structured data you can imagine how
important the topic this is to me I've
been using Scala for prob about two and
a half two and a half years
professionally and I've kind of fallen
in love with the functional way of doing
things studied a bit of Haskell and
really interested in kind of the
intersection between functional
programming and performance I oh this is
my laundry list of requirements for an
ideal functional IO system you can see
it's it's not small number one I want
any functional i/o system to be resource
safe so it should be very difficult or
perhaps even impossible for a developer
to do something like accidentally close
a resource I don't want resources
leaking left and right should be
composable I should be able to take
things that consume some input and
consume them together or compose them
together in various different ways I
should be able to take things that
produce output and also compose them
together in different ways because that
gives me the ability to reuse code it
should be pure or at least as pure as
possible because I want the benefits of
reasoning and modularity and testability
that come with pure code and by pierre i
don't mean even the IO monad I mean we
want to push even IO out as as far as
possible and make our code pure in
intention and not just in yeah
pure as pure as possible but appear
especially in the external interface not
necessarily the implementation I also
want the code to run really really fast
and part of that is because my two
projects are either the big data
analytics database or this web framework
and either of them are subject to very
very strict performance requirements i
also want as much type safety as
possible i want the compiler to catch as
many problems up front at compile time
as possible like ideally i shouldn't be
allowed to if closes an operation i
shouldn't be allowed to close something
more than once for example number six I
want it to be as simple as possible
obviously the more requirements you add
the more incompatible with each other
they become and in particular some of
these on the JVM and in the scholarly
programming languages are unachievable
together but to the degree that it's
possible I want something to be
relatively simple something that doesn't
take a lot of brainpower to understand I
wanted to be capable of incremental
input and output especially when you're
dealing with a modern web applications
which frequently have to process
hundreds of connections maybe thousands
of connections a second or the kind of
i/o that we do a Precog you can't hold
all that stuff in memory and you need to
be able to do operations incrementally
on that and finally i want the i/o
system to be very expressive and i'll
give you an example of what I mean by
that frequently when you're writing a
web application you'll be consuming
input from the user and then you'll
dynamically make a decision to for
example look look at something in the
database and then based on that result
you may decide to read something from a
file or open a new web connection and
basically you need the ability to
dynamically decide to allocate new
resources at virtually arbitrary points
in your coat and that requirement in
particular is is a real pain to get
around in a functional system so I want
to kind of give you an example of
classic io probably most people in this
room have seen at one point or another
and it's based on java's input stream
and output stream how many people have
used this at one point in their career
nearly everyone in the room is familiar
with these this it's kind of
straightforward and I want to put it
through a report croc report card how
does it stack up to my laundry list of
requirements resource safe not at all so
you'll frequently see in code that uses
input and output stream try cats live
everywhere on this because if you
accidentally forget something if you
forget that finally block on any of your
code and forget to free the resource and
suddenly you have a resource leak and
there's almost no java application out
there that hasn't had or been
beleaguered by resource leak problems
composable it doesn't actually get an F
and the reason for that is because you
can take an input stream in another
input stream for example you can compose
them together in a variety of different
ways to get another input stream and you
can also take an input stream and you
can decorate it with another input
stream to add some bit of functionality
so they're a little tiny bit composable
which is why they don't get an F in that
category obviously they're not pure at
all it's straight mutation there's
nothing here about that interface
whatsoever they get our na in
performance because input and output
streams are really really fast not an A+
mind you because they're based on
synchronous blocking I oh but they do
get an A for performance most of the
really fast open source projects out
there written in Java that do io u--'s
input and output streams number six they
are simple so any developer can
understand what these things do so they
get high marks for that they do allow
incremental I oh that's a very natural
way to use them and they are expressive
in the sense that obviously all this you
know tangled mess of imperative code can
open up new resources at any point in
time in response to anything and so yeah
yeah their expressive within the
paradigm that is input outs input stream
and output stream let's take a look at
another another means by which we might
do I oh and this whole there's a lot of
different concepts here this family of
concepts is referred to as inner at ease
and iterate ease were invented long ago
in the Haskell community and now they've
since shown up in the Scala community I
want to drive the development of an
iterative step by step unless you see
lest you think that this is purely fear
medical it Ortiz actually formed the
basis for several Haskell web frameworks
which operate very very very fast and
they also form the basis for at Precog
our analytics database I think we're the
first company or organization in the
world that can claim to have an
analytics database implemented on top of
it or at ease so what's the basic idea
here well everyone's familiar with fold
right how many people know what fold
left is and have used it a billion times
so the basic idea is if in this fold
function you're you pass a list and you
pass the function which then computes
new state as it goes along and it ends
up producing some final value this looks
like a lot of i/o problems many times
you'll be reading through a resource and
doing something passing state along and
then you'll end up computing some sort
of final value and the really nice thing
about fold is that if you translate it
to an i/o context then basically the
list or whatever is doing the fold over
all those elements has explicit control
of the resources which means that this
abstraction provides a very convenient
way to guarantee no resource links also
just by its very nature you can see this
F function is incrementally processing
every element one at a time through the
list so it's giving us some of the
benefits from my other chart we get that
incremental processing we get our
resource safety and you'll see these
things evolve naturally as we make a few
tweaks so in this particular example
this is a nice starting point but one of
the problems is that we might like to
consume a little bit from this list and
turn that into one value and then
consume a little bit more and turn it
into another value so this property can
be referred to as horizontal composition
of these f functions which I'm soon
going to call a knitter 80 and this
gives us the ability to do really
interesting things like we might have a
byte array and we want to convert that
to a list of strings a list of lines
then we might want to consume the HTTP
header portion and then consume the body
180 to consume those bytes and produce a
header another to consume the body bytes
and produce a body and this horizontal
composition property allows us to do
that how do we do that in code just very
simple modification to what we had
before it's still called fold left is
still folding over a list our f function
takes the initial state the seed and an
input element and return something
called a step and the sole purpose of
step is to give the folding function
enough information to decide when f no
longer once input when f is done so here
you can see i have two different cases
here f function can return either a step
that says it needs more input or a step
that says i'm done i don't need anything
else notice the values being stuffed
into these more and done data structures
are actually the state of the fold
function just just like your ordinary
fold function maintain state as it's
going along ultimately culminating in
the final value so also this value here
is that state function that's passed
along and this turns out to be a rather
inconvenient way to model state because
you're being very explicit about it you
have to have a data structure that
unifies all the different state
decisions you make over the course of
that fold so one thing we can do to
improve this definition is to move that
state which is currently contained in
that parameter be inside the function
and of course a function can't have any
state so what we do is end up in
producing a mealy machine which is a
function that accept some input and
returns the output along with the next
successor version of the function and
that function basically has a memory it
can remember stuff that has happened
before and this allows you to encode
state in a more natural way and that's
that's what you see there so this is
composable in one degree we can compose
together these things which I'm going to
call it or at ease because they can
consume a certain amount and then they
can produce a value when they're done
this value is called be there's no
explicit state now B is the final value
produced by that and then the case that
it needs more you pass it a function
from the next input element to a new
step so basically this allows that fold
function to start or call start
initially with the first element in
there and to proceed step by step by
step until your function returns done
with the output value at which point it
stops and says ok i'm not going to feed
this bitter tea anymore input but
there's one problem here and that is
what if this this start function this it
arati wants to consume input from a lot
of different sources right now we just
have one full function and that fold
function is promising to return a value
of type B so it's basically assuming
that that iterative on within the
lifetime of the elements inside the list
in fact that might not be true we might
may have to pump this thing with lots
and lots of data before that iterative
design zits done and emits a value so
the next thing we do is make this
composable at the level of folds by
introducing some sort of input element
that can basically represent an element
of input or a signal that there is no
more input and the iterative could emit
whatever value that it has and this
allows us to take and we also modified
the definition of fold left here so
instead of promising to return a.b it
actually promises to return a step which
is the step at
enced along as long as it can for the
number of elements in that list so what
this enables us to do is take list a
list b-list see list d etc essentially
composed them all together in a single
thing and feed this iterate ed to one
after the other after the other after
the other and when we reached the
definite end of that input we can send
it an end-of-file signal which ends up
internally causing that iterate e to say
okay i'm never going to receive any more
input i better produce a value here so
there's there's one more thing what does
this look like when you've kind of
renamed stuff well it's pretty
straightforward you have your input
element whose sole purpose is to wrap
individual elements so you can provide
an end-of-file signal to the iterative
that there's no more input and it should
produce its output value and then you
have something like this and it arati
which which has the more case saying
give me more input has another case
saying done which actually emits that
final value and then frequently you'll
have either a control signal or
something like this error handler saying
okay something something went wrong pass
that information back up through through
the chain so that basically this energy
is allowed to produce heirs other kinds
of iterative might be allowed to produce
messages to request to seek to arbitrary
points in a file or rewind or do other
kinds of things and then this thing that
has until now been been a list that
we've been folding over now becomes an
enumerator which essentially folds over
values of a given type of a and you can
call fold and produce it or feed it any
entity and then get back an iterative
that is fully advanced as far as can be
advanced given the amount of information
contained in that numerator so the
energy it may or may not be done if it's
not done and you want a value you have
to feed it in a file signal to produce
one but in many cases you end up taking
one in numerator and and sandwich in it
with another one to feed it lots of data
across different sources so you can
actually you could use option but it's
very handy in
some cases to extend input with a third
state called empty because that allows
you to do more interesting kinds of
compositions so I don't portray that in
here but often time you will see an
empty another state in there that
basically says there's no input here and
then that in arati that gets no importa
just ignores it and says give me more or
whatever it said before but yeah if you
only have those states I guess you could
use option so this is it or a tease
that's all there is to it Ortiz with one
slight detail and that is there's
another abstraction called Anna numeracy
which is a way to transform streams you
might imagine that just like in in a
list you can take a list of a's and
transform that to a list of bees that
there's some abstractions similar to
that because fundamentally and
enumerator is very list like and in fact
there is it's called an enumerative and
basically given given an iterative at
that consumes a's it can produce an
iterative at consumes B's and internally
transforms those in 2 a's so this is an
example of kind of a stream transformer
it accepts elements of one input type
and it transforms into another and
together these three abstractions the
iterative the enumerator in the numeracy
form essentially a complete algebra for
iterative a style you can do tons and
tons of things in real life they don't
look this simple they look a lot more
complicated and that's because you have
all kinds of crazy stuff here you
basically need to make guarantees a
monad transformers so all these things
need to be transformers or have
transformer versions and you need that
because well for various reasons one of
which is composition another which is
functional purity etc now let's take a
look at how it Ortiz score on my report
card there resource safe there really
resource safe it's basically impossible
to leak any handles whatsoever and the
reason for that is the enumerator is
capable of opening the resource pumping
the stuff out and sending it to the
iterative until the iterative done or
amid some air when one of those things
happens or it reaches the end of its
resource it can deallocate its resource
safely and all that's controlled by
numerator so actually with with your T's
it's impossible to leak resources it's
really really really safe composability
it gets a B+ so it's very very
composable you can combine these things
in all kinds of crazy different ways it
doesn't get an A in my opinion because
some of the more complicated
compositions are extremely complex and
difficult to express with it at ease but
but it is extraordinarily composable
there are many things you can think of
like can we read from more than one
input source at a time can we read from
one input source and another and the
results of how fast we read from this
one depend on what we read in this one
the answer is yes to all those questions
it's very complicated but it can be done
high performance this is specifically
with respect to the JVM and the scallop
programming language unfortunately it
Ortiz are not that performance they are
relatively slow because the first thing
you want to do when you have them is
compose them together and every
composition every layer of composition
adds additional overhead we had to do
some crazy things to use them ourselves
internally one of which is chunky so
instead of processing one element at a
time we process big fat chunks of
elements and that reduces the overhead
of all this infrastructure on a per
element basis to a level that it's
manageable they're reasonably type-safe
they're not completely typesafe they do
not get an a there are some weird things
about it or a tease one is the fact that
you can feed an iterative an end-of-file
signal and you have no guarantee that
it's actually going to produce about you
you have no way of encoding that in the
type system there are also some other
strange things when you use when you
have an iterative that basically has a
state that acts as a control signal to
tell things to rewind or advance it is
really really hard to develop a way of
composing those things together in a
generic manner that doesn't lead to
nonsense in some cases and and as a
result they don't get an A for type
safety but largely they are type safe so
simple unfortunately they get addie
because it Ortiz
even in the naive implementation confuse
many people they're actually not that
complicated it's a little awkward to
program with them but usually you end up
writing combined tours that do things
like take and drop while and other kinds
of things to make them a lot more
pleasant to deal with but when you do
the more advanced stuff with eternities
they become very very complex and in
Scala the type signatures start growing
to be multiple pages because you're
doing type lambdas in type lambdas and
just things go out of control like crazy
so they are not simple they're not
simple by any means they can do
incremental in fact they excel at
incremental input and output so let's
take a look at an alternate way of
phrasing things we looked at a one
example where we kind of built up this
functional i/o system using full
starting from fold left and it turns out
we can do something very similar
starting from map maps a lot simpler and
functional IO built around this concept
is much better at doing some kinds of
things so this is a basic map but we
have the same problem we had before at
some point in our iterative development
in that F has no memory you send it in a
and it will always send you a beat I
can't remember what's gone before so the
first thing we do is introduce kind of a
mealy machine where you send it a value
and it returns the output as well as the
continuation of itself the next function
in line to succeed it and with that kind
of encoding you can have as much memory
as you want it's similar because now you
can map values but over time I mean it's
more restrictive than a fold because
you're forced to admit these bees as you
go along so you're doing stream
processing instead of folding to a
single value yeah it's a scan that's
exactly what it is
yes that's right yeah it's bad
terminology i change it eventually so um
what can you do with that well you end
up calling this thing that you can call
map on it you call it a stream and the
other one you call a stream processor or
there are lots of different there are
lots of different names for these things
in in Haskell world there's a framework
built around this that's called conduits
stream processors by themselves aren't
all that interesting because they can
they can process values they can
transform them they can manipulate them
if you extend this like if B becomes an
option of something else for example
then you can conditionally emit values
you can all kinds of interesting things
you can combine them together in various
ways but at the end of the day you need
a source for values and you need some
sort of sync and for that you usually
end up with structures similar to this
you'll have a source and you'll have a
sink and I'm missing some methods here
typically what you see in these kinds of
libraries is source will have some sort
of means of pulling data out of it in it
in a semi impure way so it ends up being
wrapped in some IO monad ultimately that
will return you a value as well as the
continuation source to use for when you
want more input and sinks usually have a
push method that ends up doing the same
thing pushing a value but still you can
see some of the compositional properties
here even with the methods I've listed
you can take you can take one of these
stream processors which form a narrow
and you can you can append it on to a
source to produce the new source if you
can produce values and you can transform
them then you can produce values
basically and the same way for a sink
you can take a sink and then prepend one
of these three stream transformers to it
and then call that thing a sink it's
just sink of a different type and there
are lots of different ways you can
combine the street transformers
themselves basically anything that you
can do with an error you can do with
these stream transformers so you can do
this one and this one and this one
transform from A to B to C to D etc and
you can do other things as well so the
actual implementation of these look a
lot more complicated because
with all this impurity you basically end
up needing to introduce some notion of a
transaction to help you help you not
leak resources and once you introduce
that in the IO Mona they end up being a
lot more complicated than what you see
here so how do they do are they resource
safe well conditionally conditionally
these things are resource says you have
to do some work you have to wrap stuff
in a transaction or region to get
resource safety but you can make it work
they are very composable so you can
actually compose them more simply in
some cases than you can with it or at
ease when you have these two sinks and
you can pull from one and pull from the
other at different rates becomes a lot
more natural to do some kinds of
compositions up here no unfortunately
the only thing that's pure and it's not
even pure in like the Haskell library
conduits is the stream transformer
portrait back part can be one hundred
percent pure in most cases unless you
need to do some sort of side affecting
operation inside there everything else
is contaminated with impurity and it
just whether it's IO or whatever it just
infects it and makes it harder to reason
about high performance there about on
par with it or a tease at least if you
do it by the element by element level
every time you call the stream
transformer to produce a new element
it's supplying a new function and all
that element by element overhead adds up
its type safe it's reasonably typesafe
it's fairly simple it's a lot simpler
simpler than it Ortiz most people find
conduits these stream processor
libraries a lot simpler to understand
because they can think of it literally
as in terms of a source of values a pipe
that can maybe change stuff over time in
response to stuff it's learned in the
past and then a sink for values and
that's relatively simple it's simple to
think about you can do incremental IO
with these things and they're reasonably
expressive they're they're more
expressive than it or a tease for a
given amount of work anyway so I've
given you kind of a taste for a few
different ways of doing functional IL
none of them are perfect they all make
different trade-offs and that I've been
kind of looking for what's next in my
opinion it
use they don't quite do it stream
processors they don't like do it
conduits they're a little messy I think
definitely there's something out there
that achieves more of the criteria I
consider to be good and what does it
look like well I think for one it's
going to have a push space sources to
lend itself to a synchronous programming
the reality is is is that when you're
programming out there in the wild you
can't pull a chunk of material
instantaneously there's always some sort
of delay and that delay you don't have
control over and it's proportional to
the size of the data that you're trying
to pull and so in order to be efficient
push based sources such as it er a tease
where the enumerator is feeding all the
values instead of the receptor pulling
them make a lot more sense so it has to
use chunking in my in my opinion Scala
on the JVM you cannot have a performant
library that reads things element by
element unless your elements represent
whole documents or something you need to
chunk it and that makes the interface
more awkward to deal with and that's an
inevitable reality in my opinion of
doing of doing high-performance
functional io on the JVM the chunky
basically allows you to arbitrarily
squash down the cost of all this extra
stuff on a per element basis something
very interesting is is possibly using
monadic regions for resource safety
that's part of the main motivations of
it Ortiz is the fact that you don't leak
resources well if you use monadic
regions to get that resource safety then
some of the benefits associated with
iterate ease go away and you open
yourself up to a more simpler model of
programming that appears to be poll
based but in fact it's not poll based
and and in which you're guaranteed that
resources will will be unallocated at
the right time by the regions that
you're using and I include some
resources at the end that's if you want
to dig deeper into that and i think that
there's going to be if you hit some
certain marks i think there's going to
be if for example you hit performance
marks i think it's going to be perhaps a
little awkward and a little complex to
use and i think that's just a necessary
limitation of the JVM at this point is
that you can't have the cleanest most
beautiful most composable code that
ones performant Lee and another option
is instead of doing that I mean there
are certain points you have in designing
any of these libraries at which you can
insert something that's a little unsafe
or something that's a little dynamic and
if you do that it basically broadens the
space that you can explore and you can
reach more of the other trade-offs so if
you're willing to sacrifice the little
type safety or a little resource
allocation safety then you can get a lot
of the other stuff on that report card
so here's some source code I recommend
that you check out Scala Z in rotis
which we've contributed too heavily yeah
it's not light reading and there are
type signatures there that will scare
you Haskell conduits that's not it's not
a very clean library it's actually very
very messy but it does have all the
basics in there Scala conduits which is
an in-progress port of the Haskell
conduits that's not yet ready for prime
time but it'll be interesting to see how
that shapes up there's Scala melee
machines if you want to experiment with
that and Haskell monadic regions and
scholars that also has a region i don't
think it's fully complete yet yeah it
looks like it's a work in progress but
all these are really good resources i
recommend checking them out reading the
source code playing around with them and
seeing what you think so that's it um
any questions
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>