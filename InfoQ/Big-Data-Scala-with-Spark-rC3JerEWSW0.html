<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Big Data Scala with Spark | Coder Coacher - Coaching Coders</title><meta content="Big Data Scala with Spark - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Big Data Scala with Spark</b></h2><h5 class="post__date">2013-06-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rC3JerEWSW0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so before we get too far I'll first want
to see is there anybody that's going to
admit to not knowing anything about
spark yeah it's going to get good news
bad news kind of thing bad news is that
i'm not going to be able to spend a lot
of time explaining really what spark is
all about because i really want to talk
about some of the pieces that start to
go beyond spark the good news is I've
got a larger audience for my look now
but so we will start with a quick review
of where the whole spark ecosystem is to
date and you can start off by thinking
of spark is similar to Hadoop and
actually after alex's talk you can
actually think of it even more
accurately as being similar to Scooby in
that it's a data analysis big data and
that was just a framework that runs
across a cluster for to add it has a
scholar API to it and actually the skull
API for spark is almost identical to
what the Scooby API is I mean you can
literally change a d-list to an RDD here
and there a couple other keywords change
and you can pretty much run the exact
same MapReduce job that you would run in
scooby over on to spark spark actually
actually to do some things you can't do
with Scooby so there's we can actually
go further and run more generalized eggs
and actually will disagree what that
looks a little bit later about the
viability of running machine learning
jobs and such because right so we get to
more generalized graphs of MapReduce
operations because one of the problems
that Alex talk to you a bit about was
that with Hadoop being very much based
on HDFS on the reading things all from
disk running one pass through your
MapReduce operation writing the results
back out into disk that really limits
you when you try and do interactive or
iterative kind of algorithms
but one of the big differences with
spark is that instead of keeping your
working data set back and forth off from
disk we actually stored in the ram the
aggregate ram across the cluster which
means that once you've got your data set
resonating Ram there you can actually
iterate through it multiple times or you
run an interactive query against it and
not have to spend the time waiting for
to read off disc all the time so what
that amounts to is that we end up with
much lower latency on these jobs to do I
mean this is 100 milliseconds is
basically for a null job a job does
nothing you're going to get the response
back 100 milliseconds where it doesn't
sound all that great except when you
look at what doing the equivalent in
Hadoop it would take you probably on the
order of at least 30 seconds just to
spin up to JVMs across the cluster and
still you're doing nothing so if you
start to look at interactive kind of
jobs something more like a traditional
database query where you want to issue
an interactive query at a console and
get a response back you really want to
see something that's kind of in some
second or at worst a couple of seconds a
response time and you're just not going
to get that with a Hadoop based
clustering whereas we can do that over
with bark and like I said before we can
actually start to run more iterative
kinds of jobs as well and start to get
into machine learning so spark was kind
of the first step along the path all
these things are getting developed at
the amp lab over at Berkeley it's a
group of graduate students and faculty
over there it's actually starting to
expand as well but so spark was well
actually more like the second major
piece came out of there the earlier
piece was on the gold mesos which we'll
see in just a little bit but after spark
now we get to shark which if you think
of spark as being similar to do shark is
similar to hive and what hive and sharp
what you do is such the issue SQL
queries against your Hadoop cluster or
against your spark cluster so that opens
up a whole
it opens up being able to write jobs
against your clusters people that only
no sequel or even equally important
there's a whole sets of tools and
applications out there that know how to
write read &amp;amp; write sequel and they can
actually interact with yours in spark
cluster as well through sharp so
actually shark barrows directly from the
hive libraries we take over the hive
metadata store the actual high ql query
language which is like i said it's a
subset of sequel then we also use the
hive parser and used hive to the hive
leverage to generate the logical plan
but one actually gets submitted to the
spark closer now we're running a
physical plant instead of the Hadoop
physical plant so we start to get the
same kinds of speed of sweet because
again we're using a memory sharing on
this data set so what you end up doing
is issuing your gear sharp query
generating a result set from that that
results that you cash across the memory
of the entire cluster and then you can
run further interactive queries or more
quick short queries against it also when
you we bring the stuff over into the
memory of the cluster we also converted
over to a kilometer store format which
then allows for a lot of compression
other speed ups as well and again so
that maintains the low latency then the
next step beyond sharp was something
called spark streaming which you can
think of it as being somewhat similar to
storm trident where we're taking sliding
windows over real time streaming events
so we group up these events that are
streaming into your system and you have
essentially running lots of small spark
batch jobs against those windows of
events and if you can process those
quickly enough which of course you
couldn't do if you were doing it in at a
dupe based system but we can do with
bark then you can keep up with your
stream of events and actually do
real-time stream processing you know
across your whole entire cluster so this
is what the Berkeley data analytics tech
ends up looking like if you look at the
stuff in white that's all the existing
open source stuff I mean you got your
HDFS filesystem from badoo you got a
dupe itself I pig and there's other
things that can use the HDFS things like
storm and mpi currents processing those
kinds of things can stay within the
Berkeley data analytic stick because I
mean HDFS kind of ends up being the
common denominator can the beneath all
of these the bottom level there may so
that's a resource management framework
if you familiar with yarn to cloud arrow
that's something similar with if you
want to run so like if you want to run
MPI jobs or a storm cluster or a Hadoop
cluster in a spark cluster at the same
time or multiple Hadoop clusters are
multiple spark clusters that gets be
pretty much impossible unless you've got
some sort of resource manager underneath
allow you to share different resources
CPU and memory and such across the
clusters that's what mais les allows you
do like I say that was kind of the first
piece that came out of the amp web and
has since been picked up by Twitter and
some others actually most the further
development work isn't really done at
Berkeley anymore basis so we've already
talked about the spark and shark and
sparks trading pieces and so for the
five pieces don't even talking about
tonight are then tachyon which was just
released a couple of weeks ago and then
the next things that will probably I
mean let's say it's the most likely
future for the whole spark ecosystem
because these next pieces aren't
released yet they may change some before
they actually do get released some of
them are still kind of more research
projects
so this is kind of the way things look
now and there were things worth thinking
about learning something about but
they've made up I'm not going to get
into like trying to show you code or
anything from these it's going to be
kind of a high-level motivational kind
of discussion of these kinds of things
yeah ah that's a good question because
the question is which parts will the
book cover and spark and sharp and
streaming will definitely be there
tachyon is an important enough piece
that they'll probably parts of it that
are in there but tackling is also very
new so it won't be an awful lot about it
there graphics may get mentioned some an
FML basin blank dvd-r probably far
enough in the future that they won't
make it into this edition so so the
first thing we need to talk about is
tachyon which gives us a reliable
file-sharing had memory speed across the
cluster frameworks and ok yeah like I
said there was a recent spark user group
meetup on this and thanks to stony the
video for that is available and that's
really where you want to go if you want
to try and find out more about what
tacky I was all about because like I say
I'll be able to go through kind of the
high-level motivational points about
tachyon but won't really be going into
the details of it and ok one of do are
continuing to do our comparisons here
you can think of it as similar to HDFS
it's a distributed file system that's
easily used from MapReduce jobs Hadoop
jobs or from spark in fact the spark and
shark API for reading and writing to you
tagging out is essentially identical to
what it is to write in HDFS so you can
literally write a job now that's going
to read and write from HDFS change just
a couple of lines and you're going to be
reading and writing from tachyon now
why would you want to be doing that and
it what it mostly comes down to is that
you want to be able to share data sets
among us Park and shark jobs right so if
we write to we look here we see tech and
is essentially working as a caching
layer on top of some sort of existing
underlying file system and in most cases
is going to be HDFS and so that you'll
be reading and writing to you tachyon
and more than one Supporter MapReduce
program can then see the same data set
within tech yeah you'd be able to do the
same thing when HDFS made if you thought
about writing running one Hadoop job
take the results of that write it out to
HDFS then another job could pick up that
result set and start working further
with it then that kind of thing was
difficult to do before before we have
tachyon in spark or shark actually
stealing a set of slides here from a
rental t key developer on shark and
these are all mention shark but they
pretty much applied to spark as well
because this is a situation we have I
just running one shark job against the
cluster you end up taking blocks of data
off from your HDFS filesystem reading
them into the memory of the shark system
and then you can run I instead of
interactive jobs across that but that's
really limited to this one sharp context
that has access to that memory your
problem then is if you have more than
one user or you have more than one job
that wants to access this same set of
data that's no resident in memory it's
not really a good way to do that what
you end up having to do r is there's
actually something called the Sharks
server which essentially adds a server
layer on top of this that instead of one
user
one job directly interacting with a
sharp and context he goes through a
server layer that's going to then
aggregate multiple jobs and share this
out one shark context and I could skip
the slide oh okay and that's fine as far
as it goes but you've actually there's
two tight and coupling between the
actual the job that's between the
execution part of the job and the
storage layer part of the job because
what ends up happening is that if that
shark server ends up crashing on you
well it usually doesn't end up stopping
there what happens next is that you lose
the entire storage layer as well so now
you've a grenade at multiple jobs into
this one and shower context and now
everybody's job is dead and it's not
only that there's not really a good way
to recover you've got to go all the way
back not to you HDFS and restart that
and you can try and compensate for that
some by running multiple spark spark or
shower context but now the problem is
that we end up even want to protect
against losing a set of data we end up
having to duplicated across multiple of
sparkle share context and so we're
duplicating the amount of memory that
we're using across the cluster and what
we really want this to you added a
separate layer in there to kind of
separate out the execution from the
storage layer because what ends up
happening now is that you've what's
going on here
hello something now it's working
correctly here yeah but what is we're
supposed to be showing that if say this
cluster crashes with tachyon system the
other guy will still be able to access
the data sets that it'd still be a
resident attacking the tech aunt won't
crash just because the execution engine
crashed now and because of some of the
details of the way tacking on is it is
implemented that I won't be able to go
into it actually stores a lineage of how
a data set was correct how I data set
was constructed and so if we do end up
losing a piece out of a piece of
attacking our data that was stored one
of the nodes in the cluster if that note
goes down it said we're actually able to
or quickly recover that and so we do get
a instantaneous recovery with into
account your release yet to develop a
release so it's not really production
ready yet and we do do our db's are kind
of equivalent to these d lists that Alex
talked about before it's kind of the
fundamental abstraction of what a piece
of data is our DD is a resilient
distributed data sets of these these
distributed collections across the
cluster memory and some support for
those sharing and cashing those is in
the current developer release there's an
HDFS API to it so you can actually
you're right Hadoop MapReduce jobs using
tachyon but things like being able to
directly put these column-oriented
storage that I talked about from shark
before you can't eventually we'll be
able to take those and write those
directly into tachyon as well so if you
thought about it before you write you
would read your shark data off from HDFS
and change it over two kilometers
storage in RAM and then have to write it
back out to the non kilometer and
storage format bacon
back in hdfs eventually with attacking
out you'll be able to take that
converted kilometer store and put it
directly as a raw table into tachyon and
not pay that kind of reorganization cost
multiple times and then the next release
also introduced full tolerance for there
is a master node in tacky and currently
that's kind of similar to the Hadoop
name node and that's a single point of
failure right now it will take to be
taking care of that and then next
release and there actually is potential
for further releases you start to
support that kind of directly writing
beautiful changes to your data set again
attacking on itself so those are all
things that will be coming down the road
but are really there yet so graphics
okay we're back to you a hard diagram
here so graphics is something that's
built on top of spark and but we're
looking at graph processing now yes so
so there's what kind of trying not these
didn't talk too much about graphics
tonight because the Berkeley guys
haven't really talked about it yet
that's really just kind of one paper out
there now and this is a very nice short
paper it's like a six page paper you
take a look at it you can learn an awful
lot more about more about how it's
actually implemented so I'm just going
to give you the high level again what
this is all about so graph data
structures and algorithms are quite
important now if you want to look at the
data I'm sure a lot of you are familiar
with like social network graphs and
stuff that are out there now and that's
kind of a familiar one to a lot of us
but there are a lot of other kind of
data sets out there they're kind of
fundamentally graph warranted in nature
and then there's certain algorithms that
are most easily expressed as graph
algorithms as well about nodes
communicating messages to other nodes so
if you look at how PageRank algorithm
it's all about well in the context of
websites is about which websites are
connected to other websites and so
there's a natural graph
kind of orientation there and so if you
actually try and write page rank and
Hadoop with its data parallelism
orientation it's got a difficult to do
it and you much rather have a set of
graph primitives that allow you to say
these are nodes these are edges between
the nose these are messages that are
getting past this is what you do when
you get a message and that sort of thing
and so that's what graphics and other
graph processing frameworks and start to
allow you to do so the aim of the graph
parallelism is to reduce the
communication and computation by
exploiting the graph structure itself so
like I said if you try to write these
algorithms using kind of the normal
Hadoop primitives you have doing a lot
of extra computation and communication
across all these nodes because do
fundamentally wants to scan through the
entire set of data and do something to
it instead of being able to work with
reduced set okay so yeah the first
problem we have in trying to do any kind
of graph processing is that the data
that we get typically needs to be munge
door mangled into some sort of graph of
appropriate format I mean data sets you
get out there aren't already set up to
be used directly in their expressed as
nodes and edges you have to kind of
manipulate the existing data North turn
it into a usable graph and then once
you've actually got and then expressed
as a graph your graph algorithms like
I've said before don't typically want to
run efficiently or then they're not
easily expressed a framework like
mapreduce so these solutions to these
are you need to do you you typically end
up needing to do your data munging or
data wrangling with a separate tool from
your actual graph processing framework
so oftentimes actually MapReduce
similarly or two parameters can actually
do that quite well so you there may be
yes so there are there are existing
graph parallel tools and frameworks out
there
things like right so these are all
working with passing messages between be
aa graph nodes and so there are things
out there like prego which is a batch of
synchronous parallel processing what
amounts to said these work it kind of as
synchronous and super steps so you may
have this whole class set of nodes and
connections they know the messages they
want to send and so you get it gets step
through in a synchronous fashion that
all the nodes are going to generate a
message all of them are going to send to
the next nodes in this step of this
super loop in this super step and then
we're all going to coordinate and
generate the next message when we're on
the next super step and so the process
indeed you process in this kind of
synchronous fashion and there are other
things out there like GraphLab and it's
powered graph set of algorithms it
actually can work asynchronously which
can actually end up providing you a lot
better speed up but in both of these
cases like i said before you typically
end up needing to do a data wrangling
step before that so you have kind of in
a two-phase kind of operation wear first
we're going to manipulate the whatever
raw format of the data we got into a
graph format and then we're going to run
these graph processing tools against it
so graphics replaces the earlier bagel
library which is used to be well it
still actually is in the spark code and
bagel is kind of an implementation of
prego but using a spark instead of
Hadoop that graphics just to borrow
ideas from GraphLab one of which is
vertex cut algorithms and some of these
details like I said you can find in that
paper or referenced earlier it's tightly
integrated with spark so yeah so we
adding a new data abstraction called a
resilient distributed graph again those
details are in the paper and we're not
going to get into too much tonight
and yet it's getting kind of interesting
that these new frameworks get
implemented on top of spark and get
implemented in an astonishing small
amount of code I kind of expect that
Reynold will be presenting our graphics
in the not-too-distant future and he'll
get into a lot of these into a lot of
these know details that are also in that
paper and you'll find that the framework
itself is a small amount of code then
actual jobs expressed using the
framework or very tiny amounts of code I
mean the entire PageRank algorithm can
be implemented just a handful of lines
of code okay so then when we look at
performance of graphics so I talked
before about prego which is kind of this
Hadoop oriented that synchronous
processing our kind of way of doing
things and then there's also graph lab
which is asynchronous way of doing
things and so if you implement the same
page rank algorithm on both of those
you'll find that graphics runs roughly
an order of magnitude faster then Fragel
does but it runs an order of magnitude
slower than what GraphLab does so it's
kind of fitting in between what that
amounts to in a practical sense is it
the graphics will probably never be
equal in performance to the specialized
tools that are out there like GraphLab
but it's because of the nature of spark
and it's low latency will actually be
able to interactively or iteratively
change the graph structure that we're
working with which is something you
can't do in that two-phase process I was
talking about before because your data
ranking Wrangler data munging step using
Hadoop MapReduce that's going to take
you it's an all-day batch kind of job so
much what else was talking about before
whereas if we can keep that all within
those two steps all both within the same
Berkeley data analytics tack and then we
can do interactive or updates of the
actual graph itself so even though the
final graph processing algorithms may
not run as quickly as what what a more
specialized tool like GraphLab can do it
with there may be enough advantages that
this kind of intermediate performance
will still be an overall win in the end
okay so let's move on to the next piece
and this is ml base so again we're back
to another piece that's built on top of
spark and yea though ba the San
Francisco Bay Area machine learning
meetup is a week from tonight and that's
will actually be presenting on mo base
for the first time and where is it yelp
I think and I checked a couple of hours
ago and there's still a few slots
available there so if you get enough
interested in saw I'm actually going to
try and do this all with a single slide
here so what we need to do first is kind
of ignored the ml machine learning kind
of tags that are applied to this and
think of this as just a typical
relational database kind of model so in
your normal our DBMS you come in with a
year end user is kind of this guy in
orange of the top and he doesn't really
know all the details of
a relational database is implemented
doesn't know really anything much about
about past joins or loop joins they're
all the different possibilities of how
things are actually implemented within
the database what he's giving you as an
SQL query which is a pretty high level
description of what the kind of results
he wants not how the job is actually
done and the system will take that and
parse it or run a query planner against
it run an optimizer against it generates
some sort of physical plant against that
and then that will eventually get from
run against the database and you're
smart guy over there he's the one that
ends up having to write all those
low-level database details about how
things actually get implemented and how
they optimizer itself runs and that sort
of thing so what ml bases are attempting
to do is something a similar sort of
model but instead of issuing sequel
queries against the database what we
want to be able to do is our issue
machine learning-based queries so you
may say instead of select these rows
from a database you may end up setting
against this database I want you to
cluster it for me and so then that
high-level description of what you want
will get passed into a inquiry planner
and optimizer and similar to what the
sequel way of doing things is and that
will turn into sort of run time jobs
against a spark cluster which will ya
again I don't want to go too much into
the details because these are be
stepping on the toes of the guys
presenting in a week here but that
should be I hope sufficient to get you
answers in the idea of being able to I
mean one of the big problems we faced
with in with in machine learning or data
analysis right now is there's just not
enough of these smart guys
they know how to actually run all the
tools at all of the at the level of
detail that the frameworks require so if
you have a a system like this then
allows you to express a query at a much
higher level and be able to handle the
creation of the plans the running of
those the evaluating at the results of
those and presenting those at all at a
higher level to the ID user is something
that's very valuable that actually like
look like they are this diagram shows I
mean that kind of high level stuff will
only be in phase 2 of ML base the first
phase of it will be really implementing
kind of more than low-level libraries
yeah it's doing yeah so those kind of
things I mean exactly how all the
details of this are going to work out is
still yet to be seen but yeah when so
when you ask for something to be
clustered the planet can end up
generating may end up I mean when you've
asked for clustering you haven't told it
which clustering a laburar to use I
can't really speak to the details too
much but I mean my understanding is this
would be part of mean both yeah right
yeah again these are probably questions
at a better reserved for the guys next
week but the over idea is that you'll be
able to express your desire at a high
level that will actually end up can be
implemented as a plan that's going to
execute potentially multiple clustering
algorithms or multiple other machine
learning algorithms and then be able to
present to you some results of those
that are expressing how well each of the
different clustering algorithms worked
and there's a least one paper out there
i believe i'd have to look of it in the
details exactly he was working on it for
you it's up there I believe there's
from which
yeah I don't know if there's a paper
specific to what you're asking about but
I think there is at least one paper out
there on mo base there should be a
believe this an ml based web page is
accessible off from the main app 11 page
as well yes sometimes these papers are a
little bit in a tricky to find but I'm
sure the guys next week will be giving
you an awful lot more of pointers as to
what's up yeah and some of this stuff
has actually introduced it on amp Lev
retreat in just over this past couple of
days and not all those details have been
public released either anyway you should
hopefully at least from that you can get
the basic idea of being able to express
machine learning queries in kind of the
same fashion as what you express sequel
queries and so these low-level libraries
that will be in the first phase of
development that was actually end up
being conceptually somewhat similar to
like mahout or other machine learning
libraries that are out there that are
Hadoop specific but these will be the
spark specific and then able to be
optimized for the way spark can handle
things in memory and such so now we're
starting to get off in kind of really
into the research fringe with something
called blink DB and this is all relies
heavily upon using approximate answers
to your queries which becomes important
Aleksei yeah it's a research effort now
you're not going to see a lot in the way
of really anywhere close to production
rutted code for a while and this post of
yarn Stojko up at the amp web is thomas
pretty much when i'm covering tonight
but in more detail it's kind of a it's a
good motivational paper but we're still
not seeing anything in the way of
details about how things are actually
implemented so the problem that we're
facing right now is that the rate of
growth in the available computational
resources it pretty well understood me
that's going by Moore's law essentially
you have a pretty good idea of how much
more computing power you're going to
have two years from now
right now but we're also starting to see
that the rate of growth of data is
actually exceeding Moore's law and I
mean at first you think that well we're
doomed at mean we're just going to get
overwhelmed by the amount of data that's
out there is no way we're going to be
able to keep up with it but if you start
to look at the key insight this problem
is that right now we're generally
computing exact answers to things we go
through all of our entire data set and
run a clustering against it or something
or do some sort of machine learning
algorithm against the entire data set
and that gets us as good an answer who
could possibly get but I put the exact
in quotes because it's still really not
a perfect answer because our data sets
aren't perfect there's a certain amount
of error present in the data so what's
the point of computing this exact answer
when statistically there's still going
to be error present of whatever you
compute and so most the time approximate
answers are good enough if we can define
to know that we're going to have our
error bounded by a certain amount it's
usually actually maybe that's what we
got with our exact answer before we just
were kind of hiding the fact that there
was error involved and to create
approximate answers you don't need to be
looking at the entire data set you're
going to be looking at just a sample and
what's really important is that the
growth in the sample size is needed to
maintain a certain error bound actually
occur is much slower you know what
Moore's law it says so if you're if you
get twice as much data two years from
now you won't the size of the sample
that you will need to create the same
error that you did before will not be
twice as great and so Moore's law can
actually more than keep up with a rate
of sample size growth even given the
higher rate of overall data growth that
we're seeing so what actually ends up
happening is that we're not doomed we're
actually better than saved because
because we're more
giving us is increasing faster than what
the required sample size is we can
actually improve the accuracy of our
results over time that's one option and
that's kind of what this graph at the
bottom is showing you Moore's Law is
going in the gray there which is
probably hard to see data is going up
with a green line but the actual size of
your error is actually decreasing over
time the other option you can take is to
get the same level of accuracy just
faster or you can start to run
additional tests additional queries
against the same data and so that will
hopefully give you much richer insights
so the whole point of all this is that
if you can architect your system be
using samples and approximate answers
actually your future is looking pretty
good even though the amount of data is
increasing at this seemingly
insurmountable rate I mean it's really
not a problem as long as you can handle
approximate answers and samples so right
so when we're going back to this look at
blink TB is now implemented kind of
above shark and hive so the idea is that
it's going to be another SQL kind of
base query so you're going to have
sequel queries that will then be
expressed with an error bound and a time
in which you want to get an approximate
error as her back and like I say that's
just one kind of research effort that's
out there but it's worth really keeping
an eye on me this is a pretty key idea
going forward so it's not just blink DB
that you need to be looking at but how
other systems are going to be answering
this approximation and sample size
sample size kind of problem in the
future so now we're actually up to you
those are the four pieces that are
coming out of the amp web and now i'm
actually going off into the piece that
I'm more directly involved with so
that's outside of the amp web
and the problem we're facing right now
is that we need to be able to improve
the code bases out there but we're
starting to step on each other's toes
and try to do so so sparking related
khodam and things like shark and spark
streaming tachyon it's like I said
before it's actually a surprisingly
small code base so that means it's
pretty easy to understand it comprehend
it and the development community around
it is pretty open and friendly so it's
pretty easy to get started using it and
there actually are a quickly growing
number of contributors to the code base
but the smallness of the code is
actually a problem for us as well
because everybody's crammed into this
one small piece of code and so we're
starting to bump into each other more
and more and so who is this we that
we're talking about they're running
these problems well a couple of years
ago it was just grad students and
faculty over at the amp web but that's
starting to expand now that the amp lab
itself has hired on a group of staff
developers they're headed up a guy named
Matt Massey so if you're an Android
developer wanting to use the Berkeley
data analytics stack that's a good guy
to know and his group was kind of test
with turning this amp web code into
production production ready distribution
so being able to easily deploy the code
make sure it runs 24 7 all those kinds
of good things that are typically
associated with research projects out of
academics but the apple app is starting
to try and push it more in that
direction and the that groups also has
the task of maintaining developer
relations with outside developers then
there's also academics outside of the
amp lab there's some of them other
groups at Berkeley at are using it and
this actually been a few papers that
have been contributed they can't
remember where the guys from is a very
interesting paper out there God sparkler
that was contributed from a group
outside of berkeley and matei sahara
himself who was the lead developer on
house park he's finishing up his PhD in
the next month basically and has
announced yet precisely where he's going
but he's sticking in academics so he'll
be another academic that's outside
Berkeley so those folks need to be
coordinated more into the development
effort and then there's a whole set of
industry developers like myself who are
contributing code directly back into
these open source projects so this we is
now starting to get organized we need
some sort of road road map to enumerate
and prioritize all of our development
efforts and we started to recently see
more communication of what the amp labs
roadmap is if you look at that video of
the attack I made up Randall actually
went through and give you a pretty good
idea of what's coming next in
coordinated shark and sparking tachyon
development so we're starting to get
more information directly from the amp
web on that and that's really not
sufficient because we are certainly
getting more and more people
contributing code from outside the eff
blab to the point where there actually
are more non ample app developers
contributing code to spark and related
projects and what there are actual
developers at the amp web and yet the
needs of us outside developers our needs
and priorities they're not always the
same as what the amp labs are now it's
been pretty good so far we haven't found
any real conflicts but we still need to
have some way being able to express the
coordinates the needs of Industry as
distinct from the amp web so what we
need is a wider roadmap something wider
than just the amp labs ideas of what
should take place next and that's going
to include all these community efforts
and contributions so that's actually
something I've been involved with over
the pet
a couple of months is organizing
organizing and coordinating kind of a
steering group now that's in quotes
because we haven't really decided
exactly what to call ourselves yet but
gives you an idea we're trying to
present some sort of coordinated
roadmaps so the steering group is kind
of composed of was people from the amp
lab but it's also a collection of
industry developers some companies that
have been contributing heavily to the
spark and shark code so we first met up
almost a month ago now to try and put
together our first job was to try and
put together this kind of community
roadmap so these are some selected items
off from that roadmap things that we
added kind of to the amp labs list of
the things that we want to see next one
of which is a job progress indication
right now if you kick off a job into
your spark cluster you basically get no
feedback as to how far the job is
progressing you don't really know
whether it's crashed or whether it's
making good progress or just what's
going on another piece that we want to
see soon is more general cluster
monitoring them about the health of your
entire cluster which knows are up which
nodes are down how much of their CPU is
being used and all that sort of thing
getting T I mean I was kind of envying I
all she was talking about being able to
you with just a couple of lines being
able to deploy a new Hadoop installation
for them we'd like to be able to get the
same sorts of things working within
spark and shark and related stuff and to
do that we are looking at using a chef
or puppet scripts making those available
yes don't so the first phase this was
just kind of all of us agreeing on which
things need to be done and which kind of
somewhat a rough idea of the priority of
the priority of them and then it's so
we're kind of working next well not
quite working on it yet but the next
step will be figuring out who was going
to be working on each
one of these different jobs so it's more
just at the stage of what jobs need to
be done at the moment and the next step
will be who is going to be actually
doing them some of them people have
started to do pieces of them but like I
say the problem of us stepping on each
other's toes is present that's there can
actually multiple groups and starting to
work on the same piece and now we've got
to kind of back up a little bit and
every coordinate those yet another
possibilities to work on the it's
possible to run spark is a standalone
cluster now so it doesn't use that may
associate other kind of resource sharing
a framework underneath it just takes
over the entire cluster which is really
nice on kind of development or testing
kind of modes where you're not really
worried about sharing an entire cluster
in production use you just want to be
able to implement something fairly small
against me maybe even against virtual
machines on a single laptop or something
like that or against a small test
cluster but there are actually it's in
certain situations I mean if you want to
run in production and you don't have any
need to run another head tube or MPI job
or some of these other things if it's
perfectly fine with you taking over the
entire cluster there's really no reason
why you shouldn't be able to use this
spark standalone cluster in your
production environment as well the
problem is is that that's not really a
high availability environment right now
if you lose a master node you've lost
the entire cluster so one of the guys
it's in part of this the steering group
has actually done a fair amount of work
already with acha clustering and so he's
looking at starting to implement high
availability within the spark standalone
cluster mode then yeah how your data set
gets partitioned across your cluster is
there's room for improvement there and
yeah there's other things upcoming as
well but this we this steering group is
really not meant to exclude any of the
rest of you we
we think that a small group like this is
useful in order to be able to conduct
discussions where I mean we're intending
to continue meeting kind of on a monthly
basis and be able to make some rapid
progress within a small group but yeah
so the first step is if you actually are
have been contributing code or think you
will be contributing code in the near
future and you think that you should be
part of this group go ahead and get in
contact with me we haven't formalized
procedures for admitting people to the
group or even worse kicking them out of
the group but so now actually is a
pretty good time to try and get involved
with it if you think that's where you
want to be but this small group is not
meant to be some sort of secret society
that's going to be making all the
decisions for spark and shark and we're
going to say what's going to happen and
the rest of you just have to live with
it that's not at all what we have in
mind so your contributions are still
prized and we're going to be trying to
make it easier for you to productively
contribute to the code and still
function in this coordinated manner so
that your stuff doesn't get rejected
because it's conflicting with somebody
else's or whatever so as part of that
the amp lab is going to start to use
make much wider use of their juro system
which up until now has been mostly just
a bug reporting system but we're also
going to start to see more larger or
design kind of oriented issues being
posted to JIRA and be discussions of
them there and yeah so there's the URL
for that and like I said we had this
first meeting of this smaller group a
month ago we generated some raw and
documentation out of that that we're
actually we're supposed to have it
available for you already by this point
to kind of flesh out more some of those
bullet points that gave you some of our
ideas of what needs to be done and then
so it get fully descriptions of the
problem sets we want to work on I get
zero issues for those opened and be able
to carry out more of the community its
discussion of though
we're not quite at that point yet but
the intent and very much is for the
results of these monthly small group
discussions to within a couple of weeks
be available to the wider community and
get a larger discussion going as well so
yes all that stuff will be coming out in
a wiki that would be hosted over at the
apple app as well and I think that's
about where we end up with except of
course that clear story is also hiring</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>