<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Java EE 7 Platform: Boosting Productivity and Embracing HTML 5 | Coder Coacher - Coaching Coders</title><meta content="The Java EE 7 Platform: Boosting Productivity and Embracing HTML 5 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Java EE 7 Platform: Boosting Productivity and Embracing HTML 5</b></h2><h5 class="post__date">2013-08-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gtNhGOILpYU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is arun gupta and i work for
oracle this talk is about java ee 7
platform how it can help you improve
your productivity and what are we doing
as part of the platform I was thinking
well we have two options and we can go
either way by a show of hands the two
options first of all are I can use
slides talk through them and show you
exactly you know what's coming in there
or the other option is i can use no
slides absolutely no slides i can let
the code do the talking i will show you
bunch of code and show you exactly how
the whole thing works so option one two
hands first slides option two i guess
this is a developer conference so no
slides okay this is purely then a code
driven session and as you can see i have
NetBeans open live now this is 731
development release what I'm going to
talk over here is well first of all java
ee 7 is a major major update of the java
ee platform java ee 6 was the last one
it was released in december of 2009 so
over three and a half years ago and java
ee 7 is now ready for launch next week
literally june twelfth is when the
online launch is going to happen as part
of that we have added four new
specifications to the platform so there
is a first-class support for building
web socket driven applications and i'll
show you how we do that i will show you
how there is first-class support for
json processing i'll talk about that how
there is support for batch applications
you no longer need third-party
proprietary api's anymore and there is
support for concurrency utilities so
once again json web socket concurrency
and batch that's the new functionality
coming in sat part of the java ee 7
platform and then jax-rs to JMS to have
been majorly updated i will show
features of that what are we doing or
exactly around those lines in terms of
now in java ee 6 we introduced this
concept of a web profile so we're
profile is what is targeted toward
in a application of modern or modern
application development like let's say
if you don't need GMS and rmiii opie
interoperability and things like that
now you can just do web profile small
size you know 30 megabyte download and
you get started with it quickly same way
we have a web profile as part of java ee
7 as well and the three editions really
to web profile our first of all is
jax-rs 2 point 0 jax-rs is the first
edition no in java ee 6 it was not added
primarily because of timing scheduling
constraints and then in addition we
actually surveyed community members on
what other technologies they would like
to see as part of a profile so JS on and
web socket are also part of web profile
as part of java ee 7 so that sort of how
the web profile in the full platform
works and all now if you need badge
concurrency the whole thing then of
course you can have the full platform
implementation of java ee 7 with that
let's get started
so I have a whole bunch of samples about
200 plus samples I'm just going to go
through all of them in one hour but my
goal is to going to pick and choose
certain specific ones which will
highlight what the capabilities of the
platform are so the first one that I
want to start with is like a WebSocket
one and if you were at my web socket
talk then this would be sort of a repeat
from that but the idea is what is web
socket WebSocket gives you a full duplex
bi-directional communication over a
single TCP channel which is way better
than traditional HTTP rest because I
know it's a single TCP connection you
don't have to establish a HTTP
connection or a TCP connection every
time you want to send a request you
don't have to send those chatty HTTP
headers none of that Nate requires
WebSocket is a very lean protocol
specifically with these days you know
with html5 gaming mobile gaming you know
low bandwidth this is very very
efficient so what I'm going to show you
is a simple application which allows you
to build a collaborative whiteboard the
idea is collaborative whiteboard but can
be very easily extended to a online game
for example two players playing across
the Internet let's play the game first
and then I'll walk you through the
source code as well
and here is how my game looks like well
last one browser what I'm using here is
chrome and I can bring up the same game
in Firefox as well so on the Left what i
have is chrome browser on the right i
have firefox these two could definitely
live across internet all those things
that is very much a reality this
application would run on any html5
compliant browser as such okay now let's
say in terms of the game whatever I am
clicking here is getting reflected on my
other browser as well I can change the
shape here and then gets reflected as
well I can change the color here and
that gets reflected too so whatever I am
clicking on one the idea is if the two
players playing if they're clicking on
either of their games that clicking
either of their game screens that would
get reflected in other browsers or the
other other players grain screen now
same thing if I go here if I click a few
squares here I go back here the same
squares are reflected here so it's
literally a two-way communication
applying to server server to apply now
what happens if you go offline let's say
you're saying you know I'm not connected
to the net now or no I lost the
connectivity very typical then let's say
you change the color you click around
whatever you're clicking is not getting
reflected on the other browser now let's
say you know you do come back online but
now even though the state is both online
but the games are out of sync so how do
you update the other player so you send
a snapshot okay so a typical concept but
what I'm going to show you is the code
behind this to help you understand how
websockets work
so first thing you know if you want to
build a web socket you have to have a
web socket endpoint in terms of endpoint
the web socket API or Java API for web
socket allows you to define a web socket
in point annotated or programmatically
what I'm using is an annotation so line
57 is what is my server endpoint which
says okay this is this poor Joe is my
web socket endpoint and this is
available at the URI / web socket now is
specifying the URI where my web socket
endpoint is listening now a WebSocket
can send a text data or a binary data
but you may not want to deal with the
text and binary data and its raw form as
in raw text and raw binary what you want
to deal with is how I can convert that
text / binary data easily to my business
domain objects in my case it's a figure
object so effectively what's happening
in my html5 canvas every time I am
clicking I am capturing the shape the
color and the X&amp;amp;Y coordinates of where I
am clicking I am building that as a JSON
structure sending it over to server but
that's text you know do I need to can I
have a json parser library to deal with
that no so that's exactly where your web
socket encoders and decoders come in as
part of that what you're saying is I
have a decoder which will take my json
text as is convert or decode that text
to a dojo similarly if I am sending a
response back I may be sending a
response back as a figure object in that
case I will have an encoder it will take
a figure object and encode it to the
json text so my encoders and decoders
are specified here I have lifecycle
callback handlers in web socket which
says if a client is connecting to my
endpoint call this callback handler or
if any client is connecting to my
endpoint call this callback handler in
this case what I am doing is I am
maintaining a set of sessions session is
my client endpoint or the client that is
trying to connect to me and all i'm
doing is i'm adding that session object
to the set similarly on on clothes
which is line 69 Here I am saying em
time our client is disconnecting remove
it from the set so the idea is at any
point of time the set has the complete
set of clients that are connected to you
now as I said we have the json text
going back and forth but I want to deal
with my figure object so what I'm doing
is I have my figure object if you
receive a WebSocket message then you
want to dispatch that web socket or you
want to have access to the payload in a
business method and that method really
is identified by add-on message
annotation which is line 74 now is shown
number here our line 74 now what I'm
saying is this is the figure encoder
decoder I am receiving a text data this
encoder and decoder encodes and decodes
from text so this method will be
dispatched if I receive a text data that
can be encoded to figure and so this
method is called and in this method
effectively all I'm saying is I'm
iterating through all the clients that
are connected and I'm broadcasting the
same shape figure XY coordinates to all
the clients which then refresh
themselves similarly if WebSocket sends
binary data in our case the binary data
is when we click on the button send
snapshot in that case is just taking a
html5 canvas a snapshot of it and saying
send this as a byte buffer or array
buffer array buffer is a JavaScript
binary type now that is being received
as a byte buffer or even as a byte array
and your PO Joe endpoint here so that's
sort of your PO Joe code here if we take
a look at the index dot JSP that itself
is pretty vanilla nothing fancy there
just got some headers my canvas here
then I got some radio buttons you know
this is color shape and then I got some
buttons which says you know you want to
say an instant or set a snapshot and
then i have my web socket JS file
if you want to connect to a web socket
end point you have to use the URI called
as WS colon slash slash you don't use
the HTTP uri scheme now the moment you
say WS colon slash slash it do the data
hence it does the connection negotiation
in the sense you know there's a
handshake defined in the WebSocket
protocol which is ok you can take an
HTTP connection upgrade it to a web
socket and then do the WebSocket
protocol exchange after that the moment
you know you create well first of all
you make the URI which saying host port
path name etc this is the URI where my
endpoint is listening then you say a new
web socket this is a new JavaScript API
which allows you to make a connection to
a WebSocket endpoint very easily well
this is the only way that you can do
connection to WebSocket end point today
I'm setting the binary type as array
buffer just the way i have on Java side
i have my callback handlers same way i
have callback handlers on the javascript
type and i'm setting those if i look at
on message for example in on message
that means i am receiving a message once
you receive a message all i'm saying is
oh if the data type is string that means
i know i just need to update a specific
object in my html5 canvas and FM
receiving a snapshot that i need to
update the entire html5 canvas so that's
the on message but if you look at send
text and send binary those methods are
pretty simple just safe web sockets send
WebSockets end and the only intent here
is to kind of highlight the semantic
nature of it the syntax is exactly the
same
now looking a little bit more at the
Java code so this is my figure decoder
which says I'm going to decode a text
message here essentially taking a string
converting it into figure and in this
whatever your logic is in this case what
I'm doing is I'm using the standard JSON
parsing API which is again a new API
added to the platform to take the string
data converting it into a JSON object
and letting it populate the figure
object okay so that's my simple sample
of web socket okay let's take a look at
another sample the next thing I'm going
to jump on is a simple batch sample now
batch applications is a standard way the
batch API is a new API added to the java
ee 7 platform it allows you to create
batch applications using standard API so
you don't need to use you know any of
those proprietary api's with this
anymore now in terms of batch it defines
the concept of oh there is a job
operator which knows how to operate the
job there is a job repository where all
the jobs are stored there is a job
definition which is effectively defined
as a deployment descriptor for a job XML
and there are reasons to do that but
those are the basic concepts you know
that are very well known in the batch of
world effectively now in addition the
batch API defines two concepts called as
chunk and Bachelet the chunk is a
concept where no chunk is more like item
oriented processing where you read an
item you process an item and then you
aggregate it for writing so you read and
write an item we read and process an
item multiple times and then you give it
for aggregation to writer and then
writer writes it out think about the use
case where you are reading the records
from a CSV file so let's say you are
reading the record from a CSV file
processing it in the sense validating it
you know is the record valid or not
valid and then you're saying okay I'm
done validating you give it to writer
for an aggregation you do that maybe say
10 times read process read process and
then in the writer when you have given
it for every have given it for
aggregation it will probably make one
database call to write those validated
records now in that process there are
mechanisms by which you can say oh this
record is not valid so don't write it so
it won't be aggregated you also have
mechanism to saying you know that's the
last record I want to process there are
mechanisms for that very straightforward
the entire chunk you know read process
and write all of that is inherently done
in a transaction so the idea is there is
no need for you to explicitly start a
transaction that's completely inherent
just works out of the box there are and
think about if you are reading likes a
million records I know and if you have
done like 800 thousand records and let's
say an error occurs over there so same
thing you know in the chunk concept
there is a concept of checkpointing if
you by default it reads 10 items like
you know reads process read process 10
times and then writes those 10 items if
you have changed the chunk count or item
count so to say to say 100,000 then
there is automatic check pointing that
is occurring as well and you can resume
from the last check pointed item now
chunk is one way by which you can do you
know that's the preferred way of doing
batch processing there is another style
call as Bachelet which allows you to do
a custom roll your own sort of a batch
processing job not going to focus more
on that because the preferred style is
back chunk so let's take a look at junk
the entry point to any batch job is a
job XML is defined as a job XML and
there's a reason we stick around with
Joe of XML here because well first of
all a lot of it is borrowed from spring
batch so if you have if you've been
dealing with spring batch you know this
would be a little bit familiar the
reason we stick around with XML in this
case is because there was a discussion
in the expert group to use only
annotations but then the job could be
really complex and capturing that in
annotation would be really really tricky
so in the first version at least it's
only deployment descriptor based maybe
in the subsequent versions we will take
a look at it if it could be done using
annotations it's basically defining a
new dsl all together now here I have a
simple job this job has one step but in
a typical job that you want to run there
will be multiple steps we could have
multiple steps within the job there are
full complex workflows decisions all of
those concepts are available to define
as part of your job now this job has one
step and the step is of the type chunk
by default as i said the item count is
10 in this case I am explicitly
overriding it saying it's three that
means i'm going to read process read
process read process that's three times
and then i'm going to write those three
items at one go now i have reader
processor and writer items over here and
they have references those references
essentially our CDI be names that are
bundled as part of my war file now this
is a simple web project deployed as a
web archive so in that web archive
somewhere I have you know those beans
and those beans have their names
resolvable to these names now if it's in
a war file then your batch XML or job
XML has to live in the meta in slash
bash Dash jobs directory that is the
specific directory required you also
give it a name like my job xml we'll see
where that my job is being used okay so
first of all let's take a look at my
reader processor and writer
this is my item reader very simple over
in this case is just extending a
convenience abstract class you can
always implement an interface if you
want to implement all the methods I have
a open method that I'm overriding here
in this case this is exactly where you
initialize your resources you know
whether I'm going to read from a stream
or a reader or from a queue or whatever
it is for convenience I am just using a
stringtokenizer you know just for
simplicity no big deal now read item is
the method that is returning the items
as they are being read so effectively
let's say in your open method you have
opened a stream which is a CSV file
that's where your your stream is open in
the read item you will read line by a
line and you will read one record at a
time or we will return one record the
idea over there is you have a true
separation of concerns in reader you
read the record you're not processing
the record in any sense if you go to
processor just implements an interface
single method over there so whatever
item you recover whatever item you
return from read item is automatically
available as a method parameter over
here so in this case all I'm doing is
well let's take a look at read it once
again so this is a stringtokenizer from
one to ten so effectively I'm returning
one two three all the way up until 10 so
I have 10 records and I'm just creating
a my input record over here in this case
if I take a look at my input record it
just takes an integer identifier and
returns the value here if I go back to
my processor so effectively in my
processor even though it's synced object
but i'm getting my input record here now
from the my input record i check weather
is the ID is odd or even if it's even i
reject the record by returning null
right here and if it is valid if it is
not that means it is not even then i
create a new output record my output
record is very similar nothing fancy and
i just see
integer constructor all those things but
the whole idea over here is in your
process item method which is on line 52
you could receive a different kind of
record and you can return a different
kind of record all together for example
in a CSV thing I could return receive a
string and I could do the processing of
the string and of splitting up their
records and I could generate a jpa
entity and return from here so that is
truly the model that we are planning to
support here or that is intended to
support now in this case all even number
of records are rejected odd numbers are
returned and what I'm doing is I'm just
doubling the value of the odd number
records now if i go to my item writer
here again I mean extending a
convenience class the right items method
takes a list this is where the
aggregation happens automatically you
don't need to aggregate it you know I
mean as long as you have implementing
the right interfaces the item that is
being read is automatically passed from
reader to processor and from processor
to writer for aggregation and as soon as
the item count that is defined in our
job XML is reached you know that entire
thing with reader processor writer you
know that writer triggers writes it to
the data store in this case I am just
printing out the values and then the
transaction is committed so all of that
is inherently transactional with
frequent checkpointing so if I were to
run this well that's how all the
artifacts are hooked up together let's
see how we trigger the job first of all
in this case I have a simple servlet the
code may look a little bit convoluted
but this is a sample here line 85
basically what I'm saying is I am saying
to the batch runtime give me a job
operator okay so this is the only code
the highlighted code is only one that I
want you to look at so I am saying to
the bachelor on time give me a job
operator and to the job operator I'm
saying start my job and when I'm saying
start my job I'm actually giving it the
type the string called as my job that my
job is the same thing if you remember is
the name of my xml file so it picks up
that job triggers the job you know step
chunk reader processor writer Rida
processor writer all that and then
commit to the entire job now I could
conceivably have many many job xmls in
my batch jobs directory and that way
there is a capability by which you can
pick and select the job that you care
about now starting a job returns a job
ID that job ID is your unique identifier
which you can use to abandon or restart
or cancel the job if you want to and
that's what the stuff on the bottom is
doing over here for example I'm saying
show me how many times this job has been
run or what is the job execution status
what is the create time start time etc
so all that metadata is available to you
something that I have not shown you here
is maybe it's worth showing actually
well first of all let's run this job
okay so right click here and say run it
i'm going to start the job here it's
going to start my batch processor the
whole thing in the background does
something return the response back to me
the metadata but what we care about is
the output that is being printed for us
so if we take a look at that so this is
the output that is being returned to us
saying in my process item I am my input
record one two three bird output number
two or record number two is being
rejected one is doubled up to 23 is
doubled up to six so three records being
processed at one point of time first and
third picked up second being rejected
same thing here four five six so four
and six are rejected record number five
is taken doubled up and ten seven eight
nine again record number eight is
rejected and finally you have one record
that's automatically going through so
that's how your automatic checkpointing
transactions everything works by itself
one second
you
so here for example I'm just showing you
another job xml I'm not going to run
this job but in the job I have a step
and it has another step so I could have
two steps and then in this one for
example I'm saying or the my logical
identifier is step one but the next step
that I want you to execute is step two
and in this one step I have chunk and
this step is a bachelor so you can do
those mixing and matching of how the
chunks and the Bachelet's are mixed up
here is another sample of a job a little
bit more complex and involving so for
example I have a step this is all one
step by the way in that step i have a
chunk in the chunk i have reader
processor and writer ok now the reader
is optionally passing certain properties
so start and end so for example let's
say you are all reading from the same
csv file but instead of one reader one
processor and one writer doing the
entire thing i may want to say no reader
I may burn it in multiple threads let's
say for four core machine I may be able
to spin up up to four threads how do you
indicate that in your job xml so in this
case in the chunk itself i've added an
element called as partition as the new
element of part of job xml in the
partition i am saying i'm going to run
it in two partitions and i'm specifying
the properties in the properties i am
saying okay the start value is 1 the n
value is 10 in this case the start value
is 11 the n value is 20 so effectively
if I have say two million records then I
could say the first million records are
being read on one thread and then the
second million records are being read on
the second thread so you're basically
splitting up the job similarly your
processors and writers work accordingly
as well and once again all of this is
inherently transactional there was a
question here yeah so the question is
the well the first question was instead
of saying batch runtime dot get job
operator I would like to see it being
injected I agree there's our Fe file on
respect for that already that's a clunky
job in my opinion the second question
was that the quads team they were kind
of afraid of going down the work flow
route because you know there is not just
workflow there lot of other components
get involved as part of it and that was
a comment but the question really was is
this really becomes out of the workflow
and are there bigger discussions
happening around how a broader workflow
could be defined as part of Java EE so
the answer to
that really is in this case in batch at
least now this is only for batch we have
what I'm showing you is a simple
partition there are concepts of
decisions splits flows all of that so
all of that discussion has happened
within the context of a batch for now at
least now in terms of Java EE eight I
don't think is on the table yet but that
does not mean it's not going to get done
as part of Java EE eight because really
we are just to focus right now to
deliver java ee 7 which is going to be
next week and then after that all the
discussions around the scope and you
know what features do community care
about would be on the table at that
point of time but yeah batch already
supports and it's not a full workflow
anyway you can actually use your
decisions splits flows but that's purely
within using so that's purely within the
context of batch for example oh this job
failed so what you should do that but
it's not and there are concepts by which
it can delegate to pojos as well for
making those decisions but purely within
batch concept
alright I'm going to start with a new
sample here let me take show you some
JMS improvements that we have done now
JMS the last version if you realize was
done in december of 2003 so like jameis
1.1 so almost 10 years ago JMS two point
O is a big big big improvement on top of
JMS 1.1 most of the work has been
focused on simplifying the API making
sure we leverage all the modern language
features from the Java from the Java EE
platform so that's been the focus
primarily specifically leveraging CDI
pretty significantly so let me actually
if I can show you a different sample
now JMS 2 point 0 supports both the
older style API and the newer style API
the older style API is called as a
classic API and the newer style API is
called a simplified API we have to
maintain backwards compatibility so this
is the code that you have to write to
send a message using JMS 1.1 and i'm
sure you can improve the code but try to
understand the points here first of all
online 58 I am doing a lookup of the
connection factory online 5061 I'm
saying okay this is my destination where
I'm going to send the message then I
have a send message method where I am
doing you know honoring the API Oh from
the connection factory create a
connection then create a session then
create a producer then a text message my
real intent is only line 71 I just want
to send the message but you have to
honor the API the way is being defined
and then there are checked exceptions so
you have to make sure that the
exceptions are caught properly and then
you need to close the resources so whole
lot of boilerplate code that you need to
write just to get that job done let's
see how we have improved that as part of
GMS two point oh that's all the code
that i need to get it working okay to
send a message let's take a look JMS
context is a new object introduced as
part of GMS 2 point 0 which basically
encapsulate syou're connection and the
session object that exists in classic
api or the older api so all you need to
do is instead of saying i want to create
a new connection or a connection factory
nothing of that sort you just inject
your JMS context the container will
automatically inject it for you it's a
container manage context effectively
then of course you need to point to your
destination but in addition you know
this destination could actually be
created as part of your application
itself so we have introduced new
annotations called as JMS destination
definition if i can show that to you for
a second
so I have this new annotation called as
JMS destination definition this could be
put on any of my you know EJ bees or
servlets etcetera and then there I am
specifying what destinations need to be
created so as part of your application
deployment these destinations would be
automatically created for you so for
example in my application here if I take
a look at not here but right here so in
my say simplified message receiver I
have the JMS destination definition I
just put the annotation I put the name
and the interface name that this is a
queue and that's it then this will
automatically create my destination for
me but of course you can go the
application server specific way use for
example glassfish CLI or admin console
to create this but this simplifies it
lowers the bar for you now going back to
my sender simplified message center ok
so first of all I inject my JMS context
here now notice I am not pointing to a
connection factory here and there's a
reason for that because the spec says if
you do not point to a connection factory
then we automatically use the default
connection factory first of all the
platform itself defines a new default
connection factory not only a new
default connection factory it even
defines a new default data source for
you so for example if you were to
injecting a JDBC you know if you want to
inject a persistence unit or in a
persistence unit you want you don't need
to refer to a JTA data source there is a
default connection source that it will
point to which will point to your
application server specific jdbc
resource so all of that completely
automatic and I'll show you a sample for
that coming back here actually I'm
injecting my JMS context I am pointing
to my resource that is created by my
application then on the context and we
are using a fluent api
your pattern so on the context I create
producer then I say send to this
destination and that's the message no
more wrapping you know everything is a
runtime exception you take care of it
only if you want to the resources are
automatically closed for me so we're
actually making them an hour try with
resources completely basically
implementing order closable interface so
not only the amount of boilerplate code
is cut down but it actually improves the
semantic readability of my code I can
look at the code I don't need to comment
it anymore in this previous case yes you
will need to comment it and one of the
funniest comment typically goes over
these two parameters because we say that
in if well in this case I'm doing it in
ejb so the ejb spec says if you're using
classic API I'm going to ignore those
two parameters why go as the Egypt is
speculated on that but that's the nature
of it ok so those are sort of my
improvements in JMS
let me show you a simple sample on what
improvements we have done for Jason
actually
so what I does just did was i invoked
facebook's public api and i am searching
for the keyword java saying such for the
cute query java on all the public post
and it returned me the result set that's
returns null set comes as a JSON
structure so this is a fairly
comprehensive JSON structure data array
with bunch of name values with nested
objects etc ok i'm going to show you the
json processing api that has been added
to the java ee 7 platform how we can use
well first of all in json processing
itself there is a streaming API which is
more lower level API we generate events
start object and object start of an
array so on so forth and then there is a
higher level object API which allows you
to read the entire structure as one full
object then you can index within the
object very easily so here for example
let me show you what I'm going to do
with the object API same URL i have
mentioned here then I'm opening the
stream I'm creating on my json reader
that's the new API by the way is in Java
X J's on package then from the once I
get my reader from the reader i read the
object but once i have read the object
the entire structure is read into the
memory and then once i once it's in my
memory then i can say ok give me the
JSON array then I can start indexing
okay from the array I want the from
element which from which I want the name
element so get JSON object get string or
I want the string message okay so that's
the object API in terms of the streaming
API similar start I basically point to
the URL i get my json parser in this
case not a reader but once i get my json
parser i can actually listen for the
specific events that i care about that
didn't mean the parser is reading
through my JSON structure is going to
spit out events like key name ok oki
name encounter it don't it doesn't care
what key name it is it just knows it's a
key name because Jason is basically a
finite structure which stays exactly how
this is going to look like
so here it generates a key name event
that's the even that's the event that I
care about then on the key name I say
okay show me what is the key name now
what I mean the real key name if the key
name is name or message then I want to
do something about it and effectively
what I'm doing is so once I know the key
name then go to the next element which
is partial dot next and now if the
element next to key name is the value
and I am saying give me the value and
I'm printing it out so you can see there
is a streaming API there is a object
model API for JSON processing very well
integrated as part of the platform
okay make sure one more thing here
we talked briefly about you know how the
how we have a default data definition or
data source as part of the java ee 7
platform now typically when you're
building a Java EE application is
typically a database-driven application
so you would need some sort of a
connection to the database most of the
runtime requirement for a java ee 7
container is to ship with the database
so if you ship with the database then
typically your application server would
provide your specific JDBC resource but
then that's application server specific
you know you don't know what that name
is going to be in some cases is JDBC /
sample some cases jdbc / example but
then your apps break you know that means
they don't work out of the box so here
for example I'm using JD JD a data
source called as JDBC / sample now yeah
that would work out of the box on
glassfish but that doesn't make my
application portable so the idea here is
if I get rid of this JD a data source
then my persistence dot XML actually
maps to a default data source that's
what it automatically resolves to the
start of the JDBC name now what is the
underlying JDBC resource that is
application server specific from your
application perspective you don't care
about that all you care about it is
automatically connecting to the default
data source what is it ready bc resource
you the application server you go figure
it out so that's you know improves your
application portability these are older
properties I do want to show these one
second
well okay
okay that's where blocking helps this is
one of the blogs that I did on jpa two
dot one schema generation properties
what is that feature that feature is
primarily about how you can take a look
at a JP entity and ask your persistence
provider to generate database tables
from it now up until now like jpa to we
could take a database table and create
jpn it is out of it that is possible but
there was no way or at least a portable
way to say take my entities and generate
database tables out of it or generate my
database scripts out of it so with JP a
2.1 you can actually do that so there
are properties like java x dot
persistence not schema generation or
database action so all I'm saying is in
this case just drop my tables and
recreate them and that's the action
that's nothing interesting I'm saying
okay fine I can do that but should I do
that using scripts or that means you're
going to bundle the scripts with your
war file or should I do that priory
using your JP entities so you take a jpa
entity you understand what the meaning
is out of it and then generate the
database tables out of it so that's
possible here for example I am saying
java ex persistence schema generation
scripts dot create target that means
whether it's going to be yeah so here I
am saying what are my scripts that will
generate the database table which is
basically my DD l now you can bundle
that as part of your application and
that will automatically be taken care of
by the persistence provider similarly
dropping the tables not just that you
also have a DML or data manipulation
language that can be specified so think
about shipping a simple sample
application or getting started with it
you know you can bundle your ddl your
DML fully indexed you know all of that
package within 1 45
and then giving it or deploying it on an
application server and application
becoming complete live at one instance
one of the places where we have made
huge improvements is JTA JTA 1.2 well
not just JTA but sort of making the
platform lot more cohesive and
integrated you can do user managed
transactions today very easily you can
just inject a user transaction object
created commit rollback all of that is
possible but if you want to do container
manage transactions that was only
possible in using an ejb up until Java
EE 6 we have changed that as part of
java ee 7 so JT a 1.2 introduces two new
transactions one of them is at
transactional or a transactional so that
means you can take that add
transactional annotation specify it on
any POJO CDI bean whatever it is you
specify on any pocho class or a method
and then the underlying container will
automatically start and / commit / roll
back a transaction for you so let's take
a look at that
well not this one here so this is my
very simple CDI beam and you can see
there is no stateless or stateful on
this it's not an ejb as such now on I
have tons of methods here but the idea
is on any pojo I can specify the ad
transactional annotation and it has all
the semantics that the container managed
transactions have in ejb for example
requires required new mandatory all
those attributes are available you can
specify as part of the annotation itself
but once you specify transactional based
upon the sim or the syntax over here the
semantics are automatically enforced for
you so for example in this case is going
to ensure that a transaction is
automatically started and committed at
the end of it okay well I talked about
two new features so let me talk about
the second feature in that case
so here is a simple beam now nothing
fancy about it the only new addition
here is 948 but I am saying at
transactions coped that's a new CD i
scoped introduced as part of JD a 1.2
all I'm saying is tie the instance of
this beam or the lifecycle of this beam
to our transaction that means if
somebody tries to inject this beam
within a transaction give it an instance
otherwise do not give it an is do not
give an instance of this beam so I'm
just saying you know ty the instance of
this beam to a transaction so let's see
how will I use it now i am using ok
first of all i'm injecting this beam
twice here might be in my beam or being
been and been to ok i have three
scenarios well the first one is well in
this case I'm explicitly starting the
transaction and ending a transaction is
a user transaction I'm injecting a user
transaction here so if I am starting a
transaction and ending a transaction
here so in this case I'm saying be not
get ID and beam to dot get ID
effectively is returning the object
identifier because from the beam all I'm
saying is get the ID or return the
object by default it includes the object
identifier so in this case I'm saying be
not get ID and beam to.net ID so even
though the beam is injected twice but
the proxy because the way CDI works you
know if you're saying injection it has a
proxy and it gets the runtime instance
you know when is required so the two
proxies will point to the same instance
because a beam is tied to a transaction
is still the same transaction does not
matter is to proxies but the beam
instance is tied to the same transaction
so the two proxy is point to the same
beam so effectively what I'm saying here
is even though the beam is being
injected twice I still get the same
instance identifier for that particular
beam now here this is a different
scenario remember here I have done
committed the transaction already now I
am starting a new transaction and
committing a new transaction exactly
same as scenario 1 but the difference
being when the first transaction is
committed that beam is rolled out you
know that mean is given for garbage
collection so effectively when I am
trying to inject beam here again or at
least trying to use the beam here again
both the proxies are going to point to
the same instance but that instance is
going to be different from the one that
was from a previous transaction because
it is the new transaction now and
finally once this transaction is
committed that beam instance goes away
and here when I am trying to say be not
get ID then there is no transaction here
if there is no transaction then it says
oh there is no context that is active so
I cannot give you an instance of the
beam so clearly showing that you know
the beam instance is tied to a
transaction you know you just by adding
that transaction scope the beam is
automatically you know activated or
passivated for you so if i run this guy
here
sighs I do this so here you can see for
example this is scenario one beam one
injected twice and the object identifier
in both the cases is d 12 and d12 so
these are exactly same the two proxy is
pointing to the same instance repeat of
scenario one is a different transaction
these two are same but different from
the one over here and finally when i'm
doing a beam outside a transaction is
saying God expected context not active
exception so showing you know how a
transactional and transactions
corporately work with each other another
big improvement as part of java ee 7
platform itself is that CD I or the
context and dependency injection is a
really really core component model you
can see all the changes that we have
done like a transactional is a notation
but effectively the implementation is
done as interceptor binding which is CDI
interceptor binding same thing
transactional scope is a cbi scope so
after receiving a huge feedback from the
community we literally surveyed 1,100
existing active users of java ee and
there was a overwhelming majority for
saying enable CDI by default so for
example in here my webbing if directory
is empty there is no beans or XML I
don't need a beans dot XML to enable CDI
frankly it was very hard for me to kind
of put my head around it when I saw CDI
for the first time like really but why
do we need beans or XML why can't we
enable it by default but you know these
inconsistencies happen you know the CDI
specification itself was introduced late
in the game finally we got it right no
beans or XML required CDI is enabled by
default well and there are semantics
defined and it is enabled for what it
says is enabled for all the bean
defining annotation being defining
annotation what is that it goes into
terms the idea is any bean with the ad
stateless or stateful or with an
explicit CDI scope so you need to give
at least an indication what beans you
want to be injected
so any bean with a beam defining a
notation that is stateless stateful or
CDI scope will be automatically
available for injection okay so in this
case for example if i look at my source
packages i have my beam here on the beam
I just need to put at request scoped I
just made it at request scope and in my
servlet if I try to inject my be well of
course this is netbeans is complaining
Oh CDI you are trying to use CDI there
is no beans or XML what the IDE does not
know I am trying to trick it java ee 7
does not need a beans or xml so here the
injection would just work out of the box
if I were to run it
I say inject the beam I just say get
hello Duke but what's happening is on
the beam I'm invoking the method and
there is no beans or XML you want to
double check it let's do that so go to
target look at my war file look at my
web enough and I don't know why it
included my specific wave XML but no
beans or XML so some of the key points
here as you can see I can go on for a
few hours on this but I think I'm pretty
much out of time and I have about one
minute for any questions if you have any
the question is how does the batch API
impact the existing et al developers or
the existing tool providers so IBM is a
specification lead for batch
applications and that's one thing that I
am trying to figure out because spring
batch is used pretty heavily and that
sort of unfortunately the de facto
standard that people use in the industry
but the idea is there is a very close
similarity between spring batch and the
job XML as a matter of fact there were
folks from VMware who were part of the
expert group who were actually
contributing pretty actively to the
specification so hopefully in the near
future we should have a compare and
contrast kind of an article hopefully
providing a little bit more guidance and
direction on how to get away from spring
batch to batch applications as well
thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>