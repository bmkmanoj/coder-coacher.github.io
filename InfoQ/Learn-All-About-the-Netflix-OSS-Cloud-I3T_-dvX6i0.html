<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learn All About the Netflix OSS Cloud | Coder Coacher - Coaching Coders</title><meta content="Learn All About the Netflix OSS Cloud - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learn All About the Netflix OSS Cloud</b></h2><h5 class="post__date">2013-07-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/I3T_-dvX6i0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Karl Quinn I'm gonna talk
today about the Netflix open source
cloud what would you call it package of
projects platform cloud platform yeah
that's what it's called I was up until a
couple months ago a manager of the
engineering cloud tools team and Netflix
we did a number of projects and tools
and things that I will talk about today
I've since moved on to a company called
Riot Games we have a game called League
of Legends which is one of the most
popular games in the world right now all
over the world distributed online
real-time multiplayer game and we're
kind of in you know our growth is so big
and we're kind of going through the same
growth pains that Netflix went through
you know two or three years ago so we're
also looking at the cloud as a solution
for a lot of our back-end stuff which is
written in Java so a lot of the same
tooling in the same solutions that
Netflix came across are very exciting
it's better one of the reasons that they
pulled me over is like can you do what
you did at Netflix for us all right so
I'm doing that and in a lot of ways this
will help I think prove how reusable
this Netflix code is if another company
can build on top of it so I've broken
this talk up into some sections where
I'll first give you an overview of of
the project's sort of in how you can
find them and how they're organized and
then break down into talk about tools
and infrastructure parts and then sort
of the platform and libraries and in
connection Java kind of related stuff so
the first bit all of the projects of an
applicant source are on github and
they're under so you can just go to URL
up there
Netflix dot github calm and there's a
whole big pretty page full of different
project names and they're currently just
a big pile of names and they're all
mixed up so you have to kind of sit and
read about each one and figure out what
they do but that's it's kind of fun to
explore some of them are tools some of
them are library some of them are apps
services that you run some of them are
samples like hello world kind of samples
other ones are
like the cloud price so that's exciting
if you're interested in contributing
something back to the open source
project and earning $10,000 prize money
per category that's one of those things
there but today I'm going to focus on a
couple of different areas and so a bunch
of these that are related to some things
like Cassandra and zookeeper are very
interesting but they really are kind of
an entire talk on their own so the ones
that are lit are the ones I'll be
talking about today as you can see yeah
they're all kind of over the place all
of them that result in libraries end up
on maven central so if you're a Java
developer or you're building with maven
or Gradle you can reference them from
maven central and they'll be up there
other ones that end up as worse projects
I think what do you guys are putting
them up on blocks no or no Ben Tre okay
yeah so everything that's a binary
that's not really a library that would
be maven oriented will be on Ben Tre as
well but each of the projects will tell
you about how to go find the bits that
you might want to get and play with so
the master plan which I sort of have
inside our knowledge about the Netflix
master plan for this whole thing is they
really do want to create an entire cloud
platform that any company can use and
pick up these parts and mix and match
and build a cloud infrastructure a
complete cloud application on top of
this and they're already some of the
examples that they have are kind of mini
apps that are intend you know front end
middle tier data storage Cassandra or
dynamodb to build an entire app
service-oriented you know SOA type
application on top of this stack and all
this code came from code that Netflix
built to run their own infrastructure a
lot of it was too you know it's all
taken from stuff that was in production
good quality lots of tests but there's
still a lot of challenges to taking
something that's working fine in your
enterprise and turning into something
that's open source I mean a lot of times
you end up with code that is tangled
with other code that's very specific to
your own
case so that has to be disentangle a lot
of times dependencies have to be flipped
around and code has to be refactored any
assumptions that you've hard-coded stuff
because you know our URLs are like this
or we've got these service names like
this okay you have to make that
pluggable or you know configurable
something so all that work have to have
been done and in some cases they just
looked at the way they did something
that said well we wrote this it evolved
so much now it's really ugly and I'm
embarrassed I don't want anybody to see
my open-source code so I am going to
just rewrite it and so a number of the
projects we're really rewrites to
perform the same function but with the
cleaner code or maybe built on top of
newer dependency injection frameworks or
something where they could make it
starts from a cleaner base and one
saying that I don't know who came up
with it maybe it was Russell and the
whole bit or maybe it was Adrian
Cockroft it says the code is good enough
for production but not yet good enough
for github and so that's kind of one of
the things you want to make sure that
it's this is a lot of people kind of
your resume lives on github if you're an
open source contributor that's really
your portfolio so you want to make sure
and the people that Netflix anybody else
contribute needs projects want to make
sure it's good quality that's going to
reflect on them okay
so the next section I'll talk about a
little bit about the projects that are
related to kind of the structure or
infrastructure of the clouds as you
build it so one of the things that
Netflix does on top of AWS that's kind
of unique is that they build and define
kind of this platform structure on top
of auto scaling group so if we if you're
familiar with Amazon AWS have the notion
of an auto scaling group they don't
always get as much attention as I think
they should every you know a lot of
people look at them and say I'm not
gonna auto scale my my applications I
only need five machines maybe six but
they also provide something that's
that's useful even if you're not gonna
hide a scale you could you can create an
auto scaling group and just say I want
six done and you never change it but
what you've done is you've created an
organizational unit that says these
machines are all doing the same thing
they have a well-defined launch
configuration
that says that they're launched from the
same ami and they have the same user
data and so they kind of get associated
together and so netflix builds on top of
that by using auto scaling groups and
pairs or triples of auto scaling groups
together as a logical cluster and in
order to do that they apply so they want
to really get in and modify anything
with AWS and they wanted the source of
truth to be inside of AWS itself so they
created a very simple store the table
and simple DB I think but moving to
dynamo that uses a very small library
and naming conventions so you define an
application let's say that it really
represents a service in your service
oriented tiers that say I've got a
middle tier that is the search engine
write or query engine and that would be
the name of the application and when I
deploy clusters of that application I
can deploy those into different stacks
but I can tell what the cluster is about
because it is associate with that
application there's a naming pattern
that it uses to kind of parse apart the
auto scaling groups and so that way you
that way you can have some additional
structure and traceability throughout
your machines and groups and clusters
and applications because more metadata
can be included at the application level
now one of the things that's that's also
unique about how Netflix builds at the
cloud is a lot of the assembly of the
machines almost all of the assembly of
the machines in fact getting the binary
bits on to a machine just done at Build
time so if you really think about things
you might do when you bring up a machine
in a data center and you've got it up
and you do that you know apt-get or the
the yum install and you're putting stuff
in there and then you're adding packages
and configuring things a lot of that is
like that sounds like a build process to
me just like you're building your java
code and you're building your wor file
don't you just keep going and keep going
all the way to the point where you've
built your machine right and then that's
a deployable artifact so that's exactly
what Netflix does and they released a
couple months ago
the tool called a manator which is
really a very clever but not even a huge
amount of code but nicely done Python
tool kit that allows you to create a Mis
and also these work with eucalyptus so
the same things you can use to create
EMIs in the eucalyptus world and so what
a manator does the idea is you can treat
this like a part of your build system so
M Nader will run on any machine that's
an e on ec2 itself so it could be on a
Jenkins slave it's a command line tool
you know I just call it from you know a
Jenkins build job if you want or you can
just shell in and run it just a Python
command line tool but it'll take you
identify to it a base image to start
with which could be okay public Ubuntu
or public Amazon you know Linux I want
to take that ami you know mount that as
a volume as an EBS volume on the machine
and then then maybe run yum install or
run chef solo or one of these tools
let's say take a bunch of packages and
put them on to that image right we
haven't even launched the machine it's
just a disk image at that point then
snapshot it register it as an ami give
it a description that you've given on
the command line and boom now you have a
whole new machine defined that's based
upon you know a well-defined starting
point plus a description of what you
wanted to put on it maybe packages from
your build repo or cookbooks from chef
from your chef's repository that you've
put on there so you have traceability
from both you know the Machine the basic
foundational image plus everything else
you put on to it and now you have an
image that's identified it's immutable
and it's just like another build
artifact where you can then test it and
be sure that that image is exactly what
you want and it's reproducible whenever
you launch things from that image you
will get the same bits right the same
version and the cool thing about as a
lot of people say well that just takes
so long we can't bake a new image every
time we want to change the version of a
library we put on our on our server but
what's the only thing only takes three
or four minutes to bake an image it's
just part of your continuous integration
process that you just
make that one more step in there so I
think that's really powerful and in this
flow here you can see we've just made a
new version of an ami and back when I
mentioned clusters earlier let's see we
were running our application and we had
version 1 running it was running in one
auto scaling group we've just baked a
new version we push it out when we run
some tests on it of course in our
continuous integration system and now
we've pushed out a new auto scaling
group for that application or that
service in the cluster and with Asgard
we'll be able to switch around and move
traffic to the new one or move traffic
back to the old one the two can live in
parallel for a little while until you're
ready to completely switch traffic over
you have a lot of control this way about
how you want to scale up or warm up
machines or scale down or manage that or
having the old ones around this case for
failover a lot of flexibility there and
I'll talk a little bit about Asgard so a
scart is the tool it's written in Grails
and it's also open source very easy to
set up and install and run and play
around with this is probably that one of
the first things if you want to play
with stuff and actually run something
this is fun to bring up in your cloud
account and just start poking around
with it because they'll let you see
stuff organized in ways that you
wouldn't be able to see easily from the
Amazon console so here's a sample page
from its we're just looking at
auto-scaling groups the screenshots
probably from somewhere and Netflix's
test account but it will also show you
the associations that I mentioned
earlier between applications and
clusters instances you can drill around
everything that's a kind of a a name or
an identity of another object that you
see on any of these pages in asgard like
on the list page or a details page they
are all links so that you can really
easily traverse and click around and
figure out how things go together really
helps I think learnability of what are
all these things and how they relate to
each other in AWS it's really quite
powerful even even if you're not going
to use this model it's it's a nice tool
to bring up and use just as some
visibility into your cloud and also so
as guard against women I should mention
also these tools do sort of rely on
Amazon AWS api's in this structure
section of my talk but they also work
with eucalyptus and especially so
eucalyptus 3/3 it's coming out in this
quarter it's in I know which milestone
it is now so if in beta right now and
eucalyptus guys will be shipping a set
of the tools that are already
prepackaged with plugins necessary to
make them work a little better and
eucalyptus environment so they're using
a lot of these tools to sort of test
their compatibility with AWS so that I
think is pretty exciting if you want to
build your own hybrid cloud eucalyptus
as a nice solution there so edits
another tool which is the service that
runs this purely restful has no GUI at
all its job is to just scan and look at
the cloud in your particular account or
multiple accounts and kind of keep track
of what's going on so you can either run
it just as an in-memory only where it
will just provide you a query service to
tell you who's out there right now what
objects are there and allows you to sort
of reference things indirectly like you
can ask it what machine is at this IP
address you know sort of can do then a
reverse lookup and tell you what went on
you can also attach storage to it and
it's currently using Mongo for its
back-end and then it records the history
of things which is where it becomes
really interesting so for example you
might have some event that you're trying
to track down some problem that happened
on your machine yesterday at 4 o'clock
for 20 minutes I had a boss you know a
storm of requests that was crazy and I
don't know where they came from and you
can go through here and figure out ok
these five IP addresses were hammering
my machine what are they oh they were
somebody brought up and do some queries
figure out well that wasn't in five
instances of somebody's test cluster
that they brought up with a bunch of
bugs in it and they hammered my machine
so you can kind of reverse look at you
know history of things that happened or
like there's a guy at that right on my
team now it was building a front-end for
it so that he can do security audit
reports he wants to know the history of
everything and
changed and who made the changes or how
they got changed at what time what they
were done for and just so that nothing
funny happens and people start tooling
with things that he doesn't know about
so it's a great tool for that that the
query language that it supports is
really powerful
the bunkies are great so back up here so
the monkeys the simian army there's a
number of the monkeys like the chaos
monkey which is one of the most famous
monkeys the janitor monkey I think is
probably the most useful one for people
that are just getting started in Amazon
it can go through and track down objects
that you've created that you may not be
using anymore and give you reports and
optionally clean stuff up automatically
you can give it rules about retention
and things like that so you know
creating lots and lots of EBS snapshots
that you're not using or am eyes with
the bakery you're making a lot of a.m.
eyes in your continuous builds process
in half of them or more you're not even
going to use but that's fine the monkey
can clean him up when the chaos monkey
as you might already know creates chaos
but the hardest part and the most useful
part of the monkey itself is that he can
be told how much chaos to create and
where to create it and where not to
create it you know leave these apps
alone or leave these clusters alone
because well we're not ready for chaos
yet over here but once you sort of
embrace the chaos of the cloud that will
help ensure that your applications are
tolerant to failure sent to hardware
level like an instance can go down and
every year cluster keeps going that's
that's a good thing to know and the
conformity monkey is the newest monkey
that just came out and he's really about
checking to make sure you're following
certain rules sort of guidelines best
practices about how to organize your
systems and those rules are extensible
so you can plug those in and he'll at
the end generate reports and send mail
to the owners of the applications so you
can look you know look for any kind of
anomalies that come up and maybe how
you've deployed you've done something
funny and and he'll give you a report on
that there is a dashboard that Netflix
has and I'm not sure what are the plans
I think there's plans on open sourcing
this part
I don't know what their schedule is so i
won't i won't to quiz the netflix guys
here but they have a dashboard that
looks like this that they use to look at
sort of the state of of the monkeys
what's the what's at current thinking
about what's going to be deleted in this
case this is the the janitor monkeys
page that's sort of his dashboard of
what he's going to clean up so hopefully
that will get open source maybe
integrated into a scart joe snogging
found his backlog somewhere yeah that's
the current plan but if somebody else
wanted to contribute to that right it's
really just a you know section of pages
in asgard that are gonna be talking to
the monkeys which are our service so
it's probably a cloud prize-worthy
chunk of code if somebody wants to do
that there's another tool which is a
command-line tool this is in my slides
it's also not yet out it's on github
there's a lot of netflix specific bits
in it but it is kind of a cool client
and I worked on it so I'm kind of proud
of it but it's a command-line tool that
is really just a rest client all groovy
sort of a DSL mostly but it just allows
you to rest fully or control any kind of
the rest services which almost all the
infrastructure for the Netflix cloud and
a number of other tools like Jenkins and
JIRA some something you might want to do
as part of a continuous delivery
deployment system this kind of allows
you to orchestrate it from you know
either a workstation or from a Jenkins
job in this case we're showing you how
you can create a client to talk to
asgard
find a cluster object with a given
naming pattern and do another push so
we're gonna push a new auto scaling
group with the new AMI
and wait for it to complete so all the
work is being done on a scart in this
case we're just talking to it and
telling to start something you would
just sort of replacing you from going
and clicking on the web pages and doing
all that by hand so this kind of came
from code that release engineers were
using at Netflix and they were doing in
Python or shell or different things and
so we took all of their knowledge and
put it into this so hopefully we'll be
able to
produce a version of this that's useful
to people outside of Netflix so should
be coming in a while okay so back here
so now we'll move on over to the
connection side of things so in this
section I'll talk a bit about how you
would actually write your Java apps so
that they work in this sort of cloud
environment really a lot of it is about
breaking your application down into
small sort of mini services micro
services sometimes people call them but
really embracing the service-oriented
architecture model and one of the first
things that is different in this model
is that so
amazon has load balancers so at the top
you see those little guys coming in from
the edge that's an those arielle bees
traffic comes in there so if you're on
the if you have part of your services
just on the edge you're gonna get you
can better leverage Amazon's load
balancers for getting traffic from the
outside world but once you're inside
you're you know service architecture and
you've got all these different pieces
there really isn't a good solution from
Amazon directly that's like a middle
tier load balancer they have a few now
you can have private load balancers but
they weren't there initially when
Netflix built discovery or Eureka and
now that they have it and it's really
solid you kind of look at some of the
other approaches and say well this is
actually really very nice and so I don't
think there's any plans that I'm banning
this this is a really nice way of doing
things and so well you have is Eureka is
a service that is just in memory storage
of other services that are registering
and saying I am here so it's it's it's a
way to discover what other machines are
there service providers register their
logical name where they live what
another health check URLs and they
heartbeat into this server and it's
storing all of its state in memory now
then there's failover that could be a
cross zone failover Zoar just backup
standby backups that are in memory sync
synchronizing to each other so it is
very stable and reliable but it's also
very fast and very simple if a node goes
down that has track of everything it
just we can auto scale and bring up a
new
to replace it and it will sync itself up
to the other note and be up and running
again in a couple minutes but coming
back first when you bring up your
application so in the world where you
baked an ami let's say and we've gotten
this application so I baked my ami
application foo version X this is really
designed to be or intended to be
launched in different places I can
launch it in a stack over here I can
launch it in prod I can launch in a test
I can launch it in a debug development
cluster so when my mission when that
application comes up it kind of needs to
know what it's intended for at this
point in time you know what's my
environment what are my settings and
maybe you do want to tweak things at
runtime maybe I want to be able to turn
on experimental feature at runtime have
live traffic go to it turn it off again
later on so what Netflix did instead of
trying to do that sort of dynamically
with a service like chef where you're
integrating that with building the
machine configuring the applications
doing the discovery they say well let's
build another service right so we're
we're good at building services we've
built this whole service-oriented
architecture we know how to do rest
let's just do another one for this so
our Caius is a project which provides
zombicide
client library for dynamic properties so
it leverages annotations in Java which
are really nice to use you can have
property files which sit as part of your
build artifacts so they're in your ware'
property files plus then it can layer in
dynamic settings changes overrides that
come in from some kind of storage so the
version that of our caius that's on
github right now the client talks
directly to dynamo and does database
queries which is totally great for doing
stuff and getting out of the box and
running a small cluster but when you
start to scale up the traffic to dynamo
is going to be really big and so what so
netflix internally has a service that
sits in front of the database and serves
the queries back to all the clients and
also we've done one at
so we have that and I think so jerome at
riot who used to be at netflix wrote it
and he's working with the netflix guys
and they're gonna kind of converge those
and put that together so one way or the
other there will be available this
archive server that's there it access to
the front end so it only reads and
writes to dynamo with the rest api and
then all of the all of the dozens or
hundreds or thousands of machines that
need to query about their dynamic
properties will hit the service directly
instead of going to the to the database
quite a bit more efficient and then i
mean double check my slide no okay wait
that's it okay so back to eureka again
so now i mentioned that all the services
have registered with eureka so we know
where they all are we know what their IP
addresses are we know how healthy they
are or if any of them have been taken
out of service if you have a client that
needs to talk to a service there's a
eureka client library that you can
integrate into your application and on
top of that there's another library
called ribbon which can actually do the
RPC for you and what eureka client does
is it will talk to eureka pull down the
whole chunk of a basically table of all
the other guys that are out there and
then serve that as a library internally
for any are pcs that you want to do like
if i need to talk to you know
application x that's down below me down
stream below me i so i can even talk to
x in stack a and you'll get back out of
that query in a list of maybe okay
there's 40 machines there how do we want
to talk to them how do we want to load
balance through them do we want to
round-robin through those or do we want
it sticky or do we want some kind of
weighted so ribbon and here we could
client together will provide you with
that kind of service so you really can
just use it right out of the box and
start talking to the downstream guys and
you'll automatically connect to the
correct set of them
a little bit hard to read we got there
yeah okay there's a lot of different
libraries here on top of that as a
client you might also have to deal with
issues of downstream services being not
always reliable so if you're building
something that's close to the edge of
your application in your architecture
you may end up with a lot of downstream
dependencies some of those may be
unstable or necessarily unstable but may
have may not be to always meet their SLA
so things may get a little overloaded
you need to be very dynamic and you want
your service to be very defensive about
how it replies in response to its SLA s
right so if you need to be up 99.9
percent of the time and you rely on a
hundred services behind you that are
also only up 99.9 percent of the time
it's all going to add up and the
failures are going to accumulate right
so you'll never be able to meet your SLA
if you're always relying on those other
guys directly
so what History X does is it allows you
to have effectively a circuit breaker
type set up so that each point where
you're talking to somebody downstream
you can say well if this guy doesn't
meet the SLA that we've set and we've
all agreed upon he's starting to
overload it will switch off for a brief
period of time and go to a fallback so
if I need to find out personalized
recommendations or personalized ratings
for my movie page that's going to show
all the movies for this customer for
this member and that service is hammered
and is not getting back to me then
instead of me sitting there waiting for
it I'm going to this circuit break over
and just start giving the user generic
ratings that are global ratings from
another much less loaded service or I'll
have some pre cached values which are
reasonable for now so you get sort of
this degraded service that fallback and
that's got handled by hystrix
but no a number of other libraries which
are really handy blitz for Jay is a lock
free logging library which allows you to
do standard it's a lock for Jay logging
that is really fast and doesn't have any
lock-in in it so you can have that
integrated into code that is doing high
performance stuff and the logging won't
be creating heisenbugs for you and
walking and slowing down things right
you're just pushing stuff out very
efficiently very fast so that's handy to
have if you're logging lots of things
and like Netflix does logging and log
rotating out to s3 lots of data that you
can then look over later on and crunch
over later on cerebro is a very useful
library which sort of works with Java
annotations again lets you annotate
things that you want to be monitored so
they're metrics and behavior of things
that are going on in your application
you can annotate with servo it exposes
all those values those metrics through
JMX and then they could be pushed out to
other services so the version that's in
the open source a project can push all
the metrics to cloud watch internally
Netflix has a monitoring system called
Atlas which they probably open source at
some point hopefully it it's a it's a
big project and I'm not sure that will
come out right away but there's other
it's pretty easy to take that and maybe
you want to write kind of an accumulator
and a pusher that will push to nog
Nagios or any of the other kind of
popular monitoring systems or alerting
system so that's a nice way to get that
data out of your java application and
then SD annex here I popped in here for
an example that's that's the Cassandra
client library for Java very nice to use
if you're writing talking to Cassandra
oh and that's the end of my talk this
used to say Netflix jobs but now it says
Riot Games career so we are hiring too
and I'm doing a bunch of cloud stuff a
number of teams that ride are doing
cloud things so if you're interested
moving to LA or telecommuting like me
give us a call well thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>