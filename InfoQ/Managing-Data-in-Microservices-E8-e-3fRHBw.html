<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Managing Data in Microservices | Coder Coacher - Coaching Coders</title><meta content="Managing Data in Microservices - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Managing Data in Microservices</b></h2><h5 class="post__date">2017-08-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/E8-e-3fRHBw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to the Micra services patterns
and practices track
I am your track host Randy shout all day
if you want to stay our great lesson
from people actually practicing
micro-services very little theory lots
of practical advice so should be pretty
good so I'd like to introduce the first
speaker who's the VP of engineering at
bitch fix hi I'm Randy shell I'm the VP
of engineering at stitch fix I'm going
to talk about micro services in
particular managing data and micro
services so here we go great so I like
to start with a little bit of background
so that you kind of know where I'm
coming from and know where some of these
lessons direct from so right now I'm VP
of engineering at stitch fix in San
Francisco we are a clothing retailer and
we combine both art and science to give
people the clothes that they love I'm
going to talk a little bit more about
our business model and approach simply
because it motivates the need for data
and the our use of micro services and in
a little bit before that I was for about
a year and a half I was sort of a roving
CTO as a service as my friends used to
say I helped a bunch of startups in the
Bay Area larger companies in Europe and
Asia sort through their engineering
organizations and try to figure out how
to scale their technology earlier in my
career I was director of engineering at
Google for Google App Engine
that's Google's platform as a service
like Heroku or some other platforms you
might be familiar with and then earlier
I was chief engineer at eBay for about
six and a half years where I worked on
multiple generations of debased search
engine so very briefly about stitch fix
and I'm not trying to tell you you
should buy your clothes from us but you
should totally buy your clothes from us
but I will tell you our model because it
is very data-driven so the model of
stitch fix is kind of the reverse of a
standing standard clothing retailer so
rather than going into a physical store
or into an online shop and choosing your
own clothes let's have an expert do it
for you
so you fill out of what we call a style
profile it's about a hundred questions
very detailed information about the
styles you like your price preferences
things you wear into where your age your
parental status your occupation
everything that somebody would want to
know to be able to choose the best
clothes that you might enjoy you're
going to get in the mail five
hand-picked items so actually chosen for
you by a human you keep what you want
and you return what you don't in service
of this we combined art and science in
particular the data science part of
science so I believe this is unique in
our industry but we actually have a
one-to-one ratio essentially between
engineering and data science so we have
close to a hundred software engineers
that work on the team that I'm on we
have also close to 100 data scientists
and algorithm developers most of whom
have PhDs and things like astrophysics
and biochemistry and experimental
psychology and again like I say I'm very
happy to be assertive and wrong and hear
the counter example but as far as I'm
aware certainly at our scale there are
no other companies in our industry that
have this this ratio so what do we do
with all those data scientists right I
mean they literally have developed
exoplanets and now they're trying to
choose clothing so what do we do with
them we apply intelligence to every
aspect of statistics as this and just
like any physical business there's a
whole supply chain so we apply it to the
buying area what inventory should we buy
and what quantities when should we have
them arrive we apply it to inventory
management so where should we ship where
should we store store it how do we pick
things out of the inventory and get
those five things in the box to you we
think about it in terms of logistics
optimization what's the cheapest and
fastest way of getting our stuff from
one of our warehouses to your doorstep
and I will motivate this example a
little bit more but styling
recommendations so algorithmic
personalized recommendations for you as
a client based on the millions of other
customers that we have and then we also
do more standard things like demand
prediction because we have a physical
business so if we guess over if we guess
over or under on how many boxes were
going to send how many clients we have
that's a real problem right so there are
lots of virtual businesses where 2x more
than you expect is a great thing for us
that would be a disaster because it
would mean that half of our customers
wouldn't be able to be served does it
make sense great
okay all of these things are about
humans and machines augmenting one
another making each other better so the
humans are great the machines are great
they are better together I'm going to
talk a little bit more a little bit in
detail about the styling part so we say
styling that's the humans choosing the
five items that go in the box so we have
3500 human stylists all around the
United States that we use to help help
our clients send our clients things
we're going to like so from the client
perspective obviously you know stitch
fix has a bunch of inventory and then
magically you know five items in a box
show up and hopefully you like them all
there's a little more to it than that so
breaking down that arrow there's a first
phase of personalized algorithmic
recommendations so this is what we're
doing with a bunch of those data
scientists we look at our inventory we
do a ton of machine learned models come
up with a sort of ensemble score that
predicts the likelihood that this
particular client is going to keep this
particular piece of inventory and we
produce those scores in a set of
algorithmic recommendations we then show
those algorithmic recommendations to one
of those 3500 human stylists and those
human experts essentially curate a lot
the five items that are going to go in
the box so the machines are really good
at going through all the data and making
them and coming up with those scores the
humans are good at putting together an
outfit answering client requests like I
need something sexy for date night with
my husband so far we don't have a
machine that knows how to interpret that
but maybe someday you know that's like
that type of thing the humans do what
the humans are good at which is the
pattern matching and understanding
context and the machines do what the
machines are good at which is trolling
through tons of data and making scores
just make sense right and again just
like in chess by the way the humans are
great by themselves the machines are
great by themselves but they are even
better when combined together so how do
we work at stitch fix and why does it
work and I honestly blue I will talk
about micro-services but just in a
moment so modern software developments
in my mind that we practice at stitch
fix and Google where I used to work
combines not just technology but organ
is a
processes and practices and culture in
addition to technology and so what I'm
going to do is I'm going to set up those
first three really quickly because
they're kind of the background or the
foundation on which we're going to build
the microsoft says approach and then I
will leap into joins and transactions
and all the sexy stuff so but in
particular just a telegraph where my
beliefs I believe that organizations are
most effective when we build them out of
small teams with well-defined areas of
responsibility processes and practices I
believe those are best practice with
test-driven development and continuous
delivery for culture I believe strongly
in DevOps in the sense that you build it
you run it and for technology at least
at our scale I strongly believe in micro
services so again first talk about those
first three very quickly to give the
kind of background and sort of the
underpinnings or the prerequisites for
being successful with micro services and
then we'll go and talk about the
technology part so first I want to talk
about small teams we practice at stitch
fix and we also use to practice at
Google this idea of small service teams
so we have we have small teams that are
directly aligned with a particular
domain in the business those teams have
a clear well-defined area of
responsibility and they typically build
and maintain a single service or
application or a set of related services
and applications those teams are
cross-functional so within the team
boundary they have all the skill sets
that they need to do the job that
doesn't mean they have all skill sets in
life we don't build our own hardware we
don't write our own operating systems so
we don't have those folks but all the
skill sets that are needed to produce
the particular service are within within
that same boundary and of course teams
depend on each other right so we depend
on other teams within stitch fix we also
depend on external third parties a cloud
providers etc for supporting services
and libraries and tools this makes sense
great ok this is a grief tour so that's
next I want to talk about our practices
around test-driven development and
continuous delivery
so for test-driven development we don't
do this to slow things down we do this
to speed ourselves up write tests help
us go faster
why because tests have my back when I am
writing code or more precisely when I am
changing code the tests make sure that I
don't regress the thing that's the
things that already work and it actually
increases our development velocity by
making that investment upfront in
writing the tests rather than you know
writing the code hoping it's going to
work and then kind of testing manually
or not at all at the end of the process
tests make better code so when I have a
large suite of automated tests it gives
me the confidence to break things and it
gives me the courage to sort of
mercilessly refactor areas of the code
change cross-cutting concerns all across
the codebase exactly because I know if I
make a mistake or I don't do things
properly in one area the tests are going
to are going to catch it to make sense
tests make better systems they obviously
that having automated tests allow us to
catch but allows us to catch bugs
earlier and it allows us to fail faster
when it's a lot cheaper in the
development cycle rather than finding
out only much later when we ship stuff
the customers that the thing doesn't
work so I've been in the industry as a
long time as you can imagine by looking
at me often I hear this is anybody else
here desk we don't have time to do it
right yeah maybe half of the people so
here's what I say do you have time to do
it twice that is the choice you can do
it right the first time for some value
of right or you can do it twice that's
it or it doesn't matter right I guess
the step zero is does the thing we're
doing actually matter in which case
doesn't matter where they do it right or
wrong but if it matters do it properly
so you don't have to do it again do it
right enough the first time in fact this
is a bit counterintuitive but stay with
me the more constrained you are in time
and resources the more important it is
to build this thing solidly does it make
sense when I don't have a lot of time to
come around and do it a second time
let's make sure that I do one thing
really well and then I move on right I
would much rather as a start-up or a
medium-sized company
or a massive enterprise I would much
rather build one great thing than to
half-finished things right okay right
doesn't mean perfect so there's an 8020
rule
Pareto principle here you obviously went
you know the idea is that with 20% of
the effort we can get 80% of the way
there so what I am not suggesting is
build a perfect system but I'm saying
build a just right enough system to get
you going
move on go to the next thing the
interesting implication that has at
stitch fix it's basically we don't have
a bug we don't have a global bug
tracking system now I don't say we don't
have bugs we have lots of them but for
the most part when we find a bug we just
fix it right we find something we find
some issue write a test that
demonstrates the bug we make the fix the
test verifies the fix all done closed
move on to the next thing do we have
lots of other things we want to do of
course we do we have a large backlog of
stuff to do but that backlog is not a
list of half implemented things it's not
a list of things that that we thought
were working and aren't it is a list of
new things that we want to do right new
features that we want to produce
technical debt which we absolutely have
technical debts that we want to repay
but what it isn't is a list of you know
the endless list of priority two
priority three priority four issues that
we know we're never going to fix and
this for me is unique in in my entire
you know 27 year experience in this
industry I have never worked at a place
that had this and this is exactly and
directly comes from the test-driven
development approach just make sense
does it sound pretty cool yeah it is
okay continuous delivery we we build
stuff on Ruby on Rails for the most part
rails really wants you to build a
monolith and we really didn't so
thankfully we we avoided that siren song
we've ended up building about 50 or 60
different individual applications and
services most of which are deployed
multiple times a day by having the
ability to deliver continuously we build
more solid systems why the
because we release smaller units of work
into smaller batch sizes to use the lean
lean terminology it means we have
smaller changes to roll forward or roll
back and if there's an issue it's faster
to repair it's a lot easier to grok it's
a lot easier to understand and it's
simpler to diagnose just make sense yeah
it also allows us as we will see going
forward to rapidly experiment right our
ability to release small units of code
multiple times a day allows us to make
rapid changes to the code rapid
experimentation which we absolutely on
the data science side take advantage of
so we experiment you know constantly and
we rapidly iterate exactly because we've
made a chief for ourselves ok last thing
I want to talk about is the cultural
aspect of DevOps so apparently there are
lots of definitions of DevOps here's
mine
it means end to end ownership of the
thing that you are writing so unlike
when I started in the software industry
and we built shrink-wrap software that
we put on a CD and we ship physically to
customers our teams in the modern world
when you're building a sort of an online
system like Citrix is the team is going
to own the service all the way from the
design through the development
deployment all the way care retirement
so when I started my job was done when I
sort of hit commit and my thing went
into the repository now I am only done
when the service that I'm working on is
retired it stitch fix we just have
engineers this is very similar to
Netflix to Google to Amazon lots of
places that are really high performing
those engineers that I have on my teams
are responsible for all aspects of the
software development process they are
responsible for the features they are
responsible for the quality of the
features they are responsible for the
things that they build performing well
they are responsible for operating them
and they're responsible for maintaining
them long term so we do not have a
separate QA team a separate performance
team a separate operations team a
separate maintenance group we have
engineers they do it all and that has
wonderful properties because it means
that the things that we learn operating
and maintaining the software feed
directly back
into the software that we're building
it's basically a reification of the
burner Fogle's idea of you build it you
run it just make sense okay so all of
this is backstory to getting to where
you really wanted to hear about which is
micro services so that's we're going to
talk about for the rest of for the rest
of the session first I will talk a
little bit about a show a little bit
about the evolution of companies you've
heard ups and micro services so very
briefly eBay is you would currently
characterize as a micro services
architecture completely didn't start
that way
so famous it's depending on how you
count on it about its fifth generation
of its architecture so a fifth complete
rewrite from the ground up so it
famously started in 1995 when Pierre
Omidyar the founder took a three-day
Labor Day weekend and started playing
around with this new thing called the
web and he decided to build an auction
website took in three days it was
monolithic Perl application every item
was an individual file on his machine
that didn't scale but it was pretty cool
the next generation was a monolithic C++
application which at its worst because
3.4 million lines of code in a single
DLL don't do that you think you have a
monolith I laugh that's a monolith they
were actually hitting compiler limits on
the number of methods per class which is
16 K yeah next generation the v3 was a
rewrite in Java that wouldn't fairly be
characterized as microcircuit maybe many
applications right so individual pages
of the site were served by you know the
search application or the selling
application or the buying application
something like that and now I think it's
fair to characterize eBay as a polyglot
set of micro services
Twitter's gone through a similar
evolution there about on their third
generation so they started famously as a
monolithic rails app which the Twitter
people called the monorail very clever
next generation of it was sort of
breaking out more of the front-end into
JavaScript more of the backend into
services mostly written in scala and
then now I think it's fair to
characterize Twitter as a polyglot set
of micro services Amazon has gone
through a similar evolu
Amazon isn't so clean on their
architecture generations but it started
out as a monolithic Perl and C++
application which you actually you can
still see the history of in some of the
product detail pages so if you ever see
in the URL obidos OB i-gos that was the
name of the original monolithic app in
amazon the next year the next generation
after that was breaking out a bunch of
back-end stuff into services motsu
written in Java and Scala and then now
it's fair to characterize Amazon as a
poly block set of micro services so
there are two things to take away from
this which is why I show this slide
number one no place you've ever heard of
started with micro services and number
two no place that this scale has not
ended up in micro services does it make
sense what I'm saying yeah okay so I
want to super underline this because I'm
going to talk about micro services but I
want to make sure that micro services
are not for every company and are not
particularly not for every stage of
company when you are at eBay scale or
Google scale or Netflix scale you for
sure need to have something that looks
like micro services when you are a tiny
startup it is unclear that that is the
right way to go so I love the Martin
Fowler thing where you know the first
law of distributed object design is
don't distribute the objects right a
monolith is perfect for when you can get
away with it at some point you will no
longer be able to but it's great to
start with we did that at stitch fix
same at Netflix same at all these other
places there's no shame in that and
there's everything right about starting
in a monolithic approach so this is what
Martin Fowler says this is what I say if
you don't end up regretting your early
technology decisions you probably over
engineered right there might well have
been an eBay competitor in 1995 that
spent all their time building a
distributed system there is a reason why
we have not heard of that company all
right
microservices my definition it's not
about how many lines of code or how long
it takes to write them it is about the
scope of the interface Micra service is
our single purpose they have a simple
well-defined interface and the critical
aspect from an architectural perspective
is that they are modular and independent
now
these things sound like you could get
them in other ways without microservices
you would absolutely be right in fact as
I like to say microservices are nothing
more than service oriented architecture
done properly right
it is a service-oriented architecture
where we actually think about bounding
the context of the individual services
we think about doing one thing doing it
very well and then moving on to another
service but things but another thing
which is going to motivate some of the
data stuff that I'm going to talk about
going forward is in order for micro
services to be really effective they
really have to have what I call isolated
persistence and I am going to talk about
this on much more detail but the brief
brief overview here is that an
individual micro service in one of those
ecosystems really needs to have its own
isolated database essentially there
should not be any backdoor way for micro
services to kind of sneak in and look at
the other guys data that's not going to
work and I'll tell you why okay
so I'll tell you why now so let's talk a
little bit about some options for how
you can get what I just said how can you
make micro services sort of have
isolated persistence from each other so
the first approach is that the same team
that builds the micro service also
operates its own data store right so we
use Postgres that stitch fix you might
you know choose your own data store
whether it's my sequel or Oracle or
Cassandra or something like that so the
idea is that the team would you know
store to their own instances and sort of
own and operate those data databases and
we absolutely do in some teams you know
at Citrix we absolutely do this model
the other model of course is to use a
persistent service whether that service
was provided by potentially another team
in your company or maybe a third party
you know cloud provider or something
like that so the idea there is you store
to your own little slice you store to
your own schema in I don't know Amazon
dynamo or Google Cloud datastore or
Google spanner or Microsoft sequel
server in the cloud something like that
but it's operating the idea is that it's
operated for assert a service for you by
you know somebody else and the key thing
is that even though there might be a
kind of multi tenant situation you are
isolated from all the other ten
right all the other users of that
service so you have your own little
slice that as far as you're aware is is
alone this is making sense yeah the key
thing to get here though is that the
only external access to your data store
and your micro service is through your
published service interface right if you
have any other way of getting there you
know that way lies madness you really
don't want to have people reading and
writing behind your back without your
able your ability to execute business
logic and all that an ebay absolutely
did do that in their first attempt to do
services and it was a massive failure
exactly because the applications could
talk to the shared databases directly
and didn't need to go through the
service layer so nobody used it so don't
do that that's why I'm telling you this
okay next thing I want to talk about and
these are all kind of architectural
building blocks that we're going to
build up to talking about joins and
talking about transactions near the end
so I want to take a brief pause and make
a pitch for having events as a
first-class construct in your in your
design in your architecture so wikipedia
defines an event as a significant change
in state I like to think of it as it's a
statement that a thing happened like
something that nice something that I
cared about happened in my system
typically these things are asynchronous
so there might be nobody listening to
the events that I produce there might be
one other consumer or there might be
many other consumers for the events that
I produce in a tradition we're all
pretty familiar with the traditional
three-tier architecture a lot of us
myself included sort of cut our teeth on
building systems like that so there's a
presentation tier a sort of application
or business logic tier and maybe a
persistence tier which is often at least
traditionally a relational database I
think we are missing something I think
we are missing the fourth fundamental
building block of architecture which is
state changes or events hopefully I will
motivate this in the next slide but I
think not thinking about events as a
first-class part of your architecture
you're missing a whole dimension of
architectural flexibility that I use
that you have okay why should you do it
this way well it turns out that events
represent how the real world actually
works in finance Deutsche Bank and Bank
of America when they're trading
currencies they don't do a distributed
transaction they are firing events at
each other and then at the end of the
trading day they kind of reconcile right
I've sent you a million events you've
received you know a million and ten or
whatever we figured out at the end of
the day and reconcile I was looking for
another example that's sort of more
visceral for people in this room think
about it as the software development
process itself so raise your hand if
when you hit return in your IDE that it
gets deployed to production anyone yeah
one person great I'm all for continuous
delivery but I strongly believe that
there are steps along the way and it's
actually a workflow and with you know I
finish building my code you know locally
and then I commit it to the repository
and then you know CI happens and then it
gets deployed a cetera so they're
actually events and a whole big chain
great so now I want to talk about events
as applied to micro services so just
like it should be a first-class part of
our architecture events are a
first-class part of our service
interface so the obvious part of my
service interface as a micro service is
the synchronous part right so often that
is you know rest and JSON or maybe it's
something like G RPC or thrift but
typically people think of their
interface as that synchronous request
response part in the front well there
are lots of other parts of our interface
as well if we if we kind of open our
eyes so the interface to my service also
includes all the events my service
produces right it includes all the
events my service consumes and also as
is often true when I'm communicating
with analytic systems it also includes
any bulk reads and writes like ETL jobs
to my database does this make sense
great lots of nods okay the interface
includes any mechanism that gets data
into or out of my service okay which
includes event all right now that we
have all those building blocks I'm going
to talk first about how to extract micro
services
from a monolithic database then I'm
going to talk about some techniques for
managing data from the design
perspective in a micro services
ecosystem so this is exactly the problem
that at stitch fix when I joined and
we're still working through it so stitch
fix as I mentioned avoided the siren
song of building the rails monolith but
we did but we did I think for a very
good reason we did build a monolithic
database so almost every even now even
though we've been in at for a while
almost every interesting entity and
stitch fix lives in this shared database
right so all the information about
clients the information about the the
shipments we've spent out the items that
we have in inventory all the metadata
about items so styles and SKUs all the
information about our warehouses
etcetera etc etc at times 175 tables and
we have a bunch of applications you know
I show 8 up here but we actually have
about 50 or 60 and the vast majority of
them are still talking to this shared
database so this is a real problem right
it's a it's a single point of sort of
contention and restriction on feature
velocity for my teams but it is also a
single point of failure right so if this
thing goes down or is slow all of stitch
fix has a bad day so let's make sure
that doesn't happen anymore and I will
tell you how we're doing it so the
solution is decoupling applications and
services from the shared database so
that's pretty obvious I'm going to tell
how we do that but I'm going to tell it
in a slightly simplified form just so
that there aren't so many boxes and
lines on the on the on the slide so
let's imagine we only had two
applications and we had three tables so
step one is we're going to create a
service for one of those shared tables
so we have a service at stitched fix
which we call core client as you can
imagine it stores information about our
clients so we create a client service
now we instead of having the
applications talk directly to that
database table we change the
applications to talk to the service
instead that the table is still in the
shared database but it is all the
interactions with that table come
through the service interface rather
than going directly against the table
the next step is to move that table out
of the shared database into a private or
local database owned by
servus and then we say rinse and repeat
right so we do that for the next thing
so we move the we create an item service
and create a we move the core item table
out of the shared database into a
private database owned by that service
and we do the same thing we're with SKUs
or you know the metadata about our
inventory so we create a style service
and that that manages SKUs does this
kind of make sense what I'm saying
does it seem super overly simplistic yes
it is except there's I've never seen
anything any one of these extractions
work anyway other than this if you want
to break up a monolithic application
there are other techniques but breaking
up a monolithic database this is the way
to do it it seems even to me even though
this is probably the 20th time I've said
this in front of an audience it still
seems overly simplistic so what it
elides is not that there are missing
steps is that each step is actually
pretty complicated does it make sense
what I'm saying creating that service
like there's a lot of correctly there's
a lot of negotiation and discussion
about what that service interface should
be changing the code just is a little
bit more than just pointing two lines
from the table into you know into some
other place because there are lots of
joins to unroll and lots of other
dependencies to manage but that is the
next step you know having everything go
through the service interface and only
then can you remove you know that table
from the shared database and put it
somewhere else anyway so as I mentioned
you know this whole practice about
patterns and practices and people
actually doing it we are actually in the
process of doing all this at Citrix
right now ok and so here are the service
boundaries right and I very
intentionally draw the boundaries around
both the application parkour you know
the sort of business logic be part of
the service and the database because
nobody should be able to get into one of
these bubbles except by going through
the published service interface make
sense all right now we have started
extracting things into micro services
let's talk about some of the techniques
around managing data in this environment
and I'm we're going to talk about three
of them I'm going to talk about shared
data I'm going to talk about joins and
I'm going to talk about transactions
all of these things are wonderfully
trivially easy and powerful within a
monolithic environment and they are all
made more challenging in a microservices
environment so just as we have you know
discovered and rediscovered these
techniques I want to share them with you
so you don't have to rediscover them
from Volk loss as maybe we did okay so
the first one I want to talk about is
shared data the problem here is simply
stated in a monolithic database it's
very easy to leverage shared data so you
know there's some table in there that
represents I don't know some metadata or
something that's shared I can just join
to it right the customer table is right
there
I need customer information I can go
right in there let's add it to my from
clause and I'm good and that works fine
in a monolithic environment that does
not work at all in a micro service
environment where where each thing is
behind a service interface so how do we
do it there's a real problem here and we
can't define the problem away so how do
we do it three techniques that I want to
talk about before I do that there's a
principle here which is that every
interesting piece of data that we have
should be owned by a single service so
there is one place in the overall
infrastructure of stitch fix or Google
or Amazon or Netflix where that owns a
particular piece of data there is one
service that owns the customer customer
information is also often used by lots
of other places and sometimes even
cached so every other copy in this
example of customer data in our
infrastructure is a read-only
non-authoritative cache we're going to
let that sink in a little bit this makes
sense there is one place that owns
reading and writing this thing every
other place that understands anything
about customers the address in the you
know billing certain your billing
information in the billing service all
that stuff is just a read-only
non-authoritative cache of information
that is actually owned by the customer
service and this principle is going to
help us as we figure out what to do
about when we make changes to customers
and what does that do with caches and so
on this kind of making more sense
nods okay nods and photographs
okay cool so this is the back this is
the problem statement and the principle
for the solution so approach one is just
synchronously look it up from the place
that owns it right so in this particular
example you know the customer service is
going to be the thing that owns customer
data we have what's imagine we have a
fulfillment service which is going to
ship things to customers that
fulfillment service needs to know the
address where the customer you know
lives or wants us to ship a thing so you
want so one totally legitimate way to do
it is the fulfillment service in real
time calls the customer service and says
what is this person to address this
makes sense pretty simple okay the
second event a second option is let's
imagine that for whatever reason it's
too expensive for the fulfillment
service to ask the customer service in
real time instead because the
fulfillment service will maybe maintain
a cache of the customer data that it
cares about so again in this in this
example the customer service is the
canonical system of record for the
customer data the customer service
produces an event that says you know
address updated or something like that
the fulfillment service listens to that
event and then updates its local cache
this makes that cool alright but there's
a third approach which is for things
that are shared metadata that don't
change very often so examples in stitch
fix are things like size schemas so
that's like for women sizes you know two
four six eight a small medium large
extra large so like one could certainly
imagine creating an extra extra extra
extra extra large and maybe if current
trends continue we might have that in
the united states but that doesn't
happen very often similar things in
least in our domain are things like
colors fabrics the US states so I hope
nobody has a u.s. state service that
says you know what are the US states and
it returns the 50 US states like it's
been the same for 60 years and maybe
someday you know Puerto Rico will become
the state that would be awesome but you
know until then that doesn't change very
often so here's how we do it and I used
you know we do Ruby on Rails for the
most part for our applications with
stitch fix in addition to a bunch of
back-end services and go so I use the
Ruby icons here just to show that so
let's imagine that we have one of these
pieces of shared metadata and we just
distribute you know the color schemas to
all these different places this make
sense
so shared library is a totally
legitimate thing to do even though we
also have services in our toolbox and I
guess the meta point with all these
things is there are lots of different
ways to do it
and just because we're in a service
world or a micro service world doesn't
mean that we have to forget about other
techniques that we've been using for
many years to solve problems that are
like this okay
so that is shared data now I want to
talk a little bit about joins so again
the problem statement in a monolithic
database joins are super easy yeah
that's one of the most wonderful things
about having a monolith if I need
customer data I just joined to it and
there it is and it's in there and great
once I have split my data over multiple
services this kind of stuff isn't as
easy anymore but I still want to be able
to combine you know customer data with
order data or something like that so the
problem is still there I just need to
solve it in a slightly different way so
I'll give a couple of techniques for
that so approach one again this is
pretty obvious approach one is simply
joining in real time in the client
application right so let's imagine we
have an order history page so we want to
show to one of our customers here are
all the orders you know that we that we
sent to you so one could certainly
imagine that order history page going to
the customer service and saying get me
the information about this customer and
then separately going off to the order
service you know in parallel or in
serial or whatever going off to the
order service and asking for all the
matching orders for that customer this
makes sense yeah if this doesn't seem
familiar it's oh sorry and this is this
use case sorry this approach is best
when it's a kind of one to end joint
right so there's one customer with many
orders if this seems familiar it's every
web application you've ever built
unless unless every aspect of your web
page comes from one and only one data
source every web page is like the
like go one place for the customer data
another place for the order data and we
put it all together and we show it as
one thing okay that is one very
legitimate approach which we absolutely
use at stitch fix another approach which
we also use is approach that I call
materializing the view so the idea here
is that it might be that I can't join in
real time because there are lots of
items and lots of pieces of feedback all
together like maybe there's just too
many items and too many other things on
the other side of the join and it's just
too expensive to join in real time so
what I want to do is essentially
maintain a cache of that join wherever
I'm using it so how does this work in
practice
let's imagine that there is whoops there
we go
let's imagine that there is an item
feedback service where we want to show
all the feedback that our customers have
given about each item so we have a bunch
of individual items and a lots of pieces
lots of pieces of feedback about each
item so it's a many-to-many relationship
or an m2n join so this item feedback
service might maintain a denormalized
cache of items joined to order order
feedback by listening to events from the
item service and then separately
listening to events from the order
feedback service and then updating that
join in real time does it make sense
yeah so I'm I'm using database
terminology here a very advisedly so
this is in oracle or sequel server or
some other you know commercial-grade
relational databases there is an idea of
materializing a view this is a join and
you just simply maintain a cache of it
and it gets updated by when the
individual kind of elements of the join
get changed okay if this seems a little
bit weird or unfamiliar let me give you
some other examples of that common
systems that you use every day that do
this almost every no sequel approach
takes this tactic relational databases
optimized for the right side you write
individual records and then at the read
time you combine them all together most
no sequel approaches the Cassandra is
the reacts of the world are mostly the
other way where instead of writing
individual things and joining at the end
you write in parallel a bunch of
different you basically write all the
queries you're going to ask in parallel
and then you ask the queries and the
queries are fast again as I mentioned
lots of commercial-grade
database systems have this concept of a
materialized view search engines are
like this right so if you have an
elastic search in your anywhere in your
infrastructure probably you are doing a
thing just like I mentioned every
analytic system in the world is
combining together joining together data
that comes from multiple data sources
and also log aggregators for operational
logs so lots of use cases for this
particular pattern this makes sense ok
we're going to step it up a notch now
we're going to talk about transactions
the problem here or the wonderfulness in
the monolithic database is that
transactions are super easy right I want
to update atomically a thing and beefing
and see thing and D thing in one unit I
want it to be acid all done or not done
at all that is really easy in a
monolithic database and it is very hard
to crossing across services what I do
not recommend is thinking about it as a
multi like a distributed transaction
two-phase commit please do not do that
that's a scalability killer and a
performance killer but I will give you
some techniques to get most of what you
want from the transactional world ok
instead of thinking about it as a atomic
transaction think about it is what's
called a saga this people have heard the
term saga it's okay if you haven't wow
more than I expected maybe a quarter of
the people great
Katie McCaffrey from Twitter just left
Twitter given a wonderful set of talks
specifically about sagas way more detail
than I can give you in two seconds so
that's worth taking a look at if if this
is unfamiliar but the general idea is
take that transaction where I wanted to
update a and B and C and D together and
think about it as a workflow think about
it as a state machine of first light
update a then I produce an event and
update B then I produce an event and
update C and then I produce an event and
update
so think about it again think about it
as a saga or a workflow of individual
atomic transactions that are each within
a service boundary but you connect them
together with events and you maintain a
kind of state machine of where where you
are is this kind of somewhat making
sense yeah so how do you do roll back
Randy I'm glad you asked you just run
the workflow back the other direction so
you apply what are called compensating
operations that undo the thing that you
had done in the forward direction so
let's imagine we got all the way to
updating a and B and C and D and then we
needed to rollback for some reason you
would remove the thing that you added to
D or sort of undo that update it would
produce some events it would update the
C it would update the B and then it
would update the a so just in the same
way as you know there's a forward
movement through your state machine in
the like commit case there is a backward
movement for your state machine in the
rollback case making sense yeah if this
does not seem familiar let me give you
some ideas where this happens all the
time every single payment processing
system that you could imagine works this
way again financial systems do not do
distributive transactions for the most
part so any type any time you interact
with a third party payment provider like
you know visa or Braintree or you know
something like that they are going
through a workflow they first do this
thing and then they you know acquire the
thing and then they go to the bank and I
don't know this stuff but like they go
to all the different banks and like do
all the individual sets of things and at
the end of the at the end of which you
know my money moves from you know my
pocket into you know somebody else's
pocket something like that
every approval workflow that you've ever
seen in your company expenses you know
first it goes to this person then it
gets approved or you know send out to
the next person next person etc you know
Randi expense for the Jazz Club goes up
and like gets rejected by the CEO
unfortunately and back down and then I
try to but the Jazz Club was for work
and yeah that didn't actually happen but
I'd like you to yeah so any multi-step
workflow does this thing okay so the
last thing I want to say about trends
actually
because I we do have a whole serverless
track which you should absolutely attend
I sort of feel like I can't
in fairness end a microservices talk
without giving a bit of a nod to the
serverless techniques I would prefer to
call them functions as a service instead
of serverless but that's just me
serverless is a great way of
implementing what I just talked about
why because those operations that I want
to take in these in this workflow are
super small right it's very lightweight
logic maybe you know when you get right
down to it 10 or 20 lines of code
they are stateless right so I receive an
event I do some computation and then I
you know produce an event and it's also
again triggered by events so something
like Amazon lambda or Google Cloud
functions or Azure functions are a
perfect match for this thing does it
make sense it is super small targeted
stateless logic that is triggered from
events and producing events so server
list is a perfect technique for for this
okay
so just to sort of sum up again as I
mentioned you know I think to do micro
service as well and to develop software
in a modern way you want to have
organizations that are sort of built out
of small teams you want to do practices
of sort of test-driven development and
continuous delivery from a cultural
perspective you really want a culture of
ownership where the same team that
builds a thing also operates the thing
and then again at particularly at the
kind of scale that we're talking about
here the scale of team size scale and
the sort of load scale or customer scale
web scale micro service those are a
really great great way to go so I do
want to make sure that I leave a few
moments for questions but I'll leave
this up I would be remiss in our modern
you know world to not mention that
stitch fix is hiring and in particular
so we're based in San Francisco but less
than half of my engineers actually live
there more than half of the engineers at
stitch fix are scattered all around the
United States some in our regional
offices in Austin and Pittsburgh but
also people from all over the country
all the way from Hawaii to New York and
New Jersey
down to the Carolinas like all over the
place and you know we're hiring in
application development which are the
kinds of things that you know the
customers fee we're hiring in our
platform group that builds the
underlying technologies that I'm talking
about and then we're hiring in that data
science team that tells us how to be
smart so if any of this sounds
interesting I'm going to be around for
the whole rest of the conference so
please see me in person physically or
contact me virtually in one of these
ways because yeah Citrix is a great
place to work and if this stuff sounds
cool then come join us so now I think I
have a few minutes for questions I can
repeat it if you yell it
exactly one event delivery yes one of
the questions they've already had about
their second shared data example you
gotta like you with it ends never
arrived or then awesome why yeah that's
a very great question so just to replay
the whole question distributed systems
do not do exactly once delivery true
statements how do you deal with events
not arriving coming out of order coming
to multiple times yeah that's the whole
talk in itself I mean I will give you an
answer and also it's the whole talk in
itself which hopefully I'll deliver at
some point so the first point exactly
once delivery that is a myth the FLP
result shows that it's actually
impossible in practice to get that you
can get maybe closed in lots of
situations but you can't get in the same
ways you can't have perfect availability
you can't have you can't have exactly
ones delivery in all situations so true
statements don't rely on that okay what
do you do so that means that you might
get events out of order you might get
and you might get events multiple times
does it make sense okay first two-step
so there are two ways to design an event
system one is called
at least once delivery and the other is
called at most once delivery you want
the first part so at most once means
that you will receive an event either as
0 times or one time only do that
mechanism when you don't care about that
thing right so actually logging is a
great example there are lots of logging
systems that use UDP or unreliable
protocols exactly because if that
logging message didn't get there shrug
no big deal but any any time you use
events for business stuff you want to
use the at least one so if there is a
situation if something goes wrong or if
the sender cannot does not know that it
was sent properly then the sender will
try to send again so that is the at
least once delivery okay we'll start
from that so now with at least once you
have two problems I will I will get the
same thing multiple times and I will get
them out of order the at least the
multiple times is it forces your
consumer of the events to be what's
called item
potent so item potency is a mathematical
term it means that f of X is the same as
f of f of X so for the non-math majors i
was a math major for the non-math majors
in the room what that means is if I do a
thing one time or I do it many times I
have the same result does it make sense
idempotency so you need to write your
consumers in order to be item potent so
if I do a thing if I increment a counter
I need to make sure I don't implement it
multiple times there's lots of good
academic work about on techniques for
doing that they're a little complicated
and please don't try to discover them
from first principles but there are but
you should know there are lots of
techniques in our computer science
toolbox for doing item potent thing
there's no matter what you're trying to
achieve that is the item potency part
for the events received out of order if
you care about the ordering of events
and first off I would try to say see if
you can avoid caring about it because
often times you can it doesn't matter
what order they come in for lots of use
cases but when it does then you will
need to maintain some state on the
server side on the consumer side does it
make sense like let's imagine that I
have events that say I update a I create
a customer and I delete a customer let's
imagine that most come out of order so I
first get the delete customer and then I
get the update and I get the create
customer oh the end of which if I didn't
do it properly then the end of the end
result of that is that I have a customer
when what I intended was what I didn't
did the example make sense for people
nods yeah so again in the I'm gonna get
a little fancy look up see our DTS
they are data types like what is it
concurrent replicated data type
something like that anyways there are
lots of sort of techniques in the
literature about how to deal with all
these things and including this exact
example that I gave there there's a
thing called tombstones which is
implemented in Cassandra and other
distributed systems that have to deal
with this where like if I received a
delete I kind of remember the delete for
awhile just in case somebody comes along
with a create the basic sense ish yes
the thing you should take away is not
that you know the answer is that you
know that there is an answer and you can
go
I am being told to get off the stage and
give you an opportunity to get some more
coffee
but again I'm going to be around for the
whole rest of the conference please
enjoy it and I hope you stay in
micro-services we're going to have an
awesome day thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>