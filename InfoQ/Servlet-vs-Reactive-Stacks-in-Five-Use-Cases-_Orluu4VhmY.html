<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Servlet vs Reactive Stacks in Five Use Cases | Coder Coacher - Coaching Coders</title><meta content="Servlet vs Reactive Stacks in Five Use Cases - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Servlet vs Reactive Stacks in Five Use Cases</b></h2><h5 class="post__date">2017-09-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_Orluu4VhmY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello and welcome to my talk my name is
Ross in stay on chip I'm a commuter on
the spring framework team last year I
gave a talk introducing reactive
programming and I'm very honored to be
back this year to talk about the two web
stacks that we have in a spring
framework five and we're just weeks
ahead of GA it's been a long journey but
we're almost there
I want to start with a quick disclaimer
you may not know anything about reactive
if you haven't done anything in the
space you might need to compliment a
little bit with some other talks in
addition to this it's a bit of a tricky
space it can be a little bit of a
challenge to to catch up unless you
actually try it but the good thing is
that we're going to take a look at some
examples so you should be able to follow
along for the most part if you have
experience in building web applications
and working with a servlet stack I also
want to say that you actually don't have
to have spring backgrounds you don't
have to know much about developing web
applications with spring MVC my interest
is more in showing the evolution of the
servlet stack and what most people are
using for developing web applications
mm-hmm again the syntax that you see you
should be able to follow along as long
as you've been building rest and web
applications that shouldn't be too much
of a challenge so again my interest is
in showing that evolution of the server
stack because there are certain things
that we've been doing for a very long
time and over the last four to five
years one could say that Java has caught
up in the productivity area with the
rise of full stack frameworks like
spring boot catching up to the likes of
Ruby on Rails in terms of being able to
to get up to speed and be productive
very quickly and what I'm going to talk
about today is a similar revolution in
the execution model that we're using
bringing it on
with the likes of nodejs in terms of
having an asynchronous non-blocking
foundation and using a kind of a very
different approach to getting the most
out of the hardware and an efficient use
of resources so so we'll talk about that
on the Left left-hand side you see a
traditional servlet stack including a
servlet container consume through the
servlet API and then a web framework on
top and then on the right hand side
you'll see that there are some new
non-blocking asynchronous runtimes very
notably you have Neddie
which is a very widely used asynchronous
not walking runtime so for anybody doing
much in that space there's a good chance
that this is you know something that
you've looked at or heard about and
obviously if we have additional runtimes
then we can't really be using the
servlet API on top and this is an
interesting point in itself because the
things that I will talk about in terms
of the execution model and the use of
non blocking i/o a lot of that has been
happening in a servlet space as well in
a servlet container space I should say
the likes of jetty and Tomcat have been
innovating and refactoring quite a bit
over the quite a few years now to come
up to you know modern workloads and to
make a ton of improvements but what
hasn't really happened as much is the
programming model on top to catch up and
that's really what we're talking about
here you will notice that in spring 5 we
actually have a name for this parallel
web framework - spring MVC it's called
spring by flux so we have spring MVC and
spring web works and I also want to
mention that it isn't just the web stack
I mean the web stack is very important
but when you develop web applications
you will also be working with data so
there are other efforts that
you know create more of a vertical
approach so you have spring data
reactive that's coming out it's already
in late milestone phases so there's a
lot of stuff that you can try out and
that we're gonna take a look at today
spring security already has a couple of
milestones so all of these things that
you need to actually run applications
now you will notice that what we have
next to the servlet API is something
called reactive streams how many of you
have heard of reactive streams the
specification ok so this is by now
pretty well understood for those of you
who haven't heard about it
it's a specification that's turn out to
be extremely useful it's a very very
small spec actually about 4 interfaces
the deals in this space with
interoperability across components that
are built to be asynchronous and non
blocking so if you have for example a
Mongo driver as we will take a look at
if you have a web framework you have a
non-blocking runtime you can bring those
together through reactive streams and it
could be using our eggs over or reactor
different reactive libraries so first
we're gonna start by taking a look at
the servlet stack and this is probably
going to look very familiar this is a
classic thread per request execution
model this is where we started back in
the 90s when the servlet API was created
and this is of course a very kind of
synchronous imperative style API it's
very very easy and simple to write and
you know we have for example the filter
and a servlet contracts and those return
void which basically means that they're
not they assume that if any kind of
blocking needs to be done within them
like calling a database obviously we're
gonna have to wait until that's complete
and that's what this method signature
implies also there is blocking i/o going
on the input and output stream when you
call read or when you call writing and I
have to block until that completes so if
you have a really slow HTTP client that
means that it may take a little while
before that
all returns so for this reason we have a
threat pool that is underneath the
servlet API and those are the two kinds
of things that may block and we need
that threat pool in order to achieve
concurrency so we may block in the
application itself or we may block when
reading or writing to the clients and in
many ways the story about what we're
talking about here the whole you know
subject and why we're even talking about
a synchronicity and non-blocking is a
story of growing a synchronicity the use
of more asynchronous things that we do
in our applications so we've been using
the server with API in a servlet stack
for a very long time and maybe some of
you will argue or will have an
experience where there isn't really a
specific problem in which case you don't
really need to change so this is not
about old versus new this is about kind
of a synchronicity creeping in you know
that very popular track next door where
a lot of people are the micro-services
work that we do that kind of changes our
expectations and almost out of the box
there's plenty of a synchronicity and
you know you could argue the server API
just wasn't built for that it wasn't
built in the of course you can do
asynchronous things but the more you do
of it the more it becomes a challenge
the model is not set up in the best
possible way to make the most also out
of the hardware now we do have some
things that have happened over time
obviously it's been a long time almost
20 years since the server the API was
created so for example back around 2009
we got the server trio async API which
means that we can call start async on
the request and then we can exit the
thread so we do this particular dance
that you will see here where we're
starting out as usual the thread per
request but then we can say start racing
and then we kind of tiptoe
out of the threads meaning that we're
gonna exit all the way from the filter
chain without doing anything knowing
that we're starting asynchronous work
then we can do some work or wait for an
event without holding the servlet
container thread and when that work is
done or when we have an event we can
call dispatch on the async context that
the request gave us back and now we can
get back into the call stack and
complete the work so it's a little bit
you know obviously it wasn't originally
created for that sort of thing but it
turns out to be quite effective you know
in being able to do quite a few things
for example we in spring MVC we
integrated the async API back in the day
you know 3.2 a few years ago and it's
been quite widely used it's actually
been success in point that out because
with a synchronicity and non-blocking
it's not always easy or even possible to
retrofit as we will see is the case of
non-blocking i/o but for asynchronous
request handling it's actually worked
out pretty well and it's it's very
widely used so in effect what this means
is that you can introduce an async
boundary between the request handling
that the controller does and the service
container thread pool you're not holding
up the thread while you're doing
asynchronous things which means that you
can use reactive clients like for
example making HTTP calls or calling a
reactive data repository inside the
controller and and that that works
pretty well
with a with a service container at the
end of the day input and output stream
is still blocking though so you're not
entirely you know in async non-blocking
land but again there's a lot of things
that you can do on the servlet stack
it's not a completely black or white
picture so let's talk a little bit about
concurrency models this is a common
misconception that I've come across
especially in in our community in
Java community because we've been doing
things in a specific way for so long
that actually talking about what it
means to be asynchronous can be
confusing because a synchronicity is
kind of a perceived perception from what
we're from the EM from some perspective
it doesn't really say how that a
synchronicity is achieved so what you
see here is that for asynchronous API
where we know that there may be some
kind of blocking we actually need a
large thread pool in order to achieve
concurrency if you're going to be
blocking while we're making calls to
something we need a thread or otherwise
we cannot process more of these and of
course Java makes that quite easy and
you've been doing this for a long time
and so in our minds a large thread pool
is almost synonymous with concurrency
you know I've seen reactions where well
if you now go to a fixed small thread
pool how can I be still concurrent right
but if you think about something like
nodejs
they have only one thread and they still
have to be a server-side application
they can handle large amounts of
concurrency so really there what this
means is that the different ways to
achieve concurrency and as it turns out
the model that nodejs for example uses
because they have to is very very good
for kind of efficient use of resources
you're not using as much memory because
you don't need as many threads that are
effectively part just waiting for some
kind of event to come back let's say
you're writing to making an HTTP call
and that call may take a while so now
you're sitting there with your entire
call stack and all the memory that that
holds for that to return
whereas with non-locking code you
actually only need a few threads and
when the results of these IO operations
come back then those worker threads can
go round robin fashion and process these
events without requiring additional
threats to be allocated so you know if
this doesn't make 100% sense
I just want to point it out and put it
in your mind that there are different
ways to achieve concurrency and that
doesn't necessarily mean that you need a
lot of threads with the synchronous API
so obviously it's very easy to program
that way it's very easy to write a
single call stack kind of assumption
type imperative code the one on the
right hand side is not doesn't come as a
free lunch you know there's actually
some work you need to do to achieve that
it's it's harder to write code this way
but there are benefits associated with
that so what does it take to actually
become non-blocking well at the core you
need an event loop you need some worker
threads that are doing the low-level i/o
like if we talk about an HTTP server
that's what all servers do at the core
tomcat JD Neddie they all do that they
have an event loop they handle a large
number of connections and when a
particular connection can do stuff like
read or write they will do that and then
when they can no longer do that then
they go move on to the next connection
simplifying a little bit but essentially
it's this kind of event loop driven
processing with a fixed number of small
threads also it implies that your
architecture is going to be a lot more
event-driven because if you think about
it you have your application algorithm
you can no longer just just go from top
to bottom imperative style programming
any of you have written messaging style
applications okay so what are we doing
event style messaging we actually split
it up we send messages and then you know
there's some kind of a queue and then
we're taking things off of that queue
with a small number of threads and we
can do parallel processing that way so
this is something that needs to happen
also in the application in order to be
able to be non-blocking we need to be
much more event-driven message passing
style architecture and we also need a
way to actually compose a synchro
logic because at the end of the day what
we're trying to do is not pass messages
we're trying to write application logic
and we don't want that to be too complex
so we need some means of composing
application logic as well and then as a
bonus in this kind of architecture when
you have a lot of events flowing
actually you begin to have the issue of
overflow and then you need a mechanism
to control if you can push back to the
source and say I'm not ready
you know it's not blocking i/o so maybe
you're not able to write so you don't
want the upstream source to be sending
any more events at the moment so let's
take a quick look at the reactive stack
as well so with the reactive stack we
have the HTTP server and the event loop
so the processing actually happens on
the event loop thread and this is true
for nettie obviously that's kind of the
way nettie works but it's interesting
that even for servlet containers so
servlet api has a non-blocking i/o from
separate 3.1 which is why we can also
build all this on top of servlet
containers we just can't use the server
the API in the application so this is
going to look very similar we have a
chain of filters and then we have a web
framework at the end but there is a key
difference here is that there's now a
very different assumption whereas with
the servlet API the Void return value
kind of implies that if you have to do
any kind of blocking that's going to be
absorbed by the large thread pool of the
servlet container here we're actually
running on the event loop which means
that you know it's maybe four threads
maybe eight threads depending on the
number of course you're not allowed to
block at any time because if you do
you're pretty much blocking the server
you know again if you think in node.js
terms we have a few extra threads here
but you know it's the same principle
we're not allocating extra threads to
achieve concurrency so we have to be
non-blocking
by default that's the default assumption
now
so we in order to achieve that we have a
a synchronous API you'll see the return
value is no longer void it's a thing
called mono void and mono is a type from
the reactor library for those of you
that may be familiar with Eric's Java so
our Java has the single type it's very
similar also to a completable feature in
java 8 the main difference is that mono
gives you composability
and it also gives you reactive streams
and backpressure which means that unlike
a completable future with a mono until
there is a subscriber ready to consume
the outputs no work actually happens so
it has that deferred nature also for
non-blocking
input so if we were reading the body of
the request it's no longer the input
stream because that's blocking i/o again
we actually have a flux data structure
again that's from the reactor library so
we're reading and writing with a flux
and flux is a reactive stories publisher
also but it represents 0 to n elements
and again in terms of our exact this
would be an observable so for those of
you familiar with our java and i just
want to emphasize one more time that in
the non blocking world when you say get
body or when you save right you're not
actually writing you are declaring what
you will do because if you think about
what you're what you're getting back
here is a flux that's a promise of the
data the data is not yet consumed and on
that flux you can compose your logic you
can say what should happen next very
similar to the way you would use a Java
eight stream API and you would use
operators to declare what kind of logic
you want to apply in the case of spring
wet flux we're gonna take these data
buffers and we're going to deserialize
into JSON from json into objects
to make those available to the
application but the point is that we're
not actually reading we're not actually
writing so if you think about what
happens is that as you make a pass
through the filter chain there's
actually two separate phases and this is
again this is just kind of the wane on
walking in a sink works in the initial
pass through the filter chain we're not
actually doing any work we're declaring
the logic for the application
asynchronous style and then once the
whole chain is is built the actual
processing begins by the subscriber at
the end of the chain kicking it off by
subscribing and now the data starts
flowing and again this brings me back to
the point about a messaging message
messaging style event-driven
architecture except in your application
you're just using observable or reactor
flux but under the covers you will see
that what looks like a lot like
messaging application you have different
processing chunks of logic and then you
know there's data flowing on those monos
and fluxes and just to point out once
again reactive streams is an
interoperability spec so flux for
example is a reactive streams publisher
which means that when you subscribe to
it it's a it's a source of data it's
gonna give you some you know let's say
it's a Mongo driver it gives you some
data you can actually control how much
data comes at you by making a request
and you can indicate how many items
should come back to you and then those
items come only if you request them so
that's the concept of back pressure here
dealing with overflow of events
okay so let's actually take a look at
some code so I have a here to demo I'm
gonna start there different parts to it
so I'm just gonna start first with
showing you a car repository and this is
using the reactive repository from
spring data kay is this visible in the
back can you see well yeah good so again
you may not be familiar with spring data
but it's a really simple concept you
just implement an interface and that
gives you methods that you can use to to
insert and retrieve data so for example
you have insert here you have find all
and what you will notice is that these
methods are actually using reactive
types so this is the reactive data
support and I'll talk about it a label
in a little bit then I have a spring MVC
or spring web blocks we actually support
the same programming model on top with
flexible method signatures so you have a
controller method which is mapped to the
slash cars URL and that's a get mapping
and we're going to call the repository
and simply return the the output of that
from the controller and that's what we
want to write the HTTP response with and
if you take a look at the car this is
kind of like a ubirr lyft application
obviously extremely simplistic but we
have a car with a location and then each
location has a longitude and latitude
and this is a spring boot app and I'm
just gonna show you quickly the palm
I am simply using the web starter so the
web starter in spring boot gives me the
traditional service stack with Tomcat
spring MVC kind of you know automatic
defaults
we're gonna switch in a moment to wet
flux which gives us different the
reactive stack so let's go ahead and oh
one last thing here so on startup we're
going to insert some cars into the Mongo
collection you can see here we're
actually using it's kind of interesting
if you haven't seen flux in action we're
going to generate a range from 1 to 100
and then we're going to map each number
into an actual we're gonna create a car
out of that and we're gonna generate a
random location in the vicinity and then
we're going to save that to the Mongo
collection so let's go ahead and start
this
okay so once this is up and running you
will see that we are running on Tomcat
and that's the default it's very easy to
switch to another server container like
JD but by default we come up with Tomcat
so let's do ad
we're on a t1 here and we're gonna get a
JSON array back of all the 100 cars and
locations that we inserted I just want
to show here the JSON and let's take a
quick look at the output so what you
will see here this is the Tomcat thread
so this is kind of the server trio a
sync again we're executing here with
spring MVC unsurveyed stack so we're
using the server trio async requests
this is the Tomcat thread you can also
see the reactive streams contract here
in action because we got a flux back
from the controller spring MVC will
subscribe to that flux mm-hmm and you
can see that it's requesting unbounded
which means give me all the elements
you've got and I'll talk about that in a
moment why that is but we're then saying
concurrent handling started we're going
to leave the response open because we're
gonna exit all the way from the thread
and now we're going to get all the data
back and this is the threat coming from
Mongo producing the data into the flux
once we get all hundreds of them we got
a kind of a whole array list and then
we're going to get back
dispatch back into the server container
thread again that's the little server
trio a sync dance so let's go ahead and
change now to wet flux and this is the
wet flix starter in spring boot and this
is kind of neat I mean I actually
haven't changed the
I haven't changed the code so the coding
is exactly the same but I've switched
the stacks and you will see that
underneath now I'm running on Nettie by
default spring boot 2 is actually using
Nettie because that's a better
experience out of the box and this is
not to say that Tomcat is you know not
as good as Nettie that's kind of a
loaded comparison anyway that's a lot
more complex but there's certain things
around the server 3 Oh a sink and server
3 1 as well that aren't quite as well
done like detecting disconnected clients
they're they're little things like that
which in the scheme of things aren't
that little but they're more tied to the
service API than to Tomcat really so we
have an ad out of the box so let's go
ahead and execute the same thing here
and same outputs if we now take a look
at what happened here very similar but
we're not you're not gonna see that
whole back and forth with two different
threads it's just the reactor native
threads and then we're subscribing once
again unbounded and we get all the data
back and that's it you know it's it's a
little bit simpler we're not like
switching threads as many times
ok so let's recap here basically we
think that whether you're on the servlet
stack and there are many existing
applications that are going to continue
to be on the service stack even if
you're writing a new application you may
consider doing that because it's simple
enough you know to write applications
that way or maybe because you're not
ready to go all the way on the reactive
stack because the programming model is
actually requires you to learn quite a
bit more but one thing that's quite easy
to do which is good for micro services
is that you can call a reactive data
repository and you can do that from the
spring MVC controller and you return
that flux or we support Eric's Java you
can return observable as well and then
spring MVC will know what to do from
there and deal with the whole reactive
pooling of the data but here's an
interesting
question a flux represents a potentially
infinite stream of data right so if we
give a flux to the web framework spring
and Miss your wet flux how does it know
actually what to do are we going to be
writing an infinite stream or are we
going to be writing a collection and
sending back a JSON array that's an
important question actually we need to
know which one of these two is it
because with the collection we can
actually buffer all the elements and
then write it out besides we need to
write it as a JSON array whereas with
the infinite stream we need to flush
after each item to make sure it shows up
immediately they may be some time in
between each item so generally you know
those two use cases are quite different
so basically the answer is that we use
the media type to determine what you
actually intend to do so for example if
we know that the client or the server
you know but both can indicate the
preference
wants to produce JSON the only way to
produce JSON is actually valid JSON out
of a collection is to produce a JSON
array right I mean that's that's what we
have to go with and because browsers so
if you think about browsers which you
know may be a common use case here they
don't know how to consume a stream other
than server-sent events so the media
type for that has to be text event
stream or otherwise we have to produce a
JSON array or otherwise the browser we
can be streaming but the browser is not
going to get any of the data until we
write all of it so by default we tend to
assume that what you want to do is to
write application JSON that's why you
see that there's no back pressure we
know that this is kind of a collection
we ask for all the data to come we
accumulated you know in a list and then
we write that out as a JSON array but it
actually is more interesting to see back
pressure in action so this is we're
going to look at the streaming scenarios
and there's a
couple of different media types that can
indicate streaming obviously one of them
server-sent events but if you're not in
a browser or if you're streaming up to
the server you might use applications
stream JSON which essentially looks a
lot like a JSON array without the angle
brackets around it so it just basically
a JSON object one line at a time you
know pretty straightforward simple
concept but you know we kind of have to
know which of these cases it is so what
do we do in the case of streaming again
we're a little bit different we're not
accumulating into a list we're going to
be requesting from the source of the
data to give us some items and and
that's going to be a specific number not
saying give me all you've got then we're
going to write whatever we get we're
gonna flush immediately to make sure
that it's immediately seen by the client
and then we're gonna keep repeating that
possibly forever so this is what it
looks like here we're indicating from
the server side that we're going to be
sending SSE now interestingly the way
the backpressure works on the servlet
stack so if we're doing this right here
on a servlet stack we have to back
pressure against the blocking right at
the end of the day there's no getting
away from the fact that when you write
to the response to the server the output
stream that's a blocking right so the
only way to implement back pressure in
that case is to actually wait for the
blocking right to complete and then ask
for the next item and you just keep
doing that so that's basically your
strategy for back pressure if you keep
asking for more items then they're gonna
back up right so obviously we have to
apply this kind of back pressure
translate into this kind of simple one
by one back pressure
survey three one non-blocking i/o well
this is what I mentioned earlier that
unlike the server trio async with survey
three one non-blocking it's actually
really hard read impossible to retrofit
into an existing ecosystem of frameworks
and applications because it goes so deep
into the into the you know framework and
stack that you can't you can't undo you
know what is already been written as a
blocking code also the service api
itself contradicts itself if you go down
the path of 73 one non-blocking i/o you
have to forget about many parts of the
soviet api like you can't call get
parameter because that may block trying
to read from the request body there's
all kinds of things like that which
practically mean that you can do
non-blocking i/o on a service container
but not with the rest of the service api
so on the reactive stack we actually
adapt to a non-blocking runtime which
means that we can do back pressure all
the way to the socket and that's pretty
neat I mean you've got say the data
repository all the way on the right
reacted data repository then you have
the controller doing some work then you
have the web framework and then we have
a reactive layer on top of the HTTP
server and you've got back pressure
across all of these components
thanks to reactive streams and that's
very powerful because if the HTTP client
is slow let's say flaky client / bad
network we're not ready to write we have
a way of you know the non-blocking
runtime gives us a way to check for that
we can translate that into back pressure
and that will go all the way to the
upstream to say don't give us any more
items because we're not ready to to
write them and and that's a very
powerful mechanism so let's take a look
at that in action so we're still running
here with web flux
and I'm gonna take the same query but
I'm just going to add a HTTP a media
type let's do event stream SSE so now
we're getting the data back as
server-sent events but let's take a look
at the no I don't want to exit over here
so let's see what happened over here
this time we did a subscribe and you can
see that it's asking for a certain
amount of items at a time and this is
the implementation of the reactive
library that we're using in this case
reactor it's asking for 31 items to
start and then we're getting 31
instances from the Mongo repository then
it's asking for 24 more and we keep
going like this and what's interesting
here is that if at some point you know
obviously this went fast but if at some
point we had to block we're not holding
on to any threads so the cost of an
extra connection at that point it is
pretty cheap because we're you know our
whole stack is built to work pretty well
with that so let's switch quickly to
back to service stack here
okay so you can see we're back on Tomcat
and I'm gonna do the same thing and once
again I'm gonna get server-sent events
now what happened here you will see that
we're going through the reactive trees
protocol also but we're doing one item
at a time and the other thing you will
see is that the right is actually
performed on a on a thread because we're
switching from non-blocking library to a
blocking right we don't want to block in
this case the Mongo thread on which we
are trying to make that right so we have
to switch threads as well to ensure that
that blocking right can be absorbed with
an extra thread to achieve concurrency
you know that's the strategy for
blocking operations so we do that
automatically which means that in spring
MVC once again you can simply return a
flux and then if that's a streaming
scenario we're actually going to apply
back pressure against the source and
we're going to do the blocking right to
the HTTP response output stream using a
dedicated thread pool for that so you
can do reactive stuff but obviously at
the end of the day your input and output
to the client is still blocking
okay now reactive remote service
orchestration let's continue with the
demo here so I'm going to show you the
other bits of the application so this is
a car location service that gives me a
list of cars and locations then there's
also a request booking application and
that one is very simple it simulates a
driver say for example we make a request
to to a car and then the driver can
respond within a certain amount of time
to accept and you can see here again you
know I'm using mano here to simulate a
random think time of two to five seconds
for the driver to respond obviously it's
gonna be more than that but that's for
the demo here and then I have a
front-end app let me just start this one
while I'm showing the other so that one
is on 80-82 and then the front-end app
looks like this so this is a this is a
spring MVC to start application and it's
using the reactive web client you will
see here that it's actually making a
call to that URL we've been using slash
cars then it's deserializing to car each
item then it's taking the first five of
those and then it's making a nested
operation using flatmap to make a call
for each one of those to the other
service to actually try and perform a
booking and then whichever comes back
first we're gonna take that one so
that's kind of pretty nice orchestration
and we're using a reactive web client
which is pretty smart about using
resources it's not gonna you know use
extra threads etc so let's go ahead and
run that as well
so what I'm going to do is hey this one
is 8080 just just give me a book me a
car basically and we have to actually
make it a post an HTTP POST so there is
the random thing time of two to five
seconds and if we take a look at the
outputs for the car application you will
see here that it made the calls to get
cars and then it got five the first five
and then it made an attempt to book each
one of those in you know separate HTTP
calls and then the first one to come
back
let's see which one did we get that was
car number four so pretty nice actually
that we can do something like this it
works with spring MVC and spring web
flux we can use we can do reactive style
orchestration of remote HTTP calls do
stuff like this and I don't know if you
do this sort of thing or how I feel
about it but I think when you you know
do something like that it's usually a
good moment to kind of boast to your
colleagues you know what you just
achieved because you know it is it is
cool so for the fourth use case reactive
request input this is something that is
now reactive stack territory only
because while we can do reactive request
handling returned a flux from on the
server stack in a spring MVC controller
it's actually not possible to make the
input non-blocking
you know that's that's actually quite
quite difficult to achieve and not
really possible without using
non-blocking i/o so we are talking about
doing something like this taking the
body of the request deserialized as json
or something maybe xml possibly and then
working with that so the thing to
realize that that when this controller
method is invoked the body
hasn't been read yet you know this is
just a promise to give me the body is
that particular object type and we can
turn around and we can do some
composition of logic on that or we can
pass it into the reactive Mongo
repository here which then returns a
mono void which is again a promise that
tells us did that succeed or did that
fail but again when we're making a pass
through this controller method we're not
actually executing or reading the data
yet we're just declaring what will
happen that kind of takes some getting
used to that thinking if anybody comes
from a node.js background that's
probably like yeah that's the way it
works but for us in Java you know it's
not the way we're used to thinking so it
takes an adjustment so an extension of
that which is quite interesting is in a
game these are scenarios where the
non-blocking all the way reactive stack
you know just shines because it just
becomes so easy to do these things so
what I'm going to show you is is a
service which well the car service right
we inserted a bunch of cars on startup
but what if we could upload these
locations into the service and and we're
going to consume them as you can see
here the request body with back pressure
which means that as we're reading from
the socket we can tell the socket to
stop reading if we're not ready to
consume the data and what we're gonna do
in this case well here we're inserting
it into a repository and then and then
we're going to also stream that down so
so let's take a look at the code
actually so for that I want to make sure
that I'm on what flux for the car
location service because again that's
only possible to do on the reactive
stack and I'm going to restart that
application
so this is my car location service and
I'm running on Eddie so now what I'm
gonna do is go to my I forgot to do
something
one second here so back in the car
location service app I mentioned that
there is this method with it salable
annotation so this is for finding cars
and the terrible annotation is is
support that hooks into Mongo for an
infinite collection so this is a
streaming scenario where as things
appear in the collection I want to see
them so I'm going to switch to using
that in my controller so I'm gonna use
to switch to that method find cars by
and I'm now I'm going to restart and you
remember before that when I did
server-sent events it gave me the
hundred and then and then it finished
because the the flux completed and it
said there are no more items but now
what we actually want is a streaming so
I'm going to do let's see if I can get
it from here so now it's actually
waiting for more data to arrive because
that's an infinite collection and that's
how we're getting it from Mongo and then
I'm going to show you easier to get to
it here the uploads app so for this what
I have is I am again interesting to just
observe flux in action a lot of the
operators are very closely aligned to
our exam uh so if you're familiar with
rxjs or RX java reactor and rx Java are
very similar the way that I would
describe it is that reactor is more
positioned to be the server side Java
you know with reactive streams first and
foremost and then borrowing a lot of
influence from reactive X so here we
have the interval operator and we're
going to produce a
every two seconds or an event if you
will and then out of that we're going to
generate a car random car location and
that is a stream so then we're going to
do a post to slash cars we're going to
send that as a stream of JS as a JSON
stream basically one JSON object at a
time we're going to pass the stream into
the body method and then we're going to
say retrieve and now we're going to get
the confirmations back and that's kind
of interesting to see on the controller
side as well so on the controller side
this is where we're consuming the stream
we're inserting it into the Mongo
repository and that gives us back well
you see it here we get back a flux of
cars and those are the confirmations for
each inserted car right because if at
some point it stops we want to know how
many were actually inserted so that's
kind of working with stream semantics so
we still have this guy here sitting and
waiting and now I'm gonna go back to the
uploads and get that started so this is
now uploading into the controller on the
server side and over here so I have one
client uploading data into the car
location service then the car location
controller is taking that inserting it
into the Mongo repository with back
pressure coming from the socket as we're
reading and into the Mongo collection
and then we have another client that's
actually pulling down a stream and as
those locations are going into the Mongo
collection we're streaming down again
with back pressure so these kinds of
streaming scenarios become very easy to
deal with in webparts
okay so we can stop and again we're
going all the way to the HTTP server and
applying back pressure in both
directions so essentially on the servlet
stack we can use reactive clients
because we have servlet Rio a
synchronous requests it means that we
can effectively do asynchronous work in
the controller and kind of separate the
request handling from the servlet
container thread that allows us to do
streaming to the response with back
pressure it allows us to use reactive
HTTP client like the web client in
spring five so that's instantly usable
in present-day applications with very
little effort it means you don't have to
switch wholesale to being reactive and
using flux or observable for everything
you do which is not an easy transition
it takes it takes some time you know I
haven't seen anybody who said you know
this this was so easy from the start but
when we start talking about reading from
the body of the request or any scenarios
on that side you're not gonna be able to
make that non-blocking
and you're also not gonna be able to
make the right back to the client any
input output through the servlet input
and output stream is going to be still
blocking and that's gonna require
threads again not necessarily a bad
thing you know if your application
scales fine yeah you know it's very easy
to fall into the mindset of you know
this is the new and cool stuff and
that's the way to go now versus this is
the old stuff
well if it works you know it's actually
a lot simpler to write server
applications because of the imperative
programming model but if you're feeling
this kind of pain if you're already
checking out you know different
frameworks with different execution
models then the reactive stack is a
hundred percent kind of in that
direction
where you can get a complete reactive
stack non-blocking asynchronous
foundation and all of these scenarios
become
a hundred percent possible so with fats
I'm going to this is the end of my talk
here so if there are any questions I'll
be happy to take some now yeah
writing to the database
assuming you have a non-blocking driver
yeah or you could always do it on the
thread as a blocking right yeah so at
the moment the reactive data repository
in spring day decay has implementations
for Mongo Redis and Cassandra
there is no asynchronous database JDBC
driver I know there's some work going on
for from Oracle that was announced last
year at Java one but that's not out yet
my question is are you sharing your code
on any github project or anything
whether I will share the demo code yes I
will I will put a link in the in the
slides and share it yep
hey Russ and thank you I was wondering
if you could shed some light on perhaps
the direction of spraying whether it's
gonna continue to support both rx Java
and the reactor and project reactor
moving forward are we gonna converge on
one of the text eventually okay so the
question is again about our exam over
C's reactor and our support so what we
found out is that in order for us to
build a reactive web framework our
reactors stack we need to use a reactive
framework so we chose reactor for that
well a because it's closely developed
with Spring Framework there's a lot of
collaboration that happens we actually
went through trying to do things and
then they went through evolving their
framework so it was a very symbiotic
relationship there
the
gain reactor is built with server-side
Java in minds I think Eric's Java comes
a little bit more from the background of
you know Android and client-side it's
aligned with its origins come from
client-side like rxjs but then again the
operators are very aligned so we take
all the inspiration but we don't feel
obliged to be a hundred percent reactive
X in every respect in terms of the
support so the fact that we use reactor
internally is not an issue you can do
all of these samples using our eggs Java
and it's actually really not difficult
for us to support that combination we
have a bunch of adaptors so we don't
even have to directly depend on our exam
in any way but there are certain areas
where we have to choose like the more
functional API is the web client the
functional web framework that we have
web flex FM we're calling it which I did
not talk about here but in those areas
we've chosen reactor you can still
easily switch to using our Java from
there because using operators but again
you know we where we can with flexible
method signatures we support our Java
because it actually doesn't doesn't cost
us a lot of extra effort in spring MVC
you could store your fret context in
Fred local who's being security did that
as well what is the best way to do that
with the new web so in terms of
replacements for thread-local it's one
of those things which is a convenience
we've been using because we're executing
on a same call stack here the natural
model of execution with message passing
and non blocking is that we're actually
operating on many different threads and
switching all the time so it's really
not easy to achieve that reactor has a
feature now for context passing so if
you're using reactor all the way in the
application and in the framework then we
can achieve this kind of context passing
but we haven't built the features in web
flex yet to make it take advantage of
that so ultimately part of the answer is
we have to look away for
you know these kinds of habits because
they're not so easy or possible but in
certain situations you know when you can
make assumptions about what libraries
are used it may be possible to achieve
the same effect
is there a roadmap there is actually a
ticket that was open that you can find
in JIRA that summarized all of these
questions like asking specifically for
for that kind of support so we're
definitely going to look at it probably
get something into 500 GA but again
there are no easy answers especially if
you use different libraries reactive
libraries big kill for coming I think
Rosen will be around here for a minute
if you have any more questions and I
hope to see you all back in the
afternoon</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>