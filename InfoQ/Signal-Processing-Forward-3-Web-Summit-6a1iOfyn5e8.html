<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Signal Processing - Forward 3 Web Summit | Coder Coacher - Coaching Coders</title><meta content="Signal Processing - Forward 3 Web Summit - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Signal Processing - Forward 3 Web Summit</b></h2><h5 class="post__date">2015-07-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6a1iOfyn5e8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm a a couple times through this
presentation
Mike and begin having a coughing fit I'm
a little bit ill please don't hold it
against me but today we're going to be
talking a little bit about signal
processing would a sample it any other
rate sound is sweet so we're going to
talk a little bit about how our brains
interpret sound scientifically out sound
works and how computers interpret sound
but we'll just start with a bit of an
introduction a bit of saying hello so
I'm miles that's a cartoon of me I
really like it I currently work at a
company called famous industries heading
up the famous or project famous is a web
platform for making beautiful
experiences on the web if you have any
questions about it just grab me
afterwards I'm more than happy to talk
about and answer any questions believe
it or not but I actually got into
programming through making art my
undergraduate degree was in fine art and
my master's degree was in music I've got
a couple example installations I can
show you a little bit but early on you
know like when I first got it got
started I actually didn't really know
much about programming at all or how
anything worked and I learned about it
through trial and error through building
installations through playing with them
a lot of playing with Arduino 'he's a
lot of playing with maximus p this is an
example of an installation that i did
many years ago called string theory
where i used a laser I had the laser
being controlled by sound it was
shooting into a pool of water it was
reflecting up into a whole bunch of
strings it was a really cool piece you
can see more details about it online on
my website another installation that I
did involving sound in space and
movement was this installation called
the speaker bot this may be loud we're
going to find out
but to this installation work through a
combination of different systems that
hidden in the back of the room was a
Kinect that was doing skeletal tracking
inside of the speaker was another
computer beagleboard XM as well as a
Wi-Fi router and they're communicating
back and forth that was a really
interesting project and then this
project which I did more recently and my
Master's where I was studying music
technology the voxel meter was a really
great way of exploring how rendering
systems work how how sound is visualized
looking at sound that's in the frequency
domain and playing with that you'll
actually see a little bit of an update
to this later in my presentation but so
let's talk about why I started
programming I started programming
because of the device that you see right
here that's not reacting because I
messed with the sound so let's see if we
can get that going really quickly turn
it on turn it off and on again is it
going I cool so this device is called
the mono emits a box of buttons it
doesn't really actually do anything it's
not programmed to do anything except for
send x and y coordinates to the computer
when you hit a button and then has an
API for sending messages to control the
lights prior to having seen this I
wasn't even into electronic music I
wasn't into programming I saw this thing
and it just blew my mind and got me
really into studying like how does this
work and how does this work became this
rabbit hole that just created this whole
career for me the monome introduced me
to a programming language called max/msp
which is a really really great way to
get started if you are a visual designer
if you're a an artist even as a
programmer if you're interested in
learning about sound the tutorials to
get you up and running and figure out
how to do some basic sound processing
and signal processing are really amazing
one of the cool things about Max is it
actually has access to its internal API
through a little language called
JavaScript so you can actually use
javascript in max to control pretty much
everything from creating unit generators
drawing unit generators connecting them
handling the business logic so this led
me to karma the Center for computer
research in music and acoustics where I
learned a lot of things that are bet to
tell you about today some of the core
science behind you know how our brains
interpret sound I already said that so
let's talk about it let's talk about how
our brains interpret sound and what it
means so we'll start with what's
sampling and you may hear sampling and
think about something like this but this
isn't exactly what we're talking about
this is an MPC it's a classic controller
used by many musicians we're making hip
hop you usually put a sample in each one
of the buttons you hit them you do some
really great mashups you can basically
turn the monome into one with a little
bit of code but we're going to take a
bit of different of a deeper dive into
sampling we're going to talk about
sampling theory sampling is the method
of converting an analog signal into
digital data and then the act of taking
that digital data and turning it back
into an analog signal so you can sample
many things but today we're going to
particularly talk about sampling sound
we sample sound any time we make a
digital recording unlike analog
recording which happens in constant time
digital recording needs to represented
in blocks we need to not think about it
as this like kind of ongoing thing it is
discrete representations it's something
in which we are viewing sampling
recording and then reading back you
could think about a sample in a way as a
pixel for sound when I started thinking
about things that way it really kind of
changed the way I thought about it it's
really cool also to think about you know
like a string of samples as an array in
the same way that you would start to
think about an image as a matrix and
that really changes the way you start
thinking about how you process sounds
things like a delay line can start
becoming an array with just you know
like a pointer in it so before we get
too deep I'm going to give you a bit of
a primer on some audio slang that you
might hear me saying sample rate a
sample rate is the number of samples per
second of sound and a calm
sample rate that you'll often see is
44.1 kilohertz bit depth is the number
of bits used to include a single sample
a common bit depth is 16 bits so a codec
is an algorithm that's used to encode an
audio signal into into a digital into
digital data and I caught them a common
codec that most people would know of off
can is an mp3 so let's tie this together
and look at like a practical example
which is a CD a CD is encoded in PCM
it's 16 bits per sample and 44,000 point
1 samples per second this is kind of the
encoding standard of how a CD is made
the algorithm involves encoding each
channel of sound into a number between
minus 1 and 1 and those numbers are
actually internet interleaved so if you
think about this like a CD and any file
on their away PCM you can think of as a
series of numbers in an array left
sample right sample left sample right
sample and that number between minus one
and one is actually a representation of
your speaker cone and whether or not
it's out or it's in and so really all
you're doing is sending electronic like
electrical signals to the speaker for it
to vibrate to recreate the vibrations in
air that the sound would have originally
made and it's pretty mind-bending when
you actually think that like it really
is that simple so many will refer to
like PCM encoding as a lossless encoding
because not a lot of data is lost in the
process much of the sound is kept as
opposed to something like an mp3 which
is lossy mp3 uses a number of different
psycho acoustic tricks which I can talk
to later if i have time to essentially
just delete data that you're not going
to use but so there are limitations to
sampling so specifically this everyone
just take a second read it you know
y'all got that right it's something
called the Nyquist limit it's named
after Harold my quest Harold my quests
work was built on by Claude Shannon
creating a lot of what we know today as
appling theorem yeah that really helps
but so let's dig into what the Nyquist
limit means because when you figure it
out it's actually really really cool
your sampling rate dictates the maximum
frequency that can be represented in a
signal so the Nyquist limit essentially
states whatever your sampling rate is
you can only represent a frequency
that's half the sampling rate so if we
were to sample the system at 8,000 Hertz
we can only represent frequencies up to
4,000 Hertz in that system everything
else ends up aliasing and coming back to
the beginning unless you do some sort of
filtering to get rid of that noise so
let's go back to a number that i
mentioned before 44.1 kilohertz it's a
standard sampling rate used in audio but
why it's actually really cool it's all
about the human ear in the brain humans
actually here to about 20,000 kilohertz
our inner ear is a cochlea it's kind of
shaped like a shell or like a spiral
with many many hairs and those hairs all
vibrate based on sound and they really
only vibrate up to about 20,000 Hertz if
you can hear up to 20,000 Hertz you're
doing pretty well so if you think about
it based on the Nyquist limit 40 41 is
actually it's a compression by sampling
a 44 1 we know that will have everything
up to about 20,000 Hertz which is pretty
much what anyone's going to ever
actually hear that psycho acoustics of
it so we can throw anything else out we
could record 96 thousand samples if we
wanted but we'd be recording twice as
much data but you know why would you
want a sample higher so 96 kilohertz
actually allows you to avoid a bunch of
aliasing as mentioning before any sample
that about that ends up above that limit
ends up back at the beginning so if
you're in a studio when you're recording
an album in your recording let's say
drums and you're hitting symbols which
have a lot of really high frequencies if
you're recording at 40 41 a lot of those
high frequencies are going to wrap
around and end up muddying up your low
end whereas you can record it 96
kilohertz apply a filter on the high end
then resample down to 40 41 when you go
into production on a CD and you have
sorry it's about to happen sorry II but
so yeah so when you when you bounce down
to production you're able to have like
way way less noise in your low end and
you know when you only have like one
thing that you record you won't really
notice it but just like any system as
you start introducing lots of different
things into the system that noise starts
adding up and it starts muddying up the
sound so when you mix up your guitar and
your bass and your drums and everything
eventually you just really can't hear
what's going on in the low end because
it's muddied up with all these aliased
sounds so why would you record at a
lower sample rate and what would that
sound like telephones for example or
traditionally sampled at 8,000 Hertz
again compression humans voices or
around the 4,000 Hertz range so we don't
need to encode much more data than that
and it's really easy to send more wire
more data on along the wire when we're
only dealing with 8,000 Hertz so let's
do a first demo so here we've got a
program called Adobe edition and we can
see the representation in the time
domain of the sample up here and the
representation in the frequency domain
and this is a sound that was recorded at
40 41 it's taken from a TV show you may
recognize it
I must be out or I pick up the phone so
if we go when we take a look at this
version of the sample that's been
resampled to 8,000 Hertz we can
immediately see in the frequency domain
a whole bunch of data has been lost and
changed and what's going to be really
cool you may not really pick it up over
this mic setup but it's going to
actually sound like it's coming over a
telephone now I must be off or I pick up
the phone
so one of the things that's really
interesting about that is that we can go
and take pretty much anything that you
record resample it to 8,000 Hertz and
all of a sudden that has this kind of
like principle where it just sounds like
it's on a telephone line and that's just
your brain messing with you because
everything you've ever heard at 8,000
Hertz has been you know through a
telephone so you have these kind of like
psycho acoustic things that are working
all the time your brain is playing
tricks on you but so let's go back to
the human here and let's talk about a
few things about why music works and
this starts getting really cool so as I
mentioned you know the exponential
response with the hairs in the ears all
the different hairs in your ears like
vibrate at different frequencies but the
frequencies that they vibrate are not
just randomly dispersed if you take a
look at the diagram here you can see
that they actually disperse out in an
exponential pattern what's really cool
is that exponential pattern actually
becomes linear when we talk about
experiencing pitch so up here on the top
we can see a 4 that's the fourth a on a
standard keyboard a 4 is traditionally
440 Hertz and the western music canon
that is the note that all other notes
are tuned off of so what's really cool
is a 5 the following a as 880 hurts it's
exactly double so what's neat is you
could literally take any arbitrary
random frequency multiply it by two and
you'll experience pitch being doubled
for me this becomes really cool because
there's very few phenomena that you can
have like kind of an empirical
measurement tied up with this kind of
like psycho acoustic or just kind of
like feeling like you feel what a tone
is and the fact that what you feel is
linear compared to the exponential
growth is really crazy and all of our
music is built off of these patterns
like yeah as frequency grows
exponentially we experience pitch
linearly pretty mind-boggling this was
originally discovered by Pythagoras
which is really really cool Pythagoras
discovered what we now know as the
Western musical canon the chromatic
scale
was discovered by Pythagoras the
diatonic scale that was discovered by
Pythagoras the circle of fifths that was
discovered by Pythagoras the greatest
musical achievement in the modern era
well that was actually fishes set to
rotation jam Deer Creek August 10th 1997
but I'm just like a dirty no-good fish
fan but what's really cool is that
musical notes as we know them today and
actually like all the musical notes that
we know are false and were lied to and
if you want to know some of that musical
history just grab me but these nodes
have existed longer as a means of
communication than the English language
that's crazy it's crazy you listen to
music and like you feel something and
like humans have been communicating that
way for like a really really really long
time so I got one more demo for you
before we go last night I stayed up and
I built a little spectrometer using
famous and WebGL and so very similar to
what's going on here and I want to just
take a second to describe what's going
on here how this works the codes
available online you can take a look at
it afterwards to kind of see how this
works but what's going on is we have my
microphone feed which is being read
using the Web Audio API that's being fed
into an analyzer node that analyzer node
is applying an FFT the fast Fourier
transform is a transform that can take
something from the time domain and move
it to the frequency domain so if we
think about two arrays and one array is
representing the time domain that's like
what we were talking about before in PCM
encoding so each sample in that array is
the amplitude of the sound at that
particular time what a net what
something in the frequency domain what
the FFT gives you is a block that
represents the amount of energy that's
in one particular frequency
at any particular time and the number of
bins that you get is relative to the
number of sample the sample size that
you take so to simplify that right here
what we're seeing is sixteen bins so if
we took a sample of 32 samples in the
time domain and put that through an FFT
what we're going to get our 16 values in
the frequency domain about how much how
much energy is in that particular bin so
all we're seeing here is a visualization
over time of overlapping windows of this
frequency domain being summed up and
essentially just driving a column I can
dig into the code afterwards I'll have
my computer with me the code is all
online on github if you have any
questions but you know what's really
cool is you can also think of each one
of these bins as one of the hairs in
your ears vibrating and how much it's
vibrating all these things kind of add
up there's lots of little things in
these systems and I find it pretty
amazing I think for right now that's
about all that I've got as far as
talking about audio talking about
sampling thank you so much for finding
the time if you have any questions at
all please grab me I have a lot of
literature I can put you towards a lot
of example code but thank you so much
for the time and again thank you Dave
and the team from Ford for putting on
this amazing conference
you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>