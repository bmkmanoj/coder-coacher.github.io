<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learn What fog Brings to Ruby in the Cloud | Coder Coacher - Coaching Coders</title><meta content="Learn What fog Brings to Ruby in the Cloud - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learn What fog Brings to Ruby in the Cloud</b></h2><h5 class="post__date">2011-01-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eP44AtS_oh8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm going to talk about kind of my
experiences engaging with the cloud and
which is kind of a mess and a lot of
ways and and kind of what's come out of
that and hopefully give you some real
examples that makes it easier for you to
understand what that mess is like and
make it not as much of a mess for you
and how you can kind of get in there and
really get some stuff done so I'm Wesley
Barry I go by Jameis online that's what
you'll see on you know Twitter github
stuff like that or IRC that's where you
can find me on the web basically is just
my github account that's probably the
main point of contact you can kind of
see what I'm hacking on fogs obviously a
large part of my focus but there's a lot
of little things that I do here and
there and Jameis on Twitter i work at
Engine Yard they actually I have the
good fortune of being paid to work
full-time on my own open source project
which is fantastic if you ever get that
opportunity I really recommend it but
it's I I don't really know how I did it
so you know it's kind of how that works
out I think and it's an engineer calm
their twitter is engine yard I think
probably a lot of people in this room
have had some exposure to that it's a
ruby hosting platform that's built well
we have a couple offerings now one's
kind of on top of Amazon and ones on top
of Terremark kind of a more entry level
versus a more advanced offering and they
both use a lot of fog underneath the
covers which kind of maybe helps explain
to some extent why it makes sense for
them to have me around so that that
expertise is in house and and the next
thing I think it's important to just
take a moment and say all right when he
says cloud what does he mean I mean do I
mean in the same sense of the you know
to the cloud Microsoft ads or you know
every single marketing thing thats
related to computing at all that seems
to have the word cloud and it these days
now I really don't for me cloud is API
driven on demand services right like
this isn't every single thing that the
word cloud is applied to these days and
and I mean clouds kind of this nebulous
thing you could use it on all these
things but for me it's not when I talk
about cloud and what fog is interested
in it's this right and I think some of
the core things that the things that
I've already done some work towards our
compute service dan
service and storage there are other ones
obviously that may get added to that
that's kind of right at the middle right
now I think like key value stores like
hosted key value stores are interested
hosted load balancers hosted Q stuff
like this but those are kind of like
there's not really a lot of offerings
and to some extent with fog like if
there aren't three people in the market
offering it it's not interesting yet
like yeah it's great that you know
amazon has a queue but unless there's 3
q's that i can look at and really
evaluate and figure out what consumers
accuse one it's very hard to to make a
good abstraction on top of that so so
you know kind of diving into that what
is this cloud thing so it's on demand
it's important because you only pay for
what you're actually using it isn't this
world where you say I'm going to need 10
servers next month so I'm going to pay
for a month of 10 servers it's I need 10
servers for the next hour so I'm going
to pay for an hour worth of 10 servers
and sorry if this is a little bit
rudimentary I just want to make sure you
know like foundations same page it's
flexible you can add and remove stuff in
in seconds or minutes instead of maybe
weeks or months as it might have taken
if you had to fill out you know these
are my requirements I'm going to need
this many servers and have to get who
knows how many people to sign off on it
so it's very fast it's this you know
agile almost infrastructure it's
repeatable I think it's really important
that you know it's not that you got a
box from dell and it happened to work
this time so you could get another box
from dell and it would work again it's
that you can actually run this code test
what you're doing with your
infrastructure make sure that it works
shut it all down and you should be able
to do it again and it should work
exactly the same way and there's also
some resiliency there and this is kind
of a mixed bag right like there's a
possibility that these resources might
disappear you know it's maybe not the
most likely but by coming into it with
that mindset you're more likely to work
around that problem and actually have an
infrastructure that can deal with the
fact that a server might go away because
it's really something that we should all
live with on a day-to-day basis
regardless of whether or not we're in
the cloud but i think we are you know
it's easy to forget about that if you
own the hardware because if anything
went wrong with it you could go fix it
so maybe you don't need to worry about
something going wrong with it per se so
hopefully that's kind of healthy so you
might say that's great this is all great
but but you know where do I even start
what provider should i use who's better
why are they better in its intimidating
every single service has its own area of
expertise that you know all of a sudden
there's all this stuff that you need to
know in order to be effective and and
then you know you get to looking at the
tools to try to figure out if there are
tools that make this easier for you it
seems like every tool has a little bit
different interface than the last one
some of the tools are very high quality
some maybe haven't had a patch in a year
and a half like did anything important
on that service happen in a year and a
half maybe maybe not some of the
services are very slow to change like
there's there's so many things that's
very difficult to figure out where to
even start this is where I came into
this about a year and a half or two
years ago when I got started on this
project so my response to all of this
was to start you know maybe very naively
maybe you tistic aleeh may be
masochistic alee i don't know you know
start on this library that was trying to
accommodate for some of these things so
I call it fog and it's a ruby cloud
services library so that's where you can
find it there's also a Twitter account
so if you have specific questions or
something you can kind of hop in there
and ask them quickly or there's an IRC
channel there's there's other ways that
you can get more information I'll go
into that a little bit later and so why
did I write another cloud services
library I mean there there are other
ones out there the first off is that I
very specifically try to work towards it
being portable here's just a handful of
the providers that have services
implemented and fog and it varies some
have very complete implementation some
have somewhat less complete
implementations but there's a lot of
stuff in there it's also very powerful
there's a lot of nice abstractions that
actually make it a lot easier to work
with it you don't need to know that it's
described instances but its list servers
on a different service like that that
doesn't really matter you can work with
it kind of on your terms instead of on
their terms and it's established we just
recently hit fifty thousand downloads of
the gem there's eight hundred and sixty
followers about now there's a little bit
more than 100 Forks there's 40
contributors as I said I work full-time
on it that's more than a lot of the
cloud tools can really say so I mean
like it's it's here to stay it's growing
it's it's getting better every day
and another thing that I think is really
valuable that not a lot of the other
tools necessarily have is there's
actually some built-in mocking in a lot
of places so you can actually simulate
what would happen in the cloud without
actually having to pay the cost of those
resources and especially one of the
hidden costs i think is if you're
developing this stuff there's a high
cost to the amount of time it takes to
actually provision resources in some
cases I mean if you have to run a bunch
of tests that involve spending up a
bunch of resources and it takes five or
ten minutes to even let the resources
spend up let alone run tests on them and
you want the test to be isolated so you
don't want to use the same resources for
every single test by the time you know
your before and after each blocks have
started up and shut down and server each
test takes 10 minutes or something I
mean it's just not it's not really
feasible so in our work at Engine Yard
as well we use a lot of mocked out stuff
and and that comes from that that we can
run a lot of these tests and have a high
level of confidence that we're doing the
right thing without waiting you know six
hours to find out we're doing the right
thing and so another thing is like who's
already using this and we already have
some big users gem cutter actually uses
it which is what powers rubygems they
use it for the rest three interactions
Engine Yard uses it for our platform i
mean like we already have some pretty
big users out of the gate I don't think
you need to worry too much that it's not
stable or that it isn't you know going
to be around there's enough interest
that I think we're past that point and
so that's great but probably the most
frequent thing I hear is I I don't know
how I would use that that sounds great
yeah that's great but I'm never going to
use that that's that doesn't apply to me
all right so I'm trying to I'm going to
try to fabricate a use case for you so
that you can get a better idea of how
this might fit together alright so we're
going to be entrepreneurs we're going to
write our own web service right and so I
decided that this up service is going to
be about up time because who wants a
busted website right that's going to be
your tagline we have this business lined
up we're going to make an uptime
monitoring service right and this is
good because the location of the things
matters right and we have access to a
bunch of different clouds we can spin up
boxes wherever we need to we can do this
pinging we can aggregate data etc etc so
I'm going to walk through what this
might look like theirs theirs
code coming now just in case you know
prepare yourselves so first off just to
get set up either pseudo or not gem
install fog kind of depending on your
setup I usually try to use our vm so
pseudo isn't necessary but if you're
just using default stuff you probably
need to use sudo and the first thing is
you just need to get a connection to the
service that you care about right so
this is going to look something like
this you're going to say I want a
compute thing from fog and I want it to
boot based on some set of credentials
right so here's an example set this is
for rackspace I'm saying it's it's the
provider is Rackspace and I'm just using
some constants so that you won't boot a
bunch of instances and cost me money you
know because that's no fun and the next
thing is pretty simple you have this
compute things that's your connection to
to rackspace and it has a notion of
servers which is a collection so you
kind of get into something akin to data
mapper active record ism's per se here
servers is a collection it has a
bootstrap method so I'm going to call
that with something called server
attributes which looks like this it has
an image ID and a place where it can
find private and public SSH keys for me
and so you might ask yourself what is
this servers thing so first off if you
just call compute servers it gives you
back a list of them this is the same as
coloring compute servers at all it's
like a lazy array so it'll fill itself
in if it needs to you can call servers
get with an ID this is a totally junk ID
this wouldn't really probably give you
anything on rackspace but an error but
nonetheless that I'll give you back a
particular server you can call reload so
the value of this is there are certain
cases where maybe it basically caches
the data so if you pull back a list of
servers but now you you're here ten
minutes later and you know that the guy
sitting next to you at your desk has the
same credentials and he's testing
something to you might want to call
reload to make sure that he didn't
create 10 new servers that are going to
conflict with what you're trying to do
when you call servers dot you know array
index three or something because that's
what you expected your server was going
to be you can also call knew what this
ends up doing is I mean this is kind of
again an active record type ISM you
end up with a local model that
represents what a server would be
without actually spending it up on the
remote service soon be useful sometimes
too kind of like stager your changes
kind of stage all of your attributes
that are going to use and you can call
save on it to actually say okay now I
really need you to go do your thing and
then is create which actually is just
that that new plus save kind of thing
that I said before so then of course I
left that bootstrap what what in the
world is this bootstrap thing like it
I'm cheating right so bootstrap is
actually it's a convenience method that
is specifically for servers because
servers isn't the only collection it
just is the one that you care about when
you're making this site up time thing so
this actually bundles together a few
things specifically for servers it's
going to call create with the attributes
you passed end and then there's a method
called wait for which takes a block and
the block gets called inside of the
server basically so this is ready method
that checks and says am i running yet
you know and and this is handy because
on every service lo and behold every
single service has a different way of
indicating ready right like it might be
state it might be status it might be
ready it might be running but you don't
have to worry about it you just say
ready yes ready okay so this will loop
until that returns true or 10 minutes
pass and a raisin error whichever comes
first and then there's an SSH method
this is why we pass those SSH keys and
in the first place is that as part of
the bootstrap it actually will take the
key that you gave it and make sure in
some way shape or form it gets placed on
the server and that varies a little bit
from service to service some will let
you provide it up front and they'll
inject it for you some you need to take
a root password that they gave you and
log into the box and place it and then
disable root password so that somebody
else can't maliciously take the root
password that the service is kind enough
to email to you in plain text you know
like so there's a lot of things where
you know this kind of like smooths that
over you don't need to know what all
these different services are doing fog
takes care of it so now on to we
actually need to get this data of our to
see if our site is up see what kind of
response times we're getting so we can
use this SSH method now that the keys
are in place to actually call and send a
command over the wire so I'm going to
call ping dash C 10 which means it runs
things and then you can get some
aggregate data back from it and target
in this case would be whatever site your
customer has that you want to make sure
is going right so from that we can say I
just want the standard out hopefully it
didn't tear or anything I mean if it did
we could do more complicated stuff but
we're going to use best case to start
with and then you're going to parse the
result right so the last line looks like
that it's a summary line and then I do
some crazy splits and stuff I apologize
if that is incomprehensible it reg exes
would have been immersed I swear and the
thing that I think that's important to
note here is this is the most complex
slide of the entire thing most complex
code and this is parsing a string from
pain it wasn't booting the server it
wasn't placing SSH keys nothing like
that all that stuff was super simple the
most complex thing you had to do was
parse the output of the SSH command you
ended up running so then in terms of
clean up you can call destroy on the
thing does the right thing shuts down
for you and then you can get the data
back as a hash that's that's the data
that got parse back out of that crazy
string parsing stuff and then we can
move on to the next step right so the
next step is all right that's great but
now I have paying from only one location
I want to make sure that even though the
ping was good from us West one or
whatever which is somewhere in
California I want to make sure that the
ping is good from you know us west east
or whatever right so in this case
instead of using Rackspace we're saying
it's a provider of AWS and here's the
keys and then you get a little bit
different server attributes this is an
area that I'm still trying to work on to
make this less to spare it but as it
turns out you know Rackspace versus
amazon the index images differently
right like they don't use ID of 47 is
Ubuntu no matter what cloud you're on
like there's there are some things that
are going to be very hard to just work
around so you may have to go to a little
bit of extra effort in that case but I'm
hoping it's a relatively small amount of
effort compared to obviously what it
would be if you had nothing to go for a
middle so this would be an example debt
and then to further you know that
example you could also just merge in a
different credential for the region for
amazon so that this would add a few more
places that you could ping from your up
to maybe five or six now and it's fairly
distributed bragg spaces in
central time zone roughly I think Austin
and maybe Chicago or something amazon
can give you left and right coasts
respectively of the US as well as Asia
and Europe like that's not bad in terms
of your pain data um you know that's a
pretty good distribution around the
world but even beyond that there are all
these other services that have a lot of
the same functionality work more or less
the same way and you know pretty soon
you have you know all the data you could
want so you just kind of leather rinse
repeat it's the same thing so you know
that's awesome but how did I know what
image IDs I wanted and how these other
things fit together and what methods I
needed to call well there's actually a
fog binary that comes when you install
the gym you can just type fog the first
time you ever run it it's going to look
a lot like this it's going to output a
big chunk of stuff that's y Amal and
it's going to say if you set up a file
that looks like this until the slash fog
you're going to be happier because then
it will boot and will actually have
access to stuff and so here's an example
I've set up some credentials i have
amazon and rackspace and so the next
thing that i'm going to talk about a
little bit is is what I'm going to call
sign post so there are ways that you can
basically say okay what can I do now
what can I do now I don't understand you
know like in this context what can I do
so the first is just at the top level
you can sell you providers this will
give you back the same list that was
kind of like nicely printed before so
you know Oh amazon and rackspace so
Rackspace what collections are available
and so it has directories files flavors
images and servers okay so this is
another thing that I can say Rackspace
compute I just want the compute provider
I don't want this mixed list of all the
collections and I'll give me that or i
can say give me the requests and it will
give me a list of the lower level things
that are happening behind the scenes of
the collections and models that are
usually hidden away from you but every
once a while maybe that has something
that the abstraction is not providing
and so those particular requests just
just to as an aside kind of to let you
know what that looks like because every
once in a while you need it it gives you
back an ex-con response ex-cons the HTTP
client i'm using which has a body
headers and status pretty
straightforward if you know HTTP stuff
and the the downside to this of course
is the body will almost always be like
just kind of a hash of something it
won't necessarily be parsed into a nice
but if you know what you're doing this
can be great because you might need to
do something that the abstraction does
not provide as I said so then we're just
going to go back and do a sanity check
we're going to check to see if we have
any servers that are still in the ready
state I think part of that is gone it's
supposed to delete them afterward I
think but anyway you're making sure you
don't still have any servers running
because you don't pay for him I've made
that mistake more than once where I
realized a day later that I still had 20
amazon instances running and I was out
70 bucks basically or something so I
would definitely recommend trying to do
this anytime you play around just
because otherwise badness so now how did
I find the image how did I know it was
47 or whatever was a bunchy that I
wanted and so if i call images this is
going to image the list there's a table
helper so you can say i want to table
the images that just has the idea name
and you'll get back I obviously omitted
a large part of this table but you'll
get something back that looks kind of
like this it looked kind of like the
MySQL table output that's in the console
or whatever which would make it a lot
easier to look particular things up and
that works on any of the collections and
then for AWS images I just cheat usually
and use there's a listing on elastic com
of kind of what the official ubuntu
releases are because the actual list you
get back from amazon of images is
incomprehensibly large and dense and
it's very hard to figure out what you
might actually want from it and so it's
great exploring but it takes a long time
you know sometimes to spin up servers or
whatever else and it's expensive and so
we're going to go into the mocking
infrastructure a little bit so you can
understand how you could also do this
exploration that way instead of doing it
against live for the you know same
benefits that you get from running tests
so for this you can either do fog mock
equals true and then run the binary
which will just turn mocking on before
it kind of boots up into the binary or
after you've required fog you can call
fog at Mach bang in order to turn that
on and it's it's a simulation right so
what happens is most of the functions
just work it just keeps kind of an
in-memory hash of these are the
instances that this person has asked for
these are the volumes that they've asked
for or whatever so that if you make
subsequent calls and say give me my list
of servers it can tell you
this doesn't cover everything I mean
it's pretty hard to make an in-memory
simulation of what SSH would do on a
random machine that's running ubuntu or
something so there's a few places where
it kind of punts where it either just
raises an error or perhaps it just says
this is always going to work I don't
care what you run on ssh it's going to
return true basically there won't be
errors there'll be empty strings and
standard out or whatever most cases
though it won't just be that it'll be
either to work or it's an unimplemented
mock so it'll raise an error that very
explicitly says sorry this is on an
unimplemented mock if you really want
this behavior maybe you should think
about implementing it because I haven't
gotten around to it yet so in that way
it should help keep you on track and it
can move things along in terms of you
know making sure you're on the right
track and the other thing is that I run
all of my test suite against both the
can the mocked and unlock stuff so
there's a few cases where I've just
marked a test pending if mock mode is on
because I literally haven't implemented
the mocks yet but for everything where
the marks are implemented I would expect
that all the tests pass so if you run
into a consistency issue where something
in the mocks and something in real life
don't actually agree that's a bug I'd
appreciate if you report it and i'll try
to get fixed the the ideal is that they
work exactly the same I think that's
probably incredibly unrealistic so I
mean they work as much the same as is
reasonable and as is you know helpful in
terms of testing and simulation so back
to business all right so we have all
this data now what are we going to do
with it right so now we're going to talk
about using cloud storage so that we can
actually aggravate some of this data
this probably looks a little bit
familiar to you there there's a little
bit of repetition coming into the
presentation now we use fog storage we
boot up the storage thing credentials
look like that looks a lot like the AWS
credentials from the compute thing and
then we have directories create
directories in this case are the
container that have many files in them
and then we say this is the key that we
want it to be called and whether or not
we want it to be public and then we say
I'm going to create a file so the body
is at this path if you use the file open
version of that
we'll actually stream it for you so you
don't have to really worry about that
you can also just explicitly pass a
string if you already have it in string
format or for some reason one to read it
into a string and it will also stream
that string but you don't really gain
the same benefit of not having the whole
thing in memory then and then you can
set the key and set whether or not
that's public as well and then you can
use the public URL method to give you
back a public URL if there is one so
whether if you've liked set it to
private this will actually just return
nil or if you're using a service that
doesn't have public URLs for instance
there's a local store which you just say
I want you to put everything in the
directory called foo you know home / foo
and so that won't have a public URL
because there's not really a direct way
to serve that so you get mail back but
that's across the different storage
providers which makes it pretty easy to
use so speaking of that geo storage you
know this is probably reminiscent to you
of stuff we're part of my slide is
missing so you can use these same
credentials to create a new connection
to a rack space storage provider and
that exact same set of code will work
exactly the same way well really it's
completely different behind the scenes
but I mean it's transparent to you that
it isn't the same and then again kind of
in terms of cleanup you want to get the
directory iterate over the files in the
directory and destroy them because you
can't destroy a directory that is an
empty then destroy the directory this is
less important because this stuff's
cheap but it's not like the servers
we're going to really regret it so you
know this back to geo aggregating right
so AWS is done there's Google local and
Rackspace so you can either rinse repeat
you know again you know you might you
might be getting the idea by now I hope
so phase three is profit right we have
our service we have data we're
aggregating that data but now we know
that we need to make some money from it
so we've decided we're going to
implement a freemium model because
that's the thing to do to make money
right so what we're going to do is offer
premium access so if you register your
company food company at my service
you'll get foo company my service com
right you can send your customers there
and they can see just how many nines you
have which is fantastic obviously more
9s better all right so created DNS
connection this
and probably looks familiar we're going
to use the rego this time should say
probably the rego access stuff instead
of AWS mistaking my slides I apologize
so we create a zone you just passed the
domain that you want and the email that
you want and then you're going to create
a record that's obviously a bogus IP
address but whatever the IP address of
the server was which you could get back
from the servers that you created
earlier or the server that you have
running somewhere else just kind of
whatever this is really handy because if
you're booting and shutting down a lot
of servers this is a way that you can
actually tie that into your gayness you
can use this maybe you could use round
robin DNS or something so that you'd
have it distributed over the 10 servers
that you happen to have running on
rackspace at a particular time what have
you in this case that we're just going
to add an a record that's going to be
customer name domain name pretty simple
but now there's you know our magical
subdomain we'd have to do some stuff
behind the scenes to do the right thing
on our appt probably but by golly our
DNS records there so again probably want
to go through and clean up you know it's
just good practice I just want to
emphasize that because this stuff costs
money and I hate it when I cost people
money that they don't want to actually
spend like that's just you know bad
business so this you know again there's
there's for providers for DNS right now
we took care of Zuri go but you can just
repeat the same code and I'll work
across these other providers and so just
a moment to talk about what the road map
looks like i have a strong intention of
working on compute and I could pretty
easily say as you saw from the slides
you can run the same code for DNS across
all these providers and the same code
for storage across all these providers
and when you do it with compute it's
sort of almost the same except for these
ten exceptions right I want to make that
like nine exceptions or something
instead of 10 so that's like that's
coming up basically is trying to smooth
those edges it's obviously like a bigger
problems based there's more providers
the providers do it in much more
disparate ways like it's a lot harder
which is why I haven't really done it
yet and I keep basically procrastinating
by working on the easy stuff but it's
it's slowly getting better another thing
is just kind of working on completion I
think in the near future i'm probably
going to pick a sort of core set of
services and say these are the big boys
these are going to get everything there
I'm going to make sure they have all the
requests and models and that
everything's mocked and everything's
tested and so on and so forth I don't
know what that set is yet I'd love to
hear feedback of what people are using
fog for what they want to make sure gets
into that corset amazon is probably a
gimme just because we use it at Engine
Yard and it's also probably one of the
most used services in there but some of
the other ones are probably more on the
fence I'm not going to throw anything
out completely but there's some stuff
that I won't necessarily throw as much
time at so you know that's going to
depend on what people need and errors is
a big thing because obviously every
service returns errors a little bit
differently I've done a little bit to
try to smooth that over so you will get
similar errors from different services
when similar things happen but it's also
a pretty difficult thing and it's not
always easy to necessarily cause those
errors when you want them in order to
make sure that everything's working
right way so that's a focus and of
course documentation is always a big
area of focus I'm trying to work more on
there's there's been a few blog posts
recently about adding more of those
adding more examples I have an examples
directory in the fog project now that
has sort of best practices for dns and
storage that will actually walk you
through kind of the workflow that i was
mentioning of like if you're willing to
you know it's you're willing to accept a
certain sort of subset of the total
functionality of these providers they
are pretty interchangeable especially
for dns and storage so those walk
through what that kind of best practice
looks like and then you can kind of go
off the path once you pick the one that
you really want to use if you need to
and also there's a website fall guy 0
which has practically nothing on it yet
but it exists and I'm trying to kind of
flesh that out but I want to open up to
questions I know that's a lot of
information a very brief period of time
so the question was basically so
basically what is the relationship
between fog and something like chef or
knife right knife is a tool that
actually kind of sits in between it's a
command line tool it uses chef to
configure machines it has fog
integration actually for a number of
services already so you can say like
knifes you know AWS servers create or
something like that and have a config
file somewhere I think
says the attributes like that kind of
like I was passing in and so it's this
weird kind of thing like I honestly feel
like knife is very strange right because
part of the goals and you know the what
what the plan for chef is is that it's
repeatable that you can check it into
source control that you know like you
have this very defined set of things and
to me a command-line tool is the exact
opposite of that like a command-line
tool you like you can't check in the
commands that you're running on the
command line tool not not in a
meaningful way really anyway it's hard
to repeat because it's easy to forget
exactly what invocation you used so on
some level I can't help but feel like
knife is a really cool like
demonstration conference application
kind of thing like it's a very cool way
for the chef guys to quickly show what
it can do but I feel like it's maybe not
what you wouldn't want at the end of the
day and so the other thing too is fog
itself doesn't really try to be very
opinionated or go very far in terms of
configuration like I showed you guys
very briefly the bootstrap which will
place SSH keys and there's the SSH
command which you can pass basically
arrays of strings into and it will run
this array of strings as a bunch of ssh
commands yeah technically you could
write scripts that use that to configure
the server and do everything you want
you know like you could just run this
huge thing you could check into source
control this huge list of commands but
it's not really that's also not really
repeatable not very easy to parse what's
changed or what's different so I think
there's space for both but I well
there's space for both fog and chef I
don't know about knife I feel like knife
is a cool toy I know that a lot of
people don't use it that way like a lot
of people use it as like the thing that
they use I think the thing is that it's
still kind of this mindset of like well
we kind of are used to controlling the
hardware so we don't really like what
will will act like we control and owned
the hardware regardless right like you
use knife as though you were going to
walk out and put a machine into a rack
right it's not really like I'm going to
use a tool that I can run over and over
again because this might fall over right
like and I think that that's unrealistic
I think all of that being said that
there isn't necessarily a good tool that
integrates the two like I actually am
interested in trying to figure out at
some point somehow maybe what that might
look like I don't know if that's
creating some kind of DSL or something
that kind of better describes like that
this mapping from nothing into servers
plus configuration because I know that
knife tries to do it but I just feel
like knife tries to do it in a weird way
and I don't like in a way that's
opposite of what they're trying to
promote maybe that's just me but the
question was about so with that being
said like kind of in the current state
of things how you actually go from a
server that you've spun up with fog into
actually running chef so the first thing
I would say is if you're curious about
that one place that you can go because
it is there is if you open up the source
code for chef in the knife tool it's
already doing that so I mean like if
you're just curious like how in the
world might be do this that like they
already are doing it like there's a
pretty good example there like I said
the way that you actually invoke it I
don't necessarily like but I mean like
the code does the right thing so if you
pull that up you can see how they're
doing it with a few services anyway I
don't know if you would say that they're
cheating per se part of it that makes it
very easy as in most cases the image
that you actually boot up is an image
that they've kind of pre-prepared so the
image will already have you know chef
Andrew being like it basically has
everything on it already so you just
like start it up and download the config
stuff that you need in the recipes and
you run them and you're kind of done if
you're starting with just like a robe on
to image or something it's more
challenging because presumably it
doesn't necessarily have Ruby doesn't
necessarily have you know it might not
even have GCC right you know like there
could be a lot of things that might be
missing and you might have to walk down
that list of things and get them
installed and perhaps store that off as
an image that you have the space thing
that's always a battle to like how much
do you put into your configuration rerun
able stuff and how much do you actually
baked into the image itself image is
obviously less flexible but considerably
faster generally like oh I'll just boot
this image up that has everything on it
I'm done versus you know
yeah but what happens when in a year
when you're still running that machine
and you can't really just turn it off
but you want to have the latest and
greatest like obviously the
configuration can pull it up to the
latest and greatest you can't
necessarily shut it down and just spend
up anyone also perhaps old mindset maybe
we should just make everything's like we
can spend it down and bring it back up
and images of the way I don't know
because image maintenance is a pain to
sew but yeah I would say knife tool has
good examples but basically that's what
you end up doing is you end up SS aging
into this box placing keys in the case
of knife they aren't actually using the
bootstrap stuff that I showed I added
that after they had written the knife
stuff as I frequently do with like Oh
somebody's doing something really cool I
can see how that would be useful to my
entire user base I'm gonna you know kind
of beg borrow and steal to pull some of
that stuff back in and then it sometimes
takes awhile or Never to then you know
have the cycle returned to them using
the stuff that they inspired in the
first place um okay the question was for
four people that are a little bit newer
to this since I kind of like dived right
in like where where would you maybe go
to get started kind of like a five
minute introduction to this stuff there
are a couple things that are helpful
like I said there's the the examples
directory that's in the repo itself I
think that's pretty good it walks
through some stuff especially for dns
and storage that kind of walk along all
of the things that you might want to do
listing things and creating things and
that kind of stuff also in in this list
here this examples thing right here this
just this actually has a little bit more
elongated versions of the code that i
had in my slides and so it isn't just
like kind of all chopped up and you see
like two lines on each slide like it's
actually like here's the example of the
aggregator it does everything in one
file and it has a lot of comments and
stuff so hopefully if you found that
example interesting or you know it's
just something that hopefully you can
relate to i was trying to get an example
you could relate to any way it'll walk
through a lot of that stuff and
hopefully that that helps so the
question was and hopefully like all the
huge queue a section of this isn't too
boring for you guys I didn't really
expect to get through the slides quite
that fast ostensibly I guess it depends
what you mean by competitors right
there's definitely like for instance for
three right fog is obviously not the
only library that does s3 there's a WS
s3 and there's right a tub us and
there's an only two that come to mind
right on my head but I'm sure there are
more so first off on some level it's
very hard to say that those are
necessarily competitors with fog per se
because fog isn't just trying to be an
s3 library and to some extent by using
fog for your s3 library there's a lot of
benefit that you gain that isn't having
an s3 library and Rebbie I mean like the
flexibility to be able to meaningfully
say that you could move to rackspace
storage instead if you needed to because
you were getting better prices or better
latency or you were moving your compute
stuff to rackspace or what have you I
mean that in and of itself is a huge
value on the Mocs I think can be a huge
value in a lot of cases and a lot of
them don't provide that and the other
thing too is in some cases which was
something that I had noticed even when I
was starting on this project some of
those projects aren't very well
maintained I think in a lot of cases a
new exciting service will come out as
three whatever and people will come into
the space and write a jam over a week
ends and never look at it again I know
that's it like for instance AWS s3 is in
very common usage still and i think the
last patch to it was 2009 april maybe if
i remember right April 10th or something
I don't know like a really long time ago
there's a bunch of features that have
been added s3 since then most people
probably don't care about those features
but they are there I mean and if a bug
does come up I mean if the last patch
was then do you really think he's
necessarily going to come someone will
come magically out of thin air and fix
this bug when nobody's touched it and a
year and a half two years so I mean
that's another benefit is just that
unlike a lot of his other projects this
is very actively developed bugs usually
get fixed very quickly unless I report
them and then I'm lazy about fixing my
own bugs so if somebody else hasn't
complained might bug me but I'm too much
of a perfectionist to not be bugged by
something at any given time so so the
question was kind of a credential
management it can be a little bit tricky
if you get to the point of having
multiple multiple keys especially for
the same server
this most the way that stuff is set up
in fog it kind of assumes that you're
just using one set of keys for a given
set of operations I mean the way that
you would interact with it I guess is
how you did the like fog compute new
each time that you call that it creates
basically like a new separate socket or
whatever so you could call it a bunch of
different times of different credentials
and get different connections that would
all be two different stuff I'm not sure
that that was really your question per
se in terms of actually managing the
credentials there's not a lot per se
other than the sort of Atilla / fog
thing is kind of like a database schema
file if you're familiar with that from
like rails or something so you can
create these ammo files that have
basically like here's maybe my like
development credentials and here's my
production credentials and when you go
into fog you can say follow da
credentials equals and give the path to
that and then fog credential equals say
development right and you could switch
that based on your environment or
whatever and that can be one way that
you could do that or by setting you know
other environment variables or other
things based on which developer was
running things you could all have your
own credentials like the main way to do
it would probably be based on that just
use that switch and use those files so
that each person can kind of maintain
their own state so the first question
was kind of a question of in one hand
you have standards and in the other hand
you have fog how do these stack up
against each other it seems that in a
lot of ways standards aren't really
winning so how is fall going to win I
think that's more or less accurate it's
difficult one way well I don't know I
mean I have corporate sponsorship now so
that kind of messes with that previous
to corporate sponsorship anyway like I
have like you know a mixed faith I guess
at best and standards frequently because
there's so much money involved basically
that like there are so many people
generally butting heads about what that
standard should be that frequently it
seems to involve business needs and
desires more than it necessarily
reflects what the actual technological
needs are which I mean so like for
instance with a OpenStack right it came
out originally with I think pretty much
an AWS compliant API because you know
that's kind of what the standard
us in some sense the standard and same
way that eucalyptus has an AWS compliant
one you know everybody knows it it's
it's very common and now all of a sudden
it appears that they're going to
deprecate that and it will be a
rackspace API instead I mean that that
seems really political I mean openstax
supposed to be a standard and it's being
defined by who happens to be throwing
the most money away I mean that's very
cynical probably but i mean i think that
there's always that danger and standards
is that the standards bodies are usually
have like people from big companies
setting on them and are funded basically
by these big companies and so it's
difficult and also in that case there's
nasa on one side and there's racks based
on the other i think they have very
different needs for what that clouds
going to end up looking like which also
like it's pulling in two different
directions like i don't know i just
don't know that i had the most faith in
that that process I mean there are cases
where it works out great like well great
HTTP or something right like that
suspect that but I mean nobody really
follows it I mean that's the other
problem you even you end up with a
standard V clouds another example V
clouds a standard that VMware came out
with few people ostensibly follow it I
don't know if anybody really follows it
like everybody kind of has their
variation in their own flavor a V cloud
so at the end of the day I don't know
that you gain that much like it seems
like at the end of the day if you're
actually going to try to move back and
forth between providers that have this
supposedly same API you're still going
to have to code around the differences
regardless so if you're going to have to
code around all the differences anyway
like why even bother to some extent but
also I mean like at the end of the day
as a developer what have you gained like
that's the other thing is I feel like
this sort of like more like grassroots
approach almost gives us something that
helps us now and it's something that we
can actually take action on whereas with
standards like when was the last time
you interacted with a standards body I
haven't really ever interacted with a
standards body I don't feel like I'm
like pushing those standards anyway
that's going to help me I don't feel
like they seem to be pushing themselves
in ways that are going to help me I mean
um so the question is kind of what are
the kinds of things where what are the
kinds of things that are basically hard
to simulate I think with fog mock like
where where is that fall short
there are a couple places probably like
I said one of the places is just like a
very obvious thing that you're going to
need to do is get on two machines and
run commands and that's one of the
hardest possible things you could think
to emulate one path that I'd like to
explore more that I haven't gone far
very far down yet is doing stuff with
VMs actually for that purpose that's not
really mocking per se but I mean like in
terms of it being cloud versus not cloud
it's effectively like an in-memory local
simulation of what would happen that's
probably a bit over the horizon to say
the least like I don't know that like I
don't really unfortunately have the
tooling that like oh I'll just require
this gem and now I can spend up yen's
and like you know like that would be
spectacular but it's not really at that
point yet so maybe in terms of that
that's one big thing performance kind of
can be another thing like for instance
right now the s3 stuff works basically
immediately you say like create a file
and it's there and any of you who have
worked with Amazon Web Services a little
bit more than that probably will realize
that it has this notion of eventual
consistency you do something and
eventually it will be true but it's not
necessarily immediately and there are
some cases where that will really bite
you so if you are relying on the fact
that everything is immediately
consistent basically because that's what
the mocks happen to do it's likely to
come back and bite you and in the case
of a lot of the compute providers I've
actually purposely built in some delays
into the simulation I'm in order to
emulate that on a very small scale so
you might do to server and it might take
a second or two to come up which is
still pretty unrealistic but if you're
doing anything that's like totally bogus
it'll probably call you on it like
that's the idea anyway and you can turn
that off if it's just like too slow for
you or like maybe turn it on on the runs
that you do right before you deploy but
not have it on every single test run or
that kind of thing so hopefully that
answers that more or less anyway um the
question relates to in some ways at
least to the vm question is of does fogs
provide stuff we're doing more like
private cloud kind of stuff like
internal infrastructure
and then does that therefore provide
sort of a migration path from internal
infrastructure or internal private cloud
to public cloud we're having a hybrid
not really not currently um engineer it
actually doesn't have their own Hardware
anymore we we are out of the hardware
business where we we just use other
people's hardware now so we personally
aren't doing that I know there's a lot
of interest in that space um similar to
running hypervisors people would like to
be able to run cloud controllers
basically whether that be you know open
nebula or vSphere whatever you know and
so I'm I'm open to the idea I can
definitely see how it fits in and how it
would be very helpful for a certain
class of users but I haven't had enough
interest nor do I have a vsphere over
here in an open nebula over here that I
can test against that's one of the
problems that have run into a couple
cases of I'd love to work on this thing
but like unless I have a test setup I
can't have very much confidence that it
actually does the right thing regardless
of what code might get contributed or
what code I might write so it's
definitely something I'm interested in
pursuing more but I haven't quite
figured out how to make that happen I
don't know if that's going to be
sponsorship from someone or something of
that nature or or what but I think
there's definitely some interesting
stuff that can happen both in terms of
being able to control local vans and
then move those beams to the cloud but
also controlling a local cloud and a
remote cloud and having more sort of
uniformity in the way that you interact
with those things thank you everyone
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>