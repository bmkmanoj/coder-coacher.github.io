<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Monitoring &amp; Introspecting Django Applications | Coder Coacher - Coaching Coders</title><meta content="Monitoring &amp; Introspecting Django Applications - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Monitoring &amp; Introspecting Django Applications</b></h2><h5 class="post__date">2014-05-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/r1SbNw8eN_4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so my last stop evening I'm going to be
talking about the subject that is very
dear to my heart and that's monitoring
and introspecting of django applications
so is my microphone doing ok so django
is renowned for having fantastic
developer debugging tools the Django
error page remains my favorite error
page of any web framework and any and
the first thing I am still when I start
a new project is the Django debug tool
bar which makes it fabulously easy to
understand exactly what a page is doing
what sequels being executed what
templates it's a really fantastic way of
developing there's just one problem the
interesting bugs only happen in
production and if you look at the Django
documentation and the debug it says a
boolean that turns off debug mode never
deploy a sightings production with debug
turned on did you catch that never
deploy a site into production with deepa
turned on which is all well and good but
it means that when you're in production
all of these beautiful development tools
are gone and you're staring at this this
sort of blank void of errors being
swallowed up so there are two things
that you want to know there's what went
wrong and what's going to go wrong you
know what's the general health of my
application now there is at least there
are a few tricks you can use to start
getting back on top of things this for
my money is the most useful two lines of
Python code you can put in a project and
this is this you can find this on the
Django snippets website it's eight years
old now and it's still one of my
favorite favorite snippets what this is
a piece of middleware and what it does
is when it when it catches an exception
in your production site if you're logged
in as admin super user it returns
Django's default technical 500 page so
it's a quick and dirty hack but if you
drop us at this into your stack right
now you'll start getting those 500 error
pages again and this is great because it
means when someone hits an error
they can send you a link you can click
on the link and you can find out what's
going on so that's great as a sort of
cheap hack there are more sophisticated
approaches at eventbrite we use a piece
of software called century which i
believe is also out of the discus stable
woo and century is a pretty fantastic
way of tracking errors it's not just an
error logger it also AM groups errors
together so you get interfaces like this
this is a status screen you can't see it
there's a 10 there the Grays washed out
but this shows you not only the errors
you've had recently but it groups them
together I think it does this by hashing
the doing an md5 hash of the trace back
so it can identify when an error is the
same error and it'll say hey you've got
44 of these errors recently you found 10
of these hours four of these errors you
can mark an error is resolved so in this
case somebody's going in and fix the bug
and said yeah we fixed this one but
generally it means that all of your once
you have to set up and there's a fair
amount of maintenance involved you know
it's like you can have quite a lot of
data base traffic produced by this but
the amount of insight it gives you into
what's broken in your app is is
invaluable for each error you get a page
with the exception and a stack trace a
bunch of extra information and a URL
that you can send around to your team so
it makes it much easier to collaborate
on on errors that are occurring as well
so I'm a huge fan of I'm a huge fan of
century as a way of getting back that
sort of debug level of information about
what's happening when your app goes
wrong but what about keeping your
application healthy well two tools that
we've leaned on very heavily at django
and now at lanyard and now different
wider what as well our stats v and
graphite these are tools stats d came
out of etsy and essentially their
mechanisms for very inexpensively
keeping track of how long things are
taking and how often different things
are happening so stats d is a really
neat little piece of software it's
actually a node.js demon that runs on
your application server and listens on
UDP which I spelt UDF I've apologized
that listens on UDP which and UDP is an
unreliable network algorithm so if the
server goes away and your applications
chucking stuff at it it doesn't matter
it keeps
working you don't have to worry about an
error in your in your monitoring
software taking down the rest of your
platform and your application can send
it three things you can send it timers
saying it just took me this long to
render a page or this long to make an
HTTP request you can send it counters so
I've served I've served an ape I've done
an API key authentication and you can
send gauges and does anyone here use
stats d gauges discus back what do you
use gauges for ya a gauge is it's just a
number and so you can get a grand foot
you can just say 55 335 and get a graph
of that so what's so stats see it sits
there at collects all of this stuff it
aggregates the stats together and every
10 seconds or so it sends them over to
graphite then graphite is a piece of
software that stores the information
that stats T is sending it and renders
brass it renders graphs on demand and
you can get some really useful results
out of it so this is my favorite and
graph from our lanyard graphite set up
this is and you can't quite make out the
key at the bottom but this is a stacked
graph showing it the overall the quite
time it is taking server quests and then
breaking it down by the blue is time we
spend in sequel the yellow is CPU clock
time that tiny little red line along the
top is solar and then if we zoom right
in you can see that blue that purple
line right at the bottom is our is in
his interactions with memcache so I've
mmk she's running really fast or we're
not using it nearly enough but this
graph here is some it's dynamic it's
dynamically generated we feed a bunch of
numbers in and the actual image itself
is just one whopping huge URL which
specifies which things you'd be drawn on
it in which colors and because it's just
a URL you can take that and you can
embed it on anything you can build
dashboards very easily you can bed it in
bug reports you can bet it in wiki pages
it's a very flexible way of moving the
stage for around and so here's a
dashboard basically once you have
graphite and stats T in because it's so
cheap to send metrics out you may as
well graph all
for things and this is we've got met
time in memcache sequel time redis time
time spent on databases you can do means
you can do top 90th percentiles you can
get a really good breakdown of how
things are going in your stack and we've
also set it up so there's a key there
that says deploy when we deploy the site
it drills a white line on the graph so
you can deploy the site and then look at
it five minutes later and see hey look
our memcached uses just went up by five
percent after that change that we've
pushed out but together stop working you
have to you have to mont you have to
hook this into all sorts of different
places and in Django terms this means
you need to intercept basically
everything this also means you have to
monkey patch things sometimes if they
don't provide you with a good hook now
the obvious thing here might be to use
Django's triggers and listen for events
and graph those that's not quite good
enough because a lot of the value from
stats d is in the timings knowing how
long something took if you're going to
time something you really need to wrap a
foot have your own function called so
you can start a timer at the beginning
run the run the operation and then stop
the timer at the end so you end up
having to wrap an awful lot of things
now a bunch of ways that you can wrap
things in Django the obvious one is
response and X exception middleware and
in fact i looked at the lanyard
middleware stack we've got at least four
middlewares now which devoted to
profiling or monitoring or introspection
in some way I always use a custom render
functions so whenever I render a
template I'm calling I'm doing from
common import render and passing in a
request object the template in the
contact this gives you hooks for hooking
up graphite that it also means that you
can inject extra variables into your
context you've got somewhere that a
function that's run every time you
render any HTML at all a really
important one is the database wrapper in
Django you can override the cursor
method on it so every time a sequel
statement is executed by the RM you've
got an opportunity to get in there to
Simon it starts time at the end to send
it off to graphite as well and they'll
put up a gist later on with the code
that we use for doing that and something
which i haven't done but i aspire to do
is I want to wrap I want to send all of
my outgoing HTTP traffic for
a single point within our stack so that
we can measure things like so any time
we're calling out to an API that github
API the link to APO whatever we can
graph that drafted by host we can get a
feeling for how those external
dependencies that our site relies on for
working as well so that's graphite
that's nasty and that will gain you an
enormous amount of insight into what's
going on it's not as cheap as building
feature flags it there are quite a few
running parts of this you need to set up
a graphite machine somewhere you need to
get stats T rolled out onto all of your
individual boxes but again it will repay
you enormously if you spend the time to
get it sent set up so another principle
which I firmly believe in is that log
files are super important and once
you're generating log files you what you
need to have them aggregated and make
them searchable so most stacks will have
something that's our sis logging or
sending sending log files to a central
server if you haven't got one of those
that's again Toki worth doing and but
the tools I'm getting excited about more
recently a tools that make the take
those logs and turn them into something
that's more searchable than just running
grab on the command line and there are
two tools I've been playing with
recently this is splunk which is a
viciously expensive commercial tool like
very much call us and we'll give you a
price and then you argue with us and
spend months negotiating whatever but
what it does is absolutely awesome once
you've got splunk set up you can feed
any log file into it it gives you a mini
micro language for breaking that log
file up into fields and then when you
want to search it starts with returning
results instantly so you'll run the
search will hit enter it'll show you
results in the past five minutes worth
of logs which is enough for you to start
seeing if you've asked the right
question and then there's a slowly
backfill 10 minutes 15 minutes up to up
to 30 days and fill in those results for
you so that it's tough it better as a
free demo it's if you if you've got a
budget it's worth installing it in
playing with it and seeing if you think
it could work for you there is an
open-source alternative to slug to
splunk it's called log stash which is a
log stash does aggregation in searching
of logs using elastic search cabana is a
open source of you I that sits on the
top and does pretty much exactly the
same thing as splunk you do have to
it's very it's a case of patching
together a bunch of open-source things
to get it working but you can get very
much the same results this is worth
looking into as well another technique
that we use at a vamp right which has
proved extremely useful is correlation
IDs and as Andrew mentioned earlier
we've been breaking event right down
into a service-oriented architecture so
rather than having one monolithic
application we're breaking out
functionality into services that know
about events services know about
authentication and so forth now a
downside of doing this is that there's a
any request that comes into your stack
is now being handled by a bunch of
different different pieces of software
so tracking arrows and behavior can be a
lot more can be a lot harder and so what
we do is any requests come in and we
assign a correlation ID which is
essentially a uuid attached to that
specific request it goes through the
application server get logs gets logged
out in a log file it goes into the
application calls a service that service
will then log out what it's doing and
that same correlation ID yeah it goes
into another service we get another
another log entry now on its own this is
kind of useful but when you start
feeding these into splunk or log stash
it means that given a single request ID
you can throw it in and you can see
entries from all of the log files from
all of the services that touch that
request which makes it much easier to
track down problems in fact you can go a
step further a trick we used on lanyard
is we take our correlate our request IDs
our correlation IDs we embed them in a
meta tag on every HTML page this is
another benefit of having this single
render method that everything passes
through and that's useful because now
that it's available in the source code
if something goes wrong you can view
source pull them out and use it to
search your car your logs but we also
have a very lightweight in browser
profiling tool which is a bookmarklet
which can take that correlation ID make
an AJAX call back to back to our service
and pull out some data that was
collected during the processing of that
request we actually built this quite
early on at lanyard and all it does is
collect up information about which view
functions are called potentially with
templates for use and write it into a
memcache key which lasts for 60 seconds
so if you hit the bookmarklet within 60
seconds of loading the page you get that
information dumped out straight at you
and again it's a pretty lightweight
trick but it's sir it's really useful a
related trick which is again really
useful in these larger scale sites is to
instrument your sequel queries and it
turns out on with my sequel or postgres
there's a really tricky Z trickett you
just stick a comment at the beginning of
any sequel query you execute with a
correlation ID or other information
gathered from the request so with
lanyard we track the request part we we
have our custom cursed or execute method
we look up the request stop path in a
global request object and we stick that
in which means that when we're if we're
watching logs of sequel files or if
we're looking at our slow query log we
can tell exactly what page caused a
query to be executed likewise we do the
same thing for management commands so if
you're not in a sort of browser requests
context but you were run by a manager
command we log the command line argument
from that in the sequel query as well so
over time are our slow query logs
becoming real it becomes really easy to
track behavior from those back to the
back to the source and likewise if
you're using correlation IDs you can
drop those into the query logs as well
so when you pull up the slow query log
and see something took a long time you
can then consult your log files and see
exactly what was going on when that when
that query was triggered really i think
the conclusion here is that no one ever
hit a bug and said I wish it had less
information to help figure out what's
going on here the most interesting bugs
are the ones that happen in production
when you've got a load fully loaded
database you've got lots of traffic
going and lots of things happening you
need to if you want to know what's going
on in the general health of your stack
stats lien Graphite's are fantastically
useful for that and you should log
everything your logs should be a
detailed as possible you should
aggregate them and you should make them
searchable as well so thank you very
much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>