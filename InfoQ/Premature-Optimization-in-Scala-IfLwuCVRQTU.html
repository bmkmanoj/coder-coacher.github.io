<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Premature Optimization in Scala | Coder Coacher - Coaching Coders</title><meta content="Premature Optimization in Scala - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Premature Optimization in Scala</b></h2><h5 class="post__date">2013-03-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/IfLwuCVRQTU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right so my name is Erica Sian I
work at a company out in Boulder called
Precog with some other people who you
all probably know or are friends with I
don't know Scala's one big happy
community so we can sort of all know
each other I feel anyway my talk is kind
of on a weird topic it's something that
you're not really supposed to do and
it's kind of frowned on and I a lot of
my co-workers probably would disagree
with a lot of stuff in my talks so we'll
sort of see what you think I mean I'm
kind of it's not a troll but it's like a
quasi troll so don't you know just
accept it in the spirit in which it's
given anyway so it's about basically
about low-level optimization and this is
what you don't want to do but this is
what people sort of think you're doing
so anyway let's get started the talk is
informed by a bunch of experiences that
I've had
writing Scala so for two years I worked
at as a via working on a GIS it's a
piece of software called geo trellis
that's intended to do very fast raster
processing so lots of data you know
parallel distributed that kind of thing
I've also worked with Tom who presented
earlier on spire which is intended to do
very fast like math algebra stuff like
that sorting and I've also written my
own sort of collections that aren't had
to be faster than Scala's and and I and
I make things fast at Precog too so
that's sort of my thing these days but
performance is fiddly and your
experiences might vary and I'm
definitely not trying to firm something
some sort of expert I mean there's way
smarter people like cliff click or John
Rose or people so this is just what I
found through sort of experimental
testing and working on it and I'm
presenting I'm really talking about low
level optimizations so the idea here is
that we want to basically produce byte
code that the JVM will run fast for me
it seems easy when you put it that way
but there's actually lots of things I
could be talking about so first of all I
this hotspot specific if you're running
one of the other JVMs hopefully some of
it applies but I can't speak to that and
I'm focusing on code that you write in
Scala I'm not talking about writing Java
or C or anything like that and I do
profiling
I think profiling is important I think
everyone should do it I'm using caliper
and J profiler but other
stuff is great the things that you could
do that I'm not gonna talk about are
buying bigger more bigger machines get a
better JVM that's just smarter and you
can do a lot of tuning at run time just
by tuning parameters like which garbage
collector you use I'm not speaking on
that that stuff's really important it's
just not the focus of my talk you can
also call out to native libraries people
doing linear algebra do this all the
time and you of course you can use
parallelism to just run a whole bunch of
more processors I'm really talking about
kind of classical you know single
threaded stuff not that these are bad
but um even without these we can still
do a lot great and so how many of you
feel like you know a lot about how
hotspot works I'm sure a bunch of you do
but great so a few of you do a few hands
awesome
so hotspot is a just-in-time compiler
when the JVM is running your code
initially it's interpreting it and it's
pretty slow and then when you run it a
bunch it sort of warms up and hotspot
actually compiles a more efficient
assembly version of your code and will
do a bunch of optimizations at runtime
and this is really nice as opposed to
say C++ where it's GCC gets it wrong
it's wrong forever right and no matter
what you do it's gonna you know you have
to recompile the JVM is kind of great in
that it will make our code faster so a
bunch of the things these are some of
the main things that will make your code
faster is in lighting small methods to
avoid method call overhead eliminating
range checks so when you're looping
through a big array it doesn't have to
check every single time to see if it's
out of bounds or not and then really
optimizing virtual method calls there's
lots of other stuff it does but I think
these are kind of the big ones those are
the ones I think is worth checking out
and you can see the full list of all
said it does and then here are just I'm
just gonna really quickly give you like
a bird's eye overview of all the things
that can go wrong with this
so mega morphic dispatches when you have
a whole bunch of classes implementing
one interface at that point you can no
longer inline any particular
implementation it has to use a virtual
method table which is turns out to be a
lot slower than like if you call a
method on a final class the JVM knows
that which class you're talking about
and it can just essentially almost use
like a pointer to go right there if you
have an interface and there's ten
classes and doesn't know which one it
has to jump through a whole table which
is a lot more expensive if you have
small methods that you'd like to be
inlined but they're a little too big
above this arbitrary 35 byte limit they
won't be inlined in that that can be a
disaster for people there's also how you
write your loops or how you write your
code there's we
have to do error checking or handle edge
cases but if you do that at the same
point where you're also just doing a lot
of work you'll you'll slow the whole
thing down hot spot won't be able to
deal with that that also kind of covers
complicated loop tests and people
sometimes when they hear about inlining
they'd get create they go in line and
crazy and certain letting everything and
that's actually a disaster too because
at that point um
hot spot will have other problems in
terms of like the code cache having to
have you have too much code and when the
code cache fills up that's the last
point that's a complete disaster at that
point your application will stop
compiling anything to assembly and it'll
just sit there and be incredibly slow
and you'll see a little message in your
logs and you'll wonder what the hell it
means and you'll google it and you'll
find out that it's a disaster so as you
can see it's actually very important
that we get this right and so the
question that is like how does Scala
interact with hotspot normally and the
answer is pretty well for the most part
I mean we write we're encouraged to
write lots of small methods as I said
hotspot is great about inlining those
composition hotspot also deals pretty
well with that actually because of
inlining so having to jump through three
objects to get to something if hotspot
knows that's what it's doing it'll it
can inline that pretty well and
immutability is nice because it means
that you have to do a lot less defensive
coding defensive checks and those kinds
of checks inside of your loops will
interfere with hotspot doing its thing
but there are problems and the biggest
problem really is garbage Scala is a
huge litter bug and it's just allocating
tons of stuff all the time and the GBM
tries to keep up but sometimes it
doesn't you know most of the time maybe
it does and I would say idiomatic Scala
actually pretends to produce more
garbage so you know that's that's a
thing and then there's sort of ugly side
issues like there's a lot of class files
there's a lot of byte code and this sort
of inlining problem in terms of not
being able to inline mega morphic
dispatch scala like anytime you call map
on an array or a list or whatever your
pack that's that's that's that you're
probably hitting the mega morphic
inlining problem because you have four
different times you call map on a list
you use four different functions
it can't inline that function apply
because there's four different versions
and so it has to do a virtual method
dispatch on your function object to see
which whether you're multiplying by two
or dividing by four you know whatever it
is that you're doing this time and that
that's what gets to talk about is the
inlining problem and that that will hurt
you
a little bit so then there's the big one
that I said is garbage and so I'm just
gonna go through all the different ways
that Scala produces garbage
so boxing do you all know what boxing is
everyone it looks like everyone does
great
so does anyone want to guess how many
how many Java lying integer instances
this code snippet is going to create
how'd you get 36 no I mean it's no it's
a I mean the answer I think is I mean
someone might be run I think the answer
is 16 I think it's three times five plus
one
you're gonna box three to five all five
values in the vector when you do the map
you're gonna in you're gonna create five
more boxed values that are have been
multiplied and when you do your fold
left you're going to box the zero first
and then you're gonna box all the five
values as you as you accumulate so
that's six and in general what this
means is that this code if you effector
was N Things long you'd have three n
plus one boxes you're allocating right
this isn't so bad when you have five but
if you have like 500,000 or something
you know you can imagine where you could
have a problem no I'll get to that but
you should not except for function one
function to in function zero and a few
other things
nothing is specialized so you should I
think there's this assumption that Scala
has specialized a lot and is really
smart about this and I think that was
always the hope but it is not true right
now so in here you can also just other I
mean this isn't boxing but like you know
cons cells are objects they're allocated
you know every time you call these
collection API methods you're allocating
a whole new list and so you know as you
burn through this list you're gonna you
know allocate a bunch of stuff in
addition to all the boxing that you're
also doing right so you're you know
you're gonna get a lot of allocations
this way and then the other one is using
short-lived immutable objects right so
in this case we're folding we're
computing and max in minute the same
time we're breeding smart right we're
only doing one pass over our an array so
we're we're computing both them in the
max at the same time which is great but
we're allocating a tuple for every
single loop iteration right so again you
know this is fine but when your array
gets really big there's just gonna be a
lot of garbage and you get a similar
sort of effect when
you use option right if you if you use
collect or something like that all of
these types of things are gonna there's
gonna be a per iteration garbage that
we're talking about another example are
by name parameters and function
references I think these are less of a
problem often but the one that really
bugs me is scholars II semigroup append
because you tend to use that for it like
adding numbers and stuff and so you
think it's gonna be fast and it actually
allocates a function instance for every
single addition that you're doing
through the append method right so
spiars append is is strict not lazy
precisely because we're optimizing for
the case where you're doing it a million
times and then the last one which is
less a big deal now but using implicit
to add methods to stuff if you're not
careful and you you do that n tight loop
again you're gonna be instantiating a
million of these implicit objects so
what's the conclusion right do we have
to write Java I mean me but I say no I
mean that's definitely not my position I
just you know I feel like when you see
all the boxing happening that's kind of
your first impulse you're like oh no all
this beautiful stuff means that my stuff
has to be slow but the answer is no your
code doesn't have to be slow and you can
still write Scala and the thing to note
is that it we actually do find most of
the time right I mean I just showed you
all this horrible boxing but yet you
guys are all writing code that's
probably pretty fast it's getting the
job done it's not really a big deal you
know the JVM has a really good garbage
collector and it expects to be dealing
with lots of garbage so actually you
know often it's not such a big deal and
more than that allocating a few objects
here and there it really doesn't matter
at all I mean even if it's kind of
inefficient if you only do it a few
times really it has to be really
inefficient before you're actually gonna
your end user will notice that so the
real problem here is when you are having
like order N or worse like N squared or
something allocations and your n gets
really big that's really the only case
you should be worrying about for
allocations and so that tends to be like
in a tight loop over a big array over a
big data set over a huge table stuff
like that that's the place where I feel
like you suddenly have to have this
different mindset where you're trying to
like have an eagle eye for this kinds of
stuff in those cases you want the ratio
of actual work you do to be relatively
high compared to the sort of random
allocations that you're performing I
mean it's fine to do some of them but if
you're doing one if you're doing more if
you're spending
more time instantiating tuples than
adding numbers you know you have a
problem right I mean it's just not a
good plan and I feel like we all often
have a good intuition about this not
always but we often we often know where
the critical path is I mean and when
when you don't it's pretty easy to find
out what I mean
J profiler makes it easy and so while
we're talking about this I just want to
address this premature optimization
thing which I sort of used
tongue-in-cheek but it's a real concern
and you know Donald Knuth cautions us
that we should forget about small
efficiencies say about 90% percent of
the time and that premature optimization
is the root of all evil and I I think
this is true but I put it in context
canoes also says establish engineering
disciplines a 12 percent improvement
easily obtained is never considered
marginal and I believe the same
viewpoint should prevail in software
engineering so I think people remember
the first part but not this part which
is that canoes is really talking about
you know people fiddling assembly stuff
to try and eke out a 2% gain or
something he's not if your codes gonna
be four times faster it's like I think
Donald Knuth is totally fine with you
optimizing for that case you know and I
I just like to imagine he is at least I
mean and so most of if I'm talking about
I tend to think 2% it's two times for me
if something isn't two times faster it's
maybe not worth doing that tends to be
my cutoff and I like to think of orders
of magnitude in terms of base to not
base 10 because a base 10 jump is really
huge and you often can't get that
whereas if you get two times or four
times or eight times speed up those are
significant and I think it's like a I
tend to like thinking of that as
multiple orders of magnitude I mean it's
a it's an opinion thing anyway this is a
giant slide and here are my giant list
of premature optimization tips which is
sort of what I've been talking about the
big thing that you might be surprised
about if you have ever talked to me
about this stuff is that I really think
you should use a raise in tight loops I
really think the array data type is
maligned and it gets a bad rap because
of Java but it is pound-for-pound a
really great compact representation for
lots of data and you can iterate through
it really fast the jet hotspot has lots
of ways of making array access fast it
has array bounds checking it can it lie
that arrays tend to have good cash B
characteristics so that that's maybe
once
you'd be special also I for when you're
in the critical path and your code is
too slow and you need to make it faster
I would stay away from linking a bunch
of collection API methods together
that's again that's just me but you tend
to be doing a lot to extra work in those
cases like if you do multiple maps or a
map and a filter in a map or something
you could have written your own
recursive function that just does that
all at once right and you would you
would basically lose all the
intermediate allocations that are going
on so I tend to think that that's better
in these types of cases and you will do
a lot less allocation um other than that
the other things that are maybe weird
are I I think local VARs are fine I
really don't think anyone should be
using VARs inside of a lookup like a
field that's gonna be shared and like a
long live class but if you're in a
method I think having local VARs and
that method to to make you know to store
stuff is often the fastest thing you can
do and tail rec is actually a great
alternative to that which is you can
write these nice tail recursive method
to the compiled something it's actually
slightly faster than a while loop you
know and again you don't have to box you
can pass you can be passing as much
state you can pass to things or three
things or four things or eight things
through without using a tuple and a fold
and you your code is still functional
and nice but it's also very fast so
prefer local variables avoid field
access avoid mutable fields and pay
attention to which classes are
specialized the answer is very few of
them are so be pessimistic about that
and and this is a sort of a follow up on
this because I don't hate functional
programming and I think functional
programming actually kind of informs
this style a weird way but IB admissions
for me is that when when you need your
code to be faster you just have to do it
has to be done and you don't always like
it but you know it's just something you
need to do so the more shared your data
is or the more long-lived it is the more
I think it really has to be immutable
and you really need to be able to reason
about it in a good way which immutable
data lets you do but with transient data
like during a full not you know not
before and after the full but during the
fold though that date is transient it's
only being created for your work it's
gonna be thrown away and garbage
collected as soon as you're done with
transient data I actually think I think
using beautiful data for that is fine if
it's gonna make your algorithm more
efficient and faster and things like
that or make it even you just easier to
reason about to me that's that's really
not a big deal some people obviously we
disagree but you know this is my
so I get to sort of make the rules and
just another point here is that if
you're using local VARs in a method that
method is using mutation but it can
still be referentially transparent
there's nothing preventing you from
using referential transparency in a sort
of big sense but have particular areas
where you need to burn through an array
or you need to do complicated resampling
or you're gonna you know something like
that where you kind of need to be able
to have random access to an array that's
mutable and that and that and that can
be fine it really for me it's about
minimizing side effects and crosstalk
and and those are the things that that
that are really bad so anyway let's go
into some case studies just because I'm
saying all this stuff but maybe I'm just
lying and making it up so here's an
example where we have a list of integers
right first and let's say that we like
need a list right we need it we're maybe
we're doing like a last in first out
queue or something or we need the cons
structure we're not just gonna use an
array cuz I would love to use an array
here but let's say I can't so here's an
example where I have my list and I'm I'm
taking the min and the max over it and
I'm using a tuple to do that I think you
know what I think I made a mistake on
this I think this actually is an array
but either way I'm folding over
something and I'm computing the min and
the max and so the question is how can
we do better so here's the signature of
the method that I'm gonna write this
isn't even actually the code this is
just the signature and it's completely
ugly and terrible spec is an alias for
specialized because it's even longer you
just wouldn't fit on the slide otherwise
I do that in all my code because I just
can't bear to type it out but as you can
see we're taking in an array we're
taking in B and C which are like the
starting values for our fold and we're
taking an f1 which gives you a new given
up the in and a gives you the next B and
C and a a gives you the next C and we're
gonna return a tuple of B and C right
which is and so this is essentially what
this code here is doing right it's it's
doing the fold we're getting out a tuple
with the max in the main great and so
then this is the body of that code I
just split it up because it's just
completely unreadable otherwise on this
slide and as you can see we're like
initializing our state we've got a
little while loop it's very imperative
looking you know and then we ran our VAR
and then we're reassigning to our
based on the function and then we're
allocating one tuple at the end so the
crucial thing here is that we're not
allocating tuples every step we're
maintaining state this way and then
we're allocating tuples at the end it
looks moderately horrible is it worth it
and the answer is yes
these are logarithmic scale so if you
see a fixed difference between those
that's actually the graphs like going
off just you know like a like a like a
multiplier effect but I you know I just
wanted to make it visible so it's 100 to
330 times faster and admittedly
admittedly
for small and this isn't such a big deal
because it's there between like 25
nanoseconds in 2.4 microseconds right
and who cares about microseconds in
nanoseconds but for like a hundred
thousand it's the difference between
like 4.7 microseconds in 1.5
milliseconds and like milliseconds your
users actually care about that right you
only got probably about 10 or 20 or 50
of those to work with before people
start actually noticing that your
computer is doing something other than
being completely responsive so so you
know even in this dumb simple case you
can see that it makes a difference I
mean it seems crazy that it makes a
difference but you know it does and so
then there's this question of like well
what's this special icing how many of
you have heard of specialized or kind of
know what specializes or feel
comfortable using it I guess I sort of
increased difficulty there so a lot of
you have heard of it fewer of you are
comfortable using it I think that that
is consistent with my sort of survey of
the field
it's basically an incredibly subtle
difficult but necessary tool and I've
done a lot of work with it and it's sort
of my tragic flaw that I'm stuck using
it and it fails me periodically and it's
always disappointing but at the same
time it's good enough that I put up with
it because I just have no alternative
it's just so great it is really good and
so here's sort of a quick example that
taken from another talk Tom and I did to
sort of show you how specialization
works like if you haven't worked with it
or if you don't really have a good
intuition so this is some code it's
generic
there's a type class instance of ring
that we use we call a plus method on it
it's pretty simple we're just summing a
list of a's you know nothing fancy and a
is generic it could be integers it could
be anything that can be that has a ring
that can be summed you know from Tom's
talk
so then after specialization this is the
monstrosity that we get instead so we
have all these crazy dollar signs
and what that basically is saying is
this is a specialized version of this
method it's not the same method that you
wrote
it's a copy that has been heavily
modified by the Scala compiler and so
what happened is all the A's got turned
into ends so it's definitely you know
committed to using intz here and not
just that but whenever it works with any
methods it calls on ring it makes sure
to call the inversion because ring is
also specialized so as you can see we're
instantiating a specialized rings ops
thing down here right here and we're
calling a specialized plus method and
the upshot of that is that normally with
generics you would be boxing on the way
into that method but here we're not
because the the the specialized version
has int in the signature and so Scala
compiler uses the primitive in for it
that's basically our go ahead it would
yeah it would rarely be rarely or never
be a virtual call I mean I I'm not gonna
say never but I would not expect it to
be a virtual call right I would expect
it to be essentially invoke static which
is gonna be a lot better as you say so
this is what specialization this is the
specialization mechanism this is really
just what it does it's essentially like
C++ templates a little bit it's just
it's a little bit more complicated than
templates and in some ways I'd rather
have templates at this point but it
still works it's still great and it can
still make your code fast but
unfortunately there are a lot of gotchas
so these I can't go into all of these in
like why they are there but this is like
a list of things that I think you have
to kind of consider when you're when
you're trying to write your own
specialized code if you're using someone
else's specialized code you can assume
that they've thought about this and it's
probably fine but basically it kind of
breaks inheritance a little bit so you
need to inherit from traits not classes
if you have a specialized class and then
you inherit from it you won't actually
inherit from the specialized version
you'll inherit from the generic version
which you know defeats the purpose and
you get duplicated feels and this is
really one of the worst ones so if you
have it if you have a thing that has six
fields and you specialize it you
actually gonna have twelve fields in
your specialized version you have the
six generic ones that are still there
which it inherits and you're gonna have
six specialized ones with different
types that are the actual ones you use
these other ones are just vestigial like
you know the hip bones of a whale and
just sit there doing nothing except for
eating up your valuable memory so that
sort of sucks the other thing you have
to do is if you're using specialization
you have to be sure that you use it all
the way through because if it any
point you have code that's not
specialized it like forgets the type
information and then when you call in to
stuff that is specialized it'll call in
to the generic version because it no
longer knows which version you're
talking about whether you're talk about
insert doubles or things also there's
this problem down here which is that any
refu mix like an INT and a string even
if you're specialized it won't use the
intrusion because string is not you
can't specialize on string it's in any
ref type if it's people want to talk
about that later I can explain it more
it's a little complicated but basically
the advice I have for you is if you're
trying to use this keep it very simple
don't do anything fancy I would say even
avoid fields if you can like the
best-case scenario your writing type
classes your specializing those it'll
just work it's great if you're just
specializing methods and you're taking
things in as parameters and returning
them as value specialization works
really well the moment you have like
constructor stuff going on and fields
and different crap like that and then
there are bugs and it doesn't work and
it's not specialized and you're gonna be
chatting with you know Vlad you're icky
and people like that and you know that's
probably how you want to spend your
weekend and then the last thing I would
say is if you really are trying if
you're really invested in this you're
gonna have to invest in some time
running Java P and just seeing what it
happens it's I wanted to put in the
slide it's just too complicated there's
no way for me to actually communicate it
at all about it so like I said very
simple stuff basis is a cool library he
only specializes traits all of his
implementations are concrete that extend
the trait so he's doing what I said he's
only using it for methods he's not
specializing fields he's not doing
anything tricky and I get the sense that
it works well for him I haven't really
played with his library too much but
like I said when you write specialized
code it will often end up ugly that's
just okay and there's just no way around
it so um but here's an example that does
useless I'm like the last one which I
put it in erroneously so in this case um
how come how well can we do when we're
when we need a cons like structure so
you're gonna have a bunch of allocations
so then here's the sort of naive example
we have a list we want to basically
build a list of triples we're gonna
someone's gonna be giving us triples and
we need to be building them into some
sort of like queue this is the example I
thought I was talking about last time
anyway as you can see in this little
code snippet I've got some arrays of
numbers and I'm building them into a
queue and this is just for benchmarking
so you just see how fast it is and what
it does I think it's pretty
straightforward what's going on here
but so
one thing you can do easily to reduce
this as tuple 3 I use to pool three
specifically because it's not
specialized to pool two is you will not
have this problem with tuple tube with
tuple three is not so you get three
boxes for every single one of those
tuples an easy way to defeat this is if
you know you're dealing with intz you
just build your own little case class
you know product i think is specialized
but regardless the case class itself
your accessors will be will be typed
correctly even if the product stuff
isn't so in this case we're only
allocating one thing and we're not
boxing those ins instead of allocating
one thing and then allocating three
boxes inside of it otherwise the code is
you know very similar and then there's
this natural question which like what
can we do even do better than this and
it turns out that the answer is that you
can write so this is a little uglier but
basically the observation here is that
why allocate a tuple structure and a con
structure when you can make a tuple cons
structure that does both right so in
this case we have you know an a of BS c
and a tail we've got this weird III cons
down here that basically allocates your
cons structure but has enough room to
put all three of the values in it right
so now instead of allocating two things
we're only allocating one and this is
just sort of you know it's based on a
very simplified version of Scala's list
you know you probably want to add a
bunch more methods and stuff which I
didn't bother doing okay microphone how
well is hot spots in lining by an escape
analysis going to be able to catch the
III boxing case I mean obviously when
you're passing over a function boundary
it has to put it to box it to be able to
pass it as a parameter but in other
cases I mean if you're just living
within a tight loop is that can be okay
or do we still have to do III list well
the answer is I mean you're still gonna
have to allocate those things for sure
like it's gonna it might stack allocate
them in some cases like escape analysis
will never it's never gonna like remove
those allocations entirely but it will
but you're totally right your
observation is a good one that it will
often be able to reason about it a
little bit better because it's all right
there so it can I think it can't stack
allocate in a lot of cases anyway then
there's this question which is can we do
even better than this and then the
answer is kind of so if you if you are
willing to make some compromises you can
basically say okay well if we can go two
at a time instead of one at a time we
can build this weird mutant
cons cons thing that has six fields
right and like this might be better it's
gonna have half as many things in it so
it's fewer allocations but maybe it's a
disaster I don't know let's see so you
know the downside with that like with
vector is that cons and cons will be
slower because you gonna have to break a
potentially break apart these things and
reconstitute them but you'll have better
memory usage which might be worth it for
you I mean objects I think it they have
like 24 bits of overhead is that right
or 32 bits of overhead it's like
something like that it's a pretty your
story 32-bit integer that's like a lot
of overhead for each one so anyway
here's the graph again this is
logarithmic so if you see these things
separated that that means that there is
like a significant multiplier there it's
not just like a constant shift so what
you see is that it's actually really
significant I mean if you go up to the
large amounts I mean that's like more
than a 10 times difference the dip that
to give you a context at that top point
the yellow at the very top is 22 times
slower than the green at the bottom so
that's it that's 22 right here so if
half that distance would be like 11
times and then half that would be about
five times damn it all right so anyway
here's sort of the results in a form
that's a little easier to digest which
is that for the hundred thousand case
you're triple your list of triples takes
27 milliseconds
24 0 point 5 milliseconds just using III
is three times faster already BAM
that's super easy there's it's like kind
of a no-brainer I I a list is ugly but
it is nine point three times faster so
that's also pretty significant I mean
you know this is something that you're
critical to your business if it's like a
thing that you do once in a while who
cares
and then I six list is weird in that if
you go back to the graph it starts out
being worse here this is it's the weird
purple star thing but it kind of gets
better than the one it's really near and
what's happening there is that it's at
if you have to build it element by
element it's actually worse in a way for
small amounts because you're constantly
swapping out the head of the list for
like the one version of the two version
then back to the one version and the two
version but when you get really large
the memory savings actually starts to
take effect which is that you're it's
able to garbage collect instances as
it's going faster there's less memory
pressure so it actually does do a little
bit better and then that the faster
version the green version is cheating
that's going by - so that's that's the
version where your own
ever creating the cons cons and you just
can't you know doing that and if you can
proceed by two then obviously it's it's
better to do that and that's 22 times
faster Daniel yes so there's a there's
another alternative here that I'm
curious if you benchmarked which is
going by chunks so rather than having a
list of triple of Intendant having a
list of triple of array int array inter
and and then having some particular
chunk boundary which doesn't even need
to be that large you're totally right I
mean that I didn't I didn't do that
because I just knew that was gonna be
super fast I mean as soon as you put
array in the picture you're basically
like like list the only time list can
ever compete with array is when you're
doing like a last in first out queue
that isn't ever gonna get very big and
those are the cases where it wins it
just loses across the board so if I let
array I just didn't even want or it's
like heavy weight and welterweight
boxing you know what I mean it's just
not even but you're right I mean you're
totally right that that's actually a
great model and that's that sort of
what's being gestured at so sort of
tying into this I mean cheating is good
if we can proceed by two instead of by
one and it's better we should do it you
know we should take advantage of
whatever we have you know we shouldn't
we shouldn't force ourselves to stick
with the most generic solution if
there's a way that we can cut a corner
and be a lot faster and I like type
classes you know because they give you
that flexibility that the ad hoc
polymorphism means that if you end up
with a certain type and you know you can
do something really sneaky you do it you
know and that's great um it so it's a
way to be functional and to do that and
I need to proceed because I'm totally
behind anyway boxing and allocations
aren't always the only thing I sort of
made it have made it seem like they're
but they aren't and so cash cache
coherence is also really important I
have an example that kind of shows this
off so here's three different
collections of two-dimensional points
right the top one is a naive array of
points the middle one avoids allocating
point objects and has an array of
x-coordinate an array of wise and the
bottom one interleaves
actually the bottom one is totally is
the wrong code example crap it's
supposed to be one array of XY z--
that's what I benchmarked I just
copy/paste err anyway it's gonna have
one array where the x and y coordinates
are interleaved if you can imagine that
right and the scaling operation I'm
doing is I'm basically I'm taking the
distance from the origin and then I'm
scaling the x and y coordinates by that
so I'm basically mapping the points into
the units
somewhere along there it's it's a pretty
dumb little thing but you know it's
enough work that it's actually
significant I didn't want to do
something stupid super trivial so I'm
not gonna show you the other implement
instances they're not interesting the
one thing to remember is that the array
is twice as long for interleaf points
and then it's going to step by two not
by one because it's going X Y X Y and as
you can see here the interleaf points is
three to six times faster but the other
two are basically the same so the array
of points and the two arrays of X's and
Y's are basically identical until you
get to a certain point where the array
of points falls off a cliff basically
and what you can see there is that JVM
is actually really good at doing garbage
collection of very short lived objects
but at a certain point what's happening
is or it's very good at allocating a lot
of objects and dealing with like massive
allocation of course but at a certain
point it becomes too much and you
actually start you start hitting a wall
a little bit and so they're the same up
until the last point but for the very
last one the array of points is 14 times
slower so you really do just what kind
of fall off a cliff there and that's the
thing is if you never hit that if you're
never gonna get that big don't bother
doing anything fancy but if you are then
it's important and and the lesson here
really is that the cast you choose is
what was significant not the not the
boxing or not the allocation anyway this
is kind of the closing remarks section I
think I guess I'm kind of going over a
little bit
two minutes great but um people would
say well Ray's immutable isn't that bad
and it's like well yes it is kind of bad
but you know we sort of go to war with
the army we have and I like to consider
arrays is mutable only during a
construction period so I like think of a
Razors like they're mutable when you're
building them but once they're built you
shouldn't mess with them and at that
point you should sort of treat them like
an immutable data structure and if you
need to make a copy and making copies of
rays is actually super fast so that's
actually not a big problem if you're
someone who's a real hard liner like you
know one of the scholars the faction you
might want to just make a wrapper so you
can guarantee your arrays not going to
be modified right you make an immutable
wrapper and then you only expose apply
that works fine so for an example of how
I kind of think arrays should be done in
Scala I would point you to this geo
trailers project which is one of the
things I've worked on basically it's all
about arrays we have these giant grids
of numbers we just smash them together
and do and we tie
and do them in his tribute away and then
resampling and also it's a different
junk but we had a high level it's all
purely functional it's all referal eat
rands parent at a high level there
aren't there isn't a whole lot of shared
mutable state and it does make copies
but at the same time at a low level
table to be very fast because it doesn't
it doesn't try to enforce that and may
remove immutability down to the cell
level it only enforces it down to the
chunk or the raster level at which point
those can have very fast implementations
in terms of you know tail-recursive or
while loops or whatever and even in that
case we at a high level you can still
call map on a raster and it will still
do it like really fast we just have some
tricks to sort of works smooth stuff out
and masters aren't generic they're
specified to be either inter double or
something like that so there's there's a
lot of interesting stuff you could get
there if you're interested in this kind
of thing um what about vector I don't
know for the kinds of stuff I'm talking
about every little thing vectors are
that great I think for mid to high level
code or shared code they're really good
but amortized cost you know effectively
constant time access is not array access
and it's just a lot slower so also they
box they're not specialized like I said
so you know you're gonna have those
issues these are really the only I think
the into 10 these are the only
specialized types basically so if it's
not one of these on this list you can
assume you should just assume that it's
going to box all the time arrays are a
special case arrays also don't box
because they're sort of like a primitive
in a way and I would encourage you to
use value classes that's another way of
him removing allocations Java or Scala
Scala this is 210 I mean yeah before 210
actually function I mean I think tuple
function 2 was not specialized into 9
that was actually a big problem for a
lot of people so if you implement a
generic binary operations the two inputs
one output
it wasn't specialized and a lot of
people would have to create their own
manual function to to get around that
which was super annoying and then what
about the other collections well I don't
know I mean for this look again in the
sort of narrow scope of premature
optimization if you know exactly what
you need to do you can probably do
something faster than the generic thing
built for everyone I mean not always but
I would say often I've done a lot of
work in this and when you have a
specific thing in mind if you don't need
generic types
you can skip them and you'll save a lot
of time if you don't need you know
whatever you don't need just don't do
and that'll be better
I sort of M invocate ananda bennett here
a little bit you're the best judge of
whether it really is worth doing or not
but you know if you can get it ten times
speed up it seems like maybe it's worth
a little and IH to get that you know so
that's kind of this is kind of my ethos
is I really I really strongly believe
that it's important to profile your code
I come up with a baseline because well
if you notice all of my graphs it wasn't
just one thing it was like a bunch of
things to get a sense of where your
solution fits in the ecosystem of what
other people are doing or you know what
the state of the art is because
otherwise you just don't know you might
think your things fast and its really
slow or vice versa
and you know pay attention to the
versions of stuff you're using Java
sevens a lot better than Java six for a
lot of things so that's worth knowing
and finally make sure to test
correctness I mean I've definitely done
the thing right I think I've implement
some insanely great data structure only
to find out that it's actually not
working properly so it seems so fast
because it's not doing any work you know
that's a pretty humiliating thing and
the last thing you want to do is CRO
about it on Twitter or something and
then find out that your thing is
completely broken so make sure to also
actually test it you know not just
benchmark it and then again you know
this is what I've been saying I I think
functional programming is great I would
be reluctant to give it up but if you
can minimize the area where you need to
do something unsavory you should have no
compulsions about doing an unsavory
thing to achieve your goal basically the
ends justify the means
I've said it and then there's a bunch of
awesome links there's people who are way
smarter than me about this stuff that
I've learned a lot from here's a bunch
of different interesting links to talk
about various things I have either
alluded to or mentioned and if you look
online you'll you'll find lots of stuff
so that's it</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>