<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Eddy: Heuristic Autocorrect for Java | Coder Coacher - Coaching Coders</title><meta content="Eddy: Heuristic Autocorrect for Java - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Eddy: Heuristic Autocorrect for Java</b></h2><h5 class="post__date">2015-07-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6SVdOlvzJVE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you can everyone hear me if I
speak I'll keep talking until someone
tells me otherwise okay great okay so
this is a talk about Eddie so the basic
idea is that we are sick of programming
in sort of pedantic computer languages
so you have this wonderful idea that
you've dreamed up it's entirely on you
to translate that idea into a language
and the language is designed pretty much
for the computer and then while you do
that the computer sort of yells at you
with error messages and and bugs all
sorts of things so it just it's it's not
very helpful so the problem here is that
the input we use sure go ahead so the
question was when is a near miss is not
helpful and the best answer is undefined
is not a function another answer is
syntax error which is getting a little
less common but still still occasionally
affairs so the problem here is precise
input so we as humans are talking
directly to a language that's been
designed for a certain kind of behavior
so computers so it's it's great for a
compiler it behaves deterministically
all the time if you run it it'll do the
same thing borrowing asynchrony and such
it's good for debugging because again
it's repeatable and you can sort of
understand its exact behavior but it's
not so good as an input mechanism so as
we're as you're trying to convey or at
ease into a computer um we want the
computer to help with that translation
process to go from sort of if there's an
obvious fix the computers just figure it
out and give you the code and because
its interactive you then still get the
benefits of these sort of this is final
deterministic syntax so again we want to
make the computer help with the fuzzy
part of programming so accept broken
input so sort of as you type typos
missing syntax all this gunk ah if the
if the computer can understand what you
mean just fix it right away if it's less
certain if there are a few possibilities
ask because we're doing this at sort of
the IDE time so we have the
chance of asking the user for a sort of
for help and because we're again in an
IDE be fast enough that we can run it as
user types so Heidi the less than a
second so the simplest version of this
idea that we sort of manage to boil it
down to is fix one line of java at a
time so originally we had this grand
plan of sort of yeah this sort of fuzzy
pseudocode on the on the left and
perfect java on the right and it would
sort of you dead either side and be
great and that's just really hard
implement it sort of breaks program a
workflow what would you check in so the
simplest thing we've done is just aa if
you write one line of broken code and
the rest it's inside at a normal Java
file will replace it with the right one
instead of fixing fixing bugs in that
one line based on context Martin will
give a demo of what i mean so so yeah so
we built this thing and i'm going to
show you what it looks like so i built a
little like scaffold here so i have
something to work with eddie is a is a
plugin for IntelliJ its currents
institution and and we haven't we
haven't spent time on building for clips
and you know you will so everybody has
to use IntelliJ which some may like and
some don't but that's okay so Eddie runs
in here and it's basically this little
hint that pops up so if I say for
example you see there is a string end
here and then there's also this this in
primary so if I say N equals test it'll
tell me oh you know you actually
probably meant to write this down n you
didn't mean to to assign this this
string to to an integer and that's kind
of the simplest version of this where is
obvious what I meant in a way so you
know I could have so intelligent would
have I'm just you know until as it does
actually you know just underscore that
line red and just tell you oh there's
something wrong and it tells you oh
incompatible types we've actually tell
me what I'm what I meant to write it
just tells me what the error is
and then I have to have you guess so
Eddie instead we'll just fill in the
right thing if I accept the suggestion
sometimes it's not sure what to do and
then it'll do something else it'll it'll
give me several options so we'll see
that in a second and of course there
there are cases were you know this is
this gets more complicated so for
example I could say this is array list
Eddie and then yeah I you know I just
can save myself some time typing all
that stuff out twice because that's what
Java likes to do like it likes to have
very specific and very kind of plain
language so to speak and you have to
specify every type as often as it occurs
but you know it's not necessary to
understand what I mean like everybody
every programmer role inside what I mean
here so and here it's not entirely sure
what I meant you know I completely
omitted the the parents in the end so i
could have wanted to tell it like oh you
know it looked as like this integer
around so maybe you want a specific size
and then it's sometimes obviously yes I
can see you're like you're amused of
course you know some things don't make a
lot of sense like yeah and we're working
that so this is it's it's set up to be a
learning system and it hasn't learned a
lot yet so it will still come up with
these things anymore them fortunately
for us that's lower probability so it
doesn't it doesn't always make mistakes
but sometimes we'll make mistakes and
that's okay the thing is that in the end
what you end up with Java so you know in
the worst case you've lost nothing in
the best case you say all the time
but in the worst case you know it
suggested something unreasonable you're
like oh well that wasn't what I meant
but that's okay okay and then I can
obviously do you know we did abate with
most of the or we did it away with with
the need for most of the syntax so if I
do something like this it'll be like oh
yeah you know print line there's only so
many things you mean
and this is the one that you probably
meant and again you know it could be out
or error or it could be this that
probably nobody ever uses this and and
this probably not even like Conrad some
deploy really I mean so these are things
that that are still there still there
there in my environment they're possible
but they're low probability so you could
set these different than you probably
wouldn't see them but yeah so and this
whole like trying to make these things
more sort of do away with the syntax
requirements that are really well
sometimes they're in the way and
sometimes they're just unnecessary you
can take that you know to concerts
obviously and you can you know type sort
of pseudo code and it'll be ok let me
add this
actually I mean right contain show you
something else we sort we kind of
implemented this Mick six infix notation
for that kind of a scholar thing that
carried over to Java or like how about
this riddance carlo so we ended up
actually mixing things up so we're like
okay well and you should understand this
so here it is and most of this grammar
as it is right now is in a way
crowd-sourced I was like oh singing you
really should understand this why don't
you just end this so one of the main
advantages apart from syntax is
discovery so imagine you work in a
fairly large system like like this one
this like whole files full of code so
you get confused and you don't really
know how to use every little function in
every library that you have and but
typically you know what you want to do
and typically functions are called in a
way that are that are memorable so what
you typically forget is okay what's the
what's argument order which file is dis
defined in which package was that in so
so for example I I know like if this is
the case I probably want to log what and
it's a warning and then it'll tell me oh
you know you know there's some logs
things in particular you know this is
one I want and it figured out okay first
of all you know okay so see it's in
utility it's this class utility I didn't
know it was utilities or utility
whatever so it's filled it in for me I
had to actually give it this lager
object that's the static thing that I
had around that's great it's not
actually Warren it's like leveled at
Warren you know Java always makes you
write the class name unless you static
be imported which but you know IntelliJ
doesn't go as far as to tell you these
kind of things and then I messed up the
order of the arguments like it's
completely but it's in reality once i
wrote log and then some string and maybe
said the log level it was pretty clear
what I wanted to say like no programmer
would have said like oh I completely
don't understand what you mean
most programmers probably would have
known what I said so we believe that you
know this is my daddy should do the same
thing and should just understand you if
it can and yeah so that that's what it
that's what it looks like looks like and
we can just you know it tries to be a
little more clever about what it would
it understands what it isn't and it will
will help people in the end be more
productive and kind of can so they can
rely on a computer to actually fill in
stuff that they don't remember or don't
want to bother you want it yeah so
that's a great question so the question
is and remember your second question so
the question is how hard is it to teach
Eddie about not only the basic system
libraries but all of the libraries out
there which is one of the main main
advantages of course of the Java
ecosystem which is just really large so
the answer is Eddie as it is right now
knows about all of the libraries that
are it it has two levels of knowing
about libraries once one it knows all
the symbols that are in the project so
it will not as it currently is suggest
you like if you write some log and lar
4j happens to not appear at all in your
in your project and I know it's not
installed on your system which is I'm a
kind of impossible but you know a
different library some may be spring
right it's not even there then Eddie
will not know about it but otherwise it
knows about it and it'll it'll suggest
it and there's a second level of knowing
about stuff which is to have good priors
which symbols are very likely and which
symbols are not very likely right so
there's there's two ways you learn these
and at the published version of Eddie is
not very far down that road but
hopefully as we get more data that
they'll be better there's you can learn
this from input and learning what people
accept as the
the choice they make so Eddie is
actually collecting data you can opt out
of this but if you in solvent you let us
it'll actually collect what your choices
you make and we can analyze that and
then feed it back and basically adjust
the priors to see for example that one
of the prizes in there is system that
error is much less common end system
about so it'll even though they're
perfectly equivalent it'll first justice
until it out and then system there right
and so for these libraries basically the
users frequency is lower so it'll take
longer to learn these things and what
you can do to make that it make that
easier is you can look at open source
code and see symbol frequencies there
and then feed that back in and we have
started the process but it's not none of
that is published it so if you want to
help out go ahead yeah do you have
another question ok so so the question
to repeat given that we like the oh yeah
so the question is how would we deal
with with week early we could type
languages and and the reason is that
this particular system relies fairly
heavily on types that's why it's red for
java specifically and the AST is not so
much a problem but but basically our
main constrained apart from the priors
that you can learn the main constraint
is whatever you spit out has to type
check and that's a very strong
constraint in java it's much less strong
constraint in in say javascript we are
working on javascript and java script
will have like a very different kind of
back end and we'll talk a little bit
about it later so you can see what we do
for this and it relies pretty heavily on
types for javascript you will do it
differently there are approaches to do
it in javascript they will be a little
more fuzzy and sometimes wrong but yeah
so go ahead
so there there is in the end what we
output is standard Java huh oh sorry yes
so do we use the Java at standard type
system or do we did we build some
inference on top of that the answer is
what we output is obviously has to be
legal Java so however our out yeah our
type inference is is somewhat stronger
than the one on of java and but it's a
little bit it's a little bit tricky to
say that because we actually don't
necessarily assume that what the user
typed is correct is what what the user
meant we always have this probabilistic
process where we say like yeah you type
this you know you put this cast here but
you probably didn't mean it because
probably you meant something slightly
different so yeah so it's a it's a it's
a little hard to say like where the
infant stops and we're like just
corrections are start but yeah it's a
little stronger than what Java prides ok
ok I'll switch back to I totally I you
know some of you may have seen this but
I totally forgot my favorite line i want
it i want to show this because i like it
and again anyone standard Java so
everybody will know this but so let's
say I want to fill this list with stuff
and I just have to say it because I ever
licked so I'm originally a C++
programmer so so i always get really
upset by javas parametric method call
like type type parameter in a method
call syntax you'll see what I'm talking
about so let's say I want to add add
some stuff to the list and i want to add
there i have this method here it's it's
it's a it's a franchise method okay it
as array and actually yeah so here you
go so this is what i would write as like
a c-plus off around obviously that's not
legal and what is legal is this
wonderful this wonderful expression here
continue to at all list and then this
dot you have to you have to follow him
with this and then put your your type
parameters there so this is correct java
which is wonderful I don't have to know
this anymore so from now on I'll just
assume that it's equals plus centers
right it'll be fine which I do quite a
bit and then it's annoying because it
doesn't actually work but now it works
so it's great thank you Thank You Mari
oh we're not done so this is how it
works ah to sort of follow up on your
hypotheses so we're plugin for IntelliJ
it's about half and half Scala and Java
which really means that all of the logic
is in Scala and all the boil plate is in
Java it's the imitation so it is sort of
most of a normal Java compiler there's
the front end part but unlike a normal
Java compiler every piece of the
compiler can say well it could be this
or it could be this this is more likely
someone else aside and that of that amy
was sort of that ambiguity will filter
through the rest of the compiler and
figure itself out so the algorithm is we
read the input sort of parse it and we
parsley using a fairly sort of fuzzy
flexible grammar so you could have a
dozen courses that are possible so you
sort of someone leaves out parentheses
you don't really know how what they
meant to write um but we're going to
handle that later so we parse it into
say it doesn't puzzle possible parses
and then for each one we sort of it
expand generate this tree of what it
could mean so if it is a bunch of parts
of the line like this part could mean x
y&amp;amp;z this part payment mean ABC and we
sort of explore that tree using brute
force search but while we do that we're
constantly pruning away bits that aren't
valid Java or are unlikely unlikely
according to the prior so if we have two
different choices will pick the most
likely one first and then only go to the
less likely one if we have to and that
lets us hide the sort of exponent to
blow up in the search space behind sort
of lazy evaluation so luckily parsing
one line of Java is easy so IntelliJ is
lovely because it is everything at all
of the rest so we have your writing a
whole file we let IntelliJ do all of the
work for the
rest of the file except for the one line
you're currently on and that one we can
use sort of slow cubic time dynamic
programming and then again we use it
that's important because we want to
handle ambiguity so our parser is sort
of the Java grammar simplified and
extended so you can be a little more
lacs so there's several different ways
of applying functions you can sort of
you can drop new or add it where it
shouldn't be and it'll it sort of ignore
it lots of choices like that and that
gives you sort of this is this large
number of sort of possible parses that
which will search through later on and
also we can week instead of add in
mismatched parentheses so if you mix
those up we'll try to stick them back in
for you in the most likely way we think
the way we implement this I think there
was a fun talk a couple months ago at
this meet up on the Twitter people doing
sort of the futures monad for how they
sort of structure asynchronous
compositions or its ember this
computation in the JVM from Scala we're
also doing this sort of monadic
structure where we're instead of using
weird control flow so we have we have
our whole compiler inside this scored
monad which represents sort of this lazy
list of alternatives so it's probably
this maybe you could be this then these
these options are much less likely and
its rich ordered so that you don't
expand that sort of the tail of unlikely
options until you need to these scores
are sort of viewed as like not 0 and 1
probabilities and when you sort of if
you do two things if I thought if I say
a comma B and the score of a is point 7
and score of B is good correct so those
are those are what you get when you
multiply all of the scores together from
all of the choices I've made so it Eddie
can fix multiple mistakes at the same
time but as you do that the score gets
lower and lower and we'll push it sort
of below other more likely more likely
options so here's an example so for some
reason java and also nearly every other
language like Scala and seal applause
and blah blah blah you can't put
parenthesis and types
which is confusing because they can go
everywhere else so we allow that but
because it's not valid Java we assume
that it's less likely you're going to do
that so if we see a some parentheses
around a type well say well that's fine
but we're going to we're going to reduce
the score by a factor of point eight and
we'll because this is lazy will only
evaluate it at the type if that point
eight isn't enough to make it unlikely
so if someone else says all I can beat
point eight I can be point nine will
completely ignore this sort of type
expansion and then sort of save save
effort and again with this lets us do is
sort of keep flexibility so we we do
allow parenthesis and types but we don't
allow them as much as we allow something
else we have this sort of fuzzy notion
of what things are legal so because we
have a monad there's these various ways
of combining different sort of compiler
computations together so if you have one
value that you know that's sort of a
singleton list if you have one
computation say a list of function
arguments and if you once you've
computed that you can compute a function
call then that's like flat map if you
use that a monadic structure that you've
seen this for Scala if you have two
different computations like you did you
say f of f of X comma Y and there's sort
of two different lists for x and y those
can combine instead of a Cartesian
product and again this biased one is
just a simple case of one thing but less
likely so here's an example to make this
little more concrete so say someone
types print line X so this is almost
valid Java almost the the thing on the
left which is declaring a type a
variable of type of type print line with
name X but no one would think it means
that actually so but because it this
looks closer to Java we're a foot will
first do the thing on the left so we go
over here and we say well let's see if
print the print line at the type so we
look it up on our environment and so we
first tech of it in scope no we take a
bit sort of a variable that's on nearby
but not quite in scope
no print light is not a type and then
maybe it's a typo maybe it's some light
it's print line with a capital P but
because this bias has reduced to the
score 2.5 we're going to stop there and
go over to the other side where maybe
print line is a function call so we've
left out the parentheses so it will bias
that by point 8 which is better than
point 5 so we'll do that next so as prim
line a callable well there's a couple
things it could be solanum scope it
could be this weird static function
which is possible but unlikely because
no one wants to call really long static
functions aren't imported so maybe it's
a non static thing so we do this sort of
a flat map operation defined variables
which might be objects that you can call
print line on and sure enough we find
one and it's really great the prior says
there's no penalty for using system that
out good choice so the result is we've
sort of interpreted this line of code
which looks more like a variable
declaration to Java into the thing that
every programmer would assume it means
it's obviously a call to print X so the
fun thing about this is that then if you
sort of set up this monad and these
various ways of handling ambiguity the
optimizations are about knowing what you
need to know when and sort of pushing as
much laziness as you can so it to the
expensive sort of exponential blow-up
which we have happens later or not at
all so for example if you have two
computations that are totally
independent the two separate lists then
that's a faster structure than if the
second list appends on the first list
because then you can do you can evaluate
each one independently and then combine
them as opposed to do instead of in it
and sequential sort of blow up blow
fashion I'll skip the next option if
anyone happens to do haskell this is
sort of the same analog as applicative
versus monad so sometimes sometimes
these weaker monad structures give you
faster code so the most of the compiler
logic is written in Scala and Scala is
wonderful but it's very slow so we have
to we have to make it faster so this
we have this lovely functional sort of
weird functional programming abstraction
called the scored monad nearly all of
which is written in Java because Java is
imperative it's fast it's really nice
for writing sort of bare metal which
means JVM constructs so we the scored
monad is written in sort of highly
optimized Java but it looks functional
to the outside so our compiler can
behave as if it's working in this sort
of pure purely functional environment
Scala also loves to allocate memory
which is terrible on the GBM if you do
it as fast as sort of our we end up
doing so we the set of the JV the java
emulation of the score monad tries to
skip as many allocations that can and
with that amounts to instead of
intuitively is if you start looking
inside a computation you want to look as
far as you can before moving out to
somewhere else because whenever you do a
context switch you have to allocate some
memory to sort of preserve your state
and this is this is sort of run time
strict strictness analysis so knowing
how much you can do how much work you
know you have to do now before you move
on to some other sort of lazy lazy part
so more details so one of the things
that we allow in terms of errors is
every name can be a typo so that
includes includes variable names
functions types no lore int so keywords
in Java all of those we look up in
something this large tree with with
allowed which allows errors and we sort
of rank those arrows based on how far
you are away at a distance wise so this
is an example of laziness so we do a
first fast computation to find sort of
exact exact matches so because those are
more likely and they're faster and then
if those fail we reduce the probability
to sort of hide this this computation
and then look for typos and then which
means that we can always look for typos
but we're only start looking for typos
if this exact search has failed so the
fun thing about known ads which is sort
of any application of monads is that you
can
separate some weird kind of sort of
control flow ah jik from your actual
application logic so we have a compiler
the compiler does a bunch of stuff which
looks just like a normal Java compiler
front end and you don't want have to
think about the fact that it's sort of
jumping willy-nilly around the
computation tree searching for different
values of these these lazy lifts as it's
doing the compiler logic so writing
writing the compiler inside this monad
lets us keep that separate and we can
just one part of the code focuses on
being a compiler and sort of doing Java
type inference and dealing with the Java
semantics and ast and so on and the
other sort of other part handles this
search the problem with this is that
we're writing an interactive tool so
it's as user types and the performance
of the of the whole tool depends on
these scores so you can imagine that if
you if you increase one of the scores
towards one it's going to be more likely
that that lazy search will expand that
part of the tree and then waste a bunch
of time in possibly a useless direction
so this is version is a somewhat
important balance where we we have to
sort of adjust we can only sort of play
with these scores so much before we run
into performance problems and then have
to have to think about those so much
carefully which is more of an issue
going forwards right now are we don't
have a lot of sort of learning of these
numbers and as we start to learn them
that will be more of an issue so Java is
a complicated language it's the best
language for this probably but it's
still complicated so it has undecidable
type checking for example sort of
generics + object orientation just like
Scala only a little less so we haven't
yet handled all of Java so we don't we
don't handle sort of class declarations
and field declarations we're focused
entirely on statements extending it to
the field is not very hard but it's sort
of more work a look
we do handle switch and also inner
classes actually no lambdas though this
slide is obsolete so we don't have a
lambdas yeah but anonymous classes we do
we do yeah we're getting better yeah so
the question is what about one logical
line which spans several ID lines this
is a great question and we do handle
that so the way we currently do it is is
only halfway there for the following
reason we rely on intelligence tokenizer
to sort of eat up a line and then we
sort of have some idea when it stops and
this is not always correct so when
IntelliJ is correct it will we will soak
in the whole line and then process it
and we'll treat it as a normal line but
IntelliJ is often confused and if you
type part part of a line it'll be like
oh and you mean these next three lines
as well which is not right so we have
partial support for that and to get
further we have to be more invasive in
terms of like taking over intelligence
tokenizer in particular the prompt the
problem mostly occurs if you write
mismatch parentheses because IntelliJ
considers everything until it kind of
gives up or finds of matching
parentheses the same statement so it'll
just like expand like until the end of
the park shin most of time and then we
have this garbled mess that we like okay
whatever regular so that that is the
main problem and we kind of have to it's
actually it's not a conceptually
difficult problem because the correct
way to know is usually indentation you
don't want to keep searching if if the
user starts to unen dent back to the
original level so a fairly simple
heuristic captures that and we have not
emitted just yet but I like that
question it's bothered us many times so
intelligence is a code of a hostile war
zone so all the data structures are
imperative it's a bunch of locks and all
sorts of plugins and third party stuff
competing for these locks it's very easy
to create deadlox we because or so we
want to sort of index the entire project
we want to index the whole world so we
can search through it dynamic
those indices have to be kept up to date
all the time an intelligent like you
storing pointers into which data
structures you know it'll blow up and
it's it's the documentation is
reasonable but it's limited but on the
other hand we could not have done this
without IntelliJ so we are using so much
of their infrastructure so you we can
deal with one line and let IntelliJ do
everything else including all of the
other projects in the build system and
all and on on and on we rely on IntelliJ
for parsing and for building indices
janitor at an editor and of course
people are already using it so we don't
have to convince them to switch editors
which we would never be able to do so
IntelliJ is great despite these flaws so
the next steps are for us our
understanding the rest of Java so non
statements which are pretty easy just
more a little bit more grammar work
lambdas which are also pretty easy we
have most of the sort of the type
inference there to do lambdas the better
port the morning part is are currently
are is this prior for which things are
more or less likely is handwritten by us
my Barton and I and that's not the right
thing to do the right thing you do train
this these numbers from all of the open
source code and then other code the
people have written in particular
because that gives you what you are
saying it gives you not only a search
through through open source to these big
frameworks but also which parts of the
framers people use and in and I'll and
even more if people use if you start
using one part of the framework in the
first part of the wine by the end you've
unlikely to have switched frameworks so
you buy their sort of over the whole
line you can get a lot of information
out of these sort of out of scanning
code and there's a lot of code to scan
which is with a great we haven't gotten
there yet and again the one issue there
technically which we're going to run
into is that because we have this these
crazy optimizations that are based on
when you can be lazy and when you can
not be lazy is you start training the
prior that will degrade it may also
speed up because if you have better
accuracy in terms of what people never
do you
don't ever need to explore that until
you have nothing else to do so maybe it
could be either good or bad we will find
out another important step is sort of
clean error reporting and the sort of
two ways to do this one is you can the
most interesting thing to do is if you
have some large line it may be that the
user is sort of kind of in cortical it's
meant an error message so what they they
really meant some some complicated thing
and most of line is correct but maybe
one part is raw is right but wrong in
context so the actual bug fix is
somewhere else and as a single line
thing we can't report that what we can
say is look we've we've produced we
fixed bugs and most of the line we think
you really there's something
fundamentally wrong with its last part
can you help us and sort of combining it
up the tree so that's another area for
for future work they can also make it
too much easier and more useful to use
and then we have our long-term fancy
dreams so one as you sort of every as we
started to apply these machine learning
techniques to understand the shape of a
sort of real code that's out there in
the world they're sort of there's
suddenly these very interesting
techniques from sort of deep neural
networks for doing sort of natural
language processing and a lot of sort of
text text work and images as well on
building interesting priors about the
structure of some space so learn the
learn the structure of images or in the
structure of natural language and people
are starting to apply these now to code
and to sort of learn idioms and the
usage patterns from large databases of
code and this can be exact like directly
applied both to sort of autocorrect
we're doing now and also to define bugs
and sort of do sort of automated code
review and style fixing and then there's
really fancies things like theorem
proving which I'm I get all excited
bikes and I'm a petition one thing
that's important is you is sort of
teaching machines to co but if you do it
if you do only a mediocre job of
teaching a machine to code you can still
get useful output useful applications
out of it you don't need to have a human
level AI before this is useful so this
here is a relatively simple rule based
system
it's already useful and a little bit
better we'll just keep being you can
keep sort of filtering out garbage and
you sort of widening the gap from sort
of where you can sort of project
pseudocode to real code as set of people
type so that moving more more of the
grunt work from the humans of the
computer so love feedback this is open
and open source and downloadable and
works in Android studio as well so
IntelliJ or clones yeah that's the talk
you raise your hand first so each ah so
the question is as words that are
descending this leis leis of the
evaluating tree how do we know when a
branch has an answer and we can we're
done we can show it is that correct yeah
so the answer is that you expand the
tree until you find one that you know is
the best one so if you have two options
and you have basically what we have
during the search our upper bounds on
the score or once we hit an actual
answer then we have the score so if
you've computed a bunch of options and
one of them has score point seven and
the other ones have an upper bound of 0
point 6 you know you don't need to
expand the further and we expand I
basically we expand until we get the
first option and show it and then we
keep working while that thing is on the
screen until we either get too low or
sort of run or five new options and as
we find you obstinately show them so
we're sort of doing that adaptively as
the as if the user stops typing we start
going to work and showing them as we
sort of produce answers basically
we do so for example we we do a little
bit of that so far so we the start the
question is do we update our priors
based on intelligence indices for the
current project so in example we do now
we don't do a whole lot of that yet is
we currently scan all of the imports and
sort of produce a few sort of summary
statistics which say that if you've
imported this this prep this this file
on 10 times it's more likely that if you
forget the import we can sort of fill in
the qualification for you so you're less
likely to use a function that's brand
new so will we score that lower than a
function that has been imported say in
other files a bunch of times so the
question is what about other editors so
it clips netbeans and then yeah ID
senators so there's actually a
distinction there so we because we take
advantage of so much of the IDS
infrastructure it would be hard for us
to port to them or dim remax i sorry i
forgot the second one but it is it is
fairly easy for us to port to eclipse
because we've we've done a fair amount
of work to separate the compiler logic
that we've written from the the logic of
sort of exploring a disease and the main
interfacing with with the IDE so eclipse
port is reasonable the because we are a
compute intensive plugin we spent a lot
of time wrangling threading bugs in
IntelliJ so most of the work doing it
and club sport is just getting around
the the bugs in sort of concurrency
model which may not be bugs in IntelliJ
some of their like some of the bugs we
had most trouble with we're in the Scala
plugin and so it's a whole third party
thing which we're running at the same
time and as a conflict but we do want to
port to eclipse we we haven't started it
yet
again so not really so we this last line
is the key bit that we oh we have a
question the question is if we are we
basing basing on academic work and
actually I may have skipped this slide
how do I get to that slide okay I just
show it in here so there is a lot of
work in this area um and we are we sort
of look to the work and learn from it
and then did something dumber so we
because we want to do want to fix so
many different kinds of errors that at
the same time a lot of these are really
lovely work but have sort of it was on
it was unclear to us that we could do
them in interactive it interactive rates
so we intentionally pick something
that's sort of simpler and more Pat more
flexible in certain ways and more
limited in others so our we're sort of
inspired by some of these but um and I
can these slides we can meet up if
you're curious to read through these
these are some of these are pretty
pretty good papers this the the one
that's sort of most similar to ours is
this cavero one which is doing pretty
fancy autocomplete um not auto correct
for scala so they can sort of
autocomplete higher order functions with
with type arguments and fancy stuff
whereas and but their model is that if
this autocomplete mode where you're
extending a line which you believe is
already correct and we sort of think the
right model is the human puts down some
stuff and then we think it's just kind
of roughly what you mean because you
made a mistake you're human and we'll
fix the whole thing for you all once so
it does interact but we we've sort of
had a different a somewhat different
focus from some of the previous work
right so there's two there's two parts
to that so the question is Java 8 has
introduced particular lambdas and
lambdas what you do with reasonable
cleanliness lines which have sort of
unbounded complexity they're there you
start out with a line and then you have
a whole function call there so the first
part of that is we're actually
exponential time not cubic time just the
Parsons cubic time so the rest of it is
much worse so that's the bad news the
good news is that cubic time is just
because we were lazy there are better
puzzling I with mature parsing
algorithms to roughly linear and the
real question is sort of how many errors
are you willing to fix all at once that
are sort of connected together and so
when we for example our current current
stuff doesn't do the lambdas but it does
do inner class anonymous classes and
when we do those we sort of segment
though we like segment the line so we
kind of take the whole body of an inner
class function call and treat it as an
atomic token for the purposes of doing
bug fixing on the rest of the line and
so that approach extends to some of the
applications of lambdas but of course
not in general like after you really
would like the thing to fix the whole
thing at once and there is some there is
a certain there is a concern that
obviously for certain kinds of code this
approach does not scale we think that it
captures a period usually when that
happens you um there is a if you start
writing a bigger and bigger lambda it
does we will make sense to take bits of
that and treat it as a block and error
fix the rest and then you can go in and
fix that so you can sort of work at a
you can kind of zoom out one level and
take bits and pieces of the line apply
what we currently have to to get through
like large bit large blocks of lambdas
because even for our code we do have
situations where we say Oh function call
of new and then inner class and then a
gigantic sea of code and we of course
can't run even a cubic time algorithm on
that line without stalling the 80 the ID
yep so the the answer the question is do
is does previous user of user behavior
affect later priors it doesn't yet what
we've and we have the only server side
component we have is this opt-in sort of
data collection which is an AMA none'
mised as much as you can reasonably
anonymize code which is is questionable
but it's opt-in so we have we're
currently collecting that data if you
opt-in but we are not we have not we've
only gotten a little ways to starting to
parse it and we have not done the work
of going further than that and doing say
as you as you type a project sort of
what as you sort of as you write code in
a project changing acquires accept and
we do parse the project as I said to a
different question and make some
statistics and then go from there what
we plan to do in future is what you this
sort of this you can set a structure
these kind of hierarchical Bayesian
models where you look at all of the code
on the web and you you see that maybe
there are a hundred types of projects
and these different projects have
different sort of symbol distributions
some projects are rare very sort of
spring boot heavy and they use these
kind of spring boot behaviors and you
can build up a this hierarchical model
where if you see a little bit of user
code you can snap into a point in that
space like oh this is a spring boot
project I'm going to use the priors from
that kind of those frequency
distributions and that I think is the
sort of the right way to approach that
and does give you a lot more power terms
of what you think is reasonable code
then just just sort of then the first
line of code that you type into a parent
I knew it I knew a new project I think
that may have been a slight sorry that
may have been a slightly different angle
to this was like we don't do currently
any kind of user per user
personalization and that's definitely
possible but going from this type of
offline learning to something that's
really kind of online learning where as
you type as you select certain things
it'll update your priors in actively
that that's probably a bit further away
and it's yeah it's a question of trade
of like how much additional quality of
result will give you and the biggest
chunk is definitely like the embedding
basically embedding of the project
basically where you like from the first
few lines you'll be able to tell oh is a
guy using you know this this framework
or this is this is this a is an a WT
project or away know per project is also
nice because if a new programmer joins a
project they will immediately be using
the priors that are according to the
project style so you'll sort of you'll
naturally be sort of guided towards what
people are already typing which is
useful for large projects other
questions yep yeah so the question is
how do we come up with these numbers for
the the biases and we made them up and
then we tweaked them when we didn't like
the result so yeah so I this is we sort
of structured the system so that ah they
have a big we have a bit gigantic list
of these numbers and we hope to be
learning is from data but right now we
just made them up a little bit so we
certainly so the question is did we take
inspiration from languages which cross
compile Java and as we edit this every
as we sort of write our grammar I think
more generally we've taken inspiration
from a lot of languages so we have for
example we have a bunch of stuff in
there that sort of Python II we have
sort of scala scala syntax o camel and
haskell as syntax and see both bosses
syntax where user to put the tape when
you put angle brackets on the wrong side
and then we when we put it out there one
of the first we got several people
asking for
I want the colons at the end of if
statements from Python and so that we
added that so we have we've sort of
we've kind of added bits and pieces of
languages here and there we the
disadvantage is that as we currently
we're currently writing this grammar
ourselves so we have not you really want
to move to a model you start learning
the grammar and the challenge there is
the data you'd really like to learn that
grammar is what people would love to
type have if they have the perfect
system like Eddie and there's not a lot
of code which is oh if you were if you
were Java if you're having a job would
you loved Python what would you type
there's only correct Java code so
there's a bit of a sort of chicken and
egg learning problem which we've solved
by just writing the grammar ourselves by
hand we don't although that's a good
that is a good idea currently we have
very little um we have no state so and
that's partially just for simplicity so
we if you opt in to ductile data
collection we just send data off no
servants one way but we don't maintain
any currents at any current statistics
so it's all of the say the local
knowledge is based on the project and we
if we it's pretty hard to reliably so
for example for indices which is
unrelated it's easier if we can the fact
that we can just blow away our knowledge
and then reconstruct it as useful so we
haven't maintained any state or do
didn't use it reports that's a good good
idea so that's a great question the
question is I if Eddie learns from all
the code on the internet which is all
wonderful quality will it learn how to
whittle in to be a terrible programmer
and the answer to that is similar to the
answer about different project styles so
if you what you really want to do is
look at all the code needed on the
internet and learn a topic model which
says that code breaks down into these
classes there are various different
kinds of projects and you may even yuba
can you can start agnostic as to what
projects are good and bad but then you
get so you have these topics and some of
the topics are good code and some of
them are bad code
and then there's two ways you can sort
of figure out oh now I actually want
only the good code topics one way is if
I you join a project and the project
itself is good code and here instead of
a novice programmer then it would
naturally be projected into the space of
good good code because the closets
already there and the second way is if
you have if you have a sort of
historical data you can sort of discover
that if people write code that is in
this one topic they immediately fix it
into this other topic or there the
commits have added a certain
directionality to them across get
history and now what again tell you that
like these this style of code is bad and
should be avoided so as we start getting
into this sort of learning process which
are not there yet that's actually a very
important like area to go in because
that's where a lot of the value is so
you it's not enough to say the power of
machine learning is that you can go
beyond types and say oh these are these
are both pearly valid Java but never
write that one there's a there's a
different slightly different angle to
this which is if you are allowed to scan
a particular organizations code you will
adapt to whatever that organization
tends to do and so for example if an
organization frowns upon the use of
log4j you will not suggest that and so
you know that's really where maybe you
know in the limit or when you when you
think about enterprise applications
that's maybe work what people actually
want to do where they like oh we have
this style and we have these these rules
and we'd like Eddie to understand and
promote these rules and that'll
automatically happen if you kind of let
Eddie that work through a particular
organizations code and then what it
learned from that uses use those things
in its models and that's again a
weighted could do the projection so you
could learn these topics from all the
code in the world and then assume that
like good organizations are on the on
the positive side of that scale so if
you look more like ordinations code then
you should have stripped away a bunch of
the gunk from get up which of which
there's a lot
so actually I'm not go ahead so also the
question so the question is have the
have the folks who've installed at a
been accepting of the dislike this
logging so so so we turn we turned this
log into an optional thing and we have
three levels of longing and the foot of
the kind of the initial like initial
release default was like log everything
and we have this on reddit and people
looked at it and and you know you can
count the comment like so ever and it's
probably like a quarter of the people
probably didn't really like the idea of
having a code lock like really didn't
like it and but but then again it only
tell you so much so the problem that
we're having is we don't actually have
if somebody turns off this data
completely we don't know they exist we
can distinguish between the people who
turned up the code logging and turned up
and actually haven't analyzed the number
so I can't tell you but so we know
there's this amount of people and we
could know there's like twenty percent
of people have turned off code launches
made the number of I totally in another
up that could be the Creator present but
but we don't know how many people have
turned off logging entirely without even
like that's sort of disadvantage of
being we were deployed through the
IntelliJ plugin repository so we are not
the user doesn't download Eddie from our
website they download it from someone
else and we don't really get details to
districts so the question is how if we
could if we did more logging we could
learn a lot better how do we anonymize
that data and the answer is that we are
in a space that is extremely difficult
to anonymize so so for example if you we
as we start learning from code one of
the most powerful information sources
about code is the names of things like
the names of functions names of
variables classes etc and so you can't
say minify the code because then you'd
lose
is this structure which is actually
where the human information is so we
don't really know how to anonymize that
that stuff there are machine there's
machine learning work where people have
done really fancy theoretical techniques
called differential privacy where they
can train machine learning models that
can't be reverse engineered but those
models are lower quality and they're
harder to train and there I think
they're bigger so it's not clear that
there's there are easy ways to anonymize
this this process I think the real the
real solution to this problem is for an
organization to say okay we buy it we
want you to like install our custom
version of Eddie locally where you can
scan of all our code and then work with
our code and build whatever mall you
want and we don't have to fear that it
leaks out because it's actually on our
servers and that's cool like that's
that's a perfectly valid kind of model
to work with and you can still use you
know the open-source knowledge base but
you know the extra knowledge that you
build from that company's code cannot
leak outside so I think that's real like
for individuals that's obviously
infeasible but because they don't
produce enough co2 actually train
something on but for organizations
that's pretty reasonable to do but even
in individual working on proprietary
code of their own their own proprietary
code can use the open-source train model
which will sort of mimic a lot of the
structure of how they program hopefully
so yeah I yes you can do that and you
can like that's sort of that's kind of
the security theater approach to nanas
asian but he's trivial to reconstruct
like yeah because you can just do sort
of string matching and you'll find out
that oh these these things mitten moves
together so what like the only guarantee
we can say there is like we are terms of
service or like if you opt in we will
not reconstruct your code and then look
at it but all we can do is say that like
it's really hard to guarantee that if we
reach as malicious so we're we're pretty
upfront that there's I don't know how to
do that on modernization technically so
the question is if the user ignores our
suggestion on one line do we save that
work and use it later and we don't and
that's that's purely a sort of a code
complexity issue so I'm incremental
izing our whole compiler would make it
substantially faster but we haven't
struck to the compile of the way and it
so it's a lot more it's sort of further
along the meta programming spectrum
which is always sort of a scary place to
be as you start to write fancier and
fancier code generating code generated
code and I don't know how to do that
well without writing a compiler in a
very sort of declarative way so we have
this habit meeting where we're using
sort of reasonably nice features with
Scala to do this abstraction to build a
compiler that can do search but to build
a compiler that can do incremental
search is another layer which is just
it's it's a performance hit or a lot of
meta programming benchmark the question
is are there ya are their benchmarks on
the side of the code base and how
perform as it is well we we do know so I
mean we use it for our project which
includes all of IntelliJ so if your if
your project is smaller than IntelliJ
you're fine if if it is so it what
happens is actually that so we use
intelligence in disease and they have a
certain size and IntelliJ SVM has a
certain size and
it's seven or fifty megabytes which is
kind of ludicrous so if if you if you
have a large project you have probably
increased that value already because
we're not adding all that much on top of
it what we add on top of is a lot of
just running a lot of code in the
background so so we're expand to when we
do build our own indices but they're as
lightweight as they as we can make them
so we for example instead of storing
data structures like like pipes we just
sore strings and then we expand the
types on demand during the search so we
don't add a lot on top of intelligence
memory footprint what we do though is we
basically run one processor full time so
if you have a spare process and most of
us do then that should be a problem the
memory is actually the bigger problem
because once you run out of memory the
vm just GC Thresh's the whole thing and
everything is terrible and so if you run
it a problem you probably have run into
that problem before and you probably
have fiddled with intelligence like
memory settings and then you're probably
ok but that said like the the Senate
standard JVM GC just also kind of breaks
after a few gigabytes of size and takes
really long and at some point there's a
limit but IntelliJ is is a fairly large
project so that's actually you know most
people are probably okay
i think if i understand correctly so the
question is we're using regular
expressions a sort of search speed up or
optimize or detect correlations across
these indices of symbols in a project
and we are not currently and the
difficulty is that if you build there's
one of the one of the cases where we
need to be fairly low linear time on the
indices so we if you have a linear
number of strings and they take out how
many megabytes of memory if we if we
start if we're any available if it were
at all superlinear in that performance
then we will then thrash through
intelligence memory limits pretty fast
for large projects because we need the
whole we want the whole project indices
available there are there is something I
think as we get if we if we push the
priors further and then we have a better
notion for a small number of set of hot
symbols which are more likely searched
then we can put more intelligence in
searching those sort of hot symbols and
then do the slower sort of more sort of
low memory thing for the rest but we
haven't done that yet so the question is
what is the best part of this project
and for me the best part is so I you
said as you program in java using this
thing on I just sort of that I'm sort of
gradually getting used to it existing
and sometimes like there's one time
where I sort of forgot and I was like oh
I want to check out this file type is
Java like how do I do that like what
crazy inna min son back then and then I
just remember that oh I could just say
like is it equal to Java and then it did
have it just fixed it for me so it found
the Java symbol and fixes capitalization
and sort of change the equals equals to
e to the 2 dot equals and so it it's fun
it's sort of kind of forgetting that
that you have this ability to not work
think about stupid details and i think
is if we sort of push this thing ology
further the hope is that you can the
programming
is a little bit more of a human process
where you're not sort of mired in
pedantic nonsense and you can just sort
of write down what you want and it'll
figure out the details for you so that's
the long-term hope and sometimes when it
when it happens is a surprise it's sort
of particularly fun yeah so these these
projects are the most similar so that I
think the coolest one for anyone he goes
Scala and Eclipse i believe is this one
and there maybe i'm not sure of those
following work yet so this thing will do
so well i think most of the especially
the either the current IDEs or this
Guevera paper are autocomplete which
sort of to say what that means
autocomplete to us is I have part of a
correct line help me finish the line
whereas autocorrect is I've written some
stuff project it into what I meant to
write like I've made I've made some
mistakes but this stuff is still pretty
cool so cook aveiro can you say you say
something like type x equals like I
think you would say ? or you maybe
you've hit tab and it will be able to
fill in a complicated function call
involving sort of several layers of
calls through sort of higher order
functions that are sort of polymorphic
and the again the it's the goal of
similar the goal is to sort of reduce
the amount of sort of library noise if
you have to remember so some of that is
interesting people are starting to add
so i think xcode will do a little bit of
this so especially instead of little
typo correction and they're they're
pushing that I think they're not they're
not going far enough and I sort of green
I hope that that of this point it's like
oh we should we should we should destroy
them maybe Apple will think that and
I'll do a wonderful job and it'll be
great because I think that this all ids
should do this like there's no reason
that we have all this sort of wonderful
technology now for a sort of speech
recognition and we can detect images and
sort of hallucinate things and that that
should be applied to programming just
because it sort of oh it can the
computer can sit closer to the the
pedantic language details
and also sort of understand human sort
of syntactic ambiguities so these are
all papers but Guevera at all is in a
closed plugin which I believe you can
download I do not know that they were
they may be an abandoned paper by
resident I'm very sure that sloppy
programming is abandoned the example
centric program is definitely abandoned
go like a deviant yeah I mean that's how
it is right like we know Joel Brown to
me he's definitely not working on it
anymore that's great well ours ours is
yeah I mean depends on how you know but
we're not the fastest people right but
we're only two of us I mean it's open
source you can I help us but yeah it's
an active development yeah yeah so I
mean we are startup and the code is open
source and online and you can you
contribute it but yeah the edges it
started so it doesn't I don't think we
will be limited by either of those so
much in the long run so the main thing
is that so the sorry i should say the
question so the question is are we
limited in the long run by cpus or
memory or which will have more so i
think we're most limited by algorithms
so that what we've currently done is
very limited by cpu than a bit my memory
but if you go a little further than that
and you sort of start to train these
models from large amounts of data then
probably memory and latency are the
bigger issues so if you train a model on
all of the code in the world and you so
that's obvious something you would do
not
everyone's computer so that's that would
be a cloud thing you're going to have
more rapid sort of talk talking back and
forth of servers and you can either do
it via latency like either trying having
the search sort of asking your server
but that's probably too much because it
has to ask a lot of questions so that's
that that's probably out what you can do
instead is you can moduli 'he's this
model that you've trained on sort of
build a prior that say here's the prior
for spring and here's the prior for for
other java libraries and then you can as
if the user starts starts their project
and it appears to be using spring
because it's in their project you can
download that chunk of the model and
then then you're down to memory but
again I I do I really don't think that
it's a big it's a big memory hit I think
if you the only reason that we r memory
troubled is that IntelliJ has chosen a
low number for their default JVM size
and once we're inside once you've
launched IntelliJ it's it's fixed at
seven hundred fifty megabytes you can't
grow the J the Oracle JVM can't grow
from inside so it's a stupid reason and
it's in we could fix that if we sort of
had instructions of the web page like
here's how you would increase your
memory but we can't make that it we
don't how to make that an easy install
process so there's no real fundamental
reason why we should be memory limited
it's just the current default settings
of IntelliJ so yeah you can do can
certainly parallel as this generally and
that speeds up arm but typically the
kinds of so I've done in sort of for fun
I've done other sort of like game like
combinatorial game programming like say
chess or or or things and that the speed
of you get out of those paralyzing those
algorithms go to these deep search
algorithms is sub linear so you used to
throw four cores at it and it gets twice
as fast so because so much of the the
speed is pruning which is similar to our
domain
so we we want to do a deep search and
then find a bound and use it to destroy
another part of the tree whereas if you
search both trees at the same time
you'll you'll do the search and do to
one whole bunch of work and then you
realize that this is the better one
where you could have skipped work so
there because of that scaling it's I
think there are a lot of other
algorithmic areas to focus on before
thinking about parallelism just better
algorithms and better better machine
learning models yeah thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>