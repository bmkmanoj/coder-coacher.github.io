<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Macros in Data Pipelines | Coder Coacher - Coaching Coders</title><meta content="Macros in Data Pipelines - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Macros in Data Pipelines</b></h2><h5 class="post__date">2015-03-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/THB1xF3M2U0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">both
well okay today I'm going to talk about
macros in a data pipeline so Who am I
let me just introduce myself my name is
Nevel walk has modified in the music
recognition team and we've been using
scholar since early 2013 and then we be
mostly doing data science work with
scholar so I do a lot of Scotty and
Spock and also do a little bit work with
stormy other data tools okay so there's
a really popular date combo the combo of
software packages used in data world so
the three of them parque that's a
columnar storage so basically stores
data in a column my column major format
and groups values in the column
togethers to to achieve better
compression and i/o performance on top
of that we use a broom inside out data
pipeline which is a serialization format
formats you're a similar to shrift and
protobuf and some other formats out
there we use a rule is a strongly typed
so basically define a schema and
composites to java classes and you have
a strongly typed representation of your
data inside the pipeline and on top of
that we use Scotty and Spock so you can
write a high-level Scala code similar to
a typical scholar collection APR you
write this pipeline hole in that fashion
and then works on top of a hundreds of
machines and so these three combos are
becoming very popular by three and this
is what if schema look like in a bro
typical schema so you have a type and
name namespace I have four fields they
are tied with the industry and whatnot
you can also have nasty types so you can
have my
levels of nesting inside your schema
that's also very typical for complex
data types and this is what a typical
type of 591 not typical this is a very
simplified version but that's what it
would look like and actually the park
hey bro sauce is from type are they did
a lot of early work on that and we also
started using that so here I have a data
source from this input file and the
input type is a account so you can do a
simple map of 202 Quillan very own group
by the key and can reduce by the value
as simple as that and the framework
takes care of the underlying part so
that's what our daily job look like just
writing pipelines like that and here a
few other things you want to use to
leverage parkade and the name liter
projection a predicate so projection
means missing sextours data where groups
columns together and most cases say you
have a log file with 80 fields it's very
typical in your job and a typical
analytic job only wants to access maybe
say three or five let's say our spotify
a case we log everything at you when i
use a distance to attract like time IP
country and whatnot and for our
recommendation purpose we only want to
use a name and a track being listened to
and nothing arrows and that's a lot of
redundant I all sao paulo a column for
the projection allows you to skip
columns not access and that saves a lot
of i/o column wise you can also push
predicates down to the reader level
because package stores rogue rules
together and local statistics eight for
the next fifty thousand tracks what are
the mix maxima and the minimum lands and
if the robot doesn't satisfy a predicate
can be safely escaped so this gives I
Owen in a row major
and this often leads to ten times or
more speed up so they all sounded very
nice right what's the problem the
problem is it's kind of clunky to write
so the native call you you have these
very beautiful Scala code that's type
safe and get ID support when you to
touch and then it prompts you a kid
named get amount and blah and it's very
easy to write but in a parka coat you
have to see say use string as column
names so you have the street affected by
them as strings and imagine if you have
net nested fields you have Latin say I
can't thought amount or Todd something
that's very clunky so strange I then
save an error-prone you lose the
autocomplete I might lead to a finger
injury and as you enjoy typing a lot I
mean some people do against also
everyone has this convention they change
well the Commission has used on the
score for schema underscore name spoke
schema but somehow they change it to to
cameo case forget us oh that's a Java
scene so that gets confused confused
confusing over time and also it's hard
to migrate existing code because you had
to rewrite all these the predicate is
even worse so located a native example
it's simple scala Londoner returns
boolean and equivalent parker gets to
use the visitors presently you have to
construct the predicate syntax tree from
scratch you have to know that column
types and names ahead of time in case of
stranger to use a factory message to
construct a binary and then there's also
the Java erasure scene where
have to cast scala float back to java
float it no no we don't expect people to
write this it's it's too much yeah and
it's like close your pores yeah so
that's also where that's where the map
were really really helps I play the
wrong with Marco little bit and once I
got used to all the coding and stuff
it's actually pretty easy to to to work
this out so look back to the native code
because what we have here is strongly
typed every class and the emeril schema
is actually attached to a class so we
have everything we need to know about
the types field names and everything so
we can inspect every object and the
expression tree inside a macro and the
work that out so what is the next
expression this is a typical pretty good
getting our account which is already
getting this first element and again a
month greater than 10 expands into this
something or the compiler there's a lot
of magic like converting a box type to
the primitive and then greater than it
looks like some kind of method
invocation it's fine boom this is the
raw version like if you do show raw in
the in the sin título 1333 that's the
raw version it has a lot of stuff and
you wish you have a rainbow parenthesis
now to be able to see this well
nevermind there's a pattern matching in
the recursion so it's better matron
recurring you can traverse through the
syntax tree really easily and D couple
or these predicates package yep so this
is the projection improved version so
the signature looks like this you have
applied my so that takes a specific
record that's the Avro rekha being being
operated on and the Gators GS is just a
list of whatever type here and returning
whatever and then there were the
redirects to ever over to the macro
implementation which
is a where is the context and then
there's your expression tree that the
motto has access to I'll show the collie
in a bit this is the projection and the
code looks like this so you write
basically native Scala code and it gets
compound to predicate API and one for
most of our data scientist who doesn't
really don't really know scholar or
jawadi can just copy and paste those
macros rundas and it's expected to work
this is the predicate for the gate
version similarly you have one lambda P
that of type T that's the arrow type
returns boolean and so this scene just
gets compiled into the the filter API
dodge and and a lot of stuff like the
example before so this is higher looks
after using macro stuff I learned doing
this compiler there's a lot lot of
scenes and I have to mimic when you
write a macro for example the park AAPI
all assumes column on the left side
value on the right side but developers
may not so company you can you have to
to flip the operators and encode for
both cases there are also both types and
primitive types and announced because
box type sank and have nots and they do
a fail to cast so these are the things I
have to talk consider type coercion
because the compiler does this magically
if you have Lance vs. ins floats vs.
doubles it sometimes helps you to the
commotion behind the scene implicit
bullion's like da capo and because it's
a rebellion type it's equivalent to talk
abou equals equals to true so these kind
of cases you have
consider and the code is here we are
using it in production and it's it's
working out pretty well actually so the
code is actually surprisingly simple
this is the 144 predicate some signature
here a lot of maps between scholar
internal names and the parque names some
hard coded column names and stuff and
the main body of the code is mostly just
case and recursion and that's it like
there are only two types like one is the
ply type of interest when it's applying
one is select select is where you have
name dot something and the applies when
you call method so yeah it works out
really well that's it thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>