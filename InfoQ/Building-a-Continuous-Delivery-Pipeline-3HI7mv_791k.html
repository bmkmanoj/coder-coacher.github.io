<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building a Continuous Delivery Pipeline | Coder Coacher - Coaching Coders</title><meta content="Building a Continuous Delivery Pipeline - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building a Continuous Delivery Pipeline</b></h2><h5 class="post__date">2012-08-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3HI7mv_791k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so my name is Evgeniy
I'm the CEO of your chyron I tend to
talk about where things like class odors
and memory and today I'm going to talk
about continues delivery but in a very
pragmatic away I'm not going to talk at
all about any methodology I'm just gonna
talk about you know how do you actually
build yourself a continuous delivery
pipeline are using tools like Jenkins
Nexus and library so if you don't know
the companies your turn on then you know
we're pretty well known for our children
arrabal which helps developers around
the world be more productive by speeding
up the feedback cycle so you can just
edit your application you know and in
the ID and see their results immediately
in that in the web browser and you know
we have quite it's used by quite a few
people so if you haven't heard about it
then definitely should give it a try but
otherwise it's fairly irrelevant talk
today so what I want to talk about is
kind of like very nicely very nice
process and as an example I want to kind
of bring the FedEx process where the
packages are actually packaged dropped
off transferred delivered and well at
some point paid for as well I hope we
hope what this FedEx hopes because
otherwise they're not very happy but the
important part is that every single step
in that process is trackable and if
something goes wrong it's always
recoverable right so every step is
trackable every failure is recoverable
that's and they spend a lot of time
building that process so and you know if
you look at the kind of Java EE this
packaging building and deploying
pipeline then it's kind of same package
you know oh you test you approve you
deploy the profit but for some reason
you know everybody complains that it's
not quite as not quite as smooth as the
fair
so they're always failures there's
always issues you know the production
goes down the ups are unhappy that EPS
unhappy you know everybody's blaming
each other but somehow somehow it's much
harder to build a predictable pipeline
for deploying an application than it is
for developing and deploying an
application than it is for the FedEx
packages so you know and okay
one of the reasons for that is is that
Java EE you know and generally software
building and deploying software is
significantly more complex than actually
the FedEx project and you know if you
just just start hooking into just a few
questions like how do you package the
application where does it come from
where does it go what steps does it come
in between who touches it what exactly
gets deployed and how what exactly is in
production so there there's you know if
you just stopped going to any company
and start asking those questions and
then you know you and then you get very
different answers depending on people
you talk to you'll get very different
answers depending on organizations you
talk to you get very different answers
even depending you know in the same team
like depending sometimes we talk to so
I've done like a few hundreds of such
interviews and it was always what was
the most interesting thing what I found
from them is that there's very little
rhyme and reason reason to how these
things happen like it's very very
different like it's it's the best that
people can come up with so and you know
and another reason why why software is
kind of harder to do than FedEx is that
you know this is the FedEx fail right so
this is some some packages you know are
in that car
it'll get recovered they'll get put in
another bus you know and they'll just
get delivered a little bit later at the
very worst you know what can happen to
FedEx is that the FedEx plane Falls and
basically all the packages are lost
right and yeah and insurance pays them
out right in software so the model is
the worst that usually the worst that
happens is you get a package tomorrow
usually it's delayed and it's a very
very very slight slight probability that
you'll actually won't get your package
but you'll get the money and so the
scope so the failure probability is
fairly low
and the failure impact is fairly low
this is software right so this is what
happens when software fails and the
problem with software is that it's in
child and like almost any physical
objects it has very high probability of
failure and it is has very high scope of
failure so any single you know any
single mistake in one place in this
whole big thing that is your software
will can cause enough you know can cause
something like that right and even the
best and the brightest even Google who
can pour resources and resources and
resources solving those issues still
gets those right so and this means that
it's software it's it's almost it's very
hard to actually prevent failure so
whereas in FedEx you can build a nice
process which prevents failure or
minimizes its probability and then
quickly recovers from the you know and
then ensures basically against
everything else then it's soft we can't
actually do anything like that so
something something entirely different
is needed and I like to think that
software you know and in reality if like
when I have to explain what is software
like to people who don't understand it
and you know I like to say that there's
just a bunch of gremlins you know
running around and and basically pulling
levers and that's what it looks like and
if one gremlin gets sick then you know
he pulls the wrong lever and that's the
problem
so you have this giant you know enormous
amount of if you try to reproduce
software in in the physical world you
get this enormous amount of moving parts
which would be you know the most
complicated machine you could ever
imagine and then it's not much
surprising that it breaks from that and
then then you know this machine has
changed all the time so it's not much
surprising that it breaks quite often so
the question is how do we fix this and
recently and yeah and the key the key
problems that you want to fix is
actually kind of to 2-faced
issue the biggest one is failure so that
the biggest question is always in
software because failure scope and scale
of probability is so high that the
biggest question is always how can we
either prevent failure or how can we
recover from Taylor or if neither of
those are possible how we can detect and
fix you know how we can detect and react
to fail quickly right so there's kind of
three different paths that we can go to
and the other problem is that you know
because they actually well you know
because so this is kind of this one
problem which is that we have this big
moving machine and we want to be able to
fix it quickly but the other problem is
that you also need to you know I've
changed that machine on the fly right so
we need somehow swap out the parts let's
put some parts back in and so that the
users won't notice a thing
right and this is also and this and also
and these two problems actually in fact
to get each other quite much because
failure produces downtime you know and
downtime is and very often they update
the changing the machine is what
produces failure so this is all kind of
in triangle so the question is you know
how do we how do we manage to how can we
fix those issues and the solution that's
recently been mostly good the most focus
is continuous delivery so continuous
delivery basically has kind of this
philosophy where we try to make
everything as predictable and trackable
as we can and we also try to make you
know we also try it so you know we
automate everything right this is kind
of so so everything is as predictable as
it possibly can so we try to eliminate
either eliminate or isolate human error
which is you know the most common cause
of failure still in in everything we
record everything we track everything so
that if something does fail we would
have a you know we'd have a breadcrumb
trail so that we could go back by it and
we could figure out what what is going
on you know not just one stack race but
actually meaningful meaningful data we
test and the most interesting thing the
most coolest thing I like about chemical
also we have continuous delivery that
then it becomes less and less difference
between test and monitoring so
monitoring is just you know a type of
test you do in production right and very
often it's the same test suite if you
have a test suite which what about you
don't but if you're and that's that's
and production is actually treated as it
all to my tests right so one of the you
know one of the philosophies of one
that's kind underlying philosophy is
that we embrace failure so production is
just a lot
test you know the last ultimate taste
and that's why we do things like partial
rollouts that's what we do things like
a/b testing that's why we have to have
sophisticated monitoring which is
basically same testing right because we
don't just need we don't just need to
know that the server pings
we actually want to know that the
software that is deployed there it
actually performs correctly right so the
services that it exposes for example you
know they still work they still respond
they're still respond correctly and and
so just just some more entering and
getting closer and closer together and
finally you know we have recovery paths
which is very often it's just like you
know we can we will be able to quickly
fix something but we're often it's also
a real recovery path so that's that's
something that we definitely we'll talk
about but as I said this is not like if
a loss fit talk this is a very pragmatic
talk so starting from the next slide we
actually dive into the actual delivery
pipeline so continuous delivery is
basically about building a pipeline
starting from your patches which you
commit in to your version control system
all the way to release ready release
candidate so the interesting they should
again kind of flavor is that continuous
delivery does not require you to deploy
anything the only thing it typically
what is required is that at any moment
you have the release ready candidate
right so you identify which candidate
which builds that release ready and
basically at any moment somebody can
come and the second thing that is
required that you can have a one button
deploy you know of those who are these
candidates but there's no requirement
that that one button would be pressed
automatically there it can be so this
you know you can do that but it's not
there's absolutely no way you know
there's usually no reason why you should
start like that most people are not
comfortable pushing stuff into
production automatically most people I
need to learn to trust their tests they
need to learn to trust their environment
and but what is required is that you
know we have a repository of builds
which are production ready right and
then a business guy comes and says ok I
want those features in production now
and he can press a button you know you
can say oh those features are in those
build you can just deploy you know press
this button
deploys right so and and that's how it
should work and so we the pipeline you
know this thing that actually delivers
the badges to the production breaks down
in three main components which actually
you know manage the pipeline and then
there's a few components like testing
monitoring and configuration management
which are kind of outside outside the
scope of this talk which go more into
this nitty gritty details but circus
ruination platform is basically what you
know what that's it what manages this
but what actually manages the logic of
the pipeline like when something moves
where what happens in each step and and
as that the delivery manager is what
manages your servers your applications
your environment and the artifact
repository is where you store your
builds and where you promote your builds
as they go through the pipeline so we
start with the registration platform so
we're going to use Jenkins eight yeah if
you're one of the five percent of birth
or population that doesn't know what
Jenkins this then we just did a survey
and Jenkins is used in seventy percent
of organizations so and on second second
is I think Atlassian bamboo which is
using six percent so sorry
used to be Hudson well III you know I I
don't want to get into that you can use
Hudson you can use Jenkins as long as
you you know you can use whatever you
want it's it's it doesn't even have to
be Jenkins Atlassian bamboo team CD are
also great alternatives and I just focus
on Jenkins well for reasons which I
could have I think on the next slide so
Jenkins is our orchestration flat from
Jenkins says what happens in what order
what are the conditions and actually
executes a lot of scripts for us it's
kind of like you know it has a lot of
this nice enterprising features which is
around basically you know around
basically scripting right so it's kind
of scripting for the enterprise with
nice charts and all kind of stuff and
and this is great this is it's very
usable for that but it does have some
issues which were also going to discuss
the second tool we're going to use is
library Bowl which is our tool so don't
worry it's not gonna take a whole lot of
the talk but you know and the main
reason so it's a commercial tool there
are some open source alternatives I
think well not really but the reason why
we want is a live herbal is a one
because it's very well supports the no
downtime updates it actually provides
this failsafe deliverin recovery which
is very nice it ties into this recover
part of the philosophy that every every
everything you do in live variable is
reversible it has wide occurred system
support like it supports everything from
JT to WebSphere and even netweaver
apparently has a peanut River you get
very good knowledge what's in production
and you can install it inside five
minutes without any documentation so and
what we'll use it for is for deploying
and deploying applications for updating
like production applications without
down times low sessions and using either
hot patching or plain old restarts and
our need in place is actually irrelevant
here so here's we get to the reason why
exactly variable is there's actually you
know not know great open source
alternatives you have cargo at this
channel you have like container own
bindings which I usually you know you
need to do a lot of work around them
they're they're not anywhere they don't
provide anywhere near as high level kind
of this you know just update this
application to that version they provide
you you know if you have to usually if
you want to do this kind of no downtime
rotation then you have to do it either
yourself or risk or just use kind of
redeployment and risk out of memory
errors and yeah so so the and we also
support the whole wide ecosystem so you
can use the same tool to manage all your
containers and you know and we actually
integrate with things like Jenkins with
bamboo with a lot of maven and so on
with other open source projects so the
final tool is nexus which is you know
which is an OSS and commercial artifact
repository again like we're using
it's you know an alternative is
artifactory which is actually a great
which is also a great repository and
there's a there's a talk I think
tomorrow from baroque which which
actually is going to talk about that
repository so you can you know if you're
interested can attend
but for our purposes there won't be a
lot of difference but actually artifact
you just have some nice continuous
delivery oriented features so which
which will make some of the things that
want to do much simpler so but not
impossible to do well it's I guess you
know you can do everything always an
open source if you're just willing to
willing to script a lot yourself
and so artifactory just smooth this the
path first so you know nexus on the
other hand we use it because it
basically manages repositories it's
really easy to create dynamic like an a
new repositories since we're going to
create a bunch of them it's very good
for us and it also has some enterprise-e
features around it ok so that's it
that's that's all the philosophy I took
about 15 minutes a little bit probably
more and could be but let's let's not
start with building the actual pipeline
so now it's the rest the rest of the 45
minutes is one big demo and the pipeline
we're going to build we will build
another partial pipeline with forced
main stages but these four stages will
actually show almost everything you need
to build a bigger pipeline so one thing
that is missing here is staging you know
they typically have besides just in QA
you also have a kind of this exact
replica of a production environment
which is new new replica of a production
environment which is staging and I guess
you know you can have a lot more other
stages as well so with the environment
we have looks something like that we
have Jenkins which connects to Nexus and
library Bell so library Bell manages
three Tomcats one of them is one of them
is for testing deployments and two of
them are for production deployment
behind they are actually behind an
apache load balancer and we have also
three registers which back
the three Tomcats actually I think I'm
wrong there's two registers yeah did I
used to have because I used to have also
staging guys to have four Tomcats but I
dropped one Tomcat so actually I dropped
one Redis as well so one one radius
backs the testing and one readies backs
the production and and the application
we're actually going to deploy it's a
it's kind of a it's a chat it's a chat
application it's very nice because you
can I say show demonstrate their failure
and downtime you know because it has a
very nice user facing is it distributed
it's so you get all this all this nice
features and it actually has some state
so you get it's very good for such
demonstrations of course it's somewhat
simple so you know so I also try to give
some anecdotal stories meanwhile how how
things happen on the big apps right so
first of all so let's start with a build
stage so in the build stage we're going
to do very not nothing much that we're
gonna build the artifact we're going to
upload it to the build repository so
very very simple so now let's go to the
actual things so I have everything
running in the cloud environment and so
this is so this is Jenkins and this is
actually you know it actually contains
the pipeline that we want to build I'm
going to first build part of it and then
we're gonna review the key aspects of
the rest because building the whole
Python actually took me three weeks so
well I guess rebuilding it from scratch
now wouldn't take three weeks because I
just had to solve so much issues while I
was building it but you know but we
don't want it still one hour is not
really enough to go through apps to
build absolutely everything from scratch
so a cool thing in Jenkins is Jenkin has
this thing called build pipeline view
it's a plugin and it actually allows you
to see the whole pipeline like in an
overview and unfortunately for some
reason okay so it's here we go so so
it's so it's a little bit longer we have
you know we have a lot of steps but I
like to have it for you because for
example previously you know I try to
build something and it actually failed
and I see that it failed in the third
step right and that's very nice so it's
it's it's a very useful plugin for
continuous delivery even though I later
show that we actually
kind of quaint use it can't quite use it
that's well one of the biggest issues
with Jenkins is that it has a lot of
plugins they're all awesome but they all
don't work with each other very well so
so you know some plugins but but they
provides it provides an or view at least
like you know what you have if not
necessarily it provides an overview and
like what you know what are you gonna
how it's gonna run so second tool we use
is library boom so library bill is
actually manages applications manages
servers so I can show here that we have
this three servers one test and two
production like chest has for example
right now two applications deployed and
production has one application deployed
and you know in application centric view
we can basically look at the
applications so actually I don't need
those application so I'm gonna delete
them but so I'm just gonna undeploy
those the test ones because this was
just the previous builds got left behind
so and is there okay so now we have only
one application which is production you
know the one thing that fiber bolt does
pretty easily you know it's just a very
distance tradition but we can you know
we right now have version be 170 the
latest is actually 172 so we can just go
and you know this is all kinda this
trademark technology hook patching which
we use in general which is library
library but it's used in a very
different way then it's used in durable
which means that it's hundred percent
safe for production like we very hey
like this up greetings get that all
fetching actually means that we verified
that you know that the changes here are
all compatible to apply the hot patch
and so I can just press update yeah
production is updated now so that's that
that's that's why I say that it's really
easy to do no doubt some updates
you know I challenge you to find a tool
which lets you do it so easily but let's
let's update it back I don't actually
care right now about that I'm fine with
Fanning 170
or even whatever so I'll just bring it
back all servers again update it and
then the last two we use a sauna type
Nexus and so this is actually where we
start so the thing we do with Sona type
is that we create the four repositories
and I'm sorry that the font is a little
bit small but basically great for
repository repositories which correspond
to the four stages of continued of our
pipeline so one repository for each
stage and the repositories will actually
so one of the issues with Jenkins is
that it's really hard to model wrong
long-running jobs and jenkins and it's
actually but you know using Jenkins to
store distribute artifacts is generally
not a great idea but but on top of that
just if we want to have long-running
jobs like for example on manual QA then
it's really hard to model that purely in
Jenkins and this is where repositories
will help us very nicely so you'll see
how I use them and I think it's it's a
very it's it's you know this is where
there's having one repository first
stage okay it's gonna play it right into
that alright so and here's also we have
a passionate load balancer each extra
shows that we have to Tomcats behind it
so okay so let's go back to Jenkins and
so just as a reminder the creating at
first to create the build job which
builds the artifacts and poles is to
build your posit ring so I'm doing your
job call and get built to and I think I
just want to freestyle okay so first
thing we want to check out the source
code in our case so I have somewhere so
in our case it's a local repository it
could be remote it could be anywhere
I'm just using local because I'm going
to be updating it and it's just much
easier for me if it's local it's not a
lot easier actually but I just need a
temp repository somewhere publicly we
just think why because I'm making either
changes there okay so we do the check
out
then we do the invoke top level maven
target
so for maven we're basically doing an
install and we've pass on so we pass on
the build number and this is exactly as
I said that you know instead of
producing a snapshot the version that is
produced by the main and built it's just
you know the version numbers this could
be and the build number right so build
number is an environment variable of
Jenkins which is going to be expanded to
the actual number of this build so so
basically in Jenkins Jenkins like sets
environment variables for you just usual
kind of this you know bash style
environment variables and there's if you
just search for Jenkins environment
variables are going to find a list of
them and then in any script you can use
them all right so build build numbers of
standard environment variable which
expands to the the actual number of the
builds right so starting from 1 to
infinity yes so the way the way I do
here is that I pass on like minus D is
this property and then basically that
property in maven you know is undefined
and but in the version in the project
version I use that property right so
that property's actually expanded to
this expression yeah inside the point
file and and so then the interesting
thing is I did that originally and the
way I later structured the build it's
not even that necessary anymore but but
that's you know that's one way that's
certainly one way to do that if you want
to be consistent and and so the next
thing okay so the next time I'm creating
a text file so let's see so remember oh
I don't even want maven that one just
last time I wasn't actually doing that
you later but remember I said that that
one of the philosophies of of continuous
delivery is that we record everything
and there's all kind of fancy ways to
record it but I found that one way to do
that is just to produce a simple text
file where you dump kind of the most
important steps you're doing and the
most important you know descriptions
about what to you about what what are
you doing and you attach it like through
the whole pipe or you can thread it
the whole pipeline and attach it all the
way to production right so that so that
for every application that you have
deploy verification at every step they
actually can you know if something fails
you can go back and find out like what
was it built from like what exactly the
version what happened to it like what
was you know what what just failed what
chest didn't fail so and that's why you
know and and using a text file it's
actually very very easy to do that it
doesn't go inside the artifact so the
problem is that you can like the reason
why you cannot put it inside the
artifact is that it's going to keep
changing right we're gonna keep adding
to it to the to the actual text file
right because it's going to go through
many steps but we don't want to change
the artifact now we build the artifact
in the first step and that's it whenever
you know the artifact never changes from
that moment it is a second artifact yeah
so I'll show you but basically we're
going to to deploy it with there well
that's the next thing actually so so if
we so the next I don't know here it's so
if you look here we're doing this deploy
file right we're saying which repository
to deploy to and we're going to the
build repository so the CD is it's only
for password basically it's not relevant
so the file is this built artifact and
then we also attach the build text the
build text and we basically say that the
classifier is the build notes right and
and I think there's also should be some
what type but and then it goes all this
man and here I said that the previous
one was almost your level irrelevant
because again would give the version
here the only reason why we why it's you
reasonable to give to put the version
inside actual pom.xml is if you have
something in the build you know which
like if you display for example some or
the version in your application then
it's reasonable chose a passage a poem
XML because everything else we can do
here Oh somewhere I think there was ill
denotes a kind of feel that there was
supposed to be a minus G type so it's
funny that I can find it oh there it is
okay I just I just missed it yeah so
type so type is text classifiers build
notes and it's going to attach like the
way maven does it it you know we were
going to run it in a second actually so
there's no need to okay so we have the
built and it's actually complete so
let's just run it it should run very
quickly and let's see what happened what
what the artifact will look like so it's
a completely new artifact one one thing
I am worried about is that actually it's
probably gonna fail see ya it failed and
the reason why it failed is because we
already have an architect beat v1 so it
maybe you cannot upload the artifact
twice so what actually should do is I
here I should rename it to something
else so because I was already used a and
I think I'll you see now so so just you
see then everything should be fine
let's try again
um I think I think there is I think you
can define variables and Jenkins well
but I mean one of the for me one of the
biggest issues with Jenkins is kind of
this lack of first class things right so
you cannot define a function like
everything is copy base table and this
is there's a pain in the ass actually
maintaining Jenkins like basically the
best solution like I was talking to guys
and Netflix and the best solution to
people has come up with is that they
have a DSL for generating Jenkins jobs
right so they generate them on disk and
but this is like you know debugging that
is horrible right so it's it's that's
that's why I said the Jenkins you know
it's kind of the best we have but it's
not great yeah okay so we build the
thing it succeeded and if we go to the
repository to the build depository
refresh it
then we should nicely have and I don't
know why Nexus your system using this so
see - here's the artifact right so
here's the war here's the descriptor and
here's the build notes right here and if
we download them then you know like we
see that here's the change set here's a
Jenkins job that built it you know and
here's the log right so we already have
well at least know where to start
searching like what what what you know
what what patch created this and we can
track it right back to where it came
from
okay so build now let's let's add two
more jobs and those two jobs will deploy
a chest environment and then we'll run a
test against it and you know once we
finish with those who actually will
review the rest of them so now we're
gonna build the test page there will be
two jobs one of them is going to
download the build artifact and create
the new test deployment and the other
one was going to run acceptance test and
then upload the test artifact so nothing
terribly complicated but still pretty
hairy at places so let's just create one
more job which is the deploy chest to
testing just not again a freestyle so
and what we want to do is first download
so first download the previous artifact
so interestingly I interestingly enough
for download or for deploy you know I
so for deploy I could use just deploy
deploy file for download when I don't do
this a whole expansion of the maven you
know this scanner plugin thing it just
fails and I'd understand why maybe get
it somehow different we define the
deploy but it was one of those things
which just fail and III don't care
enough to start figuring out why it's
easier to just expand it so and so get
hmm oh thank you very nice so let's put
the c-4 good number and not notice that
the notice that the not name is now
different it's a build number its source
build number and the reason is that we
don't want to use the like Jenkins has a
separate build number for every job but
what we actually want to use is the
build number of the original job so
we're gonna actually thread it through
all the jobs which is a pain in the ass
but with Jenkins because you you know
like again like I haven't figure out how
to define like a global something for
the whole burbling and you're like
you'll see why it's it's pretty hard
because some of the parts manual and
that's kind of a tough so this source
build number the one the build job
finishes you know when it's triggers the
next rope it's gonna pass it along and
so so when we put the jobs together I'll
show how to do that so this is again so
the cool part about dependency get is
that starting I think from maven 2.1 or
something pretty recently it has this -
detest where you can actually download
the artifact where you want it to be
before it was before it actually was
very very hard to do that right but now
you can just download it here so that's
pretty easy and and we also will
download the Builder text so it's also
here
and now we'll just use library Bell
sorry right you are my friend that's
very good I love it when my audience
debugs for me awesome
yeah here it was yes okay and you know
and we'll use hyperbole to manage our
chess environment as well
so I'll just use a Jenkins job we'll use
the same our demo wor here we go
I will provide our own version Inc so
cool think about like I said like live
herbal also supports this associating
metadata with something so it's actually
going to be visible in libel when you
click like all the logs will be there
and but what we want actually is we want
so again I'm gonna change it to C but
the point is that we want to deploy a
separate application because we want to
have you know in test we want one
deployment per version because we might
have many version parallely tested right
it's not like it's not like production
we have one version at the time but it's
exactly we have a new environment for
each for each build so which you're
going to just use the application name
for that and also the context path so
which each is going to get a unique
context path and unique name yes it's
faster because that's going to be a
bottleneck
you have no guarantee like so if this is
true like a it's actually not true even
in production but for release candidate
candidates typically you will go with
the last you know release candidate that
passed the pipeline while they pass that
pipeline says you don't you like each
each part of the Pythons the bottom leg
and you don't actually know which
releases will succeed and which will
fail so you want to you know you usually
want to run as many parallels you want
especially if you have manual testing
which I'll show next so you know well
okay so okay so it's your ship okay so
here's you know another another thing
you could okay you could do that you
could just throw ttle the build so that
you would have one build at the time
running and you just you know but it's
just gonna like if it if it works for
you that's fine I don't mind that but
typically it will just put on like
they're like you know typically can test
a lot more if you have parallel
deployments and you know that's that's
typically it's better so for update
which is going to use the offline
register update or it's actually it's
gonna automatically hot patch if
everything is compatible and then fall
back to offline update because we don't
have I can actually hear it here there's
no update sorry what I was thinking
here's just we deploy a new application
then we just clean it up at some point
so don't listen to me and we're gonna
deploy to the test server so so that's
that's pretty easy save it and now we
also add a test so that's the last job
we're gonna go through in detail
automatic test to again a freestyle so
and automatic tests actually should
create now a test but txt so there
there's a good reason why I'm calling
them differently so okay so let's start
start by downloading the previous one
actually download the previous log
and then we and then we basically you
know this is a placeholder for real
tests I'm just using W get so I'm just
using W getting against a specific place
and you know oh the previous I forgot
okay so so yeah so there is my scope
text ik tested text is that actually on
every stage we need to according to
rename the Maven classifier because
otherwise I first gave the same name
like this build notes to everything but
it turns out that when you download it
to the local repository they're going to
collide and then you're going to have
real weird problems so actually for
every stage the classifier has to be
different so but anyway we just do it W
get and if it passes then we write
automated test pass and if that path and
if it's all good then we just upload
upload the artifact to the next
repository so again I'll change B to C
so the next repository is actually
confused
this is to get so we download yes we
first downloaded this is the curse like
that we didn't have a promote we have to
download and then we have to upload so
and then we actually upload it to the
new repository so this one actually look
here first of all like I said
classifiers test notes down on build
nuts
so classifier changed and also the
repository is now just so so just
repository along with the test notes and
the artifact alright so that's it okay
so now let's connect those three jobs we
have 3ds join jobs and the way you
connect them is that basically so there
are two ways to connect them one is that
you in the
next job you set up that it's triggered
when the previous one is finished and
there are other ways that you know you
can imperatively in the end of the first
job trigger the next one so impenetrably
is better if you want to pass parameters
around because the otherwise the other
job cannot grab the parameters anyhow so
I want to basically say is that we
trigger parameterize build the next
project one of the nice things and I say
nice without you know with a lot of
sarcasm and Jenkins is that it all the
time confuses the worst jobs and
projects sometimes their projects and
sometimes their jobs and for me it's
like very very different things and we
just add this source build build number
number right so okay so and for the next
one section now easier so for deploy
test you we don't anymore have to add
parameters because deploy test you we
can actually just say trigger parameter
is built and just use the current yield
parameters this that's is that is nice
alright safe and now finally we can also
add a new view which is the built by
pond you call it true and we say that
the first so you just specify the first
job which is bill two and then it
basically finds everything else it finds
this triggers and so it looks like this
alright so that took a lot of time has
everything with Jenkins does but we have
a pipeline so let's build something so
that's going to take a few
and you know and this basically no
there's three things building a small
pipeline can I give you the main idea
how to give the bigger one but we're
going to stop on the few key things like
how to do manual so how to make me one
more main thing I want to stop is how to
do how to incorporate many large
activities like for example QA
production deployment into this pipeline
this is a very interesting problem and I
think you know we I think I found a way
how to do it fairly nicely so this
actually the automatic tests actually
right now should fail because I have the
version that should be failing just so
that we could check that our pipeline is
actually doing anything and I just wish
that with Jenkins well one of the
reasons I guess is that it's also in the
cloud cloud is not super Amazon Cloud is
not known for being super fast
especially if you doing anything with
i/o so let's look at this so let's just
check how things worked so it failed it
failed with an arrow 500 and if you look
at line rebel then actually like this
new version has been deployed right so
and that is and we can even look at the
place where it's deployed I think and
here's the meta data as well so all the
major data went to the build and let's
just try to get a no this will work but
if I copy the link address and then
yeah I didn't even show the chat
application you know it's it's not
horribly relevant but the important part
is that there's no smile is in the chat
because the last part of the demo would
be actually that will update production
and add Smiley's it's a huge feature
they're important lots of state anyway
so not now we have actually yeah so the
word that the test version is deployed
so I'll build but I build isn't passing
so now so now I'm going to the wrong
place actually so now I'm going to the
right place to the repository looking at
the log just named very badly but let's
look at this is something
yes oh okay no that's right strange
okay no I'll just set it in manually
oh yeah with D if I have to specify two
versions keep forgetting that like - her
and you have to specify the two versions
otherwise it just gives you pretty much
that diff from the current one so that's
not not what I want but okay right now I
just want this sir
the change the change I made is
basically oh sorry that's so that's
mercurial that's that's basically get
get escaped and timir coriolis hg so
it's you know so I guess we end I'm just
checking in a change so that so that I
could use so basically so my chest could
pass okay so I'm gonna run the built and
because I don't want to waste a lot of
time on that so it should pass now
meanwhile we can go into the rest of
stuff so okay so we did build with it
test we have a test artifact now in the
repository everything is good so far so
next is QA and QA we're gonna do in a
nice way that we actually incorporate
manual QA and the way we're going to do
is they're going to send an email which
can change the environment and can
change the link which gray will click
which will actually say that the test is
successful and you know and
theoretically also can change the link
which says that just failed but actually
hasn't done that thing but it's really
really easy to do it so let's see how
how do we do that
it turns out that it's not terribly
complex so so if you you know if we look
back at the full demo pipeline they'd
have to build your test an automatic
test the next job is begin QA let's look
at that so begin QA
first of all downloads again the wrongly
named bill txt here but doesn't matter
it's just a file name but the point it
downloads it from the test it downloads
the test notes from the chests
repository and after that basically we
send an email so the email goes to you
know basically should be a QA list or
issue tracker or something which can
handle an email and it just says that
will be
in ink ua4 version this so here's a nice
nice okay this actually is beep so
here's a nice thing in Jenkins that the
way to say specified environment
variable in the email plug-in which is
called it's actually called email xed
the plugin that allows you to do that
but the way to expand environment
variables is completely different from
everywhere else after you of course
there's no documentation so you know it
took me quite a few hours to find that
and you have to say this M and then BA
recall source build number but once
you've found a doubt that works so and
what you want to send is like a link to
the environment right we just say k that
this is the application you need to test
and as you know remember we deployed in
unique environments for every build so
here's where it's come here much in
handy and the second thing would you is
that we send this we send this another
link which says that please Jess its own
thoroughly and if successful click on
this link and the link actually goes
back to Jenkins and does this think you
a success build with parameters so here
there's a very cool feature in Jenkins
which are really much light which is
like one of the one of the coolest
things there is is that if you want to
if you want to script something in
Jenkins all you have to do is that the
word API in the end and it takes you to
a page you know where there's API
specific to this place right so this IP
is specific to the QA success job and
you know there's XML JSON Python but
also if you just want to if you just
want to perform a build then you can
just post to this URL and if the build
has parameters you post to that URL
right so all we have to do is post to
that URL and we can also add any
parameters we want and you know and
that's what we're doing but basically
saying that here was saying the QA
success and start the build and for this
source build number right so we pass
along the build number and what the QA
success will do is actually it's does
very little it basically promotes
promotes the build further right and the
only the only caveat here is that for QA
success were like for any job that
access accepts this link build with
parameters API you have to define this
check
that this field is parametrized and if
you don't nothing will work so for every
we fold the triggers it will work
without it but if you use the API you
have to do that that's just you know
niceness that's one of those nice things
Jenkins just for you that everything is
done differently so okay so this as I
said this doesn't do anything really
it just downloads the QA and says that
manual tests have passed because we
assume that the guys you know if we if
we want to do it cooler we actually can
do a very small web application you know
kind of like and we instead of sending
an email we can do a rest post to that
application you know on this application
for example the adjusters can can also
add commands and for example add issues
you know which were created from this
right and then then we have more
information in the log we can put that
all back in the log so there's you know
it's very very this kind of it's easy to
do this kind integration because we have
the repository which holds the artifact
and we just need to pass on the build
number and we can just continue on so
that's that's why I said that the
repository gana is this long-running
sync point so we have lime herbal and
positive which which do you do this
long-running sync points Jenkins itself
is not very good at that all right and
then we basically also get there so and
then we basically deploy artifact to the
next repository again this is QA notes
now not just on build notes and the
repository is also QA so we passed the
bill temp we record that nice and next
lecture on clean up test which doesn't
do anything terribly smart
it basically deletes deletes this
environments which we created previously
so one thing this pipeline should
doesn't do and I keep forgetting about
that keep forgetting to add it as well
as we actually need another link in the
QA either another link or we need an
automated job which runs and get Co
cleans up those environments after three
you know after a few some time has
passed otherwise you just keep
accumulating them so but you know
deleting an environment with library
ball well the Jenkins plugin doesn't
support that but there is a command line
which is very easy to use and which I'm
basically you know saying here using
here so so it's it's a very short job it
just has one shell which
it's the environment all right the next
the final interesting job is begin
deploy production and I know that we're
slowly running out of time here
so begin diploid production basically
works similar way that for every for
every build that made it so far we want
to send an email or post a rest or
something and basically you know or even
you know you can even have a big red
physical button you know which just
basically does the last release but but
basically this this says this here I
just send an email and again just say
that you know here's the link you should
click but it can also be a rest post it
can also be whatever as long as
basically escaping Jenkins now and now
we're waiting for manual input right the
manual input is very easy from the point
that for you is just again its rest rest
call back into Jenkins or you can even
directed your rest colon to library
below a scripting call so and then you
can script engine Jenkins as well
so either way it's easy and and oh by
the way one thing I didn't show is that
for QA and for RC as well the in the
SEMA will also include his attachment
the whole log and this is again for
example in QA you know you want the guys
to find who do they blame right who do
they assign issues for and it makes it
really easy because all the log is with
it right and same for production you
want to if there is you know if you want
to ask somebody about it there it's
really easy to do so alright and so
that's that's pretty much it the last
thing is deploy production it's the last
job so
and it basically downloads things now
from the QA uploads things to RC so
there's nothing to be interesting and
the last thing this Genesis uses library
ball and actually you know so deploys a
new version of the build and this
happens only if somebody actually clicks
on the link and so it will again it will
do compatibility check and use hot
patching if it's compatible or fallback
like in this case to rolling restart
which is basically this automatically
rolling restart with a session drain and
library ball handles it automatically
because it can occur it creates its own
load balancing for the time of the
update so that you don't have to worry
about anything like that
anyway so now let's finish up here I'm
just gonna start the build so actually
I'm just good at it emotion can't start
to build and then we'll finish the talk
so I think it was very confused but I
think
is it me as they're all the same
damaging something very wrong no I I
wonder to add I want them to add more
emoticons array
okay eleven actually I can do them back
I wrote it to mush consists yeah okay so
we have all the gifts married it alright
alright so just open production
this is the last demo and also finish
graphics so right now there's no motion
dance I'm going to start the belt it
should also spend me meanwhile so
actually I should open like no no
there's nothing to bed there and
meanwhile let's finish ok so we build
the QA incorporated all the manual stuff
we build the production also
incorporated all the manual stuff and
the idea in continuous delivery is I
actually the business guys decide you
know when deployment happens which in
reality I don't I still don't really
understand what it means like because
business guys can mean very you know but
but basically the guys who you know it's
the guys who know how much we win from
the feature the point is that you know
developers they don't care about go to
market so much as they should maybe but
it's basically the guy who cares that
this feature goes true actually you know
gets somehow gets the benefit from this
feature go into production right so he
should be making the decision that
actually goes to production so he should
be taking the responsibility in reality
you know again I'm pragmatic so just as
long as it happens is good things that
we didn't cover is database
configuration environment and test and
more returning each three of them you
know that we could do a talk about
change 3 they're fairly complicated
I'll see if I got an email so now if we
go back to the questions we asked in the
beginning you know we have an answer to
absolute each and every once we have
this predictable pipeline where things
are packaged tested and deployed in a in
a repeatable way right so and we try to
you know we try to have the survival of
the fittest where if a patch is good
then it actually goes all the way to
production and if it's bad then you know
then it stopped early on so we have this
we have this quality released candidates
accumulating so if we took talk about
conclusions then you know Jenkins
basically creates the workflow things to
remember Nexus is your sink point for
long-running process and also your
validation point so that you are sure
that you didn't you know
make mistakes because if trying to
download the artifact and in the
previous step didn't succeed and there's
no artifact right if you want manual
flows they're pretty easy to script with
either email rest or whatever you want
tracking on the basic level can be very
nicely done with just scripting and text
files and if you want no downtime
updates in a very easy way then you can
do that with library ball well yeah I
mean we're out of time so thank you very
much for attending and you know have fun
with the conference</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>