<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Service-Oriented Development | Coder Coacher - Coaching Coders</title><meta content="Service-Oriented Development - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Service-Oriented Development</b></h2><h5 class="post__date">2018-02-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/87KzAGheaVU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">today I'm gonna talk not just about
micro-services but I'm gonna tell the
story of how we actually came to start
thinking of micro services as service
oriented development and I'm going to
talk about why we think this is one of
the most effective perspectives to
approach micro services from and I'm
also going to cover how to start
building your own platform for doing
service-oriented development in an
incremental way but first a quick poll
so show of hands how many of you have
asked these sorts of questions about
micro services things like how do I
break up my monolith what do I you know
how do I protect my app with micro
services and what kind of infrastructure
do I need in place before I can benefit
from micro services all right good
number so these were the exact same
questions we had when we started out and
we kind of learned the hard way that
these really aren't the right questions
to ask to start with so what is the
right question I'm gonna get to that but
first I'm gonna start with a little bit
of our early history and some of the
painful lessons that helped us helped us
figure out what the right question is
because I think this will give you guys
the context to appreciate what I'm going
to talk about so we were founded in 2013
and my co-founder and I we were you know
both tool builders by nature so we
wanted to help people build things
people were building distributed systems
I had a strong distributed systems
background and micro services was the
way people were building things and so
it pretty naturally turned into a
company that wanted to help people with
micro services of course we had a lot to
learn at the start and so we delve in
and we started out primarily with a sort
of a technology first perspective and we
tried to learn by speaking to all the
big guys that were doing micro services
so we talked to folks at Netflix Twitter
Yelp Google Facebook and a bunch of
other companies we talked to the
engineers on the platform teams and we
pretty much you know tried to reverse
engineer their technology stack and how
they were using
and pretty much this picture of an
emergent architecture for microservices
emerged right this control plane and
smart endpoints and the control plane
was sort of always the same set of
backbone services things like discovery
logging tracing and metrics and the
smart endpoints were all about providing
resilience all the resilient semantics
you need for layer seven network
stability things like timeouts rate
limiting and circuit breakers and a
whole bunch more so we took a look at
this and we said alright that's a lot of
tech to build just to get started with
micro services so we can help people by
building this off for them and so that's
what we did we set out to build a
control plane as a service we use micro
services ourselves because it seemed
like a pretty natural fit the control
plane was already split up into a suite
of separate services and so you know why
not so and things weren't great at first
right it was pretty fast to start out
with and then we launched and things
started slowing down so we took a step
back and scratched her head for a little
bit and try to figure out why were
things starting to move too slow and
well you know it's as is always the case
with this sort of thing when you're in
the middle of things it's not
necessarily super obvious there's a lot
of possible reasons you think of and so
we took a look at a couple of different
things right we took a look at the
technology we were using I think we went
through I don't know maybe five or six
different deployment systems we took a
look at our architecture and you know we
said okay maybe we didn't decompose this
control plane into the right set of
services so you know we we tried a
couple of things there reaching at that
a bit and that neither of those things
need seemed to make that much difference
and so finally after going through a
bunch of releases and sort of looking
back and carefully asking the right
questions we figured out what was
slowing us down it turned out that every
feature we every feature we released
required carefully coordinating the
efforts of multiple different people and
some of this and these people weren't
sort of naturally
inclined to communicate on their own and
so some of the some of this was for bad
reasons and we fixed those and that
actually made the biggest the biggest
improvement in our velocity but some of
this was actually for very good reasons
right we didn't want to break our users
and so we were releasing things the
process we had for releasing things was
deliberately more careful so in the end
it wasn't our technology or our
architecture that was slowing us down
it was our process now at the same time
something else was going slow and that
was something that was actually a lot
more concerning our pipeline we it was a
big pipeline we were talking to about 30
or 40 different companies and they
really liked us a lot they kept you know
they were all going through migrating
microservices at one stage or another
and they kept coming back to talk to us
because we had a lot of useful
information for them but a lot of them
were moving slow and because we talked
to them frequently enough we were able
to kind of track their progress and
start to put together a picture of what
was happening and we started to notice a
pattern it seemed like the slow movers
fell into two camps there are a bunch of
companies who are being very very
careful and deliberate about baking off
all the different technology
alternatives it and it seemed it seemed
that they thought the benefit of
microservices sort of somehow came from
picking exactly the right technology
stack and then there was this other
category of companies that were
approaching it from a much more
architectural perspective and they were
trying to figure out exactly the right
set of services to decompose their
monolith into and this was this meant
they were taking a while and then we
also talked to all the fast movers and
we finally had a brilliant idea to ask
them to tell us their story tell us
about your first service tell us how you
actually did this and with the fast
movers we got a we got a whole host of
different answers but you know we talked
to one company
that had a rails monolith and they had
some kind of file upload functionality
and occasionally and occasionally some
user would upload a multi gigabyte file
it would take down the monolith and the
whole application would go down and so
they had to fix this
pretty urgently they decided it was I
would take too long to fix within the
context of their monolith and a file
upload endpoint is a really simple
service to write so they just wrote it
outside the monolith and were able to
deliver it really quickly there was
another company that wanted to adopt
modern CI CD tooling and they decided
that it would take way way way too long
to retrofit their monolith and they just
decided to start implementing new
functionality outside their moneth and
adopt the new tooling as they went and
there was another company that had a
bunch of personal private information
and they wanted to minimize the scope of
the audit process that's required for
code that has access to that sort of
thing and so they they isolated and
contained those and services that were
as small as possible and so the common
theme seemed to be that all of these
companies had an urgent need that could
not be addressed quickly enough in the
context of their existing process and so
we kind of put two and two together with
our own experiences and decided that
okay velocity actually comes from
process not architecture and this kind
of makes sense if you if you sort of
take a step back and think about it
right we're all familiar with the the
classic Deathstar architecture diagrams
of thousands of services that come out
of successful micro service companies
and if you think about it you don't
stand in front of a whiteboard and
design that kind of Death Star that's
not how you get there you get there by
enabling a different way of working that
as a by-product makes it way faster and
easier to turn out the hundreds of
services you need to get to that point
and this is when we ditched the whole
idea of service oriented architecture
fine-grain or otherwise and started
thinking about service oriented
development and to understand this it
really helps to recognize two things
that dramatically impact the way we work
so first of all in software stability
versus velocity is a fundamental
trade-off the faster you go the more
things break and this is why things
slowed down for us after we launched
when we were prototyping we could break
whatever we wanted whenever we wanted
and the second we had users we adopted a
whole bunch of practices which slowed us
down and for a good reason and if you
have a lot of users that rely on you or
even just a few that rely on you for
something really really important
you really the more careful you need to
be and the slower you can move and what
that means is that if you're trying to
quickly add features while maintaining
stability there is no Goldilocks point
on this curve for you a single process
is inefficient because it forces a
single single stability versus velocity
trade off and there's another important
factor to recognize the development
process involves a bunch of distinct
activities that I'm sure you're all
familiar with and something that can be
harder to notice when you're small is
that you can really only do one of the
activities in this process at a time yet
when organizations try to scale they
seem to do this by building specialized
teams associated with some of some or
all of these activities and as an
organization like this grows this turns
into some combination of dramatic
underutilization and departments
fighting each other right if velocity is
your top priority then operations will
get frustrated with developers for
breaking things all the time and if
stability is a priority then operations
will ultimately end up putting processes
in place that slow down development and
when development slows production
management or
product management gets frustrated and
if your leadership doesn't understand
this then they can end up setting up a
combination of goals and an org
structure that literally pits an
organization against itself and what
this means is a single process does not
scale with your organization and this is
why instead of asking how to break up a
monolith we like to ask how do I break
up my process and this is the question
to ask if you want to go faster and this
is the perspective to approach
micro-services from because
micro-services lets you have as many
different processes as you like with
micro-services you can set up a
distributed work development workflow
and that lets you customize the
processes that each service uses and
when you do this that's how you can move
fast and keep things stable and get
benefits almost immediately multiple
simultaneous workflows including your
existing monolith all tuned for that
ideal stability versus velocity trade
off so this sounds great right so how do
you actually get started well starting
from the right principles makes this a
lot easier but it's the it's still a
huge shift in how people operate and
this requires both organizational and
technical changes and so I'm going to
cover some of the ways you can make this
easier on both fronts starting first
with the organizational side of things
first of all you've got to give in order
to get on this front you need a big
emphasis on education communication and
delegation if you look at the picture on
the right you can see why on each of our
small teams all of our former
specialists are exposed to every aspect
of the development cycle and so there's
a big learning curve and also because
they're all specialists nobody speaks
the same language so communication can
be a challenge and with this model you
end up delegating much bigger parts of
your business to much smaller teams and
this is sort of the point
but it can also be very scary but when
you do this when you do this right you
actually get a lot education with
education you're specialists become
generalists and this leads to better
holistic systems with learning comes
personal growth and job satisfaction and
with communication that conflict that
was there before with between
departments fighting each other that
turns into collaboration and with
delegation you can achieve massive
organizational scale and the benefits
when this is done well they're hard to
overstate I once spoke to an engineer at
an e-commerce company and he told me
some remarkable things about the impact
of the latency of recommendations on
customer conversion ecommerce sites live
and die by their conversion rates and
common wisdom is that product
recommendations increase conversions but
this guy knew that if your
recommendations increase the page
latency beyond a certain threshold then
the human at the other end gets
frustrated in your conversion rate drops
off and if you think about this it
really demonstrates a remarkable breadth
of knowledge across many aspects of both
the business and the technology behind
it so what's the best way to go about
doing this
well we want to start by creating
self-sufficient autonomous software
teams and why self-sufficiency and
autonomy if you have to work directly
with other teams to get stuff done their
process is interjected into yours and if
you have autonomy you can choose the
best process to meet your goals so to
get there there's two things to be aware
of first you need to be aware of
centralized specialist functions and try
to eliminate these no centralized
architecture team and no centralized
Operations team and don't get confused
between a platform team that provides
the platform as a service and a
centralized ops team that's responsible
for keeping all the services running
these are two very very different things
even though on an org chart they can
look very similar second thing is to
think of your teams like their own
little spin-off companies you probably
already consume external services things
like start
Twilio well your new microservices team
think of them just like another one of
these and pick a real urgent business
problem that you wish you could buy
instead of build and then form an
internal spin-off to build it this ups
up the right mindset for a lot of things
it helps you think from a process
perspective it helps you define the
service because you're thinking mission
statement you know who is the user and
what are you trying to help them do and
this is a way more effective way of
defining services than big upfront
design and it helps with communication
because you're establishing a customer
versus a co-worker relationship and it
helps you form the right team because
with us with spin-off you need a mix of
skills you can't just put a bunch of
developers on a team alone and expect
them to succeed you need people with
more product oriented skills who can
understand the user figure out how to
help them and translate that into
actionable engineering tasks and you
need people who can code and you need
people who can keep the service running
and you can even do all this with no
fancy tooling or technology at all but
it's a lot easier and more efficient if
you give them an awesome suite of
service oriented development tools and
that brings us to the technical
implementation so while it's really a
spectrum of stability versus velocity
trade-offs I'm going to break this up
into three different stages early on is
what I call the prototyping stage and in
this stage the goal of your tooling is
to give you really fast feedback from
both prospective users and the tools we
are rely on things like compilers and
stage two is really about balancing
production balancing production concerns
users and growth and the goal of this
stage is adding features without
disrupting users and then there's a
third stage and that's the mission
critical stage where the primary goal is
stability so we've all we've all worked
on stuff in all of these stages there's
there's you know sets of tools that you
can use to do all of this stuff so this
should be pretty easy right for rapid
prototyping we can just build something
in rails on our laptop for a growing
user base we can just stick it in Heroku
and for mission-critical stuff will
probably just eventually rewrite it and
go and move it over to a real cloud so
what's the problem with this
well we're Reap lat forming at every
single step and that's a whole lot of
work so what we actually need is one
platform that can support parallel
development at different stages with
seamless transitions between stages and
this is a whole lot harder the good news
is that kubernetes docker and Envoy give
you the foundational technology to do a
lot of this stuff and just in case not
everyone's a kubernetes expert and in
case people haven't heard of on board
I'm going to cover a little bit about
them so kubernetes
even think of it as infrastructure as
declarative configuration it's kind of
like a thermostat you tell it the
desired state of your infrastructure it
measures the actual state of the world
and it tries it's best to make you happy
and it provides a powerful apply
primitive to update the desired state of
your infrastructure to something new and
when you do this it will safely
transition from its current state to
that new state and it's fast at doing
all this and this combination is
powerful let's me treat my
infrastructure like source code I can
check it in to get dip it patch it and
this really fits the way I already work
in a lot of ways envoy you can think of
it as a powerful l7 Network proxy it's
out for L saw them but we really care
about it for the l7 capabilities and it
provides a huge toolkit of l7 routing
and resilience behaviors along with
great observability and things like
dynamic reconfigurability and xeric
connection loss hot restart and there's
a good reason to pay attention to both
of these projects because lots of really
smart people collaborate on these to
solve some really hard problems
the bad news is that you actually need
to wire all these together into your dev
tooling the right way in order to get
any benefit and this can be hard these
technologies are all super general and
they solve all of the hard problems are
gonna run into and a whole lot more that
you aren't and they're definitely worth
learning but learning them all up front
and then playing around with all the
different options for wiring them
together that can actually take a while
so the rest of what I'm going to talk
about is really the key strategies that
can help you get started with this
incrementally and you might see a
shameless plug here and there where we
have a tool that might fit into this
picture but I'll try to keep that to a
minimum so how do I actually use these
technologies to build tooling for my
workflows well if you remember we want
fast feedback from our tools as well as
our users and to reach users we need to
run on production infrastructure and
operations doesn't always like letting
developers mess with production so you
need to get buy-in from all parties for
an acceptable way to do this second
micro-services very quickly grow to many
remote dependencies to run locally and
not being able to run code locally
really slows down the feedback from all
the tools you're used to depending on so
excuse me we have two strategies for
dealing with this one is you need to
build some kind of self-service
provisioning and two is development
containers so the combination of
declarative infrastructure from
kubernetes and the dynamically
reconfigure bill edge proxy or Envoy
deployed as a dynamically reconfigurable
edge proxy is a really powerful basis
for some for self-service provisioning
and when you and when you wire these
things together to provide that you
really need to focus on how quickly you
can spin up a service from scratch you
might not think that that's a common
case but if you have too much friction
here you might get lazy and end up
building what should be an independent
new feature into an existing service and
this leads to I
gently coupling the process for your new
feature into an existing process and
with kubernetes non-void you can with
the aid of some relatively
straightforward tooling on top spin up
and publish a new stateless service in
less than a minute if you can code fast
enough
so this helps a lot because you can
easily play around with some ideas you
can mock up an API you can call into
other services you can use your mocked
up API in order to figure out if it's
actually worth taking it to the next
level and this gets to our second
problem coding on remote infrastructure
is really slow alright and just for some
perspective a VM based pipeline has a
deploy time you know measured in large
fractions of an hour a docker based
pipeline has a deploy time that's maybe
a few minutes and by contrast how can
you react on my laptop with live reload
it's maybe one to two seconds the most
of this is because somehow javascript
managed to turn itself into a compiled
language when nobody was looking
hacking flask on my laptop with live
reload it's pretty much instantaneous so
how can we do better than this well
developing inside a container actually
helps with this and it helps in two ways
right if you put your build inside the
container you now have a single source
of truth for your services build tool
chain and all of its dependencies and
this makes your dev environment
completely consistent and portable to
other developers and this makes
onboarding easier or having devs jump
between services easier and this also
helps you build a faster feedback loop
and there's a bunch of because as soon
as you do this there's a bunch of
strategies available to you right you
can run your dev container a remote
infrastructure and sync your edits
locally or sync your local edits and
rebuild and run your code right there
you can run your dev container locally
sync files incrementally rebuild and
snapshot the live container to create an
image in seconds and when you do this
this even
works for compiled languages that take a
really long time to build from scratch
and using this technique you can deploy
just about anything in seconds you can
also with a bit fancier tooling use a
tool a proxy to wire that live container
that's running locally directly into a
remote cluster and this lets you do all
the live reload stuff or step through
your code in it bugger and this can
happen while your code receives traffic
from any remote services and sends
traffic to all of the remote services
that it depends on an option two and
three can actually work pretty nicely
together option three lets you use all
of your local tooling what while you're
in the zone kind of hacking away and
then when you're happy you can use
option two to quickly push your changes
into a shared deployment so other devs
can see them we actually implement both
options two and three in our awesome
free and open-source tooling so if you
like the sound of any of this stuff you
should go check it out and if you hate
the sound of any of this stuff you
should definitely go play with the
in-depth just to make sure it's as awful
as you really think it is now I know all
this fast deploy stuff is really
motivated by prototyping workflow but it
actually goes beyond that being able to
quickly fix things when they're broken
is actually the most fundamental
resilience strategy of all and I think
it often gets underused I have theory
that this is a holdover from that or
level dev versus Ops tension the only
way typically the developers have to
keep things from breaking is to try and
anticipate in an eliminate bugs upfront
and the only way operations has to keep
things running is to restart or rollback
to a known good version and this is
actually really limiting because
developers don't think about strategies
to test things in production and
increasing numbers of things these days
can only really be tested in production
and operations doesn't tend to think
about fixing things quickly by rolling
forwards instead of rolling backwards
that's a shame because in modern systems
things often break because of
unanticipated
environmental changes and rolling back
doesn't really help with those and this
brings us to stage two trying to add
features without disrupting users and so
the key organizational challenge here is
recognizing the real out the reality of
that stability versus velocity trade off
and making a deliberate choice for each
service measuring user impact is
actually a business level problem and
you need to consider this as well it's
not just about 500 errors to go back to
our u commerce example again if
conversion rate is fundamental to your
business you need to measure that and
make it available to developers because
as we now know back in Lane Z can impact
that a lot in unintuitive ways so the
key technical challenge here is that
you're changing code in production and
you've got lots of protection from
hardware failure these days but how do
you protect yourself from your own bugs
right if you roll out the exact same
buggy code on all umpteen nodes of an H
a cluster you're gonna end up with some
catastrophic failures and more as we
said before more upfront testing does
not help we need to emphasize or we need
to minimize the impact of unanticipated
bugs and the basic strategy here is
genetic diversity we want to keep
multiple versions deployed so that any
single bug is less likely to be
catastrophic the most basic form of this
is canary testing but you don't need to
stop there you can keep as many versions
around as you like and slowly retired
old versions as new versions get
hardened and again kubernetes non-void
can do a lot of the heavy lifting here
for you because kubernetes lets you keep
your infrastructure declaratively
describing yet the mechanics of
deploying as many different versions as
you like are pretty straightforward we
do this by mapping branches get branches
directly to deployments instead of
keeping the manifests and get directly
we keep a templated version of our
manifests and we can instantiate that as
many times this would be like using a
variety of different profiles they get
determined from the current branch
and this means you can roll your service
back roll it forward you can run
multiple parallel versions all in terms
of whatever get flow get workflow you
want to adopt so this one diagram you're
looking at it can become both an
infrastructure diagram and a get
branching diagram if you like and this
makes transitioning between workflows
super seamless you can just deploy
straight to a single primary version
from your command line while while
you're early just like you commit to
master if you're just playing around
with stuff and later on when you want to
emphasize stability you can just run the
exact same deploy command off a PR or
tag and your CI CD server for a much
more regimented workflow now you do need
a little bit of integration so you can
trigger envoy routing reconfiguration
when these things spin up or down and we
do this in another one of our free and
open source projects self-service API
gateway called ambassador and it
provides that little bit of integration
that dynamically reconfigures on by
based on annotations in your communities
manifests and just like fast deploy
helps with resilience this multi version
deployment actually really helps with
prototyping because with this same basic
model every developer can deploy their
own private version to hack on for any
service and you can even configure envoy
to give them a special host prefix a
host or URL prefix that they can use to
access it just like they would access
the primary version and that speeds you
up even more and before you know it
you'll be ready to start worrying about
stage 3 services so I'm gonna try and
keep this short because this stuff is
definitely not part of getting started
with micro services but I'm happy to
answer more questions about this later
on what I will say here is that focusing
on the organizational fundamentals will
probably help you more than technology
here and that's because there's actually
a bit of a failure mode here where
organizations can regress back to a
centralized process when they get to
this stage this usually happens because
at some point you have a cascade failure
it's big
and someone gets put in charge of making
sure it doesn't happen again
and depending on what they decide to do
they can end up effectively
reintroducing a single centralized
process now the basic strategy for
dealing with this is to define explicit
service level objectives things like per
consumer throughput latency and
availability ranges and provide good
layer seven observability and to
understand how these things work
together it helps to understand the
nature of cascade failures they come up
when you have long chains of synchronous
dependencies and you even think of them
kind of like Christmas tree lights when
one service goes down the whole chain
can go down and so to prevent this you
either need to consider service D
mission-critical thereby slowing it down
to a crawl or you need to change the
nature of the dependency that C has on D
and there's a lot of different ways to
do this you can make it asynchronous you
can cache it or do you normalize it or
eliminate it entirely so how do you
decide what to do when something like
this becomes a problem well first you
need good Network level visibility so
you can actually root cause something
like this and second if service D has
clearly defined service level objectives
as part of its contract and these outage
causes C to violate its service level
objectives which won't necessarily be
the case if it's a prototype you might
not care about its uptime then it's
clear whether team C should take action
to change the nature of its dependency
or whether team D is actually violating
its contracts and should take action to
improve its stability and this can
happen without draconian levels of
centralized oversight and this is one of
the things that I find really really
interesting about micro services I came
to this early on as a purely technical
problem but now I view it as something
that's actually a whole lot more than
that and for me learning about micro
services has really been about learning
how people
can work together better and the part I
like best is that it has this almost
paradoxical element where enabling
people to be more self-sufficient
actually turns out to be key to making
them cooperate better and I really like
that because despite the fact that I've
been on both sides of just about every
argument a group of crotchety engineers
can blunder into I think the only reason
it really works is that deep down people
really want to cooperate with each other
and when you figure out how to actually
unleash that the results can be really
phenomenal so start with thinking about
how to break up your monolithic process
spin off a self-sufficient teams to give
your people the freedom to figure out
how best to help each other and support
all of this by building awesome tooling
for service oriented development
thank you that if you're interested in
reading more about any of this stuff you
can check out we have some hands-on
tutorials on our website and you can
check out the the tools that fill in
just a small part of what you need for a
service-oriented development platform up
there I'm happy to answer any questions
hi you made a distinction between an ops
team and a platformer team would you
elaborate on that a little bit please
yes so yeah so I this is something I've
seen happen in as companies that thought
they were Mike doing micro services and
they thought they were doing micro
services at scale I actually go through
and so the ops team is really the ones
that are on the front lining get and is
responsible for keeping each service
running and if you have thousands of
services
you can't centralize that ops team the
platform team is really just responsible
for providing what you can think of as
almost a domain-specific platform as a
service to enable the rest of the
organization to function Ryan so
platform team is you know effectively
the team that would be that would be
building the tooling to support the rest
of the team but it's really more of a
the relationship between the platform
team and the service teams is really
more of a customer relationship I think
Netflix is actually famous for actually
explicitly formalizing that so if
there's any tooling they've introduced a
lot of internal tooling but every team
is free to choose whether or not they
want to use that tooling build their own
or use something else so hopefully that
makes it clear hi oh right yeah yeah
so you mentioned so you'll be glad to
learn that in our company we do almost
all of these steps we have all of this
it goes really well however one of the
bottlenecks we face is deploying to
production that pipeline that takes what
you have developed internally across the
company by the time it makes it to
production that entire process could be
really slow it's not like it go out in
two days because there are a lot of
things we need to provision for the
redundancy is what are the data store
requirements SLA is and so on and so
forth so now if you break all these
teams up into autonomous teams this
entire end-to-end is really hard to
deliver because of that verdict
a common requirement across all the
teams of deploying to production so
question what challenges have you faced
with respect to that have you
experienced it to be a bottleneck ever
and how have you solved this problem or
what are your suggestions to handle
speedier deployment to production and
not make these things a bottleneck yes
that's I mean that's definitely factor I
think that's why you see sort of the
first generation or early earlier micro
services companies have much larger
platform teams because they had to build
a lot of that stuff for the rest of the
teams to depend on these days there's
been multiple generations of sort of
micro services companies and the way I
look at micro services sorry the way I
look at high growth SAS companies is
that they're machines that VCS pump
dumped loads of money into and one in
and they spit out micro services
platform technologies open source micro
services platform technologies out of
the other end because they all have lots
of money lots of people to throw these
problems and they build lots of tooling
to help them and but more recently
there's really been convergence around
some of these feelings so there's a lot
sort of the choices are more obvious and
it's easier to assemble this stuff so
kubernetes like I said it's doing most
of the heavy lifting around around
around that deployment and using
kubernetes you can spin up you can you
can you can make that deploy process as
fast as you want right so the limiting
factor with with the right combination
of kubernetes and docker and where
kubernetes containers in some kind of
some kind of dynamically reconfigured a
gateway the the the limitation really
just comes down to the process you want
to choose as opposed to the you know the
limitations of the technology
I have many more comment than a question
I think you seem to make the statement
that there's a trade-off between
velocity and stability yep I think
that's wrong I think it's really a sir
like me trying or a three dimensional
space where complexity or simplicity
comes in I was back at Amazon a little
over ten years ago we launched the
service in like three days
that what cup was called on every page
lot but it was super super simple and I
think one of the tricks of like getting
the architecture right is coming up with
those like simple services yeah so
that's an interesting question because I
people ask me a lot how do you design a
good micro service right and I'm I never
used to know what to say because like
there you know I have no familiarity
with the domain of whatever company
they're they're from and so I I'm really
not in a position to answer that
question but I did eventually come up
with a good answer or a clever answer at
least my answer is the way you design a
good micro service interface is by
throwing away a whole lot of bad ones
first and that's where I mean this part
of the difference between you know sort
of the service-oriented architecture
idea and the service oriented
development idea right it's it's the
difference between the the slow
deliberate architecture process of
trying to predict in advance and the
sort of faster more iterative process of
okay we're just gonna try a bunch of
services this is the problem we're
trying to solve and you know we'll we'll
try a bunch of different api's and see
what sticks right and one of the things
that has been shifting at a really rapid
pace that the cloud is enabled and now a
lot of the a lot of the technologies for
using the cloud is enabled is that you
can actually apply that much more rapid
iteration process to distributed systems
and that didn't used to be the case
right usually the case that you know
distributed systems were really really
slow and and expensive to set up and now
they're cheap you can just try stuff and
if it doesn't work throw it away and so
you know if you look at that the last
example right if you think of
architecture as really being the
topology
of your services if you look at that
last example with the Christmas tree
lights you have architecture happening
right the shape of your services is
being defined but not in a centralized
way and that's how you get architectures
that are too complex to fit in one
person's head right you're doing it by
moving sort of the boundaries between
your services you're moving that choice
of how to structure the boundaries
between your services from a technical
decision to just a much higher level
decision right this is if you know the
job of this service is to help this user
accomplish this thing and you know the
team can try as many different api's and
have as many different parallel api's as
necessary to accomplish that goal and
that's why I think search is great
example because it's one of the sort of
one of the most intuitive easiest
microservices and when you're working
with when you're trying to work in a
service oriented development style a lot
of the natural architectural intuition
that you might have it kind of gets in
the way so you don't think to do just
try things you think about your
instincts and whatnot that are probably
based on data that's maybe five years
five years out of date and so that's
something that's something you kind of
need to need to constantly fight against
with this sort of thing so I I don't
know if that I know if that answers your
question but I mean that's one of the
ways that this this kind of tooling that
that just speeds this stuff up it can
actually help you with design because
you can just try so many more of them I
have a question so you're talking about
spinning off the teams yep at these
small teams yep so can you talk about
like I think one of the things that
makes it easy to have a monolith is that
it's easier to tribute cash right so
cash flow to a particular monolith yeah
can you talk about how to create that
feedback loop when you have these small
teams like which teams are actually
being effective and can you spin up
multiple of these small teams providing
a similar service like you would see in
a marketplace it's an interesting
question actually when you talk when
you're talking about cash are you
talking about
you or cost both so it's something so I
mean okay in you know because because
we're trying to help people get started
with micro services we tend to sort of
focus on on the the smaller scale
smaller to medium scale issues but that
is something that definitely comes up
when you're at a larger scale and
there's great examples of on both sides
of how large organizations start to
actually account for some of this stuff
I know one of the on the cost side of
things it's really common when you build
this kind of things it's really common
to start using way way way more
resources more cloud resources then you
realize and so at some point you usually
need to give your teams visibility into
that right and so the first step you
usually start with there is actually
trying to build some kind of
traceability so that and having like a
leaderboard okay you know who spent the
most money this week right and you know
taking taking steps like that can
actually connect surely improve things a
lot and if you know if you get to the
scale where you need to do it you can
start you know building effectively
internal accounting systems and stuff
like that to accommodate that I don't I
haven't heard as much on sort of the
revenue side of things but yeah I'm sure
there's there's similar stories if you
look if you're interested I can probably
dig some some case studies up that might
involve some of that stuff so grab me
afterwards
hey that's it's right here on it I live
on your left it's right here
away sorry yep so yeah thanks for the
great talk why interesting inspiration I
got from you was letting customer the
end user having to access for the
catenary version of the product I feel
like that's kind of interesting because
that feels to me like we are having
we're dog fooding our product our end
user right so how do you think that
process will conflict with your business
decision in general so especially for
elected official heavy companies yeah so
that's that's a great
it's one of the reasons that it's so
important to build your teams with that
sort of that that cross platform that
cross-functional spectrum of talents and
then that needs to include the business
side of things as well
because what was it I was at a company
once that where they were they thought
they were doing micro services they had
multiple teams but sort of the it was
more sort of the the dev the separate
dev team is pictured right and there
wasn't a whole lot of trust there right
they had they had their they've been
trying to refactor their monolith I
think for two years and they tried to do
a big cut over at one point they're an
e-commerce company and they had a big
scary experience their conversion
dropped and so they didn't they didn't
like that and they got gun-shy and they
they they pretty much spent a number of
years spending a lot of effort and being
almost almost stagnant and I think I
think one of the one of the things you
can do when you sort of get the entire
business aligned is you you can think
you don't have to think about new
features as scary and negative right you
can you can you know canary testing
doesn't necessarily mean bugs right
canary testing can actually get get a
canary testing via a domain specific as
well right you can make it be a positive
thing to have your users try out new
versions of the product cuz they get new
features earlier right you can
incentivize it right you can actually
you know give them credits to try new
versions right so there's there's a
whole lot of steps you can take to make
that be a much more positive thing as
opposed to a negative thing because in
the end when you do that right you're
ultimately trying to help however the
end user is and so they will they will
appreciate that if you make that clear
create a need any last questions cool
okay so if you decided you needed to
have more questions I suspect Rafe will
be able to answer them individually one
on one but also remember the panel
discussion that we're having at the I
want to say for 10 to
five o'clock period something like that
all of the speakers will be there to
answer your questions in a group see you
later</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>