<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>An Introduction to Scalaz-Stream | Coder Coacher - Coaching Coders</title><meta content="An Introduction to Scalaz-Stream - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>An Introduction to Scalaz-Stream</b></h2><h5 class="post__date">2014-03-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/GSZhUZT7Fyc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yeah I am I'm gonna be talking about
Scalzi stream today and got a lot of
stuff I want to get to so I'm pretty
much just gonna get right to it so okay
what is
Scalzi stream so Scalzi stream is a
library for doing stream processing and
i/o and sort of the goal the goals of
the library are that we want we want to
write programs that do i/o in a
compositional way so we want to be able
to assemble them from smaller pieces and
another sort of big goal of the library
as we want to make it really easy to
write code that is resource safe so we
want to make sure that file handles get
closed database connections get closed
when they're supposed to and so forth
and I guess sort of the origin of the
project is you know it's sort of started
as you know some some work that ruin our
and I did for the book and you know last
year when I was up here talking about
this stuff this was somewhat theoretical
vaporware or you know prototype code
that that we've written for the book and
but yeah now it's actually a real
library and you can use it for real
things and you know hopefully this will
be people's interests and you know
they'll actually maybe try to try using
it so but just by show of hands how many
people are using scholars estream now
okay not not too many all right
well all right well we'll see how this
goes so so Scalzi stream is it's based
on the core data type of the library is
the stage type process and so
conceptually process represents a stream
of values and but it's sort of a special
type of stream in that it may
periodically sort of stop and wait for
some requests external requests to come
back before it continues emitting values
so I'll kind of talk more about what
that means in a minute but sort of the
simplest the simplest way of creating a
process
is we can just create a literal process
that is going to emit you know the
values that we give it so I can say
process 1 2 3 and you know we can see
it's just a process that's literally
going to emit the values 1 2 3 now
process has to type parameters here one
is int so that is the the output type
the type of elements that the stream is
going to be emitting and this this first
type parameter is the request type so if
this were an effect phul process that
we're making some external requests we
would see something else here besides
nothing the fact that it's nothing is
just saying that this is a pure just in
memory sequence it's not executing any
external requests or won't ever asked us
execute those requests so just a little
bit of I'm just to make the slide little
shorter I'm saying Val P is equal to
process and so a lot of the operations
that are defined on lists are also
defined on processes so I can append
them a pen one process to the next these
are all just different ways of kind of
writing a process is just going to emit
some values to the output I can emit a
single value if I have a sequence I can
just omit you know all the elements of
the sequence to the output and you know
you can see the result is pretty much
what you would expect okay and yeah just
just to mention so you know there's map
filter or fold so I mean all the
operations you would expect you know for
lists are also defined on process and
yeah these are just a few a few examples
if you you know are in the repple you
you know have a process do tab
completion you can see there's a whole
bunch of functions I'm not going to go
over all of them here but I mean you
know the idea is if it if it makes sense
for a sequence it probably makes sense
for a process as well okay so so so far
I've just been talking about you know
these pure pure sequences which aren't
there's no i/o involved so it's you know
not very interesting you're thinking
well I could I could have done all these
things with
regular Scala collections so here's an
example of our first effect full stream
so this process fizz is going to wake up
every three seconds and emit the value
fizz and so a couple things to notice
here so one is the okay the output type
is string so we're obviously emitting
you know the string fizz but now we can
see this is no longer nothing this is
task and task is it's a data type from
scalzi it's sort of a better IO that
handles binding to asynchronous and
parallel computations and also has some
good support for exception handling I'm
gonna show some examples of tasks a
little bit later but this is just saying
that okay
waking up every three seconds that's
that's sort of it's going to be a series
of these asynchronous steps we want to
go to sleep not literally by blocking
the thread but we want a schedule you
know an asynchronous task to be run
three seconds later and we want to keep
doing that and we can see that the you
know just the representation of it it is
it's no longer just you know emitting
some values it's this a wait so a
process is a state machine it can be one
of three states it can be emitting
values it can be a waiting for the
result of some request or it could be
halted so it's it's done emitting values
and this is just a show that you know
that that effect will stream that I that
I just created I mean I can still call
take I can still call filter I can still
call drop I can so call those same
functions on it it doesn't matter that
it's this effect 'full thing and then
just to kind of observe what's what's
happening here so here I'm using like an
evil side effect to just print out the
the Vallot the values that are emitted
by the stream and if I want to actually
you know run this stream so this this is
a conceptually you know it's it's a
program that is going to when it is
it's going to emit some values so how do
I actually run that stream and and sort
of get get something out of it so
there's this function run log which
takes a stream us it takes a stream and
it's going to sort of compile that down
to a single monolithic task and the task
the value of the task is just going to
be the values that are emitted by the
stream and so nothing actually happens
when I call run log this is really just
it's more of a process of compilation
it's converting from a stream to just a
single monolithic task and this is so
far we haven't actually done anything if
we want to actually run that task and
actually have have that effect of you
know waking up every three seconds
printing and so forth then we actually
have to run the task so we can call that
task dot run and it's gonna you know
after three seconds print fizz then
print fizz again and we've only taken
the first two elements of the stream so
it's going to stop at that point so the
interesting thing about tasks is that
there's no so task does not represent a
running computation so task is a
description of that entire process you
know once we've compiled it it's it's
just a description of what needs to
happen so the task is not used up after
you run it the first time so this is
sort of a major difference between a
task and the scala concurrent future
where you know once it's computed it's
you know that's it the value is cached
and and you can't if you run it again
you'll get the same value and this I
think is actually very important for
compositionality because what it means
is you can separate the code that sort
of produces the task from the code that
chooses how to evaluate it so if you
wanted to add some retry logic after the
fact to a task that's very easy you just
write a general-purpose function to do
that you can't really do that with the
future you have to embed
sort of any retry logic into the future
itself so I yeah in general it's it's
just much nicer to work with these sort
of pure first class descriptions of what
of what you want to happen okay
so there's a number of operations on
streams for combining combining streams
in different ways so obviously we can
operate on a stream with the usual sort
of you know list operations map filter
or all those sorts of things but we can
also combine multiple streams in various
ways and here's just this is one at one
example of how you can do that so here
we have buzz which is going to wake up
every five seconds and emit buzz and I
can say fizzbuzz which is fizz
now what that so merge the merge
operation is conceptually what it's
going to do is when either of its inputs
has a value available it is going to
emit a value to the output and you can
see that if we actually run fizzbuzz
it's going to you know at three seconds
six seconds to nine seconds it's
emitting fizz but then it's interleaving
buzz at five seconds in ten seconds and
so this is sort of an you know this is
sort of arbitrary non determinism you're
allowing sort of arbitrary interleaving
of these two streams but you could very
easily write sort of a more bounded
merge like okay merge these two streams
but make sure that you know one does not
get more than say 10 elements ahead of
the other and it's very easy to write
those those sorts of policies in scalzi
stream itself and you know they're just
sort of these generic accommodators that
you know you can reuse wherever you want
to you know just like if you write you
know something that does you know both a
map and filter at the same time I mean
that's just a generic function that you
can reuse okay and if you want to see
you know a bunch of examples of some of
the functions that are already in scalzi
stream
so there's various deterministic
functions for combining two streams in
the T module there's various non
deterministic functions for combining
streams in the Y module and there's
various functions for sort of
transforming in some staple way possibly
individual stream in in process one and
yeah I'm not going to try to go over all
these but just lot lots of different
functions there okay so that is the
basic programming model I guess of of
the library so it's you know it's a very
nice model it's I think it's familiar to
people from you know working with lists
and sequences and so forth
and so the next sort of question is like
okay this sounds great but how do I
actually bind this this API to talk to
you know external sources and so scalzi
stream has a few different ways of doing
that so I'm going to try to show a few
of them here so one is there's a few
functions in scalzi stream IO which have
just different ways of creating streams
from IO based sources so we can create a
stream from the lines of a file and you
can see the the output type is string
and the effect type is task implying
that this is going to be doing some IO
we can again call you know take and you
know take wow we can call the same
operations as on you know pure streams
and you can see when I actually run this
this is actually again this is actually
going and fetching you know the lines of
this file and and returning that as a
vector now what's interesting about this
stream is that this is actually
encapsulating the full lifecycle of
working with the file so this is not the
the consumer of the stream is not
responsible for making sure that the
file handle gets closed
when when the consumer of the stream is
finished the file handle will be closed
even if that consumer ends up throwing
an exception we still are always going
to guarantee that that file is closed so
this is sort of a nicer model than sort
of traditional i/o where it's like every
user of a resource is responsible for
you know ensuring resource safety and
you know the type system doesn't really
provide any help you know if you forget
to close a file I mean it's just gonna
be you know potentially a runtime error
or a resource leak this is sort of like
we're encapsulating all that logic in in
one one stream object so just to give a
sense for how how this works and how you
can kind of build this type of resource
safety into the streams that you
construct so there's this function on
process called on complete and it takes
it works a little bit like a pend in
that it's going to run the first process
and then the second process but unlike
append it is guaranteed that you're
going to run that second process even if
this first one finishes with an error so
here I'm just using a side-effect
- I'm printing cleanup but you know you
can imagine doing some some real real
cleanup in there and you can see if I
say lines take to run log run and then
you can see that the that cleanup action
is being run and notice this we get that
cleanup action even though we only took
the first two lines of the file so we
didn't have to traverse to the the end
of the file and then have some magic
cleanup action get run as a side effects
you know we're allowed to terminate
early we we don't sort of break resource
safety you if we terminate early another
thing is that if we have exceptions that
get thrown while we're processing the
stream we also still call the cleanup
actions so here we're calling let's go
back to the input here so you can see
the first line of the file is this
comment so it's not actually a double so
if we if we're calling map to
on all the lines of the file this is
going to bomb with an exception and so
you can see when we actually run this
the cleanup action still gets run and
then we just re raise the error so if
you want you can actually catch the
error within the stream and then you
know recover from it but yeah I mean
this is just a show that okay you can
sort of program as if you didn't have to
worry about exceptions and unless you
need to do something different to handle
those exceptions you know everything
just sort of works out which is I think
is very nice and a lot less error-prone
and than doing these things manually
okay so that all sounds really good so
what about when you have to bind to some
asynchronous or side affecting sources
so this is very common I mean you know
when you when you use Scalzi stream or
you know any sort of functional approach
I mean you don't control the entire
universe you can't really ensure that
you know sometimes you just have to you
have to interface with some API that is
you know a little bit more side
effecting or just has various nasty
stuff that you just kind of have to
figure out a way to talk to so scalzi
stream has a number of ways of binding
to those types of api so that you can
you know you have sort of the nasty you
know imperative API on one side and then
on the other side you get this nice
stream abstraction for working with it
so I'm going to cover a few different
ways of doing that so one is mmm-hmm so
tasks I mentioned has very good support
for binding to asynchronous computations
so kind of the simplest way to create a
stream is by creating a task and then
wrapping that in a stream so here's an
example of a callback II API so we have
this function read so read is not going
to return an array of byte read is
taking this callback that it
then invoke at some later time with
either the error or the array of bytes
that it that it read now then this is
kind of a common type of API and you
know if maybe if we're using nodejs we'd
you know call ourselves good and just go
ahead and program directly with this
model but I actually think this is a
kind of a horrible model to have to
program with directly we really want to
have this nicer abstraction of having
you know this thing that's sort of at
least the API feels like it's a blocking
API even if under the covers it's doing
all this asynchronous stuff so I can
take this read function and I can say
task dot async and I pass in the read
function and sort of as if by magic that
becomes a task or a byte and you know
this is a monad I can map flatmap and
sort of do all the typical operations
here and yeah I mean the type if you
just sort of follow the types of async
it just sort of works out it's a little
bit brain bending if you if you actually
look at it but yeah this this sort of
lets you sort of invert control and you
get this nice sort of straightforward
API from this callback e1 sometimes you
have a a callback a callback e API where
you have sort of two continuations a
success one and a failure one but it's
you still just use task async and you
know works a little bit differently but
it's the same same sort of idea one
interesting thing about tasks is by
default when you flat map a task it is
going to run the the flat mapped
function in the same thread as whatever
the sort of original callback gets
invoked in so if you want to sort of if
you don't want that behavior you can
fork off a new new task for the rest of
the computation so by default tasks
is not going to be going through a
thread pool submit cycle every time you
flatmap over it so that that can be very
good for for the efficiency okay so now
that I have this task how do I actually
promote that to a stream so there's a
function on unprocess the process object
eval it actually it's not even specific
to tasks you can promote any effect to
to a stream and yeah I just I take that
task or a byte I call Val and I get back
a process of a Rea byte and this is a
process that's just going to it await
the results of that task and then emit
it and then stop if I wanted to run a
task repeatedly I could just call you
know that that stream dot repeat repeat
is just another generic function in
Scala z stream it just is going to run
run that stream over and over again okay
so that's kind of the most idiomatic way
of binding to an asynchronous
computation it's it's best if you can
bind at the sort of earliest possible
stage but sometimes that's not always
possible sometimes you have some process
that is just going to be pushing you
values a stream of them you don't have
access to the asynchronous tasks
corresponding to a single element of the
stream so in that case you can use
something like these asynchronous queues
so here I'm declaring I'm importing
scalzi stream async I can say Q of in
and I actually get back to things so Q
is going to be this mutable it's as very
side affecting mutable api that thread
one in the you know imperative
programming world can can go ahead and
populate by calling enqueue multiple
times and by calling clothes it can also
call fail to like raise an asynchronous
exception and then meanwhile on the
other side in
sort of the the other side of the
universe the stream processing world
here source is going to be a just a
regular process of the values in that
that are put into that q8 asynchronously
and this cue is not blocking so there's
no yeah there's no actual blocking reads
anywhere it's actually you know this
process will just be woken up
essentially when whenever thread one and
queues a value to it so it's all sort of
non walking like like you would expect
okay and then finally the last way I'm
going to mention is a lot of times you
have some asynchronous signal so it's a
continuous value that is being updated
by some external process and the way
that you can bind to that is you can
declare this async dot signal boolean
and you can get sort of get to two
different types of streams out of a
signal so one is you can just get the
sort of continuous version of the stream
which is it's always going to be defined
whatever the current value is it's going
to return that and the other option is
you can get a discrete stream which only
is going to emit a value when the signal
has changed so using using this API you
can have thread 1 which is setting you
know setting the value of that signal
and then meanwhile and thread 2 you can
you know just react to any changes to
that to that signal and you get this
sort of nice stream stream processing
abstraction so and there's a there's a
few I was going to talk about binding to
actors but I'm actually I'm gonna skip
this but I will you know possibly come
back to it during the during the QA if
people are interested but yeah so those
are all just different ways of binding
to some a sinker
this API now yeah I just wanted to
mention four credits so ruin our and I
we you know we're obviously we worked on
a lot of this stuff for the book a lot
of this work was based on some work that
canet did in in Haskell this library
machines and then also wanted to give a
shout out to paw Bell who's he's at this
company spin oak oh and they've been
actually helping sponsor some of the
development on this and if you're
interested to learn more you can check
out chapters 13 and 15 of the book which
we're actually told by the publisher
it's looking like a June publication
date so it's actually finally going to
be on bookshelves which is which is good
and yep yeah so all all of the book
chapters are in the MEAP right now so
yeah all the content is there you know
and yeah that's the this is the the
github page if you want to check it out
we've had a number of people
contributing to the library which which
i think is awesome and yeah i'm not
going to try and mention all the
contributors but you know even stuff as
simple as just oh i added you know this
this little stream transducer for doing
this little task that was useful there's
just lots of little functions that are
very generic that you can write that are
that are helpful so yeah that's that's
all I got so any any questions yes
yeah a little bit so I guess I mean a
lot of these libraries are oh repeat the
question so contrast this with the
observable or rx Java stuff so yeah a
lot of these libraries are similar I
think it's one of these things where the
Devils in the details the thing I don't
like about rx like the the rx job of
representation is basically the entire
stream is asynchronous so it's like a
very push the entire stream is push and
that works out well when you're just
operating on one stream at a time but as
soon as you want to do some like you
know you want to do like a merge where
you're yeah where you basically need
that sort of pull type of API and then
that representation doesn't work out as
well yeah oh so yeah the question was
could you combine all of these different
types of effects really are ways of
getting data into a single computation
and yeah definitely yeah there's nothing
nothing restricting you from from doing
that yes yeah it's basically that
because task is not a running
computation you can bind to it multiple
times and it's just going to rerun the
computation yeah so yeah the question is
how do you deal with sort of queue sizes
and and yeah in back pressure and that
sort of thing so I guess the the general
my general answer is start with so the
Scalzi stream answer is you start with a
fully deterministic computation model so
if you start with that it's very easy to
ensure you know it's deterministic
memory usage and then yeah when you when
you bind to something external you know
that's why I was saying you you really
want to bind to the to the task that's
fetching individual elements because
that that's gonna that's what's going to
give you complete
control over queuing and memory usage
and yeah if you can't do that then you
know you have to implement some ad hoc
way of doing back pressure or something
and and there are like the the queue you
you can you know you can get the current
size and you can do things like that but
yeah it sort of feels somewhat ad-hoc to
me and but I think it's sort of the best
you can do so yeah I feel free to come
talk to me after or I know should should
I just wrap up here or all right thanks
everybody</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>