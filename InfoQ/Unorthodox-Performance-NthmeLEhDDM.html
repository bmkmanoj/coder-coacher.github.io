<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Unorthodox Performance | Coder Coacher - Coaching Coders</title><meta content="Unorthodox Performance - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Unorthodox Performance</b></h2><h5 class="post__date">2014-08-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NthmeLEhDDM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi my name is John David Dalton I'll get
into a little bit more
when I do in a second this talk is
called unorthodox performance and it is
about the performance optimizations that
I implemented while developing low -
solo - is a low how many people know
what low - is raisins cool lots for
those that don't know it's it's a
utility library so it's got things to
make working with arrays strings objects
collections easier and it covers gaps
that exist in the the language itself
and in doing so I originally forked low
- from an existing library called
underscore and part of the things that
differentiated myself from the
competition was performance performance
let's see if I get into this next all
right cool some of the things we'll talk
about in the the presentation is the
principles of performance and so the
perf principles I tried to add a bunch
of words that started with the same
letter because it looked cool but it's
optimized for correctness and what that
means is that JavaScript developers in
the ones that I see a lot well will
focus on performance to the point that
it's a negative you shouldn't put
performance as your highest priority in
this case I put correctness functional
correctness over performance like if you
get to these the results fast but you
get the wrong result that's not that's
not a good thing right so you should
always look at balancing performance
with other things and in case of low -
when I implement something I make sure
it's correct and consistent across all
of my supported environments and then
worry about performance and then
optimize it
there's also context - so I maintain a
site called J's perf where you can go
and benchmark little snippets of code
and a lot of times devs will will
benchmark things like single quotes or
double quotes or double equals or triple
equals our code with semicolons and cook
without semicolons and that is just it's
bananas right like you shouldn't focus
on such micro performance
so everything has context whenever you
would get a readout on je s perfect says
things like how many operations per
second is is a given snippet and a lot
of times it's millions and millions of
operations a second and for most use
cases that's the difference between a
million like ten million and eleven
million isn't going to make a difference
for your code right so that's why
there's context make sure you kind of
you weigh your perf decisions in the
context of the thing that you're
executing also something I'll mention a
bunch is optimized for the common case
and I'll go through and walk through
examples of that basically if you have
an API that you're exposing and a lot of
times your API may be able to be
overloaded so it can accept an options
argument or it can accept one or two
ways to be called you want to optimize
it for the way that it's going to be
called the most and you want to make
sure that everything else falls off into
the slow path that you don't care about
so I'll I'll go through some examples of
that and then another reason to optimize
would be to counteract the cost of
something in my case I wanted to make
lodash cross-browser consistent and that
meant fixing bugs in older environments
and fixing bugs comes with a cost right
you have more checks you have more
detection you have to do things like
iterate over properties that were missed
and so that's extra extra overhead to a
method call and so to counteract that
cost I optimize those methods and made
them faster to the point to where you
could have code that executed
consistently and was faster which is
usually something that doesn't go
together right you're doing more things
and it's faster and so that's what I did
I use perf to offset the cost of those
bug fixes and I've added features too so
for example lodash has methods that are
faster than native alternatives right so
like our underscored map is faster than
array.prototype map but it's also doing
a lot more to so it accepts instead of
just a function you can pass it a string
or you can pass it an object and it'll
will create a predicate function for you
and it does a lot of other things under
the hood and we're still able to do that
and be faster and so that's that's a
it's about counteracting costs and it's
about optimizing the common case so I'll
be talking about a few of the things
that I learned when I over the past two
years I gave a perfect auch right before
I created lo - and I said some things
and now I have a different opinion on
some of those things so I can't I'll go
into what I used to think and now what I
what I think on some of the the perf
techniques so you can follow along I'll
be I'll be digging into a lot of code
and that's gross I'm sorry there's no
really there's no way to explain it
really I got a point to the code and say
this is the chunk that's doing this and
that so you can go to github calms a low
- slash low - I'll probably be in the
the the root low - das file for most
things so just if I reference a function
name or you see a little snippet here
that's that's me referencing that file
okay so the first thing is to optimize
for the common case and I decided to
pick a example that really showed this
common case it just so happens it's a
wallet text so we'll see how well I can
do this so here's the common case Wow
right let me let me zoom in to that just
a little bit okay and you don't need to
see all the function because I'll talk
you through it but we have a function
called matches and matches creates a
function that will evaluate any passed
in object and see if it matches the
original object that you passed so you
can do that - to filter through an array
of objects right and the common case for
this method is to always evaluate or
compare a source object that has one
property and it's a primitive value with
low - we also do something called deep
object comparison where we'll take that
value and we'll crawl it and and compare
arrays partially compare arrays and and
compare nested objects and that's
horribly slow like that's gross
that's gross slow and that's not the
common case and so if devs were using
this method they would get hit with like
like just 300% performance degradation
on this on this method for something
they never use right and that's gross so
what I do is in this method I look at
here I look at if the length of the
properties that are passed in is 1 I
then say hey if can I can I compare this
simply like is strict comparable which
means can I just go triple equals on
this value and do a quick comparison and
if so then I create this really tiny
comparison function right so that means
for the common case you're getting this
tiny function that doesn't do neat that
doesn't do deep crawling that allows me
to be on par with the competition's
implementation and the competition
doesn't support deep crawling of object
comparison so I've got a feature added
and I've got performance and I'm in the
ballpark of them I've taken oh oh let's
see here we go I've taken it a step
further I just need to remember not to
scroll with two fingers so taking it a
step further and normally normally let's
see if I can get down to it
we'll just do that much for now we'll
keep going we'll keep going okay so here
and the more expensive check I have a
case where I'll be doing a deep object
comparison and that requires me to do a
has own property check relatively cheap
right compared to doing is equal which
is here this has own property check and
this is equal operation here but if any
point in the time in this in this
comparison one of the objects fails so
is false
it doesn't match then I need to exit out
of the the operation so
normally I would be doing has own
property check is equal for every
element in the collection right has on
property check is equal has own property
check is equal and then if the if the
90th property of this object failed it
would just return false so that's a lot
of work to just have a false a fail case
right and it turns out that when you're
filtering objects a lot of the time is
going to be a fail case it's not going
to match the needle in that haystack
right so what you do is instead is break
out those two checks the cheap check and
the expensive check in just two separate
loops so the first the first trick is to
always do the cheap check first so
before I was doing something like is
equal and then the has own property
check wrong it needs to do the cheap
check so do the has own property check
first but what you can do is iterate
over all the elements and do a has own
property check but the cheap check first
if at any point it fails you haven't
wasted a lot of effort on JavaScript
execution it'll exit fast without having
to ever touch the heavy path then only
after all the elements passed the light
check then you go back through and do
another pass with the heavy check and
that is crazy cool there's some stuff in
here where I'm juggling based on based
on if it is a let's see if it is a
strict comparison or deep comparison
ignore that the gist is that it's order
your execution of operations from cheap
to most expensive and then if you can if
it makes sense break them out into two
separate loops and do all your cheap
first and then do all your more
expensive next that's same and that
would be optimizing for the common case
there so we were able to get all of that
functionality in there and still be
performing now it's gross
because it's it's larger but that little
function can then be fast for every
other use and so I usually say if I can
isolate the gross miss to just a little
bit I'm okay
in this case it's it's it's not as gross
as it could've been
the next thing is abstraction and you
all have principles of common case
throughout all the methods that I'm
using so that was just like Anna nice
case that Illustrated it when I when I
first talked about JavaScript
performance a couple years ago I would
always say the easiest way to improve
your JavaScript performance is to reduce
abstraction right if you're doing a
function call that calls another
function that calls another function
that calls another function that's
abstraction and it'll it'll slow you
down right that's not the case you can
abstract in a way that you can leverage
the optimizations in the JIT of the
engine's JIT to improve your performance
and so now I'll walk you through how
that's done
so now in in the current stable version
of lodash there is code that looks like
this and I'm sorry this is a function
template this is a template that you
would normally use to create HTML I'm
using it to compile a function and I'll
zoom in just because I want gasps this
is this is gross right like you can't
read this you look at this and you go
what what is this now this is actually
the I believe the compiled form of that
function but before that was all strings
no one really wants this in their code
it was the biggest complaint I got from
devs looking at lodash is that they
couldn't understand what was going on
there and it was it was hurting
contributions to the code base because
it was something that was too bizarre
turns out you don't need it throw it
away so in the next release we're going
to just leverage abstraction and
leverage the the JIT in the engine to to
optimize it for us and so here's here's
a case here's a simple I believe this is
big enough I probably don't have to zoom
this is a simple like for each
implementation pretty basic it says hey
if you if you've got an array go and do
a for loop over the array else do this
other function that that handles
consistency over an object right or over
a string or whatever happens to be
passed to it and this is this is
starting off this is kind of like
reducing abstraction because
I'm not calling another function for
arrays I'm not calling a separate
function for objects I'm doing it inside
nested inside the function of for each
but it can be improved one of the things
that I'll do here is that if you look at
this snippet of code what's the in and
say something that's iterating over a
collection what's the thing that's
costing you the biggest perf here and
it's it's actually it's this dot call
here if we go back to the common case if
you're using for each a lot of the times
you're not executing the this Arg
right you're not passing it that last
that third argument for your your this
binding most people don't write you
don't need to always do dot call if
you're never doing at this binding so
the next step is to hoist it out alright
so we create a small function called
base callback that will sit there and do
the this binding only if the this value
is not undefined and it will also handle
things like the the case of method
shortcuts so I can have I can pass a
string and it'll handle converting that
to a function I can pass it an object
and it'll do that too but what it does
is it leaves the common case the case of
the the know this are fast because now
it's not doing dot call it allows for
engines to type specialized better for
that invocation and you get faster than
native performance just by doing that
that's the key like if you didn't do
that you'd be slower than the native
method that that little one-line change
is the secret to that function into most
of the things that are faster than
native if it's dealing with array
iteration so that's that's the next step
is to just abstract that away now you
may have noticed because of that I now
have a simplified object a branch down
there at the bottom too but that can be
taken a step further so that gives us
that gives us good performance but we
can get we can get better at that so
here's here's the next step and this is
to say hey if I'm an array go to a
method that's basically taking that for
loop and moving it into its own array or
into its I'm sorry into its own function
that handles it so now this is hey if
this is array go the array route and if
it's not go
the base each route now this is almost
there we can take it a step further and
go here now what this is doing is saying
if you're not passing something that
needs to be calling the helper function
don't do it just go straight to the
array case because that happens to be
the most common case so now I'm avoiding
even the call back sugar if it's the
common case which is to basically have
no this binding it be a function and it
be an array so I've optimized it there
too there's a there's an alternative
syntax that I have on the next slide
that's basically it's similar but what
this allows you to do is that now now
whenever your your function becomes hot
especially if you're passing it the same
kind of value so let's say it sits in
its the array it will the engine will
create an alternate form of that
function that specialized for array and
it may inline the array each right into
the actual function so it's doing what
we were doing before with with the code
being in line so you're getting that
performance benefit but it's not it's
not having to deal with the baggage of
the object branch being in there too and
so what that allows later is that
specialized function can then be
qualified to be inlined itself into
another function call so it allows you
to to to inline the inline code again so
it allows the engine to do what it does
best right well it handles the legwork
for the optimization for you so by
abstracting and creating specialized
functions for for just the array or just
the object or just your fast path you're
able to to get performance optimizations
now let's see here all right so I didn't
have the I took out the alternate
implementation and replaced it with this
one here which is to to talk about a
technique I've done with abstraction
which is if you have an exposed API that
has to do a lot of a lot of it has to
accept a lot more things like what
happens if you pass an n a n value what
happens if you pass a string do I do
error checking on this input that's
passed
if I have to do something like take the
arguments object and create a slice of
it and turn that into an array all of
that heavy lifting can be done in the
external function that's explore the
exposed function right and then you pass
it off to base functions that are
specialized to not have to do any of
those checks and so that means that
other other code in there I gotta be
careful about walking away from this mic
but other code can call that base
flatten there instead of having to call
the the actual exposed flatten because
the exposed flatten right now accepts a
function accepts deep flags and all this
other stuff and you can specify like it
automatically will filter out non array
values and arguments objects and it has
all this overhead that you don't need to
do internally right so you have this
base version of the function that's
specialized and doesn't do any of the
heavy lifting something else that you
can do here is when you're doing things
that there's operations that you can do
that effect for the engines ability to
optimize a function that disqualified
the function from optimizations I you
may see a lot of posts that say hey
here's performance killers in v8 when I
develop lodash I look for things that
are applied across the board across
engine so in Firefox in IE and v8
there's a common thread of things that
you don't do if you want up your
function to be optimized and so one of
them is converting your arguments object
to an array if you do
array.prototype.slice.call F I'd that
function from optimizations there
because the engine punts on that it goes
ah you're touching the arguments object
gross no optimizations for you but
what's what's okay is if you have that
exposed function that's doing that that
arguments object kind of conversion if
it's just that tiny external function
and it's passing off to another function
that can get optimized because it's not
doing any of that word so I create a new
function to do things like try catch a
try catch will disqualify your function
from optimizations right some are more
fine
rained into where the Diop happens but
as a general rule since you're
developing from more than one browser
you would want to abstract that try
caching to its own function that way
that that function that has the
try-catch is the optimized but all it's
doing is the try-catch block in there
with your code and so and the next
version of lodash will have a function
called underscore attempt which allows
you to execute code and it will reach if
it errors it will return the error
object and if not it will return the
return value so that way if you're
developing your own code you don't have
to worry about that perf trap just use
the API and you'll get the benefit of
not D optimizing your function so that's
that's a nifty thing to do is do if you
have an exposed API have it do the heavy
lifting and anything that's going to
disqualify it and then pass it off to a
specialized function that doesn't even
care about it so like my specialized
functions it doesn't care it doesn't do
any checks to validate that the number
is actually a number I know by the time
it gets there it's a number it doesn't
do any checks to see if the value is
true the--like the collection is truth
it I do all of those checks ahead of
time and the other functions so they get
optimized they get in lined better
there's no disqualifications of
performance for them and so that's where
abstraction is really really good and
you don't get that whenever you in line
and try to do all that stuff yourself
right then all of a sudden the engine
looks at that and goes you I can't in
line this it's past my limit so v8 has a
limit based on the actual number the
actual character size of the body the
function body ie
chakra does is based on bytecode
generated I'm not sure what Firefox does
but it's basically small functions get
in mind better than large functions and
if you if you branch off for specialized
paths like the previous example with the
array branch and the the object branch
then that even the in line form of that
could potentially be in line as well so
that's that's cool
so that is abstraction alright the next
one is bye-bye built-ins and I just I
found this it took me a while to find
this juice but I liked it so it really
it fits with what I'm about to say so
before I develop lodash I looked at
native methods and the performance was
pretty crappy and it turns out they
haven't really been optimized over the
years
and it can affect depending on the
implementation in the engine like if
your function gets in lined or not based
on if it can cross boundaries of if the
JavaScript version if your built in is
implemented in JavaScript maybe it can
be inline better but regardless they're
always doing extra work that you're
normally not doing so that's not out
there not optimized for the common case
right
you're usually working with a dense
array you're usually not caring about
the dis binding you can do this a lot
faster on your own so in certain cases
where I've profiled the implementations
across multiple browsers and found that
JavaScript versions were faster I've
used them now that's bonus the the real
reason was I wanted a way to iterate
over arrays consistently and I couldn't
do that
with native methods or shims because
older versions of ie would have would
treat sparse arrays differently than
modern versions you could have an array
with an understandin undefined value
like a literal undefined value and older
ie so ie less than nine would treat it
as a hole in the array which would cause
iterating over arrays to be wonky and if
you use a shim you're gonna get that bug
there's no way around it unless you
treat all the raisa stints and so that's
where I was coming from and then I
looked at it and was like holy crap
that's really fast so awesome so I
started at it with consistency and then
the bonus was performance and if this
isn't like a ditch all your built-ins
this is profile figure out what's right
and what you can where you can squeeze
the performance and and add
functionality so for example I'm able to
add all this functionality to a method
and still be faster than native which is
great devs don't notice the difference
they get more functionality they may get
a speed boost that's bonus it's great
there's also cases where you don't want
to say bye-bye to built-ins there's some
that are really really cool and I'll be
talking about some es6 functionality
that's that's available in all modern
browsers right now that you can use
that gives you crazy performance and in
this case there's also some es5 stuff
too let's see if I get into that before
I go too far all right so here's here's
a filter implementation again a basic
implementation of filter this happens to
be crazy fast now what I'm not doing
here is doing any if you notice there's
no this binding that's because this is
that base method remember I created
those those those tiny methods that that
are called out to by the other functions
these are the these are the small
functions these are the optimized
functions all right so before I get into
the es6 i want to talk about the the es5
goodness so if you're ever iterating
over an object and you're doing for in
plus has own property that's gross it's
slow don't do it I would even say shim
it shim it and then use object keys
object keys is full of when when it
comes to iterating over objects you
can't get faster in your JavaScript
implementation of that there's no way
like it's just where where other
implementations have dropped the ball
object keys as is picked it up like it's
it's really the best method for that so
we use that internally lodash does so
for underscore keys if it's possible we
use native object keys now when you get
into edge case land there's some bugs
across browsers even modern browsers
when it comes to iterating certain
objects and so we fix some of those bugs
too so I'd say if you're using a low -
continue - we probably fix more bugs
than a shim would so that's cool also
another one is checking if something is
an array array dot is array awesome
awesome fast way to check if something
is an array the shim for that is really
slow but all modern browsers have it so
so take advantage of it and even older
browsers now have it because it's been
around for a while so as long as you're
not going so far back like like ie eight
does that happen I don't even know
anymore because I I do a feature test
for it and if it doesn't exist I have a
fallback and if it does I use it I'd say
try it out it's pretty cool but now off
to es6 in the
coolness that is available in all
browsers right now and the thing that I
really love in lodash is getting to
leverage set es6 set so what when devs
switched from underscore to low - the
main thing that they say improve
performance was large array iteration
searching for a needle in a haystack
basically so index of if they're having
to do a unique if they're having to do
an intersection a union anything that
deals with large arrays and looking up a
value in them we perform better and in
the next version we're leveraging es6
set instead of using our internal like
implementation of es6 set we're just
using the native because it's really
cool and I'll say explain why now so one
of the cool things about a set is that
it contains unique values inherently if
you push if you try to if you try to in
this case add but I've a listed this
push because I in the internal
implementation that lodash fuses we
think it's an array it looks like an
array because it's got the method I use
it if it if native set is supported then
I use it in place of the array that's
normally returned that's why I kind of
make it look like an array and that's
why if it's found it returns 0 and
negative 1 because index of is going to
return an index or a negative 1 and the
inter my implementation doesn't care it
just says oh this looks like it's found
and it's not that but anyways set allows
you to take to cram all kinds of objects
into it and it automatically rejects the
the duplicates so it's the sets always
going to have unique characters or
unique objects so if you want to find
something that's unique you just push
all your your elements into the set and
then you just read them back out right
and then you get your you get your
unique array and it doesn't do all of
this arrayed reversing like if it's a
thousand elements you don't have to sit
there for every single element and crawl
the array right that's gross this way it
allows you to to do it really really
fast and also when you do a set and
you're looking to see if an object
exists in there it's not having to do a
linear lookup it's just going hey is
this in my set yes alright it's not
having to go 0 is that there no one is
there know too is that they're so es6
set is great what I'm doing here though
is I've kind of hidden away the feature
detect but I detect if sets exists
earlier in the code and if it's not
shimmed because we want we want to
leverage the the native goodness right
so I don't use object keys if it's been
shimmed
because I trust my code better than some
third-party code right like we don't
know if they're using some old version a
prototype that's paved over he has five
methods with their own because they
didn't check to see if they existed yet
so we avoid doing that we say yeah let's
not use a shimmed method let's only use
it if it's native so I do that and I set
the value inside my closure per set so
if it exists it's truthy and if not it's
false II normally you would not want to
do that without doing checks and
assigning variable references because it
would be an undefined variable look up
and that's gross and your code will
error but I checked that it exists and
if it does I implement the method then
later on I say hey if create cash is
truthy because it's either going to be
false or a function then I use create
cash in my code and that is es6 set and
the reason there's there's probably
shorter ways of using es6 set right
there you can you can add values a lot
easier in certain sub engines that
support more of the es6
functionality but this is a this is the
the cross-section of functionality that
works in all modern browsers when I say
all modern browsers I'm probably
excluding Safari but whatever they're
gonna have Safari eight soon enough
right so feature tests for it use it
when it's available it's great so this
is a one from last year that I liked
enough to bring back because I got
outrage in the Twitter feed from this I
don't know if you can see that I'll
scroll in a little bit zoom in so before
I said hey if you're not using this in
this binding don't bind your functions
because it's slow you can detect that a
function has at this ref
in it because it's not quite SPECT per
se now es6 maybe does a little more but
if you to string a function it'll kind
of generate the function source right so
you can use a red X to say hey does that
thing have a this reference and if it
does then you can then you can know that
it needs to leverage this binding and if
it doesn't then you can not do it right
not do that call not do the dot apply do
the optimized code path right uh so this
was cool back then there's some problems
with it turns out that on certain
resource restricted devices like some
mobile phones and certain windows apps
you can't coerce a function to a string
without incurring a cost in some cases
it's loading bytecode in some cases it's
memory impact so I have some feature
detection now to kind of avoid this so
I'd say use with caution that's why it's
unorthodoxed because it's cool but yeah
so there's something else I've done here
too which is first check to see if the
function can be decompiled and so hey
I've got like this big like hey this is
the environments that support it yeah
and here's what I returned false for and
I'm testing my my one function to see if
they can recognize that this reference
in it now that function is crazy large
so if it can find that this value in
there then it's supported so I do that
but then there's something else too a
lot of times you're you're dealing with
functions that you can't store metadata
on and so that's something I'll be
talking about I've got like just a
couple of minutes left later is metadata
and so I detect if a function can
support the name property because if
chances are normally when you're calling
an array function or like a map or a
filter a lot of times that's just a
function that's created at the time of
at the runtime right like it's you're
passing it the function right there
so storing metadata it doesn't make any
sense because that metadata is just
going to be written to and then thrown
away so I detect if the function has a
name property and if it does I go okay
it's probably safe to write metadata too
and so that leads me into
the next slide and we're going to ignore
that because I talked about it
metadata so this
it's alright folks I got this metadata
when you when you create a function bind
or you do a partial or occurring or a
partial right you're wrapping the
original function right and if you call
partial on a partial or something that's
already been bound you're wrapping an
already wrapped function and so to avoid
that especially because deads like
functional programming right where
you're always carrying this or partially
that and then applying another curry or
partial on to something that's already
carried or partials the performance
impact of that is just bogging down the
function because you're going you're
having to twist through all these
wrappers to get to the original function
but if you store metadata on the actual
function this is what lodash does we
flatten everything down to a single
function a single wrapped single wrapper
around the function so no matter how
many times you call bind on an already
bound function or bind curry partial
partial right wrap any of those
combinations on a function you can call
them 15 times and wrap it 15 levels deep
it's only ever one function call away
from the actual original function and
that's because we store metadata on the
function that then flattens all of the
attributes down so this is why I
leveraged a bit mask for the first time
ever in JavaScript for me to implement
this and I thought wow that's what
they're used for instead of having like
eight arguments to pass to this function
I can just store all the configuration
inside a bit mask so that's what I've
done
I basically bolt on an array to a
function if object that defined property
exists because I don't want this
metadata to be observed through object
iterations so I make it a non enumerable
so engines that have that get that
benefit if not the function should
execute just like it normally does the
the metadata should not make this this
was tricky because before you could
leverage that metadata to do a lot of
cool stuff but it can't have any other
side effect on there you should be able
to be pulled out in your functions
operate so here is another view of that
and this is me doing things like
detecting values like cloning the
partial right arguments and cloning the
the partial left arguments emerging
arguments together it gets really trippy
and honestly I have to throw unit tests
at this but it allows that that really
cool flattening down of functions and
I've noticed that there's there's
certain engines that optimize like
native function bind this way to that
will no matter how many times you bind a
function it's a fixed cost to that
function binding and that's not
consistent across engines so I do that
here I deal with bit maths I try to
throw a bunch of comments at it but
what's great is that if you're if your
engine doesn't support it it doesn't
matter it pulls it out things still work
so that's really cool and let's see
things okay so I'm about out of time
there's low - calm there's the repo low
- low - if you go too low - itself
you'll find all the different builds of
low - so there's AMD there's npm there's
node there's es6
because in the next release we will
support a fully tested implementation of
es6 classes that you can use and then
try and use your favorite transpiler and
transpile to the module format of your
choice so we do that - also j/s perf
please use j s / f responsibly don't go
down the rabbit hole of micro ops like
profile your code first like wait wait
for your code to have a performance
issue and then use yes perf
to test different implementations of the
bottlenecked code like that's that's the
way to do profile your code first don't
go crazy like I get devs that little say
hey you could get faster execution of
this if you do plus plus vs. minus - nah
just just say no - micro ops test first
I'm competitive so I have to look at the
the library landscaped around me and say
alright their version is this fast
my version needs to be at least that
fast or better and Deb's will end up
building on top of a library that's why
I focus on some performance
but in in non in cases that that aren't
being built on like some more stuff
isn't being built on top of your stuff
just apply context to it like if this
code is only going to be executed once
you don't need to micro op that stuff
like who cares make it as functional and
Cheney as you want it doesn't matter
that the performance impact and then
also you can follow me on Twitter at
James Elton cool that's that's my talk
questions yes ah cool yeah so that's
another one of my favorite things but
it's not really perf but I'll show you
anyways okay so is Native here's how I
do that is native so that's not really
help you there either let's say this
there is Native equals here here's the
secret sauce I decompile a native
function I strip out any identifying
characteristics of that function so
right now I'm using what object-- up
prototype to string right so I've got a
reference of two strings somewhere else
up there that's why it's just this two
string and I remove the the two string
word from it so that means that it
should be generic enough to where any
other native function where I remove its
identifier from it she kind of looked
like that when I D compile it and so
normally when you decompile a native
function it'll go the function name and
it'll say bracket native code bracket
right that's that that's the normal case
but this using a red X in D compiling
the function will allow me to support
different cases because in certain
platforms it's not just native code
other libraries do this too like ember
will detect if it's shimmed and they
just use like a native code inference
and most of them do i saw a fork a pull
request on yui where they did this and i
loved it like using the the own function
source to extract the the pattern for a
native function was was awesome so i I
did that I added a little extra check to
in there for what RINO prints out where
I know in Java runtimes will add some
extra like for this or that into it too
so I strip that out but that allows me
to check because most most shims don't
shim the two string representation of
the function right and even if they did
later on down there where I'm actually
using it I'm using function dot
prototype to string call and that allows
me to bypass any custom to string they
have on that function so I can get
straight to the actual two string value
so no matter if they've even if they've
tried to trick me I can
still detect the custom or the the
native method I'm so yeah there's that I
don't know if I repeated the question
that whole thing was about how do you
detect a shim cool any other questions I
saw more hands that were up the first
time yes so that's okay
different parts of the try-catch can be
optimized by engines a different engines
do different things with that right so
like some some of them if you're not
throwing if you're not doing the catch
but you have a finally it may be able to
optimize it but I'm programming for
performance across the board and so
across the board that hasn't been
optimized away yet so that's why you do
it there are probably some limitations
to it like I don't know if they could
optimize the entire thing away I know
that there's I've seen resistance to
trying to solve that problem so I would
say that it's es5 methods aren't
optimized trycatch is a lot lower on
their list of things to to optimize so
the lovely thing about browser
competition is that if one browser finds
a way it puts pressure on the other
browser implementations because we're
very competitive so I would say that's
probably a good way into getting
something optimized is to get one of
them to to do the legwork and optimize
it and that will put pressure on the
other vendors that's also a good thing
to try to get it whatever you want
optimized included into a benchmark
because browser vendors love benchmarks
so I would say that's that's another
case - like hey try to do a pull request
against octane or Kraken or SunSpider or
whatever benchmark like WebKit's got two
new benchmarks right do do that there
and then browser vendors will pay
attention - so cool any other questions
yes
right and so by abstracting that into a
function itself though you avoid that
issue for other engines too so that's
why I instead of recommending like all
devs do that I made it into a like an
easy utility function right so then they
can just say attempt and it becomes just
part of their their normal sugar that
they use with a library and that way
they don't have to think about it like
hey is the engine optimized this yet or
not if they if they use the the utility
method they'll get they'll get the
optimization either way cool any other
questions
someone's scratching their head it's not
a question
okay cool thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>