<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Distributed Real-Time Stream Processing - NE Scala 2016 | Coder Coacher - Coaching Coders</title><meta content="Distributed Real-Time Stream Processing - NE Scala 2016 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Distributed Real-Time Stream Processing - NE Scala 2016</b></h2><h5 class="post__date">2016-04-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sQj-W_KXHDM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Peter and I work for cake
solutions we are ya company focus on
building reactive and data processing
architectures using technologies such as
color across park and many others and
this presentation I'm going to talk
about to distribute it stream processing
this area at X potential these days and
I believe you will find X 42 45 minutes
interesting so what am I going to talk
about I will start with the motivations
what are reasons behind is increasing
demand of real-time data stream
processing and how to address it then
I'm talk I'm going to talk about three
processing in jail why do we care why
should we care wherever possible use
cases and also provides of that after
that I like to talk about available fri
works with other similarities and
differences and also they're typically
use cases finally we will conclude some
general guidelines and recommendations
I'd like to say this talk is based on my
personal observation and opinions which
I have made when investigating how to
deal with steam processing and I'm
definitely biased in some way we are
facing huge increase in the amount of
data we produce we have produced
approximately eight data bytes of data
lies there so let's put it into context
to a little bit to make it more
descriptive every minute we create two
hundreds millions of emails 48 hours of
YouTube videos and also we are able to
create Google two million times but a
question is how can we make sense of all
this data because most of data are not
interesting and also knew the new data
supersedes the old
and how is it all possible many new
sources of data became available for it
for example everyone has a smartphone
and every smartphones for Sanders or the
bad seeds also pages are created every
day or the social network to huge game
changer years many everyone is exposed
I'm pretty sure we can find many other
examples but these new data sources also
bring us new challenges for example of
that social feed mining tremendous
amount of useful information available
or written data as is in general we can
go for detection we can analyze trends
or we can do some kind of processing and
so on so as we can see there are so many
options and of course sleepers are
saying is the answer or rescue they want
to process incoming data on fly without
panel and storage the volume of data
could be very high so we are going to
need a lot of resources for that and so
we must be able to be must be able to
scale accordingly and of course we want
to be able to react to events as they
occur as late as light answering matters
here so let's briefly talk about typical
examples of streaming applications
firstly a great example ETA operations
like joining filtering or various
transformations of incoming data so
basically taking data from the source to
the operations we want and then set out
from the system a system to something
like Kafka or how Google water we need
are we doing typical operation winnowing
means we take an interval or window we
want let's say five seconds or two
minutes and then we perform operations
on it's like training to eat or turning
sales and other great examples of
streaming applications can be like
machine learning or pattern recognition
machine learning is quite a trendy area
these days and of course we can apply it
in the context of stream processing we
are able to do Custer in regression or
classification on incoming data also
part of regulation my status as a rare
example sure it is not as fancy as
machine learning but its applications
like fraud or animal detection
if we use for all last year's new
architectures were developed to address
various problems we have had so let's
have a look at the emotional processing
architecture match pipeline has a large
scale it doubles such as HDFS and many
technologies to learn kinetic jobs over
it it works well fine but it's participa
popular at them to address the slowness
of batch pipeline in standard
architecture it's adds a streamliner to
get a possibility everytime queries so
basically we grew two different systems
together trying to get best of both
worlds sloper accurate results from much
later and fast but somehow approximated
results from stream where problem is we
usually have to call it vice which is
pretty painful moreover writing
distributed algorithms is complex and
doing it for two different paradigms is
even worse there are a couple of tools
trying to solve this allowing us to
write coach as ones making things
definitely better but even if you can
avoid code in your application files the
operational board of running and the
back into system is going to be very
high so I taken architectures a
reasonable solution from times we have
no better tools available but I firmly
believe we can do better these days so
let's talk more about streaming start
thanking basic stand on design meaning
we have an increment data from various
sources which we can plug in directly to
our stemming systemic system our as it
has a little bit more common we can use
some kind of broke like Kafka and then
reprocessing or we can design our system
in ovine known as a cup architecture
couple stores data in something fast
that supports streaming the stream is an
immutable soul of truth and as well as a
source for up data for the other systems
the data can be processed queried or
replied and finally end up in a data
store a datastore can be used as a
source for separate queries where
different characteristics and guarantees
as you suspect is to pedestrian
processing is continuous processing
aggregation and analysis of angola data
as a general computational model
Asmodeus but we explain latencies in
malice or in seconds the systems are
usually model as directed acyclic graph
da cheese or dogs jack is a graphic
representation of share of task and we
use it in for description of the
topology of streaming job I'll have
myself terminology from a customs a
little bit but I think you'll be clean
anyway so as you can see the picture
data flows through channel processors
from sources to things and this
represents the streaming task and
speaking about cut streams I think it's
very important to emphasize the world
stability because even local solutions
can create a hang tag but they are going
focus only two solutions running on
multiple machines when choosing between
the Francis then there is a couple of
points which you take care of so let's
start with runtime and programming model
the programming model provide well apart
from retirement or all of its features
and it should be sufficient to handle
all possible use cases for application
this is a really crucial topic and I
will come back to it very soon the
frictional primitives exposed by
pressing platform should be able to
provide utage functionalities at
interval message levels like map or
filter which are pretty easy to
implement even if you want to scale a
lot but another up with it should also
provide a code message functionality
like aggregations and accurate stream
operations like joint for example which
are much harder to scale for state
management model application have a
stateful posting object that requires
mental state the application should
allow us to maintain access and update
estate information for message earlier
grantees we have a couple of classes for
red like and most ones and these ones
and exactly one's an important thing to
consider fellows will can and will
happen at various levels like network
partition disk failures or not going
down and so on platforms should be able
to recover from all such failures
risen from that process will stay before
harming the result and Jeremy have more
performance related more performance
related requirements like latency
throughput or scalability which are
extremely important and streaming
applications which was to take care of
maturity and adduction levels which this
information could help us or give us a
clue about potential support available
libraries or even stucco for answers and
so on and also all that release the ease
of development and ease of probability
is gradual when we have super fancy
system which covers all those cases but
if we if we cannot write a program for
it or EV Cal deployed we are done anyway
let's talk about runtime and programming
model which is probably the most
important trait of the system because it
defines is expressive as possible
operation and future annotations
therefore we define system capabilities
and its use cases there are two
distinctive approaches how to implement
streaming system first one the native
streaming it means all incoming records
or events if you want our process as
they arrive one by one second approach
is called micro batching show batches
are creating or from income and I close
and go for the system these batches are
created according to predefined time
constant typically every couple of
seconds both approaches have advantages
and disadvantages so let's start with
negative streaming the gradient the
great advantage of native streaming is
its expressiveness because it takes the
stream as a test is not limited by any
amateur abstraction over it also as the
records are processed immediately upon
arrival achievable latencies of these
systems are always better than its micro
batching companions apart from that
state flow operations are much easier to
implement as you will see in the next
couple minutes a native streaming system
have usually low throughput and fault
runs as much more expensive as system
has to take care of every single record
also balancing this kind of issue for
example I'd say we have a data partition
by okie and we want to process it if the
processing of some cuter partition is
more resource intensive for any reason
this partition quickly becomes jobs both
like splitting stream into micro batches
inevitably produces systems
expressiveness some operations like
especially state management or joint
ends plates I much harder to implement a
system has to manipulate the whole batch
moreover the batch integral connects two
things which should never be connected
and infrastructure property and a
business oj under control a photo runs
and advancing my simpler as system just
sense every batch to worker node and if
something goes wrong it just uses
different one and lastly is good to
remark we can build microbe etching
system atop native streaming quite
easily and programming models can be
justified as composition and declarative
compositional approach provides basic
building blocks like sources or
predators and they must be tied together
in order to create expected to poach a
new components can be usually defined by
implementing some kind of interfaces on
the contrary operators a ducati api i
define as higher order functions at all
those to write function code with
abstract types alone is fancy stuff and
the system creates optimizes to purge
itself also the code baby is usually
provides more advanced operations like
been doing or statement state management
out of the box I'm going to show you
some cool samples very soon there is a
number of diverse frameworks available
and is that are impossible to cover all
of them in just one session so I have
been forced limited somehow and I
decided go for popular streaming
solutions from Apache on skype therefore
we are going to focus on apache storm
and its sibling trident and on streaming
module of very popular spark we are also
going to talk about steering system
system the Harrington name Samsa and
finally we will discuss promising Apache
project flank
I believe is a great election because
even if all of them are streaming
systems they approached various
challenges very differently
unfortunately i won't talk about
repertory systems like google million or
a monkey noises and also we are going to
miss interesting but still a method
update systems like interview pump or
about GI packs so that's maybe for next
time i purchased almost origin created
by nine miles and his team at bag tied
in 2010 later it was excited opus all by
twitter and it became de facto
industrial standard and hence
reprocessing storm is a native steering
system and provides provides over the IP
I also stream uses for PG definition and
it also implements strong multi-language
protocol this basically tells us to
implement our solutions and large number
of languages which is pretty unique and
color is of course one of them tryla is
high-level microbe etching system the
top storm simplifies to pooja billing
process and also adds high-level /
ations like with doing aggregation or
state management which are not natively
supported in storm addition to storm
planet provides exactly ones diverged
semantics and try that has java closure
and scholar AP is as we on own spark is
a very popular batch processing flavor
these days with a couple of build
libraries like sparks equal or mmm lab
and of course parks Deming Paris on time
is built for batch processing and
therefore spark stemming as it was added
a little bit lighter does microbe a
chink the stream of input data is
adjustable receivers and which creates
micro batches and these micro batches
are processed and similar way as other
spark jobs spark streaming provides high
over the creative API and color java and
piping
Sansa was originally developed in
LinkedIn and as a proprietary streaming
solution arif Kafka which is another
great linking contribution to our
community became key part of their
infrastructure as you was going to fill
the blighter sums up builds heavily of
Kafka's log base for Sophie I both
together integrates really well also
some that provides compositional API and
the husband at least flank fling this
particular project it has its origin in
2008 and but right now is getting fight
a lot of attention Frank is negative
steering system and provides high level
API 3 also provides API for batch
processing a spark but there is a
fundamental distinction between those
two fling handles batch as a special
case of streaming so everything is a
stream and this is definitely by the
abstraction because this is how the
words that I looks like so they also pay
interaction over the systems and as you
can see in a table that you have pretty
different right so now let's have a look
at code samples and of course nothing is
more important than counting the words
you know what time is something like
hella worth of data processing so let's
type of storm and please note the
example will simplify simplify it
significantly first let's a howl at this
topology definition as you can see we
have to define a spa or if you want a
source and then there is a boat a
processing component which splits the
tags into the world then I have to find
another board for actual world health
world count word count calculation also
have a look at at the magic numbers 5 8
and 12 these are apparent hints and it
and they defined how many independent
friends Andrew Custer will be used for
execution of every single component as
you can see always very manual and level
now let's focus on how is the actual
work on both implemented
as long as Tim does not have building
support for vonage state so i have
defined a local state which is far from
big idea but with example apart from
that is not very interesting it's just
just a simple Java so let alone and have
a look at trident as I mentioned before
try that a storm of micro batching
extension and try that apart from any
other goodies provides state management
which is pretty useful and implementing
would count as you can see there i could
use high level / a shins like each and
goodbye so it is a little bit better and
also i was able to straighten managed
state for storing account and now it's a
time for a pretty declarative api
provided by apache spark also keep in
mind when i come try the previous
example which were all i simplified this
is nearly on code you need to run this
simple streaming word count every sparks
them in job requires streaming contact
which is basically the entry point to
the swimming punctuality swimming
context the configuration which is as
you can see in our case we're limited
but more importantly it defines its
batch integral which is set to one
second and now you can see what time
computation you know quite a difference
the that's a reason why Sparky sometime
called distribute its color as you can
see it's quite standard function code
and spark this kind of topology
definition and a distributed execution
and at last part of every super
extending job start a new computation
just keep in mind one start the job
cannot be unified and now let's look at
apache Samsung and I'll representative
of compositional API the topology is
defined in some such properties file so
you won't find it here but for us is
important the task has defined its input
and output channels and communication
goes through Kafka in our case whole
tube or JSON don't ask which does all
the work and sometimes components are
defined by implementing particle
interface
in this case it's a the streaming task I
have just over the method process its
permit release contains always need for
connecting with the rest of the system
and the completion competition itself is
just just a simple scale and now let's
look at link as you can see API is
pretty similar to spark but notice we
are not setting any batch interval
computation itself as pretty
straightforward as you can see there's
just a couple of couple of lines of
functional calls and fling takes care of
the rest surrendered knowledge of time
to have a look at more interesting
problems of stream processing starting
with photo runs for trans and streaming
systems is enhancing hardening batch
when facing an error in batch processing
system we can just restart failed part
of the computation and we are good but
this is much harder in streaming
scenarios because data are still in
coming and a lot of jobs can run 24 7
and another challenge we have to face a
state consistency because in the end of
the day we have to start a plank events
and of course that all state operations
are I'd important as you will see for
drones can be pretty hard so let's look
how our systems will deliver that still
uses a mechanism of upstream backup and
recovery acknowledgments to grantee the
messages are reprocess after failure
acknowledgement works as follows and
operators and back to the previous
operator an acknowledgement for every
record has been processed the source of
the topology keeps a backup of Oracle's
it generates once receive
acknowledgement from or droid to the
records and Angelo sings the backup can
be discarded safely at failure if not
all acknowledgement have been received
then the records are applied by the
source this grant is no data loss but
just result in duplicate records passing
through the system
it's basically elephant ivory stone
implements this we have a kind of
mechanism of upstream with michaela that
only requires a few bytes per storage
parcels or equal to trigger
acknowledgments and but in general
political acknowledgement architectures
regardless of their performance value of
fighting exactly ones guarantees to the
border link application developer with
load application also stole my crimes in
Israel throughput and has problems at
full control as the acknowledgment
mechanism often hosted classifies
failures under big pressure spark
slimming and it's michael batching
semantics for a different approach the
idea is terrible simple spark process
micro batches on various volcanoes and
each micro batch may either succeed or
fail at a failure the micro batch can be
simply computed as they are possessed
and and immutable so basic exactly
exactly once divert I made it very easy
some such a probe it is completely
different it takes an advantage of the
rebel offset based messaging system is
usually capco of course samsung monitors
offset of this task and moves it when
message is processed also can be
checkpoint in persistent storage and a
restore in case of failure the problem
is when it restores offsets from the
last checkpoint it does not know which
upcoming messages where process and it
might do it twice so that's at least
ones develop for us flags approach is
based on distributive slap shot which
keeps the state of streaming job Flinx
and chick boom barriers basically some
kind of markers through the system and
when body reaches the operator operate
the checkpoint corresponding part of the
stream so if you compare it to storm
it's far more efficient as it does not
have too much acknowledgement every
single record but does it in small
batches but only confuse it's delayed
streaming it's conceptually it's very
different from spark
and so fling provides exactly once
delivery most of the non-trivial
streaming application has some kind of
state on the contrary of the stateless
operations then we have just an input
processing and output we have an input
and a state then we do the processing
and then we have output with a modified
state we have to measure our state
pursues it and in case of failure big
spider state to be recreated the
recreation of the state may be a problem
little bit as we do not always exactly
once grantee some of the records may be
replied multiple times and this is what
not what you usually want as we know
stone provides at least one's delivery
guarantees so how can we actually
exactly one semantics provide by trident
conceptually it's quite simple you just
start committing records but obviously
it is not very efficient so you start
doing in small batches then we do some
optimizations and here we are trying to
find a couple of abstractions which
determines that when we can achieve
exactly 1 guarantee and as you can see
the picture to have some limitations and
take some time to dig into it when
thinking about state operations people
think we usually have organic operator
with a state and steep of Records
passing through it and as we know most
parks timing is micro bashing and system
and its implemented differently
basically spark streaming takes manages
a state as another microbe extreme so
during the processing of each micro
patch sparked a the current state and a
function representing the operation and
result is a process micro batch with an
updated state
sometimes solution for everything is
just push it out to Caprica and problem
solved and also works in the context of
state management Samsung has real estate
for operators so any task and whole
estate and the state's channel is pushed
to kafka if needed that can be easily
recreated from Kafka's topics to make it
to make it a little bit faster sams
allows us to plug in key value store and
so good storage so it doesn't have to go
to Khafre all the time unfortunately
some sub provides at least one semantics
only and it hurts hot but the
implementation of exactly one's delivery
is planned flink provide state to
operators commute actually very similar
to Sansa when working a flank we can use
two different types of State first one
is local or task state it's in current
state of particle operator instance only
and you know these guys do not interact
between each other then we have
partitioned or you want a key state
which maintain state of whole partition
and of course fling provides exact
valence semantics so now let's have one
more look how to convert this time will
be more stayed focused so let's start
with Trident you may have seen asleep at
already as it is fairly similar as
before we can create state by calling
President aggregate important argument
is the count which is built in component
for storing numbers if you want to
process the data from it you have to
create a stream for add as you can see
is not very convenient it's part of the
collective approach is a little bit
better firstly we had to create a DD
used as initial state then we do some
information or whatever then we have to
define transition function which takes
the word its count and a current state
this function does the computations
update the state and returns the result
and finally we can put all the bits
together and get a stage 3 which
contains world count and now let's have
a look at Sam's ax firstly we need to
define our state in this case it's given
store and also we have to define how it
should be initialized and then we can
use a drink computation as you can see
it's / this day forward just a few more
points and finally let's have a look at
flank flink provides very neat API we
just call a function of state which
takes as an argument function with two
arguments first one is the word to
processed and second is a state function
then returns process output and a new
state
I didn't wanted to show you some nice
performance comparisons but i will not
reason the comparison is a topic maybe
for all talk so i will do it here but a
couple of guys did it already so i'm
really happy to reference them but for
now just just in general when we talk
about performance in streaming we talk
about latency and throughput it depends
on many variables but in general and for
very simple task you are at 5k records
per second panel is ok if you can reach
1 million it's nice over a million it's
great and speaking about notes I mean
pretty standard knows like 24 course or
an reasonable amount of memory like 24
or 48 gigabytes for identity in case of
micro batch we we are usually faking in
seconds in case of native streaming we
can expect latencies in lower hundreds
of millions for most of the systems but
tombstone can operate in tens of malice
easily also it's important to keep in
mind the cause of delivery guarantees
for trans and state management put for
example turning on for trans men koze do
like ten to fifteen percent but in case
of storm and it can be like seventy
percent of your fruit so as always
nothing comes from free during the
throat I've shown you safely and
stateless both count examples and of
course taylor's would be faster in case
you're wondering how much so in the
context of budget flank your friend was
like twenty-five percent but in case of
spark it was around fifty percent i'm
pretty sure this could be tuned but it
could it could give us an idea it is
something we should have in mind and
speaking about during all systems have
very rich tuning options which may lead
to significant performance gains and you
should always find some time to have a
look at it also is an important time in
mind all purge all operations are
distributed and send the data through
the neighbor
rick is pretty expensive so try to take
a take an advantage of little card day
and also trying to tune of your
application sterilization just load of
to discuss the good performance so I
hope I give you basic ideas what to
expect but we have to move on when
picking of the framework for application
you should always consider its maturity
so let's have a quick look how does it
look like in our cases stone was the
first mainstream mainstream stemming
system and is used by many companies
like victory yahoo Spotify and many more
spark is the most telling Scott
repository these days and one of the
engine behind behind Scott's popularity
spice adoption grows every day it's used
by companies like Netflix is curator
Starks Intel IBM and so on Samsa is used
by Lincoln I like tens of other
companies as an example we can have like
that flakes or where flink is still an
emerging project but we can see its
first production deployments and I'm
sure more will fall soon for example i
heard that amazon was avoiding it right
now so we have just finished some basic
comparison of chosen systems and we
discuss how we approach butter with
challenges which needs to be sorted out
when implementing slimming distributed
stream processing system now you may
have a quick look at a summary from an
opinion dare to trade now is the time to
move on to last part of this talk
rainbow recommendations i have to say
this part is the most opinion based by
far but i was very trying to be fair so
as more the answer for typical question
which one is the best or which one
should i use is as always it depends so
in general always try to avoid
requirements of your application careful
and be sure you fully understand the
consequences of choosing a particle
framework i would also recommend you to
pick framework we've hired a p.i as it
is little more again and more more
importantly much more productive also
keep in mind the the most of streaming
application are stable sort of state
management of a particle framework
should be up on your evolution list i
also recommend go for a framework with
exactly ones delivery semantics as it
makes things definitely easier but of
course this really depends on particle
requirements data files use cases when
at these ones or at most once semantics
or guarantees are all you need we also
keep in mind system supporting exactly
ones does not have to support weaker
guarantees as to make sure your system
is able to recover quickly you can use
cos Monki or similar tools for testing
because also discussed fast recovery is
crucial and stream processing
so and now let's he'll look at
particular frameworks storm is still a
great fit for for small and fast ask if
you cram enable up late and say store
might be a good way to go but also keep
in mind the photons or train instead
management how is the powerful magnet
volts interesting option might be your
potential update to Twitter's Iran which
is designed as a storm the placement and
it should be better in every single
point but it also gives the API problem
is there is no guarantee peter is going
to open source it so who knows if this
is a really good idea for spark
streaming and you should definitely at
least ripe if spark is already part of
your infrastructure because in this case
streaming comes basically for free and
you can also take advantage of values
Park libraries also if you really want
to use on the architecture it is a
pretty decent choice but you should
always keep it mind micro battery
limitations and be sure latency is not
critical for you when thinking about
editing some time Kafka should be
poorest on over architecture I know it's
what you do but nearly everyone and make
me everyone is using Kafka so I was too
good at all so as mentioned before
sometimes shipping powerful local
storage and it can hello States in tens
of gigabytes easily which is pretty nice
but keep in mind sometimes at least once
the limitation flank its contractual a
great living system which covers very
most use cases and you often provides
progressive punctuality which might not
be implemented by its by its competitors
so you should always come to the flank
when you need a functionality which
might be hard to implement spark or in
general in any other micro batching
system and apart from that fling has an
API for common batch processing and
which may be pretty useful but you need
to have enough courage to adopt imagine
project and also don't
have to check out its own map
and last thing I want to mention today
is data flow and it's open source
initiative data flow is part of google
form and copper form has all sorts of
things in it as a huge data store big
fella called pops up some tools for data
analysis and so on and also
aforementioned cover the flow as
Google's managed service for batch and
stream processing with unified API and
it's built upon one on Google
technologies such as MapReduce for back
to the sink from jump from Java for
programming model definition and
millville for still possessing and
ultimately good you may be asking why
i'm talking about that as i said i will
be speaking about open source framework
and this is clearly google proprietary
solution but google decided to open
source data for sdk recently and guys
board behind spark and flank and have
implemented a trainers so now we have an
ability to run jobs define later for api
in google form in flank orange park it
also possible that more engines will
fall soon data flow provides api in java
and python implemented by google itself
but i have also found to do cells and in
schow implemented by community apart
from that google and the number of
partners submit that this as you
approach a proposal named apache bean so
it seems as a pretty interesting option
but it's very important to emphasize all
this is very recent and diplomat of some
of the promised features might be
missing
so now it's a type of question so we
have a name but I think I'm a little bit
behind schedule so so just family
somewhere and we can discuss various
things later so just find me so thank
you very much for attention I hope it
was helpful for you and also we are
hiring so if you if you like to join us
just so link we do a pretty interesting
stuff in cake that's all from me thank
you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>