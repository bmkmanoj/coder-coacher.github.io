<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What's New in HTML5 Media | Coder Coacher - Coaching Coders</title><meta content="What's New in HTML5 Media - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>What's New in HTML5 Media</b></h2><h5 class="post__date">2012-01-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/VP0SV3YWOWA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Paul Kinlan I'm a developer
advocate at Google and this is pretty
much what I do most of the time so I
come out and talk to people about what's
happening html5 JavaScript in the web
browser land and I'm also lucky enough
to work on a couple of spoil once back
in particular the web intents spec but
that's kind of cool right but we're
going to talk today about what's new in
html5 media the interesting thing about
this is that quite a lot of this is
literally just Landin in chrome right
now so some of this isn't usable some of
this is mainly in the dev channel or the
canary channel of chrome we're hoping
that some of these things come to other
browsers as well at the same time but
before I start I would like to show you
one thing it's a plug we're trying this
idea of html5 search this is just a
Google custom search engine but the idea
is that you know you're looking for kind
of information on the section article or
canvas you normally get a whole lot of
extra resources that you don't quite
like this just indexes things like the
don't you know the w3c spec html5 rocks
a couple of the best kind of html5
resources out there and so I just kind
of I'm going to encourage you to tell me
which of the kind of the sites that you
learn from the most preferably not w3
school is anyone from w3 schools here no
good preferably not from those kind of
sites okay theory the theory about this
is it's all on github so you know if you
want to make a change you know you put
it on github I'll pull the change back
in and then we're going to make the kind
of the html5 learning space a little bit
better for everyone else but thats html5
search com that's the side that I set up
quickly but let's get into the media
side of things so 1805 media most people
know that to be generally the video tag
or the audio tag but actually it's quite
a little bit more and hopefully i'm
going to show you some of the stuff
today there's a legend that goes along
with some of these slides the thing that
looks like a radar means it's not
quite ready yet but it's going to be
there soon the book means it's there is
a book for it it's going to be tracked
in WebKit hopefully we'll come to
different types of devices whether it's
Chrome Safari iPad those type of things
things like the book has been resolved
are fixed you're not going to see in
many of them actually and then sometimes
you got things like specification links
i will share the URL at the end of this
so that you can actually try some of the
demos there's a whole lot of inline
demos with this talk so this is me if
you have any questions during the
presentation just shout them out you
have any questions after and you don't
manage to see me or something catch me
on Google+ or Twitter yeah just just
email me as well Paul Kinlan at google
com yeah we're going to talk about
multimedia multimedia capture WebRTC did
anyone see an announcement for a WebRTC
to yesterday I think on Chrome I did
have a demo for you what I can't show it
because Eric who was supposed to be
doing this talk didn't send me the
server we're going to have to imagine
that it's like the best demo ever so
it's kind of cool and then the Web Audio
API so I just want to ask everyone is
anyone used any of these api's at all in
kind of in production code like Web
Audio know so actually this is going to
be kind of new for most people which is
kind of cool so the multimedia helpers
right so the first thing that we've got
and this mainly is for interacting with
the canvas and WebGL I think a while ago
there was like a security it like a
security issue with content pulled in
across the web into WebGL because it
would get access to your your actual GPU
so they introduced this idea of a cross
origin specification into the image tag
so that you could basically say I trust
these certain images on the web to be
loaded in put under canvas and then I
can extract the data back out of canvas
because the important thing to remember
about the canvas API is that it's
painted so if you load an image from
inside your domain into the canvas you
can manipulate the data you can pull the
data back out and kind of you know do
whatever you want with that data that's
on that canvas element if it if any
cross origin data comes in from another
website into your canvas which you can
do you can load a remote in
into your HTML canvas you can't pull any
the data out you can't do this to data
URL the two-day to URL is a base64
encoded string of the image but now you
can so the idea that is that we want to
be able to safely pull image data in
across the web from different domains
manipulate it in the canvas element and
then pull that back out so that we can
save it may be back to our server so the
first thing that we're going to talk
about is this whole cross origin element
this is the code it looks very much
exactly like the normal code for canvas
apart from we say cross-origin anonymous
or you can say use credentials and then
you can load the data in from the site
there's a couple of Haiti keep of things
you need to do but it's not that bad
this is a demo it's not the greatest
demo but hopefully it'll show you what
it means with no cross origin we get
security exception so we've loaded some
data onto a canvas we're trying to pull
that data out and normally what happens
is you get a Dom exception which means
that you can't actually basically saying
you can't get access to that data and
that's just a normal image on the same
domain and this is the cross origin so
we pulled that data in from the web if
we have we click this link you date URL
right and we show you here this is
showing you the actual full URL the
base64 encoded data it's not the
greatest demo but this is the data that
specifies that image after it's been
pulled back out of canvas so we've
pulled data from one remote web service
pushed it into our canvas and then we've
been able to pull that back out it's
kind of nice if you're trying to do
anything with graphical manipulation and
loading data through it just means you
don't have to proxy the kind of the
remote image for your own server and
push it back in it's kind of cool the
next has anyone seen the page visibility
yes sometimes there is sometimes you to
put little HTTP header in that just
basically says yeah by the access
control and then it pulls it back in I
yeah it's not on kind of any of our
services at the moment but we're trying
to push to make that happen the
interesting thing as well as anyone seen
the page visibility API now is it one
person way cool so the page visibility
API is basically an API that tell
you as in you as the developer inside
your page whether the user is actually
looking at that page or not whether
they've got that in their tab and it
simply it's simple event its visibility
change event and then you can detect
whether basically the tab is visible or
it's invisible the demo that we have is
a kind of nice demo by one of my
colleagues hoping this works page
visibility so cool plane right listen
you can hear the audio in the background
here we click taps the audio stops and
that's because they're basically the
code inside that page says don't play
the audio don't play the video whilst
the users not watching that's not
actually on that tab we jump back and
notice the title in the top corner here
resume in resume in seven seconds we
jump back and it continues playing and
that's all because we've got the ability
to actually detect whether they develop
whether the user is actually on that
page not so it's kind of nice I mean I
can imagine one kind of advertisers 20
uterus thing to say well you're not
actually on the page looking at my
advert so I'm not going to play you the
kind of the rest of the clip until you
come back to the page so it's kind of a
it's it's not great at it's not a great
API up in that context but you as a
developer you can do things like if you
look for instance if you look at a whole
lot of the games in the Chrome Web Store
you'll notice that they play audio when
you're playing the game you move tab a
stop the audio that's because they've
been able to detect that the user is no
longer on that page and pause the game
it's kind of a nice API in that sense
requestanimationframe is another one
it's kind of it's kind of important this
because this is used for animations
right that's the main thing about this
and if you can combine it in with the
page request API but the interesting
thing about this is that you actually
ask the browser to schedule an update
for when the next kind of frame should
be rendered and which is different from
set timeout set time are basically says
I need you to try and execute this
function every sixtieth of a second or
every 10 milliseconds and the
requestanimationframe is much more like
well I'm going to ask you to render the
frame as in i'm going to ask the browser
to render kind of my next piece of logic
my next kind of drawing command and then
let the browser decide when it should do
the interesting thing about this is that
because you're asking the browser to do
the work it knows a whole lot of things
that you don't know about the machine
for instance like the refresh rate of
the monitor so it will try and lock the
number of times that you can call your
call back to say 60 frames second so if
you're doing a game this is kind of
important right so you want to lock your
game to the vertical refresh rate of
that your monitor and you can do that
with the requestanimationframe the other
interesting thing as well is that it's
like it can act like the page visibility
API so when you're not actually looking
at the page it can say well you know the
user is not actually looking at page i'm
not going to schedule the next call back
to actually render the next frame until
the user is back on that tub so it's a
nice little API it's a lot better than
the set timeout and it's kind of locked
to about 60 frames a second we have a
demo again it's not the greatest demo in
the world but if we go here you know
about 11 milliseconds per request and
that's because we've said you know every
10 milliseconds you know call the
callback do the call the draw function
we use this new hotness which is the
requestanimationframe Wow okay so I
don't know why it's on my one but it's
locked at 30 frames a second that's
because the browser is basically saying
you know you can all you need to do the
update 30 times a second which is it
which is completely different to this to
the first version it's kind of
interesting normally when i run this
demo its 60 frames a second and but
today is like it's gone crazy about 30
times a second that's kind of
interesting the media fragments this is
actually brand-new so the media
fragments api and you probably you
probably seen this in youtube where you
can specify like a range of when the
video should start playing basically
there's an API that's a standard kind of
interface for you to specify what range
the video should start paying for the
user when they actually load your page
with a video element in so if you look
can anyone see this code I notes of this
Malcolm to zoom in so if you look at the
very top one which says t t equals 10
comma 20 that basically means just play
the video from 10 seconds to the 20th
second not sweet but right this is gonna
sound silly right so when you say in
America through 20 does that mean
220 yeah so that's fine right because
it's different in the UK so this is
pretty much knew it's a nice way of kind
of just specifying like indexed points
inside a video we never really had that
before to do this kind of thing you have
to try and move with a piece of
JavaScript 10 seconds into the video
when the page loaded it's kind of nice
it says it's implemented in Firefox it's
in the WebKit Knightley's pretty much of
it in a WebKit nightly or being Chrome
Canary actually I won't ask question so
who uses chrome quite a few people good
sweet who uses prone be channel couple
people dev channel two three four canary
oh cool so can I always kind of cool
because canary basically is his bill I
think about every 60 70 commits I'm not
exactly too sure but you're pretty much
getting the latest code that's been
committed into our repository that's
deployed every just ate every day so
basically you're getting a new update
every day at the latest version of
Chrome so you get to test a whole lot of
these things there's a whole lot of kind
of api's that we're talking about now
which we haven't enabled in the dev
channel the dev channels about once a
week update so if you really want to
test some of these things out the canary
channels are good one one of these
things in particular is the track
element so the track element is it's
like subtitles but actually the easiest
way to say it's subtitles you can
specify a VTT file which is basically
the this file here which tells the
browser if we zoom in zoom in which
basically tells the browser when to play
when to put some text next to a video so
you have like time offsets so this is
the first half a second to the second
second it basically just says that it
will say the web is always changing this
is great for accessibility you know
before this came out videos weren't
really that accessible to people who
couldn't actually have you couldn't
actually watch the video because they
have a visual impairment so I sure i
will show you the demo let's have a look
so that's what I mean it's not the
greatest kind of sexiest Emma but this
is actually a big step forward for
accessibility we have the ability to put
these subtitles in the video and let
people do stuff with that it's actually
kind of nice screen readers yes Queen it
it depends on the screen reader right
you're the screen reader has to make
sure that they can pass this I did
actually say visual impairment people
with a visual impairment wrong because
they won't be able to be the text
hearing impairment so you kind of you
can't hear the video you can actually
see what's happening there yep
I will tell you so at least 18 canary is
probably a couple of versions back as
well I say versions canary builds back
I'm told this will London the dev
channel pretty soon if it's not already
in there but essentially this is a track
element it's a HTML HTML element you can
specify the language it's in so you know
you can localize the content based off
the users language it's kind of cool
right its basic quite simple the really
interesting thing is actually the API
has a JavaScript or the element and the
kind of the API behind it is a
JavaScript API and the thing behind this
is basically it says every time the Q
which is the piece of text we saw in the
previous slide every time that changes
the browser is detected when it should
change you can get an event which means
that you can do some really nice demos
which I hope is this one yeah we don't
need the sound but this is kind of
interesting because if you notice it's
not the same track element which is
across the top the interesting thing
about this if we jump into devtools
let me just get
so the really cool thing about this is i
mean just zoom in because it's hard to
see is that because we've got the on
change event happening we can we can
update the doll so that we're updating
the dom and because we can update the
dom means we can do some nice styling
for as well it's a very basic effect but
it looks kind of nice it looks really
good the javascript is here it's
actually quite simple they track on cue
change and then basically we look at the
actual individual queue and then we
insert it into the dom and then we can
style it up from there it's really
simple it's really a key it's really
really simple it's kind of nice we just
jump the next one here we go so the
theory behind this is yes yes
I think that is still the case actually
no it's not the case because this is on
my own personal server and I'm not set
the mine type that's actually that's a
good question so has anyone ever used
that cash yeah so apparently we've got
rid of that from the spec as well but
yeah so just basically reads it into you
ask without cash I believe it's a
similar thing because I mean app cache
if you've ever done any offline work
with html5 app cache was a is a
nightmare not only because the the
format is a bit well it's a bit it's a
bit difference the way web developers
normally work but you have to serve it
with a very specific mimetype and that
caused so many like so many developer
pains as well and I didn't realize that
you had to serve this one with a
different mime type I don't and it still
works I would have to check i would have
to check I've not read the standard on
this one yeah I expect that chrome tries
to follow it the spec because art
unfortunately our implementation at the
time of app cache still requires the
actual thing even though it's gone so
hoping we're going to remove that soon
so the media source API streaming is
kind of interesting the whole bar the
whole idea behind this API is you can
say to a video where the data source
comes from normally traditionally the
data source is a URL so it's some you
know file on a server which the browser
will end pull in the media source API is
brand-new the whole idea behind this is
that you can actually specify how you
want data to be loaded into the video
element so the theory behind this
actually is that you could say well you
know we want to do some basic kind of
quality of service kind of rendering
will have three or four different types
of quality of video high quality video
medium quality and low quality low
quality video you would then go and
fetch the kind of the source block so
like a frame or a couple of a couple of
seconds of data from the server via an
XML HTTP request and then append that
data from the xmlhttprequest into the
video and it's it's a very put it's a
very basic idea of kind of adaptive
streaming but the idea behind it is is
if you recognize that the network and
action is getting slower you can then
swap to the medium quality and then
between the medium quality to the lower
quality but the problem behind this is
it's very very much up to you as the
developer to control how the data is
loaded in so you don't have to use a
traditional URL you can basically say
well I'm going to load the data in from
a set of XML HTTP requests or or
whatever you want it's in WebKit yeah we
haven't done before in this one it's in
WebKit the I'm going I'll tweet about
some of the demos actually could we had
we have got some nice demos for this or
actually on the next slide this is the
code you have to specify the source is
WebKit media source URL d that just
basically tells the browser to switch
into kind of dynamic data load rather
than just a normal load and basically
you get this WebKit sauce again it's
WebKit prefix oh it is only available in
a web key at the moment WebKit source
open event and then you can start
sending data to it so basically in this
one with type we're passing through the
source append method on the video
element we're passing a typed array
which is basically a byte buffer and
then you can start kids can and keep
passing that data it's kind of nice but
it's kind of it's nice there's a very I
think there's a very small set of use
cases for it but it's one of those
things that you can be aware of because
you can start to do some really cool
stuff for that I have seen people try to
use web stock binary web sockets because
banner web web sockets are kind of
putting you in this back and I I don't
think I'm calling them today but the
idea behind binary websockets is that
you can start pushing data to people
through the web socket interface and
then start a pending that to the end of
the video so there's some nice things
that you can do with that as well from
the kind of the push side of things this
is the demo to break file into chunks
this is actually really hard devil to
show up because there we go all it does
is it shows the video playing which is
the exact like the desired effect is a
video plays and it plays as expected but
the interesting thing here is that the
actual video is broken down into
different chunks five different chunks
and then we've just loaded them on by
appending it to the end of the data
source each time and that's because we
have raw access to the data and I'll
tweak these I'll tweet these URLs at the
end
does anyone I think a lot of people have
seen this demonstration has anyone seen
the speech speech API show me to give it
a go so it's like so the whole idea
behind this is obviously there's
multiple different ways that you can put
data into a text box it's through a
keyboard will normally fill a keyboard
right or kind of a touch sensitive
screen the idea behind this is ex hype
and WebKit speech that's the only
attribute that you have to know it
basically puts this little microphone on
this on the screen hello my name is Paul
well yeah that's it's pierre flip an act
i know some people pronounce my name
different but it's not that bad right
Bob okay so this is actually a good
sorry I have actually got an uncle
Robert doesn't matter I haven't I'm
joking if any of my family see that like
oh no you haven't I've got a friend for
Bob so the whole idea behind this is
actually there can be errors in the play
the quality of how near the data it
returns and the interesting thing about
this API is that you know if you don't
want to listen to the data near the
actual on speech change event you know
it's just going to put the text into the
kind of the text box but you know you
want to look for WebKit speak to change
because actually where it does it gives
you a range of values like the value it
thinks that you said and then the
associated confidence that like the
confidence value of one means it's like
we think that you pretty much definitely
said what you said and in this case if
we look in here and was cool it thought
hello my name is bob was eighty-three
percent likely just kind of right right
I didn't say exactly what it said hello
my name is Ben left my son's name ah
hello my name is earl how do that's kind
of odd right but anyway basically it
said the zero confidence with this i
actually think this is a book because it
shouldn't actually sent it
conference yeah that's it right you can
actually get a list of different things
that the speech engine behind the scenes
thought that you actually set so you
cannot you know if the idea behind this
right is if if there is a non keyboard
way of actually doing the input you can
actually let the user select the
different values if that if they think
it's not exactly right so it's kind of
nice camera what is the browser sport at
the moment it's pretty much Chrome it's
hyphenate it's prefixed with the WebKit
version I don't think WebKit itself
that's the Safari and the kind of the
iOS Safari support it it sorry yeah this
should be I've done it took things the
crowd I believe it's on some service
maybe I think it's quite a bit poem
right it's pretty much like me I don't
the reason I'm saying that is because I
don't exactly know but you know there's
Android functionality that's quite
similar you know it's it's the same I
presume if it's not the same type of
infrastructure it'd be all right
actually this is kind of cool so a
microphone and camera access this is
literally starting to land right now and
I'm hoping my build of chrome has not
broken because we have a demo but this
is kind of cool right because we've
never had the ability to interact with
video cameras without resorting to
silverlight or flash or the kind of
plugins and what we're trying to say
today is actually you should just be
able to do that inside the browser and
the browser should let you interact with
the microphone and camera the api is
kind of pretty simple it's called
navigated that getusermedia you specify
whether well this has changed actually
over a glass a couple of days you
specify that you want audio and video
you can say true or false for both I
don't know why you'd want to have false
for audio and false for video at the
same time but it might be possible right
but essentially it returns a stream out
from you know once the users accepted
the fact that you can access the camera
from your website or your web
application it returns the stream so
this is actually an asynchronous API and
once you get access to that stream you
just basically a window URL create
object URL with the stream and then it
which is your video camera or your audio
your microphones the audio elements if
you want straight to the source and i'm
going to show you what that looks like
now here we go basic demo so i made i
did make sure this work my mac is slow
it doesn't turn the camera on properly
as wait a cool here we go whoa it's got
like an effect going on the back but
this is the money this is the web camera
access right hello hello everyone it's
kind of cool i'll show you the code just
so we prove what it is actually video
element the video element it's got a
blob uri which is basically to URI that
prefixes the domain and then some just
extra extra geared information at the
end but this is access to the video
camera and we can do some very nice
things without them so this is literally
landed in chrome right now you have to
enable it with a prefix which i believe
is yes sorry is there is there a speaker
API so which audio which speaking you're
sending the audio through no that's
actually a nice API so there's some
stuff for the Web Audio where you can we
can do some extra stuff but we can't
direct which speaker that you want to
send it through to at the moment you
have to manage up through the actual
system preferences yourself so then this
is the video element it's kind of cool
this is the very basic one I want to see
if there's a demo that I can show you
which is really really nice so there's a
bug on my actual my machine is the video
camera never turns off this is how this
is its kind of crazy now but let's give
it a go explore video of course are
still working and because it's on canvas
you can do some really nice things and
if I wave you know it's still doing all
the stuff so this is actually really
nice this is this explode demo is quite
old it's been around for canvas kind of
showing you how to interact with the
video element in canvas the reason why
this works is because we've attached the
video camera data source to the video
element and then because it's on the
video element then we can do those same
type of processing
it's really nice and we don't suffer in
this case at least anyway we don't
suffer from kind of cross origin issues
because the blob is prefixed with the
name of the domain which means that we
can do some nice things with canvas so
that's that's pretty cool and I know two
of those demos don't work because they
they crashed on me earlier on so that's
kind of interesting right you can do
some nice stuff with the camera put up
to the video provide some nice effects
but actually normally what you want to
be able to do is either record that to a
stream maybe send it back to your server
or do something else kind of more
interesting with it like WebRTC without
having web RTC in place and we haven't
got Devon for this either because it's
not quite ready yet is the ability to
take your data from completely take your
data from a media stream which is that
thing that's returned back from they get
which is returned and come back to the S
this is the stream the function that's
for the data that the value let's return
from they get user media call you can
basically say record that's the whole
thing planet is it's it's pretty it's
pretty simple is I want to start
recording the data that's coming from
the camera theory is as well it should
be able to do audio you say stop so stop
recording here and then once you've got
access to the data the recorder object
which we set up here earlier on you can
actually say get me access to the
recorded data once you have access to
the recorded data you could probably do
a lot of things on the client with it
you know you might be able to kind of
analyze the frames the easiest thing and
then kind of the basic demo that we say
to do is you just upload that to the
server your server and you kind of then
you've got the users video camera access
so that you've got the users kind of the
video data that they just send to you
you push up and serve and you can do
whatever you want with it there so it's
kind of nice right it's kind of cool
people are going to obviously use this
for doing things like you know taking
profile photos and all that type of
stuff so it's going to be pretty cool
ah I wouldn't be surprising it with web
am in this case the theory the theory is
its kind of agnostic to the platform but
you've gotta expect them in the Rendon I
wouldn't be surprised a little web
that's not say it is I've seen some
stuff in the past where it says a web so
full screen again this is one of those
things up if you've ever been kind of a
flash developer you've been able to say
to html5 developers how I can take my
content full screen and the good thing
is we can do that in HTML now this demo
here is basically saying this is a video
element there's a button that says go
fullscreen and we call the should be we
call the WebKit request full screen
method if I as an event that says you
know we've gone into full screen but
once this method here on the element is
called essentially the screen will go
fullscreen and this is kind of
interesting because we say element an
actual demo says body up there any HTML
element can be made to go fullscreen I
mean you can make a button go fullscreen
I don't know why you want to but you
could make a button go fullscreen what
ejecting this demo does checking makes
it down at the bottom careful screen now
it doesn't exactly a nice a demo so the
idea behind this is that we've got a
video element this is going to work
great for video players or did this
didn't work in second
right cool that's it I was worried then
for a second this is just the div this
is the video element well it's not
really the video element it's the death
around the video element that we've made
to go fullscreen the reason why we've
done that because we might want to pull
I provide a nice user interface around
the video elements any arguments it's
full screen playing the video it's
pretty cool you can toggle fullscreen
either through the keyboard or you
unlike a normal user gesture so it's
pretty nice the other thing we can do as
well is we can send iframes full screen
so let me just zoom in here this content
here is an iframe all it says is I'm
Elena iframe we toggle the content and
we zoom out we toggle content and
actually it's got full screen I full
scheme full screen frame content that's
actually pretty cool we made an iframe
go fools yes
in flash comic another window yeah I
yeah so the feedback was we we locked we
can lock full screen you can go full
screen across multiple screens we also
can't detect what screen were on I
believe that the same HTML as well we
don't quite know which screen that we're
on at the time because it treats
everything as a virtual like a virtual
screen I think any weight so the iframe
side of things is kind of interesting
because the content changed it was the
same iframe we didn't reload the iframe
data for the content changed inside the
page this is kind of cool i will show
you why that works if the browser itself
at that time is hardware accelerated it
should all still be hardware accelerated
we don't I don't believe we switch out
we have a JavaScript API detect whether
you are full screen or not it's kind of
interesting request full screen on any
HTML element is kind of cool as well
heat okay I'm gonna jump men's room for
once I because I want to show you one
thing first before we go back there are
pseudo classes yes sorry right
mm-hmm
yep okay so if we jump back to the demo
right let me the screen API right here
we go so the top part there is a
unspookable it's not really unspookable
but there's an area up there which
allows you to basically say exit full
screen or allow this actually to keep
happening the interesting thing is this
is supposed to appear above any element
that's kind of rendered in the browser
so you can't kind of go above it which
is kind of interesting it's kind of cool
exit full screen so you won't run
forward on we have CSS selectors so you
can actually be able to style the
content differently based off whether
that be whether you can detect that
you're in full screen mode or not so you
don't have to use a javascript api to
then go manipulate your interface you
also have to be able to say to the
ragbrai WebKit allow full screen if you
don't have that an iframe can't go full
screen but once the iframe does the demo
that we had before was basically a
pseudo a pseudo predictable a pseudo
selective sorry with a WebKit prefix
that basically said when you're in full
screen mode kind of display the html5
logos and some extra bits of text so you
get control over that the interesting
thing is we jump back one you can detect
whether oh that's like this second you
actually you can detect whether the
actual browser service will support full
screen or not so you can actually choose
whether to let them even try and enter
CSS function this is pretty new and I've
got a demo and actually that there's a
bug in the demo right and I want to see
if anyone notices this but crossfades
kind of interesting because and I'll
give you an example actually why it's
kind of cool when Google i/o last year
we built a framework called IO reader
like Google i/o reader which was
basically just a news reading piece of
software which was like a news glide so
you can like page between articles and
they were dynamically load into the user
in space it's kind of nice but we need
to support low res phone like phones
tablets desktops and TVs all in one code
base and we had to use hacks to
basically say well we load a
low-resolution image in first and then
once the image is loaded and we kind of
pretty sure that it's going to be able
to load more data we would load a high
resolution image
for that and the primary reason for that
was because we want to deliver a low
resolution image on mobile which is kind
of interesting because the high
resolution images were like some of them
will make in size but they looked really
nice and the way that we did this was we
basically we had an image the
low-resolution images image stretched to
a sorry stretch to a particular size and
then we inserted a new image element on
top of that that was completely
transparent and then once we detected it
had loaded we'd make the transparency
from like at the opacity at least from 0
to 1 so it basically replaced the image
that was above it and it kind of had
nice kind of smooth light load in effect
oh it's kinda nice it cannot look very
well but it was complete hack he was
like there was two image elements that
we had in the screen at any one time it
wasn't kind of nice kind of Dom stuff
the idea behind this it's a similar
thing but you can essentially load two
images into an image element or anything
that's a background element at least and
then animate between one the next so you
can start off with the low resolution
one and once you're happy with that's
loaded kind of fade than you want in and
it's just essentially CSS rather than
apply an extra image into the Dom you
have the one and load them in that way
it's kind of nice it's simple API the
demo is by Peter Beverly one of my
colleagues in London the idea is that we
have limbs oom in the first image r
which is logo box PNG to logo bear PNG
0% which means that the first image is
fully showed and the second image is not
shown we go through to fifty percent
here fifty percent also scored answers
50 to 100 which basically makes the
foreground image in the background image
or the background image overlay the for
Grandma so it's kind of nice and it's
just CSS right you don't need to have
all these extra images in so it's pretty
cool CSS filters is the next one I icky
added this slide in this morning because
I managed to get it working in Chrome
has anyone seen CSS filters a couple of
people they're really nice right it's in
it might be in dev channel it's enabled
Viron about flag inside chrome so if you
want to start experimenting with it
you should be able to on second sorry
visit about what's not realized anymore
it's changed its name in social filters
CSS filters and you can enable it with
GPU acceleration this is really cool
actually because you can now apply kind
of blur effects to kind of pretty much
any HTML element with as a bug in chrome
at the moment which means that you can't
apply it to anything that's hardware
accelerated but that's going to get
fixed but the idea behind this and I
will show you a demo because it's really
nice right that's a nice image right
it's a normal image which is a normal
image element it's nothing special will
apply some blur to that there is the
image changing can we see that it's kind
of nice right and the theory behind this
is it's just a CSS attribute basically
we specify the filter you can specify
some blow on it it's kinda nice Internet
Explorer has done some stuff for for
quite a while on the password the DX
filters but now that we get this it's
pretty cool to your gray scale change
the brightness a little bit you can keep
applying them change the contrast it's
pretty nice right it's pretty cool you
can also animate as well so let me zoom
in so this is just animating the blur
the blur property on the WebKit filter
so you can do nice things there's no
code involved it's also yes yes question
I've never tried to actually I've only
ever done pixels should we give it a go
here we go
oh sorry I'm animating the blur
so if you've never used that tool for
they're really good so this is the image
let's add an attribute on it web WebKit
filter blur 1e yeah yeah you can it's
pretty cool right yeah so it's kind of
actually looks kind of cool you can
apply rain i spects we want to do some
demos soon where you know things like in
the foreground are nice and sharp and
then all the background items are kind
of blurred out and things of that so we
weren't trying to do some really cool
stuff there doug said this is in Canary
this is the canary build it could be in
dev but you get one of those things they
just try it on dev channel and see where
it goes if it doesn't work it doesn't
mean it's not supported it just means it
might be thinking that your deck it or
your element is hardware accelerated
which is a known bug at the moment
WebRTC is kind of interesting you know
the thing is like face-to-face
communication inside the browser we want
to make that super simple did anyone has
anyone ever used their physical
chatroulette yeah everyone says no by
bright they have so it's those type of
thing here we don't want to have to have
external plugins to be able to try and
do you know these things that we want to
try and do with people on the web so you
know you connect to people you talk to
people you can just connect straight
through to a representative of the
company up you know those type of things
that you want to try and be able to do
it should be possible inside the browser
with a bit like a small piece of HTML
and a small piece of JavaScript once it
lands in more like a lot of other
browsers as well it's going to change
the weather I think it's going to be
absolutely awesome there is a huge
demand for it you know people want to be
able to do this for a long time no chat
roulette was popular because you connect
people are you know because they're
popular for a lot of reasons right but
it connected people together right and
that's really powerful WebRTC itself is
the idea like I said it's a plug-in free
peer-to-peer communication channel
basically the theory behind this is that
you as the developer as the web
developers shouldn't have to do noise
cancellation buffer management jitter
management all this kind of things
you know which make you know
communication hard it should be
abstracted the way you should just say I
want to connect to that person over
there and then you've got video to video
communication or audio to audio
communication it's really powerful stuff
this is the obligatory architecture
slide ignore it for now it doesn't
matter that much all it's saying is
basically you as a developer interact
with the web api the web api interacts
with kind of things like the peer
connection the video engine the codex
echo cancellation noise cancellation
there are a whole lot of things are that
you shouldn't have to worry about so
should do it this is an example of what
the code looks like from you as a
JavaScript develop a side of things you
zoom in peer connection is the
interesting thing it's this peer
connection object which tries to make
the connection through a centralized
server bus through the firewall like
like mostly kind of the skypes and all
the kind of video communication
frameworks do of the kind of the person
who's participate on the same channel
and then connect you from that person to
the other person so the theory is and we
we tested this because we were never
quite sure whether the is an
intermediate server that streams the
video you send your video to one server
and then the server sends it back out we
whenever we were never actually quite
sure when we did a test of the day where
we had like a server running we killed
the server and the video communication
still happened between the two parties
so it's kind of interesting but this is
the peer connection API stone I don't
know why from a developer experience
point of view I have no idea why you've
got stone at the front I just doesn't
seem to make sense but basically you
initiate a peer connection with the
server and then you have an on signal on
a non signaling message it's basically
it's call back because in theory you can
send messages to kind of synchronize the
clients behind the scenes through the
peer connection API so that you can send
commands to all the participants to say
well actually you know a video stream
has been connected to a video stream has
been connected to this peer connection
stream you know what you want to do with
that you might not want to connect a
video stream directly to a video object
like you know the video tag so you can
decide what to do inside JavaScript and
this is the code here so whenever the on
add stream event fires
you can basically say take the stream
which is very similar to the where it's
a very similar it's exactly the same as
the they get user media stream earlier
on when you forget an access to the
video camera and you attach it to a
video object so the thing here is that
you just basically say new streams come
on come on line attached it to a video
object and in theory you should have
access to the person's you know the
webcam that they're sending to you so
it's really nice it's pretty cool you as
a developer if you want to attach your
video stream to the peer connection
getusermedia notice the difference here
video audio rather than the two plugs
this is a book in the slide one of the
slides is correct I believe it's the
other one not this one you basically you
get access to your local stream you can
add it to you the video so that you can
actually you know view yourself on the
screen but that same stream that you can
then add it to the peer connection so a
peer connection add stream your video
stream and then that's connected to the
people who also connected so they will
get the event saying video camera added
you know do you want to add that to the
to be jointed that to the video element
so that you can start playing that and
it's that's pretty much it once it lands
in more browsers once it lands in stable
version of Chrome as well it's going to
be there's going to be a whole load of
applications that come off the back of
this some are well break the ad break
the dial paradigm it's the worst Fraser
but but the idea is that you don't have
numbers to connect people you can have
whatever constructs you have in your
application whether it's like twitter
names or whatever you can start a call
between your video conference between
those two people based off say a twitter
name it's kind of cool build really
social networks it's kind of a hangout
thing right people want to talk to
people and want to do it face-to-face
you could be able to do that with the
web with the WebRTC WebRTC
infrastructure online gaming it's like
party chat and those type of things
you're playing the game say it's Angry
Birds on the web you start to talk to
people who also play in the same game at
the same time it's pretty cool build
cool baby monitors yeah maybe but you
could write I mean you could literally
put your Chromebook or whatever device
that you have and I say chromebook ism
you know you put bit literally put that
in the baby's bedroom watch it and then
if it's on the same network just kind of
only stream them to your kind of
advice that you've got downstairs that's
pretty cool WebRTC dog is we're kind of
all the communications happening the
news groups are the code examples and
the open source stuff obviously code doc
WebRTC is where the world free license
bsd license code is the theory is we've
got support off Mozilla I don't know how
far along they are I'm not saying it I
just don't know they just don't have far
along they are a pro Google opera has
got some really nice demos of
interacting with the video camera so I
imagine they're not too far behind but
the idea is that will get this in the
loads of browsers and it's going to be
awesome and going to build a whole lot
of really cool applications how we doing
for time fine sweet I'm getting towards
the end anyway so the Web Audio API I
supposed to some guys is anyone from
SoundCloud here no okay they really cool
I think they're based in San Francisco
and Berlin they their idea is to make
the web loud you know we've reset from
having no ability to do anything cool
with audio on a browser without plugins
before the Web Audio API is our idea of
what we want trying to on the web with
audio there are other competing
specifications and hopefully at some
point they'll just they'll all be ironed
out at the moment but this is a kind of
example of what happened in the olden
days used to have background sound play
a MIDI file that was pretty much it you
would that name but you could then
either use it in bed or you like an
object tag with some flash it's it was a
bit crazy right it wasn't basically
audio wasn't particularly native to the
browser in the past in theory it should
be we introduced the html5 and the
problem at the html5 audio is that it
was probably overhyped a little bit you
know the idea is that the audio tag
solves all your audio needs inside the
browser it's one tag with some source
files and that's pretty much it the the
interesting things that we've had is
kind of some browsers to have different
competing codecs so we didn't have a
consistent story across all the browsers
in chrome especially we didn't have an
amazingly low latency kind of API so
you'd call play on the audio tag in
maybe two hundred fifty six milliseconds
later the audio to play which basically
just ruins gamers experience so you've
got a game and you
trying to play some audio you want Lee
less than 20 second like 20 million 20
seconds is terrible agency sorry 20
milliseconds latency is is kind of what
you went you want to aim for and we were
I kind of like an order of magnitude out
so you want kind of audio like low
latency glitch-free kind of experience
and the audio tag just wasn't that I
know in explorer done a lot of work and
they've got a really low latency audio
audio play API sent you with the audio
tag but quite a lot of browsers didn't
that's not all though I mean we want low
latency the thing that we actually want
to be able to do is access the raw data
that's playing either through an audio
tag so that we can apply effect that
effect to the audio that we want to play
to the user in real time right we don't
have to render different things on the
server and kind of send them out so we
want to be able to do real-time audio
processing and make it really cool so
you know you can do things like echo you
could do echo cancellation in the
browser you could do you could add echo
to an audio tag you could pan kind of
you know in stereo you could pan the
sort like candy audio between the two
sides it's a whole lot of things that
you want to be able to do inside the
browser and not have to resort to flash
and that's what these Web Audio API SAR
for so the Mozilla API and the current
the WebKit APR as well so this well this
is it so that the main differences are
right we thought the similarities are we
want to make it easy for you to be able
to apply effects in a low latency like a
low latency manner way inside the
browser and after resort to plugins or
have to resort to basically try and do
things on the server which is near
impossible the main difference is that
the Mozilla one is all about the job you
you build the functions inside
JavaScript to apply echo maybe make it
louder a quieter through gained like
gain kind of manipulation what we try to
do with the Web Audio API is is provide
them up front so that you basically I
need to apply gain to this audio source
and then you can adjust the kind of
loudness of the audio just by
manipulating one value the theory behind
this is that we can take advantage of
the underlying hardware to actually
apply these effects so the hardware is
no sound accelerator look like you know
like a GPU book sbu I don't know or the
audio the audio for you
audio cards can accelerate kind of
common functions at least and that's the
whole idea behind ours you don't have to
do in javascript and have the browser
render the audio you can actually have
the sound card go well you know what we
need to make this louder make it louder
it's interesting because it snowed based
sorry yes royal samples will yeah it
should be and I've got a demo in a bit
to actually hopefully show you that
actually so the question actually the
question was is there an API to access
the war sample data yeah from people I
get mp3 file yeah yeah yeah I'll show
you in a bit actually we've got a nice
demo it's a node based system that's not
unfortunately no Jasper it's basically
you say there's an input data like input
node which is like the source and output
node which is the speaker and you
connect the source yeah the input to the
output via well you just connect the 2
i'm going to say like the very channel
bits not you can't the input to the
output which is basically plays audio
it's kind of cool it's very simple if
you want to apply echo you connect the
input to an echo node and the echo node
to the output and then you press play
and it plays it with some echo and I'm
going to show you some demos actually
it's kind of cool this is the interest
in one this is the zoom in this is the
one that literally just play some sound
do you work oh we are played some sound
admittedly it's a lot of code just to
play some sound I don't think you'd do
it in most cases you'd probably abstract
it away inside some API we can apply the
delay of two seconds yeah it was two
seconds the way that we apply a delay is
not via a set timeout say do it in two
seconds time there is a source element
or softness or method called note on
which is you know you give it the number
of milliseconds to wait to play the
sound so it's kind of interesting we can
go loopy right that's kind of
interesting right it's not amazingly
cool just playing one that sound it's
not the greatest however we can do some
really nice things there we are
displayed one sorry
we are so essentially we've just had it
made a method called play sound we told
it when to play on to the note on and
because we've Spacely set this up in you
know a series literally is just a series
we're not waiting for any extra stuff
we're saying that you know we should
play out like an eighth of a note four
times 870 is every four beats or
whatever so we can do all this and kind
of cue up the sound that we want to play
and then the sound card will go off and
play them at that particular time that
we've said to go and play them so it's a
kind of okay little API we can do some
nice things to that the really cool
thing hopefully this demo will work it
took me ages to actually work out what
this demo was doing let me load it
Bohemian Rhapsody okay let me just load
up you know I'm gonna come back this one
oh no wow it's crazy so the idea behind
this is you can just click on things
just taking samples of stuff the
interesting thing is that you can sort
by whole lot of different values so we
saw salt by loudness love the loudest
part of that song it's kind of cool yeah
for quiet this one but it is that quiet
kind of crazy but you've got the
different bits in between the reason why
this kind of works is that they've been
able to analyze a sound and you can do
some kind like client-side manipulation
and break that up into chunks and then
decide to play that individual chunks
it's kind of nice and that's our demo we
can do crossfade this is this is kind of
interesting i'll show you the code in a
second but that's an organ okay
drawn to the background so we can do
some kind of it should actually quite a
damper force beef so we can kind of
basically do some nice things with this
the reason why this works is not because
it's kind of a dual-channel in a way but
essentially what we've got is we've got
two buffers sound buffers playing at the
same time and then we are just the
volume between both of them and we're
just the volume through this idea of the
gain node so essentially as Jo actually
what we're doing here actually we're
saying we're connecting the source the
source is the mp3 file or whatever file
that we're playing at the time we
connect it through the gain node so
again is like the volume adjust and
after that after that essentially so the
destination of the context the audio
context itself is the speaker so
basically we said the source input is
connected to the game manipulation so we
can adjust the volume programmatically
and then that output is connected to the
speaker and that's all it does really
let me show you the code
well
so here we are everywhere so I didn't
actually do this demo my colleague Eric
bidelman did this demo but essentially I
I initially thought you'd scale it down
and kind of like inversely proportional
to the you no one's at 11 20 then ones
off fifth like half like the ball half
the volume the others are half the
volume it doesn't exactly work that way
but essentially this is how he's
adjusted the game so he's got an
algorithm which basically adjust the
kind of the volume for each channel each
sound that's playing at the time but
that's pretty much it right you can you
have the ability to basically adjust the
values on each of these nodes to
essentially adjust what playback so the
really cool thing as well is because
obviously we can you can play sound we
can play it from the browser from like
mp3 files and all that type of stuff we
can also generate sound on the client as
well which is kind of nice we've never
really been able to do that so much
we've it's been really hard to like
generate an mp3 file and then attach it
to an audio file the audio source
attribute on the audio element we can
now just generate the data as a normal
waveform and pass it through the Web
Audio API so we've got the ability to
sorry it's going to loud play a sine
wave we can then do it do a triangle
wave
that one hurts yep
so it's kind of cool right we can
actually we can actually generate the
audio on the client and pass it through
to the generate the audio on the client
and passing through to the audio
subsystem and kind of do whatever we
want with that then it's kind of pretty
cool it's pretty nice as well so this is
just basically this code at the top is
generating the sine wave we've created a
buffer sauce and the buffer is based off
the data essentially so we create a
buffer setting the channel to the value
the sine wave and then we just play it
and we play in a loop so does generates
one kind of arc or one wave of data and
then just keeps playing that over and
over again it's pretty nice it's kind of
pretty cool that we can actually
generate this information on the client
I'm not going sure that that one didn't
work so the real-time audio processing
is kind of cool which hopefully gets to
the point that you raised before the
idea behind this is that this is a node
based system so you connect like an echo
node up to the speak to the the to the
mp3 file and then you connect that echo
to the speaker then you get you played
with echo the interesting thing is you
can you can connect an analyzer node the
analyzer node essentially is a piece of
JavaScript which actually get your all
access to the data that's being played
at the time and this is it so we create
the buffer sauce we connect the buffer
to an analyzer the analyzer essentially
is this piece of code here so you can
get kind of bike frequency data and a
whole lot of other stuff so if you're
saying it's a compressed file before it
decompresses it to play it it passes it
through your analyzer node so you can
actually get the frequency information
back out it's pretty cool and you can do
some nice things was anyone at i/o last
year one person cool so this is hoping
you so this is a demo that we had at i/o
it's not playing just yet right when it
loads it would be really cool you should
try again
right so you're going to have to play
with me here right right so this is how
it's obviously a computer the idea
behind this was the audio was playing at
the time we pass it through the light
that analyzer node because we can get
access to the raw data we can manipulate
the the red kind of beam in the middle
so we can make it smaller and larger so
it looks like it's talking to us based
off the frequency data is a really nice
demo I'm not sure why it's not working
the worked in the office yeah because
Norman is a play button that works quite
nicely but that's kind of the
interesting thing is because we have
access to this information we can do a
whole lot of really nice kind of things
on the API is then it's kind of really
cool this is new I don't actually have a
demo for this but the idea is that you
might want to apply some effects and
actually record the output so you don't
want to be able to just say well we're
going to play the data and it's going to
play through the speakers and you play
for 20 seconds the idea behind this is
the process in offline mode is that you
can basically construct this node kind
of see like this node sequence to apply
effects to your audio the idea is that
you know you want to apply 20 seconds of
echo effect to an audio sample without
it going through to the speakers you can
use this kind of part the API you create
the WebKit audio context you tell it how
long it's going to be four and then
there's a function at the bottom when
you start playing called start rendering
and the name implies basically you're
rendering the audio to basically like an
output file you get an uncomplete method
and once it's complete you can get
access to the rendered data which should
be the audio file that you can then
upload to your server to go and do some
nice things to that so it's a nice thing
I believe it's in Canary but I've not
been able to test it and I haven't got a
proper demo that works at the moment but
it's coming soon and it's going to
enable a whole lot of different types of
applications it's kind of nice the
interesting thing is that we've now got
integration as well with the audio
element so that you basically your input
source for the audio tag and the thing
that I'm hoping with this is kind of in
the thing I'm hoping with this is that
you have an audio tag you connect and
analyze the notes of the audio targeting
you can do
really cool stuff with that I'd like to
be able to connect this audio data I
don't know whether it's going to work
just yet but I'd like to be able to
connect this audio data to the WebRTC
like the WebRTC stack so you could play
some audio on your side push it over the
peer connection and then people on the
other side would be able to hear it as
well so I'll be kind of nice if we can
do that but the idea behind this is
you've got audio files the audio tag
knows how to load the data nicely you
can have it in you to interface but then
you can apply effect to that data that's
all you in the type likewise with an
audio video stream as well unluckily I'm
right now at the end of the presentation</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>