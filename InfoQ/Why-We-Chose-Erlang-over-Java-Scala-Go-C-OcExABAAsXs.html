<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Why We Chose Erlang over Java, Scala, Go, C | Coder Coacher - Coaching Coders</title><meta content="Why We Chose Erlang over Java, Scala, Go, C - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Why We Chose Erlang over Java, Scala, Go, C</b></h2><h5 class="post__date">2017-11-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/OcExABAAsXs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so yeah I'm calling having some CTO a
company called outlier just there's a
kind of quick show of hands who's using
Erlang at the moment or has used Erlang
production
okay so yeah most of this talk is about
Erlang why we chose the Erlang there's a
kind of subplot I'm going to be talking
about my overly opinionated view of how
to build software in a start-up and with
some quotes and a few pitches so yeah I
tend to kind of like putting quotes into
speeches there I like the kind of
concise wisdom that's passed down from
smart people throughout kind of
generations even in tech or outside so
this is a good one from Thomas Edison
this one's just funny you'll see the the
infamous Donald Trump so who are we
so we're monitoring companies so if
you'd heard of data loop before which
you might not have done that's us we've
just kind of rebranded now to out lawyer
and yes we provide monitoring so the aim
of our application is to provide civil
service monitoring kind of primarily
targeted at companies that are running
microservices so the approach that we
have is we allow you to kind of devolve
responsibility of your monitoring delft
the individual team so it seems to work
in on Marc services can own their
monitoring as they do by their code and
making sure it stays up and running so
if they need to make changes to how do
they monitor an application they can do
they don't need to get anyone else's
help they don't need any kind of changes
being made by the operations team at the
root of it we are a replacement for a
geostrophic stats D we kind of allow you
to collect your data to visualize it and
alerts on it and yeah at the moment
we're with processing around 12 billion
measurements per day and that's kind of
linear least growing up leaning at least
growing scrolling up at the moment yeah
and so we kind of try to support open
standards so that you can just instill
the application get up and run in and
great with your current monitoring stack
or tools that you're using
we're so I've docker support which you
know it's the in thing at the moment say
startup say yeah I thought we'd get some
context around kind of what we do and
kind of how our organization work so
this kind of leads into why we chose
Erlang as well so you'll see this is a
Silicon Valley which is pretty much been
my life for the last three years
and it's kind of scary how true to life
this actually is and the start of life
is as mental as this show makes out and
so works on several kind of large
software projects throughout the years
and all have their own challenges and
issues but there's nothing quite like
building an application for a start-up
yeah when you're working in a start-up
there kind of time is critical it's
usually important but it's especially
critical in building an application for
a start-up you have to release quickly
if you least if you're slow to iterate
then you're going to die you to prime
product market fit which means
flexibility so you need to kind of work
out where your market is adjust your
product it's a kind of stay cutting-edge
and actually cover find some people that
will pay for what you're building well
so you need to be kind of quick to scale
so these things tend to kind of hit you
in the middle of nowhere that you're
fine and then all of a sudden you've got
issues and you can usually buy yourself
some time but you need to be kind of
strategic and always looking at where
your next gonna change your application
to to meet the levels of scale there are
some caveats to this so you can get away
without being these if you kind of feel
fulfilled some of these criteria so if
you're well funded which isn't such a
case in the UK it's more of a a Silicon
Valley thing so if you were raising ten
twenty million dollars or C funding
upfront then you've got like two years
to build your your your application
before you need to actually start making
revenue if you're making a lifestyle
business you don't need to make that
much money then you can kind of get on
with it and yeah some people are just
lucky there they're kind of the first in
the market there they can get by with
you know
mistakes and and still survive so it
really comes down for a business first
thing so you kind of you can't build
your application in stealth you need to
be out you need to release it to users
you need to get feedback and and
iterating from there and just to find
something that's gonna actually gonna
sell and as a kind of contrast to how
you usually like to build applications
being engineers quality can take a
backseat you don't have a lot of time to
over engineer your application or make
sure it's the most glossy shiny coat
there is you kind of just have to
deliver which also kind of comes up when
you're hiring people when you're asked
you know you know what your unit test
coverage is like and you don't have any
there's not much of an answer for that
so the first version of our product was
the model lift so when I was building
these slides over the last couple of
days I kind of searched from one leaf
and this image showed up and there
obviously it's a Minecraft and I kind of
wondered yet actually what the what it
was I could appreciate and played
minecraft a little bit that the the size
of the structure must have taken a fair
amount of time to to build but yeah I
didn't quite get it so scrolling through
the page it was actually a question on a
forum you know someone built this thing
without actually have any idea what it
was actually gonna be and so there they
were asking for some kind of advice and
what they could actually do with this
thing they'd built and the the kind of
top and the best answer was giant urinal
which yeah I can see that
either that were a little bit like a
SodaStream but I kind of took heart in
this that you know it's good to see the
student loan isn't going to a waste
so yeah the actual model if we built so
the the first version of the application
was a nodejs application saffron a
MongoDB and we had a Python agent which
he stole on a host for collecting
metrics and actually monitor and what
the service were doing so this is the
kind of at the time the the hipster
stack we had no js' and we had Mongo in
there
we didn't have any anything else really
that was just two boxes one box had no
js' and manga on it and the other box
had just no GS on it so we had a little
bit of a chain but not really so there
was kind of a few problems with this
I don't regret us building it this way
we kind of needed to get something
delivered but yeah this wasn't gonna
scale and it wasn't gonna grow with the
company so as we add more engineers and
generally more kind of technical people
into the organization having everything
on that's just a giant monolith it
doesn't really work it doesn't kind of
fit in so well so we always had the idea
of using micro services kinda made sense
it gets a little bit kind of dogmatic
around defining what a micro service
actually is but the whole concept of
sorting things out into separate
services so yeah at this point we had a
great POC we kind of wanted to get to
the the micro services thing but yeah we
needed a process or a way of getting
there we don't we had to keep delivering
features we didn't have time to stop
rewrite all this thing as microcircuit
it was kind of like steering a big ship
to slowly move into the right direction
so yeah the the kind of benefit analysis
around micro services obviously you guys
are probably fairly familiar with this
stuff like isolation is a critical parts
of this I need to be able to change my
services you know if there are bugs in
there and break one of the services I
don't really want to impact any the
other ones we to reduce that impact we
have a lot of client agents which are
connecting back into our service so I
wouldn't want to bug in the billing to
suddenly cause all of those agents that
disconnect and cause people to get
alerts and false alarms and things like
that they also need to be independently
deployable so again it's a case of
reducing risk I want to be able make a
change to one service and know that it's
really not likely to have any impact on
another service unless they're directly
cut
dependent on each other or one hour and
then but with then we can kind of see
that and we can kind of plan around that
flexibility is another key one so if I
want it to right one of my services and
nodejs or go or rust or something then I
can do that
if I need to have a separate database
for one of my services that I can do
that
we have several database in application
at the moment or for different use cases
and then this also comes back to the
team alignment and ownership of the
product so it's kind of important for
the engineers to feel like they own
their part of the application even if
they're not working on a large majority
of it
as we onboard more people the products
getting bigger and bigger and if this
takes a while for people to pick those
things up so it's useful for you to put
them in a team they can work on that
product that service eventually kind of
take ownership of that or start building
a separate service and ownership of that
and yes so there's that breakdown as
well one of the issues with mic reserves
is there's kind of some impediments to
get in there you need things like
infrastructure managing deployments for
the individual services you're not just
a blow in one thing you'd want a bunch
of things you need kind of automation
tooling and things around there
yeah packaging the deployment I need to
get this one thing distilled down as a
package or container or whatever it is
you're using to deploy and get that
pushed out some kind of communication
mechanism so whether you're using a
centralized bus for communication or
they're communicating over arrest
endpoints and also service discovery
your foreign off a new service you need
to tell the other ones about it you can
put that in config but that's not very
flexible and so yeah these are kind of
some of the opponents we had to work
around and this kind of comes back to
the actual process so the way we did it
is we kind of started out with the the
monolith we didn't split anything out at
first we just kind of gradually
reorganized the code so that it could be
split out and we started separating
state away from the stateless parts of
the application so that mostly in
volved moving out Mongo and bus services
and things like that splitting out those
separate services into separately
deployable application services as well
so they could actually we could build
these and deploy them separately
although at first they were just
deployed onto the same box it was an
iterative process process to get into
running micro services yep so if the the
first stage of this was to take what we
currently had and basically pull all the
infrastructure stuff off there so the
first one was to remove Mongo off of
that we moved that off onto its own node
still wasn't a cluster at that point
just an individual Mongo node and moved
up all the other infrastructure pieces
so we have RabbitMQ as an event bus and
some other things on there as well
now one things we started doing at this
point as well with we were previously
using our product to monitor our
products as well but we were
concentrating on monitoring resource
contention so we had a lot of things
running on one box or a lot things we
have running on the same machine they
could start starving each other
especially when they're on the load and
they're under different types of load we
wanted to make sure that one thing under
heavy load wasn't or we could see how it
was affecting our other services so yeah
one of our dirty secrets is as I said we
use Mongo
it's not a popular opinion to say that
you like Mongo but yeah it's it's done
us well it's yeah it just keeps chugging
and yeah we've had it for a while now we
originally adopted it because of the
flexibility it's really easy to query
you just dump it on a box and go I mean
it doesn't require that much
configuration it's really kind of
unpretentious it just gets on with it
this kind of comes to one issue we had a
couple of months ago around there was a
bug deployed in our query mechanism that
caused the load average on one of our
Mongo boxes to go up to 142 I've never
had a load on any books anywhere near
that in three digits before that I
thought was fairly spectacular one of
the equal
presses things as there are primary
Mongo box has been often 933 days which
year goes to kind of show the resilience
that I can have a box running for
several hours a load average 104 yield
and nothing kind of come yeah nothing
crashed it was very responsive but in
crash so yeah now we've got this get
state kind of state is the real issue
around managing scalability without the
state it's fairly simple to kind of
scale these things out the transient
services you're just kind of
horizontally scale them to a certain
degree I said yeah the the the main way
what the first thing to look at is also
your removing these state or segregating
state as much as possible into stateful
services and then keep the stateless
ones completely separate so that you're
kind of deformed you're you're splitting
out the the ways you're going to scale
these things l when you're working in
the state of services it's yeah I think
it's quite important to have high
availability clusters for them so that
you can lose a node and quickly recover
from that and bring another one back in
place
it doesn't necessarily mean it needs to
be kind of available in the CapSense as
long as you kind of recover within
seconds that's usually good enough
sharding it's kind of gets a little bit
contentious at points but we kind of
believers in shutting your data set as
it grows so the certain benefits you get
to this around performance you need to
make sure you're optimizing first kind
of sharding is a bit of a pain so you
kind of get need to make sure you kind
of optimize the performance as much as
possible before you start doing this but
when you do start shotting there are
other benefits to it as well so we can
geolocate data so we have customers
around the world Australia Far East US
Europe and having all their data located
in one location kind of works to begin
with but as we grow it it doesn't work
too well when you've got huger Network
latencies and general issues going on
it yeah it's hard to kind of manage when
you've got one central point and
everyone connected in from around the
globe so having these things
sharded that way helps it also kind of
helps for a certain data protection
issues some kind of customers don't like
their data being outside of the European
Union and so that kind of helps for that
so the v2 was a micro services yeah so
which started splitting these things out
it was a gradual process so we kind of
went from the one mana lifter then
splitting out separate services we had
so we had an exchange that will be kind
of collecting agent connected back to we
had a bunch of open source kind of
collectors support an open source kind
of protocols and we general background
workers were our first wings we split
out they were the ones that are on
intensive load all of the time so and
then then after that we started working
on our data models and entities to kind
of split those out as well as I and we
base this all around a central bus which
is race based on rabbit and queue at the
moment as we kind of scale that might
move off onto Kafka but yeah that's
working for early well in terms of
routing messages around the system one
of the CEO as I was saying we were
originally just running on Mongo they're
kind of the first thing we split off of
that was our time series data store so
I'm always great for flexibility and
kind of domain application data but not
really for time series data it's just
data it's not changing and coming in
really quickly so the first thing we did
is we rip this off and put it into react
so you guys are probably familiar how to
react works but yeah it's a key value
store based on the dynamic paper it's
kind of a hash distribution around the
ring I won't go into too much detail cuz
I tend to put people to sleep wondering
whether it's ops friendly which is a
massive plus we can lose a node or
certain proportion of nodes and not have
any customers affected and then when we
do have these issues or we need to scale
up the cluster the the command line
tools available for scaling the the
nodes up and down and the way that it
manages transition is shards around the
cluster you
it's super simple not so we haven't run
into issues around working with a data
inside of react but yeah and yeah it's
based on Erlang so they're kind of gets
back onto topic a little bit yes so this
is kind of our first production ready
version I guess many work well at first
and then around two years ago we on
board in two large customers maybe have
a little bit longer to large customers
within a month and yeah fire happened
which is not good
so yeah customers are dependent on our
system for monitoring their systems and
when things aren't working it's it's not
great even though we've got these things
out in two separate services if you're
failing to process the data as it comes
in you end up with empty dashboards and
it doesn't look good so we did is like
everyone else we put reddit in so the
issue that we're facing is that we were
yeah using nodejs and ya know just this
kind of quick in certain regards but it
just wasn't keeping up with the the
workload that we were sending into
process that time series data really so
we kind of worked around this by
injecting ready seein as a buffer so we
reduce an amount of work that nodejs a
to do and so the the main issue we were
having is that we see a lot of repeated
data coming through so that the same
time series but lots of points and we
need to kind of cache certain
information about that so we're not
constantly look in the things up and
then those the node has a kind of harder
limit the amount of kind of memory that
it can use and so we were constantly
blowing these issues and there were some
other issues around streaming that
nodejs us the kind of stream API that
allows you to kind of pipe functions
together and it handles the back version
of things but then when you break that
yeah it's bad so yeah so we started
editing it worked
ready again in awesome this just works
and yeah he's pretty powerful but yeah
we needed a week we knew we needed some
actual
solutions so this is the the start of
the Erlang story I don't know if you
guys have seen this the the Erlang the
movie I highly recommend it mostly for
comedic value first
another quick this is from Robert Verdi
one of the one of the creators of Erlang
any sufficiently complicated current
program in any other language contains
an ad hoc informal is informally
specified bog written Sloan penetration
of Erlang which it might be a bit harsh
but generally tends to be true so before
we started this we kind of looked at you
know what we wanted to get out of the
new technology we're going to pick for
building our call back in systems it
needed to scale we needed to support
being distributed for scaling purposes
and for H a so that needs to be a kind
of fundamental part of it reliable as
well when we're dealing with the the
volume of data that's coming through
although the processes could probably
crash early often and not cause any loss
of data and things because of the way
they slowly kind of ramp up to full
speed them crashing fairly often has a
huge impact on general performance yeah
another one is they need to be generally
quick so being able to be natively quick
or kind of offload into C is hugely
important production visibility when
you're dealing at this kind of scale
they being able to see what's going on
in the production systems whilst they're
running without massively negatively
affecting the the performance is a kind
of really useful to have I know this has
probably kind of upset some of the type
system nuts but this kind of you kind of
need this you can't really get around it
it's not a case of we've kind of misused
our types or anything like that so the
first thing we looked at was Java so a
few people in the team would work with
Java before for a couple of years
nobody was that keen on
getting back on that that was kind of
gets to off the fourth point in the on
there there was no real kind of driver
motivation behind doing that nobody was
particularly keen on the language its
were base kind of in expressive and then
you got the general garbage collection
madness of suddenly it's just going to
go I was collect and you can't do this
in yeah this gets fun to a chick's just
kind of a opinion on object to a
programming again probably a little bit
harsh but yeah probably a bit harsh
towards people from California
scholar we kind of like the look of
Scala but again still runs on the JVM
and a lot of the kind of negative parts
here are just things that are missing or
not as well well well defined as you get
in Erlang and OTP
but yeah generally looks fairly good but
yeah not it wasn't for us we also looked
at go so go is obviously the new hipster
thing this is growing pretty rapidly
everything now seems to be being built
and go doc oh yeah well the hash cult
tools and all that stuff but yeah it's
it's yeah it's still fairly immature the
performance is really quick but yeah
this this you don't get much the kind of
tooling around it doesn't seem to be
great or it wasn't at the time compared
to what we get with Erlang so although
it'd be useful for building kind of
little ad-hoc tools and things like that
and it wasn't something we wanted to
build a whole reliable back-end system
on the final one was see there was a lot
of kind of people that wanted to do this
just because it sounded cool but you
having built stuff in C before is yeah
not not not the most fun yeah so we kind
of we considered it for a little while
but quickly kind of dismissed it yeah
really useful for performance critical
things we use it for certain things in
our application but we kind of only
further performance critical parts of
number-crunching are things we do a lot
of kind of master process time series
data
we're also looking at rust for these
kind of things that we would previously
do and see seems to kind of have the
performance but the languages I'm a lot
more friendly to work with so Erlang so
yeah some of the kind of key brilliant
points around Erlang are the state and
concurrency model that it uses so you
don't have any the the the the idea of
shared state in Erlang you have a bunch
of processes and the processes processes
managed to their own state if you need
to update a process or something's gone
on you send a message to those other
process they update this state so the
act on model you've got here really and
that kind of fairly closely aligns with
general human interaction you know
nobody shares a brain you tend to
communicate by sending messages to each
other whether they're kind of vocal or
male or something so this really kind of
helps protect their your state and yeah
works really well when scaling things
out so allows you to kind of because you
have these things state defined in an
individual process where you need to
scale out the processes to multiple
calls or multiple machines this this the
a lot less work that you need to do to
do that and kind of Erlang takes care of
some of that for you as well I saw that
all on that point supervisors say Erlang
has the concept of let it crash which at
first sounded insane but it's a really
kind of powerful model so the way this
works is there you have the concept of
supervision trees so you basically
define what you how you want your
processes so that are running to be
spawned and how you want them to be
supervised so you you can have a process
that's kind of you know processing some
data as it comes in and if that crashes
then you want it to be restarted all the
time for your crush's too often you
might want to just die and crush the
whole application but you can
independently configure these things
which is really useful especially around
kind of protecting layers of your
application so you might have a process
running that makes all of your course
your database back-end and kind of
caches some things in memory there
you probably don't want that to crash as
often or restart as often as other
things so you'll kind of tailor your
supervision strategy around protecting
different layers of the application
things that aren't as aggressive to the
rest of the application when they start
up are probably fine to just crush them
and just keep restarting them another
cool thing is behaviors so this kind of
gets back to the maturity and battle
hardness of the Erlang an OTP system
that over the last 30 odd years that
they've been building Erlang now it's
they created these behaviors these kind
of common patterns for doing certain
things so if you have a kind of
client-server model in your application
they have a buffet behavior defined for
that and then wait the way you implement
or use that issue kind of you define
some callbacks and then say you're using
that particular thing so whether you're
using a client-server or you're using a
finite state machine or something like
that then you basically just need to
implement these callbacks and then the
library code the OTP code takes care of
all of the other stuff and it might
sound kind of fairly a simple
abstraction but it take care of
everything so monitoring the other kind
of process that you're connecting to so
if it fails mid-weight you've got a
partial failure midway through it
detects that and will handle those
issues for you so you it voids a lot of
the really hard to find bugs that you're
likely to kind of come across where it
works you know the first you know
thousand times you use it and then you
get the odd occurrence where it'll
failure and it will fail and it's kind
of impossible to track down so this this
loads of these well this several of
these behaviors that of have been
implemented in Erlang and you know
they've been tested to death over the
years and they tend to be fairly solid
so here image you can kind of build
these really reliable components of your
application with yeah fairly fairly
easily
another thing is visibility so yeah this
gets back to the production visibility
so you can actually bring off a GUI the
the observer and put it at your
production application and you can kind
of actually see what's going on inside
there so here you can see there's a
bunch of processes that I've been fired
up and you can see the dependencies
between the processes you can also see
the state some of the state of these
processes as well and you can send them
messages so if you want to kind of kick
things or you know test things out you
can do that via via this tool or the GUI
or the shell you can connect into as
well and yes this is massively powerful
being able to do investigation and
tracing on live applications is without
really affecting the performance of
those applications is really really
useful yeah and yet they're kind of the
last kind of major thing is the concept
of applications so they're the way that
the Erlang kind of virtual machine and
the beam works it kind of feels more
like an operating system that a than a
virtual machine
you kind of start these these
application things up which are an
independently kind of stop stoppable
thing that runs inside the bucket just
like an application on your or a process
in your operating system you can kind of
start stop these things independent of
the rest of them and so that means that
you can start up your stack with a bunch
of these applications and then kind of
split them out so you might have an
application here it's just a storage
application you know which is talking to
your database or whoever it is and then
you have applications for the other
services in your your app or your stack
as it were and yes you can run those all
in the same beam you can run on separate
virtual machines it's really kind of
configurable and they kind of work well
feel very similar to microcircuits and
you can kind of communicate amongst them
you can specify in your application that
it depends upon a another application
and have those loaded up when you start
your application or check to make sure
that they're there and running and yes
so this is really quite useful a couple
of other things yeah a distribution is
kind of at the core as I saying that
states kind of managed inside the
processes you can kind of split these
out to really take advantage of clusters
and multi-core machines which is
massively kind of useful now us as we
could hit the limit of CPU speed and can
I start to get on larger a lot more and
more calls and on machine and live code
read load as well we've not actually
used this so we build our services so
that they can just be independently
stopped up updated and reloaded but it's
it's a something that we'll probably
explore in the future so what you can
actually do is you're if you don't want
to run a distributed application so
there it was originally designed for
tell of telephony systems so there were
systems that couldn't go down and so
they needed ninety-nines of uptime so
they built in the concept of being able
to update the code whilst the code is
running and it has a kind of version
strategy in there to kind of update the
versions that are code in place and yeah
there's been running for for many years
and it's battle-tested so it's something
that would be more fun to play around
with than actually necessarily useful in
our situation but it might be the case
in future there are some negatives to
Erlang at the moment quickie syntax when
you first look at it it looks like
someone's vomited on your screen but
it's you kind of get used to it the
smaller community say the the number of
kind of Erlang developers aren't as vast
as Java or scholar or go or something
like that on nodejs but they tend to be
a passionate bunch of and a lot of
academics in that area as well so a lot
of people kind of look in a distributed
systems theory and consensus and things
like that so a smart bunch of people
this does have an impact on hiring it's
hard to find Erlang developers I kind of
caveat that with the ones that you do
find tend to be really good so you don't
have to filter out as many kind of
that's as you would hire another kind of
engineers and also you can kind of cut
cross train so we've hired some people
that were Scala developers and they can
picked up Erlang fairly quickly
look at the kind of concepts tend to be
the same it's just things better at
doing it the new kid on the block is
elixir so some Ruby people got bored of
Ruby not scaling and decided to kind of
jump on the Erlang bandwagon and so
they've invented a language called
elixir which runs on top of the Erlang
VM and so it can make use of
interrupting with Erlang code and OTP
and all the kind of mature hardened
parts of Erlang but using a nice kind of
sugary language there's a kind of a few
things that are missive missing from
Erlang kind of like string manipulation
things like that which on as good as
yeah other languages or completely
missing and they've kind of addressed
that in elixir and so yes he seems like
a nice language it's one that we're
going to start adopting as well there's
several reasons for that and yeah it's
growing it's growing really quickly
probably not the same speeders like no
GS and go have been doing but yeah
compared to a long it's grown at
lightning speed
so I'm scalable time series so this is
the next stage of our Erlang path so by
this point we'd replace the bunch of our
back-end services with Erlang they were
performing really well again it's not a
great metric to kind of specify the
number of resources you went down to
because when you rewrite anything you're
gonna really write it better than you
originally wrote the thing but yeah we
kind of reduced the amount of machines
that we needed to use when we were moved
to some of these services to Erlang but
yeah the next thing we looked at was a
really scalable time series database so
we built our own thing on top of react
which kind of got us to a certain degree
but then the the number of updates that
we were processing meant we were kind of
having to batch these up and write in
chunks into react and then you kind of
had to manage the kind of failure
scenarios or what brand the area with
the or batching things up which was
relased at the time so yeah we looked at
another kind of time series data store
another kind of thing around that was
the we also wanted a more queryable
database so we wanted to kind of run
some of these complex queries do
different analytics and provide
functions so the data as it come through
which would have meant write in all of
that stuff ourselves but we kind of
looked around to see what other things
are about we look to the likes of influx
and influx DB open TS DB and a couple of
other ones but yeah they wrote none of
them were particularly great and all
have their issues and so we kind of
stumbled across this one so we've been
using react we like the idea of react
Cora that kind of manages the
distribution it's kind of a funny work
for building these distributed
applications and takes care of the
sharding and the replication and so we
like the idea of that but yeah we
stumbled across this which had been kind
of written on top of yet core as well in
Erlang and so it kind of seemed to tick
all the boxes so we started
investigating and looked at some of the
benchmarks it's been running and it was
kind of yeah super quick so I kind of
recommend you guys taking a look if
you're interested in time series I want
to play around it's it's not as well as
doctored as all the time serious
databases so the documentation is a
little bit lacking but and once you get
there it's it's it's pretty quick so
yeah at the root of it there is runs on
Erlang uses react core for the
distribution it runs on top of ZFS we
used a data file on Linux but you can
use it on other on UNIX environments
obviously yeah and there's some Postgres
in there as well so the the reason for
the zero first is that are kind of
compressing the data on disk so we can
just write raw data we don't have to do
any compression ourselves we write the
raw data and let set of has to take care
of the the compression and we have
Postgres in there for create some
different kind of indexes for
multi-dimensional data yes so this kind
of gets back to the reactor ring again
so you know it uses react or for
distributing keys the time series keys
that come in around the cluster yeah it
gives it all other kind of high
availability redundancy etc completely
masterless technology so you don't have
to worry about particular nodes going
down yeah as I say it's a framework so
you kind of it takes care of doing a lot
of the the the stuff you need to do are
not building these kind of systems so it
will detect aliveness where there are
members up or down does the partition
and distribution tells you about the
cluster state when things are kind of up
and down and as with react you get these
nice set of tooling with a rillette core
to manage your cluster so you know you
want to scare your cluster up and down
yeah that you have all the tooling in
place to do that
you just really just have to handle the
kind of implementation at the the V node
level as to what you're actually going
to be storing and yeah it allows you to
kind of monitor the state of the cluster
which is really useful from our
perspective so some benchmark so we used
to talk called Haggar which is a
graphite benchmarking tool dell matino
supports the graphite protocol well
there's a way of great and support the
graphite vertical so we fired off a load
of these Haggar instances as i started
chucking data into the dalla tina
cluster and these are genuine benchmarks
we run on kind of fairly moderate
hardware in terms of the performance you
can get yeah kind of average between
three to four million
metrics per second which is yeah there's
nothing else that I've seen this gets
anywhere near there and yeah it kind of
linearly scales as well so when we fired
it up to five nodes you get the same
level of performance so we wrote a blog
post on it as well so we looked at all
of the other time series databases or so
no PTSD be in flux
graphite etc etc we've got a little bit
of kind of heated feedback on this
obviously they tend to be a little bit
opinionated but we try to reproduce the
on a standard set of tests to run across
these to actually get an idea of what
which ones are kind of quicker
these are supporting reads as well at
the same time like you can't get kind of
skewed metrics back from these things if
you're just accepting rights and never
actually read them from them and we work
with Heinz's that guy who wrote the who
wrote down latina to kind of improve
certain aspects of that as well to make
it more efficient for reading etc so
yeah you don't get any of this free
there are some trade-offs so when it
comes to processing time series data we
we have no kind of strict guarantees
around your data it is possible to lose
your some data I know that sounds
terrible but when it comes time to it if
you lose a couple of seconds or a few
points of data you're looking at trends
anyway so it's not that bad and then
this is all guarantees it doesn't mean
you're actually going to use your data
so you can configure the cluster in such
a way that you've got several replicas
and so you'd need to lose all of those
nodes to lose the data the only reason
we don't guarantee any data protection
is for a certain window of time things
get buffered in memory so if all of the
nodes with that replication of data went
down at the same time you would lose
like ten minutes of data in memory for a
certain set of metrics so yeah there's
no guarantees around your data making it
to disk but that doesn't tend to be an
issue and yeah you kind of more likely
to lose data elsewhere from different
parts of the pipe spilling over and
things yeah you have to kind of be
careful around the memory usage and
cassia caches so you have to kind of
allocate some memory for ZFS to do its
thing as well you kind of we have to set
things up in order to make things more
optimal for reads so yeah this is it's
part of the way that the the the
dommatina works the way it kind of
indexes data in a kind of consistent
format as opposed to having direct
lookup indexes for the data but yeah I
won't get into too many specifics
because it gets a little bit boring
yeah we only support 32 62 bit floating
point numbers a couple of those bits are
saved for different flags so yeah we're
a little bit less accurate than some
systems but yeah a couple of bits don't
tend to matter that much it also has a
proprietary binary protocol this was
kind of a little bit difficult to adopt
yeah you kind of have to
reverse-engineer the binary protocol the
moment if there's not an SDK that works
with this and for the language you're
using but if you use a know language
sort it so yeah this is kind of what we
ended up with which is not too
dissimilar to the first architecture
diagram so we we split out the systems
into separate services we have a huge
ring in the middle for our time series
data store and then just a bunch of
background workers processing the data
as it comes through so yeah we tend to
avoid having state as much as possible
and try to keep those the actual
stateful parts in one particular a
separate from their that the non staple
parts are the application and yeah this
is where we got to at the moment
this isn't the kind of we're not done we
need to kind of keep going but as I say
we're a company we need to make we need
to build features and keep iterating on
the stuff that's going to add value to
customers and so we kind of work on this
the micro services stuff as we go yes
the stuff we learn during our Erlang
adventure is some of these things
weren't I've kind of touched on a little
bit they weren't as obvious when we
first started that how valuable they
would be so yeah a massive one is live
code Tracy NC being able to look at
what's going on in a running application
and being able to kind of product and
poke it and get stuff out is massively
useful again the the let it crash
approach it took me probably longer than
other members of the team to get my head
around why this is particularly useful
especially when certain parts of the the
system crash that it's a general
the general approach for Erlang it does
actually prove to be really useful so
you don't need to handle all of your
edge cases and protect against failures
throughout littered throughout your code
you're kind of right for the the sunny
day scenario and when things go wrong
you kind of catch them and restart them
and I'll see you looking at logs and
monitoring how well these are performing
and then so if something is actually
going wrong in your application and
there's a bug that you need to fix then
you can grab it at that point and fix it
but most of the times things just crash
for random reasons and they're not that
critical - they're not things that you
need a fix straight away so this keeps
your processes to stuff and run in and
and ticking along yeah and again the
community we we knew that it was going
to be small but we were kind of fine
with that but yeah we weren't quite we
didn't realize how yeah how kind of how
passionate and how strong that the
Erlang community is it kind of they're
growing in numbers now especially with
the adoption of elixir but there's a lot
of smart people working in Erlang and
pushing the things forward another thing
is we we have a fairly close
relationship with Erlang solutions
so they're kind of consultancy Erlang
consultancy that we use for outsource in
different parts of the application and
neat building so they have a large bunch
of Erlang engineers that will that you
can kind of off offload work on to to
help they also kind of help with
training up some of the team as well and
it's useful to kind of be able to fall
back to the kind of a bunch of guys that
are really experienced in the area so
what's next so we're gonna Erlang all
other things specifically all of the
back-end workers are going to be Erlang
eventually and probably changing the
api's as well to say we get rid of all
of the no GS and we'll use Erlang and
elixir for all those things and you
really want to play around with a live
code reload in it sounds it sounds fun
okay this better up sit up so yeah kind
of closing up on the the startup stuff
everyone's looking if there
he's doing a startup or they're kind of
looking at it this is kind of the things
I wish I'd known was starting a startup
yeah it tries to kind of ignore the
dogma as much as possible there's a lot
of people say you shouldn't be building
these things in certain ways or you
shouldn't be a scrappy yeah you kind of
just have to get on with it get it
working
make it fast and then yeah I just shot
the hell out of it you can be a little
bit other over the top on making sure
you build the most elegant this should
be it's just impossible but then you
look at all the success stories around
technology companies they tend to follow
this approach at least in the early days
yeah be scrappy you need to get stuff
delivered but always yeah kind of this
bird the one that's kind of always you
have to kind of come back to pay your
debt so you need to be scrappy to get
things delivered but then kind of come
back and fix these things up you can't
just wait until your systems on fire and
yeah don't rush to the shiny things it's
always a tendency to see the new core
technology and want to use it straight
away docker comes to mind and all of the
kind of technologies and things that
around that yeah it's not ways a good
fit it might take a while
yeah and this pretty much you look at so
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>