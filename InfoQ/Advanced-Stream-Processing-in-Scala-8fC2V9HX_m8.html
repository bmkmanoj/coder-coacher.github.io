<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Advanced Stream Processing in Scala | Coder Coacher - Coaching Coders</title><meta content="Advanced Stream Processing in Scala - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Advanced Stream Processing in Scala</b></h2><h5 class="post__date">2013-03-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8fC2V9HX_m8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm gonna be talking about stream
processing today and I've got a lot of
stuff I'm gonna try to cram into 30
minutes so just as kind of a disclaimer
/ shameless plug up front here there is
much better coverage of these topics in
the last chapter of the book that I'm
writing with rune our functional
programming in Scala and the book also
does a much better job than I can do
here in 30 minutes just introducing all
the things that I'm going to build on
here and and all the stuff that you need
in order to get to this point so and I
encourage you to check it out and the
book is actually half off today if you
use this discount code which I will
flash up again at the end so we're not
set let's let's get rockin here so we
are going to start by looking at what is
called a single input stream processor
and it's this this type process 1 and it
defines so process 1 IO it defines a
transformation from a stream of I values
to a stream of values where a stream is
defined like more broadly it could be an
in-memory Scala stream or it could be a
stream of rows coming from a database a
stream of HTTP requests a stream of
lines coming from a file etc so it takes
the form of a state machine that can be
in one of three possible States so it
can be in the halt state so this signals
that the the transformation is done
emitting values to the output stream and
reading guides from the input stream and
the transformation is finished it can be
in the state of emitting values to the
output stream in which case we have the
sequence of values that should be
emitted to the output and then tail
which defines the next state to
transition to after those values have
been imited and finally there's an await
state which indicates that the
transformation needs to read a value
from the input stream and then when it
gets back an i it's going to use this
receive function to transition to the
next state
and if the input stream is exhausted
there's no more elements left in the
input stream then we transition to the
fallback state okay so pretty simple
so here's let's look at a typical
definition line wrapping is a little bit
angled but so this is a a process that's
going to compute a running sum of all
the values that it seen so far and you
can see we're just in a loop we're going
to await so read a value a double from
the input stream and then we're gonna
admit that value added to the current
accumulated total and then we're going
to recurse or repeat our next state will
just call go again with the new
accumulated total and if we are sort of
a plot to apply this to an in-memory
scala stream we get the running total of
the values that we've seen so far pretty
simple so let's look at how we actually
write a driver or an interpreter for one
of these processors so it's a state
machine and it's a state machine where
it's can issue one of three possible
instructions halt await or omit so this
is a simple function that interprets
those instructions in order to actually
transform a stream an in-memory stream
of hi to another stream of oh and you
can see this is pretty simple if the
state machine says halt we return the
empty stream if the state machine says
read from the input then we attempt to
do so if that fails we transition to the
fallback state and if the state machine
says omit values to the output stream
then we do so and then transition to the
next state okay so let's look at some
operations that are defined for process
so we can think of a process a little
bit like we think of a list in the sense
that the process is going to eventually
emit a sequence of values and so a lot
of the operations that were used to from
working with lists are also defined for
process for instance we can concatenate
two processes together run the first
process
when it halts run the second process we
can flatmap over a processes output we
can map over a processes output and
there's lots of other functions that we
can define repeat this is run a process
until it halts then run it again until
it halts and so on until the end of time
or until the input runs out of elements
we can define filter take take while
drop while pretty much any list function
that you could define that operates in a
single pass over its input you could
define that as a process okay so on the
other hand a process behaves a little
bit like a function from I to O or
there's there's analogous operations
that are defined for process so we can
lift any function from I to O to be a
process so you can see the way it's
defined we await get back the I then we
omit the function applied to that I and
then we repeat this is making use of
that repeat Combinator that I showed
before and we're just going to keep
doing that until the input stream runs
out of elements so another operation
that we can define is composition so
just like we can compose functions we
can compose processes so this is given a
process IO we're gonna feed the output
of one process in as the input of the
second process and the way that this
operation is defined is that these two
stages are actually going to sort of
fuse together so that as soon as values
are emitted by the first stage of the
composition they're going to be
immediately that chunk will be
immediately consumed by the second
stages of the process so using this we
can actually define these pretty complex
pipelines of transformations so here's a
line counting process that we're first
going to filter out any commented lines
and any blank lines we're then going to
map any remaining lines to the number
one we're going to sum it and then
finally convert back to an in at the end
and this is all going to sort of fuse
together as if we had written this as
one big monolithic loop pretty much as
soon as values are emitted by the filter
they're going to be consumed by the next
stage and so forth and this is actually
I mean this is a nice little programming
model we're getting to assemble these
complex loops from simpler pieces and
still get the same overall efficiency as
if we had written things in a more
monolithic way okay so that's general
idea of the stream processor now this
little data type that we've built up so
far it's it's a little bit limited so we
can only define these pure linear
sequences of transformations right so we
don't really have a way of talking to an
external data source like a file so
that's a file the the stream of lines
from a file is not represented in a
first-class way in this little API yet
and you know we're also yea constrained
to these linear sequences of
transformations really what we'd like to
be able to do is construct pretty much
an arbitrary network of these processes
where we can fork things off broadcast
the same signal to multiple processes
and have them all maybe process in
parallel I want to be able to of course
read from external sources like files
and so forth I want to be able to write
to files I want to go to do all these
things and our current process type is a
little too limited so let's think about
how we could generalize it alright so
just as motivation let's look at the
await case of process so you can see it
has this receive function and receive is
expecting an I so what this a wait case
is implicitly assuming is that there is
some context a stream which is going to
be providing us with I values
okay so we're kind of hard coding what
the context is we're saying the context
is always going to be
a stream of eyes a single stream of eyes
so if we want to generalize this we need
to abstract over the context so here's
how we can do that so I've changed the
awake constructor so now it's
parameterised on this type constructor F
and you think you can think of f as the
request type it controls what are the
types of requests that this stream
processor can make and for any requests
that it can make F of a somebody else is
going to be responsible for evaluating
that F of a give giving me an A and then
calling the receive function to
transition to the next state so these
two a is of course have to agree and
then the other stuff here is the same we
still have this fallback case I did add
this on error case which so a process
could actually terminate in one of two
ways one is if the input is exhausted
normally and the other is if the input
is exhausted with an exception and
that's um this is important for ensuring
resource safety making sure file handles
gets closed and so forth although I'm
not gonna really talk about that too
much today so here's the full process
type the await case is really the only
one that's changed the others are just
propagating through that additional type
constructor so first of all let's notice
that a lot of the operations that we've
already defined for process are going to
work exactly the same so we can still
concatenate two processes these
generalized processes run the first when
it halts run the second that still works
the same same deal with flat map and map
repeat so so that's good now let's look
at how we can actually encode a process
one as a process now the way that this
is encoded in Scala is somewhat
interesting what we're basically doing
is we're going to construct an F that
type constructor F which only allows us
to make requests for values of type I
and here's one way you can do that in
Scala we introduced this class is I and
inside of the is AI class there is a
type F but you can see the only
constructor that exists is the one that
instantiates f with I so if I have a
process is I hash F then I'm basically
saying this is a process that can only
request values of type I so if we we
look at sort of a call to a weight we're
going to say a weight
get me an integer and then the integer
that we get back has that that type
integer has to agree with the type of
the input to this function so if this if
you're not following this exactly it's
it's not not too too important but I
guess the the takeaway here is that
we're able to construct an F that
constrains the type of requests that we
can make and in this case we're just
saying we can only request values of
type I okay so now that we have this
representation of process one we can go
ahead and define our compose operation
that we defined before except this is
now that type alias that I just
introduced in the last slide but other
than that the definition is going to
work exactly the same way okay so now
that we've sort of used that trick well
we could craft an environment which
allows us to make requests from one of
two possible input streams so this is a
this is a sort of a request type that
allows us to request a value from the
left which is going to have type I or
request a value from the right which is
going to have type I too and we're gonna
call this a T because you know the shape
of the letter T it's sort of combining
together sort of two different things
into one and we can just define this as
a nice little type alias so this is a
process which could make requests from
one of two possible input streams
all right so let's use this to define
zip with so zip with is a T and let's
look at its definition we await L so
this weight L is just a little
convenience function that's going to
call a weight passing in that L request
value so we're gonna await from the left
we get back a know a weight from the
right get back an o2 and then we're
gonna emit the function applied to those
two values that we just received and
then we're gonna repeat okay pretty
simple and then we can also define a
function on process T which this is
going to take one process another
process and a T and then feed the output
of those two processes to to the T that
you've just defined so you can use that
in conjunction with the zip with two zip
together processes merge them so there's
notice there's nothing about T that
requires that we read one from the one
source and then read from the other
source we could Reif read 50 values from
one source then three values from the
other we can interleave the two sources
in whatever way we want so we have a lot
of flexibility there okay so let's look
at how we can represent effect full
sources like the lines of a file or a
stream of HTTP requests or you know a
stream of rows coming from a database so
it turns out that if we just let the F
type of our process be some monad like
let's just pick IO IO monad then you can
think of that as a source of values so
I'm gonna explain how this works so
let's look at the await case so here
I've just substituted in few sorry
substitute in IO for the for the request
type but you could also imagine maybe
future a so let's think about if we if
we're writing a driver and we encounter
in a wait case we're gonna have an IO
action or a future and then we're gonna
have
a essentially a callback to transition
to the next state
once we've evaluated that future so all
we need to do is just evaluate this or
run run the computation and then when we
have the a we go ahead and call the next
state and of course this could be you
know using actual non-blocking i/o
primitives behind the scenes using
futures and so we don't necessarily need
to be occupying a thread and so forth so
it actually turns out that we don't even
need to be able to run the computation
we don't need to be able to run the
request type we just need to be able to
flat map into it so we just needed to be
a monad and we need a little bit more
than a monad because it needs to be some
context where we can catch exceptions
and throw them but it's essentially a
monad when you when the state machine
says await we just flat map into the
request and then we that now have the
value the result and then we transition
to the next state and we can define this
function collect for instance which
given a process fo and a monad it's
going to return an F of all the values
that were emitted by that process so
this is kind of the end of the universe
okay run your entire process and get
back its list of results okay so let's
look at some examples of using this so
we could create a process which is
backed by the lines of a file it's a
process
io string and then we can transform that
as if it were any other input stream we
can compose it with other things filter
it map it we can then pull in another
file as we go let's look at another
example the rows of a database given a
prepared statement we can get a stream
that is the output of you know all the
rows of that query running that query
and then more generally we can define
this resource safe Combinator here
resource which is going to build some
stream from
resource which needs to be allocated and
then cleaned up when the resource is
done so for instance yeah this wood
could be a file you need to open the
file at the start so you need to acquire
a file handle and then you need to make
sure you close the file when you're done
either if an exception occurs or if you
just are done processing so so now we
can read from effect 'fl sources like
files streams of HTTP requests and so
forth so what about writing to files or
you know writing HTTP responses or
writing to a database so it turns out
this is kind of a somewhat surprising
thing but we can think of a sink as a
source of functions so a sink F o is a
source of functions except they're not
pure functions their effect Philomath
so it's a function that's gonna return F
of unit let's think about how this would
work let's say we had file in which is a
process io string let's say it's the
lines of a file and then we have a file
out which is a process that is functions
from string to IO unit so if we were to
just zip these two together using our
existing combinators we could we get the
line and we could get the function and
now we can apply the function to the
line and we get back what a process IO
IO unit right because we get all the all
the i/o units that are produced by that
file writing process so how do we
actually run all those IO actions well
it turns out there's this function that
you can define eval which you can
actually define for any F type it
doesn't care and all we're going to do
so this is the relevant case here is
right before we emit a value in the
process we're going to
a weight to basically request that the
driver evaluate that action and then
when we have the result of that action
we're then going to emit that
so let's now use this so we can even
generalize it a little bit further our
our sinks don't need to just return unit
they can actually return a value so we
can define this type channel which is an
effect whole transformation between I
and O and you can see it's just a source
of functions from I to F of O
so using this and this function - we can
define this is like a little example
here read the lines from this file
filter out any comments map over the
lines of the file converting Fahrenheit
to Celsius and dump that to Celsius txt
and this is all going to happen
incrementally possibly even using
non-blocking i/o primitives and you know
we're not going to load the entire file
into memory and we're also assured that
the file is going to be closed in the
event of exceptions or if things
terminate normally so this is pretty
awesome
so we've so far constructed a little
library that lets us describe these very
complicated process networks it's really
an arbitrary graph because since we can
send messages or elements in either
direction we can represent both source
and sink sources and sinks and we have
this branching operation T that lets us
sort of connect up to linear linear
pipelines of transformations we can now
pretty much represent an arbitrary graph
of of things that are happening okay but
there's just one problem with what we
have so far so the problem is that we're
forced to be completely explicit about
the order that the effects are happening
throughout the entire network so to see
why this is kind of a problem
let's look at let's go back to the zip
with definition from earlier so there's
something kind of arbitrary about this
definition so I'm awaiting from the left
and getting back an O and then I'm
awaiting from the right and getting back
an R so I'm explicitly picking an order
I'm saying read from the left and then
read from the right now I may want to I
may want to be varied that explicit
because maybe there's some external
effect associated with these requests
and I want them to happen in a
particular order but I may just want to
say hey requests from either the left or
the right I don't really care whichever
one comes back first I'll take that one
and then I'm gonna make a request for
the other one that I didn't get okay so
we can represent that sort of
non-deterministic choice with a new
request type which is called Y and so Y
now has three cases we can request an A
we can request a B or we can request
either A or B I don't care in which case
we're going to be prepared to handle
either an i or an i - okay so we can
still make the same explicit request but
now we can also non-deterministically
make a request for one side or the other
and again we'll define a type alias here
that just wraps that up in a type Y okay
so let's revisit our zip with example so
now the definition looks a little bit
different so we're gonna await a B again
that's a little helper function that's
just going to call a weight with the a B
as the request so we're gonna await a B
and now we're prepared to accept either
a no or no tip so if we get back a no -
then okay let's get the the oh by
explicitly requesting from the left side
and if we get back a no then we
explicitly request from the other side
so what this
mission is allowing for is the
possibility that whatever is
interpreting this driver or whatever's
interpreting this process is free to use
parallelism at this point so at this
point when this request is made we are
allowed to potentially run the two
requests in parallel and just race them
and whichever one comes back first use
that so in order to actually interpret
that request that things be done
non-deterministically we require a
context that supports a non determinism
and not all contexts do but so here's an
example of how we can represent the
ability to make a non-deterministic
choice explicitly so F is a context
supporting non determinism if it has
this operation F of a which can choose
between F of a and F of B and let's look
at it for a specific type like say
future so this is saying okay I have
these two futures a and B run them both
in parallel race them whichever one
comes back with a result first let's say
it's a in that case then I'm gonna
return the concrete a that I got and I'm
gonna return a residual future for B
because b may that may still be running
and like ready to dump a B to you know
some variable in the implementation so
either a could win or B could win in
which case we get back a B and a
residual future for a so this data type
just gives us the capability of actually
interpreting that non-deterministic
request and you can maybe sort of
imagine how you would make use of this
data type in the implementation of this
function Y which is now going to take a
process F Oh a process f o to a Y which
may non-deterministically make requests
from either side and a strategy or the
capability of actually implementing or
making use of that non determinism in
the interpreter okay so I'm like
breezing through things here but so now
the last thing I'm gonna talk about I'm
gonna sort of hand wave a little bit but
so we now have the ability to describe
these pretty much arbitrary networks of
processes we can fork things off we can
merge multiple input streams and we can
express non determinism at any point in
our in our network and that's a very
powerful thing so it seems like it is
possible to take a process network and
not just run it on a single machine but
actually compile it to a network of
actors that communicate by a message
passing and these actors could actually
live on different machines and the
interesting thing is we have a ton of
metadata so we have all this information
about where non-determinism is allowed
in our process networks and we also have
all this information about exactly where
effects are occurring as well and so we
have I think enough information to
compile the same process Network
description to a actual distributed
implementation that is still faithful to
the semantics of the original single
machine description so this is kind of a
night just an idea at this point sort of
hand waving but this would be sort of
the holy grail of you know you could
define a this really complex process
network test it locally and then just
simply compile it and have it execute
concurrently on you know 50 different
machines so that would be pretty awesome
if that were possible but
not not not implemented yet okay so
wrapping up here so obviously ruin our
and I we've been working together a lot
on this stuff for the book and but in
addition my co-workers Dan Dahl and that
commit who I don't know if they're in
the audience but they've been working
with us on this stuff too and Ed has
this great library in Haskell the
machines library which you can check out
if you're interested and there's also a
scala port by Runa and Dan Dahl and
lastly I think we're gonna try to so
that this library sort of crystallized
enough I think that we're gonna try to
port it to Scalzi at some point soon
it'll probably be a separate like
sub-project of scalzi but yeah it should
be pretty awesome and you know you guys
should check it out once that gets
released you know hopefully maybe in the
next few months we'll at least have some
something alpha-alpha quality that you
can check out and of course a lot more
stuff in the book if you're if you're
interested so yeah that's all I got
questions
so at Precog in one of our early
iterations on our product we we used it
er tees to serve somewhat the same
purpose here and one of the problems we
encountered was that with the overhead
of you know function calls in Scala that
just performance-wise we couldn't afford
to do things on an element by element
basis we had to do things at a block
level and yet there are some operations
which require you you know take take a
co group operation or a joint operation
or something like that that require you
to look at things on an element by
element level so how do you go about
with with machines sort of Trance
translating between those two contexts
where you need block level level
operations where you can't apply them
just purely for performance and element
level operations where the semantics of
the of the operation needs needs that
okay so I think yeah I mean the the
stuff I'm talking about here is sort of
independent of doing chunking but I mean
one thing you can obviously do is you
can deal with more coarse-grained
requests so you can request okay not
just you know one element you can
request 50 elements at a time and when
you have those 50 elements you can
operate on things explicitly chunked so
that's one way you can eliminate some
overhead but yeah I mean I think on some
level you're you're paying a little bit
of a price by having this really
compositional API I mean if you really
need to just write a monolithic loop to
get that last you know 15 20 percent or
whatever performance like
yeah well so I guess I guess the thing
is there's there's huge advantages to
having a compositional API and usually
that outweighs the disadvantages maybe
of some constant factors but I mean I
think it depends on what you're doing it
looked like there was a narrow instance
for a process one so I was wondering why
T and Y aren't represented as products
of processes instead of with special
type representations that was shown
maybe come talk to me after but it the
the arrow for if you the arrow for
process one so I guess T allows you to
be a lot more explicit about the order
that things are happening the general
sort of arrow zipping operation you're
not actually specifying whether you're
gonna do the thing on the Left first and
then the thing on the right first or
maybe do 50 things on the left person
and 50 things on the right so T gives
you in general a lot more flexibility
than what kind of an arrow eyes
API could give you I kept I kept
thinking through the whole first part of
the talk this this should map to actors
quite naturally in order to execute the
whole thing so I'm glad that you
mentioned that you might be interested
in the type channels I worked on to make
actors actually adhere more to the model
you're describing of explicit
input-output types but there is one
thing which is which is missing in your
description and that is the supervision
aspect which we implement in our car
when an actor fails that it is not
actually the duty of the one doing the
wiring or the one having sent the
message to handle failure but the
supervisor because it is not always
possible to group that failure code in a
convenient location in this sense so you
need this
entity above it yeah so that's that's
something I I haven't thought too much
about but yeah the the whole supervisor
hierarchies and and how does this play
into that you know I haven't really
thought about it but I think it'd be
interesting to see how that maybe could
serve things like that can be
incorporated into an API like this</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>