<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Build a Better Monster: Morality, Machine Learning and Mass Surveillance | Coder Coacher - Coaching Coders</title><meta content="Build a Better Monster: Morality, Machine Learning and Mass Surveillance - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Build a Better Monster: Morality, Machine Learning and Mass Surveillance</b></h2><h5 class="post__date">2018-02-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gbZeSdQdrCs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">behold the wonder something many of you
have never seen before a conference talk
with no slides all right
I need your help to get through this but
we're gonna attempt it my name is Matias
aguas ski I am an immigrant and I have a
fond memory of coming to the United
States in 1981 from Eastern Europe with
my mom and experiencing the wonder that
was the Safeway supermarket
my first supermarket we've go there
every week and for a kid from the
Eastern Bloc it was pretty astounding to
see something like an aisle of breakfast
cereals which is essentially a bunch of
cartoon characters telling me to eat
sugar that was not something that
carried over from my experience in in
the communist countries and each time I
what my mom would give me a quarter to
play pac-man being a good socialist kid
I thought the goal of pac-man was to
help pac-man who was lost in a maze find
his friends so my games would not last
very long the correct way to play
pac-man you all know is that you consume
as much as possible while running from
the ghosts that chase you so it's a good
primer into what it means to be an
American the game taught me that the
technology and ethics are actually not
so easy to separate and that when you
want to figure out how a computer system
works it's always a good idea to follow
the money
but today the technology that ran that
arcade game it permeates every aspect of
our lives we're here at this emerging
technology conference to celebrate it to
find out what the exciting new
developments are to get ahead of the
curve but just like the tail follows the
dog ethical concerns about how
technology affects who we are and how we
live together as a society they follow
us around and we can run faster but we
can't get away from them and this year
especially there's an uncomfortable
feeling in the tech industry that we did
something wrong then in following the
credo of move fast and break things we
unintentionally knocked down some stuff
that was actually the load-bearing walls
of our democracy we don't really want to
take blame for it but we feel uneasy so
you see a consensus now that we kind of
we're talking about people being too
deep in their filter bubbles and we have
a mysterious situation where Americans
have somehow polarised themselves into
opposing camps worried CEOs and venture
capitalists are roaming the landscape
they're peering into the churches and
diners of red America trying to find
answers it's
case the founder of AOL is is roaming
the middle of the country trying to get
people to start startups Mark Zuckerberg
has a photographer photographer in tow
doing beautiful photo shoots of him
talking to the people according to this
reading the polarization is a baffling
phenomenon that came from outside tech
but one that we can fight from within
tech with better fact-checking with more
empathy and in Facebook's case of course
they're going to deploy advanced
algorithms in AI to steer conversations
in more productive ways but a question
very few people are asking is whether
the tools of mass surveillance and
social control that we spent the last
decade building could have anything to
do with the debacle of the 2017 election
or whether destroying local journalism
and making national journalism almost
entirely dependent on these platforms
might not have been a stellar idea so we
built the commercial Internet by
mastering techniques of persuasion and
surveillance that we've now extended to
billions of people including essentially
the entire population of the Western
democracies but admitting that this tool
of social control might be conducive to
authoritarianism is something that we're
not ready to face you know we value
freedom so how can the tools and
techniques that we've built and we still
run not be something that serves freedom
as Upton Sinclair said it is difficult
to get a man to understand something
when his salary depends on his not
understanding it I'm gonna contend in
this talk that there are structural
reasons to worry about the role of the
tech industry in American political life
and that we have a brief window of time
in which we can fix it so the economic
basis of the Internet is surveillance
every interaction with a computing
device leaves a data trail and whole
industries exist that consume the data
unlike dystopian visions in the past
that this mechanism isn't run by evil
governments and industry and kind of
faceless corporations entirely it's also
run by a small group of sympathetic tech
companies run by quirky founders who
want to build Mars rockets and do cool
things with robots that make the world
better surveillance is just a way for
them to pay the bills while the Snowden
revelations in 2012 made people anxious
about government monitoring they don't
feel seem to feel the same anxiety about
commercial surveillance its accepted and
it's a striking fact that man
surveillance has been driven almost
entirely by private industry anyone who
owns a smartphone right now carries a
tracking device that knows with great
accuracy where you've been who you last
spoke to has all your photographs has
really intimate details of your life you
carry it in your pocket voluntarily if
the government made you carry it and
we'd be in the streets protesting
internet providers collect and can sell
your aggregated browsing data to anybody
they want and a wave of smart devices
for the home is competing to bring this
internet surveillance into the most
intimate spaces enormous ingenuity
ingenuity also goes into tracking people
who try to opt out of this whole of this
whole situation and circumventing their
attempts to block and avoid surveillance
with the exception of China which has
its own set up the information these
sites collect on users is stored
permanently and with almost no legal
oversight in the United States on
servers that we don't know we don't know
their location we don't know who runs
them but we start we trust the system
and two companies in particular dominate
the world of online advertising and
publishing the economic engines of the
surveillance economy the first is Google
valued at five hundred and sixty billion
dollars that's yesterday it might be
different today it's the world's de
facto email server it occupies a
dominant position in almost every area
of online life it's unremarkable for a
user today to connect to the internet on
a Google phone using Google Hardware
talking to Google servers servers on a
Google browser while blocking ads served
by Google Adsense on sites for the track
visitors with Google Analytics and
double-click and and whatever else it is
the Google owns and through initiatives
like a MP advanced mobile pages Google
is also attempting to extend its reach
so it becomes a proxy server for the
publishing industry and then Facebook
valued at four hundred billion dollars
it has close to two billion users and is
aggressively trying to expand to the
next billion it's the world's largest
photo storage service it owns the
world's largest messaging service
whatsapp with a billion users and for
many communities Facebook is the tool of
choice for political outreach and
organizing for event planning for
fundraising it's the primary source of
news for a sizeable fraction of
Americans and through its feat algorithm
which determines who sees what has an
unparalleled degree of editorial control
over
what that feed looks like together these
companies control 65% of the online ad
market which in 2015 was 60 billion
dollars that's the entire ad market so
of that amount half went to Google and 8
billion went to Facebook Facebook the
smaller player is more aggressive in the
move to new ad in contact formats
particularly video and augmented and
virtual reality these companies
exemplify the centralized feudal
Internet of 2017
so while the protocols that comprise the
Internet remain open and free in
practice a few large American companies
dominate every aspect of online life
Google controls search and email Amazon
controls cloud hosting Apple and Google
have a duopoly
in mobile phone operating systems and
Facebook of course is the one social
network there's more competition and
variety among telecommunications
companies and gas stations than there is
among these internet giants and all
these companies have one thing in common
which is an insatiable appetite for data
they want to know where their users are
what their viewing where their eyes are
on the page who they've been with who
they're with now what they're discussing
if possible with their heart rate is if
they're asleep or awake any possible
piece of data they can find they have
two interlocking motives for this data
hunger the first one is to drive online
advertising and the second is to Train
machine learning algorithms everyone's
familiar with online advertising the ads
are served indirectly it's based on
real-time auctions that are conducted at
the moment the page is served and it
goes through a maze of intermediaries
this highly automated market is a magnet
unfortunately for fraud so a lot of the
complexity and modern ad technology goes
into additional and very invasive
countermeasures against it to make sure
that there's a real human being sitting
at the keyboard or in front of the phone
but curiously despite years of
improvements in the technology and the
amount of user data available to the ad
networks online advertising isn't really
targeted that well and you can prove
this to yourself just by turning off ad
blocking for a week and seeing the kind
of ads that you're served
I think just last week Chase Bank
stopped serving ads to 95 percent of the
websites on its list it went to a
whitelist because it was terrified that
its ads were appearing next to some on
some right-wing sites and according to
Chase at the
see any difference in its metrics even
after cutting out 95% of domains so it's
an odd situation where the advertising
kind of works in very opaque ways many
advertisers are simply not equipped to
use the full panoply of these
surveillance app options people are just
kind of checking boxes in a spreadsheet
because their boss wants them to have
this kind of tracking and that kind of
tracking so that's one reason for it
another reason is that adversaries like
I said have become really good at gaming
these online ad marketplaces which
introduces noise into the system and
makes the targeting work not as well and
uncharitable but I think accurate
description of online advertising in
2017 is these robots that are serving
ads to other robots and we're kind of on
the on the margins of that a
considerable fraction of the money
that's sloshing around in the system
goes to scammers unfortunately only
Google and Facebook know the the the
true numbers there so surveillance
giveth and click-fraud taketh away
the surprising and effectiveness of
targeted advertising though creates
pressure to collect more data not less
ad networks are not just evaluated by
how much money they're making now but by
expectations about what new ad formats
are going to make possible in the future
this dynamic that I've called investors
story time the more poorly your ads are
performing today the more room there is
tomorrow for new algorithms and new
forms of data to create these magical
levels of of AD engagement that
everybody wants to see and of course
they're going to require new forms of
surveillance to make happen this trick
of constantly selling the next version
of the ad economy works because new ad
formats really do have better
engagements at old ones advertised
advertising is like a disease it takes
people time to develop immunity and
tolerance and you know even the first
banner ad had a click-through rate of
70% so while the drive for novelty is
good for the ad networks
it hurts publishers than anyone else
trying to earn a living from the actual
ads consider Facebook instant articles
which rolled out with great fanfare a
few years ago and now are a dead end for
online publishers Facebook promised that
this much faster living format would
drive engagement but soon after
launching it kind of lost interest in
instant articles and turned its
attention to video and now it's working
on augmented we
publishers who retooled for instant
articles are now reviewing for video are
going to find themselves in the lurch
when Facebook picks the next big thing
that it's interested in
so the real profits from online
advertising are concentrated between the
two companies who run the casino
Facebook and Google and anyone trying to
make a make a living from the ads
themselves finds they have a difficult
time the other factor that drives this
data hunger is as machine learning this
is a blanket term for a set of
mathematical tools that can mimic human
understanding in a wide set of domains
to work properly machine learning
requires enormous quantities of training
data and real data from real people
companies use machine learning to offer
desirable product features like
recommendations engines image
classifiers machine translation and they
also use the techniques to target their
advertising sometimes the machine
learning algorithms work so well that
you can package them up into a product
of their own consider Google home and
Amazon echo or the though those are the
always on home microphones that you can
talk to you or the nest thermostat that
sits on your wall and monitors who's
walking in and out of the room these
devices can only exist because the
machine learning algorithms are good
enough to make them work but they'd also
drive a feedback loop where once you
have them installed in homes you have
additional streams of data surveillance
that can feed back into the advertising
and into more products and it kind of
ratchets up everything moves into the
right in the direction of greater
surveillance we always assume that when
machines reach near human performance
and tasks like image recognition it
would be because of fundamental
breakthroughs in to the nature of how
things think you know that we could lift
the lid on the human mind and like a
Swiss watch we would see all the little
moving parts and understand the
structure somewhat but what happened
instead is weird we combine fairly
simple math with really big data and got
terrific results but we didn't uh
advance our understanding of why that's
true at all the mathematical techniques
used in machine learning don't have a
complex intelligible internal structure
that just giant matrices they're at
angle it's like opening up someone's
head all you see is you know is brain
goop all we see is matrices it doesn't
help us understand why these things work
the way they do but because machine
learning tracks human performance in
some domains like translation or object
recognition
well there's this temptation to
anthropomorphize it it acts human so we
start to think of it as human in
particular this is the point that that
I'm stealing from Zeynep to affect you
who gave an excellent TED talk on this
we assume that when the machine makes
mistakes it'll make human mistakes which
is not true at all
the algorithms are irreducibly alien
they're creatures of linear algebra we
can spot some of the ways they make
mistakes because we're attuned to them
but others are going to blow right by us
because they don't resemble human error
patterns whatsoever but for example if
you have an image classifier that
recognizes animals and objects it can
have human equivalent or better
performance-based trained on photos but
you can fool it by showing an image that
looks like pure static and convincing
the computer that what is a picture of a
school bus is actually a panda to the
human eye you don't see the difference
all you have to do is superimpose a
little bit of carefully tuned pixels
onto the bus photo and the classifier
will tell you with great confidence that
you're seeing a panda even though to us
it's it's absurd and this is what I mean
by alien failure modes that this kind of
mistake has no relationship to how human
vision works it's not the kind of
mistake we make when we you know when we
confuse things that are similar to one
another and because the image classifier
is normally so good it shocks us to see
it fail in this way
now these failure modes become important
when we start using machine learning to
affect human beings the learning
algorithms don't have any ethics or
boundaries that are completely amoral
and there's no slot in the algorithm
that says you know put the moral compass
here or add ethics or any way to tell
the algorithm that certain inferences
it's making are correct but morally
wrong so when we apply them to human
beings we leave ourselves open to some
really unpleasant surprises and the
issue isn't just intentional abuse that
people can train this stuff on data that
has bias easer that there might be
biases inadvertently left in the data
but fundamental to how the algorithms
work so these are the twin pillars of
our online economy we have this
apparatus for harvesting tremendous
qualities of quantities of personal data
from from users and then we have a set
of effective but completely opaque
learning algorithms that we train on the
data the algorithms learn how to show
people the things that they are most
likely to engage with that means
clickshare view react to post to their
feed
we make the algorithm is very good at
provoking these reactions from people
and this is our sixty billion dollar
industry so what happens when these
tools for maximizing clicks and
engagement creep into the political
sphere it's a delicate question if you
concede that they work just as well for
politics is for Commerce you're inviting
government oversight if you claim they
don't work well at all then you're
telling your advertisers that they've
been wasting their money using your your
ad engines so Facebook and Google have
tied themselves into pretzels over this
the idea that these mechanisms of
persuasion could be political useful and
especially that they might be more
useful to one side or the then the other
violates these cherished beliefs we have
that our industry is eight political and
whatever bright line we imagine
separating commerce from politics is not
something that the software running
these sites can see all the algorithms
know is what they measure which is the
same for advertising it is for politics
engagement time on site who shared what
who clicked what and who is more likely
to come back for more the persuasion
works and it works the same way in
politics as a dozen commerce by getting
a rise out of people but political sales
techniques that maximize engagement have
troubling implications in the political
realm one problem is that any system
that tries to maximize engagement will
try to push users towards the fringes
you can prove this to yourself by
opening YouTube and clicking opening it
in an incognito browser so there's no
history no cookies and clicking anything
with political content and then clicking
the recommended videos a few times I
tried this experiment last night I
started with a video about protests in
Berkeley and within five clicks I was
reading things about Trump planning
World War three in North Korea and
someone analyzing FEMA's plans for mass
genocide based on the ink color of the
stamp on a card they'd received from
from FEMA so when you try this on other
stuff it's not political if you try this
on baby animal videos what you get is a
series of baby animal videos but the
algorithms have learned that with
politics users who are interested in
this stuff respond more if they're
provoked more so the algorithms provoke
you nobody taught told them not to and
this this behaviors not programmed into
the system it just arises from correct
observations that these algorithms make
about human nature and act
social dynamics on sites where people
share links can compound this
radicalizing force the way you maximize
engagement on Twitter for example is to
say provocative things or to hoist an
opponent's tweets out of context and use
it as a rhetorical bludgeon against them
Twitter rewards captures people on
Facebook the social dynamics and the
algorithms taste for drama reinforce
each other and so Facebook selects from
stories that your friends have shared to
find links you're most likely to click
on this is a potent mix because what you
read and post on Facebook is not just an
expression of your interests but it's
part of a performative group identity
that you're showing to the people you
care about most
so without explicitly coding for any of
this behavior we already have a dynamic
where people are being pulled to the
fringes things get worse when you let
third parties use these algorithms to
target a specific audience an important
feature of the experience of politics on
social sites is that feeds are really
personal what you see is what you see
and you don't know what anybody else has
shown it has troubling implications for
democracy because it moves this kind of
political communication that used to
happen in the public sphere through
advertising through speeches through
stuff that everybody could monitor into
a very personal one-on-one interaction
political speech that tries to fly below
the radar has always existed but in the
past it was possible to catch it and
call it out for what it was but when no
two people see the same thing in their
feeds it becomes difficult to trace any
orchestrated attempts to target them in
political campaigns these techniques of
advertising under the radar were used to
great effect in both the brexit vote and
in the u.s. election what we have is
this inversion in political life that we
didn't see before conversations between
people that used to be private
that used to be ephemeral are suddenly
part of the permanent record and you can
point to them and and and they take
place in a very public venue and
conversely the kind of political
messaging they used to take place in
public view is now visible to an
audience of one so in this situation
whoever controls these algorithms that
are showing the feeds has great power
decisions like what is promoted to the
top of the newsfeed can swing elections
small changes in you I can drive big
changes in user behavior and there are
no democratic checks or controls on this
power and moreover the people who
exercise it the people running the big
tech side
are trying really hard to pretend that
that power doesn't exist political and
commercial advertising also are
independent financially in a way that
blurs boundaries even more politically
engage people spend more time online and
click more ads so if you go to a like
alarmist and conspiracy minded people
also make good targets if you go to kind
of listen to talk radio the fringe stuff
or you go to these sites that talk about
you know we're Preppers hangout talking
about imminent world destruction you see
the floor there full of ads for
supplements gold coins mutual funds we
are vitamins freeze-dried food that are
being pitched by the same people who
present the conspiracy theories many of
the sites peddling fake news during the
election we're operating just solely for
profit and field-tested articles on both
sides of the political spectrum to see
which would work better this time around
they found that the right wing was more
lucrative so we got fake news targeted
to Trump voters but it was a financial
decision and conversely many of the
propaganda sites find that online
advertising is a really good source of
revenue and depend on it to fund their
operations so why this all matters
surveillance capitalism offers these
exceptionally subtle levers of social
control apart from the obvious chilling
effect on political expression when
everything you say is recorded and
stored somewhere forever
there's the chilling effect of your own
peer group looking at what you're saying
and the lingering doubt that anything
you say might eventually even if it was
said in a private context be shown in a
public one we have no way of
safeguarding the large amounts of data
we collect in the long term so a real
worry for anyone is that their private
lives are going to be publicized
throughout the election private
communications by low-level staffers
word leaked and used as a potent
political weapon the message was very
clear stay out of politics or everything
is fair game nothing in your life will
be left private and social media also
proved useful at shifting people's
attention especially journalists
attention away when they're getting too
close to interesting stories by creating
diversions in drama or well imagine the
world where the state could shamelessly
rewrite the past but the Internet has
kind of done it one better where we've
discovered that people
are happy to do this work themselves
provided that they have their peer group
with them in a common enemy to unite
against they will happily construct
alternative realities for themselves and
adjust as necessary to fit the changing
facts
finally surveillance capitalism makes it
harder to organize effective long term
dissent in a setting where attention is
convertible into money
social media will always reward drama
dissent conflict iconoclasm and strife
are the things that get you attention
online there are no comparable rewards
for cooperation de-escalation for
consensus building for compromise
qualities that are essential for the
slow work of building a movement people
who should be looking past their
differences will instead spend their
time on purity tests and trying to
outflank each other until they can get
to the fringes so the big question we
all face is can we fix it obviously
institutions can be destroyed really
quickly they take a long time to build
and it's not clear that we'll have that
kind of time to build ones to replace
things like local journalism a lot of
what we've called disruption in the tech
industry has just been killing these
flawed but established and long-lived
institutions and mining them for parts
when we do this we make a dangerous
assumption about our ability to undo our
own bad decisions or the timespan
required to build institutions that
match the new reality right now there's
a small cast of programmers in charge of
the surveillance economy and we have
broad latitude to make changes to these
algorithms do a lot of put a lot of new
things in place if we choose to do so
but that situation is not going to last
very long the kinds of black box machine
learning that have been so successful in
the age of mass surveillance are going
to become commoditized and will no
longer require skilled artisans to
deploy and run them moreover powerful
people have noted and benefited from the
special power of social media in the
political arena they will not sit by and
let programmers dismantle useful tools
for influence and social control it
doesn't matter that the tech industry
considers itself a political and
rationalist and sort of divorced from
from this context powerful people did
not get powerful and do not stay
powerful by ceding tools
that that help them gain power the
window of time in which the tech
industry can still act is brief while
tech workers retain relatively high
influence in their companies and before
powerful political interests have put
down roots in their tech industry in the
tech industry that is the only time
available to us to fix anything I've
divided the changes that I think we need
into two groups based on how they affect
existing business models the short term
solution or change solutions are changes
that mitigate some of the harm that the
surveillance economy has caused without
requiring total reforms the long term
changes are also necessary but they're
more difficult because they will upend
business models we can compare this to
defusing a bomb the immediate task is to
disconnect the wires and turn off the
blinking timer but the longer-term task
is to get rid of the pile of explosives
and render it safe removing the timer is
urgent and necessary but we if we leave
the explosives in a pile where they are
we're just gonna have this problem recur
so the key changes we need to make in
the short term I believe without
requiring sites to relinquish their
business model are to teach social
software to be more forgetful to give it
predictable security properties and to
sever the financial connections between
online advertising and extremism let me
talk about the forgetfulness part memory
it works in a really odd way in online
spaces on a site like Facebook
everything is permanent right once
provided the data can never truly be
deleted unless you take the draconian
step of deleting your account
you can't even remove your phone number
from Facebook it'll just show your phone
number with a nice line through it you
know we know what it is you try to
delete it we still got it if you want an
interesting surprise in your Android
user or if you enabled Google Maps on
your iPhone and given it the permissions
go to your Google location history
you'll see where you've been for the
four years years and years and all of
that is not only available to you but
it's available to anyone who gets access
to your phone and your Google account so
it's always there for the taking as soon
as you want it this kind of like perfect
memory is nothing like real life it
feels weird most of what we do and say
is forgotten within a short time and in
the rare cases where you want a
permanent verbatim transcript you have
to set up a special you know
circumstances to make it happen it
doesn't happen by default and things
that we do in one context in in daily
life are not likely to come back to
haunt us years later in a completely
different venue but the online world
forces individuals to make these daily
irrevocable decisions about what is
going to be their online footprint
consider the example of the women's
March did anybody go to that a couple of
months ago
alright the women's March was organized
on Facebook and the list of people who
RSVP'd to the women's March about 4
million people came out and marched that
lives somewhere on Facebook servers and
it's not clear who controls it why it's
being kept who has access to it we
assume that Facebook has good intentions
and and and safeguards that material but
it's going to live there until Facebook
goes bankrupt or until it gets hacked or
until it's bought by hedge fund or until
some rogue sysadmin decides that that
information needs to be free anybody
here a Friendster user back in the day
some people I was a friend store users
it has anybody visited Friendster and
know what it actually is today this I
think it's a gaming site in South Korea
now it I think it's being passed around
by app yeah but the Friendster data is
somewhere it's in someone's basement
under a layer of dust and Facebook is a
great company but the lifespan of these
companies is not very long even the most
successful ones time passes so it's a
very interesting question where this
stuff is going to end up any group that
uses Facebook to organize comes up
against this problem and a lot of groups
are using Facebook to organize but
keeping the data around forever is not
even central to Facebook's business
model the algorithms that it uses a
favored recency they want to know the
stuff you've been up to lately not ever
and their output is not going to
drastically change if Facebook just
forgets what you were doing three months
ago or three years ago so we need the
parts of these sites that are used
heavily for organizing like Google
Groups or Facebook event pages and
Facebook groups to become more ephemeral
there needs to be this user configurable
time horizon after which membership
lists disappear and messages disappear
people call these disappear
hearing messages but that makes it sound
furtive which it's not it's just an
attempt to map the behavior more onto
what we expect from from everyday life
and the obstacle to giving groups and
events this kind of fixed lifespan or
organizational they're not technical all
it has to do all it requires is someone
in management to care about this and and
to request that it be built in some
cases we don't even want the data to
disappear we just don't want it to be as
accessible as it is consider the case of
mobile phones people routinely have
their phones stolen they lose them and
especially when you travel you're at
high risk of being separated from your
phone if the phone is unlocked whoever
gets it and gets their hands on it has
complete access to your account and not
just complete access to your account but
they can look at at interactions that
you don't even remember people you don't
know that you knew because your entire
online archive on both Facebook and
Gmail is available through your mobile
device this has been a problem in the
news lately because borders are now
checked you know a customs agent at the
border are now asking for people to log
into their accounts but there's really
no earthly reason you don't travel with
a suitcase full of every important
document that you've ever had but we're
made to do this with our mobile devices
so when I talk about ephemerality it's
not just forgetting things entirely it's
also making kind of the default view not
be the forever everything in the archive
view but something more limited in time
with a shorter horizon to better reflect
again the way that human beings actually
expect things to behave in the real
world and then let me talk about
security security is important because
it gives you predictability if you know
that your messages are end-to-end
encrypted and they're done and the
encryption works and you can say things
that you would not say in an email given
tools that have reliable security
properties people can better partition
their activity between private public
and semi private spaces and use them
with confidence that they'll stay that
way without proper security they have to
assume that even though most private
conversation will eventually be posted
in public and a lot of the chilling
effect an online discourse comes from
the fear that these privacy boundaries
are going to get violated that the rug
will be pulled out from under you and
statements you made in one context will
be held up for public ridicule in quite
another the good news is that we have
the technology to do all this
the bad news is that the implementations
are haphazard and often implemented in
this user hostile way I want to be
specific about the security needs we
have one is universal support for you to
eff security keys does anybody have one
on them or use one anybody wave can wave
one around triumphantly alright imagine
in your mind a little thumb drive and
you to f key looks just like that it is
a very effective defense against
phishing without with the u2 F key even
if you give me your password I can't log
into your email account because the key
can't be fooled and it talks directly to
the browser and the server so this is a
super effective technology that fights
one of the biggest threats facing people
fishing but it hasn't been deployed in a
user-friendly way many of you have never
heard of it that should not be the case
crypto got cryptographically secure
end-to-end encryption on all forms of
messaging so I messaged Twitter direct
messages especially Google Groups Gmail
all of this stuff should be encrypted
like signal and whatsapp already are and
to end in a way that the server can't
access an Android phone that is as
secure as an iPhone Android phones are
horrible right now Google prides itself
on its ability to make devices that are
better than apples but they have not
cared about security so you are
materially less secure with an Android
phone there's no earthly reason that
proud Google can't ship an iPhone
equivalent in terms of security but they
don't secure an usable group messaging
right now you can pick one or the other
but you can't have both one-click
settings that enable the highest levels
of security for users who need them so
if you're an activist or a journalist
you turn one button on and suddenly your
device is as secure as it can be
configured you don't need an expert to
help you better defaults and options for
opening attachments in email this is a
way that many people get hacked and we
don't have good solutions for it and now
that our browsing history can be sold
and resold a trustworthy and privacy
privacy preserving virtual private
network may be to you know dare to dream
finally some sort of viable alternative
for mailing lists and that kind of
communication that doesn't live inside
of Facebook past experience has shown
that security is achievable all these
dreams can happen all it takes is for
people to actually care who have the
power to push it through and the final
short-term stuff
is defunding defunding extremism we need
to disconnect the most blatant forms of
online extremism from their money supply
and here the google monopoly on online
advertising actually works to our
advantage
in recent days many companies have
pulled their ads from google for fear of
having them appear on far right-wing
sites they call this brand protection
and it's a useful step it's also an area
where we can turn the tools of
surveillance against the people who are
making money on extremist sites from ads
by just making sure that if as i saw
recently a Perrier ad comes up on a far
right-wing conspiracy site the nice
people at perry a marketing know and are
told that their product is being shown
in this context it's a very effective
way of cutting off the money supply from
some of the worst offenders on the web
but what we need are long-term solutions
the security the ephemerality and
defunding can help us stabilize what's
going on but to have a recognizable
human online world we need to make
structural changes as well above all
people need to have control of their
data they need a way to carve out
private and semi-private spaces for
discourse and some sort of functional
public arena that politics can happen
and that everybody can see they also
need robust protection from manipulation
by algorithms whether they're
well-intentioned or not it's not enough
to have Stanford grads who are deciding
how to reinvent society from their
offices startup office there needs to be
accountability and oversight as well
because we are after all a democratic
society some of these changes can only
come through a regulation and because
companies always find creative ways to
collect data even if you try to regulate
or ban it what I always propose is that
we make the locus of regulation the data
store no matter how you collect the data
you have to throw it into one big pot
for all your machine learning to work so
we regulate the pot in the past I've
proposed six fixes to the internet and
hey I'll propose them again they were
good the first one is simply the right
to examine download and delete anything
that's stored about you pretty
reasonable request
that is pretty essentially impossible
even for sites that offer Lee you know
Google you can get a download of all
your activity but you can't really get a
download of all the behavioral data
they've stored about you that they have
there's a lot more there than than what
you see
second a time horizon which is weeks
long and not years long for how long
companies can retain behavioral data
when I say behavioral data I mean
anything that you didn't give them so if
you store a photo on Google you know
they're allowed to keep that as long as
you you want it there but if they notice
that you're browsing from here in
Philadelphia in a conference that piece
of information is not something you
willingly shared it's an observation
about you there should be a time limit
on how long it can be kept I'm not a
monster I'm not saying don't keep it at
all but limited limited two months and
not years three a prohibition on selling
or transferring collections of
behavioral data whether outright or in
an acquisition or in bankruptcy if a
company sells to somebody else that data
should die if the company goes bankrupt
nobody should be able to buy it at
auction that data goes away if you
really want the data in the acquirer
then you download it and you re upload
it a week later when everything is set
up a ban this is my favorite a ban on
third party advertising ad networks can
still exist but they can only serve ads
that are targeted against the page
content all of this stuff about what we
know about you who you are where else
you've been retargeting all of this
stuff goes away and the huge ad fraud
market goes away as well people can
still use third-party networks but those
networks can't remember anything between
requests number five is an off switch
for Internet connected devices that
physically cuts their access to the
network and the switch shouldn't prevent
the device from doing anything else that
it's supposed to be doing so you know
you want to be able to stop the malware
on your refrigerator that is posting
anti-semitic rants to Twitter but still
have your beer stay cold six a legal
framework that offers certain privacy
guarantees a while ago snapchat got
caught they were telling people that
photos disappeared within a few seconds
but it was discovered that they kept
them for 30 days what happened was
snapchat was then find a small amount of
money I think a hundred thousand dollars
and told please don't do it again what I
want is a legal framework that lets me
as a site owner make binding promises
that I will go to jail or be bankrupt if
I violate them willfully so that if I
tell you for example that I'm going to
collect every image you have right now
from your phone and do cool facial
recognition on it but I'm not going to
keep it more than an hour you can
believe me and you can
lilian if i'm lying to you that unlocks
a lot of interesting features that are
impossible now just because of privacy
concerns right now our choices are we
don't give data or we give data forever
I want there to be a legal framework
that lets people credibly make kind of
intermediate solutions so these reforms
would restore a sense of agency and
ownership to people about their data
they would also force companies to make
the case to users about why they're
collecting the data they do people might
be willing to do it but right now we're
just told to use the service or not we
don't care this is a way to make sure
that people have to at least make the
argument for why they're collecting all
this stuff they do and then if if
cutting the sixty billion dollar online
advertising industry is not radical
enough for you I also propose that we
need to break up Facebook because of the
potent way that it combines social life
with publishing Facebook poses a unique
challenge at a minimum we need to break
it up so that the social features are
divorced from the newsfeed we have this
kind of separation in other places in
banks for example we recognize there has
to be what's called in the jargon a
Chinese wall between the stock brokers
and the investment bankers so that
there's no there's just too much of a
temptation otherwise to double deal with
with your clients you see a similar
thing with newspapers there's a wall
between the editorial department and the
news department or at least they're
supposed to be we need a similar wall in
social media I would be delighted if we
could have decentralized social networks
if we didn't need anything like Facebook
just like we have in real life people
interact with people and then things
organically happen but if you have to
have a central database of people's
relationships then it can't be the major
publishing outlet Facebook can remain a
platform for connecting to friends for
your long term photos and videos for
announcing life events but it can't
simultaneously be the platform for
political organizing political campaigns
and news delivery we need a code of
ethics for our industry to guide the use
of machine learning and it's acceptable
use on human beings other professions
all have a code of ethics so librarians
have a great one they hold really
tightly to patron privacy everybody who
goes through library school is
inculcated with this commitment to
patron privacy even lawyers who we make
fun of in jokes have a high code of
ethics
journalists are taught to speak truth to
power doctors have first do no harm
we have moved fast and break that
is the closest that we have to a code of
ethics in our industry and look where
it's gotten us right young people who
come into the industry have to have a
shared culture of what is and is not
acceptable in the use of computational
tools and above all they need to learn
that power always has to come with
accountability that you can't have one
without the other and finally we have to
pay our share we need to plough the huge
profits of the tech industry back into
the communities that these industries
grew out of so be blunt tech companies
have to pay their taxes yesterday we
found out that Apple is now up to two
hundred forty billion dollars that it's
kept sitting overseas because he can't
repatriate it without paying tax
California has the highest poverty rate
in the United States when you adjust for
cost of living part of the reason you
have to adjust for cost of living is
because the tech industry has raised
housing prices so much by being there
and every Apple device you buy will say
proudly on it designed in California but
Apple uses a tax tax dodge to pretend
that it's in Nevada and avoid paying
California taxes this is not unusual
behavior at the very least it should be
a source of shame for the company and at
best it should be illegal and paying our
share also means offering a living wage
to tech workers whoever they are not
just the privileged cast of programmers
and designers but the many contract
workers who work in the tech industry
the warehouse Pickers who work in
delivery services in places like Amazon
the people who drive nerd buses the
cooks the janitors the cleaners security
guards everyone who keeps the tech
industry running has the right to a
living wage we are a rich industry and
when you give people a living wage that
money also goes back into your
communities you know whoever you are
your children go to school together
presumably so you want your community to
to thrive so it's a tall order right
break up Facebook destroy the ad
industry socialism all these things I've
asked for here's my blueprint in the few
minutes I have left on how to get there
to make these substantive structural
changes we need leverage right and there
are very few levers of power over the
big tech companies
because they're essentially monopolies
consumer boycotts don't work opting out
of a site like Google is like opting out
of online life you know you just cut
yourself off some people can do it on
principle but asking people to do it in
mass numbers is not a workable strategy
and trying to apply indirect pressure
through the actual customers so the
publishers and the advertisers can work
for some limited goals like the
defunding that we talked about the
current panic around brand safety that's
helping to take money away from sites
like Breitbart but if the goal is more
fundamental reform then we're stuck
because you know you can't apply
pressure through the thing that you're
trying to abolish shareholder pressure
these companies doesn't work because the
large tech companies are structured in a
way that gives the founders absolute
control no matter how many shares they
have or don't have so Zuckerberg as long
as these a Facebook is always going to
be able to make the decisions that is
how the company is structured and that
is how investors have agreed to buy
shares in it and regulation is tricky
not just because we have a dysfunctional
political system already but because the
large tech companies have a capable
lobbyists and massive legal teams that
can fight it press campaigns obviously
can't work when these are the main
outlets for for online publishing and
when the the journalism has already been
either destroyed or than its last legs
and dependent heavily on these new
advertising business models so the one
effective lever that we have against
tech companies is employee pressure
software engineers are difficult to hire
they're expensive to train and they take
a long time to replace even really
capable people when you hire them as
someone like goo at a place like Google
take months and months to learn all of
the internal culture all of the cool
internal tools and become fully
productive and even though these the
companies themselves are large even
small teams like the people who work in
security or on the ops teams have the
power to completely shut down a tech
company if they act in concert and are
sufficiently motivated we saw some small
demonstrations of the power of employee
pressure in the last few months the
never again dot tech pledged back in
November pushed companies that have been
silent for months to finally make a
public commitment that they would not be
involved in building a muslim registry
uber employees of all people pushed
their CEO out of trumps Advisory Council
and hopeful
Tesla employees will do the same with
Elon Musk and there was an employee
walkout at Google which was quite
striking during the the first Muslim ban
in and and Refugee ban where they
prompted the founders and CEOs to come
and talk to employees and issue these
public statements in defense of
immigration
these were small victories but they were
real victories and we achieved them by
individual employees who organized kind
of in an ad hoc way but we have yet to
see in the industry is true collective
action that uses the powerful tools of
labor law to push for some of these
goals that have outlined this is the one
and only lever that can make change
happen as I said even an ops team if it
threatens not just a walkout but work to
rule follow the instructions by the book
would have enormous leverage over
management if we chose to exercise it
unfortunately the enemy is and has been
complacency more than anything tech
workers still trust their companies they
trust the process they trust their CEOs
to do the right thing they don't want to
make people angry and so our one chance
to enact meaningful change is slipping
away unless something happens to
mobilize a tech work force or unless the
advertising bubble finally bursts we can
expect this weird topsy-turvy status quo
in 2017 to be the new normal in now and
for elections to come and the important
thing is to keep trying I don't think
we're gonna succeed but we have to try
to succeed good intentions as well
intentioned as we are are not going to
make structural problems in the industry
go away and talking honestly about them
is a necessary first step but in the end
we're either gonna act or we're not that
said talking about them takes a long
time I'm really grateful to you for
being so attentive I didn't have a
single slide I read from a prepared text
but you were champs about it it is now
4:45 there are drinks outside I think
what I would like to say is people who
have questions I'd be glad to answer
them anybody who just wants to run out
there and drink please I won't be
offended if you get up and go so let's
do that and we have someone with a
microphone so if anybody has questions
raise your hand and this person will
will run over to you
thank you that's right are you familiar
with the GDP are the European Union data
privacy rules at all do you think that
addresses any of the the six rules that
you spoke of earlier the question is
about the European Union's rules on
privacy my the beef I have with the
European Union's privacy rules is that
they're kind they're targeted to
individual privacy
I like the idea very much of giving
people more leverage over what you know
what is out there about their lives
giving them that sense of agency but the
problem the European Union doesn't
address because these laws are older
than the phenomenon is the mass data
collection and cross-referencing of both
data sets and things that are somewhat
anonymized but still are very revealing
about you just because you know you can
you can analyze them to death so I think
the the the EU is unfortunately fixated
on individual privacy and I think misses
this of this big change which has been
the the mass data collection and the the
ways that it's effectively being mined
and used that's my table anybody else
it's kind of a hard question but I'll
see if you have any thoughts on it
earlier you were talking about there
should be like the one-click make
everything secure answer for journalists
for example there's there's a tension on
one hand if I understand everything
about the technology and I am the king
of the world then of course I can do all
the really hard things and make myself
secure on the other hand if I am an
amateur and let's face it most of the
world is I'm trusting someone how do any
thoughts on how we create the
transparency that that's not a one click
hey I'm a sucker button because how can
they tell it apart that's a really good
question if you have a one click make me
super secure button how do you trust the
people who are implementing it and how
do you evaluate it if you're not
necessarily the most technical person in
the world in my mind the trade-off here
is there is a small group of for most of
us the worst thing that can happen is
we're locked out of our accounts and
can't get back in that is a disaster
there's a small subset of people for
whom being locked out of your account
never being able to get back in is a
good outcome and the worst thing that
can happen is a government gets in there
so let's say you're you're a journalist
in Egypt you're detained and the people
looking at your device are able to
recover your password and get to all
your contacts you've sentenced your
friends and sources to prison that is
the kind of situation that very few
people are in but the people who are in
it really really need to be able to have
confidence that these devices are
correctly secured and configured and we
just lack that now that's that's what
I'm really referring to the trust
problem exists already you know we have
to trust something if we don't keep our
lives
I know people who keep their lives
completely offline who compile their own
Linux stuff that they've examined the
source code for it is an exhausting
thing we all trust companies to some
extent there's a reason there was a
basis for this and this extends to
people who are in in in a lot more risk
than we are all I want is while punting
on the trust problem is to make the the
technical the configuration problem go
away for them so the people who have
vouched for it said that you know just
hit this button it'll give you six big
red
but if you click through all of them you
are in a position where you can't harm
the people you care about and you're in
use it with care so that's that's kind
of how I see it
anybody else microphone and friend yes
so one of the things that you know I was
listening to you that just keeps coming
to mind is the term Pandora's Box you
know basically we've created it it's out
there it's being used and it won't be
forgotten you know no matter how much we
want to try and pull that back no matter
how many laws that we write I'm not
disagreeing that we've went too far I'm
not disagreeing with many you're but
with many of your statements but you
have foreign count you have foreign
companies that aren't bound by our laws
you have foreign companies you have
foreign governments that will probably
use this look at China they have their
own social media to do a lot of this how
do you how do you see I mean my I guess
I don't really have a question is just
just it's just the frustration that we
put it out there well we put nuclear
weapons out there and then decided oops
and it kind of worked I mean I haven't
checked the news today but but so far I
worked for a long time where we nobody's
used them which is kind of amazing so to
me if we could like do a take back on
nuclear weapons sort of successfully
with a lot of nobody would have believed
that it was possible certainly not in
the years right afterwards so that gives
me a little bit of hope you see I'm not
a very optimistic person my go-to source
of optimism is nuclear nuclear war but
it doesn't give me hope that it's at
least worth trying right and all of your
arguments I completely agree with that
this stuff is going to be out there but
it's one thing to have it be out there
it's another thing to have it be the
default and in kind of the way we live
without even having made that decision
just because we stumbled into it
any other questions people are great
nobody wants to drink all right what do
you think about this new idea that
Google has a federated machine learning
like where you train the algorithm and
then you push it to your device do you
think that's a good idea and do you
think that shows some cognizance on
Google's perspective that like
this isn't working and maybe we should
try to pivot to something else before we
lose a ton of money I'm of two minds
about it on the one hand I I like
anything that moves towards the
direction of not storing all the raw
data to train machine learning on I
think we can go a lot further in
pre-processing and cooking it defanging
it so it can so you can still get the
machine learning goodness you want
without having it all just sitting there
in raw form but I also I'm concerned
about these other aspects the stuff that
I stole from Zeynep about the real
alienness of machine algorithms and how
we have to be careful about applying
them and especially in social situations
just because we can't anticipate the
ways they'll fail and I think that
anything that pushes machine learning
further out into everyday interactions
and makes it more usable by more people
it is something that we haven't thought
enough about so I like the idea of the
Federation I like the idea of not
bringing the data to Google but I'm not
sure I want to pay the price of having
machine learning every 19 year old with
a twinkle in their eye on a startup idea
having having these tools and just
blindly trying them out anybody else so
I really appreciated your kind of
diagnosis of the problems that we face
and there are clearly a lot of problems
and I agree with a lot of the
suggestions that you make for reform and
fixing some of them what I thought was
maybe missing from the talk was an
acknowledgement that for all the
downsides that these things have brought
there are there have also been upsides
and good things that we've gained from
this so one example you know I don't
think it's a coincidence that police
brutality in minority communities spiked
when we had social networks and
everybody had a camera in their pocket
right so the the kind of old system of
journalism as good as it was for certain
things and preventing extremism also had
these huge blind spots that are now
being covered in a way that they never
would have been previously so that's
just one example I guess my question is
on balance do you think that we're worse
off today for the the monster that we
built so to speak or do you think that
we've gained
and enough to you know on that that
makes it worth it or you know does that
make sense it doesn't make sense and I
think your example is an excellent one
another thing that cameras have done for
us I can name two off the top of my head
one is we saw a really cool meteor in in
Siberia
thanks to dash cams that would have been
a local legend suddenly I can just go to
youtube and see there's a lot of stuff
that we now and can can witness and we
also know that UFOs just don't exist so
that was really helpful I don't mean to
trivialize your example I think it's
really it's a really good one the
problem is there's five hundred speakers
that will tell you how great technology
is so I'm trying to fill a different
niche it doesn't mean that I hate it one
thing I'm honestly concerned about is in
this very complex interconnected society
the ways things can fail can be really
really bad
I don't mean to be flippant about it but
in the 20th century we saw the greatest
genocides you know in human history and
there's nothing that convinces me that
something like that couldn't happen in
the 21st century I was a lot more
confident than I am now just because I
didn't think that a lot of the politics
that have happened could happen so it's
the small but horrible risks that that
are worried about and I think they're
hard to compare they only they happen
rarely and we were human beings we can't
predict the future but the ingredients
that are being mixed together really
concerned me so I also have a
pessimistic apocalyptic disposition so
I'm trying to make a career for myself
and this is really the best way I've
found to do it I you think I don't have
a full go bag you know waiting in the
corner yeah anybody else we're almost
with four minutes before my time limit
about like I thought what it was but it
was something with Watson and how you
incorporate into something and then like
if any was like massive amount of data
would be set over to lots and to figure
out like what you want right the last
thing I saw for Watson advertised was
Watson will help with your tax returns I
think that's it yes
like you'll be sending all this stuff to
watch it to figure out if it'll save you
money $5 oh no my favorite thing about
the Watson ads is that most people's tax
returns are like four pieces of
information you know your how many
deductions your social security number
and your gross income that's what you'd
so you don't need the full of
statistical power of modern AI to really
crack that nut but you see that it's
becoming a coat of paint that people
apply to stuff because it sells it's a
marketing term now so picture of you
that's an excellent question like what
what does it mean that the data is about
you if it someone uploads a photo of me
is it theirs or mine and it has into a
bigger problem that even if you want to
opt out of everything and you don't use
computers at all you're still like
there's a facebook has a profile about
you with your real name because it's
observed who you are from all your
friends who are on the service and this
is this happens it's not just I don't
want to single them out for everything
so you can't even opt-out of these sort
of privacy violating things because
everybody snitches you add to these
services unintentionally I do think that
the behavioral data is a place where you
control because I no matter what like if
you observe stuff about what I do you're
not learning much about what other
people do who are with me and that data
that's why I want to focus on it and
make it impossible to transfer it or
sell it and also make it time to limit
it so the problem you outline is more
subtle and more difficult and and I
don't have an answer for it all right
one more question and then go drink all
right cool thank you all so much again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>