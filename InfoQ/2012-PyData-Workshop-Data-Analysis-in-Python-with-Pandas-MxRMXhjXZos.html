<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>2012 PyData Workshop: Data Analysis in Python with Pandas | Coder Coacher - Coaching Coders</title><meta content="2012 PyData Workshop: Data Analysis in Python with Pandas - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>2012 PyData Workshop: Data Analysis in Python with Pandas</b></h2><h5 class="post__date">2012-03-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/MxRMXhjXZos" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so my name is Wes McKinney I'm going to
be talking about a library that I've
been working on in Python for about
about four years called pandas which is
sort of a mash-up of lots of things
panel data Python data analysis or take
your pick
if you like thinking about it is you
know being inspired by the by the animal
then certainly be my guest you're happy
to be here so so the story with pandas
so I guess most of you who use numpy my
correct has anyone not used numpy oh
that's that's fantastic news so anyway
so pandas is so I the story as I started
I started out working in Python at the
beginning of 2008 and I was working
inside of a quant hedge fund and I was
using our and I long story short as I
became very frustrated with the data
manipulation capabilities that that are
provided particularly with regard to to
time series data which is really just a
special case of an available labelled
array data structure and so I started
looking at well K is there anything in
Python well first is there anything in
our that has the the features that I
needed to really have a rich tool for
working with working with collections of
time series data I basically decided
that no and plus Nina the our language
is sort of horrible to program in to
build I was already not not satisfied
with building a real production systems
in it and wanted to do things in Python
but there was sort of a missing layer
there between between numpy and the
tools needed to implement the
domain-specific logic so I started
building this library and basically now
at now four years later it's this very
rich data manipulation tool which is
built on top of numpy so it sits on top
of numpy and provides a lot of features
like Travis was saying that are not
built into not built into numpy which
eventually some of them will be and
that's that's part of some of the work
that's going to be happening over the
next couple of years so there are data
structures the library is primarily data
structures but they're also a lot of
auxiliary tools for working with those
data structures getting data in and out
of
the pandas dataframe object writing
things to disk different different kinds
of persistence tools for working with
databases just all of the things that
you need to solve real-world problems
and I've been working I've worked you
know many different problem domains in
addition to finance and so I've been
building this tool to kind of be the
ultimate data tool for Python a lot of
people who've used are and now use
started using pandas and now can do all
their work in Python which i think is
really great so I get a lot of people
which say you know you saved me it's
like I was having to switch between
Panos doing my data data munging and
pythons and then feeding it into R and
then doing the work in R and now they
can do all that work in Python so a lot
of very happy people out there certainly
has made a big difference in in my work
so I so the development had kind of
stagnated a little bit but I picked it
up and have been working on it basically
full-time since about last May and so
you know it turns out that you can get a
lot of work done when you focus on one
thing and do nothing else for about
eight months so and so there's been a
huge amount of growth and that's going
to continue continue upward trajectory
throughout this year so actually looked
and the code bases it was already a
pretty big code base but it's tripled in
size in nine months which is pretty you
know it amazes even me um and so I've
started i've started a company it's
called called lambda foundry so if
you're a knight of the lambda calculus
and perhaps you you like the name but we
are building a so we are supporting
pandas development and also starting to
build a product a product ecosystem for
quant finance so I find that you know
quants out there a lot of them are
programming are in MATLAB they're
they're underserved by the tools that
they have and there's not a lot of
infrastructural support for for that
problem domain a lot of homebrew systems
a lot of in-house development and the
result is that you know those kinds of
users just aren't as productive as they
could be you've got these incredibly
smart people many of them with
backgrounds in you know got got PhDs and
you know physics or or economics or
finance you know they're doing modeling
they're doing research but they struggle
with the tools and you spend 50 to 80%
of your
I'm just doing really basic basic
development I find that really backwards
some other projects that I've involved
in I'm also involved in stats models
project which is statistics in Python if
you're interested in doing more
statistics in Python we need more
developers on stats models it's not the
it's not the sexiest development out
there you know scikit-learn which is a
machine learning library for python has
a huge development teams are extremely
active of course you know machine
learning is like it's it's kind of a
kind of a sexy topic and and but also
computer scientists understand the value
of a building reusable software which is
kind of a sense that's not as prevalent
in economics and econometrics which is
what stats models is more about I'm also
writing a book I just literally got the
cover today and they're going to change
it from my legal name to being just Wes
at the bottom but so I'm writing this
book with with O'Reilly compiling for
data analysis and the idea of the book
is basically to present a sort of a nice
introduction to all to all these tools
that were we're talking about today and
but tailored for a user who is working
with data working with structured data
maybe has some our experience and wants
to you know I got an email from somebody
who said you know I'm drowning in Python
I've got some are experienced I've got
some SAS experience like I just you know
where do I start where do i how do I
learn about these tools and you know
become become productive and so that's
you know I perceive that really there's
a need for that and so I you know on top
of all the other things I'm trying to do
I'm trying to you know I am I am writing
a book and it will be out later this
year so it's going to be about the
fundamental tools in the in the tool
chain ipython which I'll see more about
numpy matplotlib scifi few other few of
the libraries that are in common use but
a lot of the book is going to be about
pandas and focusing on very practical
and and very practical tools for for
real-world problems and looking at
actual data and going through case
studies and showing how to how to
synthesize all these tools to to solve
your problems so so for the next
hour and 15 minutes or so I'm going to
give you an overview of an overview of
pandas explain the data model a little
bit like how it how it relates to numpy
and then basically jump into the ipython
notebook and any of you who can get it
running on your laptop I hope that's
many of you
I'll post I will upload the the
notebooks I'll create a little archive
and put in a Dropbox for you to download
and we can fire that up and start
actually you know you can follow along
with the examples I think it's going to
be mostly just me me showing you things
I have a lot a lot to cover so so cover
some of the the basic you know getting
data in and out you know from flat files
from JSON objects so if you work a lot
with web data how to basically if you've
got a bunch of JSON objects you want to
load that into tables that you can then
you know crunch that data and analyze
and create summary statistics how you
can do that how you can dual example
showing you how you can get take data
out of a database and put it into a data
frame explain how label based indexing
works which is something that's not
really present in numpy showing you how
that can integrate into into data
alignment which is a big part of a big
part of pandas talk about descriptive
statistics and missing data and how
that's implemented how you can apply
functions to your data in an intuitive
way talk about sort of database like
joint operations and concatenated at a--
to gether talk about group I so if
you're familiar with sequel you've ever
written a sequel expression with
something with group by where you're
aggregating or transforming datasets how
that looks in pandas it's a big missing
feature from-from numpy and I'm excited
to see you know I think could take the
take the group that sort of the group by
engine that I build inside pandas and
use it for for an umpire race but as
you'll see that doing group I without
without label without labeling
especially without hierarchical indexing
which I'll explain more about the
interpreting the result of a group by
expression is hard without that richer
data structure I'll talk about how how
the indexing and and group by relates to
reshape operations and for
running pivottables so if how many of
you have ever created a pivot table in
Excel or another spreadsheet OpenOffice
okay
so I'll explain a little bit what what
that's about and what that looks like
time series I'm not going to talk about
if you're interested in time series I've
got a Vance topics later today and that
will be all about all about time series
so I'm going to admit that from from the
discussion here it's going to be using
that the ipython HTML HTML notebook
during the latter latter portion here so
so the pandas data model so there are
two there are two major objects the
first is is the series which is just a
one-dimensional labeled array so it's a
numpy array plus an array of labels and
I'll explain what the labels can be
really that the short story is that they
can be anything but they can't be they
just can't be mutable because they're
used for for lookup so it has to be
anything that you can put in a Python
dict the second major object is the data
frame so if any of you have used R
before I took the name lifted the name
directly from our it's it a data frame
is is an indexed collection of series
objects so you have a table of a table
of columns you have row and column
labels the columns can be different
types so it's it's it's if you've used
structured arrays and dump I it's very
similar to a structured array except it
has a number of additional features so
you can add and delete columns very
easily which is not not possible in a
structured array without creating new
arrays so the series object now the
reason it's called series I guess for
lack of a better name you could call the
labeled array or I guess you have series
and time series a time series is a
series that has dates as the index so
you have you have an array of values and
you have an Associated array of labels
so here it's just the strings a through
e the data in the in the array could be
any any data that you can store in a
numpy array so it's very not so if you
use nonprofits very naturally with you
know mental model of data index labels
they don't need to be order
you can have duplicates but there are
many operations which will refuse to
work if you have duplicates so if you
try to look up the value at C and it
turns out that the the index has
duplicates then it will throw an
exception because it's not a one-to-one
mapping so a little bit more on that
later but most most of the time when
people use index data in pandas it's
always a unique unique labeling and
that's how it's designed to work so the
data frame is going you know adding a
dimension so so now you have you have
column labels and row labels and so here
I have columns who are Basque books and
here I've got a got four columns they
can be they can be floating-point they
can be strings it can be boolean but the
the important thing about data frame is
it's it's sort of it's the primary
container for working with data in
pandas so you can you can very easy if
you are carrying out an analysis and you
compute additional columns you can add
them into it like a dictionary so it
works it's intended to work just like a
Python dict where the keys are where the
keys are the column labels and the
values are are the columns as as one
dimensional arrays and so it can it
works well with if you have only
homogeneous data so if you just have a
collection of floating-point data it is
very fast with that supports very fast
both row oriented and calm oriented
operations but you can also have
something that's completely
heterogeneous reach columnist is
different as a different type so that so
the story with the axis indexes so here
you know data frame we've got you've got
it we've got our row index which is
called called the index and and the
column and the column index which is the
columns so if you show you in the in the
notebook so basically these are these
contain are used to to do the lookups so
if you want to select out a row or
select out a column it all goes through
it goes through the index but they're
they're the core data structure which is
used to do data alignment and to
implement joint operations so one nice
thing about them is because
the because this index is is its own
little data structure we can do
something more sophisticated we can have
hierarchical indexing which means that
so the semantics are you can imagine
having an array of labels but each of
the elements is tuples but suppose that
you wanted to select out a group based
on the first tuple so the naive way to
implement that would be to make a linear
scan through to make a linear scan
through the tuples and then match on the
first element of each tuple and then
select out those rows based on based on
the first element but if you had a very
large data set suppose you had you know
a million rows or five million rows that
would be you'd have to make a full sweep
through the index nor through you know
through the labels in order to just
select out that data so you can imagine
that the having a big performance
bottleneck there so that so having a
proper data structure that that that
represents you know the multiple levels
of indexing allows you to do very fast
you know login lookup of a group and
slight and select out a view on the data
without copying any data so so that so
it's designed in order to enable you to
work with very large data sets to reduce
copying you know sir blunt you know
there are lots of situations where you
could be working with gigabytes of data
in memory and you want to be able to
work with groups of the data without
running into memory problems and so this
is one mechanism that really helps a lot
with that and I'll explain how this
relates to to group by operations and
reshape operations so data alignment so
the reason that so the reason the
indexes are there in the first place is
that you work with so you work with a
lot of data where you've got you've got
labels for it so in a relational in a
database table you might have these
might be your primary key which might be
you know you might have a couple columns
which uniquely identify each each
observation and that information is
intended to be expressed in the index
but you might have multiple collections
of data that are indexed differently and
it's a lot of you know creates a lot of
problems if you've got two different
data sets they're indexed slightly
differently you want to be able to
combine
together without having to write a lot
of code so that's that's really what
what data alignment is all about and
when you add and if you're doing and
doing arithmetic between data sets so
you can imagine if you're working with
two time series so you here we have two
series objects one which is labeled B
through E and another which is labeled a
through D so when you add these two
together you say I want to add the
values which I want to add each value
labeled B together each value labeled C
together but then you've got some labels
which are in one but not in the other
so when you add them together you're not
really doing an array ad you're really
doing a join between the objects so so
behind the scenes when you add these two
differently indexed series together it's
really doing a join B so that you the
result object you get the Union of the
labels and then any place where there
was a mismatch you get you get an na so
you have a missing value and the result
and then once you've done that you know
the missing values are meaningful like
you want to know that this you know this
label was missing and one of the objects
and then you can drop you can choose
after this point you know I want to just
drop out all the labels where there was
a there was an na so so in the case of
in the case of a data frame so here I
have so here I have I have one data
frame here another data frame here you
can see that the C column is missing
from this one the row labels are
different and when I add them together
it does an outer join both on the row
index and on the column index so you
know you do get a bunch of you get a
bunch of na s and the rows in the result
and you know you want anyone who's
really interested in talking a lot about
you know how how missing data is handle
is sort of outside of the scope of this
talk but you get an outer join in the
result and then you can decide you know
if you want to fill the na is some value
or you want to drop them out so you have
tools to to then clean up the clean up
the missing data and however whichever
way that you want in practice it's very
common to get data that looks like this
so it's kind of a little mock-up of you
have a bunch of data it's differently
indexed and you just want to throw it
all into a table and you want all you
want it to
the union of all the indexes represented
by each of the columns and create this
uniformly index structure that you can
then you can then clean up and start to
you know perform computations on and
actually carry out your analysis I've
you know I used I've used R and I've
used MATLAB worked with a lot of things
and I you know I see this problem
occurring over and over again where you
have outputs of analysis where things
are things are not homogeneous it thinks
or things are messy things are not
homogeneous ly indexed and you just want
you know you don't want to take the tool
to get in your way you just want to say
you know throw this all into a table
Union not Union all of the the labels
together and then let me decide what to
do with it once you're done so it turns
out that even our makes this difficult
you know and it's it shocks me that it's
difficult so so as I was saying the axes
themselves so this is a case of where
we've got got a hierarchical index so
this is a data frame with five columns
we've got years and the columns and the
and the rows are now hierarchical index
where here I've got a country name and
an age and everything in the first
column is is Australia and then we've
got a bunch of ages here but the
important thing is that you know that
everything is sort of contained in the
index and so it's separate in the index
is separate from the data and you can
use you can use this labeling
information to perform transformations
and to reshape the data into into the
form that we need it you can see that I
stole this slide from another talk that
I gave so so when you're doing reshaping
so let's go back and look at this look
at this object so here this data frame
really each value here is identified by
three things so there's a country name
and there's an age and there's a year
suppose we wanted to to rearrange this
data in a different way we might want to
say put put the ages up here and put the
years back down here and so given that
each each value is identified by those
three things that's a very well defined
operation you can just
you know you can you can see so like oh
just move age up here you're down here
and then put all the values in the right
place so how suppose you have data like
this I mean how would that look so so
the two operations for doing that I
wanted to kind of explain them in a
high-level way before I start you know
firing firing code away at you so here's
a slightly bigger data set here I've got
got multiple groups I've got two
countries Australia and Austria and I've
only got five ages here and so you could
imagine we want if we wanted to switch
age from with year so so the two
operations for doing that so the so two
pivoting up is called unstack so you can
imagine if we unstacked age from that
would pivot up unstack and then we could
take year and pivot that down and that's
the stack operation and so I'll show you
how this works so if we said data frame
unstack age from stack year you can see
it switches the place of of year and age
from and so that's how you know a
reshaping operation with indexing would
work in pandas so see you see some more
of that so as far as missing data this
old base mainly show this through
examples so I've meant 'add the numpy
and numpy has a couple of functions
which help for detecting special values
and floating-point data I use the not a
number value as a missing data marker
which occasionally makes people upset
but it's really the best the best
solution that I've got and we can you
know if you're really interested in
missing data in issues and null handling
we can talk a lot more about it it's a
problem that I've been dealing with for
a long time so I've got API functions
and pandas is null and not null and
they're the basic tools for detecting
missing data and for producing a boolean
array that you can use to that you can
use to to select out or to exclude
missing data from from from pandas
objects one one gotcha of the na of the
missing missing data implementation and
pandas is you can't have n A's in
integer arrays
this is sort of an unfortunate
implementation detail that occasionally
jumps up and you know I get emails about
it maybe a couple times a month and it's
peculiar to to numpy and sort of you
know the the various options for
implementing missing data so it's big
the big topic and you know there was
yeah I won't go into it so talk a little
bit about group by at a high level again
before we start you know jumping into
code so so high so how many of you are
guests or
have done some form of group by either
in sequel or some other tool okay so so
the general idea is that you've got
you've got some data and you've got some
labeling information for it and you want
to so here's an example where we had an
array with labels ABC and so behind the
scenes you know will be I mean the
implementation is you know you know
you're not really very concerned about
that but so it's so it splits the data
into groups based on the labels and then
you just you want to apply some function
to the data in each group so here in
this case apply the some function to
each of these groups producing the
summed value for the a group in the B
group and the C group so you can imagine
you know having an array of labels eight
you know the eighth like this and an
array of data and you just say I want to
group this data by the labels and apply
the sum function you get out a new
object which has the values aggregated
and then the labeling for the result is
then the unique the unique labels in the
original label array and so you can
imagine if you instead had two two
arrays of labels then you know suppose
the wide I don't have them here but you
can imagine I could have an array of
ones and zeros and then there are
actually six possible combinations in
the result so the so the result of the
group by operation could be up to six
elements long depending on how many how
many combinations you observed in the
data so you can I guess you can begin to
see how how hierarchical indexing kind
of falls out of group by so if you have
multiple levels of so if you have
multiple layers of identifiers
you do a group by expression then the
result is going to be is going to be
labeled by the unique combinations of
values in the labels so there are many
ways that you can that you can split
data into groups so a very common you
know if you've used sequel before the
most common case is that you have a
table and some of the some of the
columns of the table serve as the keys
that you want to aggregate on so you
might say Group by column a column B
aggregate value C so those call it so
those that grouping information might
already be could be columns in the data
frame you might have external arrays I
say I have this object I want you know I
have this external array of labels and I
want to split that up into groups and
then apply some function to each group
and of course you know the question is
where does where do the groups come from
so you know we're Python we've got
functions we can pass functions into we
can use you can use functions as objects
so you you can you can define custom
functions which which can produce the
group label kind of in a very flexible
way so I've seen a number of different
you know group by implementations if
you've used R you've ever use the plier
package that's got some has it has some
ways to to define custom groupings but
it's a very flexible way of you know
you've got you've already got this
object with labeling information and you
might want to take the labels and then
produce a group label out of that and
that's a very flexible way to group data
so we'll see see much more of that so
like I was saying about about
hierarchical indexing and I've got this
example in the in the notebook I can
take a take a look at so here was a data
set where I had a data frame with the
country let's again the same data set
that I showed you before so I figured
why not go ahead and just just show you
this in the live demo yeah so so explain
what we're looking at here so are you
familiar with ipython it was well who is
not familiar with ipython
okay so okay so ipython is is a is an
enhanced interactive Python shell so it
has tab completion it has it has good
integration with the system shell it has
an interactive debugger it's a you know
basically it's you know it's sort of
like the the code running sort of
iterative development environment that
is you know most I guess most people
inside of a Python use every tie you zit
every day and it's like where I develop
Python code now the ipython notebook is
you can see it's running in a web
browser so what's going on here is that
you are connected to a I&amp;amp;I Python shell
running on in the system and you have
editable code cells so here in this you
can see mine looks a little different
from from yours because this is the
bleeding edge version but the
functionality is is is virtually
identical so the idea is you have
editable code code cells where see here
I have from pandas import star and so in
that cell basically press shift enter
and what it does is it sends that code
to the kernel runs it if there's any
output see if I had done print five and
it it captures that output and it
displays it in the in the browser if I
had done if I put a plot in here so if
suppose I did plot a range 10 so that's
a map pot live command it captures the
it captures the plot and then it it
renders it and outputs it in the in the
notebook so it could be arbitrarily
complicated and we'll do a little some
slightly more complicated plots but if
you've used mathematic before it's just
like the Mathematica notebook and it's
designed to be very pythonic and you
know give you a nice nice way to sort of
go through like a analysis workflow so
I've got a I've got a data set here it's
been used in a number of other you know
statistical graphics you know talks that
I've seen it's the baby names data so
it's the top 1000 baby names since 1880
in the United States so I thought is
kind of interesting
data set to look at on so so to get that
so to get that data into into the
notebook here I've got a a so first of
all you need to run the the first the
first cell which has the import import
pandas so we see here so shift-enter
runs that don't worry about the about
the plot so i just shift enter runs that
cell sets things up and then i'm going
to load the baby names to dot csv file
which i hope to god i put in the archive
and so you see that that ran that it
says it will say busy someplace on your
on your notebook and then if you if you
press well there's a command key i think
its control mb creates a new cell so
that's how I did that but so you can
just up will just edit the cell and type
names and you can see what what's
happened here is it's loaded the data
into a panda's data frame object which
tells you data column so year name
proportion sex sound X it tells me the
index contains the integers from 0 to 2
200 to 250 so it's two hundred
fifty-eight thousand elements long and
so now the way that this data structure
works is it's like a dictionary so if we
want the Year column we just do name sub
year and it gives me it gives me an
array this is now a series object-- and
you can see that on the Left we've got
the row number which is just the
observation number in the data set and
then the values go from go from 1880
through 2008 so it looks like the data
is already in order so so we look at so
we look at the full data set so it's got
so now what I'm going to do here so you
can get get the Year column name sub
year name sub sex you get the sex column
so you can look at the data like look at
the
like that if you look at the you look at
the proportion column it's God
it has floating point values so it's
this is actually really big data set I
mean you know quarter of a million
observations it's pretty big so if I do
: 100 through sub : 100 so slice slice
off the first 100 elements whatever
those are you can see that that gives me
the first 100 rows of the data set so
now you can see you've got something
that's much more you know pleasing to
the eye you can look at the data look at
the data like that so so we'll play
around with this this data for the next
for the next 20 minutes or so so these
so when I do name sub sex so suppose I
just wanted to select out the boy names
so I could say name sub sex equals
equals boy and so that gives me now a
boolean array and if I pass that to if I
do names sub and then name sub sex
equals equals boy that selects out the
the section of the data set which has
which has the boy names so I'm going to
go ahead and assign that to the boys
variable and going to do the same thing
and assign it to the girls variable so
names sub sex equals equals girl and so
now we've now we split the data set into
two pieces and so the idea with I'm just
going to shut down TweetDeck otherwise
we're going to keep getting PI data
retweets there we go
shift shift enter to execute cells so so
now from here suppose that we wanted to
want it to actually to Index this data
set by by the unique identifier so if we
look at if we look at the boys data set
so let's do : 50 so get the first rows
so you can see that each each
observation here is uniquely labeled by
by year and name so in some years some
names aren't going to appear like later
you know mm the names that people are
giving their children in 2008 are
different from the names they were
giving their children in 1880 as we're
about to see but if we wanted to
you know let's say iterate through the
years you know if we do boy sub sub year
equals equals let's say 1956 and we
select out all the boy names for for
1956 well we get a thousand observations
I'm going to print this guy and then
maybe dot to string so that will just
force it to output everything to the
console and so you can see here are all
the all the boy names from 1956 suppose
we wanted to order it looks like they're
already ordered by by proportion in
descending order so you can see that
Michael was the top boy name in 1956 we
might want to I'll show you how we can
reorder these tokens you sort and do
sort operations in a second so one so
one way we could we could do
manipulation of this data says we could
add an add a level we could add indexing
so I can say boys set index pass the
name and Year columns and that's going
to create so I execute that cell and
that now creates you can see that it's
removed the name and your columns and
now the data set is indexed by by name
and year so if we do colon 100 now you
can see that the output is a little
so now the name and Europe been moved
down into the into the row index and
we've just got their proportion sex and
soundex columns remaining so that if I
do if I grab the proportion column from
that that I've got I've got now a series
but it's got the it's got the indexing
information connected to it and so so
from there I mean the reason that the
the indexing is useful suppose that I
wanted to select out all of the data
basically all of the the proportion of
children that were named a particular
name so you can see here I have indexed
it by name and year and I suppose I want
to select out all the the West data so
to do that well there a number of ways
that you can select out data based on
the row index so the most the most
useful is the is the special IX field so
if we do IDF IX that gives us a little
object that enables us to to index the
rows and columns like like an ND array
so here I can do the IX brat square
bracket wes and that selects out the the
slice of data that that corresponds to
the to the West group and that's a very
fast operation so it looks like that the
West's name only made let's see I'm
actually not printing it all out
so it looks like the West's name only
made it into the top 1000 between you
know I guess the last year was 1972
which makes me a little bit sad but we
do a little more popular name like Peter
you can see that you know the data goes
all the way through you know to 2008 and
you can see what's happened here is when
I selected out the Peter group that
before we had something that was indexed
by both name and year and it's gone and
dropped dropped the name level from from
the index so if I just select it out the
gun
my keyboard has stopped responding to me
what's going on here so if we select out
the proportion column that now gives us
the proportions for all the for Peter
through all the years and then we could
plot that so if we do dot plot that
gives you a a matplotlib plot which it
gives you the incidence of you know the
proportion of babies named Peter over
time so you can see in a peaked in the
around nineteen sixteen has been a
steady decline so you know people aren't
aren't uh aren't you know well actually
the story is more complicated than that
so it's not just that people aren't
naming their children Peter as often as
they were so so here is a so here's
another another cell where I selected
out the Travis group and the peter group
you can see who I'm interested in
learning about their names so I select
out Travis the proportion I plot that
Peter the proportion and I plot that and
so then you can see here's a plot of
well I need a legend here so I'll do PLT
legend that's matplotlib pi plot oh
that's not so great label equals Travis
thought this worked yesterday label
equals Peter and so you can see that you
know people were really enthusiastic
about naming their children
Travis around you know the 1970s and 80s
and then it's been a steady decline
since there so so this kind of raises a
question you know is do people really
are people really just not so you know
happy about these names or something
different happening with people's you
know baby naming behavior so I so I
thought I would say okay how many unique
names does it take to you know if you
take the top names that people are
giving their children how many names
does it take until you reach 50
sent of all the all the babies born so
so I looked at this data site so that
would be an interesting to get that
number and so you know I can walk you
through the code necessary to to achieve
that so if we look at the data set so
let's let's take the boy names let's see
that's right that's right yeah yeah I
think it just it just connects the
Dottie I really I guess you should what
you should really do is if there were
none if there were none in a year I
guess really it doesn't it doesn't
appear in the top 1000 yeah but what you
could do actually so if we had if we had
the West like the West group and the
proportion yeah so what you could do
here is you could say reindex and we
could do range 1880 2009 and that what
that does is that is that can freakin
forms the series to the range 1880
through 2008 but then you could you
could on that object then call fill na
with zero so that adds zeros where there
are with our na s and then you can see
if you plotted if you plotted that I
mean the reality is it's probably not
it's probably not zero but you know it's
some small number but yeah so you have
so you have that ability to do that so
the re index function enables you to to
to reconfirm the data to a new index and
so that's exactly what has happened here
so I've taken so I've taken a bunch of
data that was relatively sparse I want
to to make it exactly match the range
1880 through 2009 fill the n a0 and then
plot it
kit can I tonight sorry could you say
that again yeah yes yes you can so so a
short hand is so assuming that the
column name forms a valid Python
variable name you can do dot as XS it as
an attribute instead of having to pass a
string to get item so does it kind of
walk you through how so I slide this
question of you know how does how do
people's baby-naming habits change
through time so I kind of want to walk
you through the machinery necessary to
answer a question like that so so the
first question is how do we group this
data set by year so I've got a year
column first of all so it gives me the
years so the year for each of the year
for each row and I want to group the
data by row so I'm going to call the
group by function and past the past year
and now now the idea here is that it's
taking the string year it's looking up
that column and it says okay I want to
group this group this data set by year
and so what actually happens here is
that you create you create a group by
object so I'm going to call that grouped
and now from here there are lots of
things that you can do with the data set
so you have this object you could say
compute the well an interesting thing
might be suppose we want to select the
prop field and what's the median you
know what's the median proportion of
well what's the median value and the in
the in the prop field for each year so
if I do sub prop what that's doing is
telling the group by objects select the
prop field and then for each group apply
the median function to that group and
then and then assemble that and to
assemble that into into a series which
is now labeled by year and so you could
see you could then plot that and you can
see how the see how the median how the
median proportion is changing over time
so this is kind of interesting that it
increases so
so one thing you might say is well the
you know as I will show you that the
people the diversity of names that
people are picking has been increasing
well a lot since since the 1980s but it
you know certainly over the course of
the the people got more creative during
you know during the 1910s and then
things got not so great and then so they
were just great were thinking very hard
about the names they were giving their
kids and now things are great and so you
know people are getting very diverse but
more precise questions be how many you
know how many names does it take to get
to to fifty percent of all the children
so that's a more complicated question so
so now we're going to go back to the
grouped object yeah so it's just a view
on the data yeah so so if we take this
this grouped object so the idea is that
we've got a number of functions here so
we have aggregate which elite enables
you to aggregate a field which is what I
showed you so I could have aggregate
said aggregate and pass a function
lambda X X prop median so that is going
to call a basically each subgroup of the
data take the proportion call and call
median on it I guess not I've got to
think about what happened here but the
most the most general function you can
do is is apply so apply takes a function
applies it to each group and then given
what the results are it tries to
assemble assemble the results back into
a data frame or a series so suppose that
we wanted to take the top five names in
each group so we can apply a function so
on the chunk of data I'm going to call
that X I'm going to say X sort index so
basically reorder the data using the
using the index but by the prop column
so that was going to put the highest
occur you know the highest
occurring baby names at the end because
it orders in ascending order so I'm
going to say ascending fall so I want
them at the beginning and then do : five
to take the top five names in each year
so you can imagine in your head you know
you've got these groups of a thousand
baby names per year I'm sorting them in
descending order by the proportion and
then I'm taking the top five let me take
the top two or the top what's going on
here take the top one actually so just
taking the top one so it you know pandas
kind of defends you from you know
spitting out a hundred thousand rows of
data into your console so that's what's
happening there is a you can actually
control that but when I selected out the
top five you know I guess it decided
that 645 rows was too much to display so
I'm just going to do : one to select the
top one call that function you can see
that from 1880 on where people really
like John for a lot of years and it
became Robert and and James and some
point so that index number is actually
the the observation number in the
dataset so so what happened here is that
it took the result of each group and it
it added on on it added the year so now
we've got so there was in the result
we've got index with two levels where
the first level is the year the second
level is the the observation number from
the data set so you could get rid of
that if you wanted so this is the top
name per year the folds to full data set
at the top one thousand yeah so if I'd
done the top five let's say and I'm just
going to select off the last 100 rows of
the data of the result you can see that
in 2008 the top five names were Jacob
Michael Ethan Dan Joshua and Daniel I
actually didn't notice that Jacob is the
in the top name for a lot of years
so anyway so this so this gets us closer
to to answering the question so we can
split the data into groups like this but
now suppose that we had the data for the
boys boys here equals so let's say 2008
and we have the proportions these all
happen to be so these all happen to be
sorted so now this is an umpire race so
I can call the the numpy rake in some
function on that which gives me the
cumulative sum so let's call this scheme
some sort of walk walk you through how
this looks then I'm going to so I do
that and now I'm going to call the numpy
search sorted function with 0.5 which
gives me the the index of the index of
the value in the cumulative somewhere
where point 5 is reached so in 2008 it
it there were it took 120 set the top
127 baby names in order to to name 50%
of the 50% of the children but if you go
back to 1880 that number is only 15 so
so the question is how did this have
this evolved over time so I'm going to
take this little this little exercise
with the kiemce sum and replace this
with just a dummy
you know variable group you can even
make a generic and you know make this a
percent number this percent number
generic and so I have this this get numb
function I take the group of data
I sort index by prop descending order I
take that ordered group select the
proportion cumulative sum search sorted
by the percent that I'm interested in so
a bit of a mouthful but you know guess
you could do the probably so it might be
difficult to do in sequel but you could
do it
yes oh yeah sure
Thanks sorry about that yeah I didn't
know about that feature so I'm not
excellent okay so so then so then I've
got I made it a little a little simpler
even getting them at percent
I passed the data the percentage I group
by year and then and then I apply this
this aggregate this aggregation function
and pass the percentage that I'm
interested in so here I want to get the
number of boys it took to name 50% of
children through time I'm going to plot
that call that boys do the same thing
with the girls label that plot girls and
so you can see a rather alarming trend
that people were always a bit more
creative about girl names over time and
then around 1980 you know I'm not sure
what happened cultural revolution
everyone wants to like my children my
child is special my child is unique it
got a you know got to be more creative
about names and so it's just been a
upper a steady upward trend so you know
if you extrapolate from here you know I
don't know it's like we're gonna have a
hard time like you know saying each
other's names pretty pretty soon we'll
have to find like random sequences of
characters you know so anyway so you
know this was actually kind of
complicated in retrospect now that I
look at this but what I wanted to
explain you is that is it pandas offers
this sort of very integrated and
powerful tool chain for expressing
operations on index data in it and
enabling you to to do very fine-grained
control over operations on groups of
data being able to write those functions
in Python in a nice way and then have
that sort of integrate with the rest of
the tool chains that make plots and
matplotlib really easy basically just
have all the functions that you need to
answer answer the questions that you
might have about it about a data set and
secondly you know just like for example
like this like having a view of
data like this where it's a like I've
got this data I know that it segments
into years and I just want to look at
you know the top five opera observations
within within each group and once you
sort of you once you understand each of
the tools along the way here basically
you're just assembling these operations
say you know the sort sort select apply
select and then you've got this so you
can catenate these operations together
and sort of you know it's starting to
look a little bit functional then you
can really crunch down a big data set
and sort of get some meaningful answers
out of it pretty pretty quickly so I'm
trying to think there's any anything any
fun stuff that I had here so I also have
a data set in here you can play around
with you know now you have all these
notebooks you can play with the data so
I have a data set with the number of
births per year so I have year sex and
then the number of birds and so we can
take that merge that so do a joint
operation between the names data and the
births data and then if you actually
want to know the number of people that
were named that name in the air we can
take so the merge data set now looks and
so what's happened behind the scenes is
it's looked at these two two data frames
and it said okay the call in the common
column names are year and sex so join on
those two keys but I could have
explicitly said join on sex and year and
that that would be very explicit
database joint operation between these
two data frames and so you can see the
result now has has everything we had
before but it also has the number of
births so if you wanted to create so if
you wanted to get the number of people
in each year take the take the
proportion times the number of birds and
I just called numpy floor on it to get
an integer so I run that and see I
assigned a column to the data frame so
I've got now a new column persons maybe
may be the right word would be people
but you can actually then
you can sum up you can then group by
name sum up select the person's column
sum that up and order and you could get
the number of people born with each name
over the whole dataset so you can see
that there were five million people
names John names James
more than John actually so James is
still a pretty popular name it turns out
and so yeah it's a pretty simple way to
to aggregate that up the data set and
then to look at ad and work with that so
anyway thank you guys</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>