<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Node.js in Context with Jason Hoffman of Joyent | Coder Coacher - Coaching Coders</title><meta content="Node.js in Context with Jason Hoffman of Joyent - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Node.js in Context with Jason Hoffman of Joyent</b></h2><h5 class="post__date">2012-05-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yluchvyUzvU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yes i was i was actually looking down
for a second there but i mean how many
how many people are actively using
nodejs to static curiosity there's okay
so some some some of you and so it's
becoming an increasingly popular runtime
in especially the you no html5 CSS
JavaScript type space for a couple of
reasons and you know we're of course the
company that it sort of came from and
you know the core team works with the
company so I wanted to actually explain
a bit around well where it came from why
it exists where is it going in the
future you know as a base runtime and
that's sort of the bit around no GS
within context now at least node as far
as as something that came out of giant
you know we're an eight year old company
you know most of the engineering cares
in the US you know we actually have at
least you know upwards of you know
nearly sort of a hundred megawatts of
data centers deployed is as far as a
footprint and largely owned by you know
employees and you know intel and and
basically carriers and MSOs and there's
a couple things that we at least do on
on my team around base activities and
that as you know we do an open source
operating system an open source runtime
and then we basically package all up
together and we delivered as a box or we
delivered on premise it's effectively
what the business does you know it's
well it's no different than a typical
operating system typical runtime you
know putting it all together into a
basic box now if we look at our industry
just in general and we look at it in a
very sort of basic economic sense is
really not a lot to it you know meaning
that we have one basic economic good in
our industry which is just the bit and
we weigh it in bytes and that's no
different than if it's a soybean or a
t-shirt or anything
you sort of go and ship around too good
for us in our industry we actually
called latency is our service delivery
time how long it takes one thing to go
from one place to the other we typically
call bits per latency bandwidth and we
always put these things inside a
container of some type you know in fact
at least on things like the
standardization of container ships it's
things like Paul barons work on packet
switching networks and the 50s it
actually inspired that standardization
and in fact one of the bigger problems
that we have when we sort of looking at
especially large-scale infrastructures
is we actually have no metadata on bits
there's no the equivalent of a barcode
we only have it on packets which is a
container on the network we have it on
memory words we have it on blocks we
have it on cpu registers and you know
that's sort of basically it and
computers are also pretty simple things
we really just have data that we do
compute on and we send and receive it
over a network and when we start
thinking around then just a basic
economic model for delivering these
types of things as a service we have a
bit that can live in DRAM we have a bit
that lives on disk we have bits that
live in CPUs and those so those
effectively become the three readily
available economic goods that we have
and those are of course called
commodities and then it's the movement
of them the sort of iOS the bandwidth
and so on like that there are readily
available economic services those are
the base utilities network IL memory o
disk i/o and we of course have a base
service delivery time now you know some
want boring in a pure application sense
but this is really all there is inside
any computer that you ever touch a bit
lives in one of those three places and
it moves along one of those three paths
and so from a large scale service
provider point of view it's basically
how do I provide all three of those
commodities all three of those utilities
and do sort of a guaranteed service
delivery time and you just do that sort
of end-to-end now the bigger problem if
we look at the way that
the industry's even structured as you
effectively have networking companies
and compute companies and data companies
we might call them switch vendors server
vendors and storage vendors but they do
have diamond often diametrically opposed
view of things and in fact on the
computer side on the server side we're a
bit sort of held down very much by the
fact that we're used to using them as a
very big calculator literally a guy
sitting there just doing math turning
dials and having a five megabytes size
hard drive that of course is five tons
and has to be you know flown around and
even as we sort of sit there and we see
within the industry where we've gone
from a room size calculator to now a
calculator that sits in front of you to
a calculator that gets shipped inside
your home to even how we started using
the internet in the enterprise you know
very often we would draw these great
pictures in the 90s of you know five
people using an application between the
hours of nine to five and nowadays we
write a cloud like this and we talk
about things like you know html5-based
multi-device delivery of an application
and so on like that and we draw this now
of course the problem with a lot of this
or at least what the base abstraction
needs to be is we just need to think
about what would it be if we just
thought of it as a world of devices with
the network as the backplane right so
just everything's a device the networks
the back plan and if that's the base
sort of strata that we're going to
operate in how would we go and design a
system that runs that right not how
would we deal with legacy Croft how do
we deal with these types of things how
we look at a world of devices with the
network is the backplane and of course
when you look at device users device
user is hitting an application you know
very often are a lot of users hitting an
endpoint a lot of users sort of crushing
in and that does actually happen to be
crushing and so where you typically see
a lot of traditional runtimes a lot of
traditional frameworks a lot of these
traditional things basically begin to
start having issues now is when you say
have an enterprise application that five
people used to use and now
you're actually trying to get it to be
used by 1,500 sales guys in the field
who expect soft real-time access to it
on a mobile device and so that's a
different type of application and it's
really historically because we do use
computers to calculate things we
actually use them to do math in fact
that's even what the name computer comes
from compute means to determine by math
but the problem being that we also use
them to connect things we also use them
to do movement and of course connecting
where we join in fasten things together
where we actually go ahead and schedule
so as to provide some continuing service
that is not how computers are designed
they're designed to be good computers
are designed to be good at math they're
not actually designed to be good
connectors or movers and in fact we can
go and look inside a data center and we
can break down what's inside of a data
center and very very sort of simple now
as we actually have computers connectors
movers and stores those are currently
the four types of devices you have
inside a data center you have a server
that does computing you have a thing
that actually say connects those things
called a switch you might have an
aggregate switch and then it connects to
a router that moves packets around and
you might occasionally store stuff and
the store stuff being that well storing
things long-term does not require you to
have a bunch of compute or memory or
those types of things in it and that's
two-thirds of the cost of the box so why
spend a bunch of money and so we really
then just have computers movers
connectors and stores when we sort of
look at what that base thing is and
again the question becomes if we think
of the world as just a world of devices
with the network is the backplane and we
just have to do math store stuff connect
things move things then how would we go
ahead and redesign operating systems and
run times to do that well and how do we
do that in a way that sort of allows us
to migrate from the sort of morass that
we're in now and again the crushing part
of it is you know there's some trends
that are popping up right so one of
course
is not only as everything becoming a web
application as the base transport
mechanism but more people are using the
web in a 2001 there was what 200 300
million people using the internet and
now there's nearly a billion people
using just something like Facebook and
so the usage is significantly larger
than it was a decade ago literally
there's ten times more people on the
internet today than there was a decade
ago if you recall and say 2000 2001 what
a phone looked like it was not an iphone
we did not have iPads and now I myself
AM and I have three daughters and
they're all have iPads in the 11 year
old as an iPhone and they all have these
types of things like it we have TVs that
have four chips inside of them we have
blu-ray players in every room I mean the
typical sort of crap and so everything
really fundamentally becoming a web app
and because we actually sit down and we
start thinking of it really as a world
of devices network as the backplane the
way that we've been writing applications
whether you realize it or not is
changing we actually don't write client
server applications from a decade or two
ago we actually right sort of soft
real-time data sync to peer type
applications we actually very often have
say a server on a phone and a server in
the backend and they're passing messages
between one another and then they're
also interacting with say a local thing
that you might call a client and so what
we're really sort of seeing is we're
seeing really the sort of presence of
soft real-time expectations in an
application that someone uses we're
actually seeing that the way that you're
right that is a non-traditional client
server and if you look at just the
limited ways that one goes and does
distributed concurrent systems anyway
message passing is one of the types of
methods you use as one so it's already
one in the switching space and some
other aspects of it but we still have
these arguments now with servers where
you're like well you know we should do
is we shouldn't finna ban a bunch of
these up and create an operating system
it makes these five servers look like
one big ass server and you have a lot of
these types of things around art
see an IPC and shared memory and so on
like that when really what it is is this
message passing as one for doing these
types of systems and it honestly
reflects the way humans interact you
text message you leave a post-it note
your write little notes and so it turns
out writing applications that way the
trend around big data is not big I mean
myself coming from large-scale
scientific compute before i started
doing you know data centers in this
space that's been big data forever I
mean what we really have right now is an
interest in going from user generated
data to machine data and we have an
interest in real-time decision making
from machine data or behavioral data
that machines look at about human
activity that's the Big Data trend but
it really is a real-time analytics type
trend much more so than the size of the
data we've already had telescopes in
existence that could put out an exabyte
a day meaning it would take them two
weeks to exhaust the enterprise storage
market you know it's 2008 is where we
crossed over to the point where if we
lit up every DNA sequencer in the world
we would exhaust the world's supply of
hard drives that have ever been made in
four days and so we have big data in
that sort of world that comes from
nature but it's really real time access
and because we have so many people
typically now accessing these
applications with mobile devices and
what we actually see as we see that
applications are often becoming
connection limited connection limited
right and so handling a lot of
connections doing a lot of sort of i/o
and of course you know sort of put this
within sort of context again which is
where you know we started working on
nodejs was to actually start working of
a data center as a device you know
meaning how do i physically and
logically design a data center
independent of knowing what i'm going to
run in it and actually do this from a
very sort of traditional supercomputer
type approach where you can actually
take a very sort of traditional coupled
synchronous shared memory great at math
type compute bound supercomputer and in
fact most of the world's problems are IO
bound and so you actually need backends
that do that well they're decoupled
asynchronous event-driven
on shared memory where message passing
is basically the sort of predominant way
and in fact if you decided that you were
going to design such a thing it would
look more like the back end of ass and
thats a natively runs compute on it and
so node became very much the run time
that we were using as I'll show you in a
minute for creating that sort of large
machine to machine system across many
many many sort of data centers and then
of course as it started showing up on a
lot of devices a few years ago you know
the sort of Indian story got to be
pretty well now a lot of this of course
is doing things well I want you to run
my app well I want you to keep my data
well when I click click a button I want
it to be fast I wanted to do things you
know like that and so from a base
technology view again run applications
well data centers a box run times on
devices flattens everything down a sort
of one dynamic language like Java Script
you know typically a compiled language
like C got a good markup language good
presentation language flatten everything
out and then keep things simple you know
really sort of go with one instruction
set one transport mechanism one
messaging system one type of format and
we really have now seen applications
emerge you know in this way and emerge
in this way in the sense that people
start caring about performance and
scalability either resiliency and
reliability the application whether you
can understand what it's doing in
production is secure you know what's the
sort of data integrity like and is it
actually elegant you know meaning as
simple as possible to sort of access it
interact with it integrate with it
interoperate with it versus a typical
sort of just agility flexibility
backward compatibility don't want to
upset the boss type way to write an
application and so within that context
then when we start sort of thinking of
nodejs nodejs for a design point point
of view as we basically needed a
framework to just quickly write servers
in a dynamic language so serve as a talk
a specific protocol you know they
function as ap
I n points proxies with the policy load
balancers data ingress telemetry systems
like that so no different than just a
very traditional service oriented type
architecture where you can very quickly
right services but you actually need the
right services that we're basically
going to be lost less in terms of i/o
and we're connection intensive they were
not meant to do math well and in fact
from a design point of view one process
one core you know lesson 1 gig of ram is
actually qaid to push line rate 10 gig
and do a million connected endpoints
were about twenty five percent of them
are pushing traffic what to put within
context is about you know 20 25 hundred
times more than what a typical runtime
whether it be Java or Ruby can typically
handle you know in a single process and
even when you sort of take the memory
footprint into account it becomes more
pronounced and so it's even very normal
for us to write 128 megabytes eyes node
processes that will actually push
between 1 and 10 gigabits per second of
traffic and have 200,000 connected
endpoints on it 128 Meg's and so sitting
down and thinking about you know how one
sort of rights applications like that
which then made it very minimal for it
to be on device too and so we have
things like it's showing up on the smart
thermostats from you know Emerson power
you know showing up on you know now
windows mobile phones and it was in you
know webOS which of course at least
conceptually has you know the boot to
get go from a from a philosophical point
of view sort of overtaking that you know
but for us again it was really around
well how do we do like a tremendous
amount of data how do we actually do
telemetry systems how do we begin to
basically do things like look at a whole
lot of servers and can look you know
connect a specific amount of data bring
it back graph and in real time so you
know like not to go too much into say
the details of this but you know this is
a good illustration of what what node
was designed to do you know in that this
is this is what's called a heat map
graph and
the y-axis is like latency the x axis is
time this is about ten minutes you know
the far right over there is right now
and this is ten minutes from now and
this for example is looking at you know
about 300 database servers who were part
of one one of these large games we were
running and there's about 1.8 billion
data points in this is in terms of what
you see in every dot that you see is
basically like a you know a you know a
my sequel query latency so the actual
time it took for a quarry to happen at a
specific point in time and you know you
can see things like nothing happened
here you have this whole group of Layton
sees there and then everything gets
slower which is why this is going up and
the whole system basically collapses on
itself this is a very normal sort of
graph pattern for like congestive
collapse and you know the equivalent
being you know walking down the street
having a heart attack and the ER doctor
was able to see you know the 10 minutes
of your EKG before you died there on the
street right and so the ability to sort
of write a little run time that goes and
collects a bunch of data from a whole
lot of devices and brings it back and
graphs it up was honestly what node was
designed for the ability sort of go and
say you know what's everything that's
running on a server what's everything
that's running in Iraq what's everything
that's running in 48 racks you know how
do we sort of go and basically just
write a very large scale telemetry
system and do that by even sort of
redoing the run time now we open source
at two and a half years ago it's MIT
license which is about as liberal as it
is it's not a product of hours it will
never be a product of ours we don't do a
pass around it or something like that we
just happen to be the largest production
user of it and in fact that tends to
basically shape its use now besides
showing up in every mobile OS in
existence and and and and more of those
sort of coming out it's of course a
support at runtime like on a zoo right
so Ned nodejs and it's it's actually
deployed you know the number two there
after net you know passes like Cloud
Foundry from VMware no JSE's is
is is also the second most popular
runtime there and then we see a lot of
interesting things you know like what
was being done you know by the guys at
ebay where it was around you know how do
we actually aggregate a lot of our API
endpoints into new endpoints and create
us whole sort of you know dsl around on
these types of things and that was all
sort of done in node.js as well and
that's a exactly the perfect type of use
point how do I basically write a service
endpoint that aggregates a bunch of
other services and how do I potentially
have the devices that I'm interacting
with also be those service endpoints now
the why javascript part became pretty
pretty simple i mean it's it's actually
called nodejs because there is a node
part that i'll talk about in a second
and then there's the jas part and they
are actually largely independent of one
another even though conceptually more
difficult to separate and that's really
because javascript happens to be in
event-driven language and you is you is
our event driven and so one one way of
thinking around at least philosophically
note is just the UI way to do things on
a server side you know usually servers
are not done in the event-driven
non-blocking meant to be instantly
responsive you know type type way to do
things it has a spec you know which not
a lot of languages do not all of them do
and the specifications actually
controlled by an international standards
body which is nice and if you take at
least these two base criterias you know
there's a recent one around Ruby I
believe but the only thing that
typically falls out of these two is
things like CC sharp and JavaScript you
know as far as the base spec and so what
we see is we actually have seen in the
marketplace multiple implementations
whether you're typically competing for
performance and embed ability you know
so Microsoft has multiple JavaScript vm
is over time you have trace monkey
spider monkey you know from Mozilla you
have v8 from google give a lot of these
sort of you know great examples
of a language runtime against a spec
open language and that's been a pretty
good benefit now the added benefit of
course is that this now flattens the
stack into html5 CSS JavaScript and say
if you still want to write something
like see it becomes for c++ it's pretty
easy to do now if we look at the node.js
part of the implementations there's you
know no that's under github the
important library part that is node is a
thing called lib UV and there's some
add-ons like the parser some base
instrumentation type things that we do
like no dtrace and note panic but the
thing that was interesting around the
lib UV work you know was really around
you know as ryans asserting here as it
says lib v's the world's best
cross-platform networking library what
we wanted to do within the node.js
project was take the node part out and
actually make an entirely cross-platform
and so you know we worked last year
quite closely with Microsoft for the
year to sort of sit down and say well
how is it how can we basically make it
so that within the node part of node you
know lib UV is a see library is you know
always basically working on the
constraint that if it's not in Windows
it doesn't go in if it's not in you know
UNIX to it doesn't go in but the only
basic features that show up from a you
know I Oh abstraction point of view
within nodejs is ones that are actually
present and can be present across every
operating system in existence because a
goal really is in fact to write an
exceptional and application with an
exceptionally small footprint that runs
on every OS or device in existence right
to make something very sort of easy and
so the lib UV parts actually if you like
to geek out on runtimes it's a it's a
pretty good one to look at and of course
also sitting there on on github as well
as a separate thing and so we see things
like the love it guys you know taking
lib UV and combining it with lua as a
language interpreter which you know on
the node nomenclature if you will be no
Lua you know if you wanted to think of
it that way but being able to take a SI
library like lib UV combine it with any
language interpreter that you can
basically combine it you know something
is either in C or C++ and give it the
features of node is what Libya fees for
and also make it entirely cross-platform
as a result of doing that and so if you
really begin to look at that work Libby
UV coming out you know which was part of
dot six you know dot eight coming out
now really sort of progressing the one
point oh you know Jas is it's actually
done from uh it's it's done I mean
there's not too much to do to it anymore
you know we're not adding every thing
under the Sun to it it's it's meant to
actually handle a lot of connections do
a lot of i/o and so when we start
thinking around that sort of basic idea
that well the runtimes largely done then
it's really just around sort of handling
two parts of the implementation one is
making sure that the actual module
interface that you can go and write a
module for it is exceptionally clean
standard won't ever change and the other
one being that it actually is very easy
to instrument in production and so again
if we think about you know just some
simple examples of that little slide we
showed earlier if you're thinking around
things like performance and scalability
the way note is right now is there's
actually nothing left to do with node to
make it better performer scale better
most most of the times where it's
breaking now is more like you know the
tcp/ip stack of the operating system is
on can't handle as many connections and
so it tends actually be operating system
optimizations to drive the performance
and scale part of node and yes it's
supposed to be a single process that
runs on a single pore and that's the
design it's also not going to be
multi-threaded and anything else like
that that lives within a module if you
care about
that and so when you start thinking
around the list of doing things well
then most of the efforts that we have
remaining within nodejs is really around
resiliency and reliability of running
that in production and really around
debug ability and understanding it in
production that's actually where you can
still do things within node and so
there's some unique things around node
that we've done to you know make it good
for that one it dumps like an operating
system and so literally it's got a name
node panic where this provides
post-mortem debugging of single failures
and so you can sit down and you know be
running a thousand of these processes in
production you have one of them that's
sitting there at ninety-nine percent
utilization of a cpu and you can
literally go dump a full stack trace out
of that literally dumped the core file
and restart that process pull that cord
dump out put it in a kernel debugger
like md b or g DB that has the module
that can read the dump and go and root
cause that error and so the ability to
sort of do these one-in-a-billion type
bugs that you see and root cause it
without disruption means that you can
look at a large production environment
of this so you can look at a large
deployment across devices understand
what the normal parameters of that
application needs to be when it's
running and if it goes outside of that
dump core restart the process as a
regular sort of way of doing things and
then bringing those core dumps in and
sort of regularly analyzing them and
seeing what comes out it'll really sort
of allows you especially in a large
production environment to really go
through and find these rare bugs that
sometimes you know you know the typical
things where every six months it pops up
you know and and and all these things
are spinning out of control and you do
the typical you know reboot reboot
button type type way of dealing things
and so it actually has pretty
Mendes post-mortem debugging and we
actually do a lot of work around
post-mortem debugging and dynamic
environments and publish various things
than there if you care about following
the engineering lead that works on this
aspect of node this is as blog his
name's Dave and it's DTrace org slash
blog / dap and it's got a lot of you
know base base you know sort of things
that he does around managing a lot of no
dependencies when you deploy an
application how to actually do very good
solid node v8 post-mortem debugging you
know as a base capability you know where
one can really go through and do some
very sort of interesting stack traces
and then importantly one can actually go
through and ask you know a very simple
question that's normally impossible to
answer in a lot of other dynamic
language environments and that's like
where's the program spending all of its
time because especially in something
like node where it's a language
interpreter and then it's a whole sort
of you know framework around you know
handling all the sort of i/o aspects the
ability to sort of you know literally
trace in and out of that and go across
every layer and sit down and say you
know how long is something spent you
know one can actually go through and
well you can't see this here so I'll
show you a picture one can actually go
through and say graph this into
something that's called a flame graph
and so this is a way of visualizing
where a you know an application spends
all of its time and so like this is this
a very simple single node process it's
responsible for making an image data you
know JSON file comes in creates a PNG
file spits a PNG file out all it does
and so you know the way that a flame
graph works is the the bottom line is
the total amount of time you know like
it takes a second for the process to do
this and what it proceeds to then do is
break out every other possible part of
the system and language interpreter and
lines of code that it touches and
assigns you know of course a time to
each of them
and then that's how big the graph is
right and so for example you know it
spins you know you know the equivalent
of that amount of time you know
executing things from you know line 4868
e up and you know lib P&amp;amp;G is up here
libs e is up there and so one thing I
think that's particularly interesting
around around using nodejs in these
types of environments we're using it as
both a nun device runtime and a data
center you know back in runtime is we
put a tremendous amount of effort a
tremendous amount of effort in one
making it as I saying earlier entirely
cross-platform and then a tremendous
amount of effort and just being able to
answer two very difficult to answer
questions you know where's my
application spinning its time and when I
see something that's exceptionally rare
is a defect can I go and root cause that
having only seen it once you know and so
that that being the two issues and it's
a bigger problem especially now if
you're running a single process where
you've trusted it to handle a million
connections because when the process
pupus itself you just cut off a million
connections it's not spread across a
thousand application servers right and
so being able to do that and you know
that's that's largely node</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>