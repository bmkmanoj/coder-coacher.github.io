<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Choose Your Own Adventure: Chaos Engineering | Coder Coacher - Coaching Coders</title><meta content="Choose Your Own Adventure: Chaos Engineering - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Choose Your Own Adventure: Chaos Engineering</b></h2><h5 class="post__date">2017-09-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Ykn7WVqN1qc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm Norah Jones for those II that
thought you were getting a concert today
I deeply apologize jokes aside I'm a
senior software engineer at Netflix
specializing in chaos engineering
prior to joining Netflix I just joined
three months ago I had the opportunity
to do chaos engineering at a few
startups one of them being jet comm
which is an e-commerce company and the
other being a alarm calm which is a
security and home automation company
most recently I actually got to write a
chaos engineering book with a few of my
stunning colleagues at Netflix and we
have a few extra copies here today if
you'd like to pick one up after the
presentation so first and foremost in
this talk today we're going to talk
about what even is chaos engineering
because it means a lot of different
things to a lot of different people
we're going to talk about how you need
to choose your own adventure with chaos
and we'll actually go through some
scenarios where we choose adventures
together we'll go through different
phases of chaos that I recommend
unleashing before unleashing you know
your full-blown chaos we'll talk about
the road to cultural acceptance and how
to actually get your developers and your
managers and your business units excited
about chaos engineering and excited
about embracing it will also talk will
place a big focus on the culture around
chaos engineering and I'm gonna
alternate between anecdotes and advice
and when I do you're gonna see a story
icon so it'll just look like this so
this is to help keep things flowing
smoothly while I'm alternating between
anecdotes and advice so let's start off
with some known ways for testing for
availability some very common ways that
most organizations know are unit testing
regression testing and integration
testing there's a history of forcing
microservices the infrastructure and
ecosystem to fail in order to test the
entire system and this is commonly
accomplished through these top three
things but what most organizations don't
seem to have adopted yet is chaos
engineering you know if I've seen this
common philosophy where you know they
think people think that you can
accomplish most of your testing
through the top three and if you're
doing it well enough you don't need the
last one or people think if you're doing
the last one well enough maybe you don't
need the top three and I want to share
with you a quote from one of my
colleagues Haley Tucker she says that
and I want to emphasize that both sides
of the equation the unit regression
testing side and the chaos side are
required to get you to the level
availability you want you know there's
differences between both sides and we're
gonna get into those a little bit today
so enter chaos engineering first of all
I want to take a quick survey
who knows what chaos monkey is okay so
pretty much everyone in the room who
knows what chaos engineering is okay not
not that many hands um does anyone want
to volunteer to tell me what they think
the difference is between the two and
this isn't a trick question it's just
more meant to illustrate a point sure
yeah yeah absolutely that's a great
definition so for those of you that
couldn't hear he said that chaos
engineering is more of a strategy and a
discipline and then chaos monkey is more
of an app or tool to to use with it and
that's that's that's a that's a very
that's a very good definition but I want
to use those to bring up that that chaos
means a lot of different things to a lot
of different organizations but there are
some overarching themes I've found to be
consistent when I've been doing chaos
engineering in my different
organizations a common definition that I
found really helps and this comes from
the principles of chaos org website it's
chaos engineering is the discipline on
experiment you know in a distributed
system in order to build confidence in
the system's capability to withstand
these failing or turbulent conditions
and production and so that's that's a
lot of words but essentially it's like
making the system stronger through
through pre-emptive testing you know
through experiments and chaos monkey is
older news it's it's been a real run for
a really long time it's still actively
maintained and it's on opens it's open
source but the discipline of chaos
engineering
is emerging it's fun it's new but it
really needs to be handled with care and
practice in order to successfully run a
chaos initiative in your company it's
very important to understand the
fundamental business schools of your
products and have a high-level view of
what the technology looks like that runs
your business so some reasons for
getting into chaos engineering um you
know maybe your business isn't sold on
it yet
so so here's one reason you can't keep
blaming your cloud provider I notice a
lot of blame is placed on third party
services that maybe you don't have
control over but at some point it gets
to it gets to a point where you actually
have to own your own outages right you
can't keep blaming other people so this
is an actual screenshot says we are
having trouble communicating with the
Amazon services please sign in again to
continue right you can't you you're
gonna have to have fall backs at some
point and chaos engineering can help
with that here's another reason you know
why is there a fear of chaos when it's
inevitable Frank Underwood says at best
he says I often found that bleeding
hearts have an ironic fear of their own
blood you know if failure is happening
anyway then you know why not embrace it
why is there a fear of doing Cass when
you know systems are bound to be chaotic
anyway and my most insightful slide
computers are complicated and they will
break right things get especially
complicated when you're running on the
cloud when you have a microservices
architecture and things tend to get a
little out of control and it's
impossible for a human to keep up with
everything that's going on you know
hardware and firmware failures are
common regardless of whether you're in a
start-up or a large organization and I'm
going to place a bet that scaling your
services rapidly is a requirement and
chaos engineering is actually a way to
ensure more availability while you're
scaling outages and failures are
inevitable we all know that as engineers
but we can lessen the blow through
regular chaos experiments so now we're
going to get into our
choose-your-own-adventure now that we've
defined chaos engineering and we know
why we need to do it let's I'm going to
introduce you to chaos Carol
so chaos Carol is going to be our main
protagonists
and she's gonna get into a few different
situations and we're gonna have to
decide what the proper outcome is she
means well
right but sometimes you know she faces
her decisions and she's not really sure
what kind of situation she wants to get
she's gonna get into but her primary
goal is to is to help the company and to
help fortify availability so let's start
off with where's Carol starting her
chaos because this makes a huge
difference are you starting it at a
start-up or are you at a large-scale
organization and there's a number of
questions that come into play like you
know do you have a steady state with
your startup do you have a normal
defined are you having outages every
single day if you are you may need to
approach your chaos a little bit
differently if you're in a large
organization how long have you been
around is there is there any concept of
chaos is it is it going to met with will
be met with a lot of pain from upper
management how do you go about
convincing upper management that you
should do this so I'm gonna begin with
the startup because that's how I began
to and I'm going to share some of my
stories from this so in a startup I like
to introduce call phase one introducing
the chaos
my first project when I was at gedcom
was actually a chaos engineering project
I was about two weeks in when there was
an outage that brought the site down for
an entire day over a weekend period and
it was something that my manager at the
time thought could have been caught with
chaos engineering so he emailed me and
he said let's get started on this you
know we think we really think we could
have caught this and so you know I was
two weeks in I was very new at the
company so I said okay what does the
system look like now you know I I had to
get that info and when you're working in
a start-up you know documentation is a
few and far between right and if you do
have documentation on what the system
looks like you know it's probably
outdated you probably don't have proper
tracing yet you probably don't have a
great idea of what's talking to each
other especially at a company that's
spinning up new services all the time
and jet had about nine hundred micro
services and that was pretty much what I
knew about the system so does anyone
here play PC
by any chance yeah does anyone play a
total war Warhammer anybody yeah hands
so this this screenshot is from total
war Warhammer so I was actually making
this presentation in the library and
someone was playing this game without
headphones on and ironically enough
there's this guy I think he's the Kaos
commander and he comes on the screen and
he says the armies of chaos are coming
prepare your defenses and then he'll
like change up his messaging a little
bit but really he's just letting you
know that he has these chaos armies and
they're coming for you and he's letting
you know this every 30 seconds and when
someone's playing on the library without
headphones on it's pretty annoying but
it got to the point where I started
laughing because I was literally
creating a presentation on chaos
engineering and I thought this is so
relevant to what I'm doing right like
you have to get to a point where you
have to decide you know should I let
people know I'm doing chaos like is
something truly chaotic if I'm letting
them know I'm doing it or should I just
let the chaos run and see what happens
right that's it that's a question you
kind of have to ask yourself when you're
introducing these and so we'll get back
into this a little bit later so like I
mentioned before it's important to start
with a steady state define your normal
system and business behavior for your
service services I didn't I didn't have
that at the time you know so I couldn't
I couldn't totally define a steady state
and also determine what the system
architecture looks like on a high level
so since there wasn't a diagram of what
the architecture looked like I had to
take it a little bit at a time so like I
said it was a micro services based
architecture everyone seems to be moving
from monoliths to micro services
thinking it's the Silver Bullet that
will solve all their problems and
ultimately save them money right there's
always money and the micro services or
the banana stand but what people don't
immediately realize is that this
actually adds complexity in different
ways as well you get to a point where
the number of services is in a
one-to-one ratio with service owners to
services and inevitably things are just
chaotic on their own so
let's go back to chaos Carol you know
given this information you know how
should we start our chaos should we
randomly turn things off or should we
try to recreate issues that have already
happened so who thinks we should
randomly turn things off okay cool and
who thinks we should recreate things
that have already happened okay so is
it's roughly half in half so actually
what we're gonna start with is graceful
restarts and degradation
so recreating things that have already
happened is great when you're at a
certain point but since there wasn't a
steady-state it's it's not great to
start with that because you have no idea
what else you could be introducing to
things that are already failing so if
you're at a steady-state that's great
and you if you have a high level view of
your system to find that's great but if
you don't have those things I would
recommend starting with graceful
restarts and degradation start out small
and so back to letting people know
here's chaos Carol again like should she
let the chaos run on her owner or should
should she let people know so who thinks
letting the chaos run on its own okay
and who thinks letting people know is
more important okay so the letting
people know one out and that that is
very important and I will stress why
that's important later but you know in a
startup especially in a place that's not
used to chaos engineering and things
might be more chaotic already than
normal systems already are because it's
a start-up it's very very important to
at least people keep people in the know
so that brings me back to this guy you
let people know a little bit too much
there every 30 seconds I don't think
that's necessary so you know how do we
define our normal conditions for chaos
how do we define that we're ready since
there was very little information about
this you know the results were actually
very telling so how do you illustrate
something that's just a theory or
concept right like when we started chaos
engineering at gedcom you know it was
just a theory we had no idea if it would
work but it was you know it was an idea
like maybe we should have more primped
testing and experiments so I met with
different teams and you know I asked
them you know are you are you guys ready
to start chaos like do you know what
this means and I stride sending out
emails and like I was at a point in the
company where you know I hadn't been
working there for that long so I didn't
know the proper proper form of
communication jet wasn't heavy users of
email but I was sending out emails like
trying to let people know about this but
there were more heavy slack users so
it's very important to have a
communication place plan in place but I
wasn't getting a lot of responses on
whether I should start this chaos or not
so I assumed it was okay so I got to the
point where I said all right should I
send it should I press send and I
decided to in you know the results were
telling so while working on chaos
testing is a is a quick way to meet your
new colleagues it's not a great way so
you know I met all the people that I did
not know that week very quickly I you
know and well chaos and we're all
engineers didn't exactly welcome this at
first and in addition to their own call
rotations they eventually adapted but
how right so this brings me to my next
point of socialization which is so
important with with chaos engineering
and in doing internal tooling efforts
like socialization is a big piece you
know it actually tends to be harder than
implementation that came as a big
surprise to me you know as an engineer
you you know you're you're working on
this code and you're you're coming up
with this awesome solution and then you
know the social piece of it comes in
like how do you actually get people to
adopt it and build a culture around it
dissemination of information was
actually something that needed to go
through a lot of trial and error and I
suspect it does it a lot of companies
people and especially software engineers
like to be in the know and chaos
actually disputes both those points so
as chaos engineers and as people are
developed as people that are developing
journal tooling a lot of your job is not
just development but the socialization
and under
standing the customer and their needs at
jet and at many companies I've heard
from there's no mandate in place to
force someone to adopt a tool right so
you have to convince them that hey this
is a good tool to use hey this will
actually help the systems and the
business succeed better so it was
important for me to be able to
empathetically explain why it was in
people's best interests be chaos part of
this was relating tasks to automate a
test to SLA s and ultimately to the
customer experience so culture and chaos
just when we were starting to get some
cultural acceptance around chaos or so I
thought someone came up to me and
actually asked me to turn off chaos
during a big deployment and I sort of
facepalm Dal ittle bit because I was
like no I thought we were doing so well
you know and two things are important to
understand there one they probably
shouldn't have had to ask me right they
shouldn't have had to ask to turn it off
they should have been able to on their
own and to as the chaos engineer I
probably wasn't a value evangelizing
this correctly you know this person was
seeing chaos as a blocker and a
hindrance to their deployment process
rather than an essential part of it and
that's what I needed to evangelize
better that's what I needed to help them
understand that chaos doesn't cause
problems is that it actually reveals
them so how do you form this culture
around chaos engineering a culture where
failure is embraced because it is
inevitable so like I mentioned it
doesn't cause problems it reveals them
so let's go back to chaos Carol you know
I mentioned before that there's an
opt-in model versus an opt-out model
right like if you list all your services
and you tell s teams you know what can
be K what can not be chaos from this you
may have you know stronger results than
doing an opt-out model but this is a
cultural question too right
so if chaos has been around for a little
while and people are familiar with it
and accepting of it you may be able to
go to an opt-out model at some point but
at first it should really be opt-in
people should kind of have control like
you know they should they should
be able to prepare their services
especially if it's new so how do you
sell to your customers when they also
happen to be your co-workers as Kaos
engineers in internal tools engineers we
also have to be good salespeople whether
we like it or not and what does it mean
to be a good salesperson it means having
a good product and knowing your
customers so this brings me to some
internal tools selling 101 that I've
sort of learned along the way focus more
on asking the questions rather than
answering them this is especially
important at first because it's not all
about the information you carry it's
about understanding the worries in
thoughts about the manner and adjusting
your tooling and execution appropriately
and find customers that are willing to
try at first you know most of the time
chaos engineering is just a theory when
you're starting out with it and there's
going to be people that are resistant to
that right but after you develop this
tool it's so easy to to want to ask
everyone to do it at once and to get to
try to get everyone to adopt it at once
but that's not the the right strategy
because there's going to be people that
push back on it but they're also going
to be people that find it very cool find
those people find those teams that find
it very cool and work with them work
with them like very closely get their
experiences and use those experiences to
get other teams to adopt it too and be
honest again chaos is just a theory when
you're first starting out so don't make
false promises about what it can do and
if all else fails with adoption just cry
wololo are there any age of empire fans
here ok cool so I'm just gonna keep
making video game references Lola is
actually the battle cry that's used in
this game in order to convert enemies
over to like your side or your way of
thinking so they would use this
character and he would actually say this
and all the enemies would convert to his
way of thinking so you know if all else
fails with cass adoption you can just
say that sure it'll sure it'll work
so let's go to monitoring monitoring is
real
really important with chaos engineering
to usual useful graphical displays or
dashboards that are easily understood by
any developer in the company that
actively reflect the health of the
services and alert on key metrics that
are effective and actionable they're
very important a chaos tool that we use
at Netflix called chap focuses on what
we call minimizing blast radius which
means focusing on our key business
metric and if there's too much impact
detected actually shutting down the
experiment early shorting it early so we
we make sure that we're watching our key
business metric and if they get to if
the experiment and control cluster get
too far away from each other then we
shut down the experiment automatically
so monitoring with monitoring it's
important to leverage the tools you have
don't try to remake monitoring tools you
know work with what the developers are
comfortable with you want to introduce
the least amount of new things to them
as possible when you're trying to get
them to adopt chaos testing so at jet
comm we were heavy users of Splunk so I
leveraged that to monitor the chaos test
you know that jet because people were
already checking it and Netflix we use
an internal tool called Atlas mr. Jack's
really open also open sourced and we do
our chaos monitoring through that but if
you don't monitor and measure the chaos
how can you improve and how do you
actually know what's working and then
also look at your incidence or JIRA
tickets recently have they been
improving from when you started the
chaos versus you know maybe a few months
before a few weeks before at Netflix a
colleague of mine Lauren Hochstein is
actually working to empirically track
our JIRA tickets and do analysis on
whether or not they could have been
caught if chaos testing was in place for
those services if you don't have the
means to do that yet I strongly
recommend at least looking at your your
incident reports or your pager Duty
alerts and you know trying to piece
together whether or not it could have
been caught with chaos testing also
monitoring is not just systemic or
technically related it's you have to
monitor the culture around chaos to has
the idea of it
proved are you tracking adoption rates
successes those are very very important
things to monitor as well and most
importantly don't lose sight of your
customer company's customers remember
remember that the most important
customer is your actual business don't
lose sight of why you're doing the chaos
experiments you different companies may
be doing it for different reasons and
you should keep an watchful eye on your
most important business metric for
example you know at Netflix a key
business metric might be not being able
to stream a video what could go wrong if
you're not able to stream a video
successfully or at an e-commerce company
like a gedcom you know a key business
metric might be not being able to Add to
Cart so or a security company like I
previously worked at a key metric might
be not being able to arm your system so
those have all very different extreme
results to them right and you need to
strongly consider your customer impact
when approaching your chaos testing and
focus on like what your business goals
are and you know maybe what the worst
thing that can happen is you don't want
to cause too much customer pain and you
want to be able to measure that customer
pain appropriately so let's go back to
Kaos Carol so she also has to decide
whether or not to start in QA or
production if your start if you're doing
this at a startup or if you're just
bringing this to any company in general
I would totally recommend starting in QA
I know it doesn't monitor production
appropriately most of the time if it
does let me know who you are I want to I
want to hear more about that but I think
it's very important to start in QA to at
least establish a baseline to at least
get a sense of what's going on when
you're running these chaos experiments
and then maybe move to production later
so this brings me to face - can we cause
a cascading failure so other than
socialization efforts a jet that we
obviously needed to go through chaos
testing was going pretty well and we
started to get excited I thought if we
know what a high level what is talking
to
each other at this point can we maybe
predict when a cascading failure is
going to happen so cascading failures
are when a small foot in one component
triggers a Fault in another component
which in turn triggers further faults
cascading failures often lay dormant for
a long time until they are trickled
triggered by an unusual set of
circumstances the bugs that cause these
kinds of software fault often they often
lay dormant and there in these
circumstances it's revealed that the
software is making some kind of
assumption about its environment and
while that assumption is usually true it
eventually stops being true for some
reason so what we did at Jet was we you
know we got a bunch of downstream
services together and we had an idea of
what cascading failure we're gonna cause
and we all sat in a war room because you
know it was something that we had never
done before and even though it was QA we
wanted to prep like it was for
production as well so we did in fact
cause a cascading failure but we didn't
cause the one that we anticipated no
surprise there if you work in ops right
so all of a sudden search wasn't
resulting in data anymore and pricing
started seeing timeouts and then search
wasn't handling the pricing timeouts and
then we realized that elasticsearch was
completely down in QA so we actually
ended up causing QA to go down for an
entire week because of this experiment
yep so that caused a lot of problems
obviously and though chaos engineering
is being accepted well before that after
this it didn't have a great reputation
right so you know it caused a lot of
problems in regards to fixing tech debt
and QA and pushing back on features I
needed I knew I needed to start
evangelize evangelizing this a little
bit smarter you know I needed my
customers to understand that no I didn't
bring QA down for the entire week that
the tool did and it probably would have
happened on its own anyway and it might
have happened in production you know
these these unusual circumstances could
have revealed themselves at any point
and the chaos is actually helping us
build confidence in these that these
faults will be handled correctly when
they do occur naturally so let's go to
phase three building a failure injection
library so at Netflix we use this tool
called fit failure injection testing it
was built by a Colden Andris originally
who now works at gremlin Inc so we could
take this chaos in a different form like
actually injecting it on a code level
actually injecting these failures so I'm
gonna take you through some code I wrote
and it's purely to demonstrate that
anybody can start small with this and
anyone can start adding this to their
company I'm not going to go through all
of it but if you're interested in
looking at more of it later I have my
github up here too and I'll send that
out later as well so let's start with
our with our main chaos function so this
whole this whole library supports the
ability to inject a Delayer error
there's a simple API for the library and
there are tests with demonstrated shoes
I chose to write this in F sharp to show
that you could kind of write this in any
language I also love F sharp and I think
it's very expressive when doing
presentations as well so the chaos
module that I'm showing on the screen
here defines our main chaos injection we
have name as one parameter so this is
the name of the type of chaos that we're
injecting this parameter is very helpful
for logging purposes if we want to
remain truly random and chaotic in our
approach and not have the user pick
which type of chaos they're doing it's
important to at least have logging in
place to allow them to know afterwards
hey this was this particular type of
chaos so let's go to the next parameter
should chaos this is a simple boolean as
a parameter that tells our function
whether or not our predefined criteria
has been met and I'll get into the
predefined criteria a little bit more
later so it's just a flag true or false
like are we allowed to chaos right now
and if it's true it'll go ahead if it's
false it kind of serves as a safety
mechanism and then chaos are our final
chaos function so an F sharp you can
actually include functions as parameters
in other functions so this includes the
chaos function that we're injecting into
our normal function
and then I'm a little f-sharp specific
stuff the async arrow function created
here actually serves as a function which
produces an asynchronous computation as
an output and the use of the bang here
is interesting while in most languages
it means not in F sharp it actually
serves a unique purpose of asynchronous
workflows so it allows us to execute our
chaos parameter function and enable
execution or computations on other
threads as well as the chaos is being
performed so let's talk about our types
of chaos failures we have two common
failures in any system as as I'm sure
you guys can agree to and one of them is
failing with exception you know systems
fail because a random exception occurred
that we didn't handle correctly or you
know something got latent you know
sending messages between each other
there was some sort of latency
introduced so I think those are the two
most common failures that that we see in
systems and those are the types that
we're going to be injecting here it's
very simple purely illustrative so this
this is our actual criteria that we're
defining that I'm relating to the should
cast that I showed earlier so this
specific criteria is used to illustrate
randomly randomness with failure
injection and provide an example for how
criteria can be defined in the library
so this specific criteria will not
inject a failure unless the millisecond
at the given time is zero so something
that you could do here is maybe you only
want your chaos to run between nine and
five when developers are actually in the
office and not cause more cellphones to
go off more pager duty alerts so you
could actually define your criterias
only run between nine and five there are
a few other things that you could do as
well so after defining what went into
the library the API listed reads pretty
simply
so a serves as your healthy or normal
function and it gets piped and that's
the pipe symbol there or injected with
the Kaos functions listed given that the
function meets the minimum requirements
to be injected so let's go to Kate
for which is our chaos automation
platform or chap so this was something
that was developed at Netflix and is
something that we're actively developing
and getting people to adopt now it was
designed to overcome the problems that
fit had the failure injection testing
that we went over earlier it's focused
on minimizing blast radius looking at
those key business metrics and making
sure that we're not causing too much
pain to the customer it concentrates on
failures to dedicated incidents and it
isolates the statistics of the
experimental group and concentrates
failures onto these dedicated instances
it also takes fit and then adds more art
orchestration segmentation automation
and safety to it so here's an example of
how it works
it essentially routes a certain
percentage of traffic and splits that
traffic in half it routes some of it to
an experiment cluster and some of it to
a control cluster in the experiment
cluster is actually where we we fail or
add latency and so we can watch the
experiment in control cluster and see
how out of whack they're getting with
each other if they get too far away from
each other we will short the experiment
automatically so we deploy new clusters
we use custom routing for people in the
fit experiment as well as a similarly
sized population when the experiment
cluster a hundred percent of requests to
personalization here are impacted so you
saturate your thread pools trip your
circuit breakers etc and we call this a
concentrate experiment contrasted to
diffuse the experiments that that fit
does so let's go back to to Kaos Carol
again when we're rolling out this new
tool you know we want we want our
customers or the internal service teams
to be able to roll out their new changes
with chaos enabled right we we don't
want them to run these one-off
experiments right our our goal here is
to actually have chaos run all the time
right not just on the points not just
once a week not just when you're sitting
with the chaos engineers but actually
having it run all the time
so that's that's a that's a big goal
we've had at Netflix right now to get
all the cheer one and critical services
to be running chap all the time and we
actually got all of them to to include
it on their deployment pipelines
recently so that was a big step but we
want to go further so let's go to phase
five targeted chaos so going back to my
experiences at jet comm again chaos
engineering was going pretty well so we
wanted to focus on targeted chaos like I
mentioned earlier we we have a lot of
problems that we tend to blame on our
third party services jet was just
starting to do geo replication and we
were strongly relying on Kafka to do
that so we are strongly relying on Kafka
to do this and we're having a lot of
problems with it so we we all sat down
together and we said should we start
chaos testing Kafka should we just
target it and see if we can chaos test
it to help with our geo replication
efforts so let's start off with defining
some of the problems we were having with
Kafka we're having a lot of problems
with monitoring there there wasn't good
enough monitoring at the time and being
a start-up we didn't have a full-fledged
time series database yet and it was
really hard to monitor what was going on
with Kafka without one we had a few key
metrics that were broker specific also
with these geo replication efforts
dealing with offsets with it was
incredibly hard we were relying
completely on Kafka for geo replication
and the offsets were getting out of
whack and we weren't sure what was
causing that the offsets to be incorrect
we're also relying on a few key topics
that so many consumers were listening to
and like I mentioned Jett had almost 900
micro services so you just had random
services being spun up all the time that
we're listening to these state same key
topics which led to a huge load on the
system very high consumer read levels so
we started coming up with some some
targeted Kafka ideas right we hadn't
done a specific targeted chaos before
what what could we do what kind of chaos
could we cause we could cause
topic deletion partial topic deletion we
could for skill services we could start
feeding these bad offsets like that like
we are seeing in practice we could place
some high load on the topics you know we
could place tens of consumers on the
most popular topics and see see what
would happen there so we decided to
start very small as we had decided with
our chaos experiments earlier we did a
partial topic deletion and we started
adding a few load on rain a little bit
of load on random topics so shots were
fired right this brings me to a point
that it's very important to have a good
steady state defined with targeted chaos
before you begin we did not at this
point you know like I mentioned Kafka
was causing a lot of problems already
and then we added more problems to the
mix so it was hard to differentiate
between what was chaos and what was
actually happening already so we had to
wait again until Kafka got to a normal
state and then start introducing the
targeted chaos again it's also very very
important when when doing chaos to
record your success stories stories this
is especially important during adoption
phases and when you're getting to
different levels of adoption and
different levels of chaos your just
going to want to record your success
stories with every level at Netflix the
chaos team is actively introducing a new
tool like I mentioned called chap which
means convincing micro services teams to
adopt an unknown all over again we're in
regular communication with these teams
over issues they might have with the
tool and ways the tool has helped them
and in ways that we might not be able to
empirically record what right away so we
started recording testimonials this
customer says we ran a chaos experiment
which verifies that our fallback path
works which is critical for our
availability and it successfully caught
an issue in the fallback path and it was
resolved before it resulted in
availability incident and the
exclamation point was actually included
in this message to us like they were
excited they were so pumped to let us
know that like you know they were part
of this journey with us and they were
helping this tool succeed in helping
Netflix become more available
here's another customer testimonial
while we were failing
walls we discovered an increase in
license requests for the experiment
cluster even though fall backs were
successful which was crazy you know that
this part wouldn't have been revealed
unless they were running a Kaos
experiment and this likely means that
whoever was consuming the fallback was
retrying the call causing a retry storm
and causing an increase in these license
requests so this brings me to my next
point of engagement guys when you're
getting people to adopt and you're
trying to culturally introduce chaos
don't just come in right away and and
like start trying to get people to do
things come up with an engagement guide
part of this engagement guide means
knowing your company's culture knowing
what works well and what doesn't
can you and your company's culture force
people to adopt a tool or do you
actually have to convince them to use
that write that down write down what
your strategy is gonna be what
information do they need to know to
succeed and understand you should also
define what constitutes is fully adopted
what does it mean for for a team to be
successfully running chaos does it mean
lessening the calls at 2:00 in the
morning does it mean being careful
before releases does it mean being able
to track dollars saved improving
customer happiness decide what your goal
with chaos testing is and measure that
and record that and and also decide like
should you develop experiments for these
service teams themselves or let them do
it on their own
so with chap you know this was something
that that we had to think about a lot at
first it was a new tool and we obviously
built it so that customers could do this
on their own we do have to introduce it
to them you know it's not scalable to
sit with them on every experiment and
decide how to get them to run but we
need to make the tool we need to have
the tool be done well enough to be able
to explain to them how to make these
experiments and how to know what to test
for so it's important for them to
eventually be able to do it on their own
but at first when you're introducing
them to the tool you know maybe showing
them some examples would be very helpful
so if I can leave you with any takeaways
from this talk
that pervasive cultural patterns really
play out in advocating for chaos there's
going to be adventure choices that you
need to make along the way when choosing
your chaos and I just strongly urge you
to think about these decisions before
you make them because there could be
real customer impact here and definitely
measure your metrics for business and
cultural success make sure that you're
actually improving and then if you're
not pivot your tools appropriately
that's it thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>