<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Using Node.js to Build Great Streaming Services | Coder Coacher - Coaching Coders</title><meta content="Using Node.js to Build Great Streaming Services - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Using Node.js to Build Great Streaming Services</b></h2><h5 class="post__date">2012-11-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/dcsVyRVvpAw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">um can I tell you a story you know do
you guys like stories yes everybody
loves a story so I'm not quite James
Halliday I don't draw quite as well as
James but I want to tell you about this
a crazy awesome invention I made called
the amazing dude ed and invented this
thing and it's so awesome that everybody
in the whole world should buy one so you
know of course what did I do I set up a
doodad factory that makes doodads and in
order to power my factory you know I
need stuff to make it work you know and
I have this great model it's kind of in
the future right so I can you know I can
do it like cars I can do sort of an on
demand model where you sort by doodad
and then we send you on do you guys see
the recent South Park episode about
about Amazon well it's just like I
bought this stuff from Amazon and like I
don't even remember what I got and
that's basically my house where we get a
delivery late everyday and then it's
like guess what somebody ordered from
Amazon and nobody actually remembers and
I know that everybody that has prime
notes exactly that feeling so we're in
the future we can just kind of you know
you order a doodad and then we deliver
it to you immediately so it's just going
to on-demand model and that looks a
little bit like this so so everybody
seen a node server right before yeah
pretty much right this is the sort of
the classic node server except I added a
thing in the middle that said VAR doodad
equals new doodad and that's about it
so you know a basic idea of somebody
request something and we create the
thing that they want or we get the thing
that they want and we send it now
obviously like this this would be fine
if my web server could actually deliver
everything that my client wanted right
I want this API request here you go this
would be great except for the fact that
how likely is it really that my web
server can actually have all the
information on it to create a doodad to
give to my client very unlikely right
presumably you know you're sort of
application is a bit is a bit more
Plex in that there's a bit more kind of
interaction going on so like this is
this kind of request responsible is fine
up to a point but really it's it's
unrealistic so if I really want to make
doodads the thing that I need to do is
actually need a bunch of sort of
subsidiary factories and judging by the
latest Apple news they should be full of
14-year olds right whatever every you
know if you buy anything from China I'm
sure it's made by fourteen year old
sadly economics sucks
so you know I need screens and I need
antennas and any knobs and buttons and
different things and I've got all of
these kind of subservient factories that
are going to deliver that stuff to me so
that's great like now I have a situation
where you know I've got all of these
kind of factories and they're going to
give me stuff so the obvious analogy is
like these are my web services right in
order to construct a page I'm going to
pull together a bunch of stuff this is
service oriented architecture so here
are my different factories and they're
going to give stuff to my doodad factory
so you know we've got some trucks the
trucks represent the network right so
they go from factory to factory
delivering the stuff I'm gonna get these
boxes of parts so here are my boxes are
parts now realistically I'm not going to
get one part of time instead it's going
to be something like you know here's a
big bunch of parts like the factory
makes a bunch of parts and it delivers
them all at once and this is you know
this is the kind of classic experience
that we get when we do stuff so you know
I really need a part in order to make
one doodad but what I'm actually going
to get is like a bunch of parts and I'm
going to get three massive piles of
parts for each representing each factory
and in node it was kind of hard to
figure out how to represent this and
they finally thought what I'm just going
to use the the file system commands
because it's actually the only place in
node whether it is any kind of
synchronous i/o is actually file system
to help people write command line
scripts this is much easier to write if
I pick some other language but you know
in node it would look something like
this I get requests and then
I read you know a file from the two
different servers and they bring the
parts and they deliver them and read
file sync gives me like whole like
here's like a massive just like funk
here's a delivery of parts right here's
all of it in one go and this is you know
classically how we build stuff like I
make a request to some web service over
here and then it's like here's all your
information in one go so right and it
really makes sense because in a in the
classic languages this sense of
streaming doesn't exist so we always do
everything by assignment right
who writes callbacks in Python or PHP I
don't see any hands right like that guy
I guess if you use an event-driven
server so if you use like tornado or
write something else right then you're
going to get or twister you're going to
get callbacks but in the classic model
we just do these assignments so like
vast screen equals go and get my
resource via dial equals go and get my
resource and if you've ever tried to do
like multi curl and PHP it's God's own
hell it's awful
so like this is the kind of situation
where we're in where basically we're
dumping these massive stacks of data
into our into our processes and this is
threaded programming so this is
basically like when somebody connects to
your web server without using an
event-driven
server you're basically saying I need to
have enough warehouse space to house all
of the data that I fetch right so if you
want to go and fetch a million rows from
a database you need to have a thread
that's big enough to accept a million
rows right and that's that's actually
why if you look at things like you know
the MySQL driver in PHP they do like
pulling and the reason they do pulling
is because you don't want to have a
thread that's big enough to accept a
million rows and I've seen this with
clients with my clients where people
build stuff and they'll put the admin
interface on the same server as the as
the live production site and then it
turns out that people there are admins
can do these great big database queries
so somebody then goes and jacks the the
thread memory to be really massive so
that the admin people
don't crash the server but it means that
everybody else is like wasting memory
because they get like a massive
warehouse to cope with the admin
requests while everybody else just needs
like a couple of boxes so how can we
improve this kind of factory scenario so
really I only know only need like one
part in order to do this so I could do
something like this I could use FedEx um
and I kind of like this analogy of kind
of sticking like something like FedEx in
the middle because this actually I'm
going to talk about it in a minute or a
little bit about back pressure but FedEx
is kind of an important concept in this
because it's a lot like it's a lot like
the network it's a shared commodity
resource and if you use a network if
you're in a data center right there's
other people using the network you don't
know what they're doing you don't know
somebody just want it to burst like a
gig of traffic you have no idea so the
logistics is always going to be going
back and forth but really what we what
we need is we just need a couple of
boxes in order to sort of do our
function so that starts to look
something like this where we've created
a server and then we send off these
requests and we say what I'm going to do
is I'm going to spool up the data so I'm
now going to do this asynchronously I'm
going to go to factory one and get
screen and go to factory two and get my
dials and I'm going to spool up the data
so this is where we start to stream um
and if I can get a pointer apparently I
can't get a pointer so you can see that
I've got a part count and then at you
this this code has got a bug on it
hooray you can see that I've got counter
for parts which I forgot to iterate
silly me and I've got two different
callbacks so I go and get the factory
one I get the screen factory two I get
the dial now we've got these two
callbacks for data and end and basically
what we're saying is every time factory
one gives me some data for a screen I'm
going to add that to my screen so I'm
now buffering up like
of my screen data and then at some point
I'm going to call that right I'm going
to call that and say finish and finish
is going to check to see if I've got all
my parts if it doesn't have all my parts
then it's not going to do anything if it
does have all my parts then it's going
to finish the request as we did in the
first example I actually forgot can edit
the slide while we're all looking at it
I actually forgot to iterate the part
camp so it would be something like this
sorry I could iterate inside finish that
is completely true so this is that I
mean like this is kind of basically how
we're managing this this process of
we've got these two asynchronous things
at some point we need to synchronize
that we have enough information that we
can build the doodad and do it now this
is kind of ok right like now we're doing
asynchronously we're not blocking which
is good this is kind of notice but we're
still not really properly using
streaming does anybody see the real
problem with this does anybody does
anybody have like it like what is the
real thing that's not working here them
that's making this not streaming not you
Dave anybody right so I'm buffering
everything i'm concatenating everything
why am i doing that what's the what's
the problem here because I need to part
but that's ok I mean I'm going to need
two parts whatever what's the thing that
requires the two parts before it runs
right doodad to create this new object
the object creation doesn't stream the
object creation that I'm doing here in
order to make a new doodad I need to
complete parts so the object creation
here isn't streaming so the limit of the
streaming that we can do with this is
we're making this slightly more
efficient than if it was threaded right
if it was threaded we would have to pay
all of the cost of all of this memory
upfront and because we don't do that we
can sort of interlock you can imagine
like the curve of memory is going to go
up for this right so it's going to be
it's going to be like a growing curve
you can imagine the server can interlock
a bunch of those together and be
slightly more efficient and if we had
threads but because the creation of a
doodad widget requires completed parts
this isn't properly streaming and this
is a really important concept because at
some point we can do some streaming but
we often encounter bottlenecks
so before I start to talk about that in
more depth I'm going to cover the basics
of the stream API so the stream API
looks something like this we've got
readable streams and writable streams
and they kind of correspond together so
one side of readable corresponds to the
other side of writable so when we get a
data event the data event corresponds to
a write so a readable stream will say
hey I have data and you can see that in
the example where the there is screw
that up as well know the response the
response on data gives me data right and
that then corresponds to a write so we
can take the data event and that pairs
with the write when we get an end event
we have an end call on the writable
streams we also have a pause unreadable
we can say like hey don't sell me any
more stuff and then a resume
obviously those two go together
pause/resume imported him and then we
have destroy methods on both we also
have the special method pipe and we also
have destroy soon the drain event
corresponds with pause but the drain
event is kind of deprecated and I'll
talk about that so the pipe method the
pipe method is kind of clever you've
seen that in this example I'm using data
and and explicitly now because we can
see that data pairs with right and end
as an event pairs with end as a function
call the pipe method allows us to join
those two things together so we can
easily start to join these streams
together and say this stream goes to
this stream goes to this gym goes to
this dream and that gives us a bunch of
kind of interesting stuff so streams are
really easy to implement one of the
things you'll see is is in a lot of the
examples I'm using parts of node the
streams itself is just it's a it's an
API you can just implement it so I can
Inc I can include stream I can create a
new stream which is a vent emitter and
note so notice that this is like crop
codes class like syntax capital S or
classes and if I create a new stream and
this I'm doing terribly today stream dot
stream they suck you can all boo me at
the end so we get our stream we create a
new stream if we set it to readable we
can now do readable things with it so
we've got these two api's by setting the
property readable writable we define
what kind of a stream it is and then in
order to send data we use the event
emitter so we emit data on the stream
here's my data emit my data emit my data
and then to end it we just emit an end
event correspondingly if we want to
create a write stream we create a new
stream we set writable to true in this
case I am adding a data property on top
of the stream I created and then s dot s
dot right we have to implement the
function so when we're creating writable
streams we have to implement the
functions in the API so in this case
right I'm just
appending to data and I simply log all
the data when it's finished and then for
destroy I say this is no longer a
writable stream and because it's not a
writable stream it's going to stop
getting used I'm going to get stops
getting used it's going to get garbage
collected right so all of this is good
so far
we've seen like one kind of hiccup where
we've got a an issue where if we don't
have a fully streaming server we get
some benefit but not all the benefit we
also have an another issue and this is
actually this is a problem with node and
this is something that we going to start
to address but if we think of our you
know example we've got a doodad Factory
and it's getting a bunch of deliveries
from from the parts supplier and and
that's because the way that the the node
API works currently is we have these
data events and who controls the data
events well it turns out the readable
stream controls the data events because
the readable stream is like hey I've got
data that event data event data event so
all of these trucks are like our data
events and they took you know it's
basically you know we've got this
Factory and it's just kind of barfing
Daedra at us as and when it feels like
it's like yeah we have a contract I'm
just going to send you some parts like
when I have them you know that kind of
thing um well it turns out that like
maybe I run out of you know or maybe you
have too many parts right I've got too
many parts and what do I do now this is
this is actually like a really common
problem and this is you know the idea of
kind of if we're if this is all FedEx
right if this is all FedEx and FedEx are
running these trucks well that's great
it's like my shared resource
I now have too many parts so I call the
factory and they say stop sending me
parts it turns out they've already
mailed the parts I don't want any more
parts like my warehouse is literally
full and some dude from FedEx is going
to turn up with like more boxes of stuff
what do I do and this is a common
problem so actually when we get under
the hood it turns out that in order
to do streams particularly Network
streams there's a whole bunch of places
where we have a little warehouses FedEx
has a little warehouse right the network
itself has a little warehouse there are
warehouses in reuters along the way
right all of FedEx is internal
infrastructure right there are you know
there's a warehouse in the kernel right
so like maybe I've got a loading dock
and if the loading dock is full even if
my warehouse is empty
my loading dock is full right so there
are all these different places along the
lines where we have these buffers and we
need some way to be like hey buddy just
stop sending me stuff I'm you know in
full and right now we have this problem
where stuff can be in flight and we have
no way to cancel it so this is actually
a real problem and you know to sort of
put this into like more of a concrete
implementation so one of the things that
people don't if I have a slide on that
maybe not one of the things that people
often don't understand about how node
works is the event model is actually run
by Libba V right so on the right hand
side we've got this is this is what
notice note is no dot C C if you go and
download the node source code you're
going to get no dot C C is like the
foundation of everything it is the the C
file that loads in all of the stuff and
then it you know it loads in once all of
the stuff is loaded it then runs the
node JS file which lives in the same
source directory and then at some point
it then goes and loads all that other
stuff right but no dot C C is a sort of
root of it all and it brings in v8 it
brings in all the different add-ons it
grabs libuv and it uses libuv to start
an event loop and libuv is our
abstraction between a library called
Libby V which does event loops and it
has done on UNIX rages and iocp which is
Windows right so this is our event loop
and there's a bunch of different ways of
doing events a node and a lot of people
don't really understand like what they
what the different things do so actually
I don't think I have a slide on this so
I'm just going to I'm going to grab a
terminal and just type instead
can people see that okay yeah let's grab
the iqc is awesome snicker I heard that
all right so we've got a bunch of
different ways of doing events so for
example if I have something if you do
something like server OOP serve it on
request
you know dah dah dah dah dah
what's powering that or what's powering
that is a vent emitter so the first
thing that we have is server dot emit so
that's the first kind of thing that we
can do we've also got process next stick
and then we've also got set timeout and
set interval so one of the things I
think people often don't understand is
how actually all of these things work
this is really important this is
JavaScript this is one of the most
important things possibly to understand
while doing node events if you call them
it it is JavaScript right here is a very
simple a very simple explanation of how
event emitter works right if I've got
event emitted or on equals function and
then I've got a function I pass through
it or an event name and then a function
right it simply goes e dot events event
I should call that event e event and
then we're going to push to that the
finner right and then either emit equals
function this is like really super
simplified but event data this is
basically how a vente Metalworks is e
dot event
event now for I equals 0 is less than
that dot length I bucks plus I write
JavaScript like it's 1995 yo I'm old and
I can't learn new things that a and then
something like that
I know so something approximately like
this where basically whenever you
whenever you call them it it basically
just goes I have a I have a list of all
of the functions attached to this event
I'm just going to call them one by one
there you go so this is really important
is when you call them it when am it gets
called by anything it's actually
JavaScript and it basically just cause
as much JavaScript until it runs out and
then it's done process that next tick is
actually a special queue it's basically
I'll show the diagram in a second but
process next ik is it's a special big
boy queue at the top of the regular
event loop and it's like I'm super
important and you should call me like
next and it's a it's it's basically it's
a FIFO queue and then these guys are
kind of interesting which is basically
if I do set timeout finner zero and then
set timeout for a value or you know time
and of the event loop and that one is
end of the event loop after time so
these guys do go on to the event loop
but basically if you say zero it just
throws on the end if you say time it
will throw on the end
after at least that time but not
necessarily on that time so it's not
guaranteed and then set intervals
you know ditto actually know if you can
call set in for with zero probably I
guess you could I haven't tried that
but this is this is really important so
if we go back to our diagram at the top
you've got the next tick but basically
we've got this situation where when we
get TCP connection what happens is it
goes oh we've got an event less on the
TCP connection and then that calls are
met and you basically just bubble a
ton of JavaScript up so like the TCP
connection goes oh I'm attached to a web
server that's like a request and goes up
and up and up and up so if we go back to
you know here are our trucks we end up
with this situation where at some point
I call streamed up pause and now holy
 I have all of these things that are
already on my event loop and I have
literally no way to remove them so we're
in this interesting situation with the
current stream API where because all of
that data is pushed from the read stream
to the write stream or whatever is
listening we don't have a good way to
deal with that and this is a real
problem so there's a few things that we
can kind of do to that to manage the
back pressure and this is you know this
is a really important topic because like
managing that you know defines how
efficient our server it's so we can use
pause and resume to control the back
pressure a bit we can we can use that in
order to define some things we can
manage the buffer size on our on our web
server so if you're using Linux or UNIX
or whatever you can say like I want
connections to have this much buffer or
this much this is particularly important
because if you start using socket
streams and like chaining together a
bunch of sockets every single one of
them is also going to have its own
buffer so kind of an interesting thing
and you basically the problem is with
the current implementation you have to
write data events that assume that you
may get an event after a pause anyway so
you have no way of controlling that so
that just kind of sucks the the sort of
concrete things there when the kernel
won't accept anymore writes each socket
has an internal buffer and basically
what you can do is when you write
writes going to give you a false to be
like hey stop writing at me but you can
also check the buffer size and be like
hey like
I have some maximum kind of like safe
buffer size that I want to you know not
not go over and it can pour stuff and
then also there's like a few of these
things like file system methods you can
see when I create a read stream on the
file system I can actually define from
the file system how much of a buffer I
want so I can say to the file system
like hey create this read stream from
the file system with a certain amount of
buffer that's not the kernel buffer
that's nodes internal buffer so like
some of these are tunable but there
aren't so many of them so instead we end
up with the new API Isaac this is still
a proposal but Isaac has readable
streams on his github you can go and
look at this
it basically improves a bunch of things
so writable streams are more or less the
same they haven't really changed but the
difference that we end up with is the
first one is we can start to configure
water lines so I can basically say if
you think about my sort of my factory
analogy I want like three or five parts
you know the minimum the minimum that I
need in order to start making doodads is
I need like three parts but don't send
me more than 50 because if you give me
more than 50 it's going to be
inefficient so we can basically set a
waterline we can say about high and low
marks we then get a readable event so
basically instead of a data event the
data events like blur data blur data the
readable event is like hey data is
available like you've reached your like
low-water mark to say that you now have
enough data to do something sensible I'm
now readable and I'm not going to take
any more than my high-water mark if I
get more than my high-water mark I'm
going to push back and say like don't
give me any more data and then we end up
with instead of having the the sort of
data callback where it's actually a
callback instead we end up with this
pulling method so read Len so this is
kind of like some of the other languages
the difference is the reason why it
still event-driven is this readable
event
so this readable event says hey now
you've hit your watermark you're safe to
read but I can then go and read length
of any length I want I can pass no
length and get all the data
that's available or it can pass a
specific length and get a specific
amount of data and if you've ever
written a parse are getting a specific
amount of data is incredibly helpful so
this makes a big difference now what
we're going to do is when this drops we
can put and you can use it right now
right you can go to readable stream and
use this right now but we're going to
put the old API back on top of this so
we're going to shim it so if you're used
to the old API you can still use the old
crappy broken API it's not that crappy
it's still pretty good but you can still
use the old API but if you're doing new
stuff you can do it this way there is a
couple of complications so if you're
using pipe one of the things that you
need to do is you make sure that
subscribers must implement a readable
stream because if they don't then you
end up where somebody calls read and
then they get the data so read is now a
direct function call you read you get
the data back so if you have pipe and
you have another person that's trying to
pull read on a particular socket then
you're now going to be in like a weird
situation so that's kind of janky so
yeah I mean like basically now the new
situation is we start to push out like
all of those big like caches back to the
web services and then say I won't need
to give me like a truckload of three
give me a truckload of three give me a
truckload of three so we're in a
slightly different situation where
instead of having to like try and you
know tell the other service to back off
at some point when we think we're full
instead now in a situation where we
basically say like this is my like
capacity and then read read read so the
next thing I wanted to talk about was
types of stream so the obvious one is
simplex this is something like this if I
you know and this is just basically like
a readable stream like a one directional
stream so if I read a stream you know
and I get some data and then log it out
it's just one directional could be a
write stream could be a read stream but
it's very simple the most common one
that people use and this is kind of like
proxying but it
this idea of a throughput stream so in
this case this is almost the same
example so in this one I'm calling
console dot log in this one instead of
calling console dot log I use pipe and
process dot standard out is now a
throughput stream so it gets it gets
data in and then it immediately ejects
it out of the program right so we now
have a throughput stream and this is
really common where for example I might
do an HTTP GET so I go off to some light
web service and I grab it and then we
bring it back and then I send it
directly to my client and if I mean you
know you can do this with like nginx or
something else if you don't have any any
other logic but you know even just
sticking like a node server that simply
fetches from a remote web service and
then delivers it to a mobile client you
will probably see an efficiency gain if
you're using something like rails
simply because know won't cost you a
penalty to deal with mobile latency
right so there's a bunch of these kind
of implementations where these simple
like throughput streams are super super
effective and there's actually no reason
we saw that we can create streams
earlier there's no reason why we can't
write throughput streams that also do
interesting things so when it's doing
the throughput there's no reason why it
has to like simply do nothing to the
stream there's no reason why you can't
start to modify the stream and we'll
talk about those examples on a sec and
then the final one is like a duplex
stream so this is the idea that you
basically connect two things together
and they're just going to talk back and
forth you know chata BOTS or some other
like two-way thing could really
implement this so this is there's like a
whole bunch of a whole bunch of stuff
here so a couple of libraries that I
want to call out before I talk about
applications and then maybe some
questions check my time
so the first one is Jason stream so if I
had some data like this and I just I
grabbed this off the wiki but it's a
really good example so like here are
some database rows you know we've got a
bunch of rows and you can imagine such
total rows 129 you know this has been
abridged but I've got lots and lots and
lots of rows Jason
is wicked fast but it turns out that
there's so much data that there's no way
that I'm going to get that in a single
request right so I go and get my
requests on my database whether it's
like couch or Mongo or whatever and they
bring it back and it's much more
efficient for me to be able to do
something while I'm streaming it so
Jason Jason stream is basically the idea
that by having a JSON parser that can
read off the wire each of these rows
atomically could be useful right so I
may still want to do something
atomically on this row in order to build
my doodad so if my and this is the this
is the difference before was like you
know in the first example we had this
doodad and it needed to be a complete
thing it needed to be like here my parts
I need to do stuff in order to create
effective streaming services what you
need to do is say what's the least
possible component that I can actually
start to act on and that way I can start
to do things so I can bring some data in
imagine you know a great way to kind of
reduce your footprint it's like if
you've got this massive user profile
full of information you bring it back
the only thing you need on this page is
the name so you grab the profile you get
the name you delete that object you say
I don't want this anymore and like boom
you've just freed up a bunch of memory
right and if that's very explicit but in
this model what we're trying to do is
we're trying to say you know what's the
minimum value that I can pull off the
wire such that I can then start to act
on my data and then forget about it
so Jason stream allows us to do this the
stream parser is definitely definitely
definitely it's not as fast as Jason got
parse Jason doc past is like implemented
in v8 the people at Google are
offensively smart and you know the stuff
that they've written natively is awesome
but it turns out that if I'm streaming
lots of rows from a database the blocker
is not how fast I can pass the blocker
is how fast can I get stuff over the
wife in the database and we've got a
similar thing not that I recommend this
I did I did a lot of work with node X
Pat so
expat is basically it's a sea library
that does XML parsing there's a couple
Isaac Isaac wrote node sacks I think and
it's it's basically XML parsing
extremely XML parsing it's like stabbing
yourself in the eyes with hot knives I
mean like think about how awful regular
XML parsing is or like even just like
working with a Dom not not super
fantastic imagine trying to like and and
you know XML obviously doesn't cost
adjacent properly like imagine trying to
pull XML off the wire and then implement
it but it turns out that I can on my
macbook air from I don't know year ago I
can saturate an entire core of a
processor like one one core is a hundred
percent CPU with 50 Meg's of RAM right
so these passes are so efficient like
you can you can basically you can use
all of your CPU and still only use like
50 Meg's of RAM so they're incredibly
memory efficient and depending on what
application you're building if I've got
a server and it's got loads of memory
and I'm you know I named not only am I
not having to wait for the whole object
to start acting on my stuff but I'm also
saving all this memory well it turns out
that all the rest of that memory can now
go to memcache or it can now go to like
some object cache which means that
instead of even like going to my
dependent resource I can now just you
know fie the thing straight out of cache
so all of this stuff is kind of it's
really it's really dependent on being
able to do that so how do we apply this
what I think you know there's a few main
patents
the first one is filtering I have some
data it's coming down off the wire and I
want to take it and I want to modify it
in some way before I send it on this is
fairly simple you still need like a
stream based parser like adjacent stream
or something like that but it's a fairly
simple application you then and this is
I mean like one of the things I want to
emphasize as well is you know we've seen
a bunch of different examples I didn't
even touch socket IO this API
this concept is completely transport
neutral right it's completely transport
neutral so you can you know you can do
this over file system you can do this
over soccer i/o and WebSockets you know
and if you socket IO you get a streaming
model and it turns out that actually
under the hood socket IO implements it
with WebSockets flash sockets long
polling like a bunch of different stuff
under the hood so you don't even see
that
so filtering is one huge case I would
say the the main thing that's really
important is when we're dealing with
stuff one of the common and I guess I
don't have a diagram for this one of the
common things that I see is people build
stuff where the actual end result of an
application is dependent on a bunch of
web services so I'm going to grab Chrome
have has everybody seen web page test
has anybody seen that nobody seen that I
know I've been talking you fina you're
like oh I forgot that I'm supposed to
like respond to stuff I crap what's the
internet password what html5 Devcon okay
that was so I guess obvious I know right
and and because I've got a Mac it's
gonna take me about 10 minutes to
connect if this doesn't connect in like
the next oh there we go all right um
somebody give me a URL anybody what New
York Times we're at the front of the
queue yes all right I'm gonna keep
talking - France so one of the things I
see really often is basically we build
these these pages that are like SOA
they're like an aggregate of a bunch of
stuff and then we basically we say my
first load time like my initial load
time to the user is dependent on all of
these other resources that I depend on
well that sucks
right and primarily it sucks because we
not only is it dependent on the
resources themselves it's dependent on
loading the whole resource
right I can't flush anything until I
load the whole resource this is yeah
obviously everybody uses your I used to
work for Yahoo so I like to make jokes
about them never miss a manner they
might actually do okay but if I do like
a yahoo search for I don't know cats or
something
notice the search bar just boom loads
right this is a good page experience and
I guess webpagetest is going to take a
long time the point is is that yahoo
flush that top bar before any of the
rest of their web services have called
right and as they start calling as they
state getting results they can now start
to flush content to the page and this is
the ideal situation turns out it's quite
hard building streaming services not per
to not super easy his New York Times you
can see like render that see content
download data editor where they download
loads of stuff so ok so basically this
green line is when it starts to render
and because they start loading within
sort of 200 milliseconds right that
gives them you know the difference
between 200 milliseconds and once it
start loading
oh it says the top like two seconds
right so it takes them about a second
and a half to render the page now
imagine if their first byte took a
second right because they're waiting and
all of these dependent resources before
they started loading stuff right then
you've got a page that takes three
seconds instead of two seconds and this
is the real benefit streaming service is
that I can start to say even though it
may take me like this amount of time to
do something I can start to shuffle all
these pieces together with the minimum
possible delay and get them out the door
alright thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>