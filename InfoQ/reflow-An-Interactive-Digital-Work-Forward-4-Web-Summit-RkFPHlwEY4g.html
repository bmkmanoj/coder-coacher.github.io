<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>&quot;re.flow:&quot; An Interactive Digital Work - Forward 4 Web Summit | Coder Coacher - Coaching Coders</title><meta content="&quot;re.flow:&quot; An Interactive Digital Work - Forward 4 Web Summit - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>&quot;re.flow:&quot; An Interactive Digital Work - Forward 4 Web Summit</b></h2><h5 class="post__date">2016-04-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/RkFPHlwEY4g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yeah Jason is doing awesome stuff I'm
he's like on the leading edge because V
are a lot of people talk about VR for
the you know like doing games and things
like that and jason is also interested
in exploring vr is a method for kind of
browsing data and the web and kind of a
something that's really revolutionary so
he made this all himself you put it all
together with other people who are kind
of he brought a good team together to do
the audio people to seeing it's very
original so kind of produced this entire
thing and Jason's going to talk to about
how he built it from scratch and dolby's
very happy to have Jason help us out so
thank you very much everybody give Jason
a warm welcome and push this over here
so I have a little bit of room okay so
let me get to my presentation I mean it
will all work great okay so I think so
by the way my company which I'm trying
to start is called flow and it's really
about virtual reality this was a
fabulous fabulous project which is not
specifically about virtual reality but
it uses a lot of the same kinds of
techniques you'd want to so what I'm
going to do is I'm going to talk through
actually show you the code and point to
my blog which has a pretty good pretty
deep analysis of the code that I did so
I'm going to talk to you about how to
produce audio for dolby digital plus so
a 5.1 surround that's pretty quick then
talk about the Web Audio context how do
you create audio that can be spatialized
just in your browser and show you the
code to code to do that pretty
straightforward stuff and then the WebGL
part of it so what I'm doing is I'm
doing a bunch of textures that are
dynamically taking the amplitude out of
each of these tracks and manipulating
the shader language to make them all
glow and ripple and do do the stuff that
they're doing so that's the combination
that's what I want to play out on these
for you guys so dolby digital plus as
tight i said is
new codec even if you're not using the
5.1 aspects of it it's about half the
size of mp3 files and sounds way better
so that's kind of cool right now it's
built into the Microsoft edge browser
and in the latest Safari this project
only works in edge at least only works
an edge for the full surround sound I'll
show also show you a little bit of code
to fall back to use mp3 files if the
surround sound codec isn't available and
so that's pretty straightforward and so
let's see oh technology is actually just
told you all that okay i'm using the Web
Audio API which is built into all the
major browsers 3gs on top of WebGL and
my we talked about dolby digital plus i
used glam for this project to help me
with some of the interactivity it's
something by Tony Parisi it's called
graphics libraries and markup so I it's
not going to be really much about this
talk and it was it's only kind of a
small part of the project but it just
made things a little bit quicker for me
one of the things that I think is kind
of interesting to to think about this
project is that I really didn't know
what I was doing when I started I have a
master's in music so I know how to
produce music but I had never done any
shader language before obviously I've
done some pretty sophisticated three j/s
stuff but otherwise I had to learn a
whole bunch of things and so where did I
learned of course from the web so one of
the things I've you know one of my
inspirations was a friend of mine isaac
cohen if you haven't checked this guy
out you should check it out it's amazing
amazing stuff and let me turn on my hot
spot and maybe I can actually get to it
and if this doesn't go very quickly then
I will bail but okay my internet
connection is too slow to do those demos
so we are going to just bail on that
process but shader toy is a great place
to learn and experiment with a WebGL
with shader language and then you can
grab that and plug it into WebGL really
straightforwardly and anything that I
can't get to in an obvious way here
you can go to my blog I've got four blog
entries that talk through exactly the
code that I used for each of the four
each of the things I'm going to talk
about and also where the like the shader
language came from so let me get back to
the actual let me get back to the
production here because this is what we
really want to do okay so let me talk
about just the something I did
differently in my sequencer than you
used to seeing in typical sequencers so
for my sequencer I had each bar each
vertical column be a for VAR phrase I go
back here each one of those is a four
bar phrase and each one of my sounds is
not a loop it's a predetermined length
and one of the things where I thought
that was important is if you give
somebody pretty much anybody a looping
kind of tool it's really easy with a
whole bunch of tracks it's really easy
to turn on a whole bunch of tracks all
at once and then it's just full blast
all the time and that's not very musical
so by doing it this way each one of
these phrases is actually going to stop
and require the user to go ahead and
start out of the phrase and that gives
you a little bit more musical space in
the project so essentially what I've
done here is I've taken 16 audio clips
each one is encoded with a 5.1 surround
sound one sentence it sir is encoded
with a 5.1 surround sound the Web Audio
context is going to mix those
simultaneously to eight tracks using
dolby digital plus codec it will then
Reese pace those 85.1 channels back into
a single 5.1 mix and if you're on
headphones it will use head related
transfer functions so you still hear it
spatially around you the whole time
unfortunately I can hear any of the
spatialization because of this
particular system today so you have to
go through the site and it was i'll give
you the URL go to the site and put in
some headphones and then you can
actually here here the spatialized part
of it and all that's done by the Web
Audio context in the browser and I
didn't have to do any plugins yeah
question more the especially the room
lights right because it's it's okay
video wise great yeah so any any quick
questions i'm on the basic fundamental
thing here with getting eight
simultaneous 5.1 mixed want to see how
to do it it's really it's a lot easier
in the code then you would then you
might think let's go back to so bopping
around with too many okay so i did hire
some real vocalists vocalists to do the
vocal tracks and they did some of the
parts i wrote and some of the parts they
improvised once I had the vocal parts I
just grabbed I used Ableton Live and I
grabbed a whole bunch of little clips I
just named them things that could keep
me straight on what they were and
simultaneously mixed them into phrases
so for example there's one it's called
vocal melody in a way that's a whole
little piece in its own there turns out
that there's four parts I took her voice
and i added a count of did around added
a counterpoint to it another vocalist
improvised the harmony to that and then
i actually added a midi track to to the
same thing so that it would avail
synthesize a track to give it a little
bit more fullness and give a little bit
more interest so each one of these
tracks each one of these clips is kind
of like a set of musical steps in itself
and then how do you specialize them so
in adobe audition sorry there's a lot of
pieces to this so I'm going to keep
bopping around between applications oops
and that's a pain to bop around in adobe
audition there's a track panner so you
start out saying hey I want to do a six
channel or if I put one channel audio
file and inside the does it have enough
internet to validate and if it doesn't
launch I'll just do this in that panner
you can actually drag your mix around
now one of the things that's a little
bit confusing for the to understand
here's what's what though be is doing is
it's taking an existing 5.1 mix andrey
spatial izing it based on whatever
Hardware you've got available it's not
doing a dynamic take this sound and put
it over there or take this down and put
it over there right so that is a little
bit of a limitation and I'm sure they're
working on that too especially for like
VR applications where you turn your head
right because if you're turning your
head you need the sound to stay
spatialized over there so that's not
what this what dolby digital plus is
doing instead I'm pre encoding the
surround sound into each file and then I
run it through the Web Audio API which
i'm going to show you quickly okay oh
just here's a an image of adobe edition
so here's the track panner and each in
this case like the pan angle i actually
created spline curves to map exactly
where these things are going to move
through space that was really helpful
later on when i wanted to wanted to map
tell the program to put each sound in
each space or to put each visual to
match whatever was in the audio file
it's a little weird I have the audio
file first that's spatial eyes and then
I created a visual that stays sync to
add to it animation as it spins around
and I'm just going to use my blog as
example code examples because that's
quicker than hunting through webstorm
okay so here's the first bit of bit of
code so the Web Audio API you get to
through window audio context and it's
not big enough for you guys to see
here's me well you can give it a little
goose it a little bit here there we go
and basically every modern browser has
the Web Audio context in it especially
browsers on all your phones and
everything I don't but I mean I guess if
you go far enough back in IE you'd have
an issue but so that's the first is
audio supported and then we're just
going to say hey can we play this codec
and is it can wait to let me let me
scroll over to get to the ec3 codec
that's the dolby digital plus codec and
if we can play it it's going to return
either a maybe or probably depending on
the browser i'm not sure why that is
when it actually says yes i can play it
anyhow and if it doesn't if it returns
an empty string then we know that it's
not supported if it's not so assuming
that it's supported then we can say hey
how many channels do you support at this
time and the max channel count is the
key little piece you have to tell it to
use six channels for 5.1 mix that one
line of code actually was a nightmare to
figure out but you all know what it is
now and so that will work and if you're
not using ec3 then i'm going to fall
back to using mp3 files and then i am
going to use the Web Audio API to put
the sounds in space real time so when I
actually do this for VR that's the
Icefall back to that because at least
it's going to put it there the Web Audio
API it's not brilliant I mean it's not
the best head related transfer functions
it's not as wonderfully spatialized as
it could be
but it certainly is going to pan it
pretty well and that's that's enough to
make it make it accomplish what you want
any questions on just how to get that
set up for a go on to who is new to the
I should say whose used a Web Audio API
very much okay so three or four so i'll
just show you a little bit more that
which is here i'm going to basically you
just create a buffer source this is the
buffer the buffer is the actual the data
for that audio clip and if you're going
to use the panner then you just create a
thing called a Panar great panner and
you hook it up connect it through a
chain and that's going to alter the
audio as it goes so how my time wise
because I want to play a little bit more
okay good so I actually created a little
class map for you so you can see what
the pieces are so we've got 16 audio
clips I've got eight audio tracks I'm
going to map those 16 clips to eight
simultaneous tracks I've got an audio
visualizer which is connected to the
audio track and that has a shader the
information about how to animate it and
tell it to you know play and start and
stop along with the sequencer which
tells the whole sequencer has a list of
measures each measure saying hey start
now stop now etc so and the shader we
will talk about the visuals next
now you just pull this back up again so
you can kind of see what we're when I'm
talking about 16 clips I didn't want any
sometimes I didn't want two of those
clips to be playing simultaneously I
didn't want two different bass tracks to
play simultaneously because it's just
turned into mud so actually you're
picking between them when you click on
one of them see it turned off the other
side so it's going to make those
mutually mutually exclusive the same is
true for some of the for some of the
rhythm tracks and actually all the
tracks ok back to the visuals Oh
sequencer if you want to know more
information about the sequencer you can
check out my blog and do we have enough
internet good ok so the animation was
actually one of the hardest parts of the
project mostly because I had to do a lot
of math and I'm not a math genius so I
mean I have a music degree right and
that was 30 years ago but one of the
things I did specifically so basically i
created a a an animation where I say hey
here's how long to make it which using a
series of keyframes and I actually put
my key frames as in terms of which beat
or actually that's which measure should
this visual be at what time so in this
case at bar number one I want it to be
at 56 degrees at bar number 2.75 I
wanted to be at 37 degrees and this
little the rest little animation tool
will map that around the reason why I
used these numbers instead of all the
other ways you could describe describe
points in space or animations is because
it's what adobe audition generated so
when I drag this thing to hear is that
oh it's minus 75 ok that's the numbers I
want to use because there's a lot of
data points for all the different tracks
like hundreds and I just wanted to type
whatever adobe audition told me was
those in without having to do math on
each time I assignment typed it so as a
good lazy programmer I wanted to make it
easy so it does a little bit of the math
to map it into the right spaces and an
audition was even you know zero degrees
in Web Audio is different than zero
degrees in addition right so I had to
just add the degrees around to make it
work okay textures so once I show you
these textures you'll recognize the
imagery a little bit so these are the
actual textures I or images I used for
my shaders I used that's a picture of
Lake Tahoe I took you can see some of
the others actually a sunset on the
water bring them into Photoshop and make
sure that they wrap so that the this so
you don't see any edges and when I show
you the project again you'll see how
they actually look so I'm just going to
turn it on again
now that I've told you that that's a
picture of some water you can see it but
you would not have thought of that
beforehand because of all the math I do
on top of that so and it actually is
pretty cool I am going to try to do this
get to my source shader toy again just
because if it works it is pretty cool oh
good okay so I hunted around shader toy
looking for things that I thought would
would be relevant to the project and I
came up with this and I found this thing
called ether and it was it just met all
the different requirements I wanted to
have I wanted something that's going to
glow there's something dynamic that's
based on time ok I guess it's not going
to be happy well I'll just leave it up
because you can see the code here and
just started to experiment with all the
variables i took all the variable names
and change them into things that i
thought would make sense instead of just
being random numbers and tried to figure
out the math I don't totally understand
the math but let's see if I can get back
no let's get back to my now I am asking
my computer to do an awful lot it's it's
a surface book it's not a big beefy
computer although it does run pretty
well by the way as long as we're here
the blog i'm showing you is that flow GL
/ blog
I want to walk through that shader
language and how to get it to work in
the browser and how are we timewise so
we live in 20 okay does anybody know how
long this was scheduled for 12 okay good
I don't want to do the wrong thing ok so
to do the textures before I show you the
shader language let's show you the three
j/s code so if you haven't seen three
Jas code before then yeah 3 j s is this
library which is seems to be the
standard at this point for doing WebGL
you can do WebGL directly you know
without using the library but there's so
many just takes so many lines of code to
accomplish actually very simple things
that pretty much everybody i know is
using 3 j s instead and that's there are
other other options out there but they
i'm going to promote three Jessica's it
works great so in this case what I'm
going to do is I'm going to create a
plane and I'm going to load this texture
which i already showed you and if i
could scroll that would be nice there we
go and I you tell it you're going to
give it two important little bits of
code that are actually going to be run
on your GL chip and that's your fragment
fragment shader and your vertex shader
your vertex shader is so shader language
is a simplified form of C and it's
designed to run very very fast in a
multiprocessor environment so on a big
gaming device you know better than I do
Brandon but a big gaming box is going to
have something like 2000s simultaneous
processes something like that on I think
on my computer is more like to 156 but
you still got this little super computer
that's running very very very fast very
simple code and figuring out what to do
with a whole bunch of points in space
simultaneously and a whole bunch of
colors and pixels in space
simultaneously and so you've got two
different language two different bits of
that like I say one of it is vertex
shader which is tell me how can I
manipulate the points in space and the
other is the fragment shader how can I
mean manipulate the color of those
points in space so that an
oversimplified definition Brandon Jones
is from google and he's like the god of
of the WebGL and and virtual reality at
Google so it's I'm embarrassed to be
staying in front of him instead of him
if he himself you're going to work so
we're going to create a plane we're
going to map these two little bits of
language of shader language so first
okay I don't even bother to show you on
my blog the vertex shader because it's
doing nothing i'm not doing anything
with moving points in space on the on
the jail chip but i'm doing a lot with
moving changing the colors so a bunch of
this code maybe this chunk here no at
least this trunk here was from shader
toy I went through and manipulated all
of the little bits and I added some the
main input which I wanted to add which
is I'm actually going to pull in the
amplitude of each track and have it
ripple my texture that I loaded so the
texture gets loaded here in in the UV vu
v's is the actual wait a minute yeah
base texture hold on
scrolling this thing is driving me crazy
um but anyway so you your gun onto the
chip you're going to load a texture and
then I'm going to do a bunch of math on
top of it and what it's going to spit
out what the time it's done is a color
eye color with an alpha and that's the
whole whole process and then you need to
make sure that you've got a an update
loop that's going to tell it to update
the amplitude coming out of the Web
Audio API for each of those tracks and
that's and then there's some picker
stuff which is where I used glam and I
didn't talk about that very much so
after all of that let me play it again
Sam so you can kind of see how it works
there's two interfaces to it there's the
sequencer interface and then you can
also click directly on the objects and
I'm sorry it's a little bit light in
here
imagine that's sleeping around you in 3d
audio space
you
so the next piece of this just because I
could was since I do virtual reality and
web VR I just took it and put it on on
my phone works fine on Android and iOS
and you can drop it into a like a
cardboard device actually drop it into
gear VR with good headphones and it's
particularly fun I've had a lot of
gotten a lot of good feedback
demonstrating it a number of art shows
and technology and art kinds of
combinations so that's the whole story
I'm totally open to questions or ideas
or whatever yes um so all of the code is
open source I trying to think if it's
not it's not really organizing a good
way on github but if you go to my blog
you can see all the all the important
bits about how to how to do you know
each of the pieces and you can of course
do view source that's it's all unknowing
except for one little one little piece
around the text engines which is a kind
of a different different project I'm
working on it I couldn't open source at
yes I'm always there for those because
until right now the browsers that do VR
our beta and so the minutes there Todd
petah I'll be able to get them out there
so there's a chromium beta that has web
they are built in and there's Firefox
nightly has web PR hooks built in and
they work much much brighter than better
than old than browsers without those
hooks it has to do with how they're
pulling the the head tracking or the
gyroscope and accelerometer data off of
the phone and so when those come out
then I'll be able to release that but
right now if I put it out there be so
many issues with I know you can even get
sick if you don't with all this stuff
flying around you if you don't have a
fast enough update so I'll get it out
there but right now this project is live
at dolby flow GL and you can go to it
and and put on the headphones and check
it out I'll let me turn this down 11
so so the the Web Audio API is going to
take 86 channel track so each one of
them has six channels and it's going to
miss mix them all down to a single six
channel output and it just does it for
you and it's been built into the API for
I think a long time whether people have
been able to use it very much or not the
Web Audio API does it for you if you
wanted to have total control over it
that would be a challenge that's you
know that's not great but it actually
seems to it actually seemed to be really
intelligent and do it do it pretty well
okay yeah so I actually didn't do all of
my mixing I'm terms of volume I
pre-mixed into the tracks themselves the
and the reason for that is the rest of
the audio mixing I'm going to do is I'm
going to change the volume of the sound
certainly with the if it's a two channel
if it's doing the doing the mp3s instead
of the dolby digital plus i'm going to
change the volume based on how far it is
from you right so I actually dynamically
did that and I figured if I'm doing that
so I'm in simultaneously with trying to
maintain a another mix I would drive
myself crazy and it was only a two month
project so but I can see that if you're
really careful about exactly how each of
the relative volume of each of these
tracks it could be kind of a pain yes
oh right so where do you get the tracks
to do this yeah that's that's a
challenge I might like I say I have my
master's in music so I just composed
them out and made them and there's
enough budget in the project to hire
vocalists to do the vocal parts one of
the things i would like I've you know
thought about doing especially for VR is
to provide this as a tool set that then
musicians could write tracks and other
and visual artists could do the know the
audio parts and and even you know
dancers or motion artists could dance
themselves dance the animations into
space right and put together you know a
whole system that you could do item you
know production after production but I
haven't done that yet kind of distracted
with some other VR things right now but
yeah that would be fun anything else
so in VR I only give you this interface
basically it's a gaze and tap so when
you look at one of these objects and
then you tap on the side it will start
it basically the same way I just did
there sometimes is a little delay before
your four of our phrase comes around but
but that's the so it's only a gazing tap
on gr right now right I was I'll take
the whole sequencer and put it in VR to
we just put it on a canvas and and put
it onto a plane and then gaze over parts
but I just haven't and fill the VR until
I'm ready we are for a real release i
haven't take the time to do that I think
that's probably should we should call it
there yes thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>