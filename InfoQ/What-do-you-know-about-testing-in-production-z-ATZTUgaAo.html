<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What do you know about testing in production? | Coder Coacher - Coaching Coders</title><meta content="What do you know about testing in production? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>What do you know about testing in production?</b></h2><h5 class="post__date">2017-12-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/z-ATZTUgaAo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so today we're gonna talk about
production designing for testability and
what that really means is testing in
production how many people test in
production today great it's starting
it's happening it's real it's a
technique that helps us build higher
quality software faster today and scales
over time while reducing tech debt so
let's start let's ask let's actually
start a little bit of reflection when we
all think about something we've deployed
recently to production could be this
week could be last month three months
ago two years ago if you remember
everybody have something that they
worked on they contributed thinking
about that code running in production is
it working they're working right now in
production is it working
see a few nodding head heads not many
though how do you know actually like how
do you really know that it's working
right and even the best of learning
systems if you think about because
usually the answer just alerting I'll
get an alert if it's not working
do you get an alert to tell you that or
you're alerting is working do you know
as something failed and you said well I
didn't get the alert does that happen
this always makes me personally feel
anxious and I don't know if you share
the same feeling but that feeling of
anxiety of not knowing that's something
that we've built that's something that
we put into production is working as we
expect creates anxiety and that exact
idea takes room out of our brains out of
our minds to be able to go on and do
good work and so what I really hope to
share today is some techniques and
feeling to some techniques and
approaches to remove that anxiety so
that we know that what we've built in
production actually is working so that
we can focus on building new product new
features and iterate quickly so quickly
a little bit of background of myself in
2007 as a co-founder and CTO Gilt Groupe
here in the city Gil comm online
e-commerce site we have a few alumni
have gilt here in the aught in the
audience as well as colleagues from A to
B so welcome
guilt is became a large company large
retailer the an early pioneer and the
micro service architectures we grew a
lot learned a lot and then two years ago
I left
to start flow flow as an enterprise
software company helping brands expand
internationally to sell internationally
based on what we learned a gilt and I
think what was really interesting is to
take almost a decade of experience
building microservice architectures
building teams building a culture of
progress and innovation and reliable
software and great customer experience
dealing with all the great things and
all the things we learned because it
wasn't all perfect and then being able
to start over at the clean sheet and to
do it again and to think about on day
one what have we learned what are the
practices that we want to put into play
from the beginning of a company so that
we can build the company not just for
the time to market for MVP and version
one but to build a company that can
scale over time without technical debt
with happy productive developers and
fundamentally when they thought about
this in the beginning
I mean software quality is hard I mean
it's a it's a it's a great discipline we
love the art but it's hard any we have
to be perfect any imperfection
eventually results in mistake it's not
just what we're thinking about today
it's what happens in the future how
things change and so one of the shifts
was to really just really think
end-to-end for the entire lifecycle of
our code and to understand what's
happening there
and with that verification of production
I think was a term coined by
thoughtworks we're really thinking about
production as part of the developer
experience if you think about the
culture of many of the companies that
are that we all belong to many of the
companies that presented here at Q con
we talked about accountability and
developers owning software DevOps
infrastructure monitoring pagers going
off and the developers who wrote the
code getting the alert to go fix the
problem in in in production so we talked
about ownership end-to-end and
production as part of that and if we can
then focus on production being a tool a
complementary tool to the other
practices that we have we can find that
we have new techniques to make sure that
the software we're building in fact is
testable is in fact running as we expect
and really a powerful technique to help
builders build quality software so some
of the techniques and Sangeeta
referenced a few of these that we've
adopted at flow to deliver quality
software one is we've invested from the
beginning a true continuous delivery
second there are no staging environments
at flow they don't exist
we're going to have test environments or
any other environment by any
their name we just don't have them we'll
talk about why and third what's happened
as we evolved this is something we
didn't do in day one but happened
probably the first few months of
development the company is that we
actually stopped running our code
locally and no longer made sense for us
to run our code locally some people have
said this is crazy
maybe they may turn out to be right
we'll see but don't worry it when you
join flow you don't have to be crazy we
train people to be crazy at flow but so
far it's working we want to share what
we're actually doing first let's talk
about true continuous delivery so this
is pretty important here really the
grounding here is in psychology and if
you think about our psychology of the
individual and the developer actually
has to make the decision to deploy
software if we make that super simple so
any developer can deploy software and
they feel ready that flow you deploy
software by merging a pool request the
answer the question that you have to ask
is is it ok to deploy this piece of
software right now right and if you
focus on continuous delivery and you
focus on automated tests then the answer
is the person who decides to deploy
makes that decision and then what do we
need to do to make sure that the
decision is a sound one
well remove all the friction there isn't
another staging environment there isn't
a QA environment there isn't another
group of people that's going to come in
and certify whether or not the software
is valid or not that decision and the
accountability the decision lies solely
with the person who decides the merge
the pull request you're not ready to
merge the pull request why not think
about that that's an interesting
question that sees that out
second culturally we've decided there's
only one way to do something so
continuous delivery it's a good example
say we have a pipeline that knows how to
deploy software reliably to production
over time somebody comes up with an
innovation a better way to do it great
let's move everything on to new way to
do it everything and then stop and then
next great idea can go from there but
what we don't want is half-baked ideas
that come through the pipeline so that
we have multiple different ways to do
things across the organization and today
at flow we have one way to deploy
software one continuous delivery
pipeline it works for our node react
apps it works for our Play api's it's
the same no matter what the underlying
technology that the teams are using and
third once you have continuous delivery
we actually can assume from the
beginning that we have continuous
delivery and it changes the way we think
about things because
I think one area we see the spread a lot
is in environment variable is a managing
configuration how do you deploy an
environment change to production well if
it's really easy to just deploy your
software through the continuous delivery
pipeline trigger release push that
through your continuous delivery
pipeline all the monitoring all the
instrumentation all the alerts all the
notifications will tell everybody who's
interested that something has changed I
mean go back and look at one single way
to understand what has changed there's
nothing different about it and that
proves to be really really important on
continuous delivery fundamentally the
the way that we operate is we we don't
actually deploy software we say we'd
like the state of this offer to be X in
production and then we've instrumented
that layer to go inspect production
figure out what's actually running
generate the diff to bring it to current
state and and that that instrumentation
that's the way the system works
that comes from learnings from I think
it was puppet and chef before continuous
delivery that really instrumented that
process we should say what desired state
is let the tooling let us get there so
we can forget about it I love my staging
environment I love this one
I have never heard anybody say that and
in fact at our time at GUILTY went
through five iterations of staging and
sure the initial ones worked they were
brittle the last ones were brilliant and
we could never implement them
does anybody here love your staging
environment let's see one hand and even
if you think about it this is a hard
problem right really hard I think of how
excited we got with docker and docker
compose and what was what it was going
to do to make us love our staging
environments executed very well it's
still a very very very hard problem so
what's wrong with staging one it's a
bottleneck you have initially
organisations start they have one
staging environment that's managed by
people and it breaks and everyone nobody
can do any work sorry releases the late
till next week because staging is
unavailable - its fragile and by fragile
means it breaks it breaks all the time
and nobody really knows why and it
shouldn't break because just like
production right but it's not just like
production because at the end of the day
if there's a failure in staging and
somebody gets woken up they say you know
what it's just staging I'll fix it in
the morning
it's not treated as production because
it doesn't have the same impact on the
the our clients our users of the
business
found that over time is really difficult
to understand failure in staging
something breaks in staging why did it
break oh I don't know oh look look at
this script that somebody contributed
somewhere to do this weird thing to set
up this one thing to work around the
network layer in staging and that's the
reason it broke and by the way that
doesn't exist in production is so the
expertise around how we run our
production infrastructure doesn't exist
it's really difficult to understand
failure fourth it's expensive
I think the 30 to 40 percent is an
accurate number from what we were
spending on staging if you looked at it
holistically in terms of not only the
resources the infrastructure people's
time the lost productivity it's probably
the half of the engineering budget was
spent on managing staging and not
building product not improving
scalability 30 to 40 percent and
initially when I learned this is really
embarrassed and they went out and talked
to a bunch of people to see when we must
be doing it wrong and found that
actually it's quite common comment to
see that and finally I think it creates
the wrong incentive it creates the
incentive to deploy something to staging
environment where it could be manually
inspected before it goes to production
well great you do that today who's going
to do that in six months and in six
months we're gonna have more stuff who's
going to do all that stuff and so
creates this incentive to do manual
inspection to rely on other teams to
look at and verify our software before
he goes to production and finally at the
end the day even the best staging
environment I always like to ask as
myself ask the people I've worked with
can you guarantee that this will work in
production can you any guarantee you
can't no matter how much we try it will
there will be failures in production so
the highest quality code ever written
was written for the space shuttle that
team was diligent they had an extremely
good process and an incredibly high
quality software and it's amazing and
it's absolutely amazing the process they
went through a simple example is if
they're ready to cut a release and they
looked at the bug count and saw that
they had 15 bugs filed against the
release they knew they weren't done
because statistics said they should find
70 bugs so let's keep going until we
find about 70 bugs because we know
they're there we just haven't discovered
them extremely disciplined team
extremely high quality software
extremely expensive extremely expensive
I think it was classified as the most
expensive software ever written and
that's the trade-off right and I think
our market has shown that we we don't
need to
like investing at the level of space
shuttle quality may not be the right
answer for our businesses and therefore
we are in a world of having to make
compromise don't run code locally so
this was super interesting so we were
let's say you're writing an API you're
feeling good and then you want to run
your server and then you fire a postman
so you can see your beautiful API why
are you doing that what is it that
you're looking for in postman to verify
move that to a test write the
integration test why didn't you write
the integration test to verify that
write the integration test oh you're not
sure if your codes gonna work why not
write the test you can't write the test
what's wrong with your code refactor
your code write the test and
fundamentally what ends up happening at
the end of all of this is if you have CD
and it's front pull request and there's
nothing in the way it's our
accountability the incentives line up to
say this better work I better write high
quality unit test integration test
whatever kind of testing I need to make
sure that my code works and then we
begin to trust our tests and that's a
cultural thing you just decide to trust
your test if we mark if a PR they CI if
the tests against the pull requests our
green code is safe to deploy to
production organizationally that just
becomes a fact and that puts the
pressure on all of us and increase the
incentives that we continue to write
great tests that cover it failure
happens in production great rollback
vastly vastly rollback quickly write the
test move forward and we keep going so
super super important now in a touch on
architecture just a lot a little bit
because some of the quality does come
through architecture and there was a lot
has happened with micro service
architectures over the last few years
maybe decade but one of the key benefits
that we can get from architecture for
being for safely testing in production
improving quality software's through
isolation just really being paranoid
about isolation what that means is
making sure that somebody else can't
break your software so that when your
software is broken it's very clear that
it's your fault really really important
it just simplifies a lot of things we
have to do and just a few of the
techniques their events streaming when
the earlier talks of Q con there is a
note that if you don't have event
streaming in your architecture is
probably something missing from the
architecture and the power of event
stream is is great because it helps us
change failure modes it'll talk about
that in a sec at flow this is an example
but our architecture looks like it
actually looks like that nice pretty
structured
top consume there's a proxy layer for
the api's microservice below serving
different parts of the stack each
micro-service has its own private
database nobody's allowed to touch that
database it is private to the
application and then all the
applications publish events so if you
want data from another micro service
subscribe to the event stream keep a
copy of that data for yourself that
means on failure modes when a failure
happens we've changed the failure mode
from an outage to a delay we've gone
from unavailable to maybe there's
seconds or minutes of delay in
replication or on the event bus or a
particular component if as a severe
outage is affected but it's basically
impossible for that outage at an
individual component level to cascade to
a failure because there's nothing shared
we share an AWS account today and beyond
that literally there's nothing sure
nothing shared but that isolation is
important as we think about what we're
going to be doing in production ok so I
want to shift gears and spend a few
minutes to talk about some actual real
examples of successfully testing in
production
it really is testing in production
sometimes the verification production I
feel like is a euphemism because it's
uncomfortable to say we're going to go
test our software in production because
that feels dangerous but in reality if
we do it diligently if we think about
what we're doing it turns out that we
can actually learn a lot actually
produce higher-quality software and
believe it or not it's safe and even if
we're not testing a production we have
to remember that bugs get to production
and they're failures in production right
so really what we're measuring is does
the failure rate increase when we start
doing testing and production and I would
pause this and kind of evidence shows
that actually the failure rate goes down
so it's look at a few real examples Gill
comm online e-commerce site people go
shopping they add things to their carts
and then they get to checkout and they
have this button today it's says submit
your order
you click the button customer will end
up with their goods gilt the the company
the business is working and everybody is
happy
turns out check out any commerce it can
be complicated but ultimately you want
to know that it works and so how do you
know if checkout is actually working
well we can say that the we wrote tests
and the integration test passed and all
of our unit tests pass in fact I've seen
cases where we had a 100% test coverage
in the in the applications 100% test
coverage is showed on the dashboard
hundred percent test coverage like great
tests the tests are amazing still there
was a bug in production you know how
does that happen but we want to know is
like despite all those things that are
happening is it still working because
what is it about production that's
different
probably the scale is different most
companies that run staging environments
and even pre production environments
rarely invest to have that environment
be at the same scale maybe the network
is different maybe the network that
production on even if it logically is
similar is different right maybe the
provider has a different version of a
switch maybe the chip in their server is
different we don't know something is
different production so we did a gilt as
we wrote a bot and the bot went through
and browse the site and place orders all
the time and it was great and the bot
failed to place an order pretty high
fidelity signal that hey guys there's a
problem something is not right we were
unable to place an order but we're
finding out from our bot and we're
finding out immediately right and then
we can control the cadence of this we
can say place an order every few seconds
placed in order every few minutes
doesn't really matter but that
confidence that we get from being able
place an order is significant similarly
what we built actually on low testing
this is the slightest site to check out
button load testing the way guilt
actually does production load testing
and the reason for that is if you look
guilt calm the way it works is every day
at noon Eastern a new selection of
brands goes on sale and traffic is 50
times higher at noon than it is at 11:59
there's a huge spike of traffic and you
want to know if he can handle that and
it turned out that it was better for
guilt early in the morning to run a load
test on the production environment for a
few minutes and just verify that nothing
has changed and if something has changed
you run the load test at 4 a.m.
you've got 8 hours to recover before it
actually has a materially impact on the
business and those are kind of
trade-offs there come into the office
every morning you see the results say
the load test this morning passed in
production with how things are set up
you feel pretty good you feel pretty you
feel pretty confident right and a lot of
this is about increasing confidence some
of the problems with a bot that goes out
and buy stuff one there's less stuff for
customers to buy because the bot bought
everything right and what's the box
address if you actually ship it to the
bot is he or she going to be there to
receive the package that they bought so
what we did there is we
let's just invent a test domain name I'd
remember that the actual one was like
add tests or at random string Gil calm
and we'll just say that every time a
somebody with that domain places an
order we just cancel the order
we went into order processing system a
guilts a big system and we added three
lines of code if the email address and
to this domain then cancel the order and
that was it and so now all the sudden we
have a bot running a production every
few minutes can place an order tells us
that everything is working from a
checkout perspective few minutes later
the orders cancelled nothing ships no
credit cards are charged inventories are
released back to other consumers and the
world operates and nobody nobody even
knows but we at gilt know that checkout
is working right very very very powerful
second example so flow is a
software-as-a-service company and we and
what that really means we have a
multi-tenant architecture where when a
client comes to us they create an
organization or an account and then they
can create as many sandbox accounts as
they want but interestingly years ago we
started doing this with our internal
services and it stemmed from this
observation when we were modifying login
to allow users to come to gilt.com and
login through Facebook right we didn't
go to Facebook and say excuse me
Facebook can you please send us a copy
of your source code so that we can run
all of Facebook and our staging
environment so that we can test that
login works right we didn't ask Facebook
to do that yet a colleague across the
hall for me that's what we were doing
internally right you you run the
inventory system great
can I please run your inventory system
in my staging environment so I can
verify the inventory is working there is
no concept really of a contract and
believing in the contract between two
services yet when we look outside the
organization with every third party that
we work we at a contract and we
respected that contract so from that we
learned that actually there's this
notion of a sandbox account or creating
multiple accounts even for software that
we write internally who is the consumer
might be our production property it
might be a different domain that we run
it might be an internal test group it
might be an integration test but from
that rose's notion of the sandbox and
what is the sandbox a sandbox is a
identifier
in production that is safe and it's safe
because the authors of the software have
made it safe and we see these all over
the place so at flow for example we run
a payment system you can submit a credit
card will charge your credit card if you
send us a credit card in a sandbox
account that credit card never goes to a
bank and in fact there's test numbers
that work right and that's instrumented
in the software and as the authors of
that software we provide a guarantee
that says hey in sandbox mode here's
some test cards that you can work trust
us trust our contract that if you can
integrate against the sandbox account
it'll work in production right all the
payment gateways do that
super-powerful technique Facebook does
that you get test accounts they're
almost all this house companies today do
that stripe does that have used them but
it's interrupt to think about doing that
internally for our own software right
because now we can deploy our software
into production and we can write
integration tests against sandbox
accounts one other interesting thing
we've done here at flow is that we allow
our clients and ourselves to create as
many sandbox accounts as you want and do
that using one API key and that's a
really powerful thing and so we actually
have clients who have written an
integration test against they stand
against flow in production and what they
do is say hey create a sandbox
organization great got one now they go
through their own integration test in
production all the way through and all
the actions they do and then when
they're all done they delete the account
why is that powerful it's powerful
because when the sandbox account is
created it doesn't come with any data it
is initialized the same way every single
time and that means that the integration
test that they write actually work every
single time right and that's really
really powerful because now we can
schedule that in production and run it
over and over again
once we saw we actually built this for
the first time for our clients and we
saw what they were doing and we loved it
and we adopted it internally and a lot
of our own internal tooling networks
like this create a sandbox account run
as many tests as you want those are all
running in production sandbox is a
guarantee that is safe and then we
delete the sandbox org and here we'll
show a more kind of detailed example so
this is an actual integration test
this particular one is running in Travis
CI Travis CI has a cron feature this one
runs daily and this is a snippet of Ruby
code that actually communicates with the
API so at the beginning we've created a
sandbox and organization in sandbox mode
we then go through and create a certain
number a random number of orders flow as
a global e-commerce thing so random
number of orders of random currencies
and random countries and this is what it
looks like crane order create a payment
authorization create app create a
capture if everything works the test
pass if not it's a build failure and
turns out Travis is quite good at
notifying us of Bill failure don't you
have to do anything right we can do more
but we don't have to do anything and
then it just runs every day it just runs
here's another example this one I think
is a little bit uh I think this is
interesting in a different way so an API
platform in front of the API platform
sits an API proxy we we've written our
own called proxy there's a link at the
bottom it's an open source reverse proxy
written in Scala play and the and the
proxy is everything I mean API dive flow
data i/o resolves on this proxy right
and so mistake here is hi earlier we
talked about isolation this is an area
where there is no isolation a bug in
this layer casket I mean Cascades the
API goes down that flow so this is a
high-risk piece of software so how do we
evolve it how do we manage the software
and make sure that as this software
itself evolves and deploys in production
we're managing what's happening we know
that things are working so the approach
that we took several things that we do
the standard things around code review
integration tests automation but
ultimately what was the what was the
context ultimately we were resolving a
course issue with ie a browsers and some
weird domain thing we're the only HTTP
verb that was available across origin
was post and you had to we had the
support allowing the API to available
across all HTTP methods proper REST API
is when actually the calling client
could only use post it was the only
method that was available
it's a corner case did you go read the
docs on ie there's actually non-apology
for the bug but it is what it is right
and so what we decided to do is well we
have this reverse proxy
why don't we terminate the post requests
with a envelope that then tells us what
to do
similar to json p and then we can
forward the request appropriately as a
proper HTTP rest call to the back-end
service and that way all of the services
at flow they don't need to know any of
the stuff that's going on right they
just got a proper HTTP request this is a
big change right because we're at the
edge of the network we're going to
inspect with all of the incoming traffic
and if we get it wrong
nothing works this is a big change so
how do we test something like this we
said why don't we actually run the
development instance of our proxy server
using production config right so using
the production hosts actually using the
production house and so we have this
this is how we run our stuff eval AWS
profile which identifies an s3 bucket
where we saw our environment variables
def SBT starts up SBT and we passed in
environment production so this is saying
please start my application using the
production environment variables right
now this is this is a little scary but
we're doing it very diligently and now
what's happening is we have a reverse
proxy running in an integration
environment that's actually talking to
production and we can do damage here by
the way this is you know this is why
we're doing this incrementally and very
very carefully and then what we did is
we actually wrote an intro a series of
integration tests actually there are a
list of curl commands that's quite long
that goes out and exercises a collection
of requests that we were seeing in
actual production right do these
requests get routed as we expect curl to
the local server proxying to production
and then we can verify that the service
it shows and the structure of the
requested forwarded was correct and if
not we fail so we did that and then we
wrote another integration test that just
said a create a sandbox org now we're
safe and do a whole bunch of stuff
throughout the API and make sure that
the API reverse proxy is working and
then we were happy and we deployed it to
production and as usual everything
worked as expected but was super
interesting now
we have this asset we have the tests
that run safely against production and
now we can run this all the time right
when you just put this back into Travis
or back into some other scheduler and
run this all the time and we have a
complete regression test of our proxy
not just the integration code but
actually running in production and every
single day we know that the proxy is
working there's no surprises there
that's incredibly powerful to know that
it's working right when a bug comes in
you don't have to ask I think the bug is
in proxy it's done you just look at the
history no it's but all the bills are
successful against production I don't
need to debug there the problem is
somewhere else and if you have that
confidence
it is incredibly liberating to then
focus on what else may actually be wrong
at the end of the day what we're really
excited about is seeing the green
checkmark everything is operating as
expected so we can focus on other things
so when a touched on very briefly that
sometimes despite best of intentions
despite the best of teams with the time
and energy to devote to diligent
software development things go wrong and
I just want to highlight what a few of
those considerations are one is to make
production access explicit so I remember
early on me and talk about testing in
production this isn't just open up the
firewall and run everything in
production it's not you could do that
wouldn't advise it but more that it's
very very explicit we know we're going
into production but let's think about it
is it safe to interact with a user
service probably is it safe to interact
with a payment processor maybe maybe not
well let's go find out if it is or not
and probably take one of these
techniques create a sandbox account to
make it safe but it really is
systematically thinking about what is
safe capturing it and then running it
over and over again second is the notion
just using defined paths and really what
we're talking about here like if you
have an API use your API when you're
testing in production don't belong into
production and go talk to the production
database if that's not what your system
is doing right when we go into
production we really want to emulate how
production is behaving as we're serving
our users in the same way so if it's an
apk API call to choose the API if we
think we have an API
the API is not helping us test aha maybe
we need a new API right but we want to
use our software the way our clients use
it not in a different way so that we can
manage it the same way sensitive data
sometimes comes up and this is whether
it's a personally identifiable
information credit card data and just
mention here to just this takes a little
bit more thought before opening up and
then this notion for designing for
side-effects and these are in the
canonical example is a credit card if
you actually allow that credit card to
go to a bank your users may regret that
and it turns out we found in most
systems there's a few things that really
make external calls that have negative
side effects easy to all those off and
try different techniques but for the
vast majority of the software that we're
writing it turns out that is actually
quite safe and quite simple to start
automating our tests against production
other one in touch in just some
unexpected benefits so this is one I
call it perfect documentation it turns
out that when we start writing automated
tests that are running constantly in
production we're actually using
production and from that we can start to
actually capture lots of information an
example of that is we we run a
regression test against all the api's at
flow
there's our automated tests so they
create a sound backstory they're on all
the whole bunch of stuff verify that
it's all correct and then we actually
capture that and publish it to a
documentation site right so now all of a
sudden when we work with developers you
say check out our site you can guarantee
the documentation is perfect because
it's real right it's real every time our
integration test run we can just trigger
a new continuous delivery build of the
node app that runs the documentation
site it's gonna pick up the new output
and document the documentation always
current always correct
I was actually every version is there
too but that's hugely powerful hugely
powerful let me show you what this looks
like because that this is worked out
quite well here's an example we use curl
for this so curl an API key to an
endpoint we capture that request in a
file called simple that requests JSON we
capture the response
in this case is JSON and we saw that in
another file and we just stick it in a
directory tree our directory tree is I
think it's must be a resource we're
looking at a now resource HTTP verb and
then the path so in our case scrapbook
demo catalog if you can read that
scrapbook demo is the sandbox account we
created catalog slash items is the URL
and then we just captured in a in a file
system very low-tech right but this is
running automated all the time and we
just capture these and then what do we
do with the directory system we use a
very complicated command tar CF create a
tarball eval the captured requests and
responses we just upload it to s3 we're
using continuous delivery if we want we
trigger a build or deploy of the doc
site when the doc site builds it
downloads the latest example is from s3
and then it uses that to build the
documentation right so we've connected
the pipeline all the way through
end-to-end
but we can actually say we have perfect
documentation is perfect it's perfect
because if it didn't work the build
failed and it told us hey you have a
problem in production because there's
something wrong in production the build
failed right and this runs all the time
hugely powerful hugely I mean it just
changes it just first it just changed
the game so now in this shift just a
little bit at highlight a little bit on
tooling because I think underlying all
of this is really an investment in
tooling and I won't just highlight kinda
three of the tools that we use that
really help us ant and not only execute
the tests in production but know that
we're doing it safely and then receive
notification if actually we've made a
mistake one is a tool called API builder
this is formally known as API doc it's
an open source project that dates back
to probably three four years ago at gilt
when we were solving for micro service
architectures and consistent api's for
breast services as well as event schemas
but the key things here is it provides
version control the API so that
developers that they introduce a
breaking change into an API they know
immediately that you can fail a CI bill
because you know because the tooling
will tell you that a breaking change was
introduced
so it really manages version control for
the API is backwards compatibility and a
notion of high quality mocks and I want
to touch on high quality mocking and
here's an example so high quality
mocking what do you mean by high quality
mocks
if we're if we use mocks either we trust
our marks every doubt right that really
is the fork if you trust your Mach then
you're not going to feel the need to
deploy to staging to verify there's
nothing to verify because the Mach is
real but how can you trust the Mach
right because there's so much that the
Mach doesn't capture so the way that we
we put into the development process
actually both the guilt in it flow is we
start off by defining the schema of the
services the models and whether using G
RPC your swagger API builder at home it
doesn't matter but as long as you've
defined as first-class what the
interface is whether the next step is
really important the next step is to use
generated clients to be able to consume
services and then to use generated mocks
from the same specification and all of
your integration tests and if you have a
high quality mock then when you write
the integration test all you really have
to do is step out the one thing that
you're testing and this example the
snippet of the top is just a snippet of
a full mock client library generated for
this is for a geolocation service and
then on the bottom right where we're
testing is that an IP address resolves
to a particular address and so we
overrode the mock we can set an address
and map this IP to that to build
database and then we just call our API
and we verify that the country is as we
expected and that's it with the high
quality mocking with that provides to us
as a technique for integration tests
that can run reliably in our tests so
that we can trust them right the build
passes it will pass in production and
this technique has worked like we have
yet to experience a failure in
production where the mock passed but
production did not like that just
doesn't happen anymore and what was
interesting is we found as as it became
ingrained of culture as we work with
other third parties we now actually
prefer to document the third party
schemas ourselves so that we generate
our own SDK so that we can get the high
quality mocks built into our integration
test so more and more developers at flow
choose to use their own SDKs generated
SDKs as opposed to client provided you
know third-party SDKs simply to get the
high quality mocks because it helps us
write the integration tests that let us
know that we can trust our tests so that
we can deploy to production when the
tests pass
two other quick tools one this is kind
of early but they were there amazing
since when - mention excite never heard
of them until colleague Matt introduced
them company called vivid cortex this is
they excel in real-time database
monitoring and there's a fantastic
product and this is an example from them
where developer came in good intentions
creating index that's the top-line query
number two expected performance get
better didn't get better but queries
four six and seven started to see
variability in response time and really
capturing at the database layer being
able to turn this back in hey this thing
that you expected to happen didn't have
the desired effect so that a developer
can take can undo the change in this
case the action is to undo so there's a
link at the bottom but a fan fantastic
product if you're not aware of them and
last one just to mention is around log
tooling for logging and alerting for
logging so this one is really really
simple but we're writing code and we
have a decision point an if statement if
statements are pretty common so if this
then everything is good otherwise
there's a problem we want to make it
trivial for any one of us to receive a
notification when that branch gets
executed and the way that we've
instrumented that is you simply create a
prefix so in this case the prefix is
flow alerts error just log info or log
error whatever you want floored alert
error and your message and then you go
to a logging system malaga aggregator
we're using a company called sumo logic
at gilt we use Splunk and in there you
just save a search in real time or every
15 minutes if you ever see this string
please email these people or me and
that's it and it works across the board
right and so what this really means is
that as we go through as we start
building our applications we know that
things are gonna happen that we're not
aware of trivial to notify us of
something going on and this I think for
us bridges that gap between things that
we don't know in advance or particularly
this happens a lot with third-party
services there may be some weird
validation rule that's not documented
but you'll see in production this gives
us immediate fed feedback back in real
time to developer to say hey this thing
that you didn't expect actually happened
here you go you can fix it and now to
fix it you can iterate really quickly
right you know that the problem occurred
before it becomes a real issue for the
business
okay I think just the kind of summarize
a few key takeaways in terms of thinking
about how we design production to be
testable when they're really big
learnings is that this has to start at
the beginning of a project right so we
build new software we can think about
how we're going to test in production
verify in production and if we do that
then actually there's lots of ways to
make it safe and the the value it
provides is incredible so just a few
specific things learning to trust our
tests like really trusting our tests and
doing the work that's needed to actually
try and trust your tests and then if you
have high quality tests you can just run
a subset of those in production all the
time an investment in continuous
delivery being able to deploy quickly
being able to rollback quickly in a
systematic way pretty important
interestingly the way we think about
this is we don't actually have any gates
to deploy right the typical process
uploaded PR the tests run the tests are
green developers confident emergency PR
it's on its way to production but if you
can't wait for the test you just merge
the PR and we chose to do that because
in an emergency situation we need the
deploy of the rollback to be fast and
fundamentally we want the same tooling
to be used in normal mode of operation
as well as kind of the rare emergencies
this notion of sandbox accounts not just
for third-party libraries as we build
software that other people in our
company are consuming we can provide
them really nice ways to safely test
against our applications or API is in
production we mentioned mocking we're
really if if it's a handwritten mock
that's a one-off that peel is not great
but if it's a mock that you can really
trust me because it comes it comes from
a specification that's being used in
production it's a hugely powerful tool
to building great to writing simple and
complete integration tests and finally
just making sure that there's a method
to get real-time feedback from
production on the off chance that
something goes and expected which never
happens but occasionally will so thank
you very much
questions oh wow lots of hands you guys
use any feature flag to enable
functionality by a user by a tenant yeah
I chose not to talk specifically about
how we manage deployment but dark
separating deployment from release is
super important get the code in
production that's different from users
interacting feature Flags a lot we use
those quite a bit and then in addition
on the traffic side getting really good
about being able to say actually I just
want a little bit of traffic 1% of
traffic or 10% of traffic and there's
one tool in particular
knowing production works frees your mind
to build new applications and live in
bliss with rainbows and unicorns one in
particular is this tool called splitter
that's the link came from Erik Bowman
and his work at TomTom and what it
allows you to do is have a new version
of a piece of software in production and
then you split your real traffic into
shadow to the new version and real to
the old good version and you discard the
response from the shadow right and so
this gives you really safe way to deploy
into production start verifying load
give a little bit of load and make sure
that at the end the day everything is
working as expected the metrics are
there and more than that the new
software supports the load as well so if
you don't know a splitter it's a
fantastic tool on the the idea of not
running your application locally I'm
sure a lot of developers feel that they
rely on the you know the the validation
if they get from seeing it running right
there and it's right you know it's quick
how how do you help get over that yeah
it's a great question I - is there I
love saying software run the what we
found is that the members of the team
that in that had written higher quality
tests and we admire their tests were the
ones that were initially not running
their code locally and it just changed
the incentives it's like and that was it
it's like I aspire to write great tests
if I stop writing my code locally I'm
gonna force myself to write those tests
because let me no other way and it's
really and I think that's the decision
it's like ultimately
to put it bluntly it's like if you run
your code locally you're producing
terrible code so stop doing that
start writing great automation and live
the life of a high quality code like
that's the decision and it's a really
hard decision to make right really hard
follow-up question on the running
locally I do you run your tests locally
or do you actually send it up to the
integration system and let it do the
tests unless you get the results yeah
great question we actually do run the
integration test locally they'll run in
the integration environment or the CI
environment as well but yeah we do that
is the process and so developers our
development process if we're doing if
something chosen TDD for something right
the test and when the test passed push
the PR if we're designing and have a
prototype and then write the test test
pass and then write the PR yeah you also
get really good at writing tests that
are meaningful yes sir we actually run a
lot of automation on production and one
of the issues we are heating right now
is that they generate a lot of garbage
and sometimes those tests are because
they're involved in a lot of sister a
lot of aspects in the system sometimes
they break and then you get calls at
3:00 a.m. to to fix something that you
know you can you it can wait till eight
or nine or eleven depends on when you
arrive so what what are your thoughts on
that yeah so the question is really
around running tests in production
you're actually generating data load
this will fill up and actually more than
that you may have an analytics problem
because if you don't think about it
it'll show up in your analytics reports
so it's a good question generally what
we find though is that it's helping us
find our scalability or our
infrastructure management problems
earlier in the lifecycle because
eventually these things are just going
to happen when the next client or the
bigger client or the bigger users or the
TV show that brings more users whatever
it is happens right so these are just
like those are actually just signs of an
area of investment we need to make in
infrastructure generally and so we
treasure that it's like let us and learn
early on our own dime
that this is happening the second point
on analytics I mean I think that is
something if you go back to the guilt
use case an order was placed by a test
user
eventually we did have to we did have to
think about this user and exclu time for
the reports otherwise your you know
cancel rate approaches a hundred
depending on how many orders you're
submitting so end up thinking about
those things those are costs but they
come at the great benefit of knowing
that everything is working a great
question have you ever had your your
sandbox account conditional logic fail
and an order gets placed or credit cards
get charged anything like that no why
would that happen it's a good question
and really the question is if the basic
missing the feature flag around sandbox
accounts fails and a credit card
something bad happens right unexpected
to be honest is actually very very rare
and the reason it's rare is that the
conditional logic ends up being very
easy to test at a very high level of
equality and an integration test that's
an easy thing to test and so what it
ends up falling into is just the broader
camp of what is our error what is our
error rate what is our bug right and it
just falls in that camp so it's not any
more prevalent than any other bug that
we see and then more than that actually
turns out to be pretty easy to test yes
since you only have a production
environment I assume when you run your
tests locally they hit the production
environment so my question is are you
familiar with any large companies or
perhaps medium-sized companies that do
this type of process because I think a
lot of those companies have firewalls
and such where you can't reach
production from a local environment yes
that's a good question it's really
around for companies that have a
lockdown production environment where
you may not be able to access what you
need from outside this technique may not
work right and how do we manage her on
that first part was like are we seeing
other companies do that my feeling is
that this is actually we're just
starting to talk about testing and
production verification production my
feeling is this is something that we're
all doing today and all of organizations
at some scale at some point and I think
the highest quality organizations are
probably doing this all the time to be
perfectly honest because how else would
they know that something's not working
they rely on users and other like I
think this is very prevalent the
question of like private networks
interestingly at flow all of our API is
run on the public Internet API fluid at
i/o and we authenticate that way we do
that to eat our own dog food on the API
so for our particular you
it's quite simple because we've chosen
to present everything to the public
generally a good example of where that
happened at gilt is we were trying to
test orders on our iPhone app and the
iPhone app wasn't on the VPN and so
therefore didn't have access to our
staging environment and the example we
gave was action response to that so
rather than try to open up and figure
out how we can test our iPhone apps and
get the VPN thing working and feature
flags in the app we just decided why
don't we invest a little bit to make it
safe and build that piece for the test
domains to submit a test order and when
we did that now when we test our iPhone
app he's open up the iPhone app and
place an order using a test account but
it did require a little bit of
investment so that the data flow that we
wanted for the feature that we wanted to
test was correct and I think that's
fundamentally the answer either it's
available today and it's simple or it's
just a trade-off is it worth the effort
to make this component testable given
the benefits you're gonna gain from
knowing it works and sometimes the
answer is yes sometimes the answer's no
a great question the fact that you have
conditional logic and you know test goes
sorry can you speak a little bit closer
the fact that you have conditional logic
you know test may have a different flow
than actual production does not mean
that she'll there is some code that only
runs in production for actual users and
there may be surprises yes I think the
question is there's always gonna be a
gap anyway of code path between
production and test environments is kind
of how do we manage the risk of errors
happening in that code path said roughly
I hear that roughly correctly yeah yeah
so I think in coverage we view this as
really complimentary to all of the
testing that we're doing this isn't a
replacement right we're still writing
integration tests and I think the way to
think about it which actually
interesting is by not spending 30 to 40
percent of time on staging it frees us
up to write more tests and integration
and in production and actually to
instrumental Ertz right we have more
time to do that stuff which is a higher
value higher return on money in time
than dealing with pulling our hair out
trying to get staging to run but we look
at it really holistically and if a
particular feature is too expensive to
test in production right more
integration tests around it if a
particular feature is very easy to
verify and obviously safe and production
great do that and spend less time
running the integration test but
ultimately it's that end Enlai
cycle of quality that were really after
at the end of the day great with with
the tests running against new sandbox
orgs in in production do you ever run
into problems with the test running for
too long taking too long to run with all
the build-up the question is if the
tests are running on sandbox orgs do we
ever have a problem the test running too
long I mean we do you know if he if the
test does fail or is terminated never
gets garbage collected how do you manage
garbage collection of those tests and
the are creating data and flow itself as
an event-driven stream so all this data
is actually going out to the event bus
and being published and replicated but
interestingly it hasn't been a big issue
because if there is a problem running a
test or the test is taking too long it's
probably highlights an area that we need
to improve performance in the platform
and the second thing that it did really
interestingly is it forced us to handle
the delete events quite well and the
first pass through the system we didn't
we're really good inserts updates
everybody is really really happy and we
looked in this system over here all the
sudden has 10,000 deleted organizations
they're all sandbox like why haven't we
clean those up I mean I should to go
back through the system and instrument
the delete event properly all the way
through so that we can clean up our
software which we viewed is actually
quite valuable like let's do the right
thing and actually write our software to
be 100% correct I think we're out of
time but absolutely thank you very very
much this is a great fun topic</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>