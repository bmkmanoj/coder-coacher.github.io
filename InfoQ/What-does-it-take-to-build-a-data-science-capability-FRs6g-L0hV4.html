<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What does it take to build a data science capability? | Coder Coacher - Coaching Coders</title><meta content="What does it take to build a data science capability? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>What does it take to build a data science capability?</b></h2><h5 class="post__date">2018-04-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FRs6g-L0hV4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello and welcome to the info cute
podcast my name is Wes rice and I'm here
with Charles Homer the chief editor of
info cue and today we're live at cue
Connie I we absolutely did not rehearse
that by the way so today we're doing a
special panel it's after day 1 of cue
Connie I and this panel was is with a
variety of people that represent of
different data personas and what we're
gonna do is talk about building a data
science capability so today we have
Stephanie Yee data scientist that's did
tricks
welcome to definitely we have met a
Zahara assistant professor of computer
science at Stanford and chief
technologists of data bricks you may
have heard of patchy spark we have
sitting on who is the chief data
engineer at PayPal and we have super
Jean who is the director of data science
at coinbase
and as i mentioned i'm joined by charles
humble the chief editor of info q thank
you very much all right so to start this
off I'm gonna ask each one of you to
tell me about a project or projects and
some of your case that you might be
working on right now and then answer
this question for your persona and you
can identify that persona what do you
feel is the most important skill set in
AI ml data engineering so Stephanie
we'll start off with you what projects
are you working on and how would you ask
that question yeah sure so I oversee or
other I'm director of cloud algorithms
at stitch mix and in that capacity I
oversee things where we are modeling
clients so this is things like marketing
product forecasting I think that there's
a couple of interesting product projects
that we're working on one of them is
really like how do you think about
taking a really scientific approach to
performance marketing for example in
terms of the different skill sets that
we look for that's what's the most
important
that's the most important skill set for
a data scientist just in general I would
say problem framing so when you think
about like if you're taking a scientific
method to something it's making sure
that you're answering the right question
and sometimes I think especially when
you're working closely with
cross-functional partners they can ask a
question and it's a really good question
but the solution is actually the answer
to a different question okay hi I'm
Marissa yes so both at Stanford and I at
data books I'm working a lot on
platforms for machine learning
infrastructure for machine learning so a
specific project at Stanford I'm part of
a lab called dawn which is a group of
four faculty members focusing on
infrastructure for usable machine
learning so basically our sort of thesis
there is there's a lot of work a lot of
existing systems that do machine
learning training but just training a
model is a small part of the overall
work so we look at all the other pieces
you need to get a successful model
including data preparation labeling how
can we use the cost of labeling data so
that you can actually use machine
learning and more domains and production
you know serving and monitoring and
debugging so I'm working badly and
projects in that space and in terms of I
guess what what do I think is an
important skill for a data center saying
it's actually it's a whole that spans
that requires interacting with so many
aspects of a business that you really
need you know this ability to talk to
different stakeholders and and
understand you know their perspective
everything from the business itself to
the technical sort of algorithms to the
engineers who need to deploy or rely on
this type of model so I think more than
many engineering style jobs this
requires that high so as a data engineer
which is my persona
in my current role I oversee multiple
like data engineering projects
and some of them span the online world
obviously people processes payments so
it needs to have a very high highly
available databases and connection
connectivity framework to databases and
then for the purposes of things like
risk analysis it needs to have a pretty
robust analytics practice and the two of
them need to be tied together so how do
you take you know structure data that's
being written at a high pitch to a
transactional store and then ship it for
offline transformation enrichment
analysis in a way that's high fidelity
and that actually points you probably
one of the best or one of the first
projects that I've taken on is that all
data that lands in our databases whether
it's a PayPal or one of the four or five
companies we bought that are basically
spanning you know seven no sequel and
five our DBMS databases how do we how do
we capture it and then ship it to say a
Kafka stream or offline to any number of
persistent sinks where they're
scientists and other sort of analysts
can analyze it and do stuff with it and
do that in a self-service way that's
essentially always-on never down so
that's sort of what I'm working on now
and when I look for a member of say my
team I look for somebody who has breadth
and depth in data engineering
it may take someone fifteen years if you
think about it right if if you go from
company to company and and you work on
different parts of data engineering to
have a very full portfolio of talent so
you should know sort of how a database
works under the hood how streaming
systems work how graph processing works
how graph search works I'm looking for
somebody who or people who have a mix of
that talent and it often takes about
like 15 years of exposure to that to try
to pick it up but that's that's what we
look for him hi everyone so I had all of
data
at coinbase and we've stayed away from
categorizing anyone as a data scientist
even though officially my dad still says
dear science for the following reason
because the word data science just means
something very different to everyone so
one of my favorite questions that I ask
anyone who is joining my team is I ask
them to just describe themselves as a
histogram where on the x-axis they have
things like sequel stats you know ETL
which is data engineering and you know
even streaming like spark and building
machine learning models which is feature
engineering and I have I have noticed
that that's that's really one of the
best questions I could be asking anyone
who wants to join a deal a team because
very naturally you figured out all the
different types of personas right and
then the second question I asked them
okay where do they want to see
themselves like a couple of years from
now so that then gives me direction as
to where should I actually you know
focus their efforts towards a particular
project so yeah and I am a software
chain by training and I identify myself
as a machine learning a junior
essentially a software engineer who
picked up machine learning and the other
because of the way I reform lated as and
as a histogram you know different
personas they fall out one is you're
someone who just knows who's really
excellent of sequel is a data analyst
someone who knows sequel very well and
also no stats very well is a quant and
then someone who does machine learning
feature engineering is an ml engineer
someone who does ETL and enjoys bringing
data together into data warehouse is the
data engineer and someone who really
enjoys building machine learning
pipelines event streaming is a machine
learning infrastructure engineer so
that's at least how we've broken it up
so following on from that then could you
maybe talk a bit about what roles data
professionals play within a company or
within your companies right so we have
all five of those personas and each of
them are tasked with different things
and for instance data analysts and
quants they're tasked with helping the
different business units or products
with respect to deriving insights from
data and helping with
business metric data engineers and
machine learning infrastructure
engineers are tasked with essentially
laying the foundation for what our next
generation architecture is gonna be and
machine learning engineers are also
matrix into different products so they
could be matrix into risk where they are
actually working on reducing payment
fraud or preventing compliance risks or
they could be matrix into growth where
they're helping with user acquisition
campaigns and optimizing those campaigns
using machine learning what about the
rest of you what about that's a hard
question to answer because I feel like
every company I've been at there's been
various fuzzy lines at the startup I was
at I think the people who call
themselves data scientists did mostly
data engineering work at other LinkedIn
I think I felt like the data scientists
were mostly statistics people and they
were kind of not interested in touching
code and then they were kind of forced
into touching code and then other places
that there are very clear separations
you know data engineers will do that
will build a platform for you and and
you know all you sort of have to do is
generate some model profile that we can
ship into production and and we all take
her or the production side of it so I
think people so large I don't think any
each division probably runs it slightly
differently the group I'm in mostly is
just end to end data engineers and you
know the ml people the people who are
developing the risk models I would say
they use the platform we build is it a
function of size is it at a smaller
company people just wearing more hats
under the small company is hard to hire
specialists sir
and it's hot you have to pivot and so
you yep I think my team so I add data
books especially we see sort of hundreds
of different data science teams from
different companies which are organized
in different ways and you can kind of
see the pose and cons of each one -
there isn't a single you know solution
that's like perfect for everything so
I've seen sort of two broad types of
organizations one is kind of a vertical
specific team so
you have the same people same team of
people that does the data engineering to
import data it does you know reporting
it does machine learning models and
training and so on is the same set of
people and they work as a team and this
can require you know people who learn
multiple of those skills or at least a
team that's cohesive or you can do this
stuff but the benefit is that they're
all working in one vertical problem area
so like let's say they're doing all
these tasks for I don't know smart
meters or something like that and then
the other thing I've seen especially at
large companies but you know is you know
you have a separate like data science or
machine learning infrastructure team and
then the benefit with that is you can
have you know specialists in each area
but the downside is now you know people
become blocked on that team and also
they may not understand the vertical use
cases very well so you can easily cause
things to be you know delayed as they go
through the organization but on the
other hand you're doing everything in a
more consistent way so there are pros
and cons with both of these models so
I'd say it stitch fix you can so we have
what our our org is called the analytics
and algorithms org and you can split it
into three different groups so one is
the data science team and I'll partition
that a little bit later the next is what
we call the data platforms team and the
idea behind this team or their mandate
is to make tools that can help make the
data science team more productive and
then the third one is what we call
analytics engineering so they are
they're tasked with sort of making
self-serve tools for business partners
within the data science team we actually
organized functionally so we try to map
to our business partners so stitch fix
styling companies so we've got sort of a
styling algorithms team merchandising
algorithms team and then flying
algorithms so what makes a good data
science professional do you need a
computer science background you need a
mouse stance background what are their
kind of different career paths that
people have taken to end up anyway
yeah so I would say it's we sort of take
a very broad view like a lot of it is
very context dependent so if you're I
was at a company prior to this and it
was a Java shop and we would sort of
roam around looking for these unicorns
you happen to know both Java and have a
PhD in statistics and I mean I'm sure
that these people exist it's just hard
to find them so then you just become a
recruiting firm the way that I look at
it though is that everyone sort of has
their superpower so and every context is
going to need a different superpower so
like we do have some people they have
computer science backgrounds and then
they'll be more sort of on the machine
learning engineering side we have other
folks like who are astrophysicists or
who just are neuro scientists and they
just sort of approach problems in
different ways so we try to have a broad
spectrum of people yeah I think it will
take a while until you have set of
people sort of either who learn all the
skills and in their normal industry job
or people who graduate to like have all
these skills from their education so I
think a lot of the work is figuring out
you know with the backgrounds that
people have and how can you set up the
infrastructure and and set up a process
so that you have an efficient team as a
result there's a lot of work in that I
had to try to reduce the barriers
between different people and I think to
your point about centralized versus you
know I remember in LinkedIn the the
search team had a relevance team and a
search infra team and the separation of
the two orgs was a file right it was
like Conway's law right so the the
responsibility the relevancy was to
generate a file and the responsibility
of the infra team was to consume the
file and that actually worked quite well
yeah so I can going back to the
histogram analogy so I've found it to
work incredibly well for instance quants
are usually folks who've had an advanced
degree in a in a stem field and they
have picked up stats or they already
know stats and they've picked up some
software engineering so and then we also
see a variety of software engineers
who've picked up machine learning and
they know not only how to create a model
but also deploy it into production so
those become more machine learning
engineers and data engineering is is
essentially like that's the simplest one
to define because there and as machine
learning in front forks because those
are essentially you know back-end
developers who know you know what does
it really mean to actually move data
across and build micro-services right
okay we have a question so as some of
the analysts panelists was talking about
training the model it's just part of the
process I wonder if there's work being
done oh there's a tour ready that can
standardize or having a general format
for the model so that it's easier to
wrap the model to make a lightweight API
I mean I think the short answer is that
unfortunately there isn't a standard
tool to package models yet there are
many different sort of attempts that go
to different you know the different
extents their source one extreme is like
Oh your model is it's just a docker
container with a REST API this can be
good if you're doing you know just a few
predictions at a time but it's may be
very heavyweight if you're trying to for
example use your model in a spark
application and apply it to lots of data
like do you really want to make a rest
call for every item and then for
specific frameworks you know there are
formats like onyx for deep networks or
like the tensor flow model format or
different ones I think it would be great
if there was a way to sort of
standardize on this but it just hasn't
happened and people have been trying to
do it for a while and sometimes people
the interface is a no sequel store where
as a key value lookup for some sort of
models and and to your model your your
comment about packaging in like a docker
container the other idea is like the
clasp further the scorer gets packaged
with the model and then their Co
versioned and then it's like an ami or a
docker image that gets shipped and if
there's a problem with it you don't know
if it's a problem in the data or problem
in the score you just roll it back
because you can never know and that's
one that's what
used Wellington and even in my startup I
have a question regarding like the
talent shortage especially in data
science and deep learning how do your
companies cope with that because like
there's definitely less people than
needed in the market do you have like
special programs you do internally to
get your people up to speed or kind of
an approach at all to deal with that
situation how do you hire managers for
their sites yeah oh there's lots of boot
camps out there so we definitely you
know seek for talent from there right
and then the other thing that that's at
least worked quite well for us Aquinas
has been just providing access to all
the data to all the analysts and even
folks who watch you want to become
analysts and we we we've seen some
amazing results out of that people you
know when they're incredibly motivated
they actually pick up things themselves
and then we've had folks who've
transitioned from risk analysts sudhir
analyst or risk analyst to a dealer
scientist who risk analyst to a software
engineer so we've had all all sorts of
spectrum over there just answered he
said it takes 15 years to get all the
skill sets that you need to to hire
someone who's doing things yet you just
said you just said boot camp is that's a
long boot camp I'm just saying I think
that's a teenage year that's that's a
very specific skill set right the other
part of the data scientist is the domain
knowledge right so even if you bring
someone in they have to learn the domain
and because they need to understand what
heuristics make sense how to evaluate
the models if they make sense
so I think in terms of recruiting one
thing that I think stitch fix did really
well in the beginning especially as they
invested in creating an environment
that's really really friendly for data
scientists so we actually when we're
recruiting I mean you're obviously
having to compete against a lot of
companies but we're in the very
fortunate position where it's like oh
well like you can come and run and play
here and it's really fun if it's like
wow that's really cool so but but it is
really enough for an investment there's
a component of what we call tech
branding I think on some level we had to
do this all along because it's sort of
hard to convince like a neuroscientist
to be like hey you should go into
women's retail there was like a there's
like okay now hold on we need to really
try out this but it's it's it helps us
recruiting even now stitch fix is a
company that has something like 90 data
scientists and less engineers can you
talk a bit about the philosophy of I
guess that many data scientist for your
business the philosophy or yeah so I
would say it's interesting so when
Katrina the founder started the company
one of her things was you know what I
think that we can use machine learning
and data science to actually change the
way some of these companies work and our
chief algorithms officer which like it's
crazy that we have one but I think in
ten years everyone will he was I think
one of the first ten employees at the
company so this is one of those things
were it's like you had to start at the
ground up so I think there was another
question over here that's actually a
good segue so the the podcast is titled
building a data science capability I'd
like to get the panelists feelings on
where do you start to build that right
where do you start because you all seem
to have a mature capability there but
for companies that don't have it what's
what's the beginning what's the first
step and then the building blocks to to
maturity great question yeah it's funny
I was actually talking to the CTO of a
company who was thinking about this as
well a while back I think that there's a
couple things the number one thing
though is that you have to sit there you
have to say like what do you want this
capability to do right like a capability
as a task to be done and like what
the goal it's very easy for people to
sit there and say you know what I'm
gonna hire a data scientist and they're
gonna do things and then that's not
often successful if there's not a very
clear mandate so you got to start with
that yeah so I've seen again different
organizations that are at different
stages of doing this including many that
are just starting out and what I found
is actually the first thing that
everyone has to get right is the actual
data itself you know the pipeline to
collect it and clean it up and and just
understand it and if you don't do that
well you can't really learn anything
from it after and if you do it well even
very simple questions or like observing
changes in it might reveal a lot of
insights so that's that's the thing we
spend a lot of time on is like helping
people figure out you know what what
they what data they should bring in what
else they need and how to reliably you
know collect and and compare that so I
think if you start anywhere you don't
need to do even any machine learning and
you'll get value for from this I'd say
let me follow up with that question so I
had lunch today so Q can I is all about
artificial intelligence machine learning
for software developers that that's what
we were really trying to focus on I had
lunch today with a architect and he was
he works on cloud waste at platforms
we'll call him a Java architect I'm not
sure if he was but we'll say is and he
said I don't know where to start I don't
know what the state of the art is I
don't know
what I should I don't know what I don't
know it would your advice be to start
with just collecting data start
collecting input and then start to look
at that data so I think Stephanie
answered you you have like a business
goal or a question that you want to you
know to tackle with this and it's
important to pick one I think if you
just say oh we'll set up a data science
team and you know just check in six
months later and see whether they found
anything it's not going to work but
there are many specific things you can
say that you want them to do you can say
we want to increase lift on this metric
by this amount you can say we want to
understand just even like understand
customers usage so that you know the you
know the customer success team can talk
to them in advance
stuff like that so you pick some
specific goals and then for those you
figure out okay what data do we need to
collect maybe there is in many cases
there are a bunch of logs or JSON files
somewhere no one's looking at them and
then figure out how you actually want to
organize it to ask questions and as I
said you can get much of the value using
very simple analysis of course once you
do that you'll want to do more to get
you know the last 10 20 percent but
doing anything simple is you know it's
much better than not looking at it at
all yeah I agree with that when I
trending 10 actually what was
interesting as almost all of the
relevance models were heuristic models
their hand-built models and what's
interesting is you know I always find
this funny when I go to a conference and
a data scientists or another person is
like giving say I cannot reveal the
features I'm using and and I and I in it
like it confuses me because the features
are very specific to the data that that
company collects for example LinkedIn
has information about your connections
and about your profile your professional
profile like everybody doesn't have that
no one else has that right so the set of
like say 20 feature that LinkedIn has no
one else has like knows your profile it
knows who you're connected to it knows
your job title it knows things in your
job history
Netflix has different things it knows
your watch behavior it knows your
address it can probably infer your
gender or something in this in your age
it can probably do some of that but it
it has a different set of data so all of
these companies have different sets of
data you're you from that data you will
do feature engineering then when you go
to a conference that you never share it
they say I can't show this feature that
that's very important to me and I never
understood it but but I think you know I
where I went off on this but what if
this person's in infra and he just he
wants to use machine learning to improve
performance of the servers that are
running what's the state of the art what
are people doing well one thing I wanted
to say was that I think every every
company could
benefit from the data science capability
yeah like if you have any process which
is fairly manual let's say insurance
right you're some sort of credit scoring
for sure you can actually just extract
all of the data and you know apply
machine learning to do your credit risk
as I spend you know in a more automated
and intelligent manner right or if you
are an e-commerce company which is just
trying to grow right acquiring users of
course you have already collected some
data you can go and you know try to
optimize that that that growth right or
the cost of user acquisition but yeah
the key I think over here is a having an
exact team which really buys in to you
know how access to data and data
intelligence can improve either the top
line on the bottom line and the second
is of course you know building a solid
foundation where you can actually bring
all the data together in a data
warehouse which allows other people to
actually play with it as Stephanie
mentioned right and I will let's it take
the in for a question so say this person
is this architect I was talking to was
in infra they in operations or something
along those lines what's the state of
the are how are people using machine
learning and infrastructure in
operations yeah yeah so of course you
know one of the one of the key things is
an anomaly detection right so which is
you know you want to know if you have a
fairly complex distributed system as to
you know where did things go wrong well
where did it break down right you know
if you have a map a complex MapReduce
task maybe or you have a complex you
know dag which is doing event streaming
an event aggregation so in such cases I
think you know like gathering all of the
data from the logs and the CPU and the
network usage and throwing it all there
and some sort of an anomaly detection
can actually really help you debug a
very complex system anything to add yeah
I'll just that so so one of the other
professor is in in the dango Pat Sanford
peter baelish works exactly on a system
for large-scale anomaly detection called
macro basin I've been also helping with
like some some problems related to that
recently
and it's in some ways like what it does
is very simple is you just take two
tables of data that have attributes and
a metric and it does a basically it
computes a difference and it finds the
groups of attributes that have the
biggest difference in the metric and it
just it can quickly explore the
different you know potential
combinatorial groups and give you the
top ones it's super simple but what they
found with this is that you know many
different companies once they plug it
into the sort of data center or serving
system type metrics they immediately
find anomalous groups that are actually
a problem and what happens in info often
is you you're collecting metrics you
have all the historical data but no one
looks at them unless there is a problem
and it's severe enough that someone
calls and then you know they take it and
they say like oh you know everything
every Content item on this CDN is like
not being served in this country or
something but you can't proactively
catch these so with this type of system
and many other anomaly detection methods
to you quickly see a summary of the top
ones and you can just like look at it
and you know not be overwhelmed with
data and see an interesting group we had
a talk at Q Khan I think London a year
or two ago with like straggler reduction
in data flow that was pretty awesome
I think it was data flow right yeah yeah
it was a I think that was pushing the
envelope it basically said it it can
reduce your times by 25 to 50 percent by
splitting your job on the fly without
any prior history of the job I think
that was amazing so I'm gonna ask a
quick follow-on to something that said
you said a little bit earlier about
slightly flipped me I think about hiring
more managers so given how many data
scientists have PhDs do their managers
have PhDs do you need specific skills to
manage the team of data scientists I
think you have to be able to deal with a
lot of prima donnas I don't think I need
a PhD to be literally there but that is
mighty good from what I found it's it's
very important to have the right culture
for the team so basically try to
establish a culture and find people that
are
most excited about actually solving the
business problems and you know making
the company's successful and having that
in there and you know having people be
rewarded for that and so on so and if
you do that you know it depends what you
want the manager to do if they're kind
of a tech lead to they should understand
what's happening but you could also have
someone who's a great manager who
understands the business and who
understands how to help people in their
careers but you know isn't a PhD yeah so
it's a so the specific question I think
was do you have to have just being a PhD
make you less of a manager or do you
have to have a PhD science team yeah so
I don't think you necessarily have to
have a PhD I think some deeper expertise
or like exposure to at least the tools
and the tool shed is kind of useful this
is like like I have a master's degree I
don't have a PhD but a lot of my team
does so yeah I don't think you have to
have a PhD but you you know you can of
course as Stephanie said you can
substitute it substitute for it by
having a deep expertise which in a lot
of ways in in this industry is really
just applied you know experience right
but one thing though I would like to say
is that you know I have seen after a PhD
you realize that you don't know anything
so you know that that that is actually
you know pretty refreshing so in that
respect you know then then you need a
strong manager who who understands you
know that aspect of somebody who has
really attained knowledge it really
knows that I really don't know anything
and therefore that that manager would
then be able to you know really
distinguish between the prima donnas as
you said and the ones who are humble and
then of course you'll always have you
have to have some deep conversations and
you know you have to actually have
rebuttals but I strongly believe in then
a manager who's very skilled at conflict
resolutions and you know making sure
that everyone can let's say disagree but
still commit which is what Jeff Bezos
say is that Amazon so yeah I think those
attributes are more core than that than
having a PhD in order to be a good
manager or are there different skill
sets that you look for for a manager for
a data science team are the same that
you would for a front-end JavaScript
team no yeah so it ya French and manager
may not translate directly into any data
manager type role so there has to be
some domain expertise right for sure and
that is in a sense in order to let's say
just understand at a very high level and
what what the team is working on and be
able to have a vision and articulate it
such that you know the team actually
buys into it so Brian that's whether the
skills have to actually still be
domain-specific you have to have some
credibility yeah okay I think we have
another question over here
Rowland yes thank you and our Dorota
Faye is going superfast data science is
just so many knowledge coming in how do
you make sure that your team keeps up to
date with all the new knowledge that's
being published lately how do you keep
up to date with all the stuff that's
happening yeah by coming to events like
this right yeah I learned quite a ton
yeah um I usually when I go to
conferences I am usually hanging out in
the hallways but I have attended all the
talks and not not that you know because
I'm the track host but still I fought
all the talks that I attended in my
track really useful so yeah
yeah I mean I think building time in for
it in the day is also pretty important
so like we have like quant our research
meetings we'll send around papers like I
think a lot of it is just encouraging
people to do that the nice or rather one
other thing that is convenient is if you
hire people who are gonna do it anyway
then they'll like do it on their own
time as well so one thing all that did
is that I've seen as having a way to
quickly test out some new idea and see
whether it would actually help in your
case which is good practice anyway for
most of the things you do in data sense
but you know if it's very easy for
someone to like try a new model and
compare it with your existing one or
something then you're more likely to
benefit from them if that is a huge
process of like even discovering how to
bring together all the right inputs
people are just not going to do it so I
want to go back for a second said
earlier you mentioned Conway's law so I
want to ask a question about engineering
teams and data science groups should
they be separate teams should they be
grouped together as cross-functional
teams it is it depend on the domain how
do you structure your teams so I I think
what Matea said earlier made total sense
to me which was that you have the two
models one model is you have vertical
teams at their vertical by domain and so
they were working in some domain and in
that domain the they work with a
thickness dev or the product manager and
that's telling them what the business
needs to do and then together the team
kind of organizes as a scrum and you
know you have the data scientist
generating the models or testing the
models or validating the things and then
you've got the sort of the data
engineers helping out where they can the
negative of that is everyone's it's like
the Wild West everyone's using your HDFS
as their like scratch and there's no
organization and so it's very hard for
the one team to share the data that an
other team can use so then what happens
is they say that oh wait this doesn't
work anymore we need a central team and
that central team will organize how data
the lineage of that data right the
governance the provenance of this data
but then that team becomes a bottleneck
right and so I very much taught this at
LinkedIn when I was there
I think I came at an interesting point
where they said okay so we had this one
on a ship as we had the thing called
data slash data okay that was like where
you put data okay then there's not a
thing called slash data derived that's
where you put derive data okay
there's only basically two states it
either came or there was like slash data
databases like it came from a database
right now with the promise with derived
as someone took some thing from a
database and enriched it with derived
and input in back and derived and
someone took that derived and put it
back in derived and then nobody knows
who owns the original thing that they
had the lineage becomes a huge mess so
you need this policing force at some
point you just to handle this otherwise
it goes nuts but yeah you end up getting
a bottleneck yeah - yeah just just to
tee off of what said said I think yeah
the the best functioning model that I've
seen are ones where you know they're all
aligned across a functional unit like
search engine companies like Yelp where
I used to before they they've done a
pretty good job like they have data
mining teams which has machine learning
engineers back and engineers and deal
engineer is all just working together
solving for either search or ads or spam
and we've tried to do the same thing at
coin base as well yep everyone who's
working on the risk side of the arc
they're just working together risk
engineers risk and those data engineers
and machinery engineers so I I feel like
that that is the best way to keep the
the whole machine moving smoothly
anything to add I will have this one
thing from Conway's law the I can't list
exactly which company it is but a
company I've been affiliated with or
maybe currently affiliated with goes
through reorge and because the org
boundaries keep changing there's a lot
of jobs that running that have no owners
like tens of thousands of jobs are
running that nobody owns anymore because
the org
I don't think this is a solve problem
curious what other people think I've
seen
yeah I don't have a comment on this
specific problem but I definitely I mean
it is very important to document like
all the steps involved in producing a
specific data set and if others are
going to build on it you need a plan for
how you're going to keep producing that
all these data sets are live basically
they'll they'll keep being updated
something will fail in the future
someone will need to go back and
understand what's in there yeah so some
what relates it to weathers question
what do you think that a scientists
could learn from software engineers I
know from experience for example of map
positions right horrible horrible code
yeah I think so just a bit of a saying I
think in general there's no established
software engineering process around data
science and even in some ways around
just data analytics in general certainly
not around machine learning so I think
there'll be a lot of stuff and people
are coming up you know for example we
had this question about whether it has a
way of packaging models and shipping
them people are coming up with solutions
to specific areas here and there are
just some basic things that we do in
software engineering like you know using
version control or being able to hold
back code but also things that are
specific to data science for example how
do you monitor a machine learning based
system you know it's not just like is
the server up or down it's actually a
pretty complicated problem to figure out
how it's doing so I think this is an
exciting day where people will discover
things and one analogy I have is it's
kind of like the early days of the web
it used to be very difficult to build a
web application required lots of arcane
knowledge across many different things
and today people figured out ways to
package them and frameworks that make it
possible to build them and as a result
it's you know maybe ten or hundred times
easier and companies built 10 to 100
times more web applications so I think
we can get to that stage if we define
sort of the right processes so in
today's session that went through some
of the like good practices and tech
stack that show us how to production
Eliza
I guess machine learning and models and
one night for companies that more doing
traditional development right now wanna
tap into the benefit of ml they what are
the top three let's say tech stack or
patterns that you would recommend these
companies to invest in and get good at
yeah I think patchy spark might be I
heard it can do data stuff and and
machine learning so that's that's one
thing I think like the cloud-based
the public cloud ones now are just
amazing so both Google and I think as
you're also has a sure ml but I've never
had experience with it but I think the
things that are available in the cloud
today are if that's great if you can use
it amazon has sage maker as well that
we've been playing with but like if you
wanted to to have like a tech stack
which is in-house then you know if you
want to have of like ability to actually
production is quote faster etc then by
phone or you know Scala beast Lang Scala
or any Java beast language I have I have
found a difficulty productionize
anything with our it's quick to
prototype but hard to production is
although there are several companies
which have successful production eyes
with r2 but yeah if you want to set
yourself up for less pain in future
stick with Python or Scala yeah I've
been thinking about cognitive diversity
a lot that on a team you can have people
with very different skills and you want
to let them all contribute in their own
way but still wind up with data products
that are they can all work with so how
do you balance the cognitive diversity
of people versus commonality for our
team so one idea is if you run in a
scrum team at the end of the scrum there
are at the Sprint there's like a demo as
long as you show the worth of both
groups or through all three groups I
think
then you're going to send the message
that all of the disciplines are
important you're equally important yeah
I'm here sitting thinking about how to
represent myself on an Instagram but the
histogram but my question is what what
mistake in billing out data science
capabilities you know too fresh you know
what mistakes do people make you can
help us avoid and then also you know as
you get going and you think you've got
it down what are the traps people fall
into that you should try to avoid yeah
if you are really starting a data team
from scratch then I don't think your
first hire should be at you know what in
the valley people call data scientists
right or in my histogram that's a quant
the reason for that being that you know
you you that quant would then need
support in order to actually
productionize
what whatever model or algorithm they
came up with right so unless you have
like a colleague on the other side you
know who's gonna help the quant actually
productionize it then don't hire the
quant as the first data hire I would
almost say you should be hiring either a
data analyst does the first hire if you
just want to derive insights first or
you should be hiring you know a data
engineer if you don't even have a data
warehouse right so those would be my
first first hires and then if you're
really just starting then you probably
don't even need machine learning just
yet you probably just need a data
analyst to give you insights to the data
and even probably can get away with a
rules-based system and then eventually
you hire a machine learning engineer
right yeah anything to add yeah I think
in terms of pitfalls you know one of the
main ones I've seen is if you don't have
a metric of success that you know you've
thought about very clearly and that you
can keep monitoring so you and and then
the second one I've seen is you know you
collect some initial set of data you do
something with that you got a result but
then you can't reproduce that later or
change it as as new
so you really need to think about that
both like how are you going to run this
again and also how are you going to
measure that same metric and I've seen a
lot of the people that I work with who
have lots of data science experience
they begin by defining those metrics
that's like the first thing they work
with with any project is how do we
define that yeah it's definitely I think
related to the metrics is like once
again what is the problem that you're
trying to sell like if you're starting
out and you're trying to convince your
colleagues that investing in data
science is a good idea a lot of times
you want to sort of find that really
nice problem that it will just very very
cleanly solve right so if you're in
operations it's like okay let's figure
out how to optimize different components
of that I think that there are some more
hairy problems that actually don't
require sort of that don't need to be in
production so this is a little bit
different than I would say a
quantitative analyst but people who are
trying to help people make deeper
decisions so it's sitting there and
really pulling out the confounding
variables and and yeah but then once
again like it that that that position is
not going to be as high as clearly high
ROI okay I think we have time for one
more question
data science is such a perhaps
intrinsically sophisticated discipline
that it's difficult to intuit your way
through such a complex solution
sometimes so as an executive building
out a data science competency how do I
protect the or from human error sorry
how do you protect the org from human
error yeah what controls can I put in
place that can protect us from human
error out of a data science team because
people make mistakes but with such a
complex solution coming out of it
there's no way for me to know if there's
a mistake being made I see you know I
think that that's fair I think that
there's sort of things that you can put
in place like if there's certain
problems that you're trying to solve
that are important enough to understand
then you can just put that as a
constraint on the data science team you
can say hey guys like we need to use a
really interpret will model right now
because we actually need to be able to
peel it apart and understand what's
going on
I think that there are yeah so I'd
actually just say put it as as a
constraint for people to work under cuz
like there's some things where it's like
you know what using deep nets is not
gonna get you what you want it might be
a little bit too complex and you have no
idea what's going on yeah I think what I
found is like you you you often need to
try the simple thing as well and compare
with it so and also the metric you're
measuring needs to be very well defined
so that's the thing that an executive
should understand if they don't
understand that then of course they
won't be able to make a decision and
then you know compare it with like a
linear model compare it with some very
simple thing often and that will give
you a baseline that's pretty interesting
to see I think one thing to answer that
Rachel's keynote tomorrow evening will
uncover quite a lot of the same ground
so make sure you come along to that one
as well
alright so what do you think of our
first ever live recording of the infill
queue podcast alright so we we should
drew it again all right keep it going
thank you to our panelists thank you so
much for joining us and once again thank
you for joining us on in for Q podcast
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>