<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Testing in Production - Quality Software Faster | Coder Coacher - Coaching Coders</title><meta content="Testing in Production - Quality Software Faster - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Testing in Production - Quality Software Faster</b></h2><h5 class="post__date">2018-04-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9C0efJkT0Hg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you and what a great conference
it's got to be the best tech conference
in the world right now it's amazing you
see so many great people here so let's
get started testing in production but
really what are we talking about it's
how we make quality software faster at
the end of the day that's what we're
talking about and it turns out that
testing and production gives us a great
tool to be able to accelerate our
software development and actually
produce higher quality software faster
so let's get started I want you to think
about the last feature that you've
worked on and deploy to production maybe
a small feature a big feature a bug fix
but imagine the last thing that you
worked on we went through your software
development process code reviewed it
felt great came home told your family
how great this feature is that you're
about to deploy at work answered all the
questions from your nine-year-old we
knew you're gonna save the world of this
feature is that feature working is it
working thinking about that feature I
mean is it working right now in
production as you said here is that
feature working right
two people nodding a few people thinking
how do you know that it's working
your phone's not ringing who would call
you how do you know they're working
how do you know alright maybe your
battery's not dying because your inbox
isn't getting spammed with all the
alerts from Nagios or graphite but how
do you really know and ultimately if
you're feeling a little bit anxious it's
really that feeling of anxiety that
we're trying to solve like how can we
really really be sure that the work that
we've done is actually working not just
at the moment that we deployed it when
we verified it but a week later a month
later a year later and ultimately if we
could know that our work was in fact
done and the truth I think the broader
meaning of the word done it's working
it's working as expected it continues to
work as expected and we would know if it
changed if we can do all of that then we
can reduce some of our anxiety and then
focus our energy full-time into whatever
it is that we're building next and I
don't know about you but when
something's not done and I don't know if
it's working like I'm not hundred
percent working on the next thing I'm
just not there's something in the back
of my mind constantly worried I may flip
over I may be looking at a chart and
they be looking at monitors I'm not 100%
focused on the next thing I'm working
out because I'm worried about that thing
that I built because it may or may not
be working and if it's not working I may
or may not know and the dreaded outcome
of that is that ultimately we hear from
customer service we hear from our
friends we hear from customers who have
our direct phone number to tell us when
we make mistakes and the phone rings and
we realize that we missed something and
it's not a great feeling and ultimately
this is about how can what can we do to
fix that to get rid of the anxiety and
know that the software that we've built
is working so let's remove that anxiety
quickly about me so in 2007 the
co-founder and CTO of gilt groupe gilt
comm company grew to over a thousand
people I was approaching a billion
dollars in revenue I think a hundred and
hundred fifty engineers working in the
company a few years ago sold to Hudson's
Bay started off as a Ruby on Rails
monolith broke out into a large
distributed monolith 400 plus individual
applications over 1,500 unique code
bases and lots of lessons learned in
terms of what it means to operate a
distributed model with or a marker
service architecture at scale
and then a couple years ago Coco founded
a company called floo floo is a
enterprise software company that we
build software that helps brand sell
internationally so just like as guilt
when guilt expanded internationally
creating great experiences to sell a
product into Canada China Australia etc
what was really really interesting about
the journey is you take everything we
had the opportunity to take what we
learned about building guilt about going
to a very distributed micro-service
architecture the lessons learned what
worked what didn't the five attempts at
building a staging environment which
we'll talk about later and five failures
building a successful productive staging
environment and then rethinking the
things that we wanted to do with the
fortune of starting with a clean slate
and ultimately what we learned and where
this talk comes from is some of our
software practices at flow are quite
different but first let's talk a little
bit about just software in general so
software call it's hard to build quality
software he's a really really hard thing
a few examples of the highest quality
software in the world one was the space
shuttle a few years ago an article was
published about how they write software
for the space shuttle and it's amazing
people work 9:00 to 5:00 they're steady
when they find a bug they review they
fix the bug it would be why it happened
but then they look at where else in our
entire code base could this conditions
these same conditions exist for this
same type of bug to happen and then they
go find all those places and fix all
those things when they're preparing for
a software release they say well how
many bugs have we found we found 50 bugs
well our data says that on average every
new release has a hundred and twenty
bugs that means we still have to find
seventy more bugs on average before we
can release our software so we can't
release everybody go find bugs because
we can't release the software until we
find the unknowns that's their process
and they produce some of the highest
quality software in the world it's also
the most expensive software ever
produced in the world so there's a
trade-off there other companies here in
the valley a few years ago
salesforce.com made a huge investment
into testing their cloud software and
really scaling all of their integration
tests across the AP eyes and everything
else I think that at that time they had
50,000 tests and if you ran them
serially you'd run them for a decade or
something like that so a massive massive
investment into tooling and technology
to scale
and we see that same sort of investment
happening at a lot of the other
companies you look at Facebook I think
today thousands of Engineers work just
on software to detect changes in the
code review process automatically before
they become issues for for customers and
all this is just a signal that it's hard
and then we fast forward to where most
most of us operate and of course there's
a trade-off between the amount of
resources we spend in testing and
deploying and really navigating that
balance is tricky when we think about
software quality a lot of times we think
about the software development process
up until the point that we push code to
production and here really we just want
to make the case that if we really think
about the end-to-end lifecycle of code
so everything from when a feature and
idea is conceived all the way through
decades later for successful software
when it might that software may find
maybe sunset that's the life cycle that
we're working with and we want quality
throughout that entire lifecycle and
that's important because if we think
about it that way then we can think
about what production is and just be
honest that production is a really
important part of our lives as
developers and as engineers and that
testing and production which I think has
always gotten a bad name but it's an
incredibly powerful technique to help us
build quality software if we could test
our software in production we could
prove to ourselves that our software
works and interestingly it helps us test
software in a number of different ways
that previously was difficult let's talk
quickly about software development at
flow so at flow we have true continuous
delivery and by that what it means is
that when you merge a pool request that
code is going to production there's
nothing else standing in the way you
don't merge your code and then have a
continuous delivery continuous
integration test run that doesn't happen
continuous integration happens before
the commit is merged and it's important
distinction because we wanted to make
sure that the process by which we move
code to production is the same in
standard times when there's no stress
and in urgent times and a bug needs to
be fixed quickly the pipeline is exactly
the same typical process is a developer
open to pool requests CI runs we use
Travis when CI passes the developer has
a choice to make do I push the green
button to merge my code or not and if
they push that button that codes going
to production we
don't have any staging environments we
don't have any developer environments we
don't have any QA environments we don't
have any pre-production environments or
any environments like that by any other
name they don't exist in the very first
few months of flow it was interesting
that we were actually running code in
developer environments and then about
six months in we realized that the
majority of the engineers we're no
longer doing that those engineers are
writing integration tests and when
there's integration test we're
successful
they feel confident that they could
deploy their code and so it became
interesting we started asking people
what is it about the development
environment that's interesting oh I want
to inspect my code that it's correct
well if you inspect your code that it's
correct who's going to be there to
inspect your code three months later six
months later three years later when we
still need to know that it's correct and
so what we did is we removed all of
those things we remove the staging
environments the test environments that
the separate people verify in the
quality of the code is on the developer
to make that choice and now if you're
the developer what do you want to do you
want your code to be in production but
do you really what you want is you don't
want to cause an issue great if you're
uncomfortable pushing the button write
some tests you're still uncomfortable
write some more tests and eventually
you'll write enough tests that you feel
comfortable that your code can go to
production and by the way all those
tests are automated you push the button
your code goes to production and now if
you've done a good job we'll come to
talk on testing in production now we can
talk about which portion of those tests
are safe to continue to run in
production and let's talk about how we
can do that and so ultimately you found
that we don't run code locally and that
was that's a really groundbreaking thing
right
we just don't run the code locally and
this primarily in the API is the UI we
write we still run locally to visually
inspect but everything else is the same
if there's something that you want to
verify that we want to verify I've write
the test if the test is hard is gonna be
hard for my colleague figure out how to
make that test easy invest in that
tooling so that we can get in comfort
and then we can deploy software to
production let's talk a little bit about
true continuous delivery so last two
years of the first part of my career I
started writing software in I guess
professionally in 96 so it took almost
20 years to get to a point to experience
continuous delivery and it's amazing
it's better than anything anybody
or tells you if you haven't lived this
way to actually know that when you merge
something that's going to production all
the time safely repeatedly is a
fantastic way to operate because when
you're deploys are that real are really
that simple and reliable it opens you up
to lots of different ways to produce in
code one is what does it do so as if we
think about developers and we're all
people when we think about the
psychology of people right if we want
all of ours include myself if we want
our engineering groups if we want
ourselves to really invest the time to
write good automated tests what do we
need to do well one technique is you
remove the safeguards right and you
depend on people wanting to do the right
thing and that's really works if really
the only way that you know that your
software is going to work in production
is if you write the automated test guess
what your incentive you're motivated to
write a good automated test because you
want to know that your stuff works
assuming continuous delivery in the
design process so this is also pretty
interesting but if you know that it's
very very simple to release software
then at the end of the day you can
release software all the time and we
talked about small releases been talking
about that for a long time and lots of
organizations are doing it but now we
can talk about things like configuration
is if you can release software just by
pushing a button can a configuration
change be the same as a software deploy
as a code change why do they need to be
different and if you can actually manage
your configuration changes in the same
way as you man as your software changes
guess what it's the same visibility you
make a configuration change all of your
tests run you click the button to merge
the pr it goes into this delivery
pipeline and a ghost of production all
of the notifications you probably have
for changes in production continue to
work all of those neat monitoring
systems that tell you that a deploy
happened continue to work if you want to
see what happened in a deploy you can
see that a configuration stay changed
and all of a sudden we're managing
change in our environment exactly the
same way and that notion of seeing
things exactly the same way is also
critical to operating I think operating
this way or maybe just generally
operating in an excellent way where we
really really know what's happening the
screenshot at the bottom so head flow we
wrote a small tool called Delta it's
open source github.com flow Commerce
Delta and it is our continuous delivery
engine
what it does is it listens to web hooks
from github it knows how to build docker
images on Travis and it knows how to
scale clusters and inspect this the
health of clusters and we use AWS CCS
and then it just gives you this
dashboard that says okay
I saw something new on master I'm going
to go ahead and create a new tag for you
and get it safely into production very
very lightweight tool
it took about I think it was a week and
a half a development effort by one of
the developers at flow to get this up
and running but the key thing was to
really have the process in place that we
can have continuous delivery in place to
support the other deploys up flow so
let's talk about staging I love my
staging environment said nobody ever
ever but let's do a quick pull hands in
the room if you love your staging
environment prove me wrong pretty good
pretty good I'm going to call that at 1%
so that's probably eight people when we
think about staging environments what is
this staging environments feel great
right like we have a place we can deploy
all of the changes or just our change
and then we can visually inspect it or
we can have another team run through
scenarios to test and verify what's
going on there as we move into a
particularly as I think we move into
these micro service architectures a few
things start to happen one is that the
staging environment changes during the
testing otherwise if it takes 12 hours
or 24 hours to verify something you're
doing one thing at a time one thing a
day and it feels slow and inefficient
second is that actually it's very
difficult to treat a staging environment
as a production environment and what
that means is that if some service that
you depend on for your test that's run
by another team becomes unavailable or
unresponsive or doesn't have the
appropriate data or hasn't been updated
or is out of memory maybe an alert goes
off it probably not and that person
won't respond in the middle of the night
because it's staging it's not a
production issue and it's not treated as
such and without that what that means is
that staging becomes unreliable and more
than that it becomes unreliable in a way
that we don't know how to fix it because
it's someone else's stuff
that's running there and broken as an
analogy when I remember when we were
doing in the early days Facebook
introduced this pretty cool feature
where you could login with Facebook and
it was early days of the feature and we
integrated against it so that you can
log into gilt through Facebook and at
the time we didn't go to Facebook and
say we need a copy of all your code to
run on our sandbox environment so that
we can test the feature we didn't do
that yet when we're testing log in
against our own internal services
against our authentication service or
user service as it was called at gilt we
go to that team and we say please give
me all your code because I'm going to
run it on my staging server to prove
that I can log in and so there's a
difference right and that difference is
interesting and worth worth exploring
why we're treating our internally
developed software different from the
software that we're using out in the
ecosystem let's talk a little bit more
about staging environments so they're
bottlenecks many organizations start off
with one and then you get into a
distributed architecture and you say ok
payments team you have your own staging
environment check out team you have your
other one login team you have another
one front-end team you have your another
one and now you have lots of staging
environments and then what ends up
happening is they have disparate
failures and sometimes they work
sometimes they don't but teams are under
pressure to get their features released
and so they start hacking them to get to
the point that the staging environment
is consistent enough that they can test
the one feature that they need to get
out to prove to themselves with some
reasonable certainty that if that
feature goes to production is going to
work and even if they do that the
feature goes to production does it work
sometimes most of the time but there's
still bugs it's not a hundred percent
staging environments are fragile when
they failed they're difficult
recently I was debugging a staging
environment during an integration at the
client and the staging environment
wasn't working the way that ID bug the
staging environment is I wrote a small
Ruby script that went and found all the
log files on the system and every three
seconds showed me the top five that
changed the most because I knew nobody
was using the staging environment and I
knew that those log files that were
growing were probably errors and sure
enough I went one by one and killed the
servers because they were not able to
stop
and they were hogging all of the CPU in
the staging environment that's insane
can you imagine doing that in a
production system the key point is that
those services weren't required and it
required other teams who weren't
involved on our work to participate to
make the system stable and that is a
very very expensive proposition and I
think this is at the heart of it the
organizations that I've personally seen
there haven't been many we're staging
works commonly invest over half their
budget in staging most organizations I
see invests 20 to 40 percent of the
budget 30 to 40 percents pretty common
but those are the organizations that
have I'd say dysfunctional staging
environments it requires a huge huge
investment across the organization to
make it work and then arguably I would
say in today's day and age of a lot of
automation
perhaps station creates the wrong
incentives where staging is asking
people to spend time to do things over
and over again without automation in
most cases right because you don't need
it if you have a staging environment you
can inspect and you can release and so
our incentive to write the automation
goes down it's hard to write good
automated tests it's hard to write
automated tests they're repeatable and
by the way if we have this failsafe to
just say deploy to staging I have a few
people look at it we'll take advantage
of it we touched on this a little bit
but if you remove staging and you still
want to have good production quality
code go out then the question really
goes down to your tests and at the end
of the day this is super super powerful
right if you're not comfortable that
your codes gonna work right some tests
you're still not comfortable right some
test you're still not comfortable right
more tests still not comfortable right
some more tests and eventually if we do
that what we find is that we start to
trust our tests that we can trust that
if our tests tell us that our code is
good that we can deploy to production
and by the way if we do this lots of
other things start to come into play one
of the practices that we have at flow we
call dependence they depend on today and
dependence day is that we just decided
that all of our stuff is going to be on
the latest versions of everything our
own code our own libraries the open
source libraries that we use we upgrade
AWS every week because they're
constantly published like new versions
twice a week we're always on latest
versions and we do it
depending what dependents they does is
it finds all the versions of everything
that we use and it submits pull requests
automatically to all the services and
the bill that says green you merge and
you deploy that change to production and
we can do that and now all of our
services are current all of them across
the board without exception are on the
latest versions and the same versions
observed of all of those libraries that
we use and if you think about it's
amazing because now if you need to do
something else you can because you don't
have to worry about version mismatch or
upgrades for services that have been six
months old I wouldn't touch briefly on
architecture so quality through
architecture I think it's super super
important and there's a few elements
here but one is just this idea of
extreme isolation so as a developer if
you deploy something and you break
something you probably know what it is
and you could write pretty quickly and
you fix it and probably the impact on
the business in most cases is small
because you've moved so quickly if you
receive a page and your service is not
functioning because something else broke
your service that's hard right and it's
powerless you're powerless like how can
I run a reliable service if anything out
there can break my service and one of
the approaches to fix this is what we
call extreme isolation extremely isolate
your service from everything else
services that flow have their own DNS
they have their own load balancers if
they have a database that database is
private nobody else is allowed to talk
to it there is no shared state there's
no consul there's no zookeeper there's
nothing there's no shared state and we
really focus on this stopping cascading
failures and preventing the chance of
somebody else to cause an issue in your
service the services are extremely
isolated and initially as an engineer
you come into this it's not or will be
efficient we can just have one load
balancer do this for everybody the cost
is not in how the extra incremental
dollar is running the load balancers
it's really an understanding failure and
understanding that failure is not caused
by other people so that we can again
trust our services and drive quality one
other small detail in the there's a lot
of talk about event streaming and what
we found interestingly ad flow is we
have built in a pretty sophisticated
data architecture that's really based on
event streaming so every micro service
publishes events and other micro
services consume
and what ends up happening on the
network is our micro services don't talk
to each other the network is very very
quiet
instead they consume data through the
event stream and there's only a handful
and it turns out it's quite rare of use
cases that really require the services
to be synchronous and yeah those guys
will go talk to each other and it's in
e-commerce if you submit an order you
want to make sure that you have payment
for the order is an example of a
synchronous transaction but it turns out
those are the minority everything else
is asynchronous right so there's micro
service architecture but there's no
traffic between the services and the
reason we did that is again a cascading
failure if I'm a service and I depend on
you and you have a hiccup I don't want
it to affect me and event streams really
give us that I can listen to the event
stream and if you have an issue the the
problem in our business is a slight
delay in receiving the data through the
event streams and that ends up being a
much easier thing to manage but I think
the main thing to really focus in on
here is this notion of extreme isolation
as we architect and build our systems to
reduce the dependencies that can cause
issues on us in terms of quality or
uptime is an incredibly powerful tool so
let's look at a few real examples of
successfully testing at production one
that we did a gilt ecommerce system you
want to know that the submit button
works right can customers buy stuff and
said being a pretty important KPI and
but how do you do that you place an
order
you're probably decrementing inventory
you may be charging a credit card there
are a lot of bad things that happen and
so it turns out that in I think the
common use case would be you testing
sandbox and then you deploy to
production and maybe you set up an alert
that says if I haven't seen an order in
five minutes or ten minutes maybe
something's wrong it's kind of status
quo but what if we thought this and said
you know what let's just go submit an
order every minute every five minutes
ourselves actively let's actively submit
an order so that we know it's there what
would have to happen for that to take
place so what we did a gilt and actually
this was driven by our mobile apps
because initially our mobile apps as we
built the iPhone app it couldn't
communicate to our VPN environment which
is where staging was talk about friction
for developers you want to test the
change
you got to make your staging environment
work you got a debug it you have to use
this VPN crazy thing and then now you
have an iPhone app and now you have to
configure iPhone app onto a VPN and
that's what our developers are spending
time on instead of building automation
and building features so what do we do
we said okay let's think about this
why don't we identify find a way to
identify a test user this is great we
can even know that registration is
working right register a test user you
can even log in now we have a test user
oh great now registration is working log
in is working we can browse the site we
can put something in our cart we get to
check out we can submit an order and
interestingly all we have to do is agree
we identify test users buy a domain name
I think was guilt test com any user of
guilt test com if you place an order and
guilt com your order will get cancelled
three line change in order processing
three lines if user dot email domain
equals guilt test com order cancel bang
it's a ruby app that's it and now we can
run automation every few minutes go
through the final place an order safely
yes we've claimed inventory but we've
claimed inventory for five minutes right
and we can now start dissecting those
problems Oh claiming inventory that
seems like such a bad thing well great
well why don't we shop for an item that
has a lot of inventory cool so we'll add
a little web service that says tell me
the item currently in the catalogue that
has over a thousand units of inventory
available and let's go buy one of those
so that there's plenty left for
customers this is a really simple thing
and now we can write an alert that says
if we don't see an order every three
minutes from our test user or if that
test user gets an error of any kind
submitting the order that's a very high
fidelity alert that we have a problem in
production right and now we can take the
learnings from that we can investigate
faster we'll start faster and nothing
else changes about our process that's
understand what happened let's
understand how to learn from it and now
let's get better at what we're doing
interestingly when we look in in
e-commerce there's a lot of subtlety
about inventory and locations and things
like that
what's super interesting about this
technique is let's say that we found
that it worked for all orders shipping
to the US but there's a problem of
shipping orders to France great now we
write two tests let the user go through
production ship something to the US
great now have the user go through and
ship something to France now we're
running both tests and we can verify
forever
that this is working and know that the
instant there's a problem we're going to
be notified so this is a hugely hugely
powerful thing one other small thing
that we did a guilt so and it was load
testing we was talking to somebody
before this talk about load testing and
actually the good folks as a Lando load
testing and production is amazing it's
amazing not saying that you shouldn't do
load testing in other places but load
testing and production is amazing
add guilt if you think about guilt use
case so really Gil Gil told business
model was every day at noon Eastern a
new selection of inventory went on sale
at great prices and everything sold out
and we saw a 50x traffic increase
between 859 a.m. PST and 9:00 a.m. PST
50/50 times traffic and in the early
days of guilt eighty percent of our
revenue happened between 9:00 a.m. and
10:00 a.m. Pacific time what do you
think the cost of an error is between
9:00 a.m. and 10:00 a.m. Pacific times
high what if we do a load test at 1:00
a.m. Pacific time when traffic is super
quiet and if we identify a problem at
1:00 a.m. we've got a what is that eight
hours to fix it before it really matters
and it was super super revealing and it
feels scary but the first time you do it
you do a load test and probably things
fail in production and they probably
passed in staging by the way or in your
pre-production environment that's what
we learned and then we fix them and then
we run the load test again and then we
fix it and then we run the load test
again and then we fix it and then every
single day that load test runs and the
day it breaks we find out 12 hours
before it matters and we have a chance
at protecting the revenue for the
business overall from a system
perspective the overall system is much
much higher quality when we're doing
this with respect to flow so flow is a
software-as-a-service business what this
really means is it's a multi-tenant data
architecture if you sign up with flow
we'll give you a unique organization ID
and that organization idea is for your
production data and then if you want to
write tests you can create as many
sandbox organizations as you want the
only difference in the sandbox
organization is that they have an
attribute named environment and
environment is sandbox instead of
production that's it and now you can do
whatever you want to do with your
sandbox organization in fact we
appliance that
when they wrote their integration test
with with flow step one of their
integration tests create a new sandbox
organization add flow now run their
series of tests through the API and
their integration and when they're done
delete the sandbox organization from
flow and there's an incredibly powerful
technique because by doing that when
they create the initial sandbox
organization at flow it's an empty shell
no human or bot or API came in and
created data or change data it's empty
and because it's empty its reliable
right so they can create this
organization they can create their
product catalog they can do all the
things that they need to do they can
place some test orders and they can
delete it now what makes it safe so at
flow we said we wanted to offer sandbox
accounts so now add flow we have to
think about what are the things that are
dangerous and they in dangerous in our
world really is has an effect in the
real world we do payment processing so
charging a credit card on a sandbox and
just an Box account probably not the
greatest thing and so we have a in our
payment system there is a branch of code
that says if this organization is
sandbox then use the sandbox processor
and the sandbox processors are no op it
does nothing
it happens in fulfillment and we do
things and logistics printing shipping
labels we want to make sure that you
don't get charged for those if you print
a shipping label for an Oregon for a
sandbox organization but that's it there
were maybe two or three maybe four
examples in an Entente commerce system
where things actually had a negative
real-world effect so what did we do we
made sure that those systems understood
what the sandbox account meant turns out
that's really really easy to unit test
create an organization make sure that
payment works create a sandbox
organization make sure that payment
doesn't go to a third party
bulletproof unit tests we can deploy to
production and now every single client
of ours can use sandbox accounts there's
a detail here about one API key for all
sandbox accounts and this is something
that we just learned at flow where when
our clients were integrating and they
want to create a new organization one
way to do that is you create a new
organization and then you have to get a
new API key we just made sure that their
same API key would work for all of the
sandbox organizations that they're
running so every hour when they run
their integration tests themselves they
don't have to change
their environment variables for talking
to flow there's a small detail but one
API key to run these integration tests
the learning here is to treat every
service as a third party whether its
internal or external and it's a really
really powerful cost of so back to
Facebook and Facebook login we don't
have facebook to host their code to run
it we just test using Facebook's api's
and they have test the api's or sandbox
accounts payment processors like stripe
give you a test account in a production
account and we use that we don't ask
stripe that we're going to run all your
code or our infrastructure to test and
this same concept turns out to be
relatively straightforward to apply to
the own software that we're writing
internally if our teams develop a
contract and provide for it
here's a live example of an integration
test that we run regularly this now runs
once a day travis has a cron feature I
think the most frequent in Travis is
once a day so this runs once a day this
is a little Ruby script using the flow
api to go and create orders and this
basically says order equals create order
or some parameters different countries
then go create a payment authorization
using a credit card token and then go
ahead and capture funds against that
credit card authorization and you can
see the history it runs about once a day
so this is a really nice test it runs
once a day if this fails we know
immediately that there's a problem and
we've invested the time to make this
test reliable which is worth saying
first time this went to production I'd
say it took us about three weeks until
it was green every day because we
uncovered issues along the way right we
ran out of inventory or whatever normal
validation is just took us about three
weeks not three weeks full time but
every few days there's a new issue
uncovered and then we fixed it until the
point that this thing runs every single
day and I think now we have about a year
that it's just stayed green we know
every single day we can accept orders
and process payment super super powerful
we know that when we deploy changes to
our payment system we can trigger this
build and make sure that these tests
continue to work against the payment
system we know when we deploy our API
proxies and change API routes we can run
this integration test and know that the
heart of the system continues to work is
incredibly calming I think is the word
to know that things are working as
expected
here's another example so at flow we
wrote our own reverse proxy which is API
dot flow at i/o and it makes all of our
micro-service api's feel like one
handles authentication handles weird
things like JSON PE and requesting
envelopes a whole bunch of other stuff
this is a critical piece of
infrastructure for us if there is an
error in our API proxy all of the API is
become unavailable right so this is a
central point of service earlier we
talked about extreme isolation in our
services the API proxy in our case ends
up being the thing that has no isolation
like this thing goes wrong it is a
cascading failure across flow it's an
emergency
but by virtue of knowing that this works
in two relatively small piece of code
then we can really drive extreme
isolation for all the other services so
now when we make changes to the proxies
dangerous how do we test those services
proxy has its own tests mind you but how
do we really know that a configuration
change or new feature continues to work
so here's an example of what we do this
is running its AWS profile go grab our
configuration for the AWS account flow
vault which is where our PCI environment
dev is a go script that our developers
use that handles everything for
developers at Flo Scala app so SBT and
production so go get the production
environment for the reverse proxy but
run it locally so now I have on my
laptop running our reverse API proxy
talking to all our production services
and then I can run tests locally and
instead of hitting API fluid out i/o I'm
hitting localhost 7000 and then capture
the output that the tests pass and these
tests do all sorts of things they're
basically for all the features that we
add into the reverse proxy we had a
little test to verify that it works if
you mistype something is the error
message good if you I don't know if
you're doing JSON PE with a complicated
URL string does it get parsed correctly
into JSON body and forwarded to the
right service or the right response
codes all those things and then we can
run it and verify it here we do this all
the time right because now even before
we touch production we can have the
latest version the software running we
can run all the tests and now we can do
everything else that we do great
all the tests pass let's deploy to
production in fact let's deploy to one
node in production of canary great now
that the canary is running let's run the
test against the canary great let's
monitor the canary is everything working
on the canary yes let's roll out to the
rest of the cluster let's run these
tests again and by the way we can
schedule these tests and run them every
single day as well and know that the
proxy server is working one of their
side benefit reverse proxies have a lot
of features in them and it's interesting
to think about the complexity of our
test code some tests are hard to write
when you're inside the code base and
much much easier to write when you're
inspecting externally an API proxies end
up being one of these things it's very
easy to just talk HTTP to a server and
check what the HTTP response is so
actually by introducing this way of
testing we were able to simplify the
tests that run against the proxy and
ultimately this is what we're after that
everything is operating as expected and
if it's not that we would know right
alas sometimes things go wrong
even to the best of teams he hasn't
quite yet mastered the art of the diving
header this one says and so let's talk a
little bit about how we handle that and
what some of the considerations should
be so what is that we make production
access to explicit not the default right
so we really think about this and we
think about this from the beginning from
the design phases we're building the
next feature like let's think about from
the start how are we going to write
tests that run in production which this
feature is live or said another way if
you imagine you're about to deploy a
change once that change is deployed
great engineers will go verify in
production that it does the right thing
right they'll go look at it well now
think about how can i aughtta mate what
I would verify can I do that can I write
a script that's gonna automate and if I
can great because now I can deploy my
software I can run my verification
script and if it succeeds great I can
think about scheduling it and if it
doesn't I can quickly roll back probably
faster than I could before because I've
already thought about from the beginning
how I'm going to verify that my software
is working second is to use defined
paths if you have an API use API calls
and this is opposed to just reaching
into a database in production and
changing some data to enable some use
case the idea here is to
use the defined paths however your
software works in production use that
don't invent a new way use that there's
a classic
in classic case I'll call it a case is a
would call production event a friend of
mine was describing and they were
approaching their peak season and said
we got to have more servers and we
should deploy less frequently and maybe
do a code freeze or something like that
and so a week goes by everything is fine
and week two things start crashing and
it turned out they had a memory leak for
years but because they're continuously
delivering their software it didn't
matter and they changed their mind they
changed how they were managing
production and new issues surfaced and
that can happen here and so I think the
solution to that has to really not
change the way we work with production
we work with production a very certain
way as we conscious of that not change
it working that way and then iterate
slowly and deliberately sensitive data
comes up quite a bit
HIPAA PCI PII there's new regulations in
Europe and I think just thinking about
these things up front is just important
here we show you an example of a
production test that was actually very
creating credit cards verifying credit
cards authorizing capturing funds you
could do it it absolutely works in our
case the solution here is just to use a
test credit card and make sure that that
test credit card was threaded through
but it's just worth some flagging and
thinking about from the beginning and
designing for side effects there are
lots of side effects there side effects
all the time the common ones that people
run into are things like I'm running an
a/b test and now all of a sudden I have
all these test orders which has happened
or my a/b test results valid things like
that will happen and just good to think
about those upfront the two broad
solutions are either cleansing data
right you've created the data you know
what it is you can cleanse it or to
making sure that your own data that
you're injecting is random and normal
and if it's random and normal then in
general the impact for those sorts of
things is factored in it's negligible in
terms of an impact on the business I
want to touch on a few unexpected
benefits of testing in production one is
what we call perfect perfect
documentation really perfect so I hate
as a developer going to a doc side
cutting and pasting the example then
having it not work
is infuriating so the way that we solve
that problem at flow is we actually just
capture the request in the response as
part of our production testing right
we're testing this stuff all the time
so why don't we just add a log to our
tests that captures the request that's
being sent captures the response at the
end of the regression test if it's
successful it uploads that to s3 and we
have a tarball with all of our examples
when when you release our documentation
site it downloads the latest tar ball
and pulls the examples from that right
so we know that the examples are real
cures are real and this is just an
example of that so quick curl command on
the Left we captured the request that
was coming in on the right you can see
the output we have a very organized file
system it's a RESTful API and so
resource / method / path and then
response that JSON requests out JSON
this is actually the contract for a
documentation site we produce a
directory we tar it we throw it in s3
and it has a standard format so that it
can get merged into our documentation
it's amazing second I think great demos
so we are an enterprise software company
we do demos one of the things we'd like
to demo is our analytics page a long
time ago our analytics page had no data
because nobody was using our demo store
to buy stuff so what do we do the
earlier automated test that you saw that
runs and creates a few orders it's
actually using our demo account and that
straight line that you see everyday
places 10 orders and so it's been 10
orders the spike that you see that's me
just getting some more data for this
talk over the last few days right it
went up to 30 because I must have run it
a couple extra times in November 11th
and a November 12th I read an extra-time
real data and now we're done
every single day we're producing data
and that we get to use it for a demo
it's great it's real I want to touch a
little bit on tooling we depend a lot on
something called API builder IO if
you're familiar with G RPC and swagger
and things like that think of and github
best to describe it
think about API builder as like G RPC
for JSON or JSON is truly truly
first-class
some people have said API builders like
github for your api's where it gives you
incredible visibility into your changes
what's breaking what's not incredibly
high-quality mocks and clients and so
what's actually happening and this is
really really important because
ultimately to make some of this stuff
work you have to really trust the
contract if you're if you have a micro
service architecture with a lot of api's
you really need to make sure that
develop different teams trust the
contracts that the other teams are
publishing
if using GRP see in your binary lend you
probably this probably already the case
if you're in JSON and using some of the
other tools that probably is not the
case that the publish documentation or
specification of an API matches what's
actually in production but it's really
really important to have that and so
maybe API builder is something we
started a guild for five years ago it
interrupts with swagger and Avro and
some of the other things but provide
some really really nice tooling we do a
lot of mocking at flow in our
integration tests and also actually have
so a gilt and here's an example of what
API builder provides so what you can
download from API builder is a mock of
an interface of any one of the services
or the event streams that are flowing
and that mock we scholar that mock
compiles and it knows how to generate
valid data and then what you can do is
very easily just override the parts that
you want and so an integration test as
an example that this is a geolocation
test that basically says for this IP
address return and/or the address that I
want the code on the right is all we had
to do in terms of the mock to know that
it works and because the contracts are
guaranteed to be correct we know that if
the mock passes it's going to work in
production and actually our experience
over the last few years is that this has
been the case we don't have situations
where things work with the mocks and
then fail in production and the only
caveat to that is authentication but it
has never been the case so we can trust
our mocks to that point because they're
generated in the same way that our
clients are generated that if our tests
are automated tests working into the
mock they will work in production so
that's API builder we use this tool
called vivid cortex on the database side
incredible real-time feedback on what's
happening in your databases and in this
particular
case it's just highlighting an index was
created very quickly you can see that a
query did not improve and then queries
four six seven you see the variability
in response time those queries got
slower but the important thing here is
on the data side to also have responsive
real-time feedback in terms of what's
actually happening so that if something
does happen that's unexpected we know
right away Vivid was a tool was
introduced to about a year ago and has
it's proven to be fantastic as made it
into the I'd say daily developer tool
chest at flow earlier today the talked
prior Sara mentioned the importance of
consolidating logging we also was one of
the early things we did couldn't agree
more she uses spunk we use sumo logic by
the end of the day every single log file
from every single service goes into a
consolidated view that is fully
searchable and then within here they
have kind of a nice tool chat to the
tool set to define alerts so in real
time anything matching this query
deliver it to pager duty or deliver it
to an email and what this means from a
developer perspective is that all the
developers as we as developers have to
do is just log things in our
applications and somebody else is
responsible for getting those things to
us so a few key takeaways one trust your
tests and run them in production maybe
not all of them but run a subset in
production all the time and then to come
back to the beginning will know that the
software that we deployed is working not
just when we deployed it but today
continuous delivery invest in it
leverage it fantastic for all the
reasons of we we know small changes easy
easier to know what's happening with
something's not happening is expected
fast rollback but also it just changes
the way that we design our systems in a
fundamental way there are plenty of it
techniques to invest in so we talked
today about sandbox accounts mocks but
there's lots of techniques that we can
use to improve the quality of our
automated tests so that when we reach
production things work as expected
and finally just instrumenting
production for real-time feedback for
the cases where things don't go as
expected and with that i think we have
just a few minutes for a few questions
if you have them and thank you so thanks
for such an inspiring presentation and
my question is how do you test your data
migrations do tested in production so
the questions how do we test our data
migrations interestingly on data what we
found well first of all how many people
write rollback scripts for their data
migrations is that like a practice you
guys are all wasting your time
stop doing that it doesn't work and if
you don't trust me think about the last
time your rollback failed probably
because the data in production had a
different network latency or the data
size was bigger than what you tested it
on and you've just created a crisis and
the crisis is amplified because you
thought it would work and you're not
prepared to deal with the consequences
of it not working so frankly my
suggestion on data migration on that
side if you're really going to go with a
rollback strategy you have to have a
cluster of data separate that you can
practice on that has the same size and
characteristics and same load as you
have in production and if you figure out
how to do that I want to come to your
talk because I don't know what we've
done at flow and a guilt is we decided
that you cannot have a breaking schema
change at the data layer and also in the
event layer flow you cannot do that you
just cannot that's cultural we just
decided you don't do that so what you
have to do is make small incremental
changes and we have no automation around
it when you deploy your database change
you're actually logging in to a
production server and you're applying
that change and we try to do that you've
gone through all your testing and
everything else
you're obviously in a position where you
think this is going to work you've run
your tests ideally against both versions
of the schema but when it comes time to
applying it that process is fraught with
peril and so we actually remove
safeguards it's a human process you're
doing something that is dangerous let's
put ourselves in that mindset and then
be as careful as we can and be as a
responsibility can to come back that's
what we do I think it works in practice
I wish there was a better answer but at
the end of the day that's what we found
for for data anything yes sir
my question is that many times you run
into problems with the data which is
coming in the production service from
the users so and it's it's sometimes
hard or you are not expecting to write
tests for those kind of data it's
something unique about a user or
environment something so have you have
you think thought about anything using
real production data and using your
tests with the data or something similar
yeah it's a great question so we do a
couple things with production data
number one actually this is really this
is great this is amazing it just went
into production so I'm super excited our
API proxy receives a request for is it
to the back-end receives the response
and checks the status code the HTTP
status code and then looks up the
expected status codes against the API
builder specification for that API and
if the returned response code is not
expected it logs a very verbose warning
actually it's an error now it triggers
pagers it says I got this risk I got
this request and the service returned at
202 I was expecting a 201 and it logs it
and we have a library that does very
good
sanitization of data again based on the
API builder specifications so now what
happens is when that happens a pager
goes off and we've captured the request
data from the client and the response
data from the server in a secure way so
we can we can actually usually diagnose
the issue immediately now step two is
now we have to decide what to do for
sure we're gonna put that into a test we
have a practice that when something
happens in production we write a test
somewhere right it might be a test that
runs in production it might be unit test
might be an integration test don't care
but write the test and then second in
some cases we've built tooling to say go
back out and get sample data that was
interesting and then run regression
tests over that and that ends up being a
pretty interesting way to to converge
pretty quickly great right sorry where
we go here Justin you mentioned that you
starting with a clean slate from gilt to
flow do you see any kind of restrictions
if you're not starting with the clean
slates on thank you that infrastructure
so
it's a great question I'm gonna rephrase
that as have you learned anything with
the flow experience where that could
have helped in the guilt experience of
migrating to this sort of development
given the parameters of a very
successful company with everything that
comes with that right so there's a few
things one continuous delivery like
really really nailing continuous
delivery to actually having one way to
do things so I didn't talk about this
here but at flow we've decided we have
one way to do things we have an event
processing pipeline somebody came up
with a better idea and improve something
somebody else has yet another idea that
person has to wait we've got one idea in
queue either we move everything to new
idea or we discard a new idea and go
back to the way that we were we have one
way of doing things we only adopt one of
the way one of the mistakes now you can
see I think mistakes in hindsight one of
the I think mistakes we made is we had
multiple ways to deploy code we had
multiple ways to provision code we and
those things start to pile up and today
in a world where we have
containerization and docker and all the
tools available in the clouds there's no
reason for that there should be one
pipeline to production that handles all
of the variety almost all the variety of
the services that we're writing it's a
huge huge point of leverage and then
finishing it like really finishing it
and being disciplined to finish it and
not getting distracted by whatever it is
the you know we have a huge opportunity
a new partnership all the shiny things
that drive revenue for a business just
have the discipline that somebody stays
focused and drives us think to
conclusion so again we have one way of
doing things and really understand how
the business works I think have been
huge things and with that we're out of
time I'm happy to take a few questions
after but I just want to thank you for
joining us today</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>