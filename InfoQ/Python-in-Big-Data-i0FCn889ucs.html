<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Python in Big Data | Coder Coacher - Coaching Coders</title><meta content="Python in Big Data - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Python in Big Data</b></h2><h5 class="post__date">2012-03-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/i0FCn889ucs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay welcome it is nice to see over here
thank you for making the trip and sort
of so much short notice but I really do
want to thank you for being here I hope
we have a good discussion today I just
came back from the strata conference
where there are a lot of people talking
about big data and analytics and things
I've been doing for a long time
basically with Python and there wasn't
enough Python there right so that's
that's essentially my frustration and
one of these we're trying to figure out
why and figure out how to fix and so I'm
glad everybody's here and want to also
give a shout out to the folks that Peter
mentioned Julie Steele was very helpful
when the idea for this conference was
hatched she's very very helpful giving
us the facilities getting us the
location at done bill was on some calls
as well he was organizer the strata
conference really helped us out to make
this possible and then I want to give a
shout out to Peter Wang he did a lot of
work making this happen we can give a
round of applause to Peter degrade
thanks to her he's uh he's a force of
nature if you get a chance to interact
with him it's a it's a real treat he's
got a uh but somebody said you know
usually when you listen to somebody just
talk all the time you get really bored
you don't get bored talking to Peter I
mean he could just listen him all day
long and he has something interesting to
say so most of that is relevant to
Python so it's pretty exciting
I'm excited be working with him a
continuum so like I said I just got back
from the strata conference and talked
about it a little bit some of you might
have been there let's sit raise of hand
if who was at the strata conference okay
that's great I mean the whole the hope
was we'll be able to get some folks who
are at the strata conference to come and
work together and talk about pythons use
in similar areas so at the strata
conference you know it's Hadoop all the
time Hadoop everywhere and you're just
drown in Hadoop and and then are on
occasion on the back of the doop
everywhere and in Python you don't
really know where it's being used of
course if you go talk to people you
realize it's everywhere people are using
Python they're using the tools to do
but then it's just not done really have
a big boys big name so that was you know
why is that hopefully we'll talk a
little bit about that during this
conference there were some interesting
talks I spent a lot of time in our booth
actually talking to people coming by and
actually just kind of receiving people
who use Python and who wanted to come by
and talk about how they were using it
and maybe they could improve it but I do
remember Doug cuttings talk and he had a
quote that said Hadoop is the kernel of
the new distributed OS that sort of
caught my attention it's the first time
I'd heard somebody in a talk say
something that I've been thinking about
for a while that yeah in fact when you
talk about an enormous number of
machines there is this need for an
operating system or some way to
communicate an application to
communicate with all those machines with
seamlessly so you're not worried about
all the details of configuring that
system and in that sense Hadoop has sort
of emerged as this big player in that
kernel but from my perspective that's
not the kernel I want to be using that's
not the kernel I want to be having to
interact with and I'll explain why in a
little minute in a minute and Michaelsen
the CEO of cloud era gave a nice talk on
guns drugs and oil just basically
showing use cases of big data
you know big data has a bit of hype
behind it for sure but at the core is
this idea that we've got commodity
Hardware at your fingertips the ability
to do analysis on a lot of data and
there are a lot of big problems where
people need a lot of data in order to
make decisions that improve all of our
lives so it's an exciting signing time
to be associated with some of these
problems one of the interesting talks I
saw or heard about actually was Google
of course is that they're always on the
cusp of big data in some sense it's
because they're commoditization of the
data center that we have the notion of
big data and the kind of ability to use
commodity Hardware in a unified fashion
but they uh they've been pioneering
using search terms to track things of
course you've all heard about using
search terms to find outbreaks of
disease people searching for medicines
there's another talk on the market State
people searching for terms related to
ello you know looking for unemployment
benefits or something or you know house
prices you know people searching for
houses
you can actually there's some research
that shows you can predict the state of
the market or trends in the market based
on Google search terms
the interesting aspect interesting
application of big data and then another
talk that I really like because I saw it
relevant to a lot of people I have
associated with in my life is the sigh
TV talk but it also opened a few you saw
it helped me see that there are some
real things we need to focus on the
Python community to to ensure that
Python stays relevant as the March to
big data emerges so if those who aren't
familiar with just how many areas of big
data these are ones that came out of a
blog big did is the answer what was the
question it's really nice blog actually
and he lists a bunch of use cases which
is exactly the right way to think when
you're thinking about big data you don't
to think about Big D in the abstract
until you've actually tackled the
specific use cases like this is what I'm
actually trying to solve and it's got a
lot of data and here's the problem
trying to solve and there's a there's a
bunch of them this is one he listed
retail telecommunications utilities
financial services but you know he
didn't even cover the areas that I would
say if you talked about big data
you know what would I come up with big
science the data collection from CERN
astronomy bioinformatics weather and
remote sensing now is that the American
Meteorological Society convention where
people have sensors all over the planet
not just in the air looking down at us
through satellite but they've got
devices measuring wind speeds and
barometers and pressure sensors all over
the place and all those data they've
been trying to figure out for a long
time to predict weather but this or a
started big data there are heavy Python
users right and that their use of it
doesn't really show up in a lot of
radars so weather remote sensing
research experiments in general iBM has
a sense of the planet notion it's been a
lot of time in New York last year for
better for worse a lot of time in
Manhattan racked up JetBlue miles so
that my wife could actually come visit
me now she's gonna fly out for free on
JetBlue into San Francisco because all
those miles but every time I walked into
the New York Airport I saw IBM's posters
that said you know make the world a
smarter planet right by essentially
putting sensors everywhere and taking
those data and making predictions try to
do traffic flow trying to
disease trying to detect better food
manufacturing and then of course you've
got oil exploration and industrial
processes these are projects that I've
personally been involved with while
working for and thought and actually I
wanted to make sure give a shout-out to
n thought I think Peter mentioned it but
they were very gracious to provide the
the epd trials for us so that we could
get it all Python installed in
everybody's computer very quickly so I
wanted to make sure and thank them and
while working friend thought I had a lot
of chance to look at a lot of companies
big data problems they don't advertise
themselves as big data problems but they
are in fact using a lot of data to try
to answer important questions so in
particular some of those places where
Python is being used for big data oil
exploration a lot of companies this is
there's a diagram when they're showing
seismic seismic information is captured
many of you probably aren't familiar but
it's a pretty simple process you have an
air cannon you explode sound waves down
into the ocean it bounces off layers in
the ocean sir under the subsurface of
the ocean and you take a huge train of
sensors in the back behind that air
cannon and just record the sound coming
back from the different surfaces it's a
pretty raw data set and from that data
set you're trying to infer what are the
layers under the ocean you know based on
the speed of sound you know when the air
cannons shot you know when you're
measuring the sound so you kind of know
if you get it this time it must have
bounced from this layer and was a signal
amplitude you can infer okay how much
was transmitted you have to basically
unravel this all this data into this
picture of the ocean floor to try to
find salt domes shale layers places
between sand and shale or oil will
accumulate you're looking for oil big
deal you see whatever tool they can find
right to do this it doesn't matter no
but there's there are no language bigots
when you're trying to solve a problem
right you just want to use your tools to
solve your problem it doesn't matter
what it is but pythons in use there's a
lot of people using Python and and in
sort of why is that is an important
question an important question we should
continue to consider on Wall Street
there's a lot of large banks using
Python there's a lot of hedge funds
using Python to
under understand their tick data
understand pricing data and make a lot
of decisions about it I actually have
somebody here lino work had a chance to
work with on Wall Street solving a
counterparty exposure problem you know
everybody's aware of the big problems
that occurred in 2008 when the market
crashed actually some of the banks did
pretty well because they had some
semblance of a notion of what their
positions were when all the positions
start unravel and people start going
bankrupt and people knew how they would
be impacted by people going bankrupt not
everybody did its Lehman Brothers you
make sure they ask though we know that
people would try to find out what's
going to happen if these guys go
bankrupt and actually they didn't really
know it took them a while to figure that
out and you know day before they were
run out of money is when they figured it
out so you know exposure to companies
going bankrupt when you've got all these
deals and complicated transactions
between those figuring that out and and
you've got transactions happening
thousands of transactions happen today
hundreds of thousand transactions happen
today what does that do to your net
position and how is it changing
important a real data problem big data
problem and of course the genome
bioinformatics huge amounts of data
being generated there and pythons in use
so how do we get how does Python swallow
the elephant of a Duke that's uh it
actually is in many ways this I guess is
my reaction to all the all the hype that
I saw yeah past couple of days
not and I don't want to take anything
away from who oops a great project and
it does a lot of things really really
well and it's paved the way and it's
it's being used in production it's
really exciting to see companies like
Microsoft and Oracle kind of jump on the
open-source bandwagon and use tools that
are available everybody and get them out
so that's you know the important thing
is solving people's problems but I do
have a couple of questions
I heard that Hadoop is the distributed
OS and it's a de facto standard okay why
is that why is that why does our use so
often data analysis right we all know
that pythons a better language so why is
our use so often right and this is so
there's a quote I heard from a very
large company they came over and said we
actually use Python all the time Python
a non-pilot time and I said they said I
use Python and
I to do all my data prototyping my data
analysis prototyping and I deploy to a
Java Hadoop production system right and
I okay that's frustrating to me it's
frustrating me for a couple of reasons
why why should I care right well there's
a company called LexisNexis that makes
they've actually been making a lot of
money selling data analysis for lawyers
like legal studies and and searching
patents and searching all kinds of
people teams of lawyers looking at
rulings and trying to pull out relevant
pieces of that in order to write a
database to other lawyers so they can
search them and even making a lot of
money doing that and they spot out a
company called HPCC high performance
computing and a bunch of people they are
wrote a data analysis platform data and
a platform so you can use commodity
Hardware put your data out there
everywhere and and then have a
relatively straightforward language to
query it and to do analysis on it they
were at strata enforce as well and their
engineers we're basically they turned to
their CTO and said you know if we don't
do something five years from now we're
all going to have to write in to do if
my boss comes to me I've got this tool
that works it's amazing it's wonderful
but my boss gonna come to me and say hey
how come this isn't Hadoop right and
they're gonna they're going to be
frustrated like what happened so in fact
they took some drastic measures they
released HPC see it's on github and go
to github and look at their entire code
base it's all there open source of pero
GPL but it's all there so that was their
answers like hey here's some tools let's
push it out there I was a little bit
cheeky perhaps I tend not to be too
cheeky on Twitter but this is but during
the conference somebody was talking
about Donald Rumsfeld's famous unknown
unknowns right here the known knowns
don't unknowns well that's uh you know
that's a contingency table there's this
there's no known and known unknown
nobody talks about the unknown knowns
right the things everybody knows about
but nobody's talking about right and so
and that that's what I felt like it
started a little bit is all the unknown
knowns there's a lot of ways to do this
beside this kind of the way that's being
product produced all right so what why
does it matter why Python the end of the
day
I have the same feeling right I want I
don't want to wake up in fact it was
just last year I saw kind of the rise of
MongoDB a lot of people using MongoDB
and to write a stored procedure in
MongoDB you whip out your JavaScript and
start plugging away in JavaScript and I
thought you know I don't want to wake up
five years from now and have to write
JavaScript right in order to do my data
analysis I didn't mean it's just it's
like there's so much we've done to build
- that allow Python to be used simply
for data analysis and yet in a in big
data in moving code to data where
retrograde we're retrogressive we're
trying we were now using sort of less
and inferior languages to do it so
that's one of the strengths of Python
why have we seen Python actually be
pushed and be used
Robert Kern who many of you know from
the scientific community has a great
quote when he wouldn't ask when you ask
him and you know rot if you know Robert
Kern you've met him he doesn't mince
words he doesn't just he doesn't sort of
talk to hear himself talk
in fact if you ask him a question he
loft me just pause and stare at you for
about 30 seconds while you're fidgeting
I know I said something dumb and he'll
come out with a reason response when you
ask him you know why why do you spy
thought he says it stays out of my way
right it's not I'm not fighting with the
syntax in order to do what I want to do
I think that's that's beautiful exactly
right the syntax stays out of your way
the fact that Guido who's here with us
actually that wrote Python is a teaching
language I think is really significant
it was meant so people can understand it
and that's actually been the reason why
it's been it's it's flooded the
scientific computing use where you have
domain experts you have all this stuff
in their head they don't to be also
thinking about point arithmetic and hash
tables and what's the difference between
a b-tree and a KD tree and how do i you
know unravel you know they just want to
write code that translates what's in
their head to the computer as quickly
and efficiently as possible and then
python has be partly because of that
syntax it has unparalleled integration
across technology pythons been the
ultimate glue language right that's why
scientists have used it for now 1517
years because it
allows them to reuse their code they
don't have to be siloed oh I got it oh
if I want to use Python now I've got to
go over here until the Big Data movement
I guess that's kind of what I'm noticing
and then it's got this kitchen sink
included ecosystem of outstanding tools
I mean Python distribution comes with
batteries included but if you look
beyond just the standard library there's
an enormous number it's just I mean
you've all had that fun with Google
going hey I want to do this search for
it in Python and what do you know
there's probably three or four packages
that at least are in the direction of
doing something like that
and then a very vibrant community is as
illustrated by this conference I mean
the fact you can basically make
basically tweet that we're gonna have a
Python data hack night and 100 people
respond within two days that's not that
there's a bunch of users out there bunch
of people who care but people who are
trying to make things better all right
so I know some of you are unfamiliar
let's actually raise of hands who has
not used numpy okay sorry me that was a
wrong question make you kind of yeah
sorry I haven't
that's who uses numpy every day raise
your hand they're looking okay so
there's a there's a few folks who have
used it probably heard of it probably
didn't realize it's on your Mac laptop
if you just type Python you can import
numpy so it's distributed with OS 10
I'll give a little overview of what
numpy is in a little bit of history I
mean I've given talks in the past I've
talked about the history of numpy in
sci-fi this is just a just very brief
actually you know Jim Fulton
I credit with the introduction of the
matrix object into Python in 1994 he had
a little post to the matrix sigla stand
kind of said here's my matrix object for
python and it was python only syntax and
he any real test matrix object it was
pretty good and Jim Dugan and look at
that he was a grad student MIT at the
time and said oh cool I mean showing the
power of code for sharing and code reuse
these two had never met they don't know
each other but they knew each other
because this community and Jim said I
like that and so he took time off his
research schedule or whatever schedule
he was on and wrote numeric
and road numeric and did some amazing
things when he Nerdist the concept of
you funks eBay and in doing so as we'll
see later he learned from other
languages before him so I wrote in
numeric that came out in 1995 I showed
up because I showed up because numeric
existed I started using Python because
numeric existed if it hadn't existed I
probably still be I don't know probably
in grad school still I'm my wife might
be happier might still be in Rochester
Minnesota as a research associate at
Mayo but it you know as I started get
sucked into the community write a lot of
code realizing okay I was excited about
sci-fi I was excited about reusing
Python instead of MATLAB but realizing
they need to be packages still and going
out there's a bunch of things that do
the job but how do we pull this in and
wrap it in a Python in the process of
doing that is there's people say well
the American will need some work there's
some things I'd like to see in it that
aren't there and number a started to be
emerged as a solution in 2001 that's
tended to split the community which I
wasn't happy about I'm kind of I like
people to work together I mean the end
of the day I like I don't I don't like
seeing I think it's useful to have a lot
to have different approaches but if you
can share let's share right that's kind
of the perspective so in 2005 numpy was
released and fortunately it's kind of
become the array package that people use
for Python now it's actually an ancestor
gotta give a lot of credit to Ken
Iverson the 1964 Ken was I think one of
the first people who recognized the
power of writing array oriented syntax
right rather than forcing people to
write for loops and in and take a
programmer who's thinking about just
matrix operations it goes beyond matrix
operations but imagine that rather than
thinking I want to be a times be having
to go okay now I want to for loops here
and one cross for loop here once you do
that and then that's what you handle the
compiler you actually lose information
the computer could do a much better job
with the high level information that the
domain expert the person who knows what
they're doing can provide can recognize
that wrote a language called APL which
is has many descendants actually MATLAB
and M pile and Allah
from APL the problem with APL is the
syntax it was really nice idea a vector
vector expressions but the idiot but the
syntax was really difficult I like to
show the syntax with this Conway's Game
of Life I hope who's seen Conway's Game
of Life raise your hand I hope I don't
have to explain it too much you know the
dead cell comes alive based on the
neighbors around it interesting patterns
emerge it's one of these you know first
simple rules lead to complex emergent
ideas so in one line you can write
Conway's Game of Life in APL right so
interesting hieroglyphics yeah you need
to reset a stone to figure out what the
heck that is it's worse than pearl right
I mean I was just talking about dinner
last night with somebody who said he
wrote Perl 100,000 lines of Perl went
back to D or later had no idea what I
was doing worse took his graduate
student and had no idea what they'd
written previous day just I mean again
syntax matters and there are really nice
ideas there but it's really hard to come
across in numpy it's a little more
verbose but it's still pretty compact I
mean there's some initialization code
that I showing there but that's you can
implement Conway's Game of Life
basically by iterating on this update
step which is you know two lines using
array oriented primitives right so you
don't explicitly describe the four loops
you just describe what you want to do
and that's that's the idea of a ray
learning programming the numpy array
really is a header describing a bunch of
homogeneous data right so that
homogeneous data is interpreted as an N
dimensional array based on shape
information in the header and it's also
that every numpy array starts with a
contiguous chunk but a particular numpy
array may not have to be a contiguous
chunk if it's been sliced if you've
sliced out a version from another one so
some parent of an umpire ray is a
contiguous chunk but the one you've got
ahold of might not be so there's there's
something called strides information
that provides that the other thing the
numpy array provides is this data type
object the data type object allows you
just it just describes what's in that
memory region for every element and if
you're used to a MATLAB or IDL you're
familiar with float six floats or in
soar complex numbers as your datatype it
starts to get a little interesting for
general data analysis when you see the
data type can be anything data type can
be an arbitrary structured array it can
be arbitrary nested array it can be a
string and a float and then another
array inside of it and it gets you it
gets sort of kissing it's gives you your
your taste buds wetted for this ability
to all kinds of data analysis now
there's it doesn't get you all the way
there but it gets here it gets you
started to think about why I could
really use this for also some incredible
things but the essentials of numpy are
that is a data structure that numpy end
the array object that allows you to do
the slicing basically I can map a
description over data and then access it
with slicing and pull out columns plot
rows pullout fields and just do all
kinds of nib relations at a high level
without thinking about writing for loops
and interacting with individual
individual pieces of memory the other
piece of numpy that so that's it's
essential core is the fast math it's got
sums reductions array math you can just
type an array plus an array and get a
result just I just want to show briefly
for perhaps those who have not done this
kind of what that might look like
right and you can feel free to do this
on your it with your distribution as
well so the pylab just brings a lot of
things in the namespace something like
linspace which lets me go like this and
then I can basically compute a sinc
function if I plot that you see Figure 1
I've gone nearly far enough to be
interesting alright there we go a little
more interesting right and then I can do
things like I'm going to create a plot X
where Y is greater than zero and Y where
Y is greater than zero with a red dot
right
it lets me do this sort of thing where I
can do array expressions to grab out
particular elements plot those
particular elements y greater than zero
if you kind of unroll what that's doing
it creates a mask array of boolean's
then you index with that masquerade to
extract just those elements out you
could see how the syntax supports it
actually one of the reasons numeric was
successful I think is because Guido did
a lot of things to support in the syntax
things that were needed by numeric you
look specifically at complex numbers
complex numbers were added at an early
time and that was a huge hugely
important thing for it to be useful for
scientific computing to language support
for complex numbers molten metal slice
syntax for a long time it was this
extension module that exists it was the
only thing that didn't used
multi-dimensional slice in tax right and
what that really amounted to was just
simply allowing not having to put
parentheses around tuples just in the
set item or the get item allowing a
tuple to be constructed just with commas
all right so that's very briefest
overview if you haven't seen it before
kind of what I guess we can you know the
slicing
you can pull out a slice I can go from
10 to 20 and just pull a piece of that
out I can step step through every second
and you just pull out pieces of sarey
very very quickly and then do operations
on this array x 2 add 10 in place to
just those elements and that's the sort
of thing you can do at a high level with
with numpy so numpy array has different
methods it has a shape item size it has
what's called this d type this d type
turns out to be a very important concept
for numpy the d type is the kind of the
element here this syntax it shows us a
little endian floating point 8 byte
floating point date theme types can
actually be big or little-endian that
was a feature that allows d types to
just memory map over over data where
that data might be stored in big-endian
or little-endian format and so it's
seamless you can just map your
description on top of the data and then
when the processor does the work it does
the by swapping behind the scenes for
you there's actually some interesting
ideas about how that could where we go
with that a little later the memory
model I think I'll skip for now array
slicing we talked a little bit about but
the the big deal about numpy that is
some most people love it a few people
early on say oh this is really dangerous
is the idea that it when you take a
slice you get a view back the memory
model allows that to happen so you just
have a new description of the same data
the same memory it now has described
slightly differently you'd said to me
just be careful about that it's now a
mutable object so if you change the view
you'll change that airline memory the
power of that is that allows you to do
things in many other languages memory
explodes really really quickly with the
simplest operations and that doesn't
happen with numpy so that's been a real
real feature and another feature of
numpy is just the enormous number of
types of supports it supports all the C
types basically sign and unsigned bytes
floating-point complex numbers and then
some string types character Unicode and
the scene called a void type which is
where really structured data types show
up I can make a data type that is a
combination of an integer a float and a
string say now every element of the
numpy array is that record and I can
have you know then a five by a five
dimensional array of those records it's
pretty straightforward to create I mean
there's a lot of there's things can be
improved and how you spell this but it's
it's pretty simple pretty
straightforward to use and then when you
get out of field you use indexing
notation as well there is a wreck or a
subclass at the end the array that
allows you to use attribute access to
get out to get the fields which is quite
popular and there's some talk of there's
been talk for a while trying to figure
out how to do that by default a lot of
attribute access to the arrays through
some probably through some intermediate
attribute on the array themselves so
that's the array object the you funks
are these universal functions that
essentially implement the FASTA map this
was one of the key innovations of the
Jim provided was this object that will
store it's basically a generic dispatch
mechanism generic function mechanism
where you have an underlying loop for
every data type that that loops over n
elements and then you have a dispatch
mechanism on top that takes whatever
calculation you're doing and says well
okay which of these interline loops do i
call based on the data types i have all
right so i there's some coercion
involved it gets a little bit messy
because you're talking about okay floats
and unsigned ins and what is this
what's the coercion table and how do you
compute it and how do you determine it
and some places are actually determined
by the compiler some implementations are
actually determined by whatever platform
you have but that's the sense that you
funks and they just hand that off to
this low-level loop and to make a you
func it's as simple as writing that
low-level loop or whatever you want to
do whether it's a sine or cosine
currently or originally you funks only
work element by element so it
essentially that low-level loop got a
whole got one single element from all
the input arrays and did something with
it and returned the output there is
something called this generalized you
func it's a fairly new feature it's it's
equivalent to pearls pearl has
by a Perl data language called piddle
and they have something called threading
they call it interesting enough that can
take more generic kernels that can
actually operate on a whole dimension of
the array instead of element by element
and a great contribution I've added this
to numpy although still only four
contiguous arrays it needs to be allowed
to support for general arrays
broadcasting is something that is one of
the powers of numpy arrays you saw me
add and multiply
I took an array and I multi by a scalar
and not you know what it was that
supposed to do well it broadcasted the
scalar to a full array and into the
operation element by element
broadcasting can be even a little more
death if you don't know what it is and
I'm going to teach you in about two
seconds if you do know what it is you
don't need me to so just know that it's
something that's important about the way
shapes get get converted there's a bunch
of available you funks there so
generalize you funks are we talked about
all right so that's that's a numpy in
you know ten minutes serve or less it's
it sort of serves it's it's a foundation
for a lot of other packages another
aspect of numpy that i didn't talk about
is the C API Python has an API and C
numpy also has a C API so you can build
extension modules to Python that use
numpy from the sea level it's very
actually popular API and a lot of people
use it to do other things down the stack
important to keep in mind because numpy
is more than just a few python calls
it's actually got some C infrastructure
just like Python does SCI pi is where I
when I started with Python I was just
wanting to see a MATLAB equivalent
that's kind of where my mind was I
wanted to see integration I wanted to
see interpolation linear algebra
optimization and I noticed that we can
get there by there's a lot of packages
out on the net there's a net Lib gorg I
think it's still around right there's
there's a bunch of Fortran code that's
been used for years min pack OTE pack so
you start pulling that in putting nice
Python wrappers around it I did it by
hand people kind of came in and said
what are you doing let me do this let me
automate this for you yeah maybe I'm not
really a Python maybe I'm
I'm more of a mathematician than a
hacker right because you can always tell
a hacker because they'll they'll uh
they'll automate a problem but I always
just trying to just get the problem
solved even if I don't automate it but
Sify fortunately lots of people have
jumped in and helped Syfy grow to where
it is today
it's the core set has stayed pretty
constant although spatial has been added
ODR isn't listed here it's been added
cluster stats has received a lot of
attention by Joseph Burke told the
special functions have not have have
basically been added to a little bit but
it's this huge collection now of tools
for doing all kinds of things a basic
course of the things you might want to
do in data analytics essentially simple
example this is what code might look
like that's using sy PI this was an
example I gave actually four or five
years ago at a sci-fi conference where I
took pictures of a bunch of people and
then tried to find the eigen image of
everybody right so let me do an s sing
thereby decomposition on the images and
then just look at the first three eigen
images right of all those people it's
just kind of a cute example of how you
might read images reshape them into a 2d
array call the SVD on the red green and
blue channels insert the first insert
the the first vector back into a new
image and then save out those images and
you know that's a bunch of sci-fi people
that's their dragon image they all look
like that as your amorphous Python
hacker of course the first one looks
pretty good then the second one the
colors you know that's not quite the
same quite the same averages curve
fitting is another common example idea I
show actually so a Microsoft hired end
thought while I was there to port numpy
inside PI to the net platform
unfortunately Microsoft changed their
directions sort of right when that
project started that's where the time
Jim Hugoton became a Google employee as
well so it didn't it didn't quite get to
where I think it could have been but one
of the things it's show
is it I went I went and try to figure
out which of the Syfy modules get used
like what and how do I figure that out
well I went to code.google.com
I searched it has a there's a mecca
there's a way to search kind of all open
source code that it can it's been able
to crawl and I search for imports I PI
basically and try to see you know what
packages out there use Syfy and then if
they did which sub packages did they use
interesting results I mean actually and
probably predict yourselves what
packages were in common use it's
basically optimized linear algebra stats
with some special functions optimized so
the dominant use case of Syfy was
optimize stats linear algebra right
which makes a lot of sense curve fitting
this is a you know you have a function I
have data here I'm just generating data
it's a simple taking data that I'm
adding some noise in practice you might
get data that's noisy you think fits
this function here I'm generating that
date on the fly so you have this noisy
data yn you have the independent axis X
and then the function you're trying to
fit to those data and cerf it does that
for you pretty quickly gives you out the
optimal parameters as well as a
covariance estimate on those parameters
so very simple function to use to make
for a common common use case that people
people have all right so now that I'll
have nine minutes left basically for the
past four and a half years had the great
chance at n thought to work with a lot
of people in industry who are using
Python I've seen a lot of people using
numpy as well as Sipe I get a lot of
work done I've also found that their use
there are things they're not using them
pipe for is I think they should be like
they should be using numpy for that why
aren't you and as you dig a little
deeper you're less okay yeah you're
right there's that little low-hanging
fruit it's kind of a little bit if num
pie had this then it would Maps your
problem better it would allow you to
solve what you're trying to do a little
better and so kind of over that time I
built up this long list of things I wish
numpy could do and could have and throw
these that they're here and hopefully
you
talk more about these over the coming
months I'll be putting numpy enhancing
proposals to the mailing list getting
community feedback and a lot of these
ideas to try to get and change what's in
numpy really move numpy forward push it
forward to where it needs to be I think
given the kinds of problems we're trying
to solve given the kind of things people
are trying to do and really just promote
using Python to do the analysis instead
of you know JavaScript or Java or some
other you know version of a of a
language or if there is a DSL that we
use great use that DSL but have it
essentially be a lightweight DSL on top
of Python so the Python library that
essentially undergirds it so that the
code reuse can occur so this is just a
couple of so the ndaa I think when you
have indices especially for structured
arrays I'd like to see a sequel front
end most label hierarchal labels some of
this stuff actually you'll hear in
pandas I mean wes is pioneering a lot of
things that I really like to see my only
complaint is I want that stuff in numpy
too I don't want to just in data frames
I would love to see the day where a data
frame is a view on top of an umpire a
we're not there yet
you know Wes has been doing a tremendous
work to actually solve user stories and
use cases and make people's lives better
wonderful work he's doing if you haven't
checked it out make sure you see the
pandas talk but a lot of the stuff he's
doing I'd like to see just available on
numpy raised as well the global array
the distributor array there's a lot to
think about there
I think the start of that is actually
memory spaces instead of having an array
just be a single chunk having an array
be at least multiple chunks and we can
talk more about that actually
standardized distributive persistence
fancy indexing is a view optimizations
to their streaming arrays there's some
ideas I'll talk about a later
I also relate to that I think d-types
needs some improvements I think there
need to be an enumerated type
categorical data and thanks my friend
Lev here actually is a wonderful idea
for dynamic enumeration I hope to see
that at it soon an idea called derived
fields and to give you an idea of what
that what I mean by a derived field I
mean the ability to find a D type like
this let's say kind of a class
description where you have different
types and in one field it doesn't exist
it just is computed on the fly it's not
stored anywhere but it's just as
calculated version of the
other fields and that's I call that a
computed column I go to derive field as
soon as you want to do a insert now I
wanted to the set item what up how do
you do that how do I take somebody
inserting data what happens then where
does the data actually update so how do
we how do we make that possible so that
that calculation is done not in Python
runtime but at least expressed with
Python syntax but then convert it as
something that happens very very quickly
the the date/time is you finished a VAR
card data type you know a string
datatype essentially so you don't have
to know exactly how many you're going to
have and then missing data I think it's
important to get to really nail the
missing data question and then there's
some other ideas there as well
you funks need to be improved there
needs to be generalized you func support
more than just contiguous arrays
specification of your function Python it
we'll talk more about that move most
data type array functions to you folks
there's a lot there if you look at the
details of how numpy is implemented
there's the youth universal functions
which is this generic function
calculation hierarchy and there's the
data type and the data type doesn't
always use that generic function
dispatch mechanism it has also some
function pointers hanging off of it I'd
really like to have a framework where
that is minimized most of it just goes
to this New York function dispatch
mechanism so once you add these
generalize you funks that a lot of that
can happen and how close are we
error handling unification for the dot
product basically you funks have unified
error handling but some of the other
calculations don't lazy evaluation role
computation is something I think a lot
about ultimately I want to we all know
we got to move code to data I want that
code that's moved to data to be Python
that's in a nutshell what I what I want
to see so how do we make that happen
right so you as a researcher can write
Python code yet you know the data is
actually distributed all over the place
and you're not going to pull the data to
you you got to push the code of the data
but you don't want to have okay that
code actually have to rewrite that now
in JavaScript or some combination of
JavaScript plus Java plus R plus
something else how do I just use what
you're doing and push it to the code
that's it the data that's sitting there
multi-core GPU optimized you funks
there's a lot to be done there and then
group by reduction
all right there's a ton there's a ton of
ton of work to do I hope to explain an
idea I have about how to incorporate
LLVM there's some interesting work I'd
like some help with actually it allows
you to specify Python and then translate
to LLVM and then run a machine code and
insert that into the numpy runtime at
various places all right so there's a
lot of work so the approach that I'm
taking right because I just I see this
work needs be done and I'm just really
excited to do it so how I'm gonna do
this right well so I started a company
with Peter right and we're going to
focus on enterprise you know trying to
figure out how to get money from the
enterprise basically from folks that are
using big data
pull it and channel it to the numpad
numpy development right at the same time
I've also we've also started a
foundation the foundation is called non
focus I wanted to talk about that just a
little bit so numb focus you can go to
the website now wmm focus org it's just
nascent it's just getting started
the person that is actually full-time
administrator for the foundation has
been working night and day to get this
website up this week she's been doing a
good job so the mission of the unfocused
foundation really is to undergird and
make sure that all the software that
people are using for scientific analysis
stays open source is supported try to
figure out how to get money from people
that are using the tools but you know
not necessarily want to they just want
to support a foundation actually was
interested here doug cutting talked
about the Apache Software Foundation and
I see in that a model kind of what we're
trying to do we're trying to for Python
for sign to the computing create a
foundation that people can use and get
behind it'll channel money towards the
projects themselves so currently we have
sponsored projects and the sponsored
projects that we have now are basically
because people have stepped up and said
they would be willing to accept the
money and do something with it
do something productive with it and so
right now currently sponsored products
are numpy scipy matplotlib ipython
basically joining me on the board of num
focus are Jared Millman Nick he's here
right
John Hunters here author of map
live front of perez author of ipython
and python evangelist extraordinaire
i've seen him give i've seen go talk to
the siam conference for broad days
straight i mean he gave fifteen people's
talks is if i known he would do that i
would just I would just stayed home and
said hey give my talk too but he's got
these enormous energy and enormous
ability to articulate the Python
position and it's great to have him and
in Perry green field of the Space
Telescope Science Institute current
board of directors we're right now just
organizing trying to figure out okay how
we're going to move forward the idea of
members is coming soon and right now we
can take sponsors and donors and we and
we're trying to get money out to people
this summer right so there's equipment
grants boot camp in a box figure out how
to teach people Python quickly and fund
that fund those boot camps and then
figure out how to even you know possibly
buying out faculty time from folks or
buying out graduate student time so
people can spend their time making the
tools better and stronger so that's
that's the mission of Numb focus if
you're interested in getting involved so
far where it's all volunteers that are
sharing their time doing this except the
full-time administrator we have Anthony
scope ATS is acting as the treasurer
there is still a need I think for other
people who can come in and volunteer
their time to help in many ways so
you're interested actually me or Jared
here you're gonna be here all weekend
Jared's are great when he's in the Bay
Area he'll be in grad school soon right
which is the first part of grad school
is great because you're no pressure know
you have all this time right pause here
all this time that's actually not true
it's actually that after your first
batch of classes we've got that finish
your classwork then you've got this sort
of okay I just got a thesis to finish
but that's not forever I don't have to
spend that forever so I got two years do
whatever I want yeah look what that goes
the goal is to sponsor Sprint's and
conferences and just do whatever we can
to improve the state of the codebase and
there's some other ideas that Toronto
Paris is talking about perhaps putting a
goober package together a lot of things
I think we can talk about today and into
the text couple of days about how to
make that better
so in the end
why are we doing better it's the data
right it's the data Hadoop's dirty
secret I think is that most of the uses
are just the dupe filesystem it's just a
easy way people to stick their data out
on a bunch of machines now actually
using the tube runtown MapReduce runtime
there's a lot of proof of concepts out
there but it's not it's it's it's not
used that often in in production so what
are the distributed data storage
solutions for Python how do you create
and just get data make it available to
everybody but as you're moving code to
data let's make that Python alright if
the distributed data solution is
requiring you to write code in some
other language or some other stack it's
not good enough it's not going to for me
I'm not going to be I'm not excited
about I mean trying to figure out some
way to replace it if that's the case so
so that's the gloves are off that's what
I'm trying to do I want to make Python
Universal in this in code reuse just a
slide I put together kind of start to
explain some of the ways I think about
this problem of the software stack when
you talk about moving code to data you
really get into the heart of the
software stack because what is the code
you're saying the data well it's some
combination of Python or C runtime if
you're using javascript and what's its
runtime and then translate it through
these other 15 layers what is that code
and how does it run kind of I really
like I'm starting to really like this
model right of how you think about the
software stack right you have plateaus
of code reuse right see for a long time
in this place where people come together
share libraries I'd actually like to see
that low-level kind of there's this
low-level virtual machine called LLVM if
you don't know about it come talk to me
we can talk about it I'd like to see
high bandwidth connections between
Python and low-level virtual machine
that allows Python to be a plateau of
code reuse at the high level and then
have little dsls domain-specific
languages are MATLAB I'd love to see all
those just be domain-specific languages
where the library support is all Python
and then in a very same way that C and
C++ or just DSL is for all of em now
that si Lang exists that's
tongue-in-cheek it's it's a little I'm
not entirely serious but but nonetheless
you see a lot of people here on this
bandwagon app
all currently their their compiler stack
is using LVM as a low-level assembly
that's in their compiler chain you have
dragon egg that allows GCC any GCC
language to essentially emit LLVM
instead of the and then allow that code
gen to happen there you see Nvidia using
a their back-end they have LVM and then
they emit GPU code from there it's just
it's it's a nice place where at the
hardware level in the low level there's
some cooperation happening so that
significant code reuse can take place
that's all I've got I appreciate
everybody here I'm excited for the talks
excited for what you're going to present
and looking forward to talking anybody
about anything you've got
alright thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>