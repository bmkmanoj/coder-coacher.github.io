<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>MySQL High Availability Solutions with Lenz Grimmer | Coder Coacher - Coaching Coders</title><meta content="MySQL High Availability Solutions with Lenz Grimmer - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>MySQL High Availability Solutions with Lenz Grimmer</b></h2><h5 class="post__date">2011-02-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2sBsTruebCQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Wow that's a big crowd I'm pretty
excited to be here thanks for having me
topic of this talk is going to be MySQL
high-availability solutions and what I'd
like to do is give you an overview of
how you can make a MySQL server instance
more robust and or yeah more available
if some of these systems go down let me
start with a quick introduction of
myself yeah my first contact with open
source software was in 1995 during my
studies in the university this is where
I first learned about Linux and all the
exciting things that you can do with it
I've been using Linux on my desktop
exclusively since then which kind of led
me to working for a company that is
related with Linux I was a distribution
engineer at Sousa from 1998 until 2002
that was before they got acquired by
Novell one of my first tasks there was
to add MySQL to the distribution that
didn't exist before
back then my squirrel was not available
under the GPL they still had their own
homegrown or homebrew license which
basically made it impossible to include
it on the distribution based on the
terms they have set up so I got in
contact with these guys Monty and debate
the founders of the company we exchanged
some emails and I kind of asked them
okay what can we do to get MySQL on
Susan Linux since we I really wanted to
have it on there and the deal that we
struck over email was that Susan is
allowed to include MySQL and in return
we sent them five package boxes of the
distribution each time we make a new
release so that was a pretty cool deal
and so since then MySQL is available on
this distribution actually souza was the
first of the Linux distributors that
ship MySQL as part of their package so
I've been in contact with these guys
very early on which yeah we we stayed in
contact every time there was a new
release we were talking about what needs
to be fixed
I met Monty
at numerous conferences all across the
world they were giving talks about MySQL
I was giving talks about SUSE Linux so
we bumped into each other quite a lot
and during some random email discussion
I kind of jokingly asked if they would
have a need for a guy like me and boom
two months later I had joined MySQL as a
release engineer so my first task was
offloading Monte from the task of
building the MySQL releases so the
developers were hiking on the code and
at some point it was time to make a new
release and then when I got into gear I
started the builds compiling MySQL and
all the various platforms doing the
packaging publishing and uploading those
things
sending up the release announcements all
these things that relate to release
engineering were in my lab back then I
also started getting engaged with the
MySQL community on our mailing list and
all the other available forums that we
had so at some point I realized that
this is what I'd like to do more and I
went to doing community relations
exclusively and this is what I still do
back when we were an independent company
the community community relations team
actually reported to Martyn Miko's to
see or directly so it was always a very
important role inside of the company so
we didn't report to marketing or were
part of engineering really were
independent from all of these groups
sometimes even with a different agenda
especially with marketing and we of
course held contact with all these
groups as as the community team you
really have to pull strings into all
these various directions you get
feedback from the users from your
community that you have to then trickle
into the engineering organization to let
them know what needs to be fixed what
the focus of the product should be you
talk with the marketing folks about how
the messaging to the community should
look like product management needs to be
advised on how the community expects
things to be done so it's a very
exciting job and I still enjoy doing it
even though I switch companies two times
in the meanwhile you probably all know
the story of MySQL and how we got
acquired by Sun and how Sun in turn got
acquired by Oracle
so I'm now an
Hockley employee by business card and
well kind of still in my squalor by
heart i guess so this is who I am I'm
here in the Bay Area for the same event
that Sarah was talking about the i/o you
see I'm summit as in my role as the
MySQL community relations contact for
the AMIA region so this meeting was
really a meet-up of all the leaders and
presidents of Oracle user groups
worldwide not just the US and what
struck me as very interesting is that
all of these Oracle user groups do have
a lot of interest in my school there
they uses the members already used my
school summer and their data centers
already and know that they're that my
school is part of Oracle they are not
shy anymore to actually talk about it so
in a way my school has become a bit more
serious with this corporate backing and
as it's probably obvious with the latest
release of my school that five Oracle's
not out to kill MySQL in any way quite
the contrary
my school definitely changed and mature
over time this is what a big company
brings with it and I think some of these
changes are certainly for the better I
mean a small start-up has different
focus and different requirements on for
product and a company like Oracle who
definitely realized that my school is
not competing with a big database MySQL
serves a completely different need in
audience and this is where my skew is
going to be be improved for in the
future so we're not trying to become a
replacement or a competition to the
Oracle database but we are going to make
sure that my school will continue to be
better for the use case that you are all
using it for and so we're my no I'm much
better suited to really address the
needs and the requirements of where my
school is being used today that said let
me give you a short agenda I start with
a little background about my school high
availability concepts then I'll try to
introduce the various building blocks of
what you should take a look at if you
want to create a high
available in my secure setup and this is
an introduction area talk I'm not going
to go into the gory details on how to
actually set this up each of these
components are quite complex with the
except exception of MySQL replication
maybe so it also requires that you have
to look into what your particular needs
are high availability usually isn't
something that you can get off the shelf
and it suits your needs you have to
really customize it and make sure it
fits your personal requirements and what
you need to get configured in your
system MySQL cluster pacemaker all these
are tools that I'm going to talk about
so let's take a look at what you
probably know so we have a server here a
PC you have my square running over there
you have your local hard disk drive and
your client either your web app or an
external application it talks to the
MySQL server using SQL statements this
can come either through the wire so over
tcp/ip or even on a local socket coming
from from the same machine the MySQL
server takes your statements and
performs the required action and then
stores the data on disk on your
filesystem and returns the result sets
to you so what happens if this machine
crashes well you're screwed you don't
have any replacement you don't have any
backup the client can't talk to the
server anymore so something needs to be
done about that particularly if that
client is a web app that serves a
hundred thousand people that are waiting
to get there they are placed into a
forum so why do I need high availability
or HEA what you can really be sure of
something can and it will fail at some
point and according to Murphy it will
always fail in the time that you are not
expecting it to be and well if you are a
web shop there isn't really an ideal
time because somewhere over the globe
somebody is awake and wants to do a
purchase so downtime is usually not an
option but it does miss the only
necessary for to avoid
great failures in hardware software
sometimes you just want to be able to
make an update of the operating system
or there's a security problem with MySQL
you should update so for service
maintenance you need to be able to have
a way to keep your system up and running
but still be able to perform such
maintenance tasks and yes I've already
mentioned it downtime is expensive and
depending on the role in your company
either get fired or you go bankrupt if
something like this happens so keep it
in mind
downtime can be significant and also if
you are just starting from scratch and
you're building up your infrastructure
and you're working on developing a new
system try to consider high availability
as part of your entire setup from the
very beginning it's usually quite
painful to add this to an already
existing and running system without
introducing any downtime if you start
with having high availability in mind
from the beginning you are much better
off than trying to plug this in at a
later point in time so the aim of high
availability is to eliminate the
so-called buff the single point of
failure so and the single point of
failure can be quite a wide range of
things things that definitely fail at
some point is everything that is moving
and spinning like hard disk fans
spinning rusts like hard disk they have
a mean time between failures and
especially under extreme circumstances
like high temperature these end of life
situations tend to get reach much faster
than you think
CPU fans are always cheap or too cheap
and they start to fail but not always
Hardware can fail your application can
crash there's a buck and one of the
services goes down and your website
still fails and it's not reachable Linux
for example has this nice tendency to
completely come to a grinding halt when
you run out of memory or if you go
heavily into swap all the sudden your
system is so busy with itself that it's
not so
any requests anymore and the only
solution for that usually is you have to
reboot if you can still shut down enter
the shutdown command emilynics
can really get itself into a state where
it's not reacting to anything anymore
and in that case you just have to flip
the switch which then might lead to
other problems and you want to get back
up on your feet again other operating
systems handle this a bit more
gracefully or well the classical case
that the cleaner trips over the cable
and the network cable of your servers
out no connection what happens power
supplies are always good for fun so
there are lots of sources that can
become the single point of failure that
you should take a look at and need to
have or need to be aware of and this
really is something that only you can
identify you have to go through your
configuration your system your
environment and take a look at okay
where are the crucial parts with which
other things where I might want to have
a replacement somewhere on the shelf or
even better in a hot standby mode ready
to be acting as the replacement for the
active system and with computers and
servers what you usually do is you
create a cluster a high available custom
means you provide redundancy of hardware
and the data that you want to store in
it in that case you have a backup system
or more of them that can take over in
case that your primary system goes down
in in the case that I'm talking about
what you usually do is you have a
so-called virtual IP address this is the
IP address that is known to the other
services and applications to talk with
it this particular server but this
virtual IP address can move between
different physical Hardware machines so
the application doesn't really care it's
always talking to the same IP address
and it doesn't realize that the hardware
and the system behind it has been
replaced because the the original ones
went down in the meanwhile
and yeah you have to ensure that the
data that you want to make available is
also in an integer state or is in a it's
not corrupted by the failover
or by the by the failure that has
occurred and even though it's tempting a
high availability cluster is not
designed to replace any performance
tuning measurements that you might want
to also make so high available H a
cluster is something different from a
high performance cluster sometimes you
can use it for both purposes but
something that you have to keep in mind
if you design your system that two
machines are constantly serving your
load because well who wants to have a
system in just being there running idle
we can make use of this because we we
currently have such a spike in load
let's use the hot spare for this cool
and then the primary system fails and
all of a sudden the load that you've
gotten used to had to be served from
that single remaining box and then you
run into the next problem because it
will get saturated and fall on its feet
or over its seat so high availability
and scale out are two different things
and both need to be kept in the in
consideration of course you probably
have seen this slide before if my
clicker works and the level of high of
availability is usually given in a
percentage uptime per year and the
magical five nines is if when you have
only around five minutes of downtime per
year and that little curfew also shows
the cost that is usually involved with
getting there so the question that you
should be a quest asking yourself do I
need five nines or is it fine if my
systems available for well at least less
than an hour per year that's a basis
know is it or can it go down for less
than an hour per year sorry
so you want to get an explanation of the
difference between high availability and
high performance
sure okay consider that you you have a
system that you want to make highly
available in order to do this you need
redundancy maybe in the case of a second
server so your application runs on your
primary server the second server is a
hot standby it's doing nothing because
it just waits for the case that the
primary goes down and then it takes over
so it makes sure that the data has
always been synchronized and it's it's
ready to start at any time then your
boss comes in and says hey our website
is getting so much load we need more
power isn't there this second box that
can't we use that to serve some parts of
the load so you enable the second box
and you start serving requests from
there so now your application is
distributed on two machines and the load
goes down cool and then the primary node
crashes so all of a sudden the load from
this service and the additional note
that you have put on the other box goes
to one system yeah that could be doable
so you could say yes we are using both
systems but we're just utilizing them to
50% each but where's the difference 2
times 50% to 1 times 100% yeah you might
get away with that sure sure
all I'm trying to say is don't assume
that your high availability should be
serving to for the load distribution or
to increase the performance this should
really be done on dedicated machines
that can also be replaced with hell over
mechanisms rules of high availability I
put this in front I usually had this as
the last night and then I realized I run
out of time and this slide never shows
up so I start with it here again prepare
for failure it will happen at some point
if your service is valuable and you
depend on it make sure that it's always
up or that you can provide at least a
reduced level of service and you're not
completely of offline in any case and
also try to identify what is really
important that needs to be available is
it the entire website with everything
just parts of it most of the really
popular websites usually the great in a
graceful way so that
of the service is still available let's
say you have a video or a picture
uploading site the the part that still
sells pictures is still up but the path
where you upload pictures might be down
for a moment because this part just has
it down time so how try to identify if
you have any options for implementing it
in this direction in order to not having
to make everything fully redundant and
yeah kiss keep it simple stupid the case
of a down time when something has
crashes usually when you have the
highest stress and you need to get your
system up and running as fast as
possible if you first have to read a 50
page manual to follow up and figure out
how the system gets back up this is
likely going to cause you a lot of
stress so make sure to keep it easy and
simple and it's tempting to start adding
everything to the high availability
system hey the mail server cool let's
put it into in here as well and the
first server yeah we want to make sure
that this is highly available - so you
have a very complex setup that all the
sudden surfs way too many purposes and
it's hard to figure out what happened
all the administrators on vacation or
has left the company so the more complex
the system is the the hard it really is
to make get it up on its feet in case
there is a failure and also as much as
possible automate this whole thing
create scripts reduce the manual
intervention as much as you can to make
sure it's repeatable and has been tested
so the last part really is most
important one there's no point in
setting something up that is highly
available that you haven't tested at all
because you just trust yeah it'll work
also if you have made change to the
system test if it still fails over if
you have installed a new package if you
have made it an upgrade of something it
may have changed something underneath
that you're not aware of maybe the
system doesn't boot up anymore so even
though there's always a little risk
involved the more testing you do the
less harmful is the fire drill if it
really goes down it it doesn't come back
up again because then it's under your
control you're in front of the system
you
can make the change you can see if it
comes back up properly or not Murphy
strikes again usually if a failure
occurs you're not around because you're
just asleep it's 4:00 a.m. and then
you're back in the data center or half
asleep and the system doesn't come up
because you made a mistake so that's
something to avoid if you tested it
before parts of an H a system heartbeat
that's the process of the application
that kind of Pink's a service or an
application or an entire system if it's
still alive
or several systems talk to each other
and ensure that there are still
available that the data that you they
are returning makes sense and it's not
garbage these things are usually done
through some kind of heart beating
system you can either create this by
yourself the easiest way to check if a
webservice
app you create a little shell script
that runs double you get for a webpage
and you compare the content of that
webpage with the checksum or something
like that so you can check both that the
system is actually answering and that
what it returns still makes sense okay
in case that the heartbeat tells you
that something is not answering or gives
you wrong results you need to take
action this part is usually been taken
care of by an a monitor application or
tool it makes sure that it takes the
appropriate action to remedy the
situation either by just restarting a
service if it's just the process that
has crashed or by switching over to a
completely different system making sure
that the services are being started and
initialized in the appropriate way and
I'm going to give you an introduction to
the most popular tool here in a later
slide and also it should be able to
manually control those things especially
if you want to test this there should be
a console where you can run commands to
do the failover in an in a manual way as
well so we're talking a lot about how to
make the system and the service is
highly available but something that's
very crucial about it is actually the
data that you work with so if you have a
mail server the actual email or the
mailbox
of users this is the important data and
in our case with my score of course it's
the databases in table that you want to
make sure remain up-to-date and
accessible so there are several ways on
how you can make sure that the data is
available as being made redundant and
I'm going to talk about the two most
popular solutions in the MySQL
I'm filled here another term that pops
up quite frequently split-brain
this is the situation in which you have
two systems and a well or more depending
on on your setup that both think that
they are known in charge of the entire
application because they can't reach the
other one anymore so if you have two
systems and they have a heartbeat going
on and they check each other if they are
still alive and all of a sudden the
connection between these two machines is
down they are still both up and running
but they can't reach their partner
anymore so they assume okay the other
one is gone I am not the one to take
charge of the application and depending
on how your system is configured this
may lead to really really bad things
especially if you have a shared storage
and you have two MySQL servers that no
want to access the same table files bad
so in order to avoid this you need to
have a moderator or an arbitrator which
is usually a process or a server that
runs somewhere outside that can kind of
make the decision for these two guys if
they can't figure it out by themselves
and then depending on what you use this
of moderator takes some very serious
action by simply shutting off one of the
systems to make sure they can't create
any more harm or he runs scripts or
executes any certain commands to make
sure to solve the situation this depends
on how it's being configured the more
tools you use
but split-brain is something to to avoid
as the plague okay I'm now going to talk
a bit how to make the data redundant
the first thing I'm going to talk about
is what's built into MySQL replication
you're probably all aware of it I hope
so what we do this is the setup that we
just have we have our server with the
local hard disk running MySQL and we
just pop a second box right next to it
in this case it's also running MySQL
with the local hard disk the client is
configured to talk to this box as usual
which then stores the data on its local
disk but also replicates the data to the
second MySQL instance so you now have a
backup copy of your data sitting on a
second machine ready for you to be used
in case it's needed so the data start
here as well and in case this one falls
down your application just talks with
the second copy which is still there and
the usual way to do this is by using
what I already mentioned the floating IP
address so the MySQL client application
appears being configured to talk to
virtual IP address leanness which is
then moved over to the second machine by
either a script that you've created
yourself or using a load balancer or one
of the tools that are available so a bit
more details about MySQL replication I
hope I don't bore you with this my skill
replication is built into my skills
since 3.23 it has been around for quite
a while it's a way to replicate
statements that changed data in your
tables so you need to have a second copy
of the data that is in the same state
and the replication then copies over all
the statements that modify data in any
way so the changes are being applied on
both sides and it used to be statement
based so we actually distributed the SQL
statements that I used to change the
data since MySQL 5.1 you can also use
so-called row based replication in which
case the actual changed data is being
copied over to the other side
fairly easy to configure and set up
there is also a mixed mode yes good
point
so in the mixed mode MySQL decides if
it's going to use statement or row based
replication based on what makes more
sense in this situation one thing to
keep in mind MySQL replication by
default is a synchronous which means
that the MySQL master server doesn't
really know or care if any of the slaves
has reached and replicated the data it
just proceeds and goes on it's not
actually not aware of the slaves at all
so it's it's up to the slave to make
sure that it's keeping up with what's
happening on the master we have added a
new feature in MySQL 5.5 which is called
the semi synchronous replication since
it's not fully synchronous it's a nice
workaround that we have implemented
there what we basically do is that the
MySQL master server waits until at least
one of the slaves has acknowledged that
it has received the data on its side so
there is a backup copy somewhere outside
of the master server before it proceeds
with giving the okay to the application
so on the master server you have a
so-called binary log file and this is
where all this statements all the rows
are being stored the slave then connects
to the mess and just pulls everything
that has been put into the binary log
since the last time it has connected to
the master so my school replication is
push a pull the slave connects to the
master and pulls the data from there
it's not the master that says hey I've
got something new here this the master
just writes it to its log files and
forgets about it the slave goes to the
master and asks ok do you have anything
new for me and then it grabs all the
changes since then a little caveat here
is that replication on the slave is
single threaded so while on the master
you can have multi concurrent sessions
banging on the server at the same time
on the slave all these changes are being
serialized and being applied after one
after another not in a parallel fashion
it happens on the master so this left
slaves may lag behind if you have really
quite a lot of updates happening so if
you are very heavy on IO your
replication staff might actually have to
be a bit faster than the master in order
to keep up with what's happening we are
working on how to solve this problem
right now what you are thinking of is
having separate threads for separate
tables not at the moment MySQL isn't
designed like that but we are aware of
this limitation and the link here gives
you a bit of background information how
we try to solve this problem just to
repeat for the remote audience one of
the problems is that the replication
used to be statement based and since
you're having if you want to treat
transactions in the appropriate way you
simply have to serialize this to make
sure that the data ends up in the in the
right order and is consistent one thing
also to keep in mind this is just pure
data replication there is no heart
beating there's no monitoring or nothing
it's to be implemented outside of the
MySQL server something that we've added
with MySQL 5.5 is a so called
replication heartbeat so this allows the
slave to determine if the master is
actually still up or if it has failed
which can be then used with with
external scripts to take appropriate
action if the heartbeat is missing and
here's a quick overview on how
replication is being configured so you
have the Mexica server here it writes
the data to its local tables and also
all the changes are being stored into
the binary lock the slave then connects
and replicates the data and the first
thing the slave does is storing the data
in its own log file in the relay lock so
the all the changes they don't end up in
the slaves tables directly they are put
into a temporary space so to say the
relay lock and from there the SQL that
is taking all the the updates that
inserts and deletes and applies them to
the local tape
okay I'm not going to this much detail
but both statement based and row based
replications have their pros and cons I
will make the slides available for you
to download so I guess we can skip this
for now it would take a bit too long so
row based replication was included or
added in my school's 5.1 and this is the
replication technology that usually is
used by all the other classical database
systems so statement based replication
was pretty unique to MySQL there weren't
really only a few other database that
implemented this approach there are
several ways in how you can set up MySQL
replication the simplest one is you have
one master and one slave a master can
also have multiple slaves that take the
same data and replicate it it can be
cascaded in this fashion this makes
sense if you have for example quite a
lot of replication slaves that would add
too much load on your primary master so
you can set up one slave that then
serves just as a as a master for all the
others to offload the system from from
this task what's currently not possible
is that you have multi source
replication or multi master replication
where you have several mascot masters
that all replicate into one single slave
will this becoming eventually we have
lots of requests for that I'm sure
there's a work log entry for this my
school keeps track of all the features
and things that we need to fix in a so
called work lock which is our internal
tool for planning the releases I would
have to look it up if it's already being
worked on and how far the implementation
has gone yes we do have a public copy of
our work lock on the my school forge
Forge my school.com slash work lock you
want to take a look at what our
engineers are up to this is a very
special setup that I'm going to explain
in more detail later on
master master so you have two servers
that are both master and slave to each
other and this can be quite useful you
can also create a ring where you have
boxes replicating each other until the
replication goes back to the beginning
it's also possible has some use cases
but these two setups have their got
chest that you need to be aware of okay
elaborating on master master so you have
two machines both are from a mysql
standpoint contribute to be master and
slave of each other which makes it quite
easy to failover because they are
already aware of the relationship with
each other which with each other you
don't have to reconfigure anything if a
slave all the sudden becomes the master
because the other system crashes it's
already properly configured so it looks
like this is very tempting to simply
spread right load between those two
machines as well it's master master
right you can just shoot queries at both
of them doesn't really help because
people sometimes assume that this gives
them load balancing or helps them to
distribute the right load but since they
are replicating from each other anyway
they are also have to apply the same
changes on the other side that and if
one of the systems fails
since the replication is a synchronous
you don't really know if the data has
already made it to the other side so you
are definitely going to run into
inconsistencies that are hard to resolve
so if you are setting up a master master
my school setup make sure that you any
quest that modify your data in that
update delete only sent to one of these
nodes at a time right so forth schema
changes there this setup has an
advantage because you can make the
schema change on on the replication
slave without any outage but that
depends on the schema change if you just
add another column this works but
sometimes schema changes are not RepRap
replicatable anymore so depends
sometimes you get lucky with this but
you definitely need to know what you're
doing
DDL is also replicated yes so creating
tables dropping tables also replicates
to the slave and that's something too
if you accidentally drop a table it's
quickly gone on the slave as well so we
do have a patch in the pipeline that
will implement delayed replication where
you can set up the slave that is
deliberately lagging behind the master
for a given amount of time which is a
nice way to stage replication to avoid
accidental errors like this way you know
okay I just made a mistake but
fortunately this lathe is lagging behind
it hasn't received this statement yet
and allows you to recover from there so
MySQL replication is an HJ solution what
happens if the master fails well the
application won't work anymore right and
the slave has nothing to replicate from
what happens if the slave fails data
will no longer be replicated but the
application still runs fine on the
master and is this high availability yes
no this doesn't sound like high
availability right foot by my own slides
anyway so replication is just a part of
an HJ configuration so replication by by
design is pretty dumb so it does its
thing it replicates data make sure you
have a copy but in order to use it in an
high availability system you need to do
some more work and if you're running
Linux which you probably should when
you're running MySQL in production you
should take a look at pacemaker formerly
known as heartbeat this pacemaker is
kind of the second generation of this
tool and it's an open source project
that provides a framework for making
basically any generic Linux service
highly available so it provides services
that allow you to monitor resources like
processes or hardware it has the heart
beating functionality it provides a
fencing mechanism fencing is the the
approach that you want to
make sure that one system is failing or
is in a very in in an undefined state
that it doesn't interfere anymore so the
approach that they are using is called
stone s shoot the other node in the head
and they usually do this by flipping a
switch and taking off the power from the
box there are power strips that have a
tcp/ip or a serial interface so you can
control them by a PC in order to M
switch off the powers of the system in
in question is being shut off it's
pretty fast in determining if a service
or a node has failed and it can then
take the appropriate action to do the
failover to the backup system and for
MySQL it even includes predefined
scripts that automate this process
making sure that Meister the master
slave configuration is being changed
appropriately it's quite complex to set
up but it has good docks and there are
even two examples that you can't really
read on these slides I guess how to
create a load balance MySQL replication
cluster and how to use dr BD with mysql
and dr BD is something that i'm going to
talk about so we have replication we
have pacemaker these two pieces combined
give us a quite well working high
availability solution so yeah pacemaker
also uses virtual IP address that can
float between systems so I set up in the
minimal case to MySQL servers that
replicate to each other we have a
virtual IP address that is being used
for the application to talk with one of
these servers and pacemaker make sure
that if the my school process dies or
the hardware fails the other takes over
and everything is being configured
appropriately
the problem with MySQL replication is
one that it's as in Cronus so in a case
of a failover there might be a gap and
that data is lost because it hasn't
replicated before the master crashed or
disappeared whatever and once the
primary system is back up you can't
easily fall back
because of the way replication works so
you have to figure out okay is anything
missing can I simply continue their
application with what has happened on
the new master since then or do I have
to restore from backup so from failing
from the master to the slave is usually
easy but going back again may require
some manual interaction since there is
no automatic conflict resolution and
therefore yeah you need to invest some
time or brain to get this sorted out
okay we can use other replication
technologies and disk replication is
another one I'm going to cover so in
this case we again have our MySQL server
which stores its data on this we have
another one and this time we just have a
disk in there running at the moment
application talks with my school on this
side stores the data on disk and in this
case the replication is being done on
the disk level not we are not using
MySQL replication here but we were
replicating the files as they are stored
on the disk by the MySQL server and in
case that the first one goes down we
start MySQL on the second system and
have access to the filesystem and can
start serving data from there that
process is not automatic the switch over
here would have to be done with
something like pacemaker for example
well in the very basic case this
couldn't be a DBA yes but you usually
have a script or something like that or
you use pacemaker or a dedicated
solution that takes care of this if you
are running Linux we have a kernel
module named dr BD the distributed
replicated block device and what dr BD
does is yeah well it can be compared
with raid 1 over a network card so you
have a partition or a block device on on
the on the primary server and then you
set up a second machine
ideally configured in the similar way
also with the
and you enable dr BD on both systems and
the LBD will replicate blocks from one
device to another with dedicated network
cut and it's doing this in an
synchronous way which is very essential
so every time you make a change on the
primary system every brought block that
has changed on this block device is
being replicated over to the other side
and only when the second node
acknowledged that it has received the
block then the RVD gives back the okay
they've been trickles up from the file
system layer up to the application by
default they are being configured in an
active/passive configuration let me go
back to that slide real quick so you
have the active system and the
replication takes place and the block
device on the often the secondary system
is not accessible even though you have a
full identical copy of the data as long
as this one is in replication mode you
can't really access it well the Abadie
has changed listen they mean well so
they're now our options of doing this
using a cluster file system but by
default with the usual file systems like
XFS or XT you wouldn't be able to access
the data since the RBD works on a block
device layer so it's a layer underneath
the file system and file systems usually
don't cope well with blocks that are
changing underneath them if when they
are mounted they don't expect this to
happen so you will run into grave
inconsistencies if you try to mount such
a file system in fact the RBD protects
you you can't mount the RBD control file
system as long as it's in in passive
replication you can put them both in
active mode yes the our ability will
complain about this and if you don't
have a cluster file system like
OCFS or GFS you will corrupt your data
yeah well but be aware that this is not
recommended so only if the primary node
crashes the secondary will be promoted
to be the new primary and
you can mount the file system start the
MySQL server and get going again alright
let's see yeah I mentioned this year to
primary mode is available dr BD del
orcas the website the whole thing is
maintained by an austrian company named
Lynn bitch and they have been very
actively developing this thing for many
many years and I think some time last
year they Lena Starr was finally
accepted the coding it's no part of the
mainline Linux kernel replicates blocks
we already said that yes entire body is
very commonly used in combination with
pacemaker for example because well since
it's under on the block level layer you
can replicate anything be it may serve
our fight server data MySQL tables it's
used for anything that's true so since
it's synchronous replication and an RM
minus RF star on the left side
replicates immediately to the other side
so in this case a backup is needed since
this is happening again on the block
level layer when you failover you mount
the filesystem and the file system
usually quite likely is in an
inconsistent state first because well
it's not a filesystem replication it's a
block replication so this secondary
starts up you mount the file system in
first has to perform an integrity check
that's why you have to use a journaling
file system like xf s res FS x t4 j FS
there are many options but don't use X
t2 or anything else that is not
journaling and then you have a file
system then you start my squirrel if you
use a new DB which you should because my
eyes I'm is not that robust for such
situations in DB will have to perform
its love recovery and consistency check
and then you finally get going again
there were several question lets up with
it were in the back so the question was
how much latency is involved by this
replication because it's synchronous and
what happens if the slave crashes the
terms that you've just been usually make
it sound as if you think this is a
database but it
really block replication there's no
transactions involved but it's it's
synchronous and in the way the OBD works
is that the application rights to the
first system the file system writes in
to the block device dr BD replicates
this block over to the secondary node
the secondary node gives the
confirmation that it has dot the block
on its local disk then the primary
confirms the file system the block has
written to disk the filesystem
information informs the application that
the data is there so there is latency
involved yes and therefore you need to
make sure that for dr BD you have a low
latency high bandwidth connection
between those two so gigabit ethan
switched or a crossover cable between
two network cuts is probably the best
and the second it was what happens if
the secondary replication node fails
basically nothing dr BD continues to run
just fine on the primary node it stores
the data locally of course and it also
confirms to the application immediately
that the data has been stored but the
RBD is able to trigger a warning or you
have to take action in this point and
there are hooks in the ability that
allow it to do that
once the secondary node is back up again
it will catch up the master tapes care
of what has changed in the meanwhile so
once the the secondary node is up again
it will simply take everything that has
been changed since then so it'll be in a
synchronous mode for a while until it
has fully caught up and then it will
switch back to synchronous mode a dr BD
can also be configured in a synchronous
mode so if you think that you can live
with data loss and you are more
concerned about getting a quick reply to
the application dr BD can also be
configured to run in a synchronous mode
but this kind of defeats the purpose and
yes for dr BD you definitely want to use
in ODB tables and not my eyes on tables
because in a DB is simply much more risk
robust against corruption and yeah since
we are replicating blocks again you
never know in what
day to the file system of the my eyes on
tables are on disk in case you have to
feel over my item takes just too long to
get back in a consistent state the MySQL
system tables yes they are they are in
my eyes on by default that's true the
fortunate thing about the system tables
is that they usually don't change that
much so the risk that you have a crash
in the moment where you create a garand
for a new user or something like that is
relatively low these tables aren't that
hot like the rest of your data so the
chances are pretty high that they will
be recovered just fine
yes you can definitely compared to this
so since the IBD is synchronous and
creates a one to one copy of your data
it's basically similar to having a SAN
or some other shared storage that you
use because you have just one MySQL
server accessing the data at the same
time and then you flip over and in fact
speaking of that let me continue this is
how you would use MySQL using a shared
storage system like ascend or something
like that
so in this case we have three pcs or
servers and this one just wants the
MySQL server again the client just talks
with this one using a virtual IP address
and the data is then stored on the
central storage system using fiber
channel
what have nots or Amazon whatever is
available in case this one fails you
start MySQL on the second node and it
will then mount the filesystem and
access the tables on that shared storage
system that's another option either you
have to disk in both machines using the
RVD to keep make sure they are in sync
or you have a central storage but this
central piece of storage may then be
another single point of failure you have
to consider in your analysis and I have
a bit more of a comparison and a few
aspects here so data consistency and
integrity especially with a shared
storage or dr BD since it's
synchronously replicated or it's just
start one time anyway if your data is
corrupted because of the failure there's
it will be corrupted regardless where
you failover to the
second incident that starts up and tries
to access the data if it's garbage its
garbage in you're screwed so MySQL
replication in that case might have an
edge because the data is really being
duplicated to a second system and a
corruption or on the file system that we
can't easily propagate to the next box
the Sun can become the spot called
caches are a really nasty thing in any
case where you have to start my school
from scratch and mount the tables means
that well dig the caches are cold you
have just started the MySQL server so
you will have to live with in a certain
amount of time where the performance
isn't optimal yet that's probably how to
avoid with MySQL replication the caches
are already in a somewhat warm State
simply by the fact that the replication
is going on and there are tools there's
a script included in math kits that you
can use to run queries based on the data
that is being replicated that make sure
that even more information is stored in
the caches which make a failover a bit
more faster yes using inner DB was
already said let me see split brain yes
blood pain can usually just happen in
this setup if you by accident start to
MySQL instances accessing the same data
you are host MySQL isn't designed for
that and even though some people say
yeah but I can put my eyes em in
read-only mode yeah you might but is
this a classical scenario probably not
and we don't really have any protection
against this so make sure it doesn't
happen okay my Scott clusters the next
one in my list who of you has heard of
MySQL cluster using it a few heads
excellent good so MySQL cluster is a
very interesting beast even though it's
called MySQL
it's basically independent from the
masker servant can actually be used
independently as well so I have my MySQL
D process running on one box and then
here this is my cluster in this case I
have four machines the masochist server
talks to a mice cluster as if it is a
storage engine so instead of storing the
data locally like in my eyes amor InnoDB
any table that I create is being created
over the network in a cluster of
machines which are this fall down here
for example I can also use 2 or 8 or
what have nots and these guys who take
care of distributing and replicating the
data in a fashion that makes sure that
failure can be tolerated and the MySQL
server doesn't really know about this it
just talks as if it was a regular
storage engine my application isn't
aware of it because it just talks to a
regular micro server so in this case
instead update delete go to my SQL
client server protocol and then the
server puts the data into the cluster
notes and they will then take care of
the communication and the distribution
of off the data for me I can also take a
second MySQL server and connect it to
the same cluster and an update in the
delete that I make on this side is
automatically visible on the other side
as well
so since the data nodes in a MySQL
cluster replicate information
synchronously changes are automatically
visible on both sides of the MySQL
servers and you can have more than two
MySQL server instances so this is pretty
nifty because it allows you if that one
crashes I would simply talk to the other
my school server it's still available if
that one goes down I don't even notice
because the data is replicated to the
other nodes and they take care of
serving the missing pieces from another
node of course
well the administrator gets notified
that the clusters running integrated
motor needs to take action but this all
happens automatically without any
interaction it's as part
of the building cluster how would the
money to know which database to use okay
up here right again this is something
that you would have to do or have to
script with something like pacemaker or
a load balance or something like that so
informing the client application that
needs to talk to another MySQL server
follows the same approach that I've
introduced already my school cluster
just takes care of the redundancy part
down here how would you assess the
availability and we claim that my school
cluster gives you five nines for nodes
as a very common setup depends of course
on the quality of your hardware but it's
it's a very robust system icicle cluster
comes from the telecommunication
industry back when MySQL was still an
independent company we acquired another
company named Asato they were a spinoff
from erickson at big telecommunications
company in Sweden I think and and they
created this thing called NDB the
network database as an as a product
aimed for the telecommunications
industry Ericsson uses NDB in there I
don't know how you call this the color
registers I think it's hot so parts of
the mobile phone network that take care
that mobile phones are being registered
that codes are being distributed and
that everything is being built
appropriately so you have lots of high
concurrency very short running
transactions with high volume this is
where MySQL cluster or NDB really shines
and what we acquired the company and
then we we realize that it's very easy
to make this into a storage engine but
you don't have to talk to MySQL client
so a protocol actually I'm going to show
this in another slide these are
commodity off-the-shelf Linux boxes yes
so you don't really need any special
hardware to set up a cluster in fact for
for testing purposes it's quite
appropriate to simply start all these
processes on one single Linux box they
don't really have to be on dedicated
machines
you just want to toy around with it but
then you don't have the redundancy that
you probably want to achieve good point
in the early days my Scot cluster was an
in-memory database so your entire tables
had to fit in the memory the total
memory of the of the storage nodes and
this is a limitation that has been
lifted in the meanwhile so the latest
versions of MySQL cluster can make use
of local disk drives to store data but
the indexes that I needed still have to
fit in memory this is simply a
requirement in order to be able to
provide the low latency and fast
response time the cluster gives you how
does the client pick the note of the
cluster to talk to it just talks with
one and then they internally make sure
that you get the information so if this
one talks with that one it knows who
else to us to get receive the eight
information suit this is transparent the
NDB API that is being used in the
background
takes care of this a few more keywords
here so data is automatically being
partitioned among the nodes so you also
have load balancing the fragments are
distributed so you have multiple copies
of the data failover happens
automatically in a subsequent mode so
you don't really realize that a node has
failed if you wouldn't get the
notification by the logging and they can
also automatically resynchronize so if a
node has failed due to heart of a
failure you replace the machine you
start this node up again and it will
register back into the cluster retrieve
the data and we'll continue working
without you doing anything it's
transparent as already set to the
application supports transactions and I
have some more info we should continue
in memory indexes that already mentioned
big bummer my skew cluster is not
suitable for any application so if you
think you can make it drupal highly
available using MySQL cluster think
again due to its nature there are
certain workloads in query patterns
where MySQL cluster doesn't perform very
well especially anything
has to join multiple tables together or
if you have to make range scans where
you need the data from every single line
of your table because this requires a
lot of communication between the nodes
in the cluster and that simply takes
longer yes
it handles rights very well in fact much
better than read queries so if you need
to pipe a lot of data into it just use
several MySQL servers and you'll all the
inserts deletes into the cluster using
multiple nodes so that is possible and
in fact I have a slide that I wanted to
show you here if my clicker will work so
I think anything else has been said
Network relation latency is crucial you
can combine with replication to set up a
replicated cluster in another data
center if you need it doesn't support
foreign keys might be a gotcha here's a
more elaborate picture again here these
other storage nodes that you have and
this is really what my skull cluster is
all about then you have a small
so-called management node which takes
care of configuring the cluster but only
at startup time once the data nodes have
booted up so to say and they know their
peers you can even shut this thing down
this is a very small process that you
can even install on one of the MySQL
servers on top of them so here in this
example we are using three mascar
servers to talk to the cluster something
that's missing from this picture you
don't need my squirrel for this this
cluster is fully autonomous and you can
use its own API to talk with cluster
directly so in a way my school cluster
is yet another no SQL key value store
with high availability that you can use
and we have I think a Java API and the
Python API that you can use in your
application to store and retrieve data
from MySQL cluster without even using
SQL if you want to the question is if if
it's usually the case that you use a
load balancer to distribute load and
sure you could either configure the
application to be aware that there are
multiple my score service you use a load
balancer to distribute the load
everything is possible or down here
now the my squad service here speak the
so-called NDB API so they to query the
management server for the IP addresses
of all the data nodes that are available
and then it depends on the data that you
want to get which of the notes they are
contacting so you don't care about this
it's done automatically do the MySQL
server instances have a query cache sure
you can use the query cache is it useful
yes it might actually hear it it can be
combined with the query cache if needed
and especially since joins and certain
queries don't perform that well the
query cache might actually be beneficial
here so the question was if it is it
possible to use my school cluster as one
big my school master server for
application and that's exactly the case
that I wanted to show you here so
cluster comes to paralysing inserts
particularly so a colleague of mine came
up with idea hey how can this be
combined with replication and making use
of other storage engines to distribute
the read load and this is the picture
that he came up with so your application
needs to be aware that reads and writes
need to be split you can use for example
my skew proxy or a load balancer that is
MySQL aware for this so any inserts go
into this direction you have two MySQL
servers and they use my skew cluster to
store the data and have synchronous
replication and then you set up a
regular as in Cronus MySQL replication
stream that replicates to one or more
MySQL servers that use regular storage
engines so up here the data is highly
highly available start in my secure
cluster and it's then being replicated
into a normal of my item or any DB
tables and you can then run your queries
that are more complex on this side of
the story so you have the best of both
worlds and that's the set up that has
already been set up in production with
some of our users all right another
interesting approach to replication
comes from a company named coder ship
based in
Finland I guess somewhere in Scandinavia
and they basically patched in ODB to
create a synchronous replication
mechanism inside of InnoDB and it can be
used to provide both high availability
since the replication is synchronous
among multiple MySQL servers as well as
high performance since you can
distribute the load between those
machines and they are not using the
classical scheme of using two-phase
commit protocol to make sure that the
data is synchronized they call it
certificate based replication their
white paper is highly technical I admit
that I haven't understood it but it
seems to work quite impressively well so
Galera is something to keep a close eye
on they are very actively behind this
thing mmm if you don't want to set up
pacemaker you just have a MySQL setup
that you want to make highly available
the MySQL master master replication
manager is the tool to take a look at
it's a Perl script with a very active
community that takes care of nothing
than making sure that my square servers
in a replication configuration are being
made highly available by moving a
virtual IP address and making sure that
the master slave relationships are set
up properly so this is the smaller
version very dedicated and specialized
to MySQL pacemaker really is the big gun
that can do much more things and it can
also support rebalancing which is kind
of nice so if your application is
capable to send reach load to at a
different IP address mmm provides a
floating IP address that can move
between replication slaves based on
which of these slaves is up-to-date if
one of the slaves is lagging behind the
IP address will move to another slave
that is fully up to date which is kind
of neat what happens if every slave has
a big lag I guess you can either
configure mmm to give up in this case or
it picks the one with the lowest lag
that would be my wild guess but I have
to admit
or it should go back to the master yeah
good point if the master steer there the
virtual IP address would move to the
master yes how well does mmm handle
split-brain it has functionality that
makes use of an arbitrator so I would
guess that they have considered this
case and should handle it gracefully
cool stuff I've seen webinars of this it
does a lot of the things that my skill
replication currently isn't capable of
there are more redhead cluster suite is
an application that does stuff pretty
similar to what pacemaker does but with
the blessing and support from redhead if
you happen to use the Enterprise Linux
edition I've said other operating
systems have similar functionality
solaris has open h a cluster which is
the open source version of solaris
cluster this is really the big big
gunwale Solaris Enterprise UNIX
operating system this thing is quite
impressive and they have a special MySQL
plugin that you can use if you have
Solaris in your data centers this is the
way to go and what not really a Han H a
solution but kind of nifty flipper is a
little perl script that allows you to
switch master and slave by moving
virtual IP addresses manually on the
command line if without having to
configure the my CNF file manually and
making the changes flipper does this for
you in case you have no need for
automatic high availability but you just
want to be able to switch between one
MySQL server to another one for
maintenance purposes as an administrator
so kind of neat and with that I'm
finally through more questions comments
feedback the best way to test failover
of MySQL what is the best way to test
fail over of mice
well at first you would have to set up
an H a system like mmm to get started
and the best way well kill me ah -9
would be one option ready to shoot the
process with kill -9 take the IP address
offline pull the cable
insert random data into the table files
change the routing tables also a good
idea there various ways on how to to
trigger it but for a basic test just
kill the process and see what happens
and use the manual system most of these
failover systems usually have a manual
trigger that you can use if that one
works as a first step then you can start
playing with killing stuff and
destroying things any more questions
otherwise going once going twice thank
you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>