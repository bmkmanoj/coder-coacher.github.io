<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Modular Module Systems: A Survey (Northeast Scala Symposium) | Coder Coacher - Coaching Coders</title><meta content="Modular Module Systems: A Survey (Northeast Scala Symposium) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Modular Module Systems: A Survey (Northeast Scala Symposium)</b></h2><h5 class="post__date">2012-04-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/0TFtAL-Vy80" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so this is basically a survey of module
systems in various programming languages
and some of the things that I've noticed
about them being kind of a language guru
if I daresay or at least a polyglot and
what I want to start with is basically
what is a module all about what does
that mean not every language has a
syntax which says module and so what are
we talking about if we say module and
there's kind of a superior find of
effect here linguistic relativity
because what you think a module is is
certainly influenced by the languages
that you know just like what types what
you think about types is influenced by
the languages that you've had experience
with and so if you tell the sea
programmer that you're doing these fancy
things with types they'll think you're
kind of crazy but so what is a module I
think there are three things to look at
maybe the simplest is that it's just
about separate compilation right I want
to have my program broken into units
that can be compiled separately or in a
dynamic language maybe even loaded
separately when you when you import them
second it's about namespace management
which is a pretty simple idea but it's
extremely important and third maybe the
the richest area is that it's about
abstraction and one element of
abstraction is just hiding right just
concealing things but also a distraction
means parameterization and so we'll look
at both kinds of abstraction so I'm
going to start out with that programming
language that's kind of the lingua
franca and known as a bastion of
modularity see so in see a module if you
want to call it that and maybe you can
use scare quotes a module is basically
just a file and several languages have
this approach that a file is a module in
some languages
you can have files where you can have
modules which are not files but all
files of you know it goes both ways and
the other interesting thing that C does
that we don't always see in languages is
this idea of separating declarations
from the definitions so that you can
have an interface a dot H file and then
have an implementation in dot C file and
that's something that Java more or less
abandoned but some other languages try
to keep some distinction there too so
that's the separate compilation
component what about namespace
management and see do we have anything
well basically all that you can do for
namespace management is don't export
stuff by making it static within
whatever module or file that it that
it's in and that's that's what you get
when we move to C++ of course namespaces
or something that got a lot richer with
C++ and so we have indeed syntax for
name spaces that can enclose things we
can import them we can import just
particular members we can rename them
which I actually didn't know but I found
that and then we've got this scope
operator that can reach in just like a
dot operator in more modern languages so
namespace management in C++ is fairly
rich what about abstraction and hiding
so just in pure see there's this pattern
this technique for doing abstract data
types where you can declare an opaque
type declaration you just say struct
stack and you don't know you don't say
what it is but that's ok as long as you
only refer to pointers to it then we
don't have to know what its members are
what size or shape it is so that's a
kind of opaque type declaration you
could even say it's a fancy existential
type you can make an analogy except it
breaks down pretty fast but but there's
also this trick of using void star to
say that this is just some pointer and
we don't care what it is and so generics
work that way in NC in C++ we of course
have templates as much as I've tried to
forget about them
and that is more like a real universal
quantifier a real abstraction of a type
except that it's not really type checked
in advance its type checked once you
instantiate it and so that makes
templates a lot more fussy I would say
and the error messages are horrible they
certainly makes calles type errors look
look concise and understandable so so
that's type abstraction in C++ there's
other kinds of hiding besides type
abstraction and of course in most
object-oriented languages we have
classes which have private members so
private is a form of access control
that's a kind of hiding so that's that's
useful and then there's another common
technique which we can call privacy via
subsumption which is a fancy name but it
just means that your private stuff
doesn't really have to be marched
private if your interface is such that
it doesn't have any private stuff but
all the real work happens in some
implementation class which is derived
from that or implements that or whatever
your terminology is so although these
things are not marked private I'm not
going to get access to them as long as
I'm only seeing them at the super class
level struct in class are
interchangeable in C++ it turns out you
know the only difference between classes
struct is that a struct is by default
public and a classes by default private
but other than that you can you can do
this but this is a common technique in
object or any languages anyway to have
an interface class and an implementation
class so that's C++ now we're going to
move into Haskell and look at some of
the same ideas but what's interesting
about Haskell is that as far as modules
go it's not very sophisticated the
Haskell module system is mainly about
namespace management so you can do
things like up here I say I've got a
and they can be nested which which is
useful this is the set of definitions
that i'm exporting so i can limit what I
export and then I can import things I
can do imports where I only import
certain elements from there I can do
some renames or qualified imports like
that so you can do namespace management
with ease but they don't get you a whole
lot else and then the other major thing
in Haskell is type classes right and so
our type classes modules well I lent too
fast type classes are very interesting
they can do lots of great things they do
a kind of name space management in a
sense that they do overloading right
it's like a principal over loading
mechanism this is an example from quick
chek which is the randomized testing
library for Haskell and this was pretty
neat the first time I saw it definitely
that you can define a class arbitrary
that allows you to generate values of
arbitrary types and I haven't said what
gen is but you just it's something where
you can pull values out of it so you can
define that for all the base types like
boolean and integers and so forth and
you have you have random values of those
types and they need to find these
derived type classes so that if I have
an instance of arbitrary for a and B
which are type parameters then I can
generate pairs of a and B of course by
pairing them together and there are all
kinds of definitions of that in quick
check so that's a kind of overloading
and then I can do a kind of abstraction
based on these type classes so any
function could have basically for all
alpha for all types so that they
implement these two type classes then I
can implement this function so that's
are they modules I'm a little hesitant
to call that a module but but it has
some of
some of those features the next language
I want to look at is the one I've spent
the most time in and that's ml
especially standard ml just quite an old
book now but I still think there's some
ideas in ml module system that are
pretty interesting and in case they're
not widely known I'll show you some some
examples of that so the first thing that
we do this kind of gets back to what I
said about see where you've got a
distinction between declarations and
definitions right and so signatures are
a way to just have declarations of types
and values so that like for example
here's a collection signature where I
define a type T which is parameterized
by a in ml the type parameters are type
operators or post fix so in Scala this
would be T brackets a and here it's 80
so this collection has a value empty and
a function is empty that returns a
boolean and we can define all kinds of
signatures like that you can mix and
include signatures in other signatures
like this ok so I define a queue and
then a deck which is a double ended
queue includes collection and then it
can have structures nested structures
within it that match certain signatures
so the double ended queue has you know a
front side where you can ank you in DQ
at a rear side where you can do the same
so those are some examples of just
specifying the values or the functions
that that are available or should be
available so next what I do is go to the
definition side and that's called a
structure so structures are just nested
collections of definitions and they can
be constrained by signatures so up here
I define a structure deck which is
constrained by the signature deck on the
previous slide and this actually is an
opaque signature match which basically
provides a form of abstraction it means
that this
definition of T as a pair of lists won't
leak out of this structure it's
constrained to stay private inside there
and you can't rely on it being a pair of
lists from outside so that's a very
important form of hiding and then we can
define some of the functions we can
divine substructures n and so on okay so
if the ML module system was just about
signatures and structures it wouldn't
look all that different from what I
showed you in see where you have
declarations and definitions and you can
have abstract types and see but what
makes it a little fancier is the next
thing which is called functors and
functors are basically structures that
are parameterized by other structures so
in this example up just in case you're
familiar with the name functor from
categories here from Haskell or scholars
that or something the name kind of comes
from the same place but it doesn't
really mean the same thing this doesn't
refer to the applicative functor kind of
thing with the certain operations it's
just it's just a name for functions of
structures so what we do here is to find
a functor with the name test deck and it
can take any structure any module d
which satisfies the deck interface and
then we can define whatever we want
based on that right so in this case I
might define a particular Q and then go
through and run some tests on it and
make sure that it works the way i expect
or whatever and then to actually
instantiate that functor a little bit
like instantiating templates in c++ but
it works better is to what i will do is
take the functor test deck and then pass
in whatever implementation of decks that
i want and so if i've got three
different implementations that match
this same signature i can just generate
three different output structures based
on that and all of them will be capable
of testing the different implementations
of the deck generically right so that's
kind of a valuable idea too to be able
to program at the love
of structures where we have essentially
functions that can take in all these
definitions and create new definitions
based on those this leads to a style
that a lot of ml programmers adopt which
we call functor eyes to the style or
heavily funk turd style or something
like that and what we're doing there is
that for most dependencies between
structures so it's very common to have a
module need to refer to another module
and maybe those both refer to other
modules and so on in most cases what you
could do is lift those dependencies up
and make them functor parameters okay
and now your module is basically closed
with respect to any other structures
that it would depend on it only depends
on signatures for example and you don't
have to do this it's just a style that
that some people adopt so this is some
code approximately from from the SML
compiler itself and what it does is
these are course the body of the functor
is missing because it would take up much
more than a slide but this compile
functor takes a code generator module
which is machine specific and generate
some kind of other compiler interface
and then what we're doing here is
basically putting together the repple
for SML a read of Al print loop that we
can interact with and so we sort of
stack these abstractions together such
that well you can kind of match up the
signatures here except that compiles
zero and top compiler not exactly the
same but one subsumes the other so it
still matches so to look at the
instantiation of it basically we take
some code generator that's machine
specific for whatever architecture and
wrap that to create the full compiler
and then create the reave a loop from it
and an interactive top level that we get
out of that and you can reinstate these
things lots of
of course if you want to do cross
compiles then you can substitute in
different different machine
specifications they're different code
generators of course cross-compiling is
something that the ml compiler is good
at but it's not something you want to do
at the read of our print level because
you couldn't actually eval maybe you can
you can read and ship it to some other
computer any valid so this is the
functor eyes style in in ml and it's
something that I think is worth looking
at and and doing perhaps in Scala yeah
it's it's very similar and I'm going to
show I'm going to show just some
examples of ways to think of
parameterizing different sorts of
algorithms in and such to get modularity
and yeah that's so Scala I think you can
do much much more with with traits then
then you can do with functors although
there are some interesting differences
one difference is in ml there's a notion
of link time and basically these these
functor applications happen before
runtime so your compiler goes alone and
it's going to actually execute all of
the functor applications if there's code
that gets run it gets run before the
normal run time and so this gives you a
kind of rudimentary staging that you can
do and in in Scala we won't have that
the any classes or objects you're using
in this way will be evaluated when
they're evaluated later on so that part
of it is more dynamic so let's just look
at some scala code i was playing with I
i created a little data type for a
directed graph and this is kind of I I
might call it a double decker trait or a
double decker interface because I'm I'm
used to ml and I guess it's just a
factory pattern right
I've got these operations on a graph
which is that the inner trait and then i
can create it as well but that gives me
more like what we have in ml for
signatures because the signatures are
not dependent on having a self type or
something but but here I'd you split
them into those two parts so here's
here's my directed graph signature and
then this is mutable for which I
apologize but I I don't want to show off
functional programming chops right now
so that's that's it but when we go to
represent this and implement this you
can think of different ways to represent
graphs and so the famous ones from
computer science textbook might be that
we can use an adjacency list or an
adjacency matrix and of course maybe the
list has better space performance for
sparse graphs and so forth they're
different trade-offs but in general we
can do is look at this is just a map of
vertex to vertex to edge whatever the
data types are for these things and so
the first the first map we'll take our
vertices here or maybe the rose and the
second map is about the columns or maybe
it's a list but what we can do is be
completely generic in which kinds of
maps we want to use in each case so
here's an analog of a functor that we
could do where there's kind of a lot of
type code at the top but what I'm doing
is creating a directed graph
implementation using the mutable map
factory twice and the first map is going
to give me that first level and the 2nd
mass going to give me the second level
and later on we can decide what those
should be right but then I can do my
graph implementation based on that and
the representation will just start off
with an empty map of the first kind so
we can implement graphs where
essentially the entire data structure is
outsourced to these other these others
mutable map
representations and so we're just
relying on that to build our own notion
of a graph and then we can instantiate
that that functor using whatever types
of maps that we want and so something
like an adjacency list might have a
hashmap for the first one and a list map
for the second one or if you use to hash
maps and it's a little bit more like an
adjacency matrix I suppose or at least
that's the analogy I'm going for but we
don't have to rewrite any code right
it's just the same representation I mean
the same logic the same implementation
but we're substituting in the essential
parts of that data structure to get
different space-time characteristics
right the next thing I wanted to be able
to do is take some more inspiration from
C++ and C++ programmers have this maybe
it's a fantasy or maybe just a desire
that that we can have algorithms that
are implemented independent of whatever
representations you want to use and so
algorithm is part of the standard
template library and I wanted to do
something a little bit along those lines
so here's an implementation of graph
search as a functor you know using the
analogy to ml where I can define a
search but a lot of the way that I do
the search can be outsourced to these
other signatures or other modules that I
will instantiate at some point right so
to do a search I need a work list to
decide what to do next or to keep track
of where I am and that work list can be
some other signature that I just defined
somewhere else and then I need a set to
keep track of which ones I visited and
so I can use the mutable set factory to
get to get that so here's here's the
trait for that work list it worth list
is just something that might be empty or
I can put something or take something to
get it's beautiful and I can create one
so it's the factory and the
the ADT all together like that so that's
a worklist signature and of course my
work list could be implemented a variety
of different ways one way might just be
to use a stack so here's a simple way
with traits to build a last in first out
object that extends worklist signature
and to put a new object you push to take
it you pop but you can do the same thing
with a FIFO right to put you in queue to
take u DQ and both of these implement my
work list signature so then it becomes
very flexible to have different
algorithms that arise from different
choices for these so breadth-first
search is basically my graph search
where I just plug in a FIFO and depth
first search where I plug in a stack
instead and you you get a lot of
flexibility out of that so that's a very
simple example but it reminds me of the
way that we do things in ml so I just
wanted to kind of show you what that
looks like here's just an example of it
running I drew a little graph and I i
implemented it even this example is
parameterised by the graph
representation so you can create this
whether it's the matrix or the set you
create the same graph and then you can
run breadth-first search or depth first
search either way and this this produces
the past that it took to get to in
reverse order but the path it took to
get to the the node okay so now I just
like to step back a little bit and make
a bit of a point about modularity in
general it seems to me that a lot of the
fancier ways to modularize and reuse
code start out in untyped languages and
then we eventually once they prove
useful and we understand and we
eventually find ways to give them types
and so traits came from similar
mechanisms have been proposed but but
this paper is about traits and small
talk and there are older systems flavors
was a kind of mix in that made it into a
common lisp object system and there lots
of ideas here but the what they have in
common is that they're not really
concerned about types the way that we
are in Scala so there's a way in which
we can look for inspiration at the less
well typed languages maybe to find ways
to do modular developments and here is a
popular / infamous blog post by Gilad
bracha that types are anti modular which
I don't necessarily disagree with and
he's a proponent of some of some of
these systems as well so basically well
you can read that later and then here
from the C++ reference manual there's a
quote it wasn't obvious how to combine
the C++ strong patch static type
checking with the scheme flexible enough
to support mix-ins used in some Lisp
dialects so what that's basically what
they're saying is that okay we had
templates and templates can do some
fancy things but we don't really know
how to type them still and so what I
think is is valuable about Scala is that
we have ways to to type check this stuff
there is one thing I found just last
night I wasn't aware of this system
before but this is an account of traits
in a specification language that goes
back to I think this is nineteen eighty
five or so and although it's a
specification language not a programming
language there there clearly are typed
in four there's type information here
and I'm not sure how or how well it was
type checked and that kind of thing but
it's something i would like to look into
more because it seems to be an earlier
instance of typed trait like things that
I had never known about all right thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>