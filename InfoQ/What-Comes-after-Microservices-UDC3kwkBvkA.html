<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What Comes after Microservices? | Coder Coacher - Coaching Coders</title><meta content="What Comes after Microservices? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>What Comes after Microservices?</b></h2><h5 class="post__date">2017-10-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UDC3kwkBvkA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so first of all wow thank you so much
for everyone coming out to hear my
thoughts about the future or whatever
I'm sorry not everyone has a place to
sit I hope that this is going to be
really interesting I guess we'll all
find out together so my name is Matt I
work at uber working a lot of back-end
infrastructure and stuff like that and
so I've been there for a couple years
and learned a few things then I would
like to sort of share with you a little
story so a while back as you may have
known like uber has been growing a lot
and in the process of this we hired a
lot of Engineers when I first started
two years ago there were about 200
engineers and now we find ourselves two
years later with about 2,500 engineers
and so that is more than 5x growth year
over year as you can imagine that that's
not that's not very common or very easy
to sort of incorporate that much you
know that much new talent so quickly and
like all good engineers there wrote a
lot of software I mean otherwise why
hire our engineers right if you're not
gonna write a lot of software that's why
you need them so so they did we got them
and they really wrote a lot of software
and much of that software on the back
end anyway it was deployed as services
so you can call micro services you like
I mean you know playing buzzword bingo
or whatever you can tick it off a few
more times but like Emily and their
services here's the total count of
services in our deployment system and
you can see that it's going up fast and
I didn't really start at zero that's
just kind of prehistory where before
things were actually in the in the
system where I can keep track of this
eventually they all got migrated over to
and so that ends up being the very real
number on the right so there's like a
lot of services and so here's a here's a
dashboard of that we're sort of tracking
I took that this morning so that is the
latest freshest up-to-date number this
is from the the instrumentation team who
is trying to sort of make sense of
this you know this whole
service-oriented architecture this big
swath of micro services and as you can
see not even everything is instrumented
them but you know the important stuff is
right and so I say all of this to sort
of establish that we are way down the
road of building out micro services we
have embraced it big time and as you
probably heard you may have heard me
talk about this your other people are
talking about this you know they caused
a lot of problems right like breaking up
a monolith it's like the cool thing to
do but once you have it broken up then
it's causes a new set of problems like
it's hard to debug and you know it's
hard to understand the system as a whole
now that you've broken it up into these
same you know the same parts you see
straight off we're trade-offs worked
both ways and you know it's hard to
profile etc but some new kind of curious
problems are emerging which is maybe
micro-services make it hard to
collaborate I know that sounds like a
bit of a paradox I'm just gonna I'm
gonna leave that there for a minute and
feeling a little bit more of the
background so you take a step back like
like why should we use micro services at
all like like I know it's cool everyone
is talking about it it can now go to a
technology conference nowadays without
seeing so you know every other talk is
like something about micro services and
and obviously we all agree cuz cuz look
at this room what's filled we all we're
all pretty excited about this micro
services thing so so what's what's so
good about it well maybe you know easier
releases like I guess you don't
necessarily have to release the whole
thing if you make some change to some
small part you can only just release
that and you know releases are
disruptive that's the you know that's
when things break is whenever you
release them so okay fine
yeah probably I mean I guess I guess
that's good but like another kind of
argument goes like oh it's more
efficient and I guess I guess that it I
guess there's there's some truth to that
you could scale out perhaps different
parts of the stack you know maybe if you
need more video encoders or you know
chat socket aggregators maybe you don't
need to scale out the whole the whole
stack you don't need a hundred more
copies of everything you can scale out
just
the parts of the stack that you need
more of okay fine
but at the same time like I kind of
don't by the efficiency argument because
now by putting the network in between
all these processes you've added all
this extra overhead of you know our pcs
or Q's or whatever it is you're using to
talk in between them and it's just a lot
more I mean it's a lot less efficient
for computers so maybe efficiency kind
of I guess but I don't know kind of not
buying it so scaling the organization I
think this is where where we have come
to a doober anyway is I don't think we
could have scaled our engineering
organization as quickly as we did if we
did not embrace micro-services model and
I think it comes down to this concept
like like why micro services like what's
good about that is it comes down to this
concept of coupling and specifically of
loose coupling and we we have you know
kind of a couple or I have a couple of
different sort of perspectives on this
my previous company voxer was a mobile
messaging company we did in micro
services as well but there are only five
of us and we got to some pretty
interesting scale and but we built micro
services anyway I'm five engineers we
had like 20 services and but at the time
we were you know it was kind of like a
cultural fit forever you know the team
we consume you know we used a lot of
open-source we produced a lot of open
source this kind of you know more
modular loosely coupled system worked
really well for us and we you know
scaled different parts of the stack
independently like that was cool but you
know ed Eber I think it really like was
thrust upon us I don't think we really
had much of a choice the early Ober
started with with a big monolith and it
took a long time to sort of break it
apart we're only just now finally on the
other side of our kind of monolith
adventure and so so that was you know
that was a huge project that I feel like
we could not have done that if we were
not more loosely coupled because we just
would not have enough time to coordinate
and plan and and just sort of guide all
the efforts of all these engineers
another aspect that that you know comes
into play when you know considering sort
of how coupled your system is
is the is the mono repo versus many repo
debate and at uber we are squarely on
the many repo this is a quick little
check that I've just checked in a few
times just there's no official tracking
of this but you this is our internal git
repo and you can see that as of a few
days ago there were 14,000 repos in our
internal git repo and you know some of
them are like configuration and Zulu and
you sort of go down this loosely coupled
path after a while you're like well sure
everything is a you know everything as
well make it a repo for everything the
configuration for my service is in a
separate repo like why not a lot of
people who come to who come to
engineering from places like Google
where they have this fantastic mono repo
and an exquisite tooling that makes it
all that makes it all possible they sort
of pine for the days when they had all
their their single repo and it's really
interesting cuz like I think I kind of
do too like it sounds it sounds more
elegant you know like it sounds nicer it
sounds like being more responsible
software engineers like this just kind
of seems like I don't know haphazard and
sloppy but you know I think the way
Google got there was spending a
tremendous amount of time and
specifically engineering time they
invested heavily in building out their
infrastructure and it didn't just show
up overnight I mean this took a long
time to get there so who knows maybe
maybe we'll maybe we'll get fancy
tooling and get down to a mono repo I
don't know I kind of don't see it
happening but anyway so you know we we
built up this you know we built up this
team and we we wrote a lot of software
and you know we counter with kind of the
usual problems and and we've sort of
come up with our own without solutions
to these problems that that I think most
people who go through this kind of
scaling journey they encounter you know
things like the databases are too small
so we had to build a you know charted
database deal and you know it's kind of
weird making make sure you DP requests
are just haphazard willy-nilly JSON all
over the place so yeah we're gonna have
to get serious about our RPC frameworks
and it's kind of hard to find all these
services
coming up and down all the time you know
1700 of them or whatever so yeah you
have to have some solution for service
discovery and keep internally like you
know bossing ourselves just like
accidentally like we're gonna put some
rate limits in place like okay that's
cool and of course like the whole the
whole point of having this modular
system is that things can fail
independently and not take down the
whole site so we're gonna get some
circuit breaking going and you know
tracing it'll be able understand this
thing and I showed you the dashboard
earlier of the you know the tracing team
and release management it's like the to
deliver on the the potential of having
all these microservices teams need to be
able to release their software
independently but like that software is
not gonna release itself like there's
got to be some kind of an infrastructure
tooling that you know engineers can use
to say like how's my last one doing okay
I want to get my new one out there be
able to you know canary and roll back
that doesn't work and there's a whole
set of infrastructure there and so in
general I feel like we kind of these
problems in you know maybe we we built a
lot of custom solutions where where
there could have been other open-source
options like I don't know maybe a lot of
these things kind of evolved out from
under us like while we were working on
them like new like you know G RPC didn't
exist when we started doing our thing
it's like we have our own RPC thing and
you know a few a few other examples like
that but you know I feel like in general
we've gotten to a pretty good place with
at the infrastructure level you know
these are sort of like the basic like
you scaled up a bunch of micro services
like now what happens kind of problems
so thing is now we're finding some new
problems and that's what I want to talk
to you about is now that you've if you
you know scaled up a big big micro
services deployment there are those last
you know that last the last slide is
like okay cool you'll definitely want to
get all that stuff done but I feel like
there are a bunch of a bunch of new
things we're gonna have to figure out
and we're grappling with these now and
I'm gonna explain our thinking around
how we're trying to solve those problems
but I also want to I want to I want to
work with others to to figure out better
solutions to these problems so like
here's the deal after we've
gotten a lot of this productivity gains
from you know allowing adding adding
people really quickly and you know
helping them be productive we're sort of
finding that momentum is slowing it's
hard to make progress it's hard to make
seemingly simple changes now that you
know the org is bigger but also things
are spread out all over the place it's
hard to know where to make a change
changes that seem like they should be
fairly simple to make end up involving a
bunch of different parts and about owned
by a bunch of different teams and so I
think that the useful way to think about
that the problem here of this this big
deployment is one of composability the
micro services like i think the idea is
that we have built these like unix kind
of pipelines with text interfaces and
you can sort of mix and match them swap
them out and you know do one thing and
do it well and my experience is that's
very hard to do with with micro services
that are you know swapping objects with
types and running logic on them and
talking to databases and it becomes very
hard to construct that kind of
composable pipeline and but I think
we've you know at some level this is not
a new problem right this is reusing
software software you reuse I mean it's
been around since since forever it's
like always harder than it seems like it
should be to reuse your software
I think the difference that we've that
we have now with a lot of micro services
is we've added a service boundary in
between you know like all over the place
and if your change cuts through that
service boundary it might I mean it a it
makes it harder because you got to
golike work with some other people and
sort of get in there you know release
schedule but be it makes it be it opens
the opportunity that maybe you'll just
write some new software like maybe it's
easier just organizationally to write a
new service as opposed to going through
you know tying your schedule to
everybody else's schedule and figuring
out how to do these cross-cutting
changes it might actually be easier for
you to just like write some new thing
instead of fixing the old thing
so this is kind of a new angle on like
software reuse which is like we've we've
cheated the cost levers around a little
bit alright so let me show you this you
know to make it a little more real I'm
gonna show you an example of of a flow
at uber now this is super super
simplified version of how it works and
any other people who are watching this I
know those lines don't necessarily
connect to each other but there's no way
to put a meaningful set of boxes on a
slide that would have all the right
names and all of the correct thing
conceptually it kind of works like this
and it sort of serves to explain the you
know the situation here so so imagine
you've got a mobile phone and it's it's
talking to or we have this API layer at
the end it's called IRT API and if you
want to get picked up you're like pick
me up here that request goes to a
service called demand which manages the
state machine for for the marketplace
you know in the the point of this
marketplace is to match up supply with
demand
and that demand uses a bunch of
different services to get its work done
it goes off to optic to figure out what
things you're allowed to see so like
what products are available in your area
and like how much are they cost and you
know what icons are they use and all
that kind of stuff and then geo base is
a geospatial index so find the nearest
vehicles to you and but it also you know
filters down by your product
requirements so you're like I don't want
to Brax but you know whatever all the
all the different ways of filtering down
the the product sorted by by distance
from you and then disco is kind of the
routing engine that decides based on
various other various other services
that are not pictured here what the best
vehicle really is that we want to
dispatch and as supply runs the state
machine for the other side the other
side of the marketplace so just give you
a sense of I mean this is these are some
kind of core services that that are
working in here but what those grey
boxes and kind of like surrounding this
whole thing
is a absolute swarm of other services
and just to get a give you a sense of
what that looks like I went into our the
the the tracing team has a thing that
one of the services that are traced they
will draw a dependency graph and I
scrolled around on I this morning to
find to find our tapi and so there it is
oops missed the mouse there and then up
here whoops and up there is our user
service called populist so I'll talk
about that in a second but you can see
like there are a lot of lines going a
lot of places and so that's what it
really looks like okay I mean it's not
my my little my little thing with the
eight you know orange boxes or whatever
is - you know just to break it down so
it's simple enough so you can understand
this is this is sort of another view of
our tea API this is from our anomaly
detection system it's the best graph I
could find where you could actually see
like the count by one service so ignore
the colors those just mean something's a
little weird along along that path but
that big red dot in the center that's
our tea API and all the things on the
right those are all downstream services
from it and like here's here's optic so
like they're a bunch of downstream
things dancing stream things from that
so wanted to give you a flavor like it
doesn't really look like this it looks
like that whole crazy world but there
are some you know pretty important you
know some of those parts are are more
well you know trafficked and scrutinized
than others okay so imagine you have
this thing you have this you have this
setup and you're you know you're
dispatching people and you're matching
up rides or whatever and you want to add
some new products you want to deliver
food or route autonomous vehicles or put
some cars on a road that have puppies in
the back like I don't know there are a
bunch of different ways in which you
might want to change this system and
like how it works so let's take the
puppies example like you want to put
some you wanna put some puppy cars on
the road that's cool so there aren't
suddenly some new rules like the puppies
they're from the pound and we don't want
them to go very too far from the pound
and so we got to put some like different
kind of waiting on like where the people
want to go and how likely is it that
they're going to stay
than the the range and you know next
thing you know you have to change some
of this other routing logic because it
turns out there they're a bunch of other
things about like well the puppies can
only actually be on the road for two
hours and they have to pee so then like
we got to figure out some other stuff
there and then we gotta ask the users
because it turns out some people are
allergic to dogs or just don't like dogs
or just not into it and next thing you
know we have changes all over the place
to implement this very simple thing of
let's put some cute puppies in a car and
people will love it and now we got to
work with all these different teams you
got to touch all of these really
important services that are critical to
the business just for your fun little
puppy promotion or whatever right so you
can sort of see how because all of these
these are often team boundaries that the
puppy team has got a challenge like it
takes a lot of efforts to implement
puppies in this world and I think that
that's because these systems are not
composable there's no easy way to just
add in the puppy logic and I think that
is the world that we want to live in we
want to be able to have these have the
benefits of this you know very modular
system you know granular deploys and you
know teams on their uptime etc but we
want to be able to implement new
features without having a massive cross
the company you know architecture design
- implemented puppy situation so here
are some I here are some things that
that we're working on these are all kind
of works in progress but some are a
little further along than others but
these are general ideas we have around
how to how to make this better how to
make this whole thing more composable so
the first thing is a bunch of these
services and a bunch of the the
complexity comes from the fact that a
lot of services needs storage right so
you wouldn't have a you wouldn't have a
proper micro services deployment if if
things were sharing databases right like
that would be crazy no one wants to
share database sort of right right the
first thing you learn in micro services
school is like you can't have shared
databases so so fine so services want
their own storage but
man yeah a lot of services out there and
so you can imagine that's a lot and you
know all need storage but that is a lot
of different you know storage
installations that we that we have to
manage and because everyone wants their
own storage and they want to kind of own
their you know own some amount it's a
part of the data model right the user
service for example like if you want to
if you want a user you got to go out to
the user service and so this is the user
service and so that to the left and I
can't see the line but to the left those
are all the things that consume the user
service so everybody you know not
everybody but a lot of things want to
know about a user and so in order to
know about a user they had to reach out
to the user service and figure that out
so this is hard to cache first of all
like obviously if every time you want to
know about a user you always have to ask
the user service but it puts this really
big burden on the user service as well
then now they have all these customers
and they all want to know about user and
it's very very hard to make changes in
the user service if you want to change
something about letting you add some new
properties to a user or just I don't
know change how users work
you got a potentially coordinate with a
lot of customers and so developing
against the system with all these
services and all the storage is very
hard you can't spin up the full stack
just for you like even if you want to
like you can't just say I got a nice new
laptop I'm gonna put the whole thing on
there like it simply does not work so
it's not even just can you get all the
software running all the same time which
you can't it's also the software doesn't
make any sense unless you have access to
the data so there are a whole bunch of
stuff in various databases that kind of
all work together to make the thing work
right and if you're a developer you're
trying to make some change you want to
validate that it's working you have kind
of a challenge which is how do you test
it in a realistic environment and a lot
of what makes that environment realistic
is the data that's in these database
so we had some oh yeah one more thing
it's so like I said if you had if you're
the user service especially and you want
to change your you know chink you know
you got some new customers and they need
some new field or they want to change
the way something works you want to
change your schema you want to change
what kind of user objects you return for
these you know for these queries and
it's a real challenge if everybody's
depending on certain aspects of your
data model and it gets worse because
it's not just your direct consumers you
know your direct consumers are perhaps
all the way to the left of service a you
know calling the user service with there
are pcs but chances are you're also
putting something you're putting these
objects into a message queue and there
are some you know services that consume
it by a pub/sub you know maybe they're
on the end of some Kafka RabbitMQ or
whatever and you know you probably got a
data warehouse to like all these objects
these user objects they're like all
flowing into something so you can you
know run your run your bi or whatever
and so your schema changes now are
suddenly very very complicated because
you've got consumers upstream and
downstream and just all over the place
it's tricky so we set out to to work on
this project this is one that I've spent
a little bit of time myself personally
working on and we had some goals which
is I wanted to stop having the
conversation of if we have a lot of
services like it's somehow bad like once
you get past I don't know ten I want to
I want to add enough automation to make
it so that it doesn't really matter how
many services you had like I think if if
people had this if people said well you
sure have a lot of libraries in your
repo like no one would say like Oh too
many libraries but somehow saying too
many if you have 1,700 services like
that sounds really bad but I think lots
of people have 1,700 libraries so I want
to I want us to get to a world where the
actual number of services doesn't really
matter the provisioning services like
engineers should be able to just get
storage they shouldn't have to spin up a
cluster and you know figure out all the
details around that but more but more
importantly they should be able to
safely test with real production data
and this is a real controversial goal
still not a lot of people are on board
that this is that this is maybe possible
I guess I think eventually most people
get on board with this is probably a
good idea if you can do it safely but
you know safely is right there in the
line so like I won't only want to do it
if we can do it safely but this is this
is super powerful if you can if you can
safely work with production data I think
you can you can write better code the
first time and it's sort of easier to
sort of get your changes get your
changes in their fancy types by that I
mean thing you know types like like a
location or phone number or or email
address things that programming
languages don't generally have and if
you're you know serializing out to like
you know to thrift or protobufs or
whatever that these things are often
lost and that that the those these rich
richer types I think provide a lot of
value so we build a system but this
thing called dosa it's clever acronym it
doesn't really matter what it stands for
but but we think it's quite you know
quite clever and so here's the way it
works is you've got this library inside
of your service so your service a and
you know that you want to you own some
certain object you know like you're the
user service let's just say and so you
define the schema for this user service
and you've got this library and when you
start up you you find the dosis service
and the library negotiates the schema
and says hey look I think that objects I
think that users I look like this I
think they have all these fields and I
think that here are the things you can
do to them and you buy that like is that
gonna work for you and they as long as
they're there's some way that both the
the library and the service can read and
write each other's objects then we're
allowed to continue and so we we
register the schema and a schema service
that's used by both by dosa and by other
downstream components and then on the
back are a couple of I mean I don't know
it doesn't really matter how many there
are or even where they are but there's
some storage it happens to be Cassandra
in our case but it could be it could be
whatever we happen to want to separate
out the the dev users into their own
cluster but like fine whatever and so
how do we get to this this kind of
magical state of being allowing
developers to safely work with
production data well we have an RPC
gateway that if you are on your laptop
or you're on some dev server or whatever
we have a you know ssh authentication
scheme and you've write the same code
but when you talk to prod you go through
this RPC gateway and then your RPC has
some context associated with it and that
context is what allows us to do some
interesting things which is we have this
idea called storage scopes and a storage
scope allows you to implement a sort of
copy-on-write layer toward toward your
database your storage whatever you like
and that is that's sort of that's the
magic that's how we allow developers
safe access to production data so when
when reads come in like if a dev user
has the scoped list and it says you know
the scope is m junior and then prod so
first reads will always go to the reads
cascade through the scope list but
writes always go to the first element in
the scope so you can read you try it you
looking for u1 and you don't find it in
the MJS scope but you can read the
pradhan of u1 and then if you write some
u2 it always goes into the top-level
scope and this doesn't have to be - I
mean it could be some long list like
maybe you've got some team the MPX team
and they've got some fixtures or
whatever that they're all kind of
working on and so you can do reads can
cascade through through a scope list and
that way you know that way we can safely
not only work with production data but
the team can stage up some some
pre-production data before before it
actually gets released and of course all
in order to support the schema evolution
process like every the scopes also have
schemas so this so this allows you to
safely test schema changes because you
can drop a scope if you decide you don't
like what you did to it just kill it
it's copying right no big deal you'll
start over from the the underlying layer
so you can test involving your schemas
without worrying about breaking anybody
else so that's pretty cool
and so what we what we find is that
we're able to add a sort of
encapsulation layer to to our objects
and this a capsulation layer allows us
to transit other systems that don't
necessarily know about our schema so the
the things that we store in the database
are opaque blobs effectively and those
are fake blobs can be transported
through a message queue perhaps and come
out into some service B which uses a the
library that we provide to extract these
values and and interact with them but
this is sort of a way that we can get
some some amount of composability out of
our storage systems that we don't have
to teach the message queue for example
about our schema it doesn't have to be
aware of schema evolution or any of
those problems we you know so it's it's
a it's a step and and you know back to
the you know back to the user service
problem the user service can now start
shipping around a library a user library
like users don't you know user users of
the user service don't have to know like
I better make this RPC to the user
service to find out what a user looks
like they import the user package and
they sort of make their you know they
make their requests and of course that's
you know that's how we can get caching
and all the rest so we're back to this
thing there's another sort of tricky
problem here which is the the demand
service in this case is fly service
there are actually others like this
where we have state that needs to be
coordinated and now we've gone and we've
broken that whole thing up into a whole
bunch of different micro services that
all on their own all their own their own
state but sometimes we actually need to
coordinate like we want to assign a job
or if especially like in the in the Ober
eats case to be more complicated because
there's like inventory to manage and all
this other stuff and the way that we are
working or working on solving this
problem is by implementing the saga
pattern and if you've not familiar with
this you should check out Katie's talk
she's talked about this quite a lot but
the basic idea is if for you you make
these long live transactions that might
involve multiple different entities and
for
every action you you take you supply a
corresponding like undo action and
there's a coordinator that kind of
advances things through this state and
this is this is a really good idea if
you have things that need coordinated
state and the the tricky bit that we're
kind of grappling with is how can we
implement sagas but allow teams to
change the you know change the flow
change the elements of them and not have
to have full 100% coordination at the
team level like how can we make a a
pluggable saga framework and this is
this is an active area of development
and if anyone else is working on this
particular problem I would I would love
to chat with you about it so coming back
to the the really the biggest one I
think is that we got all these services
right and they all talk directly to each
other they all know about each other the
way that you want to make you want to
get something out of some other service
is you make an RPC to that you know to
that other thing and if you look around
and if you especially if you ask people
in in academia or just people have been
in the industry for a while they will
tell you like our pcs are terrible idea
like why are we relearning the same
things like like every 10 years
read this this christmukkah John blog
post here as well as he's given a couple
talks on it it's super good its sites
all these references and just shows how
like we keep running into the same
problems like again and again and again
like we wish local computing and remote
computing were the same but turns out
they're not and they're just
fundamentally not the same and as much
as we try to make them be the same like
they fail in different ways and they're
they're just not so the conclusion
always comes down to you know what we
should have a set of RPC is we should
have asynchronous message passing like
that would be way better and I guess so
like my conclusion is probably like I
don't know I think but you know a
secretest message passing alone does not
give us composability and I've really
been struggling with us lately and is
something funny going on here like like
why like why is it so hard to change the
behavior of the system and
there's a quote at the end of of that
RPC the RPC post that that's like the
you know that closed our quote which is
like this developer convenience really
Trump correctness scalability
performance separation of concerns
extensibility and accidental complexity
and you know I read that I'm like no
come on those things are great like I
want all of that stuff but then I
started thinking about it and I'm like
you know there was a time not too long
ago I don't know maybe like two years
ago where I probably would have had a
different answer like I probably would
have chosen developer convenience that's
interesting
you know developers are really expensive
so like when you don't actually have all
those other problems you tend to
optimize for developer convenience so
let's say that we converted all of these
you know all of these are pcs and and we
made all of these our pcs be be
asynchronous messages okay cool I don't
think that that necessarily fixes this
problem like we still have the challenge
of if you want to change how these
things are assembled there's no kind of
obvious way to do this to make a
cross-cutting change so let's let's zoom
in like on one particular interaction so
like the demand service sends an
asynchronous message not an RPC to to
the Geo base figure out one of the
closest vehicles it uses those results
and it says a disco listen how like
what's the best it says who has low say
ETA but it's obviously many many more
dimensions than that it turns out for
the current situation the answer is
puppies like puppies are closest you
know congratulations you win problem is
that user might not be into it and so
what we want to do is we want to have
the puppies team be able to add that
little block right there not touch
anything else like not till the routing
team the DTA people in the disco people
and all the stuff they want to just
stick up piece of code right in there
that says hey wait a minute
if you're ever about to dispatch puppies
make sure that the users into puppies
sounds so simple but there's no obvious
way to do this in this kind of the the
microservices are PC or async messages
or whatever kind of framework and I
think the world that we want to live in
in order to sort of have that kind of
flexibility is instead of services I
think a better model is one of
composable event processors so these are
things where we would would pass an
object along with some action and then
there is an there is some other way of
orchestrating those things together that
is I don't know what it is like maybe
that's the next generation of service
discovery maybe that's some kind of
workflow thing like I don't know I mean
these these ideas start sounding kind of
similar right like maybe maybe I'm like
am I talking about like Amazon's
workflow and lambda thing like I don't
know kind of but they're still lacking
the composability and not to mention
it's like way too slow so like we would
never be able to get the kind of
throughput that we need but they'll
probably fix that right you'll probably
make it fast eventually but what does
service discovery look like in a world
of composable event processors like are
you discovering a service like that's
kind of the problem like the problem is
we had to know who was on the other side
and service a has to know service B I
want to tell you this thing and then the
puppies team cannot wedge their code in
there and so I guess that's like service
discovery like I don't know it's it's
really really complicated and I think
super powerful but I want to take a
really big step back here for a second
and ask why in the hell do I care about
any of this
like I work at a transportation company
I do not work at a future of computing
company like this is not this should not
be our jobs like we should not have to
be building this infrastructure it's not
our it's not our product and I would bet
other than a few of you most of you are
not in the business of sort of building
these low level components either like I
don't know maybe you work for a cloud
provider and that's cool like cloud
providers may eventually you know figure
this out
but it's weird like what how come there
are no obvious solutions for fixing this
problem so I think it comes down to the
fact that the tools that that work for
building small like you're just getting
started like I got a Python thing and
I'll just make some you know Postgres in
HTTP it'll be great and it is great the
problem is that the tools for building
small stop being the best for building
big and the tools for building big they
just make no sense if you're if you're
building small and in fact people will
yell at you if you say like well I'm
worried about maybe I'll have scaling
problems in the future like you will get
seriously yelled at and people will say
you're not ever
you're not Google you don't need all
that stuff like it's weird like there's
real rage about like pre scaling you
know like are even worrying about
whether you might want to be scalable in
the future like I'm actually not sure
where that comes from but that's sort of
a different roblem thing is can't can't
change the fact that the tools for
building small are are just simply
better than the tools for building big
so I think we need to do as an industry
is we need to flip this we need to make
the tools for building big be just plain
better than the tools for building small
like for example like copy-on-write
storage like why is this not a thing
like if you had even as a one-person
developer you still get the idea that I
would actually rather test with my
production database I mean realistically
if you're one person you probably do
test with your production database but
like you what you would like to do is do
that safely you would like to be safely
working with your production data and
there's no obvious way to do this right
now so I mean that's that's a example
but so the list goes on and I think look
I think that the cloud vendors will
eventually get here but we need a vendor
neutral way of building systems that
work this way of building big systems
that are built in such a way even when
they're small that they're just better
so that if they need to become large we
can make them large and it can't be
controlled by one company like if if it
is it's never going to get the kind of
you know the kind of industry change
that I think we need to get here so yeah
I think this I mean this is this is the
tricky problem but I think it it really
you know comes back to this like does
developer convenience Trump correctness
like at first it absolutely does like
who cares about all those other things
like at first like at first you are just
trying to ship a product you got to get
something out the door like you do not
care about separation of concerns you
care about like am I going out of
business so all you care about is
writing software but then after a while
you're like my own developer convenience
I'd trade a little bit of that if I
could have you know some of this
extensibility or whatever so I think
that's just where we have to start I
think a good way to tell whether we have
achieved this is to look at our systems
and to see how composable they are
that's all I have thanks a lot
so there is some time for questions if
you have any
okay thanks Matt I think we've got time
for questions if anyone wants to put
their hand up I can run over right here
Clifford hi
I'm very curious on how your develop
environment looks like and how do you
you can possibly be spinning several
this several V pcs for containing all
those micro services together so how is
like your everyday work mostly work with
unit tasks or do you deploy on those
test networks how do you do that
yeah so developers I mean so developers
have have a limited subset of the whole
the whole system they have enough
services that they can kind of make
something useful happen but yeah I mean
it's a lot of unit testing and you know
integration tests we're getting more
more and more of that done but but no
you can't have the full stack and so you
have to find a way to test just you're
part of it and you know maybe it's
clever curls or whatever or maybe I
don't know but yeah you you just you
have to find a way to exercise just just
the part that you're working on because
it doesn't fit any more questions okay
how do you guys handle that dependency
during the release management like this
service needs to go live and in order to
get this service life you need to have
five other services to go live with it
and in order to do this you have to
break another five and the tree grows
yeah yeah yeah so dependency management
during releases um so it's obviously
complicated I think that the main answer
is all releases have to always be roll
back a bowl so you can't ever move
forward unless you can also roll it back
if that's not working and it might mean
that in the scenario you described it
might mean that in if there really is
truly that much coordination it might
mean that to roll this thing out I might
like take two weeks because like you
might have to roll
thing out and you know get confidence
with that and then do a few more things
perhaps I would say that generally that
makes people come up with some other
idea like like if it's that hard like it
it better be really valuable for for
somebody to want to propose a change
that's that cross-cutting so I mean
typically what people do is if it's
really that big is they'll spin up a
pair an entire parallel version of that
path and then try to shadow traffic into
it for a while they'll build a you know
some kind of traffic shadow or fork in
their RPC chain and validate that that
whole new thing works and maybe it's new
versions of a few different services but
they'll if it's that complicated
they'll pre spin up a dark version of it
and then as soon as the results look
good then they'll steer you know they'll
they'll flip it over to handle actual
traffic okay I have a question
concerning versioning of micro services
doesn't they help in the composability
of like micro services together to which
extent they have good impact or positive
impact or negative impact so but what is
what would versioning versioning mean
like you're you have multiple versions
running at the same time and you get to
pick the one you like yes I see yeah we
don't do that we we make changes all the
changes have to be backward compatible
and so we all you move forward and no
nobody knows what version anything is
it's like I don't even know how you know
like versions are like I get hash in a
date you know it's like this is the
version of the thing that we released
the other day and if you want to know
what code that was like the git hash is
right there so you can figure it out but
yeah it has to be backward compatible
silver like nothing is versioned about
the compostable event processor can you
explain a little bit more on that
do you have already something on it in
the pipelines yeah this is this is the
thing that we're actively working on how
we can you know it's it sounds like a
you know a major change so we're trying
to try to come up with a way that we can
that we can be more incremental
mental and you know get some properties
you know some properties of a system
like that and it's it's still it's still
really early days but I mean that's I
think something like that is is where we
have to go I'm actually not sure what it
will take to get there or even
necessarily like like what the right
abstraction is like are you moving
actions around or like I I'm not
actually sure but I know the properties
that I want the system to have which is
I want to be able to implement things
like puppies without changing any code
and we're just working backwards from
that like whatever whatever it will take
to to make that use case possible we're
trying to figure it out and I mean if
you have ideas on what such a system
could look like we'd love to to work
with you and like ideally we would build
some open-source deal that does this and
it wouldn't have to be re-implemented by
by every company that scales up there
there are micro services deployment hi
can you put up a slide where you
introduce dohsa I would like to take a
picture of it to be completely honest
okay I the slides will be on the on the
website you can get the drop the PDF and
like in glorious high resolution okay
thanks I mean I'll put it up if you
really want to see it but this one
that's the woman okay super I remember
you mentioned about using the production
data in the development environment and
then copy and write are you guys
currently using it how is your
experience so doses in production but
it's it's very early there are only a
few customers that are on it I mean it
said it just came out like a few weeks
ago but so far so good I mean the the no
provisioning and the the copy-on-write
is is a killer feature and yeah I mean
we'll you know ask me ask me in in nine
months and I will I will know for sure
how well it's going because we it's kind
of non-critical things that are on it
right now we want to get it to be the
point where where most services are on
top of dosa
um how do you handle transactionality
and consistency across
microservices yeah so that's where the
sagas come in we don't have like I
ideally we I mean we basically
discourage people from having that
requirement so we try to keep though you
know keep it within a given service then
you know if if you truly do need that
then you know we have we have ways to do
it I mean it's it's not all Cassandra
storage on the back end but generally
speaking anytime someone says we have
this requirement that can only be met
with a transaction it's kind of like a
red flag because like it's really hard
to scale those they just have
operational properties that are not not
the greatest so but in the case where we
do need to do like especially
distributed transactions like we're you
know we need to do things across
multiple services that either work or
don't work that's where that's where
we're building sagas any all questions I
had a question regarding how do you
decide is there a playbook or a set of
rules whether a certain new thing is
part of a new service or an existing
service oh yeah so right um no I think I
think it's just kind of up to the
prevailing forces of like what people
are available on which teams and where
the there's not really a guideline that
says services should be built like this
we kind of leave it up to teams to solve
the problem however it is that they feel
is best so it's not always a new service
like a lot of times people modify
existing services but like ya know we
empower the teams to make their whatever
choice they feel is the best if you have
if you have a situation where your
shipping libraries for accessing the
example the user service two thousand
other services how do you deal with the
versioning of the library to make sure
that
each of the other services is using
compatible version right well that's
where this comes in I mean that is
exactly the the use case here which is
the like the dosa layer allows services
to evolve and provides a schema
evolution path so that may be oh maybe
there are old versions that have an old
version of library but they negotiate a
compatible version with with the dosa
service so they can still read and write
old objects even though they don't have
the latest schema but importantly
because we have this layer that like is
an active service like it's an active
RPC like we can also now tell that
people are using an older version where
as a big problem with library like age
is it's often hard to know if some of
your users are calling you with an older
version of a thing but with this we
explicitly know thanks MA and thank you
all for attending we're back in here in
about 25 minutes with Josh Evans from
Netflix so please do come back thank you
mom</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>