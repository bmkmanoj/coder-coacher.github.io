<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Goodbye PrintGCDetails... and Other JDK 9 Changes! | Coder Coacher - Coaching Coders</title><meta content="Goodbye PrintGCDetails... and Other JDK 9 Changes! - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Goodbye PrintGCDetails... and Other JDK 9 Changes!</b></h2><h5 class="post__date">2017-10-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/M9AYK5PtX40" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you very much thank you very much
Wes for a very kind introduction
so clearly so obvious for my employers
during my career I spend a lot of time
working on JVMs I was for Oracle and
before that Sun in the June the hospital
for over seven years then after a short
stint on Adobe have been at Twitter in
the Twitter VM team for just over three
years now
and a Twitter we of course evaluate
technologies that we're gonna use in the
future so currently we're on Java 8 but
Java 9 is coming so we started looking
into it so I'm gonna share some of my
experiences about Java 9 so as we know
Java 9 is almost upon us right so this
was the initial prediction and well it's
been pushed out a couple you know a
couple of times so hopefully in July of
next year we're gonna have the first
general availability release for Gemini
that we can all move to and start using
right so what are the new features the
new interesting features that are are
that will appear in Java 9 well the
obvious one is jigsaw the new module
system I would like to take a moment now
to say that I know everybody's
complaining about the delays however
this is a huge task right you have a
very mature language you try to retrofit
it with a module system this is a huge a
complicated task
so given my live - give them a little
bit of slack about the delays I'm glad
that they're trying to do it right
rather a rush again getting wrong and
they will have to live with words and
for many many many years to come right
so everybody we talk about jigsaw well
what's what else is there in Java 9 well
Gil in the morning touched a little bit
but well there is a long list of
features in Java 9 that nobody talks
about because everybody suggests with
jigsaw right so for this talk I'm gonna
concentrate on a few of these okay and
in particular concentrate on three and
features that are related to performance
performance tuning profiling etc so the
first thing we're gonna touch upon and
is going to affect a lot of folks is the
unified JVM login framework and wall of
GC logs right so hands up who has like
who reads GC logs that work regularly ok
a few people who hates GC logs with a
passion all right excellent
you have the idea so for anybody who
hasn't seen GC logs I'm gonna
a little bit of a kind of overview and
whyever terrible and why you know the
jvm the new logging framework is you're
not gonna help us a lot from nine so
here is an example of a GC log if you
just you know type Java that agency
which shows you hey you have this option
verbose that you can say GC and you
enable for most you CA you get something
like this and every log record
represents a garbage collection you have
some information about what caused the
garbage collection is a location failure
in this case you have a heap information
before and after and how long did you
see lasted right so that's the proposed
disinformation and nobody uses verbose
receive during like really serious about
doing GC tuning because it has very very
minimal information and most of the time
it doesn't tell you you know what when
you know what went wrong here did you
see what happened and what potentially
caused causing the issue so the minimum
number of arguments I would command line
arguments I would recommend that you
enable and again we have to survive with
Java 8 for the time being at least until
July so this is not too late to actually
start using these options right the
minimum number of our parameters are
these and if you enable them so well I'm
gonna cover the first five the last one
basically sends that UC log to a file is
very very helpful so it doesn't mess up
your output right and the output doesn't
mess up the output of the GC lock so
please you know use that option so I'm
gonna show you what the other five do so
the output from a single GC looks like
this and somebody looks at for the first
time it is like completely overwhelming
right so I'm gonna kind of go slowly
through it and dissect it a little bit
so first pretty see details the first
thing that shows you is otherwise a GC
the the cause of the GC allocation fail
by the way there was no failure right in
the VM and what that means is basically
the location could not be satisfied
because the young generation was full
and it has to be collected before the
allocation can be satisfied right
but having failure in the lock just
freaks out everybody who you know hasn't
seen this before so you know don't use
the word failure in a log when there is
really like no drama okay okay so during
the GC the previous details will also
show you the different parts of the of
the heap that were collected in this
case there was a young collection and
the pärnu shows and the young
collection took just under 38
milliseconds and then only the young
collection happened during this GC so
the whole collection was 38 milliseconds
the other thing that produces details
shows the shows shows is the GC I'm
sorry the CPU times it shows user system
in real time as measured during that you
see and it's really helpful for example
if suddenly your GC times go up but the
the user time doesn't go up stays
roughly the same that means that maybe
another process started running on the
same machine pre-empting the you know
the JVM right if you suddenly you start
seeing system time going up maybe your
the JVM is paging right and these will
cause very very long disease so from
from those you can actually get like a
better idea what happened whether an
external event start reflecting
particular disease or is really the heap
shape itself so in orange we have you
know the output from premature print GC
timestamps which is in timestamp in
seconds from the when the VM started and
this is very helpful because you can
tell how far apart the GCS are in blue
who have the output from print heap at
GC and this is very very helpful he
tells you for every space in the in the
heap if the young generation the spaces
within a young generation in the
survivor in the old generation the meta
space it tells you what the occupancy
was and how big the space was before and
after that you see and that's really
helpful cuz you you see what's growing
in the GC whether a particular you know
whether the old generation is growing
fast or slow or how full the survivors
are etc this is very very useful
information then in magenta is the
output from print reference GC this
tells us how long the GC spend
processing references references here
are basically instances of classes that
the subclass java.lang ref reference
right like quick references phantom
reference etc so again sometimes maybe
the application is are using a lot of
finalized errs suddenly your GC times go
up maybe they're caused because of their
caused by the
the final reference processing which is
related to analyzers being being very
high finally print tenure distribution
shows you how many of us in green shows
you how many bytes per age cohort were
copied within a young generation and by
an age cohort is like objects that have
survived a certain number of collections
in the young generation so h1 is objects
that have survived
one young collection to origin ever
survived two young collections etc and
this is very helpful cause it tells you
the lifetime or expected lifetime of of
your certainly the objects so if that
changes maybe something's going on in
the application or maybe you know that
that could be reflected on the GC times
go up so all this information is really
helpful this is what we enabled at
Twitter where we have an elaborate
monitoring infrastructure that to my
colleague Megan talked about yesterday
but when we need to drill down what's
going on for that particular VM we do
let me look at you see lock and all
these information is really helpful
however it looks like a freaking mess
right and apart from all the nice colors
that are used right so at this point I
would you know allow me to give you a
quick overview about why the GC logs are
terrible right so so where do I start so
first lines are split so this was to be
one line but because I enable print
reference GC and pre-tenure distribution
the output basically was generated
between the first part of the line of
the second this way the line is split
and I don't know whether you can see
that premiere hope the curtain is not at
the front there is an orphan : either at
the bottom left
why is it doing there well the output is
supposed to be curly bracket I'm sorry
square bracket pärnu : and then tell
you something about the young generation
but again that split because of the
extra lines in between there's a
distinct lack of white space especially
before before timestamps there is a lot
of finesse
oops sorry I've got too excited about
this so there is a lot of unnecessary
for what the hell is this these are the
address ranges of the different parts of
the heap why is it helpful and why is he
filling up my log there is duplicate
information so the occupancy before and
after the disease
replicate the both a prenup GC and with
princessy details right
so all those complains now there are the
mild ones now let's go to the uglier
ones so this is a full GC so let's kind
of drill down on the important parts
well instead of GC that were saying
before now he says Fuji C remember then
then it tells us which part of which
space in the heap was collected in this
case is instead of party you say CMS
right cause CMS is the same as all
generation and the old generation was
collected now so we have square bracket
CMS :
and then it tells you that the OL
generation was collected and then it
took like 1.4 seconds right now let's
look at this GC which says GC says
pärnu but it took two seconds why this
young GC was so slow well actually
what's up fools you see in these guys so
we see a mess even if it doesn't say
Fuji see the log there might have been a
full GC and the way you you have to
recognize it of course is by looking for
the string square bracket CMS :
because that tells you that part to
taiga you know that collection the old
generation was collected but actually
like because the string square bracket
team as : doesn't appear because again
is split by some extra output in the log
so it's a complete mess right it gets
even worse believe it or not this is a
similar GC to the one I showed you
previously but if it's not obvious now
the line is actually split because some
other output from a different thread so
in this case the concurrent marking
thread is generating some GC logging
output and was emitted half way through
the output of the of the out of the
other GC so now you have randomly inter
lead output from like two different
threads and this is a mild case that you
can maybe be able to parse but some
cases so like messed up that is just
impossible to to actually make any heads
or tail of it so why do you log suck
I've been dealing with this for years
so formatting is inconsistent I didn't
touch on this but different formatting
for is GC so you you know not only you
have to write the code to parse one you
know the like let's say the same as
though you have to write the code again
like two other times the parts you know
if you want paroled and
there is missing information output is
split and also concurrent output causes
like random interleaving and because of
the stew basically they cannot be parsed
reliably I mean everybody has some sort
of usually Python script that can parse
them and it doesn't work all the time or
it misses information it's terrible I
mean it's 2016 I mean come on really
okay so thank you very much for
listening so but still going back to
this still this is really really really
interesting information in the log that
we learn a lot from it so let's see how
we'll be able to get the same
information in JDK 9 with a new JVM
unified logging so the first thing to
point out is that all those parameters
that I mentioned they are gone in JDK 9
right they're not like deprecated
they're just gone so let's all take a
moment to commemorate their demise and
ya know it's supposed to be a joke yes I
know it's blank
and and thank them for the service
ok you spoiled it now our new favorite
argument in JDK 9 ok take no don't do
that joke again so our new argument
favorite argument JK 9 is it's gonna be
X log ok and there is only one
command-line argument X log and then you
pass lots of options that you control
you control the log in different ways so
I'm just gonna kind of build up on that
over the next few slides so the simplest
version is basically X log colon and a
tag in this case GC lock : GC it will
enable log records that are tagged with
attack GC ok and there are many tax or a
time kind of corresponds to maybe like a
JVM module like GC will have class
loading unloading with class exceptions
or s etc but I'm concentrate on GC
because you know hey I'm a GC died right
and I'll be talking about DC locks I
hope it's ok you can also give a logging
level for for a particular tag so you
say Tod equals and the level so in this
case x log G C equals debug so we'll
enable debug level or logging level for
the GC tag and the levels are apparently
what most people expect you know error
warning in for the back-trace if you
don't give a level it defaults to info
all right so let's
look at the output from from a VM that I
enabled X log GC which is equivalent to
GC go simple right so this is a log
record it looks very familiar right
compared to what we seen earlier and the
second part kind of looks like verbose
GC the output I sold earlier is very
very similar but the first part there is
some new parts in the first part the the
first thing to point out is like the
first part of iya of the record this is
a timestamp again is in seconds
since the start of the VM right very
similar to what we saw before something
is going to catch a lot of people though
is that this timestamp correspond to the
time the log record was generated not
the start of the GC so you want to find
the start of the GC you have to subtract
it by just from this you have to
subtract the time of the GC from that
timestamp okay and it's different
compared to like verbose GC so keep that
in mind the other part of the output
that contains the level in this case
info right and at the tab that generated
a la grecque record in this case GC
finally for and remember that the the
logging framework is normally for GC but
on all the GC records have a GC ID so
this says that this GC was the 634 GC in
the you know in the log and this is
really helpful because you can have
several log records that basically
belong to the same GC and that's a very
easy way to combine them you don't have
to deal with like nesting and and all
that nonsense so this is actually way
nicer so the tags are hierarchical so we
saw GC you can actually add several tags
you know that makes sense and separate
it with classes so here we have X log GC
plus heap and I will enable heap output
GC heap output okay and and then if you
want to enable all kind of sub tags if
you want of a particular tag view you
can use star so G C star will enable all
the GC plus bla tags so it's kind of
convenient and that you know not all
paths combinations make sense so I have
some examples here keeper F and CPU make
sense for GC as we see a little later
but load and unload make sense for class
for you know for class records like
close to claim you know enables class
loading and class unloading
log records so apart from you know
deciding which tags you're gonna enable
and at which level you can also decide
where to send the output so after the
tag and level output level options you
can add the output option which is : and
inside our spanner output stander error
or file it goes in a file name and you
can omit the file equals if you want to
the default is standard output as you'd
expect and the file name can actually
include some special strings like like
in it is the case for JDK 8 like percent
P which will be replaced by the pit of
the process percent T which will be
replaced by the time the JVM started etc
these are really helpful if you storing
lots of logs on the same directory they
don't keep overwriting each other that
you can kind of separate them you can
also control what decorators to enable
so after the output the output option
you say again : and then a series of
decorators separate by comma and
different will enable you know different
decorators will show different things
like time you will show you am kind of a
timestamp kind of that shows date and
hour and time and all that stuff is
similar to preen GC date stamps that in
JDK 8 uptime is what we saw earlier you
can you can add the the P double process
as decorator etc the default is uptime
level in tags so let's look at a example
output this is GC and then we enabled
with the decorators time and paid so
instead of what we're seeing before now
you see that time generates this very
elaborate date stamp right and then the
second column is the page why is this
helpful maybe you end up sending the
output from different VMs to the same
place so again so you can reliably
separate it something to point out
though notice that the two columns in
the in the option so it's log GC colon
colon time comma page why is that
because the the syntax is that it's you
pass the tag information and then you
pass the output information call on the
output and then call on the decorators
so if I had only : time coma page I had
only one colon that would be interpreted
as a file name so it will actually
create a file name called time to come
up
and we send a log to the that file right
I really hate this a find is really
frustrating but that's okay so I've
showed you enough on how to enable
different things within the new in the
new logging framework so how can we get
output similar to what I show you
earlier in JDK 9 so this is the
incantation this is one line so
something I didn't mention earlier is
that you can enable different times at
different levels and you separate them
by comma right so we have now GC star so
all the tags of the GC tags at info
level because that's the default coma
gc+ ref at the bug level and then GC age
at race level then we send the file to a
particularly they should send a look to
a particular file name and we only
enable the decorators types a nap time I
don't think the levels actually you know
the showing what the level that
generator lock record in me I don't
think is very helpful they log it just
makes the log larger and these are a
kind of an one-to-one correspondence
these are roughly equivalent to the
parameters or so you are here roughy so
let's look at what the lock looks like
like now so this from from one GC with
with those arguments so we have a log
record of the start that says that's the
start of the GC a log record at the end
that says the end of the GC and how long
it took we have the CPU times that I saw
earlier is very similar to what we're
seeing with previously details then
again with the GC start at times we also
get some heap information in blue again
the nice column showing correspond to
the colors are sold earlier right and
the width showing the using the app time
decorator you now get those timestamps
and if you get the timestamp that was
generated at the start of the GC that's
the actual time some without the other
you want don't do it the time some at
the end of the GC cause remember that's
that's not the start of the GC is like
when the log record was generated as I
said earlier with GC ref a debug level
we enable the referencing processing
information again in magenta and finally
in green is the a tenure distribution
and as enabled with GC age at the trace
level okay so this is very similar very
similar information to what I saw
earlier and it's actually all more
precise which is really nice
so your local OTT however there's
something missing and is that the much
more detail about the heap shape so here
you have like a genuine information
about this was the occupancy of the
young generation before and after but I
really want to know how the survivors
were helpful the Eden's was etcetera
that's really really helpful information
when we track things issues down can you
do that it not yes you can yes we can
that's a kind of appropriate for an
election day man everybody's asleep
today okay so and you just enable the GC
heap tag at the bug level that's
basically exactly the same marker that
pre as with premium GC that I saw you
earlier in fact this is it with all the
extra useless information we don't need
but you have the exact the exact heap
information that is really helpful okay
this will triple your log size I think
but it's it's really helpful so if you
can handle the extra size is really
worth it okay just a couple of quick
things you can enable log rotation
this is done with extra parameters in
JDK 8 here you just add yet another set
of options to the X log command-line
arguments so file count for file size 16
Meg's so the log will rotate up to on up
to four files and each file is going to
be up to 16 Meg's and the cool thing is
that you can actually enable different
logs so let's say we want to enable some
basic logging like GC the the GC tag at
the very basic level it's tender
standard output so we're looking at the
console to see what's going on right but
then we want to enable more logging that
goes to a file you can get a past
different parameters in this case we'll
just send much more information to the
to the log file so that's that's really
cool that's something you can do right
now and that's actually something very
very cool and mainly concentrated on GC
tags but of course other useful things
that you can other usable tags that you
can enable class loading and loading is
an obvious one just to see where classes
are being you know they're coming from
exception so you can actually get local
record for every time an exception it's
known even if it's caught of course so
if suddenly you think that your
application is throw lots of exceptions
that there is some performance issue you
can track it with that etc
so in summary this is a huge improvement
right we have more control over the
output you can enable multiple logs
there is no interleaving a split lines
anymore every log records guarantee to
be on one line there's no you know
screwing around by different threads etc
and it can be much more reliably parsed
so I'm definitely looking forward to
have know how to deal with the current
GC logs and kind of dealing with this
which is gonna be great so hopefully
you're gonna find that helpful as well
okay alright so moving on to the next
topic which i think is kind of cool I
don't know whether is anybody's been
keeping up with what is so it's compact
strings so I'll give a little bit of um
kind of how the string class evolved in
Java starting with like the beginning of
time I the first Java release up to JDK
up to Java six so until Java six string
class had four fields it had the value
field which was a character array that
was pointing to the the array that
contained the payload or the string it
had an offset an account which was which
defines basically the subset of the
array that actually contains the payload
that B string corresponds to right so if
you want to do substring you just you
didn't have to replicate the character
you just create another string with
different offset and can't get that
different if you essentially on the same
character array and finally a hash field
so if you want to hash the string you
only calculate the hash ones because
sometimes could be time-consuming and
then you store it and then you keep
reusing it okay so from JDK 7 the
removed actually the offset an account
field so now you only have the hash and
then the value field which points to the
character array so now the character
array basically always contains the ID
you know all the characters that belong
you know that you know that the string
represents and if you substring then you
know you you might get like a new
character array there is a huge amount
of trade performance trade-offs and
other than footprint arrows between the
two different schemes so and I won't go
into them right now you can ask me later
but this seems to work pretty well in
most cases ok so now let's see how big
in in bytes are string of a given length
is so at least in hotspot
so we have 24 bytes for the string
object so it's the header of the string
instance plus the payload then 16 bytes
for the array header and then 2 times
the length of the string because
characters in Java are unicode right so
there are two bytes each so let's put
let's just pick an example at random so
let's say we want to calculate the size
of a 140 character string so it's
basically 320 the only ways got the joke
everybody's like looking really serious
okay so how can we improve on this
further so the observation is that if if
for example strings are tweets and I
tweet in English right and you generally
using only the Latin character set and
you don't use unicode half of your your
character is basically going to be zeros
because the look the cards can actually
be encoded in one bite and then the rest
is not really not gonna be used if again
if you don't take advantage of the full
Unicode so it would be really nice to be
able to in if that's the case would be
really nice to be able to represent the
do to have a different representation
for for the you know the character array
that is more compact okay and this is
exactly what the string class in JDK 9
does so notice that we still have the
value field but now it's a byte array is
not a character array okay and we'll
have a new field which is called the
coder the coder is either Latin or
Unicode and I believe 0 &amp;amp; 1 there are
two they are the actual values and the
coder tells you how the string is
encoded so if it's Latin then the the
byte array has one byte per character
and if it's unicode the color the byte
array has two bytes per character okay
and let's do the calculation again to
see how much space this takes up now
again the calculation is that okay so we
have 24 bytes for the string up from the
string object science you should be gone
you add in a new field how can he still
be 24 bytes what's 24 bytes before when
you didn't have the color field so it
turns out that the VM Alliance objects
to eight bytes and the world had four
bytes to spare from before so that was
lucky
so you add a field in the object size
doesn't doesn't increase that's very
nice
and yeah if you use only the Latin
character set you don't have to you know
multiply by two and now the string size
of a string with 140 characters
it goes from 320 to 180 which is a huge
improvement so some numbers published
from bat by Oracle so there for typical
applications in double quotes whatever
that means that mostly used Latin
character said and don't use Unicode
heavily they observe a 5 to 15% memory
fruit production which is very nice
your mileage might vary depending on how
heavily you use strings and also
observed 32.7% throughput improvement
and this is because of two reasons first
the GCS are faster and less frequent
there are less frequent because now the
strings are smaller so it takes more it
takes longer to fill up the yang
generate and there are faster because
the copy less because now you don't have
to copy what's you know 16 bytes per
character and also the main reason why
the put the throughput improvement I
believe is because of better cache
utilization now you can fit much more
into cache line you know much more
characters into a cache line than before
so you decrease the number of cache
misses um folks might remember that in
anybody remembers this in JDK 6 updates
there was an option use compressed
strings that did something very similar
ok anybody remembers it yeah a few
people ok no yes yes you I so this is
similar but it's done kind of properly
in double ports so the complexity tracks
on a much bigger project so it is on by
default because the the doesn't seem to
be a huge or actually there's very
little overhead even if you use a lot of
unique codes you just don't take don't
you know you don't have the footprint
reduction but there's no much overhead
with that it is more complete and it's
done in a way that they changed a lot of
other classes that kind of relied on the
fact of the the chain a lot of hard
relies stringbuilder that knows upon the
encoding so it can actually pass the
right thing rather than having to kind
of encoding decode byte arrays to
character in backwards use compress
strings it was much more limited it only
changed the string class and in order
for everybody to be there anybody else
to interface with a string class the
in the the the battery had to basically
be translated to the character array so
it's a much better much better approach
it has better performance improvements
and it's much more maintainable I think
I believe one of the reasons that
dropped it from seven the drop the use
compressed rings option from seven it
was likely it was kind of hard to
maintain okay so this is a very nice
improvement in Java nine again you kind
of get it for free by just using strings
the string API doesn't change it's
basically all the changes are kind of
under the covers
so the third topic I will talk about
which I person thing is really cool they
new is the new stock walking API so
first why do you want to walk the stock
from from Java so there are a few
reasons why you want to do that the most
obvious one is logging so you have some
rare and maybe expensive event that
happens maybe you want to take a stack
trace and when you log it along with the
event to maybe get to work out what you
know what caused it what was going on
etc other reasons includes well you have
a library you want to know who's calling
to the library you have to walk the
stack ignore all the other frames that
belong to methods in your library and
just reach the the one outside your
library and that's your caller another
reason is to find out the first
privilege frame so you will need to do
some access control on a particular
operation you go down the stack find the
first previous frame and know what kind
of privileges he has in order to know
whether we can do that operation or not
so in JDK 8 and earlier the only way to
get a stock stack trace was to call the
get stack trace method on thread so that
returns big array of stack trace
elements one stack trace element per
stack frame in the stack and and you
know depending on how big big you know
how deep your stock is then that array
could be quite large and then you can
just use it in this case I just iterate
over the elements I just bring the
method name of each of its stack frame
from corresponds to a stack frame so the
disadvantage of this is that is the cost
is proportional to the stack there so
the deeper your stack so let's say you
are done or 600-700 methods deep then it
could take a you know a reasonable
amount of time to actually construct all
those stack trace elements and add them
to to the
and also the food broom is also
proportional as well and as I was
showing earlier during the examples you
don't always need to in the info know
stack frames you might need the if one
on the top five or the top ten or
something and it's kind of a waste to
get all this information just throw it
away
so adjudicate now the new stock walking
API improves all this by quite a lot but
I would take a couple of minutes first
to describe why doing our do we start
walking in a more flexible way it's
actually a very tricky thing to do I
don't know if it's obvious or not it was
not obvious to me initially so this is
you know Java running Java thread there
are some stack frames on the stack the
stack grows up the way the agenda boxes
corresponding each corresponds to one
stack frame right and that's at this
point the Java the thread says I want to
walk the stack right and of course you
know you call some method which of
course has to push like another stack
frame on on this on the stack right and
let's say we want to do the iteration
with say a stream okay so we create you
know it creates a stream object that
Horan's blob is is supposed to be a
string object in the heap right that's
pointed to by the the top stack frame
right and the stream object knows how to
go to the first stack frame that is
below the one that created it right in
it has it has it address say that it can
go and look at the information and then
from there it can go to the previous on
etc right straightforward now if we're
not careful remember this is just the
last moment is just an object in Java
so we were no careful what we can do is
you can read returned by from a few
methods right we now go down the stack
and pass the stream object or actually
down the stack in this case right and
then we can just call some new methods
now and then pass that stream object as
an argument and now the top level frame
has a pointer to the stream object and
if we try to do an iteration we're gonna
crash and burn because the stack just
changed under our feet right the by
virtue of just returning from a master
calling new methods you just basically
messed up the stack so and there is no
reasonable way address reasonable
performance you know trade-off to
actually keep up keep the what's in the
stream and what's happening to the start
to keep them in saying it's just it's
way too expensive it would be impossible
so the way to fix this is we have to
ensure that when you try to do when
you're doing the iteration you should
never basically go below that top frame
so all the stack frames that the stream
nose had to iterate over the remain
basically intact so it can iterate over
them safely and this is exactly what the
new stock working API does so there's a
new class that working java.lang and
instead of just retaining a stream which
is the obvious thing to do right and
explain but just explain is very unsafe
thing to do now it has a walk function a
walk method that takes a function that
takes a stream of stack frames I would
tell tell you a little bit later what
the stack frame is and returns a result
and that result is returned further by
the work function so you're into lambda
heaven here when you start doing the
stock walking so here's an example was
similar to what I showed earlier you
just we call walk and you take the
stream and then you map the frame to the
method name and then you just print the
method names right this is similar
example to what I showed earlier so why
is this safe there are a couple of
reasons why actually the main reason is
that the stream cannot be used outside
the walk method it is possible if you're
like really naughty you pass a lambda
that stores the stream to a static field
or creates a new thread and passes it to
the other thread so you can actually
even run the new thread can run
concurrently with the walk method right
after that riedel is just to see what's
going to happen and it turns out the
stream cannot be used outside walk for a
couple of reasons
first it is closed before walk returns
so if the same thread tries to access
the stream we'll get an exception and
also it cannot be accessed by any other
thread so when the stream is created it
has the pointer to the thread that
created also if another thread tries to
access it we just get an exception as
well so the stream is only really usable
within the walk method and this is what
makes this iteration safe so about just
a few examples and as I said this is
just more like an exercise on how to do
something in with lambdas so so here we
want to get like a series of interesting
frames but ever an interesting with
double quotes right whatever an
interesting frame is so it's very
straightforward we take the stream we
like filter it based on a method call
it's interesting and then we collect
into a list this will go through the
entire stack but we'll only create a
list of the
the frames are interesting if we wanted
to limit it it's easy you just add limit
32 and this would only look look up to
32 frames and it would not go further so
this is a very nice way to kind of bound
the cost of this operation both in terms
of memory footprint and also in terms of
time you know how long it will take to
finish and if you want to pick a
particular frame again you can filter it
based on something and then return fine
first and then you get the result or not
because it returns an option because
there might not be a result right so the
stack frame interface I showed you
earlier is some inner interface of stack
worker and with extra policies for the
slightly dodgy syntax there so it's an
intern interface of the stock walker
class it has methods similar to what the
stack trace element class has so you can
get the class name you can get the
method name blah blah blah but on top of
this you can get the declaring class the
class whose method that the method that
off of the frame belongs to and this
interesting course if you'd only have
the class name you cannot always get the
class right why because the class
loaders you can have the same class with
the same name loaded multiple times by
different loaders so you don't know
which one it is but with this you can
and there is also a convenience method
that translates a stack frame to a
struct trace elements if you already
have code the operation of a stack trace
elements you can just use that alright
so just to summarize the the new stop
walking app is actually very flexible
and powerful it has way better
performance characteristics compared to
what was there before and I believe
there are several parts of the JDK have
already been updated to use that instead
of whatever scheme that they were using
before and it might kind of allow allow
stuck walking to be done instead of
situations that before it was too
expensive like for example you have some
logging system and you say well I cannot
afford you know we look reasonably
frequently I cannot afford get like a
fool you know stacktrace because too
expensive but I can I can afford you
know look at the top five frames and
just log that just in case just the
cases is helpful before you gonna do
that maybe now you can do that alright
so I cover the three main topics and we
have a bonus topic that will cover last
that I think is very cool
so using the immortal words of Morpheus
so what if I told you you can write a
just-in-time compiler in Java and this
is exactly what you can do with a new
JVM see I the Java JVM compiler
interface and by compiler we're talking
about a JIT that translates byte codes
into machine code while the game is
running not Java C right this is very
cool everybody's like looking perplexed
or you've seen this before okay
people are looking perplexed alright so
I will give a little bit of an overview
how kind of the legit works in Java and
how it interacts with the rest of the VM
so when a method is executed in hotspot
it can be executed at three different
levels so first it can be interpreted
then compiled by if it's hot enough
whatever that means it compiled by the
client compiler C 1 and if it's like
still remains hot it would be compiled
by the server compilers C 2 and all that
stuff if you enable tier compilation
that were neighbor both compilers to
work in in the same VM and what's the
trade-off between the two different
compilers the client compiler is a fast
compiler but generates so and so code
the server compiler is a much slower
compiler but generates much better code
okay so you want to compile with a clang
compiler maybe to kind of get improve
startup a little bit but ultimately you
want to compile the server compiler to
have great throughput in along in the
long run so I'll cover a little bit the
interaction between JVM and the JIT
compiler so the JVM has a code cache and
the code cache contains
all the methods that have been compiled
by the JIT and and you know and that's
how they are executed for every method
it has a set of dependencies so when a
JIT compilers a particular method it
makes a set of assumptions like for
example it can assume that hey the only
class that has been loaded that
implements them the interface map is
hash map so every time I see an instance
of type map I can actually safely assume
that it's a hash map because it has to
be there's no other you know there's no
other class that it can be so you can
make maybe generate better code that's
you know making that assumption but it
has to record that assumption somewhere
because maybe five minutes later three
map is loaded
validates that assumption and in that
case the VM has to go through the
dependencies and invalidate parts you
know several compiled methods that
happen some so that doesn't hold anymore
and on top of this of course it has the
GBM has out of metadata like you know
class information class by codes method
signature field signature
blah-di-blah-di-blah
you know all that stuff what's in the
class file basically and also make
things lots of profiling information
which methods are hot which part of
methods tend to be executed more so
which which paths through so a
particular method tends to be hotter
than others etc so when are the VM
notices that a particular method is hot
it tells the G can you please compile
this and the way does that usually just
adds that as as that to IQ that the
compiler basically looks every time they
finishes a compilation so the JIT start
compiling the method and it has to
request a lot of information from the VM
while it's compiling the method the
information includes give me the by
codes
give me the signature of the method that
that is being called give me the bios of
my method maybe wants to inline it sting
nature of fields layout of objects
because the VM ultimately decides what
the object layout is going to be etc
finally when the the code is a weather
JIT finishes and finish the compilation
it puts back puts the generated code in
the code cache right you see the new
items that appeared there right and then
also remember that it has to also add
the set of dependencies that that code
depends on it's basically the assumption
that the JIT made while it was compiling
then that method just the case they're
gonna be invalid evaluated later so how
does this work with JVM CI so in when
you neighbor JMC I basically eat the JVM
CI compiler which is written in Java and
implements interface JVM CI compiler it
replaces the server compiler ok and JVM
see either interface basically defines
that interaction between the compiler it
and in Java the VM
and it's done so that's so in Java okay
and what I tried to say earlier is that
a lot of it there actually is not like
Jimmy you know compiled this method okay
here's the here's the result the result
is usually like I think a byte array
right it returns the machine code in a
byte array
so a lot of the complexity of JVM CI is
just the interaction between the
compiler and the JVM when the compiler
needs to get metadata information from
the JVM profiling information of the
angiogram here is the set of
dependencies that you have to add to
that method etc so this is a lot of you
know by the time you know so this allows
with a complexity for JVM cia's so why
you want to do that why you want to
write a JIT in Java well it's easier to
write and maintain right I assume like
most people here will assume that
writing Java is easier to write them in
thing unlike C++ it is safer so
compilers have bugs right if C 2 crashes
it takes down a VM in this case if the
compiler has a bug you will throw an
exception right and it will be caught
and that compiler should be abandoned by
the VM stays and then you can just call
it again right and it is pluggable and
this is actually pretty cool
so imagine and kind of being a little
bit optimistic here but imagine like
your child's not alright who's been
working on JRuby for a long time right
and then he comes up with a really cool
way to optimize jvj Ruby by codes in the
jet but if you wanted to go release that
currently has to released his own JVM
which is kind of not not easy and it has
to basically you know release every time
it'll release an update every time I new
up JVM you know a new jdk update goes
out but maybe with this you can just
distribute the JIT along with JRuby and
then you know it would just you know in
and the VM will just pick it up without
having to you know rebuild the VM etc
and it's actually pretty cool right one
thing to point out though is that you
know you know write once run anywhere
what it doesn't hold here for a couple
of reasons and maybe everybody's gonna
be surprised and that this is the case
but there are a couple of reasons first
the the generate machine code so it's
generating machine code for a particular
architecture right so in order to make
it usable for more architectures then
you have to basically have a JIT that
would differ a back-end okay
and there are second reason why it's not
as very portable is that a particular VM
has certain it does things in a certain
way like the way allocation works is
differ
you know hot smoker - j9 the way
synchronization works is different in
hotspot number than j9 and the G has to
kind of generate code that deals with
synchronization or a location etc just
to get best performance so the G is you
know the G can be actually targeting a
specific VF for a specific architecture
so it's not you know as portable as you
expect but it's still easier to write
and maintain and all that stuff so yes
there is a JIT written in java is called
growl it's a high performers dynamic
compiler done at oracle labs interacts
with hotspot through jb NCI and it's
open source and you can download it you
can download that jdk 9 early early
access and then there is like a long set
of command-line argument you have to
pass there's an incantation and then you
you actually you not be running with a
JIT in Java and a couple things if you
use growl so whom implies the compiler
so the compiler is Java right first is
gonna be interpreted and then well
currently only c1 will compile the the
compiler because by the time the
compiler gets gets really hot you
probably got compiled a lot of things so
there's no point in optimizing it
further however there is another JP that
was recently announced ahead of time
compiler that would be able to compile
the JIT compiler ahead of time so you
don't have to compile it when the VM
starts out right and it is enough the
ahead of time compiler is also grabbed
base so in this case growl will be
compiling itself which is kind of
critical something to note though is
that there is some extra heap overhead
and pressure if using growl why because
it's just a java application right so it
would create data structures in the heap
and it does have some state that it
maintains with some between come
violations so there would be some extra
overhead in in the heap if you Ronnie so
you have to take into account when you
size your your heat and just to
summarize this so this is my colleague
Chris before he joined us he was
actually the in the compiler group for
in the hospital compiler group at Oracle
and he worked on this and this actually
are real tweaked
I usually kind of have joked which
sometimes but these are real tweet they
said this is one of the most important
things I've worked on in a while so
that's all I had thank you very much for
coming thank you very much for for come
even though they told you know the title
of the talk did not have micro-services
server less agile and I don't know what
else so it was great they have you here
and I can take questions thank you very
much
any questions so in the beginning you
listed big list of the features yeah so
any other features that that you can
tell like in five seconds oh I kind of
which was to pick so Gil went a few you
know over a few of them earlier not sure
I tried to kind of keep keep two
features that kind of had had to be kind
of kind of performance and profiling
related so these were the ones that kind
of found interesting yeah so the unified
JVM logging is there another set of
options after another column where you
can specify the format of those logs no
no so so the yeah that's not good
question so no so yeah apart from the
decorators that you to anything after
that is basically a string so any
generates a string so hotspot does have
a way to log in a structured format
which is JFR and it's an Oracle product
and it's not open JDK so if you want to
do that you have to basically use an or
at Oracle product to do that yeah and
anybody else you can hug around here if
you want to come in grab if you're gonna
go to the Java open space it'll be in
the Pacific BC downstairs yeah thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>