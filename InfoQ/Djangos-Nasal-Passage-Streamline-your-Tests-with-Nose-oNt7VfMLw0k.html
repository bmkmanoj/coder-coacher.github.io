<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Django's Nasal Passage: Streamline your Tests with Nose | Coder Coacher - Coaching Coders</title><meta content="Django's Nasal Passage: Streamline your Tests with Nose - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Django's Nasal Passage: Streamline your Tests with Nose</b></h2><h5 class="post__date">2012-09-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/oNt7VfMLw0k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so this is going to be a tour of Jango's
nasal passage a journey from its stock
test equipment over to a wondrous
boilerplate free world where you can
enjoy ponies and things like that so
first of all come to vote is in secret
lair we're trying to hear reduce the
influence of politics or excuse me
review it's Freudian slip we're doing
reduce the influence of money in
politics by replacing like expensive
broadcast media like TV and billboards
and things with more efficient peer to
peer interactions or people aren't as
annoyed by fair phone ringing from
robots all the time we do some fairly
thorough applications of Jango here and
some pretty heavyweight testing we have
about 1,700 tests right now and we found
the stock django test framework well
really easy to get started with is not
enough once your program scales beyond
trivial here are a couple things that
are wrong with it so almost immediately
you get far too many tests to fit in
this that one little test stop PI module
so of course you turn it into a package
right you blow it up split it onto
little things but then you have to
import all the names from those little
things up into unit dot pi and that's
not only annoying but error-prone as
we'll see things also end up slower than
they could be you end up having to do a
full database flush for every
transaction test case you have and a
full fix to reload for each test that
uses fixtures also the test runner
creates a an entirely new database for
each time you invoke it each time you go
back we run the tests new database very
expensive third the default test runner
is kind of overzealous not only does it
test your code but it tests everything
else that happens to be installed apps
and that's going to be a lot of
third-party stuff that's already proven
to work so at best you're testing
whether you have a third party stuff
configured right and at worst you're
just wasting your time running tests on
things that are already known good the
see here you I i find the default
testing you I to be pretty rough you
don't get any trace backs until
everything is done
true text test runner fashion and
there's a lot of trash in the output a
lot of 80 equals signs here an equal
signs there what's a line skip between
friends there are no facilities also for
round tripping back into the code so
when something goes wrong you've got to
eyeball that line number out of there
dig around in the file system and bring
your editor up and all that stuff you
know computer should be good fat and
then finally the extensibility story is
kind of unscalable if you make say a
Django test run or subclass that does
xml output you can't just mix in
somebody else's that does say say limits
limits you to testing just the
applications that are yours not easy to
compose those sonos is going to help us
solve all that thing all those things
it's really nice to test framework it
draws on the unit test heritage and it
puts it on steroids it questions a lot
of the limitations that come out of the
strict static kind of j unit descended
test frameworks and gives you the tools
to test more stuff in fewer lines i love
it so let's talk about nose and how you
apply it to django before we dig too
deep into its capabilities Pierce I can
install it you just pip install Django
nose which is a shim that implements the
Django test runner and then just calls
out to nose and invokes that from their
nose itself is a requirement of Django
know so that just gets pulled down
automatically you don't to install that
explicitly and then all its left to do
is set up your settings just add Django
nose to your installed apps and set the
test runner to django noses mannsville
test runner now let's see what that gets
us first of all we have discovery so
Django stock test runner as we said
makes you pull everything into test
style unit or test stop i knows on the
other hand makes all of this go poof
instead nose finds your tests by name so
these are some tests like names if nose
finds a class or a function with a test
like name inside a module with the test
name it considers that to be a test and
if you have something that doesn't fit
that pattern you can always use a
decorator no this isn't the test yes
this really is a test of course
subclasses of unit test test case are
all those considered tests so all year
old Django tests continue to be found
recognized and run so the application of
these simple rules kills off a whole
bunch of boilerplate eliminates several
classes of errors for example since we
don't have to import into in it anymore
you don't have to worry about things
getting shadowed we've had this happen a
couple times to us we end up with
something called such and such test case
in one test module and something else
called such and such test case in
another module next to it you do some
pretty naive import stars and in it one
of them wins one of them doesn't run not
a lot of fun you get no errors nothing
to track down just you know six months
later you realize you know this test
hasn't been running for ever since it
was written the other fun thing about
not having to import up into in it is
you can reverse the typical import
direction you can use in it original I
can leave it blank or what I like to do
is I put my bass test classes in there
or little stand alone testing utilities
that are application specific and then
you can import down from that into your
test modules without having to worry
about circular reports or anything you
don't end up forgetting to import things
that's happened to us a couple of times
and then finally you don't have these
long Java like crazy long names in order
to maintain uniqueness so all good stuff
and then remember how the test runner
ran through all the installed apps well
Django knows doesn't do that it only
looks in the folders within your actual
project so it tests only your code
saving you a lot of compute cycles
really save a bunch of time every time
you test this also means that you can
have code in your django project that's
tested but doesn't live in a django app
so you can have levels
in their stills tested so with all that
freedom how should you organize your
tests here's my favorite way I still
like to nestle my tests inside a tests
package in each app why not why change
things that work the unit is either
blank or like I said full of base
classes and then tests go in test
whatever files test models test views
test robbers that naming convention is
nice for making the tests all kind of
clumped together and contrast with other
artifacts you may have sitting in there
may be an image file for testing some
pills stuff sample data file another
perfectly reasonable convention is to
put the high entropy words first model
tests view tests and nose is happy to
recognize those as well and those are a
little bit easier to do type to select
little shorter to do tab completion on
if photos and we also toyed with
splitting tests into a deeper hierarchy
of tests and then put a models folder
inside there and have a file / model
that you're testing and this is a matter
of personal preference but we found that
that made us dink around too much in the
file system and we are willing to take
some some longer test modules as a
trade-off the other cool thing knows
what you do is break out of the test
class pattern when it makes sense you
can just have flat-out functions as
tests so if you have something that for
example doesn't require the typical
Django database you know roll back and
set up tear down kind of things you
could just make a function perfectly
happy test and then Django gives you
these little helper procedures like eq
underscore to replace things like self
assertequals not nevertheless there are
allowances for setup and teardown so you
can see the decorator here and that just
takes two parameters a setup function
the teardown function and you can put
the setup and teardown functions out of
the root level or in a library and you
can mix and match something I'd like to
do in the future with Django nose is
provide Django database setup and
teardown as
stand-alone procedures like that so that
you could use them in top-level
functions if you felt a need to support
function tests further there are
packaged module as well as a class and
test level setup and teardown so if you
put a setup procedure at the top of your
say in it in a package that will happen
before any test in the package is run
similarly if you put a tear down in
there that gets run after all the tests
in that package get run if you want to
get really crazy you can generate your
tests dynamically now this is kind of a
niche thing admittedly but sometimes it
feels nice to generate several similar
assertions programmatically like an a
for loop in unit tests say you had a
bunch of asserts in a for loop when that
first one fails that whole test is shot
now you have to go correct some things
and you don't get any more information
about the assertions that didn't get run
until you rerun the thing it knows if
you use a test generator you can keep on
going so you can make a bunch of
independent assertions and you get all
your feedback right at the top you can't
use this in unit test test case
subclasses but it works everywhere else
now here's a fun trick you can do with
attributes you can use this adder
decorator that knows provides to stick
arbitrary tags on to your tests works on
classes it works on functions and they
can be unvalued like the top one or
valued like the bottom one and then when
you invoke knows what you do through the
typical manage spy test you can say i
want you to only run my selenium tests
that is the tests where an attribute
called selenium exists or you can do
kind of boolean expressions you can say
give me the ones that are priority
equals two and speed equal slow or you
can do alternation you can say give me
the ones that are priority to or with a
slow speed really really handy stuff I
can't wait to take more advantage of it
lots of other goodies i mean we could go
all day about knows but
as a custom error classes so the typical
unit tested up you've got errors and
you've got failures right what if there
are other kinds of useful things like
you could yield a deprecation for
example say well yeah it's passing but
it sucks skips skips I think knows
either originated those or certainly had
them before unit test two came out to
do's you can see something yielding a to
do like yeah you know this test is here
but it's not really doing what I want
xml output you get that for free so if
you're going to use Jenkins or something
you just passed it i think it's dash
dash with dash xml that's what we're
using to integrate with cruise control
in our case lots of extensibility all
these these things I've been showing the
discovery and the attribute things are
implemented as plugins so you can
customize all that stuff and the plugins
all get away with you get along with
each other really nicely they compose
well you get the plugins up obviously
it's a good ecosystem of plugins going
on and there's even some multiprocessor
support though I haven't got it working
with the Django yet due to you know
contention for a database but that's a
good future thing to look at I hope to
get more into some of this with my
django con talk next week this is this
is a preview so let's talk a little bit
about some of the specific optimizations
that Django knows provides earlier when
I said it was just a shim I told a
little fib it sure started out that way
but by now it's got all these crazy
performance-enhancing features that you
can optionally take advantage of so to
demonstrate those I'm going to use the
example of support mozilla org
affectionately nicknamed sumo which I
used to work on now it's got about 1,200
tests gets about a billion hits a month
it's kind of a moderate-sized site for
Mozilla and over time those tests have
grown to take about 20 minutes on the
build server and five minutes locally
now five minutes might not sound like
long it's easy enough to say but it's
worth saying a few words about why
faster tests are desirable first and
foremost you save all the sword fighting
time
well the tests run save injuries this
way save chairs more importantly you
recoup the time you would have lost in
context switching re-establishing your
flow getting stuff back into your head
third when people know it's going to
take seven eight nine seven minutes
right now presented optimized they skip
running pieces of them they say well I'm
just working this app I'll just run this
apps tests right so you run some of the
tests or none of the tests and then of
course you break the bill because you
noticed so lots of lots of good reasons
to optimize here so where does Django
nose go looking for that extra speed
well there's really only one real answer
for that and that is IO if you take a
look at this little chart it represents
one nanosecond of access time as a
single pixel now just take a look at how
all the levels of memory hierarchy
combined or just warped by that
mechanical hard drive it's horrendous so
if you can take a chunk out of that
that's where to go first now I'm looking
up to have an SSD in this box and things
are a lot faster theoretically an SSD
has an access time on the order of 100
nanoseconds so just a little bit more
than core ram but in fact you end up
bottlenecking on writing a reads are
cheap but rights are amplified or
they're just flat-out honestly slow so a
little less true than it was five years
ago still the case if you have a Mac I
recommend getting a copy of istat menus
or menu meters similar things for other
platforms and your Linux has tons of
them out of the box really great for
establishing a baseline expectation of
what a reasonable test load is python is
terrible multi processor used in general
and certainly a single-threaded for
django tests so if you see Python not
hitting a hundred percent that probably
means you can optimize a little bit more
our current test run at about 70 you
something percent we could do better
we're better than we were I think we
start at 30
let's see here so we can confirm our I
Oh rule of thumb by applying a couple of
profiling tools first of all obviously
the Python profiler but uh knob viously
it doesn't tell you anything about IO
time at all it just tells you four
seconds on the CPU well great but my
test took a minute and a half to run
where's the rest of the time so we bust
out the Handy unix time command which is
nice it gives you not only the CPU time
with you clock time and handy little
ratios you know to do any math take a
look at the CPU percentage see it's
using thirty percent and you can
conclude that whatever I was doing in my
tests a lot of it is spent in cycles
outside my process either it's waiting
on Io or I've you know fired off some
other process that's doing some
computation for me so a little bit more
digging in the case of almost any Django
project shows that to be database i/o
which is why Django knows provides for
optimizations for reducing it first of
which is fast fixed your test cases so
test fixtures hands up if you use test
text pictures familiar with test
fixtures yeah love them hate him okay
evenly divided a lot of lot of Nova
opinions their site access your data
typically goes into a JSON file kind of
like this one this is an actual test
fixture from the form application in
sumo and this one's on the small side
about thirty nine objects trouble is you
got to blow a sequel statement to make
each of these objects so that's 39
sequel inserts even in Django 1.4 you
can't use bulky inserts for this because
of the possibility of post save hooks
existing and wanting to insert you know
additional objects or do important
things so you still need a sequel
statement for each one and here's one of
sumos test classes that uses that
fixture along with two other similarly
sized ones and couple dozen inserts and
it took four minutes to run it was not
computationally intense so what's going
on it seems like an awful long time
to run to load a couple of dozen
database rose well if you want to find
out what's going on in the case of my
sequel for example you just login as
root and say general global type that
then it'll start tailing every statement
it receives to a file you can take a
look at that and it becomes clear that
not only is the fixture reloaded ones
for class but in fact it's reloaded once
for each test so 39 x number of fixtures
x 20 tests in here starts to add up to 4
minutes each test begins a transaction
load the fixtures runs its stuff and
then rolls back the transaction back to
a blank database very tidy but very
inefficient so run roll back load it
roll back load it roll back so on sumo
this was thirty seven thousand five
hundred and eighty three queries over
the course of the entire suite and it
seemed to me that we could do a lot
better so here is a conceptual
illustration of fast fixture test case
which exists you can use it for free in
Django notes we've got set up class so
this is a class level set of thing
happens before any of the stuff runs in
this class unit tests to brings that
knows his head that for a while it loads
up the fixtures it commits them that's
the difference so then when we run our
tests we run the test and we roll back
which takes us not to a blank database
but back to a pristine set of fixtures
and then finally when we're done we tear
down the class by removing the fixtures
explicitly truncating tables taking rose
out whatever and then commit it now how
do we know what to rip out well we have
a modified version of Django stock
fixture loading routine we run that
through a dry run it records what it was
going to do and then we know what to rip
out so let's see how we did with the
stock Django fixture loading Summa fired
up 30
7500 83 queries with the per class
fixtures only 4100 that's nine times
less database traffic or if you look at
it in terms of time the stock fixtures
are just over five minutes and the per
class fixtures come in at about a minute
and a half so you can get these
improvements yourself you just have to
subclass the fast fixture test case
instead of test case oh and there's one
little caveat there that if you have
post safe handlers you can't do that but
that's something that could be solved
and I welcome patches in fact there was
an additional four seconds saved here by
reusing a single database connection in
Django knows Django tends to flap the
connection open and closed a lot to be
very very conservative so we went ahead
and put the branch and to say well in
this database safe in this database it's
not and we save for second six offend 93
seconds so big improvement and all
thanks to getting rid of my oh but there
are additional speed optimizations that
we can apply there is fixture bundling
which is kind of exotic these are three
actual test cases from sumo they use the
same fixtures as you can see now if you
wanted to optimize this you could merge
them all into one class right so they're
only loaded at the top of the one class
and then unloaded again just once but
then you can't organize your clap your
test classes as you want it's nice to
conceptually group these things
sometimes so what do we do well we take
advantage of one of noses little hooks
nose has this prepare test hook which is
kind of Miss named what it really should
be called is prepare sweet so at the
very beginning before any tests are run
it says alright prepared test you buell
blend of this here's a sweet do what you
want and we just had to do some evil
things so here's how it typically
happens when those runs your test cases
it runs them and basically alphabetical
order like this so you know test case
bullets right loads mixtures a B and C
tears them down test case too low
ABC and D tears him down test case three
loads a B and C again redundant Lee and
tears them down let's save that work so
by using prepared tests we can rent a
plug-in to dynamically reorder these
tests so that we know would be any work
so how does this work well we have
loaded there obviously we load the next
pictures there and the next fixture is
there but how do they know what to do we
put advisory bits on the first test case
of each group and the last test case of
each group and then in a decoupled way
we have a hour fast fixture test case
says by the first test case in the group
well if so I better set up the fixtures
in by the last test case well if though
I better tear them down otherwise I
don't have to do anything I can just
cruise on do my tests and I have to
worry about doing any i/o and save all
that time throughout all this test
independence is fully preserved we're
just factoring out pointlessly repeated
setup now a future optimization you
could easily see here is to be smart
about subsets right we've set up a B and
C we could leave them there and then
just bring in d I'm sure that's
computationally intense but as we saw
from the memory hierarchy diagram
computation is all free you can do as
much computation as you want to avoid
hitting the disk if you have any trouble
with this you probably have order
dependencies in your tests so take a
look at things like Singleton's locales
a big thing if you're activating or
deactivating any locales and your tests
those are thread locals and tend to leak
especially if you have an exception or
something and then any other thread
locals are a great place for state to
hide out so what impact did fixture
bundling have on our test project here
well before bundling we had 114 test
classes of fixtures and we did the
loading unloading 114 times however it
turns out there were only 11 distinct
sets of fixtures so with bundling we can
save about a quarter of the time off of
our already improved test room all you
have to do to take advantage of fixture
bundling is subclass effects past
fixture test case say that five times
fast and then pass the with fixture
bundling flag
when you invoke your test runner so
another place that I shaved some time
off is database we use waiting for
database setup is no fun at all
especially when you're in a trivial test
that adds two numbers or does little
computation or something I think our
current project takes like 15 seconds or
something to set up our three different
databases and if you run on Amazon or
you can just go to get some lunch
because that's that's kind of take 10
minutes to set up it's insane so what I
realized is at the end of your test run
your database is in a valid state so why
would I redo all that work at the front
of the next one why not just leave it
alone at the end of the last phone line
I know don't tear it down and then just
reuse it as is so we did that the flag
is not the the the switch isn't very
observant I'll say you have to keep
track if you make any schema changes for
example you have to omit the flag next
time you run it and say look you better
go ahead and reinitialize but otherwise
you save you know a good 10 seconds
aveda base set up time and there's the
flag it's it's a strange implication
because of the way the sess runners call
each other I couldn't make it an
argument yet so it's kind of an
environment variable you just kind of do
that but research continues and if it's
us within within a whisker of a minute
for that project which is about where I
party that's that's about all I could
stand so here's a summary of the
optimization so far stock Django the per
class test pictures of the big win
fixture bundling notch another quarter
off of that and then database reuse
takes that last little ten-second
annoyance off if that saves four minutes
per test run like in this when you have
a team of four and they run their test
suite maybe four times a day
conservatively you save about an hour a
day that comes up to 261 hours or 32
working days per year so I figure every
team member can take an extra week off
and if you do happen to be using Django
and have a lot of fixture heavy tests
tests you get all this pretty cheaply by
using Django knows so let's talk about
user interface even though we are
technical people we still have feelings
and they can still be hurt by
inconsiderate software and I cannot help
but rant a little bit about what we put
ourselves through with the dots so this
is the standard django test display it
basically is what standard unit tests
text test runner spits out I took the
liberty of trimming out some of the time
consuming setups this actually it's not
real time now i can see i got an error
there right but i can't see what the
heck went wrong so i just gotta sit here
and wait until the very end when
hopefully all the trace backs will show
up all at once GG what I could record
book estrace and try to guess what's
going on out so I find that pretty
inconsiderate in fact I don't even know
how long I'm gonna have to wait to see
my results like should I get a sandwich
or should I get you know a spouse or in
fact this goes on for over two minutes
so we'll just sit and wait while this
goes no just kidding I might not to be
just kidding because when i was trying
this earlier i actually couldn't get it
to skip to the end yeah it's doing that
again so yeah so everybody knows at the
output I it looks like you end up with
these wrapped lines full of garbage that
say equal signs yay or trace back most
recent line last is if you've never read
a trace back before and then in cayton
less you're using like some kind of
fancy IDE or something you've got to
ferret that number out and figure out
what what crazy line wrapped file it was
and get into your editor and it's a pain
in the neck and computer should be good
at doing this for us well waste the time
so wouldn't it be nice instead if we had
something like this this is an
alternative test runner
and I put together works with your
existing tests you have to do anything
it's got a little progress bar fires up
down the lower right you can always see
what test is running over to the left
see trace backs as they happen and there
are no wasted lines the trace backs are
even formatted interestingly there are
actually more useful than they look
they're pretty but they're also very
useful so we with the useless lines the
equal signs the most recent line last
that kind of stuff but also we omit test
frames that aren't interesting so test
frames that are out of the guts of unit
tests or are part of a comparator like
noses EQ underscore or assertequals
those things get stripped off in fact
the first frame of every trace back is
guaranteed to be the one out of your
test let's see try to compress it
horizontally all the path names are
optionally relativized the function
names or color so you can just scan down
through the stack and see what's going
on figure out where you are and then you
can actually copy and paste these mold
test names at your prompt to rerun them
so you say manage tests and then paste
that thing and you can rerun a failed
test for easily like that but my
favorite part of all is these editor
shortcuts like all these great things
that happen to start in my case with
bbedit here's how they work so once you
know where you want to go you just
triple click on one of these editor
shortcuts copy paste real quick and you
pop up right in your editor at the line
that that indicates works and emacs
works and VI works and textmate works in
bbedit works in anything that takes the
little plus command-line syntax for
indicating a line to edit on knows
progressive is on pi PI you can grab it
right now just pip install those
progressive and then pass with
progressive when you do your tests I
like to match all that into an alias so
I don't have to type it all the time
great thank you so much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>