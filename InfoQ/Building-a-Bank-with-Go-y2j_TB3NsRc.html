<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building a Bank with Go | Coder Coacher - Coaching Coders</title><meta content="Building a Bank with Go - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building a Bank with Go</b></h2><h5 class="post__date">2017-08-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/y2j_TB3NsRc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so hi I'm Matt and I'm going to talk a
little bit how you could build a brain
with go which apparently is the thing
you can do I didn't really think that be
the case two years ago but yeah it's a
thing so little quick instruction I
match you could put me on Twitter here
if you have any questions give me a
shout I mainly work as a back-end
engineer do a lot of infrastructure and
kind of back-end systems and I've been
doing that for a few years and I've been
working with go for kind of four and a
half years pretty much full-time for
last four years which for me has been
kind of amazing i as a PHP engineer
before I say engineer very loosely there
I know form from PHP but my ability at
that point was terrible and for me goes
kind of changed the way I think quite a
lot about programming and kind of
different kind of approach that it's
given me but has anyone had a bad ones
oh okay so a few people go so I work a
company called one zone we make these
kind of hot coral debit cards cover
Dupre page soon to be full debit cards
and we release current accounts later
this year and we're a bank so the the
main reason we kind of started this
whole thing to like build a new kind of
bank is mainly because this is how I see
banks and yeah I mean they're kind of
they look pretty fancy and this for me
is kind of as a guy with slightly crazy
eyes and for me anytime I interact with
my bank this is kind of how it feels
occasionally I have to go physically to
a bank which is quite annoying and even
if I don't then I have to bring someone
up my internet marketing is not really
that great and ultimately the cutting of
customer experience that I expect from
banking in 2017 is not what prankster
little in a world where like I can
tackle my
and a car arrives to pick me up and
while I'm in that car I order some food
on my phone and it arrives in my house
by the time I get home but like to even
deal with my money I have to physically
walk somewhere a bit lazy but that that
kind of is a bit crazy Glee and there's
a lot some lots of reasons for that
banking is an interesting business where
the banks tend to consolidate quite
heavily which means you end up with lots
and lots of different IT systems that
have to be managed by kind of a whole
team of different people and the core of
that we have like super awesome
mainframes which are very powerful and
insanely expensive but cool facts if you
wrote code the run on this in like 1960
you can still buy a mainframe that will
run your code which is great if you
don't really want to change things but
if you actually need to then interact
with that code and kind of modify how
your business works and kind of stay up
to date that that is very difficult and
you end up in this kind of standard
place where you built up technical debt
but it's very very difficult to turn him
head out to that so we started building
ones about two years ago which was back
in February 2015
getting the full banking license takes a
little while we kind of got our
restricted banking license in August
last year
and we're kind of working through with
regulators to get those last couple of
restrictions lifted and hopefully that
will happen very soon and then at that
point we are a fully regulated bank we
can issue current occurs to people and
you have all the kind of standard
protections that any normal high street
won't gives you so what do we do this
difference so start with we give you an
out and everything you do with Manzo's
to your cards I swipe through through
the app on your phone so this is why one
of my kind of funding features favorite
features you can if you have your cards
are legal awesome you can you can freeze
it and then if you find it then you can
turn it back on amazing and kind of like
it's just something that like obviously
every bank in the world should provide
and should have provided ten years ago
where I don't really need the backing
where so far I don't I shouldn't really
have to wait for like three days for a
replacement Walton place five days
probably for a replacement to arrive and
so lots of kind of little things like
that or what we're trying to do to
change the water banking so we have now
we show you like where you actually
bought things so you understand where
you spend your money we give you like
kind of budgeting advice you can send
money through Yap in which case you get
like James in space if you send James
money we can we have like fully built in
search again this is like just kind of
standard stuff that you have building
anything that wasn't about you would go
to insurance including the ability to
search with emoji oh yeah and like when
you go when you've actually bought
something you can see like on a map
where it was so there's no more like
confusion around like what is this thing
on my bank statement you can also attach
receipts I attach photos of my brunch
which again is super useful and yeah as
I mentioned before you can like if you
lose your card you can freeze it
literally with one tap and if you find
it you can one tap on freezers or you
can just order a replacement you don't
you speak 21 just comes on the post like
the next day usually and that's kind of
it so all of these things seem like
relatively straightforward like you're
building kind of any kind of
internet-based app like there's a huge
range of different technologies you can
use and they're all like pretty standard
but Mike how would you how do you start
that if you're building a mobile app so
usually you have an application of some
form let's say rails whatever and behind
that you're going to have some kind of
database that's going to store your
customers data and over time that's
going to get much larger it's kind of
the inevitability of like adding
features and functionality to to your
application and that's kind of going to
increasing complexity you might have
multiple databases you might need like
kind of search things caching
and all sorts of other like really
important features and ultimately you
end up in this horrible world where you
have this monolith kind of a huge
application now that's not always a bad
thing like right at the beginning if
you're a startup this is not your
problem right like you don't have any
customers so like building an
application that people actually use at
the most important part but at some
point further down the line you end up
with lots of complexity and this is kind
of a very very common pattern loads of
people here have talked about that and
the last day or two loads of other
companies have kind of talked about this
situation where they have to real
connect at some point in the future and
this is pretty much what happens and
this is my face and ultimately it it's a
really bad problem for developers
because if if you would develop a day to
day is just so frustrating because you
have to like you want to do like also
kind of different things you want to
like add a really cool feature and then
you could deploy it because like someone
else is kind of dealing with something
and you have to like deal with one
horrible release pipeline so stand of
thing we kind of break this up into lots
of discrete services I hate to say micro
services some science services and these
will be communicating in a variety of
different ways potentially depending on
how your application works and this is
basically how we start it
so it's an in order perfect system if
you start from day one building lots of
small kind of web services that
communicate to each other you have a
very big kind of amount up from work to
do and that amount of work is getting a
lot smaller as tooling is kind of
getting a capacity better but there's a
lot of work to do if you want to like
start off with a load of applications
that communicate to each other in our
case getting a banking license takes a
really long time so we have like
slightly more time which meant that we
could kind of build a a kind of platform
which would allow us to them
and a scale design without hand to me
architect at some point of the future so
where we were kind of going through this
we kind of
kind of few basic principles single
responsibility principle so every one of
our services does one job does it well
within those things we are bounding the
context of each application so we're
taking a discrete area of functionality
in our app building a service that
supports that or a number of services
that are not kind of a sharing
functionality across boundaries there
and the cool part about that is we then
get like really well-defined interfaces
between our services which also means if
you're skiing out your development team
you have very well-defined interfaces
and teams can do stuff without needing
to like entrap on each other so how does
that involve Gophers so anyone who
hasn't seen the Go gopher this is the Go
gopher mascots of go program lounges and
the real question is like why would we
use a relatively new language to build a
bank which is like super risky and
actually there's a number of reasons for
one we want something that is kind of
memory managed we want something as
statically typed so we don't get like
number conversions accidentally that
would be quite bad if your bank we also
are building a micro servers
architecture or at least we're building
a number of discrete systems which
communicate over a network which means
we realistically need pretty good
concurrency and because we're building
small services we want them to be very
very lightweight so obviously memory
management has been a really good thing
kind of demonstrated quite recently we
don't really want like buffer overflows
because they're quite bad and they've
been in the news recently I went a while
but as far as like lightweight goes we
we have a lot of different applications
and if we're using something on the JVM
then we're going to have every
application is n 100 megabytes of memory
whereas ghost services you can use like
20 or 30 megabytes of memory and that's
the whole application running they can
also run like huge huge numbers of
requests and pretty much scale linearly
with the number
cause so some of the features that we're
looking for
in our language as I mentioned we're
running network services we're doing a
lot in network communication so we need
these things to they'd be a pretty good
at currency especially in our run like
network services so has anyone heard of
go routines in the go program language
ok so quite a few people cool and so if
you don't think her and see a standard
sound concurrency model would be to use
something like threads or if you're
doing an extreme kite Ruppert server
like you see might be using a small
number of threads and like an
appallingly pole or something to kind of
minimize the number of our s threads
you're running an operating system the
reason for that is because threads are
very resource intensive and if you are
scaling like your servers that you're
scaling out your number requests with
with the number of threads you're going
to hit like the limitations of physical
hardware relatively quickly lots of
languages provide alternative ways to do
that and go provides guarantees so GUI
teens are essentially lightweight
concurrently running functions so Chico
routines which are then multiplexed
across a number of threads by the go
runtime and what that means is you don't
really have to think about it it's just
kind of magic that magically happens the
runtime will take care of running a
number of threads based on the number of
cores that you've allocated to the
program itself if you're dealing with
i/o over a network or reading from disk
again the runtime will deal with threads
for that problem but the the actual
function is B you're running your
business project that is doing all of
this will be multiplexed over those
threads without you having to deal with
it and it's extremely efficient there's
very very low switching cost and the
ghost scheduler is kind of quite
optimistic on how it will move between
executing the routines so to demonstrate
how easy that is let's assume we have
function call in our code somewhere and
we would like this to run at the same
time as the calling function so we're
going to put go
for it and now it will run concurrently
magic and of course now we just have I
mean that's great but now we've also got
all sorts of problems of concurrently
running programs we we have all sorts of
like concur a variable access and all of
those kind of things which are kind of
slightly harder problems but the go
language makes it extremely simple to do
this and you can run like hundreds of
thousands of go routines concurrently on
a reasonable amount of hardware that's a
perfectly realistic amount to run so as
an example and the HTTP server will be
running a new go routine every single
request that comes in into HTTP server
they're extremely lightweight so when
you create a new go routine it's going
to allocate very small amount of stack
memory that's going to grow dynamically
and contract on a mcli and it's usually
kind of like 8k or something like that
compared to like a megabyte or like half
a megabyte which is a limp agent when
you create a new thread
so in our say we have a main function in
our main package this is kind of what go
programmers alike and we want to run
this handle request method and run that
concurrently since you're our flow will
be our main outer function will run and
then this will run at some point
concurrently probably on under the core
and then it will exit and the main
program has carried on running during
that time so as I mentioned when you're
then using shared values you potentially
have a problem you need to kind of
coordinate access between potentially
hundreds of thousands of different like
co-routines so the kind of monitoring go
is to not communicate by sharing memory
but share memory by communicating and
what this means is instead of like
having a global variable that is
protected by mutexes or kind of some
other kind of locking mechanism we
should press values between our
executing go routines and go will take
care of the kind of access to those
variables in
case so that only one go routine will
have access to very well at that time
and go provides a really nice way of
doing that our chance
so channels are essentially a pipeline
that you can put something into and it
will come out the other end and usually
you will have one go routine which is
doing lots of stuff and it will stick
something in and come out and a
different go routine which can then work
on that value and then it may go
somewhere else and they're extremely
simple but they allow us to do like a
huge range of different kind of design
patterns in our application so in this
case I have to go FERS who are shouting
at each other and we're going to pass
something from one together if we had a
pipeline of different kind of
functionality we could have one go
routine that's doing lots of things it
has the kind of results of that that
kind of functionality is going to press
it down another ton of channel to
another go routine which will then do
some more functionality and then those
results can be pressed down again to
another one and they can be either in
this case synchronous or you can
actually allow your channels to be
buffered in which case you can size the
amount of messages that can be fitted in
the channel and as long as there's space
in the channel then you you're kind of
there eating this putting stuff in we'll
just put it in is non-blocking and
they'll carry on working and as soon as
it does fill up by default it'll block
until there's space on the channel or
there are kind of other mechanisms that
allow you to have a different case if
the troubles form and that's quite cool
because it means like actually so I
think if anyone's use the acute
echnology call desk you know okay
so nsq is like a quite high throughput
messaging system by default on a topic
it has 10,000 messages in memory and
then once that succeeded it puts the
restaurant disk and that's how it's
using a kernel so it has a buffered
channel with 10,000 slots and as soon as
that's film it starts writing messages
to disk instead and that's quite cool
because that's like about this much code
like literally three or four lines and
that functionality is just super simple
to write
so the other thing channels allow us to
do kind of different patterns so this
will be like a Fanning in pattern where
you might have lots of different workers
generating things that then a single
worker that perhaps has coordination can
then use the results about weekly if you
have something is generating loads of
work you can have multiple workers which
again pulling messages off this channel
and you can then scale these things
independently within the process of your
service
so the other cool thing for us to go is
that the language is South is extremely
simple so if anyone first started using
it you can go on the goaline websites
there's like a 70 step kind of tutorials
in the browser that starts off like
really really simple and then it will
take you through life and concurrency
patterns some pretty cool like maths
puzzles and the the language itself is
like really really small and the thing I
like about that is in the case of like
most other programming languages I've
worked in there's like a million
different ways you can solve a problem
and I kind of this is probably entirely
my fault but I I find I spend like some
amount of time working on the actual
problem and then the other respite I am
trying to make the code more idiomatic
because I think that's what it should be
like I mean though I just don't really
have a choice like there's kind of the
language itself is extremely small the
syntax is very very simple so it's kind
of almost a natural way to to solve a
lot of problems on top of that when you
build the go programming you get a
single executable binary so if you are
shipping a huge number of different
applications you don't have to ship
around like an entire source tree kind
of runtime and make sure the runtimes
installed on those servers and all of
that kind of stuff you get a single
binary which you can just run now a lot
of those problems are kind of taken care
of by running all your applications in
docker containers which hopefully
everyone is but in the case of go
programs you actually don't really need
to do that because you don't need a
runtime the runtime is built into the
binary as long as you compile it for the
right architecture your kind of problems
and that means like if you did right
you're like compile your program your
deployment is pretty much compile put in
s3 hope s3 is working this week and then
put your for your binary on your server
and run it and that's literally it
on top of that the standard library has
huge amounts of functionality so
although the language itself is really
small the standard library provides
everything you can spin a HTTP server in
like three lines of code that will
automatically upgrade towards HTTP 2
since go 1.7 March it's kind of just
done and all of those things kind of
have extremely sensible defaults you
don't really need to fiddle with but if
you want to kind of customize the dial
or timeouts on your HTTP clients you can
do all the back yourself bundling so for
us like having that simplicity is really
important because as we've been building
our services and our infrastructure over
the last two years things have got
progressively more complicated which
obviously is kind of the inevitability
of building a large application so I
mentioned before we we have Micro
Service architecture in February we had
no services obviously and then
progressively over time we're up to like
a hundred ninety something now and each
of these is a discrete go binary single
process that can communicate over HTTP
to any of the other services so if
you're kind of starting with this there
is actually a few kind of tools you can
use are those go kits which don't if
anyone's heard of which provides you a
kind of toolkit pretty much like a
framework that allows you to build
simple services but then plug in the
more complicated things you need for
kind of distributed systems things like
tracing logging like all of those things
to kind of instrument how your code is
working there's also micro which is
again micro service toolkit this one
comes like more fully featured by
default and then you can switch things
out if you don't really like the way
that they work in our case these
unfortunately didn't exist when we
started building on restrictive so we
have a really simple
kind of library called Tyson and that's
on github and all that is is it allows
us to build really simple HTTP service
and clients that are kind of
pre-configured in the kind of way that
we use them so if we have a kind of
service talking to another service a lot
of this happens in orange structure
these are communicating over some form
of transport now in some cases that
might be a message bus you might be
using something RabbitMQ zero and cue
something like that however that works
you're going to realistically be
communicating to more than one copy of
every service and hopefully doing that
because any one of these could fail at
any point especially if you're running
on kind of cloud infrastructure that's
kind of a good thing they have fails
networks are unreliable and basically by
kind of knowing that and building an
intro application you can make your
applications much stronger as a result
so in our case we have a client server
library this is that Titans package that
we use and we're actually communicating
which you just with HTTP but the problem
you have is like when you're building a
micro service architecture you need to
build a huge number of things into these
clients and servers to make it was
reliable stuff like so discovering load
balancing timeouts rate limiting surfer
braking failure detection like things
are extremely unreliable
I think break all the time and if you're
building up I mean unfortunately that's
not really an option like your
applications have to be very very
resilient ideally they would be quite
quick but I did like even more ideally
requests will succeed within a kind of
branded amount of time so in our
infrastructure we kind of big question
mark here we can either build all of
these things ourselves automatically
into our virtual services or there are a
number of tools that you can use in
between these which kind of take away a
lot of that complexity and that's
actually what we want we want to make
our services as small as possible which
means we can just write smaller HTTP
servers that live here and our
application development has been super
fast and super quick
so in our case we use linka d the know
if anyone's heard of that so it's
basically if anyone's used integral
which is Skyler Connor library that came
out of Twitter that provides they're
like RPC between processes linker D
wraps that up in like a sidecar process
you put one on a host and allows you to
kind of does all of that stuff without
you really dealing enough and it's very
configurable and in our case we use
Cuban Artie's so this is plugged into
Cuban attitudes as well so it knows
where all of our services are and I'll
come back a little bit so in our
infrastructure we have an load balancer
at the top we run on Amazon so just nail
B and behind that we have a kind of go
based HTTP layer which is going to take
in HTTP requests and decide where
they're going to go and route them
within our in structure we then route
that off to what we call an api service
so this is again just a small go server
which is this thing on on a port in a
container infinities and it takes in
requests and then probably onion juice
on Marshalls room doesn't staff returns
some kind of response yeah kind of like
I think 90% of what we do and probably
what everybody does is basically
Marshall JSON into a database and then
back out to the database and that's kind
of what happens here so a song and then
in our case what we don't want to do is
change this routing layer at the top
every time we have functionality to
application we want this to like be the
most stable possible thing that can deal
with potential failure further down our
infrastructure so instead we deploy
individual API services and we route
them based on name so in our case we
have an API if you've signed up for a
multi card and a have an account you can
literally go to the kind of API Doc's
there's a developer portal I put them on
your handler but you can go to this you
can get full access to your data as you
spend it as you use your card all around
the world and in this case I'm using a
web hook so I can register a new web
hook which will
real swing callbacks to a NASA I thought
as a third-party app so while I use my
card until or in a shop somewhere you'll
actually receive a HTTP call
realistically before the receipt has
printed alpha machine so this is
literally slash web hooks on our API now
if we want to add lots of extra stuff to
our API we don't change our routing
there so what we can do is we route this
web hooks thing to a service which is
just a go binary and that will deal with
web hooks for us and if you want to add
a new thing which is like I don't know
slash ponies and we have like a highly
available Pony based API we just deploy
new service and our API will see it's
they're using service discovery and then
it will stop forward for in those
requests people route them through to
the correct application so in our case
this is the web hook API and then behind
out this will do some kind of business
logic realistically it's going to like
check your actually a valid user and
then register or D register or web hook
for you and dual validation and these
services can do anything they want again
they're just standard HTTP servers and
behind this they're then using a
database or some kind of external
provider or anything like that so in our
case we one of the kind of really cool
functionality and go is you can just
appoint really really basic interfaces
for kind of any data type really
so in our case we define any of these
functions like essentially HTTP comers
to literally just be a type of service
which is a function that takes requests
and returns a response and that's all it
does so I can do anything I want as an
application developer I don't need to
like kind of think of like them do
anything really complicated I literally
just register a thing that takes
standardized request type does anything
and then returns a response type and
then when we're doing and registering
these in our go service we can just
register like get slash will be to list
them post will be register new one and
delete with an ID would be register one
and this is just using those
there's quite a few different like
routing libraries for go you can use my
key to gorilla or like gorilla marks a
couple different ones but as an
application developer I can create a new
service like with a single single
commands I can then write a couple of
handlers which are just simple functions
I can't violet push it through CI and
deploy it realistically within IBM for
the super super critical making half an
hour probably less and that's incredibly
liberating if if you're an application
developer you don't have to you've gone
through like all the kind of the checks
and balances we obviously have code
review and we're asserting everything in
our normal infrastructure works even
after the addition of my new new code
but being able to do that extremely
quickly is like what that's kind of our
advantage
like our competition is huge the the
vias that banks that spend billions by
like billions of pounds on i.t every
year and the only real thing that we
have going for us is like speed like we
can execute really quickly and that's
what we need to be able to do in order
to commit stay ahead and provide a
really good experience to customers and
so be able to do stuff really quickly is
super important the other point is
making our system really reliable and if
anyone has built micro service
architectures and send lots of lots of
calls over the network that's generally
not very reliable so we have a bit of
kind of a trade-off here now in our case
I mentioned earlier we use document
abilities so we build all of our
individual services into a docker
container cool thing with go binaries is
because you don't have a runtime your
containers are literally the size of
binary you can use a scratch detailer
that also means you don't even have a
shell in your container
so if hopefully this never happens but
if there is some kind of like breakout
or escape vulnerability you kind of
break out into a potato that of another
shell which is largely infuriating and
the other thing is then they're really
clean so we can ship these around in
if it is you run them in pods you can
still do like all the kind of if you
need to like chapter a TCP dump HTTP
server but you don't have a shell in the
container then that's fine because
include niceties you have a shared
network name space within pods so you
can run like a special TCP dump
container in the pod and you can like
TCP dump the interface that your actual
services using which is quite cool and
in our case we switch to kubernetes
actually from methane's
a little while back in August last year
and this is kind of our previous
infrastructure which was starting to get
quite expensive and we switched over to
communities and that's worked out about
a third of the cost of our previous
infrastructure and that's mainly because
we can condense things a lot more
densely but we still have things like
pod auto scaling so our individual
services can scale within the
constraints of our main infrastructure
so to go back to my previous example if
I'm registering web hooks and I want
really reliable web server web hooks
then we're going to run a number of
number copies of these services so this
is just again a pod in communities we're
running many copies of that and let's
say that this one fails and then all
requests going to this or failing if it
actually vanishes or like the host
machine vanishes then cube Ulysses will
deal with that and it will spin up a new
pod for us and then that will kind of
propagate through service discovery our
services will find out work where it is
and requests will go through time the
other case is we might have that one's
dead got a new one this one is
particularly slow in which case the
other thing we need to make our system
more reliable is going to be some kind
of either circuit braking or ideally
kind of a load balancing and the client
to design which instances are best
suited to serving our individual
requests in our case link addy does that
it has a power of two choices
exponentially weighted moving average
load balancer which who knows what that
does but it's like super great and the
main thing is doing is checking that
like these two a faster that one's
slower
here and some cases that might be
routing a request on a single host and
there might be a copy of the kind of
receiving service on the same host and
that might not be the fastest one so it
will send it across the network to a
different machine and that will just
happen automatically so if you're
building again like distributed
infrastructure like distributed
architectures you have to be aware of
these problems and you need to be able
to either have things that will retry if
the random Potence
or like deal with the fact that some
services are going to be slower than
others especially if you're kind of
running in cloud infrastructure where
you might have one of those that is
officially the same but much much slower
because it's more heavily loaded the
other thing we do is we try and push it
as much stuff I'm going to be a
decoupled as possible by moving it to
being a event based event-driven
architecture and this means we can do
things like if something is down if a
system is down and it's not of critical
importance we can buffer messages and
deal with later we can process things
asynchronously that don't need immediate
responses and all of these things mean
that we can filter them within a
reasonable amount of time but that we
can provide a better more reliable
experience to customers so actually in
the case of so similar kind of thing
we'll have some synchronous call that
comes to our API - again just another go
service we're going to read that through
maybe it does cause to these two
services and as a result of some kind of
action in kind of in rem structure will
generate an event that this has happened
and published a little message wails so
let's say this was creating a
transaction that's obviously going to go
into someone's like an app online light
break statement pretty much so we can
publish that this transaction has been
created and then any number of things
downstream of that can consume that and
this is completely decoupled from the
consumers so anyone we can build any new
functionality and deploy that again
internally separate of our core
transaction flow which obviously needs
to be super reliable
however the problem we have here is any
number of things could be happening here
and if you have a system that has
hundreds of microservices and you've
decoupled consumers and producers you
probably have no idea what's going on
like I have no idea how our
infrastructure works I know how some
sections of it work but we have lots and
lots of developers and that will go grow
infinitely more complicated over 20 and
we need to be able to test them and we
make sure that our synchronous and kind
of cost reduction flows extremely
reliable but fundamentally the flip side
is we need to be able to empower
developers to build stuff really really
quickly and decoupling this kind of
makes that much easier so in order to
like understand how I'm structure works
we need to kind of trace things through
through that now go provides kind of a
way of doing this with contexts so go
1.7 actually pull this into the main
standard library but it for a given kind
of request path we need to understand
how this is flowing through our
infrastructure and in the case of
something coming into our API going to
one of our API services doing some JSON
stuff and then hitting something that
actually does real work at the top of
our API we can tag something with a
unique reference kind of request ID if
anyone's use kind of trading systems
like Zipkin basically something like
that we pass that then down our request
tree so will at this point generate the
ID
Marceline's the headers send it over the
wire unmarshal it pass it through every
function call in this context object
when it comes over at this point marshal
it back onto the wire send it down and
that means even though these are between
running on different machines we can
still tie together different different
requests across different services so
and go you can use this context there's
kind of contact interface so you can
actually build this into any of your own
custom types so now our request type
implements the context interface which
does lots of stuff which don't really
care
but the cool part is this so you can
stick any key value into this object
it's immutable so every time you modify
it it actually copies itself internally
which means it's thread-safe
and you don't have to worry about that
as you pass it around so a kind of a
common pattern that you see in go is for
a lot of functions to have the first
function argument as a context you pass
in this context object and that means
that then any further callers have
access to potentially any keys and
values so you kind of define like
request ID something like a well-known
key and then you can try and pull that
out and if it's there you could log out
and if it's not peyo
so obviously the reason you need this is
because go doesn't read local variables
so pros and cons but that's because
we're running in co-routines rather than
the threads so assuming that we have a
request ID available all the way down we
can then at each one of these points
kind of instrument various kind of piece
of information like the time that we
receive the request sent sent on
receiver response sent it back obviously
we can only correlate times on
individual nodes because of clock skew
but we can then try those together
because we know that that send happened
before this receive so our our system
can kind of correlate them and in our
case we aggregate all this together so
you could use something like system for
this and you get a huge block of data
that's completely unintelligible and
obviously humans are not meant to read
stuff like this but giving you've done
that you can then kind of reconstruct
that into some kind of core graph and
this is calling across lots of different
services so each one of these is again a
different go binary we've got HTTP
server hits to be clients all the way
down again really straightforward kind
of simple standard library stuff and
what we're actually modeling here is
this first section is a synchronous call
for using a comment
so if you have a card which well maybe I
do you make the don'ts I don't okay
and if you've got to cut your debit card
and then you stick it in a machine or
use con telus at some point we're going
to receive some form of HTTP or from
that at the moment we receive them over
HTTP as soap and we pretend to be a soap
server and unfortunately that's the way
that the banking world works
if you connect directly to payment
schemes realistically or be doing like
really low-level socket stuff quite
often you have to use like EDC Dec
encoding because ASCII is like way too
modern and the result of that is some
kind of payment instructions from a card
machine we then have to do a few things
and so we need to look at the cards we
need to make sure it's not like blocked
completely I need to make sure you've
not frozen it
we then obviously a transactions I've
taken parents do all these kind of
things but then there's a lot of other
things we do in the app which we don't
need to do right at that point so in the
ones around when you use your card we
display like the merchants logo we
display like a really nice name we kind
of show you on a map where the merchant
was we don't need to do any of that
right now because that's kind of
irrelevant for your card working in the
shop and I'd prefer my card to work in
the shop and get a pretty map so this
point we can respond back to our payment
provider and we can all about
synchronously but during that will
publish a message that says this
transaction was created with some kind
of basic amount of information and
further down from that we do this like
transaction enrichment step where we'll
kind of correlate it to a merchant will
like look up the merchant details try
and kind of work out where that is do
all that kind of stuff and then at that
point we'll insert it will actually kind
of fire in other events and then at that
point we'll insert it into the feed in
the app so the interesting part is
actually if all of this was broken
you're kind of work but it wouldn't
appear in your app but that's kind of
okay because you can't worked and it
some point in the next like couple of
seconds hopefully they'll appear in your
app or your app will be out of date for
a little while but in the real world
like is going to be a shorter at a time
worst case scenario we're down to ours
but your card still works and we still
have the right balance but just your
apps kind of it out of date which like
realistically is like a good way of
making our systems a lot more reliable
and then after this we push send your
push notifications and the cool thing is
although this looks really complicated
you get a push notification disappears
in your app usually before the receipt
has printed on the machine because
computers are really fast and like 20
networks are very slow and here we have
a coffee cup emoji because it's at
Starbucks so we know it's a coffee so he
gave you a coffee cup of and people love
this like this is like our best feature
if you buy stuff at it so you get sushi
emoji like truth or II and we we do all
of this like before the receipt comes
out of the machine because again like
computers are quite fast you can do
stuff like this really quickly
tastes like 200 milliseconds and yeah
that's pretty straightforward and so
this is of course like a massive line
this is actually what happens and
actually that was a couple months ago I
have no idea what some of this stuff is
but things like if you have budgeting
enabled will will check your budgets
will life see if you are above or below
target will send you like kind of praise
if you are something like that we'll
look up new merchants we like get all of
that information and all of that stuff
happens before you get a push
notification because like if you're
doing spending analysis like the push
privation contains that information so
you did before but even if all that's
broken your cards there works in a job
so it's all good
so in our case we've kind of started
using go 99% of our services are in go
we've got one or two the arms because we
run everything as really basic HTTP
servers in cuba Nettie's and we have
like our service discovery is separate
from
actual business logic we can write stuff
in like a Python if things like kind of
machine learning data analysis that kind
of stuff that's way more suited to that
if we're dealing with IBM MQ then don't
use the go laboring for that there's
like really good Java libraries so like
use scholar or Java for that particular
thing but in our case like goes being
kind of perfect for for like that kind
of micro service architecture it's
allowed us to build stuff really quickly
the kind of concurrency and like kind of
features it provides a language really
like looks into the language let us
build highly performant very scalable
very lightweight services and build them
really really quickly and the language
itself is like really small and simple
and easy and that's meant if we're
onboarding engineers like even if you've
used the language before when you start
another company like inevitably there is
like some wonderful homegrown framework
that you have to learn and it's kind of
like it never table and in our case like
sure there is some of that but it's so
simple that like even though you're
learning a new language potentially and
you're learning potentially new
framework like people are productive
within like a couple of days and a
deploying to production within a few
days or usually a double day or so yeah
and so that's about it thank you very
much everyone
yes so if anyone's got questions if the
question is do you have mondo cars the
answer is yes cool
so the question is once we have the
banking license will we do credit
facilities yeah
so we apprentice or for overdrafts and
but we won't initially be doing like
things like loans or contracts by our
aim is to like build the best possible
current account and like really like
mail back oh yeah over just is part
again so you talked a lot about using
RPC over the network and using a liquidy
and stuff like that and getting stuff
out quickly to prague from development
but there's kind of been less talk about
doing this while insuring that the
security and in between like doing kind
authentication or protecting hands
lateral movement I'm curious how you're
maintaining like this this velocity
while also while also protecting like
the security of your users yes
so I guess there's a lot of different
areas of that like security is a pretty
pretty wide topic and we have a security
team that kind of works full-time on
that
so both in the client itself obviously
clients are untrusted like we contrast
anything that our clients send us
however we can build in lots of
functionality in smart things like touch
ID and that kind of stuff actually in
our infrastructure I think one my
colleague Simon has done a couple of
talks about how we segregate Amazon
access so you can separate people who
can manage users versus people who can
provision users and give them roles you
can do those in separate Amazon accounts
so you can separate that kind of thing
within there you then have all sorts of
network policies and Cuban entities you
can use Coleco to do network policies
between services even below that you
then have to like prove who you are
within
structure that's essentially a big soup
of stuff that can communicate and
humanities provides a little way of
doing that but it's not really kind of
established enough we are I don't know
how far we've got with it yet but we we
do like client authentication with
certificates that rotated between
services which means we do like a lot of
kind of CA stuff internally and you can
keep parts of that offline like wikis
and queens yeah
I don't know if that's really answer
your question like essentially there's
there's a lot of stuff you have to do
and ultimately if you have like 200
services each of which you're running
between 3 &amp;amp; n copies of you're
realistically running like a couple of
thousand binaries across a number of
machines that can all make HTTP calls to
each other so yeah they have to have
relatively strong authentication and you
have to know something is who it says it
is within the infrastructure to
guarantee what countries do you operate
in so the moment just UK I'm afraid all
right but the cards work globally so
that's one advantage of like we are cars
or mass cards which means they work in
every machine in the world pretty much
versus like building your own point of
sale devices we can't give you a cards
if you live in another country yet
although hopefully soon but the cards
will work anywhere in the world and like
you can't get a better exchange rate as
far as well hello you mentioned that you
are using linker team you know with
kubernetes can you elaborate a little
bit how to deploy in Gardena kubernetes
environment and yes we we one link the
locally owned a free machine which means
you run it as a diamond set in
communities so that means like I seem to
bring up a new node link a teapot
launches on that runs that obviously you
can't communicate to localhost because
that's not a thing in kubernetes like
every pot has its own IP and so we the
the pod manifest for the diamond set
like works out what the local link ID is
given the subnet and provides that as a
proxy address to all of the pods that
run on that machine so that means all
the things know
the local engineers they communicate
back and then that uses the kubernetes
namer
which lengthy provides which hits big
simonetti api which gives you service
discovery so it then knows about all the
other pods are and if it's communicating
from this one this service to that
service it'll go for the local entity
over an established TCP connection to
that local links B and then to that one
so the whole point is like to stop
opening socket connections with your web
structure which is like relatively slow
with that many services how do you
handle automated integration testing and
to end automated automated integration
testing so say do you test the entire
flow with that many services so we have
we have lots of different plays and yet
you basically have to like run you have
to write something that can run your
automated test suite like against your
production infrastructure I think
actually Craig talked a little bit about
that in the failure track yesterday yes
we we have a test suite that does both
individual unit testing but also
acceptance tests that's what I sailing
to remember in the micro service
architecture like unit tests are great
but like they essentially prove that
they've really tiny amount of
functionality works which is ultimately
useless because the thing is the bugs
that you have are like between the
interfaces like you've changed something
it provides the parent sir this isn't
expecting it it explodes so yes you have
to have full accepting tests we have
those we run those on CI as well on
every single kind of comment which which
is time-consuming or at least not if you
provide enough power so I guess
expensive but that means that we have
flows that everything out there's
everything the core like Cod flow all of
those kind of things will be admin staff
and those are run against a set of we
run on every single service against the
set of docker containers which run all
of our shared infrastructure I've spun
up on CI way every single time that
tests that you in theory have a working
set
precise commit but it doesn't assert
that if you deploy that commit and that
commit in production that makes but it
would work so then yes realistically you
have to then build a system which can
take those exceptions tests and run
those as from tasks attempt against
production we do some of that some of
that in production at the moment so
we'll do like we simulate customer
behavior and once we have our actual
core processor because we win the
process directing directly connecting to
MasterCard we can then stimulate full
card flows without going through
separate infrastructure so we'll do both
like hey here's an actual card terminal
and you probably see loads of videos
online of like train track which drives
like a card around goes past a card
terminal and that's hooked up to a
monitoring system will justify that but
we can test also at the actual
MasterCard point than that point as well
which we thank you yes cool well thank
you very much the only question is going
to give yourself</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>