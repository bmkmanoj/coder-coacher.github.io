<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Dependency Management in Scala: Now and Later | Coder Coacher - Coaching Coders</title><meta content="Dependency Management in Scala: Now and Later - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Dependency Management in Scala: Now and Later</b></h2><h5 class="post__date">2013-03-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/TMQWFSM9_1A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I feel like I could spend the whole time
with caveats just listing caveats about
about this talk because basically it's
vapor where none of it exists i'm
proposing that this is something that we
should do but i don't want to do it by
myself and there's no code in this talk
hopefully that'll be good for an end of
the day talk and necessarily going to be
kind of superficial on how i go into
these things i'd be happy to discuss
this more tomorrow in detail but think
of this as something of here's how
things are now I think we have some
issues and I think they're worth doing
something different and I'll really
focus on I think the issues that I see
and where we should go and its really
meant as motivation if you have if you
need more of a motivation say you know
then seems such a big deal to me
especially since we have an existing
system and interoperating with that
existing system is kind of going to be a
lot of work so we want to start just
with manual dependency management this
is like super super basic I hope nobody
does this but you want to use some new
dependency you're writing your Scala
code you know you just learned scholar
or something in your you're running
Scala see and now you want to use actors
so you go to the aqha website you
download the jar copy it to your project
and well now you try to run well it
needs it has dependencies so you've got
to look up those dependencies download
those copy those to the project and then
keep on doing that so nobody does is
because it's high maintenance right if
you want to go change one of those
dependencies later you want to upgrade
acha 2.1 and well now you got to go
check its dependencies again and go
download those dependencies see if any
of those changed the other thing is
collaboration if somebody else wants to
work on your project they have to do the
same stuff that you just did somebody
wants to use your project you met you
make in a library that's useful and now
somebody has to go download the aqha
jars download those dependencies so
notice nobody does this but of course
they solve it in different ways Scala
has inherited Javas dependency
management for better or for worse and
that's Ivy and maven maven is the clear
winner in terms of the repository format
the metadata format and i would say
adoption well really the key
to it in general is the machine-readable
dependency information so that's both
the product definition so like the files
you actually generate for your project
as well as the dependencies that your
project needs to run compile or whatever
and this is key because now it makes it
automated you can process all those the
dependencies transitively you aren't
excluded from verifying those
dependencies right you can say well I
don't want any of these things to change
or like I don't want them to update or
to show me the ones that have changed
since last time but it will resolve
conflicts we'll get to that more it is
now abstracting actually fetching those
dependencies ideally these are
declarative dependencies you just say I
depend on project a version 1 you don't
say how to fetch it so necessarily a
dependency manager is going to abstract
/ actually fetching that and that
requires caching and if you've used
dependency management Scala through SBT
you know that's a problem finally you
you want to make other let other people
use your stuff so you publish it so this
is just really basic you have a project
let's call it demo 1 point 0 you use
another project a another project be
another project d and somewhere these
have pulled in two different versions of
some projects see you have c 3.0 and see
four point oh and what do you do now
because you don't want both of those on
your classpath one will shadow the other
if anybody says osgi we're not talking
about that here the there's there's a
couple different ways you can handle
this maven's default is nearest so you
have your route here demo 1 point 0 c 3
point 0 is the closest to that route so
let's go with that ivy has the fault of
latest so let's let's take some
information from these versions 3.0 is
older than four point oh if you if you
ascribe some meaning to it so let's go
with four point Oaks that's newer that
IVs pluggable so you could there's
another one called strict well I don't
know what to do with this I don't know
whether they're compatible so you tell
me and so strict is kind of like manual
I think personally that that's really
the only one that you can do in an
automated system you just don't have the
metadata to know whether three point 0
can be substituted for four-point-oh or
not but that's not what the defaults are
so that's not what aspect he does it's
not what maven does you can of course
get warnings in both of those systems in
any case but I think the cake the key
takeaway here is that the you're only as
good as the metadata if you if your
metadata relies on like semantic
versioning which I don't think is common
enough to do that and I don't think it
actually solves the problem but I won't
get into that so you just don't have the
metadata to make a good decision here so
one of the next talk about caching this
is kind of simplified it's very
simplified and it just shows what I call
the on demand model of getting metadata
so you say I depend on project a one
point oh well your dependency manager
says okay that's nice I don't know
anything about project a one-point oh I
need to get some metadata for it so then
it will go because this is going to
involve getting it from some remote
server we need we don't really want to
do that like all the time so we want to
cash it and we say is it in the cash yes
okay well is it you know the latest is
it up to date is something changed on
the remote server and this is kind of a
problem with the on demand model because
you're doing this per per module and you
don't want to contact the remote
repository but you have to in order to
know whether it's up to date it's not
it's not fundamental in this this is
this model because here's how you
determine that path you say I have some
module worked out example is the group a
is the name one point it was a version
let's turn that into a path well it
tells me nothing about the content at
the end other than I know I'm going to
get some metadata so other than that I
have no idea whether what I have locally
is the same as what i have remotely so i
have to do this remote access so if it's
not up to date or it's not in the cache
or whatever then i have to actually you
know try and get it from a repository
and so i'll check a repository if it
exists then i'll download it and cash it
and then carry on process the next set
of dependencies
if it's not in that repository check the
next one and so forth and so these
remote accesses are kind of what can
make it slow you can mitigate this a
little bit with like a asynchronous
downloads and such but it's still a
problem and then if it doesn't exist
maven 3 will actually cash this failure
and you can kind of see where that might
go wrong because if it caches failure
well what if somebody you know makes it
exists later well how do I know that it
exists later the this is a problem on
with the on-demand access model so this
leads into some more motivations for
doing something different I think the
on-demand access model for metadata is
perhaps not the right way to base your
dependency management system because
your remote path can have many many
possible files at the end of it so for
example like a snapshot that can be
updated there's there's different things
you could have at the end and you have
to contact the remote repository to see
whether it's up to date then we'll move
into a Disqus a couple of different
areas and one of those is metadata the
palm format is kind of deficient in
being able to describe comp maybe not
common but fairly common needs for
dependency management and I don't think
it's going anywhere I don't think it's
going to evolve or anything like that
ivy is a little more powerful but it's
not the standard so I think we should
consider whether we should do something
about that and so I'll talk I'll talk
about some motivation some use cases for
that and then very vague proposals it's
kind of like wave the magic wand and our
problems are solved but it's something
to consider the other thing is just with
workflow this is probably the most
boring thing ever but this is the kind
of thing that you deal with daily if i'm
running a continuous integration server
those might is my cash threadsafe if
it's maven it's not if it's SVT it is
but only because there's a gigantic
global lock on the IV cash so let's I'll
talk about all of these things the big
motivation that I think you're probably
familiar with at least to some extent if
you've used libraries from Scala even if
you're using it from maven or some other
tool the problem is that
it's not it's kind of a problem but
Skyler 2.9 is binary compatible with two
point 10 it's a problem when you're
trying to use a library that was only
built for two point nine with two point
10 because that won't work it will give
you a runtime error because they aren't
compatible it's not a problem because it
allows Scala to evolve and we don't
really want it to stagnate so it would
be nice if we could kind of have both
they are mostly source compatible and so
this led to people wanting to build the
library against two point nine and two
point 10 and every you know it's a
little extra work when you're publishing
and its maybe it's annoying you can't
use some new feature but it generally
isn't a terrible idea so we want to in
order to do that though when you publish
42.9 you need your dependencies
available for tuna 2.9 and same thing
when you publish for two points n in
order to compile you need your
dependencies for two points n so what
that really is is separate universes
here's the dependencies for Scala 29
here's the dependencies for Scala 210
the best solution that I could come up
with and that I think has I don't think
anyone else has come up with a better
solution that encodes to maven metadata
so this is both meta maybe a metadata
problem and I maven repository problem
is to append the scala binary version to
the module name so if i have like combat
type saved acha acha acha name will be
acha underscore to 10 so this is a this
isn't a great solution but it's it's
fairly simple so even if it has some
problems at least it's simple and we can
understand it but it's fragile because
you know when they do these these
conflict resolutions it only does it
between names that are staying the same
so it's only going to do it between a
and a not a underscore 2.9 and a
underscore to point 10 so it's outside
of conflict resolution so now we've
we've kind of we're trying to encode
something into a system that doesn't
support it and we will pay for it it
also does not scale to other any other
axes other things you might want to
cross version SBT plugins 0 12 0 13 i
also want to brake pad ability
occasionally it helps move forward
without too much effort maintaining
compatibility same with play 2.0 to 2.1
you might want to write play plug
and then it's not able to hit a little
difference between like forward and
backward compatibility so one option is
ivy has these things called extra
attributes and I think they work pretty
well for this you would say you know
this is my library for scala binary
version 2.2 N and this participates in
dependency resolution so it's kind of
natively encoded the problem is that
nobody uses IV metadata it's not publish
to maven repositories so you could say
well let's just use IV metadata I think
this is a little hard to push because
IVs a mature project it's not really
going to be developed what we really
want is something that's going to evolve
with their needs the other benefit is
its structured information and I didn't
emphasize this is not for the beginning
but really what we want is automation to
the extent that we can code things that
are machine readable we can automate
another example it's kind of similar but
it's actually different and that's
richer resolution so there was a problem
that came up that acha distributes
standard jars you know aqua cool rocker
actors I feel but then they also have
instrumented jars so like I think with
aspects and this is used for the type
safe console so if you want to you know
debug your application you just depend
on this special version of the jars
instead and their binary compatible
everything like that they're just drop
in but you can't have both on the
classpath you don't want the under
instrumented ones shadowing the
instrumented once but there's no real
way to do this in maven there's no way
to say this conflicts with this or this
provides this and so I forget the exact
solution we came up with but it was I
think it was basically we're going to
count I think was either like hope for
the best or write like an SVT plugin or
something but this this is completely
excessive and unnecessary oh right it
was right spt plugin maven plugin and
every other bill to let people use the
other one is renaming something there's
limited support and in the palm format
for something called relocation this is
a rather inadequate it's not as good of
a user experience I'm happy to go into
any of these in detail but again I don't
spend the whole time on it you always
want to fix the current problems the
problems you perceive for the the near
future and you also want to say well hey
maybe there's some cooler things we
could do because you don't want to
there's a lot of obstacles than doing
this it's kind of a high barrier you
have to really prove that it's worth
doing this and one of those things is
well why can't we just add some extra
metadata we should have extra metadata
associated with the class I mean with
the sorry with the metadata there should
be extra information with the metadata
and one of those things could be main
classes associated with the module then
you could just tell your dependency
manager run this main class well the
pendency manager has the list of all the
metadata it knows you can say I know
what metadata that is I'm I know what
module that is let's go fetch the module
just one the class for you not thinking
about this necessarily for like you know
production people who have this big
build and so forth but it's a nice way
to get people up and running quickly
with examples other things like that if
you like this example come up with a
better one the last motivation that
we'll talk about is management and
distribution this is kind of what you
deal with if you're not configuring the
build or configuring your dependencies
and taking use of this information
you're working with it you're running
compile compile then needs a classpath
how's that class both coming about it's
coming about from the dependency manager
which is going to resolve your
dependencies and put them on the
classpath so and then and then at some
point you want to release it right if
you don't ever publish your stuff it's
useless to other people so as a library
of course you have an application that
doesn't matter but in my opinion the
barrier to publishing is too high people
are spending time trying to complete the
18 steps to publish to maven central
that's something that could be doing
they could be writing more innovative
things for scholar or working on stuff
like that cache access current
concurrent processes like I said for
continuous integration server that's a
problem you really don't want to be
limited to that the next two are related
integration with native package managers
well that's kind of thing that you don't
typically care about for the libraries
you're developing you know usually we
like we don't mind that they're managed
by SBT maven Ivy whatever but it's still
important you might get SVT from your
package managers a lot nice
Pacman's spt or whatever or whatever
package manager you use same with
offline installations kind of similar
the maven repository way of doing things
in the on-demand metadata model doesn't
really work so well with all flying
installation we'd really like to be able
to for example play likes to provide a
fairly decent out-of-the-box experience
give you one download once it's
downloaded you don't have to download
anything again of course we also provide
a stack and we like to do that there too
at type-safe so and repository
management mirian if you've had any
issues with the typesafe repository
recently this is kind of related to this
maryna maven repository is very
expensive and rather tricky to do you if
you remember the Scala tools shut down
this is kind of wrap that into this
point so I guess done complaining here's
what we should do about it what do you
think split the metadata and the
artifact repositories make the metadata
repository stored and get or any other
distributed version control update and
batch instead of on demand don't pull
down the individual metadata files one
by one so don't make your caching
decisions per file pull them down all at
once you're done the user tells you when
to update just do it once efficiently
and incrementally for the artifact
repository keep that an on-demand file
repository but make the path the hash of
the content and the metadata format have
kind of hinted at some things that would
be nice to have make it richer and
evolving and of course the tricky part
is actually implementing the dependency
manager that supports that but um that's
implementation detail for the metadata
repository so store it and get there are
quite a few advantages to that see what
do I have to say about that yeah okay
I'll talk about that later but you
retrieve it locally so you get all of
the metadata all at once this makes it
possible to implement that that run main
class feature that i showed you have it
all available you can implement a search
I've seen quite a few
attempts to search for a independency I
just want to find an HTTP library why do
I have to go contact a remote server or
why do i have to like scan maven central
in order to find all the metadata that
there's a barrier to this if you want to
write a tool now you have to figure out
how to index all of maven central so you
have maven repository calm but I mean
how many you just don't see a lot of
innovation in this space I think part of
the reason is that it's not easy to get
access to all the metadata I think
there's some things to consider instead
of a centralized repository I you think
svn right every every action had to go
to name not every action but you had
centralized server for your version
control get came along up you were like
well why do I need that then you start
using getting you're like okay what's
lesbian I think the same thing here so
for the new one I think you know before
you head this on-demand access I think
well it's not even like it's a new idea
right homebrew does this and then linux
distributions do the batch update where
you pull all the metadata all at once
big questions answer does this scale
maven central's large what is it like to
download all the metadata can get do it
efficiently enough or do we just split
the repositories up so you only download
what you need so can we solve that open
question what does it by you I think I
already covered a couple of these things
efficient incremental updates what how
many times a day do you delete your IV
cash I hope it's a decreased if you use
0 12 if it's not please reproduce and
let me know but still if you delete your
local cash you have to download
everything so that kind of mitigates the
problem with downloading all of the
metadata right if you download all the
metadata well now you have all the
metadata you only need to get the
updates and get we can offload that to
get I that's what it's good at right
just how to pull stuff down efficiently
incrementally let it do that if you're
not always redownloading all of the
metadata it might be lower resource
requirements on the server I would be
interested to see if that happens
because it is we know that it is
expensive to mirror a large repository
is expensive to host a large apposite or
ii would be nice if it were not
I think something interesting here that
you get for free is you you could
publish all your all your modules in
your project all at once and one commits
it's all localized you just view the
commits see everything that changed in
the metadata as opposed to you know you
publish a few modules and then something
happens in your building it breaks and
you don't publish the rest of them so
you even inconsistent publish this is
mitigated with staging repositories and
maven usually but that's kind of like an
intermediate step that you know just
adds overhead so I think really the big
advantage another big advantage for me
is if github if you can just make a
github repository and that's your
repository I think that's a pretty big
win it's really nice to see how easy it
is to create a repository on github
compared to how easy it is to make your
own maven repository if we can reduce
that I think it'll be really big win for
the whole Scala ecosystem version
controlling your metadata that also has
I think quite a bit of benefits you can
have reproducible builds with most of
the like more features of your system if
you say to pay em if you say dynamic
revisions to someone who works with
builds they're going to say no don't use
them that's you can it's not
reproducible builds and the reason is
because there's only ever one version of
the metadata on maven central you know
if you publish a new if you say I want
anything between version 1 and version 2
exclusive and someone publishes a new
version next time you go back to build
that build you built last week it'll get
a different version now but if you tag
you say last week I built with this
commit from this repository you know you
can actually improve the metadata over
time because you're not going to break
people who are replying relying on your
metadata to not change so I think
another useful thing is you can you can
view and and audit and if the metadata
changes so you can say you know when you
do an update you say okay that that now
depends on 1.1 makes it a little bit
easier to see the changes in metadata
the artifact repository I think is
fairly straightforward and it's a pretty
easy win
if you make the path the hash of the
actual content of the jar and you make
it like a cryptographically strong hash
so that in practice there's one hash one
jar you have the hash it maps to one jar
one jar has one hash this means that you
always know whether you have the right
content right if there's a path with a
certain hash there's only one content
that's going to be at the end of that
hash so if you have that hash in your
cash then it's never going to be any
different and so you don't need to check
the remote repository it's easy to
mirror splitter merge there's nothing
fancy to it if I mirror or something I
don't ever have to contact what I'm
mirroring to know whether I'm still up
to date because nothing's going to write
it the hash this hash is always going to
correspond to this content now they can
delete it on that remote repository but
it doesn't matter it's still valid the
main problem is coming up with a human
readable name I don't really want to see
hashes on my classpath it's not going to
tell me anything at all so I think
there's ways to get around this but um
that's just really the main drawback I
would say so we come back to metadata
core this is a very vague proposal on
what to do about it but it kind of
identifies the direction and I'm
interested in I'll get to that later but
i'm interested in needs like what people
would have liked to have done what
workflows you have etc but I think this
kind of summarizes that the what you
kind of gives the outline of what you
would do with with new metadata and
first is identifying attributes the
dependency management doesn't care
whether you have like an organization
the name whatever it just says are the
is the identifier for this the same as
this so if there's some utility and
generalizing that to just keep value
pairs you just have a map we can do that
similarly with version attributes I've
already shown that with cross versioning
you have like a unique version that
uniquely identifies it so if someone
wants to pen on that particular version
they say i want dependency a with this
unique version it will never ever pick a
different version for you if you just
want something that is binary compatible
with you know version 1 point 0 you say
I want acha binary version 1 point 0
because this is an instruction format
the idea is to make all of this
automated for you it's not supposed to
be like you know oh now I gotta have to
specify 18 different properties and this
is going to be really complicated the
ideas gave it a structured format
evolved it as the users needs and let's
make it happen so describing attributes
these are just like general these aren't
necessary for dependency resolution
these are the things like main class
that I talked about maybe you list all
the packages in a dependency so that
something like rapture can map packages
back to dependencies so it analyzes your
imports and that can automatically put
those dependencies on the classpath so
you don't even need to specify this
generally I think this is where you have
potential for innovation if you're
thinking of something that you would
like attached to that metadata put it
here SBT 0-13 will put the base URL for
your api docs in maven properties this
is like the super big hack and any time
I ever hack anything in the maven
metadata it always comes back to bite me
so i'm i'm not sure what this is
particularly going to do if you can tell
me in advance that would be great but
this is where that would go instead make
it native and then when SBT pools and
all your dependencies it can pull that
base URL from all of those from all that
metadata and pass it to scala doc which
as of two point seven point one will be
able to link to external scala docs it
just needs a mapping from class path
entry to base URL well you don't want to
provide that for every single one of
your dependencies all right you don't
want to go look that up and list them
because now you're back to basically
explicitly listing your dependencies so
if we can automate that let's do that
and that's what describing attributes
can do I've already mentioned how
artifacts are going to be would be put
in a repository you mark them by hash
this is the nice thing about this is
that there's there's no room for
question it's it's not going to vary you
say i want this hash that's what you're
going to get then if you sign the
metadata like you sign the commit you've
signed the metadata you've signed all
the artifacts all at once
configurations if you're familiar with
IV configurations this would be
basically the same thing but cleaned up
I don't really want to go into that
resolution controls what I was talking
about with akka and their instrumented
jars and the basic jars I want to be
able to say this provides this or this
conflicts with that and just as an
example this is you know just the table
that I threw together flattened and
simplified you have your standard thing
organization name you have a unique
version maybe a common version so if
someone just says well they don't really
correspond but maybe you would say to
1100 dash snapshot and you would just
get the latest one and of course this
isn't quite like maven where it would be
like an on-demand fetching you'd have to
actually update the metadata through get
so you would say like get pool and then
right so then it would get the latest
version within that and you can lock it
down you can lock down that commit and
you don't have to worry about when it
will update the snapshot if you want to
snapshot updated update the metadata the
artifacts listed as hashes yeah it's
basically what I've already said the
kind of like biggest absolute biggest
problem is compatibility with existing
maven repositories I don't think anyone
would ever underestimate this I
certainly would not I've seen all of the
bugs in maven I don't know how much to
what extent you have to reproduce those
I guess part of the solution is you just
use ether and IV as your interface but
and one thing that would be nice would
be repository sides so we've we've said
we have this git repository with
metadata in it so you would just import
maven central for example I mean I say
just import I have no idea how difficult
that is but that would be the idea is
you do it once you have a repository
that pulls in all the metadata and you
write a conversion tool so that's
completely separate component we can
develop the rest of it separately I mean
of course you have to have a metadata
format that is useful and worth
converting to but you do the conversion
wants you don't embed it in your tool
like like ivy has to convert maven
metadata on the fly and if there's a
problem you have to publish new version
of IV right and people have to actually
start using that and then s BTW has used
that there's a lot a lot
delay in between fixing it but if we
have version control and we do batch
conversion you report a problem we fix
it problem solved like end of problem
not eighteen thousand other people also
have this problem I think the biggest
difficulty is probably publishing back
to maven repositories and working with
general maven workflows things that
support maven so I think the the best
perhaps the best idea that I have now is
to proxy a this new dependency
management repository with like a server
that will convert requests for maven
artifacts not real clear on the details
it sounds like a good idea though many
of these things are in that category so
there's lots of opportunities though so
if any of these things sound interesting
you should speak up because it's a good
time to get started in the beginning
really really big thing that I think is
most difficult to do is what do we want
to do what are the workflows that should
work well what are the requirements for
dependencies what things do we need we
can of course look at other build
systems of other dependency management
systems linux distribution we can look
at all of these things but those will
only kind of tell us what other people
have bothered to solve there's a lot of
smart people so that maybe everything
but anything is specific to scala that
we run into this is really where you can
help a lot I don't have all the problems
that you have I have different problems
same with everyone else but then when it
comes to actually doing certain things
there's of course lots of good test
their metadata format and dependency
resolution that's a good like actual
computer science like official hard
problem I think the existing things
don't really they do heuristics I think
there was an attempt to get maven using
set for J I don't believe that worked
out a very noble effort regardless of
how it happened to actually work out but
this is a hard problem I think it's
interesting and we're
worth doing I think metadata format can
really improve our experiences with
working because dependency management is
really about collaboration it's really
about me being able to use your your
binaries you've been able to use mine
and the less time we spend all that the
more time we spend on useful things
compatibility writing this tool that
imports stuff that'll be a blast but I
think everyone will respect that the
difference between if if you think this
is a good idea the difference between is
succeeding and not succeeding is whether
it works well with maven I mean that
that's really the way it's going to work
out the user interface is also important
all these things are important but for
example being able to just say hey hash
this jar sticking in the cash you know
nice nice simple command for that simple
command for add a repository do you
update stuff like that I haven't really
talked about us 50 a huge amount because
really the pendant manage the pendency
manager should be independent of the
build tool built tool should be
independent they should inform each
other and certainly I am interested in
this working well with SBT in solving
SPT problems but absolutely it should be
a separate library with its own user
interface and also good API but I think
those don't need to be together this is
a good example of something that I don't
think is a huge amount of work but is a
worthwhile contribution for someone to
focus on exclusively so there's more
stuff to do but there's plenty of plenty
of things to do the key here is that if
you are waiting for me to do this it's
never going to happen
maybe not never but it would take a long
time so the real question though is it
worth it because it is going to be a lot
of effort you say even I were to do it
by myself that's something that I'm
going to be spending time on as opposed
to doing something else fixing your bug
in SVT or whatever making compilation
faster oh that's generally grapes job
now so maybe i will have time to do this
again it's people's people's interest in
doing this is whether it's going to
succeed and yeah that's that's about all
i have to say other than session
tomorrow if this is interesting so the
first question I want to hear from you
is is it worth it because if it's not
let's just go drink and then if it is
worth it are you interested what ideas
do you have what is not going to work
really constructive feedback is the best
you know what is what problems have you
had now what can we do workflows
reliability automation or the idea so
yeah again this is just me saying I
think this would help is certainly not
like a guaranteed project type safes not
saying like yeah mark you should do this
it's kind of like you know if it's what
we need to do then let's get people to
help really all right well thank you for
your time
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>