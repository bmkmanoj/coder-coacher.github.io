<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Serverless &amp; GraphQL | Coder Coacher - Coaching Coders</title><meta content="Serverless &amp; GraphQL - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Serverless &amp; GraphQL</b></h2><h5 class="post__date">2018-03-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/SM8CJdfuXsc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks everyone for coming out hope
everyone's having a good Q con learning
a lot really enjoying yourselves what I
want to do today is do something kind of
fun we're gonna talk about two fairly
new technologies in the space those
obviously being service and graph QL
we're good so let's talk about them kind
of separately one at a time kind of try
to understand those and then talk about
putting them together because we all
know nothing ever goes wrong when you
take two interesting technologies and
putting them together microtransactions
and triple a console games for instance
nothing ever goes wrong there so Who am
I I'm Jared short I'm the director of
innovation at Trek 10 Trek Ted is an AWS
advanced authorized consulting partner
very much a start-up and a few years ago
AWS lamda came out and I sat down with a
small group of people we're about six
people at that point in time and said
guys I think I think we're gonna see
more in this space this is a really
compelling way of approaching building
architectures and software in a way that
I don't have to worry about the
underlying infrastructure necessarily so
my job at Trek 10 is the director of
innovation so what that means is really
I get to play with all of the bleeding
edge stuff the new shiny knees out there
and figure out more importantly how do I
take these these new shinies and tame
them down and up and racialize and then
operationalize them and take them back
to our clients so they can actually
build value with those new tools
utilities approaches infrastructure etc
so I've actually been working with
serverless in production at production
loads across startups and enterprises
for about two years at this point
hundreds of millions of executions and
and we've seen some really some really
interesting and compelling outcomes out
of that so first I'd like to talk about
graph QL graph QL is a technology that
comes out of Facebook they've been using
it internally since about 2012 and they
released it publicly
both the spec and some example
implementations in 2015
I don't know how many of you know about
some of the Facebook technologies and
the patents and licensing issues that
were around those they had an
interesting clause that said if you ever
sued Facebook you lost the rights to use
any of their stuff and basically any of
your products some people are really
scared of it but recently Facebook MIT
licensed graph QL and react Jas and
other technologies that are kind of core
to this this ecosystem that they're
building and so people have really
appreciated that and they're listening
they're communicating community
so what graph QL is it's actually a way
of modeling your data and and your
business as somewhat of a graph and then
giving you a standardized query and
mutation language and system that you
can go and and work with this data and
and this and your business as a graph so
what it really gives you is essentially
a one endpoint for your entire API
unlike a rest-based in system you have
not path based but just the single end
points where you can issue your queries
and and mutations in this standardized
pattern and it gives you back all of the
data that you would expect right so what
this gives you is an easy-to-understand
API layer a single endpoint all of your
aggregated resources can exist behind
this endpoint your developers only get
exactly the data that they're asking for
in the shape that they're asking for it
we're gonna look at that a little bit
later and understand what that really
means you get some streamlined API
iteration and extensibility right
there's really easy ways to keep
improving on your API without impacting
existing clients or developers it
empowers your clients to easily build
more efficient requests across the
network and really you can abstract away
a lot of complexities that you would
normally run into you when dealing with
API and then more importantly the graph
QL community and tooling is is insane
there's there's so much power behind
this that it's it's hard to ignore
some technical details of graph QL
obviously there's there's a schema and a
spec but importantly it's a typed API
meaning that everything has to be well
defined similar to a typed programming
language or something like that you have
to define all of these things ahead of
time which introduces some interesting
capabilities later on further in the
stack so queries whatever I say query I
essentially mean a read something that
is reading data from the system when I
say mutation it's obviously something
that is writing to the system causing a
data change of some kind so graphical is
both the specification for issuing these
queries and these mutations this
language this typed API and also it's an
execution engine that knows how to
understand those and there's reference
implementations for nodejs in many other
languages but it's this execution engine
that can take these these queries in
these mutations and figure out how to
resolve them for you and provide a
pattern to to resolve across your data
sources and things like that also one
really interesting thing is that it
elegantly solves the one percent problem
where typically if you were to list out
say for instance a list of speakers at Q
Khan and then you also want to know
about the talks right so I say give me
all of the speakers in the rest
implementation and I get back to all the
speakers and it might have a list of
talk IDs that are related those speakers
and then I'd have to iterate through
each of those speakers for instance and
say okay give me the information about
this talk and this talk so at Q Khan
there's something like a hundred and
seventy nine speakers I would have to do
a hundred and seventy nine more requests
for talks for instance with graph QL you
can elegantly solve that problem we're
gonna look at that actually so I do have
some examples of the schema here so you
can kind of understand it like I said
you have to explicitly define all of
your types that are going to exist in
your API we have a type of speaker a
speaker has a first name a last name has
a list of talks so you can define lists
of types obviously denoted by the
brackets there you can have no levels
and non nullable meaning that the API is
guaranteed to return some data
or doesn't have to guarantee that it
will turn data back scalers unions and
we're both inputs there's all sorts of
things you can define in these schemas
that make it easier to understand and
use later so if we want to understand
this concept of Route resolvers route
resolvers are essentially something that
says at the very beginning of my graph
there has to be an entry points to
understand how to change or how to read
data from my API so for instance the
kind of the standard approach to this is
you have a query route so for instance
in this case we have a query route that
has two possible things you can ask for
you can either ask for a list of all
speakers or you can ask for a list of
all talks you can pass in arguments or
things like that and define these inside
of your schema saying hey four speakers
you can pass this in a limit we might
default to some number like 10 or
something like that and you could define
that and say as an argument of when you
do these queries how many speakers you
actually want or you can do things for
instance sorts I want to say I want the
talks in ascending order or descending
order based on some attribute or field
in those and then both of these are
returning back for instance list of
speakers or the talk type mutations are
another I have an instance here you have
a mutation routes and you can take an
input type which can define things like
the title of the talk or a list of
speaker ID so that the back end could
eventually resolve to the speaker type
and then we passion that input type so
everything is well-defined which means
that we can do really interesting things
and provide really interesting tooling
for developers and clients using these
systems in graft well this is actually
an example this is kind of like a
reference implementation we actually
have systems in production that look
pretty much exactly like this the top is
the query route in graph QL
specification the schema language then
the bottom is actually a ripped out
chunk of JavaScript that you can look at
and essentially what we do is here this
is demonstrating how light I like to
actually keep the graph QL the engines
themselves when they're actually doing
the implementation so for instance we
asked for at the query a list of
speakers and we have a route which is
essentially looking at what is the the
thing the node that potentially called
this resolver we have arguments we have
context most of the the reference
implementations of graph QL will have
some kind of format like this context
could pass through things like
authorization or your users in the
system and then you can propagate those
down through the graph tree so this is a
really simple implementation we have a
speaker service some kind of library or
something in our code that is aware of
how to go fetch from our data sources
these speakers or these talks or things
like that now what's more interesting
you'll notice back here we were at the
query route if we want to navigate
further down we have the speaker type
right so a speaker has a list of talks
and how do we know how to resolve talks
for a particular speaker you can kind of
do a very similar thing as we did on the
query route but more importantly if you
look when we look at the route the route
at this point essentially becomes the
actual speaker node that has returned
back from our data our data sets our
data resolvers and we have a list of
talk ids and so our speaker type says
for talks this is how you resolve a talk
field which we know is a list of talks
and we pass in those talk IDs and load
by those so essentially you end up
modeling your entire graph QL execution
and an engine in somewhat of this this
pattern but the really important part is
that code that I showed is is very
similar to what we actually do for graph
QL wrappers in in production systems the
important part being that graph 0 is
definitely not your business logic layer
we're going to look at some interesting
approaches later on where you can wrap
various data sources and things like
that but your business logic should not
live in your graph QL Engineering
lair should be as thin as possible on
top of those other services or those
other fetchers of your data and your
other business logic so another really
exciting part is that you get just by
using graph dwell and that schema
definition is the developer and client
experience is really quite elegant your
developers for instance if they were
asking for the the speakers could simply
say I just want a list of speakers and
only their first name I don't want
anything else out about them and that is
all that they will ever get back and
it's an elegant way for providing an
efficient interface for making those
network requests for traversing that
tree down deeper also there's there's
this kind of limited API version and
concerns where I can as a provider of a
graphical endpoint add additional types
add additional nodes add additional
fields for people to be able to query
against as my product grows and the
demand grows and people have different
expectations of the system I can keep
adding on and extending without
impacting existing clients in any way
their request phone change now obviously
you have to be careful you can't just
completely remove a field you can't
change how a field works but as long as
you're being careful about that you can
easily add things without impacting
anyone else or sending them a bunch of
data that they're not expecting for
instance if API introspection since this
is a completely typed API it's really
easy to essentially introspect on the
API and learn about it just by playing
with it and issuing essentially kind of
like introspection queries against the
actual engine itself so what this
actually looks like there's some tools
out there once called graphical this is
what it looks like and any graph QL API
that exposes the introspection
capabilities can do this right so you
automatically get for instance a
documentation Explorer built in you can
navigate through and quickly search this
because you understand the queries that
are possible the mutations that are
possible all of the types that are
possible you can get autocomplete on the
fields for free I can go point this to
prac
any graph QL API and this stuff will
just work
it's actually really incredible and
really compelling to have people be able
to just like point in this kind of
utility at your API and just explore it
and learn by playing with it so that's
graphed Y well I wanna talk about
service first of all I want to apologize
for the name service I'm not personally
responsible for it but there's been a
lot of complaints if you ever look on
Hacker News it's hilarious like half of
it is complaining about how the server
but I still have servers so sorry about
the name it's like this massively
overloaded term to the point that is
getting pretty useless it's kind of
become too mean anything that's a
function that's using functions as a
unit of deployment people I really enjoy
this this actually just happened like
two days ago someone released a new
server list platform and the first thing
they do is like go spin up a server put
the thing on it you missed the whole
point guys so more importantly what what
server list kind of means for myself for
our company for our clients is that
obviously you still run on servers
everything runs on servers you just
don't care
you don't have to worry about operating
system patching you don't have to worry
about the server maintenance you don't
have to worry if this server dies is my
auto scaling group going to to heal or
self heal you you don't have to care
about that you just simply care that
I've given my code to somebody I've told
it what kind of offense it accepts or
what kind of requests it accepts and
they'll handle all of the mapping and
scaling and making sure that my code
actually responds to those requests
right so my responsibility as a
developer or even as an infrastructure
ops person really moves higher up this
stack right can I spend more time
looking at our code and building better
tracing in our code can I figure out
what our data sources are doing better I
can do that instead of worrying about
you know is Ubuntu up-to-date for
instance kind of the second core tenant
of server
is building at the the microsecond
increments you never pay for IO right so
this is um for those game companies out
there this is like micro payments and
transactions done right I want to pay at
the hundred millisecond scale for
instance not at the the minute scale
even the hours to get or anything like
that
so this pairs really really well with
event-driven models as well we're not
going to talk a whole lot about that
today but if you ever get a chance
really try to dig in and understand how
do I stream events into something like
service and why is it so powerful right
it's it's this capability of having
these massively scalable systems and you
really just don't have to worry about a
whole lot of the scaling that you
normally would have to so right many of
those complexities of scaling and
availability are absolutely gone some
other kind of hidden benefits that you
start to realize as you build more with
serverless infrastructures and start
really diving in is that you get these
like massive total cost of ownership
drops when you aren't worrying about the
underlying servers or infrastructure or
things like that when your systems scale
simply by what I like to say just like
turning up a dial and saying I will
input more dollars and get get out more
scale and without having to do anything
else
it really works quite elegantly we have
one client that I can give you an idea
for scale that does millions and
millions and millions and millions of
requests a month and their compute bill
is like 50 bucks a month and we're
storing hundreds of millions of images
so their storage cost is like thousands
of dollars a month and their compute
cost is like literally $50 like people
just don't understand it if we were
trying to run servers to do all that it
would be way more expensive so with all
these TCO games and economics you can
really focus on the higher value targets
in your organization your ops teams can
say you know what how can we take what
this service is doing and operationalize
it in such a way that we're providing
for instance a better event stream or
data stream to other parts of our
business to other clients in our
business you can focus on those higher
value target
also an interesting thing is that you
can fail fast and learn things really
fast and we do that you can do it for
almost free
you can go build a surveillance system a
practice I like to do with some of our
clients is go and say hey what's like
something that's really challenging that
you have to solve like in the next week
that someone's ask you to solve right
can we take the next 4 hours and do an
MVP of that and launch it and have it
working inside of the next four hours
and sometimes it works sometimes it
doesn't but the key is we found out
inside if like one business day if we
have like a viable approach or if it's
totally gonna fail so we fail fast
through practically free and we learn
really fast so some developer hints as
you're starting to work on these systems
and start looking at service your
functions as a service provider whether
it's lamda or a juror or Google compute
or anyone is really irrelevant something
I've seen recently is that people are
starting to complain that don't use
lamda it's vendor lock-in don't use
Azure its vendor locking you're gonna be
as stuck in their event model that's not
true right so you can abstract away
whatever they're doing in terms of how
they're getting you the events fairly
easily there's actually utilities out
there and people out there that kind of
provide these wrappers and you can like
scale across these different clouds now
what is true and is the case is that
people like AWS people like Microsoft
people like Google are providing other
really really compelling services that
tie really closely to their functions as
a service whether it's lambda or
whatever and once you start leveraging
those particular services now you have
vendor lock-in that's their plan right
that's what they're gonna get you that
said for us in our clients we're totally
for it because Amazon obviously builds
really fantastic utilities sure is
coming out with really cool stuff
durable function
with affinity streams and things like
that you can do really cool things and
you just have to evaluate and say is
this platform going to provide more
value than I can build myself if so you
know tie yourself to it functions as a
service itself lambda things like that
they're not a vendor lock-in risk really
all right so we've talked about service
we've talked about graph qo what happens
when we put these two things together
what does it actually look at so right
off the bat we can obviously assume that
we're gonna get all the normal server
list wins right we're gonna scalability
availability I don't have to worry about
the operating system I don't have to
worry about patching all of those great
great benefits now you also get all of
the benefits of graph QL for instance
clients and the graphical and things
like that and all of that type API
goodness and those systems you get all
of that as well now what's really cool
is that this is very much a one plus one
equals three scenario where I get
something that's actually higher value
than just the two components separately
because I can mitigate things like
resource exhaustion attacks which we're
going to look at I can do really complex
resolvers and do interesting things
based on service giving me isolated
resources and execution environments so
resource exhaustion attacks is actually
something that's that's that's fun that
I didn't really think about or
understand it till one day I was like
hey why is like our system not working
like why are these requests hammering or
our Dynamo table so hard like I thought
they were supposed to be serviced and
dynamos like this magical thing why is
our system like coming to a crawl well
resource exhaustion attacks you could
kind of think about them as a denial of
service attack that's a really easy to
do against yourself in some
circumstances not good be really really
easy for an attacker to hurt you really
badly with
minimal input from their side so a
resource exhaustion attack is
essentially this idea of a really deeply
nested request you can use recursion or
things like that
pagination abuse we're gonna look at an
example in a little bit but we're also
going to talk about some useful
optimization and bike prevention
techniques so github I don't know if
you've seen their graph QL API they
actually approach this by enabling
pagination and enforcing pagination and
limits on any kind of node request for
instance most types you have to say I
want up to a hundred of this particular
node and they won't give you any more
than that and then you also have to go
through the pagination as well you can
do things like maximum death checking so
if you think about a graph and like
traversing that graph you could say for
instance that anything that has a nested
graph of deeper than five nest we're
gonna throw it out obviously never run
it and they were also going to look at
another just huge performance win which
is request batching and caching so
resource exhaustion attacks this is kind
of what it looks like so for instance
there's a Star Wars API out there I
don't know if any of you are aware of it
there's a graph QL wrapper for that Star
Wars API but right here what we're
essentially modeling is the concept of
films and characters and Star Wars so
say we want to list out all of the films
and then we will know all of the
characters in each film that's a pretty
simple graph QL requests this is
actually using the relay specification
which you have to have edges in node in
relay you can simplify some of this
stuff following the release back is not
a terrible idea it helps make your
request easier but you can kind of see
if you just look down a couple levels
you see okay I have all the films and
all of the characters right now say
someone at your job decides hey you know
what I actually want I want to know all
of the films that each character is
actually into and I don't know about
maps introduces so I'm just gonna add it
to my request here so I'm gonna
drove the films for every character well
okay you can do that it's not great but
eventually it'll still resolve it we're
three three levels deep now
some enterprising individual or just
mean person decides hey you know what I
actually want I want all of the
characters of every film for every
character in each of the films of each
of the characters and brought a memory
right our memory can actually get blown
up in these requests especially in a
server model someone making one of these
requests you can just eat an entire CPU
core eat a ton of memory especially if
you haven't put a lot of thought into
how do I protect against this particular
attack so this is an interesting attack
model but when we apply this service
model I tend to be somewhat lazy is
saying okay what's like the 80% solution
I can get away with I don't know if this
product was going to make it for
instance I don't want to implement all
of these extra protections I don't want
to have to enforce limits or paginations
or artificially limit my clients in any
way before I need to so when I apply the
service model the graphic well there's
there's some interesting things I can do
right so if you look at service the idea
is each request is isolated in its own
running container or lambda function or
what have you and since each graph QL
execution each request goes to its own
lambda function it gets its own
resources it gets its own 128 megabytes
or gigabytes and CPU I instantly one
don't have to worry about someone
attacking my endpoint and like
completely destroying my one server
which now blocks everybody else they're
just destroying one lambda function
which was there's assigned to their
request so I don't have to worry about
it
and then also interestingly the other
thing you can do is the infrastructure
on most of the the functions as a
service providers give you this idea of
timeouts right so instead of even having
to look at the maximum depth of a graph
because it might be valid use cases
where I have a really deep graph what I
can do instead I say hey any request
that should normally succeed
in let's say five seconds or 10 seconds
all of my valid requests at the high end
or 10 seconds right so let's just say
instead of that all of our requests that
are coming into our system let's just
limit and say if this goes for 15 or 20
seconds whatever they're doing is
probably bad and we're just gonna throw
them out of our system obviously what
monitoring and alerting around that kind
of thing if that starts becoming more
common but you get an 80% solution for
basically one little configuration
change in your system obviously in the
server list model and people also like
to call it server full or service
service full I should say not server
full service full meaning that you
should totally leverage other products
and services that are out there like web
application firewalls right if you can
have someone else just handle like a
normal Doss attack lots of IP lots of
people coming and hitting you from a
single IP address certainly throttle
it's like leverage those normal
mitigations of those attack vectors
request batching and caching this is
this is a little more complex and and
and takes some some reasoning about I do
want to point out so there's this query
that we have here where we're saying
give me all of the speakers and give me
all of their first names and then give
me all of their talks and the title of
their talk and then actually give me all
of the speakers of each of the talks so
this is totally not an optimal query
from the graph QL standpoint but it
helps us illustrate a couple interesting
things if you start thinking about
caching and batching so if we were to
just do naive implementation and for
every time we try to run one of these
resolvers thinking back to kind of the
beginning when I was talking about the
resolvers in graph QL and kind of those
services and resolving by IDs from our
data stores if you had this just
strictly naive implementation and we ran
this query where we said hey okay give
me a list of all the speakers then give
me all the talks of the information for
each talk for
each of those speakers and then actually
give me each of the speakers for each of
those talks that are resolving you end
up with something like 359 metric
requests if you just resolve each of
those singularly so right so from the
front end the n plus one problem is gone
from the back end you're absolutely
destroying any of your downstream
systems if we implement cash-only
approach which essentially says all
right I'm going to ask for all of the
speakers and then I'm still gonna have
to resolve all of the talks as I haven't
resolved those yet but now I'm gonna ask
for all of the speakers again if I store
each of those speakers from the first
time that I requested them and my system
is smart enough I really only have a
hundred in 32 requests or something
something like that because I asked for
all of the speakers and then all the
talk so that's that's that's a hundred
and thirty-two actually has a hundred
thirty-two I think and then when I asked
me to the speakers again I've already
got them cached I don't have to do more
Network requests batching is where you
essentially say instead of immediately
firing every single one of my requests
whenever my system decides it needs to
ask for the talk data or for speaker
data you essentially can do things like
tap into the node event loop or in other
languages there's other constructs and
batch up and say you know what instead
of asking for them individually I'm
gonna ask for them all at once at that
level so that actually gets you down to
three here three requests because you
asked for all the speakers and then we
batch up and ask for all the talks then
we asked for all of the speakers again
notice we're not cashing in this this is
bachelor only we batch up all of the
speakers that we need requests so we
have three requests now if you implement
cash and batching that's your optimal
point right we asked for all of the
speakers from our systems we get all of
those we batch and ask for all the talks
in our systems we get all of those then
we ask for all the speakers which are
batched again we actually have them all
existing in cash so we're down to two
requests the important part about this
is this is really really hard to do if
you ask your developers to do it they're
gonna make a mistake and make things
worse Facebook actually realized this as
they were building out
craftwell and they released a project
called data loader which is essentially
a reference implementation for nodejs
and how to effectively do kind of this
caching and batching technique in a way
that still looks like a normal
implementation of just asking for
something from your data source in a
one-off like I want this ID I want this
ID but what it'll do on the back end is
actually batch this up into a single
request with caching and things like
that all right so once we start looking
deeper into server list we come and
graft well we come inside ZF hey what if
our actual resolvers are doing different
things right you can actually unify
different data sources for instance I
have one graph QL endpoint and I'm gonna
go say hey you know what I want to hit a
legacy API system I want to hit a
relational database system and I want to
hit a no sequel system right you can
actually do interesting things in your
resolvers where for instance I had like
the talk service in the speaker service
this could exist in two completely
different endpoints one could be in our
user management system or user database
in the relational database and our talks
for instance might actually be in a no
sequel database your graph QL endpoint
itself that's running in a service
function or things like that could
actually talk to other smaller micro
services running in their own lambda
functions and go have those actually
fetch your data where this gets really
interesting is for systems that you
might have more compute heavy operations
that have to happen and you want to spin
those off into their own lambda
functions and not have to worry about
blowing out all of the resources in your
single lambda function or your single
function execution but you want those
systems to still operate quickly and
efficiently and have more resources than
just the one so this is this is an
interesting approach it becomes more
interesting with something else we're
going to talk about in a little bit but
this is certainly a valid approach now
one thing I do have to bring up so
there's still these problems in the
service world that we're all trying to
solve and that problem is traceability
and debug ability
I don't know if any of you have worked
it with the server life space or
anything like that
but it's actually ridiculously hard to
even just get like simple information
out of these systems let alone do
something like this where my one request
might blow out across three or five or
ten or a dozen more executions and then
try to figure out okay someone executed
a request asking for something and then
I have no idea where it went
this is actively being worked on by all
of the big providers this is a really
hard problem but just know that you're
going to sacrifice what you're normally
used to in in a server environment in
terms of debug ability and traceability
to go for an approach like this it takes
a lot of work and instrumentation it's
like essentially distributed tracing on
a whole nother scale okay so I kind of
alluded to another approach with complex
resolvers and multiple data sources but
there's this new and and opportunity in
graph QL and kind of this growing
movement for something called schema
stitching so the folks at Apollo who are
doing a lot for the graph QL community
essentially developed this idea of you
know what I have all of these potential
graph QL api's these graphical endpoints
why can't I do something to put them all
behind one particular endpoint right so
in this case for instance we have two
graph QL api's they're completely
distinct from one another we have
essentially there's a universe API where
you can actually ask for details about
particular events that are going on
particular locations or things like that
and we have a weather API right where I
can ask for at a particular location
what is the weather look like or what
will it look like at a certain point in
time what's the what's the forecast so
obviously there's there's a connection
between these two you know I would like
to have the weather at the location of a
particular event so we can scheme a
stitch these two api's together and we
might get something that looks like this
now this is obviously kind of a naive
implementation right because when I
asked for it I'm saying hey I want an
event of some ID that I somehow found
whether it's all off some other listing
or things like that is irrelevant but
I'm asking for the events in this query
now I'm also asking for hey somehow I
happen to know that the location for
this event is in San Francisco so I
actually want the weather for that
particular location as well right so
this is ok great we get like one less
call we kind of have a unified API it's
not optimal and it's you kind of need
knowledge ahead of time from the client
side so we can obviously do better
so what schema stitching what we're
working on and what people are working
on is this idea that I can create these
systems independent of one another and
then create and name my resolvers in
such a way that I can resolve from one
type in one schema of graph QL to
another type in another schema in Agra
nother graph QL endpoint so essentially
once I link these two things together
and the engine understands how to
resolve across them with these remote
executable schemas is what they're
called I can do something that's way way
more compelling if we look at this now I
have to do is say hey I want the
information for an event of a particular
ID is irrelevant I want the title the
venue but more importantly at the
location for this event I want the
weather that's going to be happening at
this particular event right so suddenly
we've gone through something where you
have to have kind of this preconceived
information about where this events
gonna happen before I knew where the
events gonna happen and so making that
request was really hard in the first
place now it's become this system where
your developer the person using your
stitched schema doesn't even have to
know that there's two schemas they don't
have to know that there's two endpoints
behind this so this gets actually really
really interesting but what I'm really
excited about this for is now I can kind
of take the typical practices and
learnings for micro services and apply
them to graph QL now I can have people
experiment really quickly and build new
services really quickly in graph QL
and provide these small chunks of
functionality and in doing so in using
graphical in in building the schemas I
create these really essentially
standardized contracts for integrating
together these various services through
graphic UL what we're starting to do and
they're starting to work with folks on
is how do we enable business units to
produce things in graph QL in such a way
that it's valuable to them internally
it's valuable for them to consume their
own services but present them in such a
way that other part departments other
business units can look at these things
say hey you know what your your your
weather surface is great it would match
really well with my boat rental service
right these distinct operations can
start pulling and stitching these things
together forming entirely new products
extending products in ways that would
traditionally not be very easy and then
presenting them to end clients in these
seamless patterns so that'll said it's
really exciting it's it's still a super
new space we're still trying to figure
things out so there's there's some words
of warning that I would like to give all
of you before you go running back so my
first word of advice and I've learned
this the hard way way is that don't be
this guy I've tried to go to companies
and say hey you know what graph QL like
literally everything your life will be
amazing and then they're like what do
you mean REST API is we're still using
soap so yeah if you try to do this kind
of thing it's it ends up being a lot
more difficult than you would expect it
gets really hard um so obviously don't
don't force it where I would not suggest
doing this kind of thing and trying to
implement this it's a lot of this is
common knowledge right if you have like
non-problem legacy systems that are
rarely used and you have no problems
with them whatsoever don't don't try to
graph don't try to rewrite it in
graphical I should say
it's also not great for big data exports
like a REST API right you don't want to
like send like gigs or even tons of
Meg's of data through it now async
returns are fine right that's a common
practice I want to get a report of
something I get back a URL or something
that I can get a check and eventually
get my data that's fine
more importantly like any new technology
internal bayan is its key if you have
inertia against you if people are
building on rest and you actually have a
solid micro-service infrastructure on
rest there with side cars or things like
that yeah you're gonna have some
momentum against you there and so don't
force it start small like start in your
internal teams maybe get some of those
small wins internally and evangelize
based on their successes
now when it does come to non-problem and
rarely use legacy systems or you have
other services that you depend on other
folks that you depend on and their
services you can do some fun stuff where
you can essentially wrap there rest api
are there soap API or their system with
graph QL yourself internally and simply
consume it with those graph your own
kind of graph QL wrapper around it
and in that way you can kind of like
just be sneaky about it and they don't
really have to know that you're doing
that but then your actual developers on
your team can consume it in a more
usable pattern you can kind of start
sharing that out with other units like
hey I kind of made their service you
know not not be terrible to work with
you can be sneaky about it now if you do
do something like that or you have other
downstream dependencies you have to be a
good citizen of your business whether
it's it's service or graph QL or service
graph QL you're really only as strong as
your weakest resource right so if you
have a typical relational or sequel
database behind your your service graph
QL engine your server list stuff can
massively out scale any kind of
relational database you can we've we've
had situations where we turned on a
server service and we're getting 10,000
requests per second we don't flinch
because the server list whatever it's
fine
now if we had had particular
relational databases behind it or things
that don't scale as well obviously we're
in trouble because we're only as strong
as that one weakest resource if you are
playing with other folks play nice
things like queues caching all of that
good stuff you might have to put a
little bit more thought in a saying I
need to be nice to folks I don't want to
overrun those downstream systems people
won't appreciate it
they won't be happy for you that you
have this massively scalable system that
can take down there they tend to not
appreciate that some things that I
didn't talk about a whole lot it's kind
of some of that some of the basic stuff
and this is stuff that actually while I
say it's basics becomes interesting to
solve how do I actually pass
authorization down through my various
graph QL endpoints right so there's like
this idea of a context in graphic QL
that I talked about and the
implementations are kind of different
between the language and reference
implementations and it differs between
even organizations whether you're using
something a JWT or other token
approaches or things like that it really
depends on kind of the organization and
how you've decided to approach that so
pagination is not a completely solved
problem there's the relay spec which is
a Facebook spec for how they handle
pagination through graph QL schemas and
gateways and then good documentation so
this is actually really important when
you start playing the the game of having
lots of like essentially micro-service
graph QL endpoints yes you can have
graph QL kind of spit out this nice like
auto complete documentation searchable
documentation but it ends up being that
people want better examples so like okay
so what's the actual right way to make
this request for all of these speakers
and talks right you want to provide ways
that people can just go and kind of
browse I'd say best practices or best
implementations so if you want to get
started all this stuff there's a few
great resources and utilities out there
dan Schafer someone that's worked very
hard on the graphic girl stuff he
doesn't he's part of Facebook he
actually talks about pagination and auth
and and some really interesting
approaches you can look that up on
YouTube dan Schaefer
the apollo stack they're a great group
of guys doing some really interesting
stuff with graphic UL providing actually
metrics on graph QL engines providing
really awesome clients that have like
built-in client-side caching and schema
stitching
Graciela schema cheat sheet go look that
up if you really want to understand the
api and and and the types and things
like that quickly there's a service
framework so service comm graph QL
boilerplate which essentially gives you
kind of a look at here's how to build a
graph QL engine on AWS with things like
DynamoDB and lambda things like that and
then graph cool is actually a cool
implementation of this kind of hybrid
approach between functions as a service
and graph QL and I would say if you were
to start anywhere go look at this what
they're doing is this idea that your
resolvers and custom resolvers in in
graph QL should by default be kind of
like this hybrid approach where you can
directly map to a function execution
they kind of take the complexity out of
there's multi targeted resolvers and
things like that and say you know what
like your resolver if its customers
gonna want to have a function behind it
and so they provide kind of a DSL for
defining what a a server list graph QL
implementation could look like so with
that said thank you I hope you learned
something and it was certainly fun for
me and go play with server lists and
graph QL</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>