<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Application Deployment: State of the Onion | Coder Coacher - Coaching Coders</title><meta content="Application Deployment: State of the Onion - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Application Deployment: State of the Onion</b></h2><h5 class="post__date">2014-07-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cqxyefS7Las" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright welcome hope everyone had some
lovely pizza and thank you again to de
grace and everyone else here so my first
talk tonight is the application
deployment state of the onion so first
just a quick bit about me so like gray
said I giving a little bit feedback
there I do operations and server
management for the Python Software
Foundation and I helped organize pikkon
I currently work for balance payments I
work a lot on chef and I really like
making things so let's move right along
to talk about application platforms so
really we're talking about deploying
applications we're talking about is
building application platforms so what
goes into an application platform five
main components database web server the
application code itself and then
configuration orchestration there's no
other parts i'll cover later but those
five are really the biggest moving
pieces in any application platform i
will do my best to illustrate the
differences between the various tools
trade-offs and whatnot but this is not
an opinion to talk these are my views on
what tools are good for deploying
applications caveat emptor so to begin
application code usually the first thing
you have to deal with when you're
deploying an app is getting the code
onto the server so we needed a
transportation mechanism something to
get the code from point A to point B so
the earliest of these is talk tar has
been around forever it is the ancestor
of every major deployment system you
probably already have it on every
machine you've ever touched it's very
very simple to use you take code on your
machine you make a tarball you transfer
that somewhere you unpack it and bam the
code is on the machine it's really all
there is to it but it is pretty
repetitive it's very easy to make
mistakes you should really write some
scripts wrapping this sort of tar
workflow copying the files around make
sure that everything is in sync and if
if synchronization sounds like a good
thing there's our sake our sink is also
probably installed on every machine
you've ever touched
it copies the files from your machine to
the target but whereas tar requires
copying the files over and over our sink
does it in a much more efficient fashion
you can also set it to exclude certain
files stuff like that so those are push
based systems copying it straight from
your laptop to a target server get is an
example usually of a pull system so you
push your code from your laptop to a get
server and then you pull from the git
server onto the target application
machine it does also use an efficient
binary protocol and if you're already
using it for your source code management
itself it's very very easy to use for
deployment it means that there's a
single point of truth of what is the
current version of the software that
lives in one place as opposed to using
something like tar our sink where can
live in multiple places and those can
easily fall out of sync packages are
another pull based option so again you
have a central server usually this case
a package repository of some kind either
yum repository an apt repository and
again you're you're pushing it from a
build server into the package repository
and you know then pulling that onto the
target machines this is somewhat nicer
than get in some cases because the
server can be a lot simpler running a
git server mercurial server or something
like that requires a fair bit of
complexity and that's not always
something you want in your deployment
pipeline if things go wrong they usually
go very very wrong I see JJ glaring at
me about this whereas package servers is
usually just simple web server and
nothing more so fewer moving pieces can
be pretty nice there's a lot of very
solid tooling around working with
packages like apt and yum whereas a lot
of other stuff like manual tarball
deployment you're gonna have to write
all those tools yourself and the
repositories themselves there's
efficient tools for managing those and a
quick shout-out on the packaging side to
a tool called omnibus it's a very nice
way of building packages so if you want
to build a package on a CI build slave
and then ship it up to a package
repository how many of us lets you build
standalone packages that do not depend
on anything on the system so you have to
worry about changing system dependencies
and things like that my current
recommendation for how to deploy
applications is Omni bus built packages
a nice big package repository so that
cover is getting the application code on
machine so then we need to deal with
configuration management so what does
configuration management I mean this
very literally managing the actual
configuration of the software not the
somewhat more buzzword friendly way it's
applied to somewhat more fanciful tools
so we have to provide our application
with some kind of settings file in
almost all cases so how we can do that
simplest way flat files check them into
source control they live as part of the
source code this is really really simple
they are properly versioned they're very
readable it's also super inflexible it
means that if things change you need to
deploy a new version of your software
and that's not usually a great thing if
say your database server goes down so i
would highly recommend looking into one
of these other tools full disclosure
like i said i do a lot of work with chef
so i will talk about that one probably a
little bit more depth but all of them
are good options so chef Ruby based it
is a declarative ish system it's it's
not fully declarative but it's mostly
declarative has a very big ecosystem of
tools around it and is a great way to
write out config files puppet uses a
custom dsl instead of Ruby and it's
fully declarative instead bo than that
generally similar to chef one problem
you can have though is that it doesn't
scale quite as well as chef does so if
you have more than 50 or 100 servers
puppet can get to be a bit of a
management headache saltstack newer than
chef and puppet but still relatively
well established it uses yeah Mel and
ginger and its community is an ecosystem
smaller than chef or puppet but growing
quite nicely it is somewhat nice to be
written in Python but I would ask you
please do not pick your tools based on
what language they are written in and
finally ansible another great option for
writing a config files again it uses
gamelan jinja it is very very new
compared to all of the others it has
some interesting bits like an agentless
model you don't have to actually install
anything on the target machine but
that's not used super commonly at scale
so while it's cute for you know under
five servers or for small personal
projects in in actual production deploys
it ends up looking very very similar to
the other three it's also because it's
so new it has the smallest ecosystem of
all of them but I think as of last month
it is the third
roaring project on github so to say it's
growing very quickly would be an
understatement so watch ansible but
check out all four of them so that's
talking about writing config files what
are a few other things that you should
maybe think about having your config
management system deal with so stuff
like creating user and group accounts on
the system for the application to run as
and installing service files those three
things config files users and services
are really the most important to manage
via some kind of config management tool
beware of overusing config management
tools for example it is very nice to
sometimes use your config management
tool to deploy application code but
sometimes that can get turned into a
pretty serious headache don't worry too
much about having those be separate
systems do whatever works for your
workflow and your team's workflow so on
to orchestration chances are you'll have
more than one server so you need to do
things on different machines make sure
they happen in the right order that's an
orchestration tool they provide a way to
run things usually shell commands on
multiple machines in the correct order
gather the output make sure that all of
the commands are succeeding things like
that so this is very useful for either
executing the config management tool if
they don't ship their own orchestration
system as well as managing code
deployments if that's not already being
handled by your config management system
simple as possible orchestration system
SSH and a for loop super simple most
people who have done application
deployments have done this at least once
this is the current official solution
with chef it's also exactly as bad as
you would imagine it to be super
inflexible you can only process one loop
at a time and if anything fails you have
to make sure you're doing all the
failure handling on your own you can't
do things like well say if you know 75%
of them succeeded then you should
continue stuff like that head of it
starts to matter because if you're
deploying on to 500 machines all 500
never exceed it will never ever happen
so having the flexibility to be able to
account for that kind of failure rate at
large scale does matter but when you're
getting started a station of for loop
not the worst option on the planet the
next one that people usually play with
at least the people in this room will be
fabric so it's written in Python it lets
you write tasks
in a python-based not quite a DSL it's a
set of helpers and tools for Python to
write you know things that should run on
remote systems you can say what order
they run in you should say where they
should run things like that you get to
write these tasks in Python code can
also as an advantage over ass agent for
loop it can run tasks in parallel across
multiple machines which is quite nice if
you have a longer complicated deploy
process and you want to be running it on
all of your machines at the same time
and it allows you to do multi-tier
deployments once you start playing with
things like the execute helpers so
ansible also ships their own
orchestration tool it does allow running
at hot shell commands and it's it's
hooked into their node catalog system
but you don't necessarily need to use it
with ansible you can just use it to run
arbitrary commands machine so actually
know people that are using ansible to
run chef happens not super common but it
can be done it also offers a thing
called accelerated mode which allows you
to run multiple tasks multiplex to their
single ssh connection which can be a lot
faster than fabric in certain cases some
only salt also ships their own
orchestration system so I'm like the
previous two which were based around SSH
saltstack actually uses a custom zeromq
based framework so it does require you
to use the salt minion master system but
if you are already using that or you
just don't mind installing that anyway
it does offer a much lower overhead
system as compared to ssh just the raw
computational overhead of running a
hundred or a thousand parallel SH
connections can get to be pretty
significant but again only really
matters if you have a hundred or a
thousand machines which I certainly
don't and most of you probably don't
either so don't worry too much about
that one thing to know about the
saltstack system it doesn't really allow
ad hoc command execution kind of but
it's really built to be running pieces
of salt configuration and then M
collective is the last of the bundled
ones so this is part of puppet like the
salt stack one it uses a message queue
internally in this case uses mqp so
either RabbitMQ activemq generally it
does again offer some ad hoc command
support but it's pretty limited it's
really designed for
us running puppet but nicely this one
does offer live discovery so it has a
built-in no discovery system as part of
the orchestration layer you don't need
to provide it with a list of your
servers it will figure out who is
listening and use that as a list of
servers and finally on the orchestration
tools is run dank so whereas the rest of
these have pretty much all been you run
a command line tool on your laptop and
then stuff happens somewhere on the
servers run deck is a centralized API
service so it's very similar to Jenkins
in that you create jobs in it and then
you can execute jobs it captures the
output but unlike Jenkins this is really
built for mode orchestration so it
understands the concept of running jobs
on multiple machines running jobs in
parallel things like that the advantage
of run deck over something like fabric
or all the other ones I mentioned is
that it puts everything into a single
centralized location that means that you
can see who's run what jobs is there
currently deployed pending and who
started that what things have been
failing what their output was so it
means if somebody kicks off a deploy and
it fails halfway through and they
already left for the day you can
actually see what's going on that is
really really useful and just in general
lets you sort of encode all of the work
flow into coat into actual usable code
instead of having a readme with if you
want to do X run fabric task Y which
isn't bad but it is nice to have have
that all in a single place with a pretty
interface and then it's not really a
specific tool but a brief mention of the
idea of chat ops cubot is a tool and is
probably the most popular of the the
current generation of chat ops tools
this is the general idea of taking all
the stuff I just mentioned about
centralized workflow and having sort of
encoded work flows into services and put
that into your corporate chat room most
people use things like hip chatter or
sometimes now slack possibly IRC but
most companies will have this sort of
general chat room for just employee
conversations and having all of your
operations management stuff in there is
really really nice it makes it a lot
easier for non-technical people to
interact with the tools and it means
that the team gets automatic visibility
so if somebody kicks off a deploy by
saying it in a public chat room everyone
can see that that happened everyone can
see that it was initiated
you can see the result that is very very
important when you have a lot of deploys
flying around so chat ops is definitely
not what I would say is common I think
it should be though and I think everyone
should pay attention to this at least
and consider it would be right for your
organization sups orchestration tools
now let's talk about databases so while
your application servers can hopefully
be stateless and not really have too
much information stored on those servers
themselves the database is not so lucky
that's what contains all the state
stored information for all of your
applications sometimes it will be things
like user accounts sometimes will be
page data or just any other business
specific information in most cases your
application will need to be able to
reach database server to work correctly
I'll be at some form of degradation is
sometimes possible so the the
availability and performance of your
database is one of the largest source of
yak shaves in the operations world so to
kick it off the probably the most
popular database in the Python world is
postgres most of you have probably
played with it at least once it's
relational use a sequel offers all kinds
of nice acid ebenefits and it has add
ons glory thing from json types to GIS
database storage anything you can really
think of in the database world somebody
has probably tried it with postgres so
one of the big problems with postgres
though is because it is a relational
database that means that it is single
master for the most part there are some
multi-master replication systems
available for it but they're pretty rare
and they're still pretty error-prone so
for the most part you will be bounded on
availability by the availability of this
one master database for writing anyway
and we can't really talk about
post-grant so that at least mentioning
my sequel a very polarizing topic
basically everything that I said about
post grafts applies with the exception
that their idea of acid is a little bit
less acid II so somewhat somewhat less
transactional than postgres notably ddl
changes so things like alter table means
if you ever get a crash during a schema
migration good luck you're restoring
from backup now so the biggest problem
with with my staple right now is that
since oracle took over from sun there
has been a lot of community
fragmentation Oracle's continuing to
manage the official my sequel project
but there have been several Forks
let off Maria DB is the biggest of the
community run Forks although drizzle is
starting to gain prominence mara is
actually now shipping in fedora linux as
the the primary my sequel version
there's also Percona which is offering a
commercial fork so they offer commercial
support and some additional features
over the standard my sequel between all
of those i can't really give you much
advice other than look at all of them
they all have very similar features but
they tend to play catch up with each
other so if one adds a feature the other
Forks generally will within a year but
any given time it can be a bit of a mess
so that's to remain relational databases
sequel lights notwithstanding but there
has been a growing trend to to lump a
lot of other databases together and
under the incredibly unhelpful name of
no sequel so the first of those that
people will usually encounter is Rattus
it's a key value store it runs
completely out of memory it has
effectively no solution for high
availability and it's really nice for
what it is if what you need is a a
slightly nicer memcache just storing a
little bit of transient data in memory
if it disappears you're okay with that
your application can cope with it all
vanishing at any time then Redis is
really cool it offers a lot of really
nice high-level constructs for an
insulating data but never ever use it as
a database ever cassandra is another
popular no sequel store it has
absolutely nothing to do with Redis in
any way shape or form it is a highly
distributed database so high
availability is part of it from day one
it uses a layout called big table which
is kinda similar to the way sequel works
in that you have the same idea of tables
with with rows and columns but instead
of them all living on one server those
tables are broken up and spread across
many different servers it uses something
called cql for running the queries which
does look very much like sequel so if
you just want something that's sort of
very warm and fuzzy and close to sequel
Sanders probably the right place to
start if you want high availability but
you don't want to quite dive completely
into the MapReduce world yet and on that
note react so again fully distributed
database came from the same origination
as
Sandra which was the old Amazon dynamo
paper nothing could do with the Amazon
dynamo product anymore but unlike
Cassandra react has gone much more
towards trying to actually let you model
data in a way that is truly highly
available so this means things like
mapreduce it means things like secondary
indexes it's really just a large key
value store so you have to actually
write your queries much more manually so
why would anyone ever do this the
advantage of react over cassandra is
that it exposes something called crd
tease that stands for commutative
replicated data type mostly some people
disagree on exactly what it stands for
but usually commuted replicated data
type it's kind of like get for your
database it lets you branch and merge
your data later this is really important
if you get random failures all over your
network which if you run in the cloud
you do all the time and it lets you then
after a failure you can merge the data
back together so using c or d DS is not
easy you will have to read a lot of
academic papers but if you really really
want one hundred percent availability
it's really the only game in town and a
couple of other databases that I can
mention briefly MongoDB the various
couches MongoDB is prized for its
simplicity and ease of use but
continually plagued by data loss and
performance issues couch not quite as
simple as Mongo and I've had a lot of
issues with its replication system but
it's still pretty simple to use as a
document abase none of them really offer
anything over Cassandra or react in my
opinion and between these three options
I would choose the third take that as
you will a quick shout-out to zookeeper
so zookeeper really isn't like the other
databases I mentioned it's it's a very
very slow database is designed for small
amounts of data specifically
configuration information the main thing
it has going for it is consistency so
whereas the others were designed for
high availability you can have your data
spread across many servers in many
different places so the data is not fit
in one place zookeeper is designed for
very small data that you want to be
consistent across your entire network
this is really useful for things like
who is the current postgres master
that's why it's called a configuration
database usually but really it's just a
database with another type of
replication
in this case a highly consistent one
using the paxos family of algorithms I
would definitely recommend checking it
out there's also at CD which is overall
relatively similar and now console from
hachey Corp but both of those are very
early on in development and then on to
web servers so web servers will perform
many functions in your application
platform the simplest and most important
is it opens a socket it listens for HTTP
requests and it sends those to your
application and then it sends back your
application response that is the heart
of any web app it also will often
responsible for sending out static
content and possibly other pieces of
middleware so apache is probably the
second oldest piece of software i've
mentioned today only after tar and it's
still going strong a lot of people just
count apache as bloated outdated a relic
of a former era but i think that's
generally unfair you do need to take a
lot of care when you're configuring its
performance settings and most of the
defaults configs coming from
distributions like Red Hat new bhuntu
are woefully out of date but it does
allow you to use mod whiskey which is an
excellent application container and will
let you then run your application and
your static file hosting from a single
system which is really really nice so
engine X is usually the next stop after
Apache also an excellent choice it uses
a slightly different internal
concurrency model and people will go
back and forth on performance metrics
between engine X and apache until they
are blue in the face unless you are
running Alexa top 100 website it really
really doesn't matter the performance of
your web server itself is not going to
be the blocking piece of performance in
your application so really just pick the
one that you like and stick with it
they're all good it does offer somewhat
simpler configuration than Apache does
and it's very very nice to use for
reverse proxies so what are you going to
reverse proxy to so while mod whiskey
allows you to run your application
within Apache itself and genetics
doesn't really offer that so you have to
do static file hosting from engine X and
then serve your application from a
dedicated app server and proxy to it so
the first of those is usually jewnicorn
it's written into your Python it's
really really simple to set up usually
one command and it's pretty fast it does
have to be run behind a proxy so you
can't just directly exposed unicore
the internet or you risk do s attacks
but it's very very simple and easy to
get going usg offers a lot more
application support integrates a lot of
service frameworks and things like that
it offers a nice binary protocol for the
reverse proxying with engine X but it's
much more complex to set up it is
written in C instead of in Python so you
do have to compile it and it's
unfortunately a victim of configuration
soup it has at least 100 different
config options most of which are pretty
poorly documented it is faster than
jewnicorn but exactly as I said between
Apache and engine X the performance
between those two really isn't going to
be the bottleneck in your application I
promise twisted and it's not
specifically a web server but it does
ship a very nice whiskey server inside
it it is extremely fast and the really
nice thing about using twisted is it
means you can mix your standard whiskey
web app along with non whiskey
asynchronous code this is really
important if you want to do something
like use web sockets or anything else
that doesn't sort of follow the standard
CGI model of web apps that we've been
using since I don't even know before I
was born probably so this also all
applies tornado although between those
two I've generally seen twisted used
more but neither of them are really used
all that much so unfortunately you will
not find the documentation quite as easy
as setting up engine exim jewnicorn and
you won't find nearly as many guides as
for the other tools but still worth
checking out if you're interested in
things like web sockets or server sent
events and finally CDNs not quite in the
same realm as the other web servers I
mentioned but they're definitely
something to be aware of the idea of a
CDN is that you take your content and
they instead of serving it directly from
your server they cash it in a bunch of
intermediary server spread all over the
world connected to really really fast
internet pipes this means that most of
your content for most users will be
coming directly from those cache servers
and generally go much faster for all of
them fastly is an excellent choice for
this and full disclosure they are a very
generous psf sponsor but if you already
use Amazon Cloud front is very easy to
great without amazon services and if you
want to do some level of caching but you
don't necessarily want to shell out the
big bucks for a full CDN you can look at
varnish which is actually what powers
fastly internally onward again to server
provisioning so now we have a pretty
good idea of the things that we need to
run we need somewhere to run them
in the simplest case this will be
physical hardware you will fill out a
purchase order for Dell or HP and you
will send them a very large check and
then you will wait six weeks and then
some machines will show up and you will
put your server you put your application
on those servers but most people aren't
going to do that both because physical
servers are increasingly a rarity and
just because it's very slow inexpensive
most people will be deploying on some
mix of public and private cloud systems
so we generally want to have some kind
of provisioning tool to control how we
create virtual machines and the other
virtual hardware used for modern
infrastructures simplest one of those
again purely manual you go on the web UI
or use a simple command-line client you
say boot me a server and then you wait
five minutes and the server appears and
it is lovely but this means that human
intervention is needed so it means if a
server fails on a weekend or if you get
the reddit hug of death at 4am you're
going to be unhappy if you use Amazon
already a slight step up for manual
prison is to use what's called auto
scaling groups they are relatively cool
80 you do have to buy into the Amazon
ecosystem to a large degree but they
offer pretty simple scaling so if you
already have one machine you can turn it
into n machines and they will scale up
linearly and then scale back down as
your load decreases you do have to drink
a lot of kool-aid it really is tightly
integrated into their ecosystem but it
is a lot of benefit for very little
effort but if that wasn't enough
kool-aid don't worry there's also cloud
formation whereas auto scaling groups
really only deal with provisioning the
ec2 instances the actual virtual
machines cloud formation allows you to
describe and create script to the
creation of your entire Amazon
infrastructure everything in Amazon can
be controlled through cloud formation
more or less but really really really
cool lady and it can be a bit fragile if
you change the state of something that
cloud formation thinks it's owning
collaboration doesn't hide any of the
API complexity to for you from you so if
you change things and cloud formation
doesn't know that cloud formation will
generally just break and there's nothing
you can do about it so incredibly
powerful but definitely fragile not a
whole lot I can say about heat heat is a
almost line for line port of class
for openstack so everything I've said it
just applies to OpenStack instead of
Amazon it does offer some limited
compatibility with the Amazon resources
but you should usually use the open
source the OpenStack specific ones
briefly mentioned RightScale it is
another option it offers a lot of very
nice benefits if you have a multi cloud
provider deployment so if you're
deploying on to multiple public clouds
or public and private cloud right scale
can be very interesting it also offers
tight integration with Chef although
their chef implementation has at times
lagged behind the main version of Chef
by years it's also very expensive and
because of that I've never used it so I
can't really speak to it much personally
and finally asgard a tool from netflix
so this is really built around
automating the creation of management of
auto scaling groups so it allows you to
manage auto Celyn groups as part of your
application deployment cycle every time
you want to deploy a new version rather
than changing existing auto scaling
group you create a new one and slowly
move traffic over to it if you want to
if you detect any any issues of the
deployer you want to switch back you
just switch the traffic back to the
original auto scaling groups
unfortunately hasn't really been used
outside of Netflix very much so it's
still rough around the edges and odd
places and then on to secrets management
so secrets management is the idea that
in most most of the configuration data
in your system can be public things like
the from address on your emails or the
port on your load balancer that you're
using no one really cares who knows that
information in some cases like the from
address everyone who is going to know it
it is by definition public but some
stuff needs to be secret for example
database passwords the most common case
for this but there are other things
things like your page duty API keys or
other integration keys you need to keep
them secret sometimes from the public
and sometimes even within the
organization so we don't necessarily
want to store these same way we do other
data so the biggest problem with storing
them the same way we do configuration is
that it's it's going to be insecure the
existing config management tools don't
really provide the kind of audit logging
kind of access controls that you would
really need to lockdown secret
information so the next step for a lot
of people is encryption encryption is
wonderful and secure and all that No so
just because it says encryption on it
doesn't mean you're actually getting
security so this is things
chef encrypted data bag is the ansible
vault system they do render the data as
an opaque blob but all they're really
doing is moving the problem around and
now you don't have to manage the
original secrets but you have to figure
out how to get the decryption keys on
all the machines and good luck with that
so I consider these to be unwise
structurally also some of them have in
the past had dangerously shoddy
implementations although fortunately I
think all of them are now fixed if
you're running on Amazon and you don't
mind even more vendor lock-in using the
AWS I am system combined with server
roles and a private s3 bucket gives you
a very very nice and secure system
unfortunately has a lot of moving pieces
and a lot of complexity so the idea is
you put your secrets as files in a
private s3 bucket and you use I am roles
to authorize specific servers to access
those unfortunately because the number
of moving pieces you will probably need
some kind of scripting to help you
manage this cloud formation is good at
that or you can write something yourself
using something like boto but it does
have a lot of moving pieces and it can
be a little unwieldy to manage but the
advantage is that it's somewhat provably
secure to whatever degree you trust that
I am will be safe and I have a lovely
PCI certification which says if it's not
they can't sue me so barbican is project
from the OpenStack world but it's not
really limited to use with OpenStack it
is a dedicated secret storage and
management system complete with acls
auditing all the lovely powerful
features you really want a secrets
management platform unfortunately it's
not actually finished so I don't think
you can even use it yet but I think it's
very promising as a potential way out of
this secrets quagmire and then Red
October Red October is a bit of a
different take so whereas all the other
systems are generally dealing with
encrypting stuff with a single key or
distributing unencrypted data to a bunch
of servers Red October is what's called
n of M management so this means that you
take a piece of secret data and you
encrypt it such that any n of M people
can access it so if you have five
operations engineers you give each of
them here this is your M you get five
and you get the MS five you give them
each a decryption key and it means you
can set it up so that anyone any to
whatever the end you want
is you can you can control who can
access stuff by virtue of how many
people you need this means that for
simple stuff you can set it to N equals
one where anyone can access it but for
high security stuff maybe it's three or
four where you need most of the company
to work together to agree to unlock this
data so what is this useful for whereas
the other ones were really for a sort of
online or hot storage where the data is
going to be accessed frequently without
human intervention Red October is really
built for cold or offline storage
secrets that need to be written down but
you're not really going to access very
often so an example is the master
password for an amazon account or the
recovery credentials for say your github
or page beauty account so it's stuff
that you may need at some point you do
need to write this down but you don't
really need to access it every day and
you probably want a little bit more
security than usual about it because if
somebody gets access to it they can
probably torpedo your company at least
for a while and then a few other things
that maybe you just want to think about
a little bit when your specking out an
application platform so with metrics you
are going to need some information with
the health of your application so
metrics are the tools let you judge
whether or not your application is
healthy so stats d is a buffering proxy
it sits between the rest of these metric
tools in your application so that you
don't have to deal with buffer overflows
or spinning up a background thread
within your app collecti is a another
metric statement it runs on all of your
machines and it spits data about the
servers up to a central collection point
and then graphite is very often that
central collection point it's a data
storage system and a graphing like a
graphics API so you can create nice
pretty graphs and see what's going on in
your system most people are still
managing log files by writing the file
out of the local machine and they SSH
around and they grep a bunch of files
everyone has done this at some point and
it's terrible so usually you want to try
to migrate through some kind of central
logging system log stash is a very
popular choice for this as is Splunk
Kabana is a UI for log stash so it gives
you a centralized place to search and
view your log files and splunk has a
built-in interface I would also highly
recommend looking at sentry specifically
for cure logs it handles only errors and
exceptions but it gives you a lot of
very nice tools to look at your error
rates and figure out if there's new
error is happening in your application
so now we know a lot of the components
complexity is building an application
platform and some of you are probably
saying I'll never have time to do all of
this well I have a solution you can get
other people to do it for you sober oku
is the king of platformers service or
pass for simple single web let
single-layer web applications that are
powered by postgres you can very often
be up and running in under an hour and
you can run your application for free
which is pretty hard to beat so and it's
it is very very simple and easy to get
going as you up are there free tier you
can very easily scale up usually as
simple as either typing one command or
even just moving a slider on a web page
to say I want more performance
unfortunately you pay a premium for this
it's a it's not a cheap service after
you outgrow their free tier and it can
also be a little restrictive and
stifling they really only offer one
model of how to run your application and
if your application doesn't fit that
they say not our problem fortunately
pouring off Roku is very very easy they
are very much anti vendor lock-in so
moving from Heroku onto your own
Hardware can be as easy as it can
possibly get not saying a whole lot but
it's it's nice to have that as an option
I highly recommend using Heroku for
small personal experiments or
applications that you're just trying out
to see if they'll work Google App Engine
is another option for platforms of
service but it's so drawer fighter Roku
that I don't really think there's much
going for it it does allow you to run in
Google's infrastructure instead of on
Amazon karoku itself runs on top of AWS
and it does come with a lot of baked in
expertise about how to run scalable
applications things like the google data
store but i don't actually know anyone
that uses this anymore so take that as
you well open shift is an open source
platform as a service tool written by
written and managed i guess by Red Hat
they also offer a hosted version but you
can download and deploy it yourself
unfortunately deploying openshift is not
simple and it may you may find that it's
just as easy to deploy an application
platform yourself than to deploy
openshift Cloud Foundry is also an
option basically all the same things
apply acceptance from VMware instead of
red hat and finally dais and Flynn both
passes built on top of docker to say
they are early a development is a very
very vast understatement dr. itself is
not production ready so needless to say
neither of the user production ready
not even remotely but if you like the
idea for roku and you want to run it
yourself and you'd like to play around
with some emerging technology i'd
definitely recommend checking out both
days and Flynn if nothing else there
they're promising ways to run
applications in the future and some
quick attributions and thank you
we have time for a few questions on this
top sure we have any questions just
waste to the people running around
microphones you briefly touch upon I
just like to hear your thoughts on
leaving for a sensation and daugher a
lot of those in that space I don't think
there's a whole lot there I mean what
you call a container is really pretty
arbitrary you know docker as a container
sure so is a Zen vm or a kvm vm I mean
it's a question of the overhead and the
time it takes a spin one up so spinning
up as nvm on Amazon takes 45 seconds
spinning up a docker lxc vm takes like
200 milliseconds spending it with zero
vm vm takes nanoseconds but really it's
all just different layers on the same
technology on the other hand I think
it's the right model for applications
and so if doctor is the thing that
finally gets people to pay attention to
this is how you're supposed to be using
computers I'm really not going to
complain I have I like the core OS guys
I mean like I said FCD is cool fleet is
interesting I don't agree with a lot of
their decisions mostly around Fleet
there they're really building stuff
around a very manual model which i think
is wrong but I think core OS itself is a
pretty cool idea you know I like the
idea of a very so so for those not
familiar Korres is a very slim linux
build it's basically just a linux kernel
and the barest essentials to run
containers on top of it so you don't get
very much in the hypervisor system and I
think that's pretty nice I mean that's
basically DM where does already vmware's
hypervisors are a stripped-down Linux
system and they've been selling that
product for years that seems to work
pretty well so cool again I'm not going
to complain if that's what it gets
people to to use the stuff correctly
are you familiar with modifies liji
system or any of the other task
management systems that are starting to
come in from the MapReduce management
world I'm not familiar with Spotify I am
somewhat more familiar with mezzo sand
that the Apache world under there I
don't know again like I'm not going to
complain it's certainly better I think
that there is a lot of stuff that is
really built around manually kicking off
jobs and I don't like that idea that's a
lot of the mezzos world seems to be
built around that people really need to
move towards scheduled with what's
called resource schedulers which is what
confirmation is of document the the
desired state of what should be running
where rather than thinking it as running
one off tasks in different places any
other questions
alright have you ah sorry have you ever
considered elastic search for sure yeah
I actually use it I don't really think
it's worth mentioning because it's
pretty specific to one use case and
really your options if you want a search
system or elastic search and solar and
nobody wants to use solar so it is what
it is and there's basically no choice so
if you want a system with faceted search
you're using elastic search and it's
pretty good okay that's and Simeon
breathless they no longer his first talk</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>