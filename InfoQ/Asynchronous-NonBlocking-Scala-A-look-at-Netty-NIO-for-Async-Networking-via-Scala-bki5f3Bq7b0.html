<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Asynchronous &amp; Non-Blocking Scala - A look at Netty &amp; NIO for Async Networking via Scala | Coder Coacher - Coaching Coders</title><meta content="Asynchronous &amp; Non-Blocking Scala - A look at Netty &amp; NIO for Async Networking via Scala - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Asynchronous &amp; Non-Blocking Scala - A look at Netty &amp; NIO for Async Networking via Scala</b></h2><h5 class="post__date">2012-04-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bki5f3Bq7b0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so for those who don't know me who
haven't seen me speak before
I'm Brenda McAdams I'm an engineer at
Engine one of the products we make his
mama TB and I spend my day working on
stuff around mommy-to-be I do a lot of
work with Scala before I joined engine I
created a driver for Mongo and scholar
called Kasbah which I now maintain there
and I spent a lot of time early on
getting a feel for you know more and
more of using skull that was really how
I learned Scala and early in my career
that was it that was all I had done in
the career in Scala and I've given a
talk
Scala days and a couple of other
conferences and it on my experiences
learning you know what I learned about
Scala writing a driver the big thing
with with Kasbah is that rather than
reinventing the wheel for the networking
part of Mambo there was a perfectly good
Java driver that already supports the
networking to Mongo so I figured I'll
focus on all the parts that make things
look pretty in Scala and leave the
networking there um but one of things I
did come up with is that there are
different people out there so there are
asynchronous frameworks like blue-eyes
we're having a blocking network driver
becomes problematic and so I started to
play with I was sort of excited at that
point to start doing more and playing
with writing a pure Scala version of the
Mongo driver and I started to build
something called hammersmith which is
stable now a version of it shipped with
akka 2.0 to do mom with durable mail
boxes it doesn't have all the features
yet but a bunch of different people have
contributed to it it's been a lot of fun
to work on I've been busy the last few
months and haven't be able to work on it
much I'm starting work on it again and
so I learned a lot about doing
asynchronous IO from doing that and I
want to use that to guide this a little
bit we're gonna talk about why we might
do a circus i/o and a couple of the
lessons that I learned things that were
hard to do they're easy to do in
synchronous programming and there's sort
of patterns or tricks that you can apply
to doing this yourself so we have a
couple of goals here we need to stop
wasting resources in blocking i/o and
I'll talk about some of the reasons why
I rather maybe speciously accuse you of
wasting resources because in blocking
i/o we have a very set path for doing
things and if we have to deviate from
that path to maybe wait for something to
happen we can't really do anything else
with those resources that are going on
we want to try to achieve see 10 K now
I've heard people say recently this see
10 K is sort of a laughable number
because that was the target five years
ago see 10 K is a sort of shorthand term
that refers to the idea of scaling to
handle ten thousand simultaneous clients
there's people who claim now that that
number is too low but that was a number
that's thrown out there when you're
talking about asynchronous programming
it's a target it's something where ten
thousand simultaneous clients in a
synchronous networking layer might be a
little bit tough and profit because
ultimately at the end of the day we're
not you know most of us who you know are
going to jobs every day and as much as
we like playing with these tools we have
to produce something for them that shows
our boss that there is a reason we hid
for three months and rewrote the entire
system to use Neddie and not just
because we heard Neddy was cool at a
conference and so I'm not just gonna
tell you Nettie is cool I have my issues
with Nettie as well but it's better than
doing raw and i/o but what I'm gonna
show you is that there is benefit to
doing it there are things that are up
and down about Neddy but in on a whole
you get a big performance gain so what
do I mean with with this you know we are
talking about i/o by which I mean
input/output does anybody not familiar
with what I meant by i/o do I have to go
back and explain computers take things
in they spit things out um they do you
know mutate state and have side effects
it's just the way it is we're gonna
focus on networking technically a lot of
these interfaces you can use them with
files or something else like the niño
stuff has file iterators we're dealing
with networks under the covers in many
operating systems a network device is
really just a file descriptor and in a
lot of ways you interact with the kernel
it doesn't care whether it's a network
or a file or something else so
asynchronous is not the same as
non-blocking but they're often lumped
together because asynchronous describes
a way of computing on top of
non-blocking i/o I tend to think of
these as a little mini stack there are
two concepts that fit together nicely
asynchronous is a way of making
non-blocking i/o work well for you
because there are some versions of
non-blocking i/o out there that don't
have the the asynchronous the way that
they're non-blocking is they throw an
exception that says would block if they
were going to block
and expect you to do something another
way in the last few years we've all
gotten used to asynchronous being
hand-in-hand because most frameworks
have realized that throwing a it would
block if you did this exception isn't
very productive so we have a couple of
problems of blocking when we haven't a
blocking i/o operation everything that
thread really halts in weights so if I
go do a big piece of computation or I'm
reading off of a disk so imagine you're
on ec2 which happens a lot these days
the EBS volumes are a network device and
they're probably a disc that five or six
other people have that spindle and so
you're waiting for that spindle to go to
your devices you're waiting for it to
spool over the network and while you're
waiting for that read off a final system
that threat of execution is basically
doing nothing it's sitting there
spinning saying are you ready yet and
that's really it internally you've got a
big loop that's saying are we there yet
um you know you if you know you've
remember being kids trips you didn't
want to go on you probably figured out
early if you bug your parents with are
we there yet they threaten to turn
around you know in some cases that can
be to your advantage we don't want that
with i/o because it's a waste of
resources and a lot of us have also
gotten the point where we're not a lot
of us aren't using physical Hardware
anymore and it's easier in some ways to
have this happening ignore it because
it's so easy to get another machine but
at the end of the month I've had places
you know you hear the boss coming around
asking why the ec2 bill is so absurdly
large and how does he revoke your access
to spit up new resources and we need to
deal with this we need to handle this
idea so idleness is essentially
happening because the thread is waiting
for the i/o to complete and it's doing
nothing else at the time so there's
really no need for that thread to be
sitting there doing nothing because the
kernel is the one that's really handling
the is this i/o done yet or not
so this limits our ability to scale
because we're just sitting there doing
nothing
um it's the do the equivalent of I'm not
screwing around I'm waiting for my code
to compile so non-blocking i/o gives us
potentially a solution which is we could
avoid blocking on each operation we can
find ways to work with the kernel to
manage multiple blocking resources in
groups so we're still gonna have to pull
somewhere but in most modern operating
systems there are a couple
things like selecting a pole KQ on
FreeBSD that understand that you don't
want it event loop running for each
operation you're doing but instead you
can ask the kernel of you know what
you're the person who's ultimately
deciding whether this resource is
available or not would you be so kind as
to just tell me when this group of files
have something happened to them within a
set of what I care about so we can free
up threads that are no longer blocked
waiting while they're doing the IO we
can just do something else with that
thread we can execute some of the
callback or some other piece of code and
there's another event loop running
that's telling us when whatever we're
waiting for happens and that's really
how node.js works nodejs is a single
event thread
there's no threading it's just a big
event loop and it's firing off callbacks
when something happens on a piece of
information that's registered in the
event loop is interesting it's a single
thread we have the benefit of threading
which means if we're smart about it we
can make this happen at scale we can use
multiple cores and all these other
things
so we're asynchronous comes in is if
we're no longer blocking and we're
reusing our threads we have to figure
out how to handle completion events and
callbacks or a nice easy way to do that
so async techniques they give us that
solution it's really the equivalent of
you know you've been to different
restaurants I've seen different fast
food restaurants where some of them for
whatever reason you order your food it's
gonna take them five minutes and they
make you stand there and the cashier
isn't serving anyone else while they're
waiting and then some give you a number
and you step to the side and they call
you when you're ready that's really the
asynchronous I can serve five other
customers we've got people in the
kitchen whose entire job is to cook food
they will let us know when your order is
ready and then we will call you as
opposed to be sitting there at the
register waiting for your food to come
up it makes no sense the synchronous and
blocking i/o really forces us to do
certain things that we may not want to
do and that's things like in a server
we're more or less in a one-to-one ratio
of quiet connections to threads that
we're running it's worse if any of you
dealt with the really Apache 1x and the
pre fork model in Apache 2 is the
similar thing where it's individual
processes you had one parent that was
responsible for accepting all
connections and then queuing them until
a child was it was available
and a child process could only handle
one thing at a time
that's an exploded way of thinking of
what's really happening we're just doing
it the threats we're doing with
lightweight processes instead of actual
processes there's still overhead there's
a heap size that comes with all these
things threads have overhead
despite the argument I got in an
interview once with someone who thought
you could spin up a million threads with
no overhead there is overhead threads on
the client side you know we can end up
with a lot of other problems and these
come and go different people have
different opinions but you can't under
with connection pools that are bigger
than they need to be because while
you're waiting on the server to respond
to a request or while you're waiting on
a connection to be available for writing
you're sitting there blocking which
means you have to have more connections
ready to go at any time because you've
got this one-to-one ratio going on on
the server in many cases clients are
something sitting in a server in a web
application you'll probably have an
asynchronous or a synchronous server
with a client to a database or something
else within it which means both rooms
are going to apply if we go asynchronous
we can change this up though with
servers we can have many client
connections to one execution thread as a
ratio it can happen it's possible and
this gives us the ability to scale up we
can have a thread waiting for an i/o
response not need to block on it but
give some other callback a chance to do
work and operations such as write can be
cued up until something is ready so we
don't have to block until the write
happens instead we can say look I
realize all the connections are Vale are
not available right now but I need you
to write this to the database and I'll
call you back when it's ready to happen
you go do something else in the meantime
so basically go to sleep and let
somebody else use this thread um
this of course means we have to know how
to dispatch back to people we have to
call that code we have to figure out
when a message comes back from the
server that were connected to who the
hell it goes to and what call back to
open up and run we also have to
understand concurrency because otherwise
you get all sorts of weird race
conditions and fun things because you're
sharing state across threads the you
know one of the benefits is potentially
you may not have the same thread that
ran before run your callback we also
can't really block within those threads
because this is a framework built around
the idea of you're not blocking anytime
you block because we're trying to have
many client connections in one thread if
you're blocking you're slowing everyone
down and you can't process as much
anymore and we can reduce our pool sizes
on clients and we can leverage these
resources to reuse them so a little bit
about ni o most people have heard of it
I hadn't played with it much until this
year
it's short for new IO it was actually
introduced in Java one for I'm really
what it produced is a low-level IO API
instead of the old IO which is very high
level blocking it's sort of the socket
interface there's a couple of cool ideas
in here that we just within a 25-minute
30-minute time window we don't really
have the time to dig in this is an
article I highly recommend apparently
this guy works with Jamie Allen now at
chariot but he wrote a great article on
what byte buffers are which are one of
the better things introduced in niño
which is this idea of it's zero copy
holders for things like arrays and other
data so instead of you having to do
system array copy you can do things like
slicing out a piece of a buffer of bytes
an array of bytes from a byte buffer but
it's still pointing to the same memory
location is the original byte buffer and
not copying them around and this gives
you a lot of efficiency you even have
the ability to allocate directly on this
on a heap with no GC all these although
that tends to be dangerous and you have
lots of memory leaks seem to occur with
those because if you don't free them up
properly just like in C you end up with
memory leaks and odd behavior so for
working with the network we have to
manually work with a selector and
request and we know to read and write
that calls back when ready and there's a
couple of core units of work we have a
buffer a channel and a selector the
buffer are basically contiguous memory
slots they're they're able to hold
information whatever that information
represents and they typically offer some
kind of a data transfer operation shift
this to this other buffer shift this to
this file descriptor on disk whatever
you need to do channels are really bulk
wrappers to this they're there for us to
do bulk operations like reading and
writing to a file descriptor be it a
network socket whatever else the big
piece is this part where we have to
figure out what's going on and instead
of us having to pull on a channel to see
if it's available to read or
available to write we give information
about each channel to a selector and we
write an event loop around that which is
monitoring for whether anything's
available in the channel instance so
really you register interest I would
like to read I would like to write and
that loop will come back and give you
information when it's ready so you can
maybe have a hundred channels but
there's one thread which is handling
these things available and dispatching
as things come up so we can relocate the
task of checking this i/o off and it
makes a big difference and you can do
all sorts of different tricks there's a
really good article that I'm gonna be
linked up from Havok Pennington on his
blog I think it's blog ohmmeter com
he did a great article a few weeks ago
about this kind of thing and talked
about even techniques for making sure
that you use all the cores so that
you're minimizing your threads so that
you've got event loops maybe on each
core and how this compares to stuff like
node the reality is I've tried for three
days to come up with niño example code
that isn't going to be a sinkhole you've
all seen these presentations where you
show code really early on and everyone's
gets scared you either take out your
laptops and start doing something else
you just get up and leave I don't want
to do that I think it's better to
describe the concepts of why niño is
difficult show where Nettie improves it
and talk about the conceptual x' then to
try to show you a very complicated piece
of code that's kind of insane they went
a little too level within art to low
level with an i/o which is why things
like Nettie exists so here's what you
really need to know I mentioned you
register interest with a selector I'm
interested in reading I'm interested in
writing whatever you need to do but it's
non-blocking which means you have to
basically give it a call back and said
let me know when you're ready to let me
do what I want we write a loop that
looks for these notification events and
we have to dispatch incoming events so
if we want to read or whatever else if
you want to write this is where it gets
nasty I think you have to tell a
selector that you're interested in
writing and eventually when the channel
isn't busy reading it can switch into a
write mode and call you back and say hey
I've got some availability to write you
then need to make sure you remove the
status that you're interested in writing
because otherwise you'll keep getting
notified that it's available for writing
you need to dispatch a hey I'm ready to
write call to whoever that callback is
and then you need to do your right so it
gets very complicated it's also an area
where you can very easily get into
trouble if you miss a message or miss
something
and rinse and repeat is desired so
obviously the first thing that seems to
have happened with niño is everybody
about frameworks around it so there was
a patchy minor or Meena neti grew out of
that
you know all of these things are meant
to give you this functionality in this
performance without all the complication
I tend to think daddy went a little
overboard because it is a Java framework
so in Scala I feel like I'm doing a
little too much Java to work with it but
this really simplifies niño they
actually also have a package called Ohio
which is how they refer to the old i/o
you can use blocking sockets within
detie if you need to but the framework
design is very oriented towards assuming
you're doing async so it's just really a
wrapper and it hides all the selector
stuff away you no longer have to say are
you available to write instead what you
really just say is here's a buffer this
is what I'd like to write and then it
takes care of when writing is available
it puts it on the network for you which
makes more sense um really it's built
around a filter pipeline so there's a
pattern in Neddie that you can register
on both the input and output side to
have filters that can transform data
check data validate data and dispatch it
where it needs to be as it goes through
each end it's very nice and composable
although I'd love to have a better
scholar API for it um they also have a
system called channel buffers which seem
to be a little up and down a lot of
people have had issues with them part
the idea of channel buffers is to not
rely on the byte buffers that not niño
introduced because people might still
want to work with byte arrays or
anything else what they don't want to do
in Eddy as if you give them a byte array
to then be forced to system array copy
that all the way through the pipeline
and so channel buffers take a lot of the
concepts from byte buffers and let you
use multiple things not just you're
forced to start with a byte buffer if
you don't want memory copying and copy
these things through and so you can have
multiple composite buffers and
everything else and we avoid memory
copying there is direct memory
allocation for what I'm told I've seen
heard rumors and seen bug reports of
lots of memory leakage which seems to be
what happens when you start playing with
direct memory in the JVM so here is
quickly I mean this is of course because
we're linking
with Java this is an example from
Hammersmith of setting up in Eddy
so really because I'm not going to walk
line by line through the code but the
general idea is we're setting up a
pipeline so really we give it a thread
Coupole executors so that it has the
ability to kick things around as it
needs to and we add in this message
decoder which we're going to talk about
when we talk about the problems here we
connect most importantly this is all we
have to do to writing in Eddy once we
have a channel it's a big improvement
over what the niño equivocal II say I'd
like to write now let me know when I'm
ready and go through five or six steps
so stupid pet tricks um very quickly if
you've never heard of him of guffin it's
a Hitchcock was fond of them it's the
idea of a plot device to carry something
through so obviously we're talking about
a driver I've written because it's a
good way of looking at what these things
are we're gonna talk about a couple
things in Hammersmith basically decoding
and dispatching inbound messages so you
may have a thousand people reading from
one socket though that's probably a high
ratio so you have to figure out of the
thousand people who was this message
destined for does it matter
is it a reply to another message they
sent and dispatching it adequately I'm
handling errors and exceptions across
threads etc follow-up operations that
need a same connection context and
working with multi-state iterations
we're talking a little about a belt a
bit area yeah we're going to talk a
little bit about iterate es which is
apparently a tongue twister hopefully in
an easy way is how do we handle database
cursors so the first problem I ran into
it's really packets are bytes
you know in every networking program we
have defined some kind of application
level API which is how we think of the
world the kernel Java etc doesn't
understand or care to them it's just an
array of bytes which means it's also
difficult when we're doing asynchronous
reads because we just get bytes and we
need to figure out which parts of those
bytes are relevant to us so if I have so
let's say a hundred connect clients
using a connection I have to figure out
messages if I get a thousand messages
well which of these goes to what person
which of these are replies which of
these are Jeanette
things and we have to figure out where
they go so the challenge is separating
them out and sending into the right
place so it's really the law of Demeter
in niño you're sort of forced to deal
with that in place of knowing just
enough about what's happening to deal
with it
so essentially you said I'd like to read
now and you've got to break this out it
can get very complex you're sort of
trying not to go into the office fridge
and eat someone else's lunch so and I Oh
leaves this on their own
Nettie's pipeline actually makes that
really easy because with nettie pipeline
instead we register something that
understands how to decode our protocol
it picks out the individual messages
from the byte stream and then uses the
rest of the pipeline to dispatch those
as we need them which is much saner way
of dealing with this so this is an
example of how we decode the Mongo
messages which is among other things
it's a length field base frame decoder
because Mongo messages are very specific
lengths the first four bytes of a Mongo
protocol message is what the length of
the rest of the messages and so nettie
provides a basic context for handling
that of now by passing the arguments in
the constructor of how big the message
can be possibly total what the offset of
the length header is and then where to
start because Nettie by default assumes
that your length and does not include
the length in a length we include the
length in the length which is what the
minus four is which is actually saying
Nettie considers zero to be after the
length and so we have to say no
backtrack and read the whole thing
together and so now we actually get a
byte stream that's an exact message as
long as a well-formed mono message came
over the wire and we can break that down
essentially into our class and I have a
series of classes that know how to then
turn that message into some valid
representation of a Mongo protocol and
so this is just stuffed into the
pipeline and everything that comes in to
read from that socket Neddie will decode
into a message and then there's a lookup
table that says essentially these are
all looking for replies from the server
and each reply has the ID of the message
that was sent and there's a lookup table
that says if this ID should invoke this
callback and everything gets where it
needs to be and this was just the tail
end of that so really the
the part my channal handler which is the
part of neti that's responsible for
responding the messages that come in
this is invoked after that pipeline so
that reply message decoder goes before
message received
so instead of in message received get
message gives you an object but in this
case unless something's really broken it
should already be a Mongo message
because it was either decoded or an
exception was thrown in that packet was
discarded I can cast that as a longer
message and then do a case statement a
match to is it what kind of a message is
it and how do I respond to it and I
didn't think you'd want to see like
twelve hundred lines of Scala cases I
can pull those up if you prefer but the
general idea is you know this is a huge
advantage of something like Neddie is
you have to understand how to slice out
the pieces of the message that you're
looking for and send them to the right
place and deal with that efficiently and
not accidentally overeating the first
six bytes of the next message which
makes the next message impossible to
read because you've sucked six bytes off
the wire so handling errors we get
really used to I think using throw and
catch try catch etc throwing exceptions
but we never know what thread we might
be executing on so that thread might be
isolated from our main execution area
and so if an exception is thrown it may
just disappear or it may you know bubble
up the stack and cause other unexpected
errors and so we need a way of passing
information about problems Scala
obviously has either and either has two
possible states left and right it's
really a monad and it's representing
failure and success by convention the
left hand side is typically representing
an error and the right hand side is
representing success in Scala note has a
similar system if you've ever written no
js' every callback method typically by
convention gets both a failure and a
success and you test which one is
defined this is better because it's one
composed thing that can be either or it
cannot be both at once there's no real
different way to handle this in Eddy
versus ni oh it's just a conceptual
either is a great thing because you can
you know you can compose a throwable or
exception you don't have to throw it you
can wrap it in this thing that indicates
success or failure and pass that up to
your users and their implicit tricks for
lazy people who want to write a success
block and I'm gonna skip through these a
little bit to make sure we cover the
other ones but I'm happy to come back to
them afterwards we have a little extra
time I think at the end but the general
idea here is these are a bunch of
structures that are used within this
driver that ultimately when you're
writing a request future and without
meaning to I ended up implementing
futures and then I realized it was a
future and rename the class and
ultimately it's gonna be using akka
futures but the general idea is you give
it a body and the body is supposed to
have a left which is oh sorry in this
case it's oh the way the class is but
essentially a body is supposed to be an
either of throwable or a success
condition and a handler looks like this
so really we're expecting to get back an
either throwable any rep and you deal
with the result you deal with an a
either by doing case write a success
left as failure you could have a global
event handler or something else that
handles errors if you needed to and if
you wanted to ignore errors which many
people do you can make an implicit that
sort of pretends as if if they don't
specify the either it just takes the
success and you can globally dispatch
your error another one that I ran into
it was same connection follow-ups so a
lot you know a lot of Davis's of context
there's something that has to happen on
the same connection as your right you
can get follow-up information MySQL is
last insert ID where you know MySQL can
auto increment an ID and you want to
find out what that ID was but that has
to be called immediately after the write
on the same connection as the write or
you don't get the right info Mongo has
something similar if you want to control
write concern if you basically the
consistency if you want to get
information about the success or failure
Mongo writes by default or asynchronous
you have to make another call it has to
be on the same connection immediately
after the right so how do you deal with
that in a synchronous framework it's
easy you get a pool connection out of
the pool you hold on to it don't let
anyone else touch it problem solved you
know no one else has written to that
connection in async
it turned out that really the reason was
ballot box stuffing is what I like to
think of we're reversing the issue of
once it gets to the JVM the network the
OS they don't know it's anything but a
bunch of bytes
but if you give it one buffer of bytes
and say this has to go on the network it
will guarantee that that whole array
gets on the network in order because
it's important so the trick is to just
put both protocol messages together in
one right operation and the OS will make
sure they get where they need to be
which means on the connection it will
get to right and immediately it get last
error or a last insert ID and it's gonna
get where it needs to be and there's an
example of it here which I'm happy to
show to people afterwards if they're
interested in but the general idea is
just if you want to do the right add
that into the stream then he makes that
easy
so the last one and this is iterate ease
everybody hopefully has heard of iterate
ease a little bit the name floats around
quite a bit
Scala Zed has them just surrett wrote a
really good article on them recently so
in typical iteration we're dealing with
basically a dual state monad and this is
an iterator of a that is to calls those
calls are hasnext which returns a
boolean do you have more information and
there's a call called necks which says
give me another piece because you expect
to get an element a being the type of
whatever you're looking for in a simple
form an iterator is just pre-populated
with its buffer of items all the
possible items that can return are there
when it's instantiated if the buffer is
not empty has next is true and next we
return another element the buffer is
empty iteration halts because it has
Nexus false now if you actually look at
the Scala doc it turns out that it
specifically says the behavior when next
is called when it has next as false is
undefined there's no contract in Scala
basically calling how next one has next
is not defined is going to do weird
unexpected things thankfully like the
for each expressions and all that use
and it has next to determine if they're
gonna call next so long as your iterator
is written correctly and it doesn't say
it has more when it doesn't you're okay
in a simple database or a simple
construct working over a network a query
might just return everything that was
the answer to the query and we could
instantiate an iterator of database row
this is nice and simple because really
we can just construct a curve you know a
database row iterator it's got
everything it needs it can iterate the
same way
but of course forcing a client to buffer
10,000 20,000 results is questionable do
have enough memory on the client for the
entire result set if we have a lot of
async clients we could have a lot of
memory and a lot of day they says Mongo
MySQL Oracle sequel server have
something called cursors which is
buffering the server is using its memory
to hold on to these things so a cursor
is gonna be an initial batch a result so
maybe you'll get the first 200 results
and it will tell us that there's more on
the server that you could get with a
batch so a Mongo there's a call called
get more I mean it's similar in every
database get me more and there's gonna
be additional batches they're not you
know there's gonna be more about you
keep calling get more when you want more
results and once it's exhausted there's
nothing left try doing this without
blocking because I did and it was
painful because we have three states now
in our iteration typical solution and
synchronous drivers just has next
boolean if the local buffers non empty
return or if there's more results on the
server next can just if it's not empty
return it otherwise go to the server and
an intelligent driver might be
intelligently prefetching what's going
on there a synchronously though that
block on get more will kill you I try to
thread dot sleep at one point early on
I'm like I'll figure this out later I
couldn't figure out why there applied to
get more was never coming in it's
because I was sleeping and blocking the
thread that was responsible for reading
off the socket the reply that I was
waiting on so we're reusing a small pool
of threads we will block and I may have
been heavy drinking involved afterwards
and about halfway home on the train I
went oh I was blocking the thread that I
was supposed to be reading from um so I
talked to a couple people including John
de gose and Josh surrett who had
suggested iterate ease you know I read
some Haskell white papers I read some
scalzi code my head hurt repeatedly
there may then be more drinking so I
wanted to point out that I may be
completely wrong on what I explained it
or 80s this is my interpretation the
general idea is instead of blocking next
we want to introduce a higher-order
function we pass a function that takes
an argument of an iteration state and
returns an iteration command based on
that state
our code is now async and if the
response to not quite what I wanted the
response to know more on client-server
has some ones go get more you don't have
to block the i/o because you could pass
a copy of your current method with the
get more and you'll be called back when
there's more and the method will return
as if you went to sleep and came back
awake so very quickly because we've got
about two minutes I think I don't know
how is that accurate to the original
time and we have a few minutes after
okay
so very quickly looking at an example of
this I've got two trades iteration state
iteration command I've got a entry which
represents here's a valid entry this is
a proper response and next I had local
entries here's an entry do something
with it empty which is my indicator of
there's nothing left on the client but
there's more on the server and end a
file which says that both sides are
exhausted there's nothing else for me to
give to you on the iteration command
done means I'm done I don't want to do
anything else with this cursor clean it
up and shut down next says okay get me
another item and here's a copy of my
function again a function that expects
to take an iteration state and return a
command and then next batch which does
the same thing it takes the function
next batch says ok go to the server get
the next batch populate your local
buffer and keep iterating me as if there
was a local buffer this is on the on the
actual cursor what the next method looks
like which is that instead of the next
method actually working on the network
it returns a bunch of possible iteration
states which are fed into your inner 80
method there's a helper function that I
wrote on the object to just make it
easier for you to have you know just you
can define iterate give it a copy of the
cursor give it your command and it will
wrap everything automatically so it
invokes next when it needs to it Vokes
next batch and this is an iteration of a
curse and really we're looking here and
I don't know if the guys on the other
side of the room can see me cuz I've got
a pillar in the way but really here if
we get a state of entry process it if we
get a state of empty ask for the next
batch and if we get a state of end of
file just close it up this is also
testing that you can return different
commands to States then you
expected so if there's more than 100
items it just shuts it down finally
there is in JDK seven I found this on
the train up yesterday a new thing
called either niño 2 or a IO depending
on who did the write-up and it actually
has something called a synchronous
socket channels which fixes some of the
problems with an i/o being too low-level
without being as insanely high level as
Neddie God so what you get is instead
something that Maps really nicely to
what maybe you might expect from akka
which is you don't have to select and
pull by hand there's a read and a write
method they all take optional timeouts
and you have two ways that you can get a
response back you can give it a future
which most people who've worked with
skål have probably seen in one form or
another future is just really a method
that eventually will return a result you
have the option of blocking on it or you
can do a completion handler if you look
at what a completion Handler is it has
two methods on a completion Handler
success which returns T which is your
success instance and error which returns
the error that occurred so if you can be
smart about writing your implicit you
could really easily write an implicit
that converts and either down to a
completion handler so it could map very
nicely it's unfortunately not really
something you can run with I would love
to switch hammersmith to it because it
requires JDK seven and I don't think
anyone would be like oh yeah I have this
great async driver but you can only run
it on Java seven which no one's really
using yet so it's an idea but not quite
there I already did post the slides this
morning so if you're interested in
digging through the code and all that
the code for Hammersmith is up there as
well and if I haven't confused everyone
thoroughly I'm happy to answer some
questions so the slides are up I'll be
here for the rest of the day off you be
here Saturday and Sunday as well so if
you have questions or want to have me
walk you through any of the stuff you
didn't understand and feel free and
thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>