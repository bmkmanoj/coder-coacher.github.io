<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Node, npm, and Service Oriented Architecture - Forward 4 Web Summit | Coder Coacher - Coaching Coders</title><meta content="Node, npm, and Service Oriented Architecture - Forward 4 Web Summit - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/InfoQ/">InfoQ</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Node, npm, and Service Oriented Architecture - Forward 4 Web Summit</b></h2><h5 class="post__date">2016-04-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5yK3lx-PQV0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this thing where I have my speaker notes
on my phone and I can hit a button and
the slides advance that's not gonna work
at all so I'm gonna be awkwardly going
back to them oh my god it worked all
right yes Web Apps everyone so hello my
name is Laurie I am the CTO of NPM and
in case anybody is confused I am NOT the
famous NPM guide the famous NPM guy is
Isaac and I am just the guy that he
picked around his engineering and what
are we talking about today
this is a talk not about how to write
node code because there's a fair number
of those that this at this conference
this is a talk about how to what I do is
I run a really popular web service that
is consists of dozens and dozens of node
apps and this is a talk about how to do
that it's about how to run the whole
system not just how to write one
particular piece of software in node and
specifically it's about service-oriented
architecture or SOA which is the
architectural pattern that we use a
10:00 p.m. and we are big fans of SOA so
specifically what I'm going to be
talking about is what SOA is in case
you're unaware of it
why I think you should use it why you
should do it in node specifically why is
node good at this stuff how to do it
properly and a case study of how we use
NPM at we use SOA at NPM because we've
been doing it for two years now and
we've picked up some you know tips about
what we think works and what we think
doesn't my hope is that by ended by the
end of this you'll understand why we
like it and have a pretty good idea of
how to apply it yourself but first a
quick confession which is that yesterday
I had a whole different talk and at
around 4 o'clock I had a really
interesting conversation with my VPNs
and I was like I should do that instead
so I threw out the middle half of this
talk and and replaced it with a
completely new talk so it's somewhat
unrehearsed I think you'll like it
better than the old talk but be warned
so what is SOA it's a design pattern
somewhat formally it is a design pattern
in which the logical components of an
application are separated into
standalone services that communicate via
defined protocols much less formally it
means splitting your app up so it runs
on lots of boxes as this is as in this
drastically oversimplified diagram here
on the left you've got the more
traditional monolithic thing you've got
one big
machine and everything's happening on
that big machine and this is the sort of
Platonic ideal of the SOA where every
single thing that is happening is
happening on its own box usually the
protocol that these things are speaking
to each other is HTTP but it can be
anything it can be you know thrift or a
bro or buffers or whatever the hell to
dip into slightly academic terminology
just for a second an SOA is an example
of a disk of a distributed system and
distributed systems have some really
interesting properties
the first is concurrency concurrency
meaning that there are many actions
happening interleaved with each other
not necessarily in parallel with each
other although that can happen as well
and there is no global clock which means
that actions can be happening at
different speeds in different parts of
the up of the system and you cannot
guarantee that things that happen in one
order will always happen in that order
the third crucial crucial attribute of
them is that they is that they have
independent components and independence
means not just that they're on separate
machines but that a failure in one part
of the system does not create failures
in other parts of the system it is very
easy to move your giant monolithic
application in to lots and lots of boxes
and have it still be a monolith it will
still you know if the front door fails
everything else will fail then it's not
really a distributed system it's just a
really big monolith and these are super
interesting properties for a web service
and as we'll see will lead they lead
directly to the advantages of an SOA you
may also have heard of a pattern called
micro services there is a difference
between SOA and micro services and that
is that one takes much longer to say
other than that there's no real
difference they are that they're the
same thing there are small focused
services talking to each other over the
network and if you think that there is
some big difference between them that I
miss feel free to put your hand up in
the QA QA section and be that person
but for this talk I'm going to be using
them interchangeably and you can
consider them interchangeable terms so
am I going too fast or too slow this is
a thing about being unrehearsed so let's
talk about why SOA is a good idea there
are two types of reasons that I like SOA
the first are technical architectural
reasons and the second are
organisational human reasons
let's do the technical ones first the
tank the first technical advantage is
resource efficiency imagine you have
this big monolithic app that does all
sorts of stuff but it's mostly getting
one type of request it's getting this
one read request over and over to run it
needs to have everything that it can do
in memory but it's really only doing one
of those things so even though you're
only using you know those four bits of
the of your software you have to use all
of your memory you can only fit four of
these processes into memory at the same
time if you instead run a micro service
that does only that thing you can in
this imaginary box that I have drawn on
the screen fit twice as many processes
into exactly the same amount of hardware
with no change to what you're doing
other than a change in your architecture
this is obviously a stupidly
oversimplified version of this principle
but you know take me at my word when I
say that this works whether or not
you're you're constrained resources
memory or disk or processor or network
or whatever it is
the next technical advantage is cost
efficiency by splitting your functions
into separate machines you can buy
hardware that is specialized to those
purposes so if you need high memory or
high CPU or high disk space whatever and
it also means that you can scale the hot
part of your application without wasting
money if you have you know seven
services that make up your machine and
one of them is your front door and your
front door gets 10,000 requests per
second but one of them is your login
service and your login service gets you
know one or two requests for a minute
you don't if you're in a monolith you
have to buy you know 10,000 requests for
a second worth of boxes and you've
scaled everything suddenly your login
server can do 10,000 requests for a
second but it doesn't need to in an SOA
you can just take the hot part of your
application and scale that which means
that there's less risk because you're
scaling only that part and you don't
have to think about what happens when
you scale your login server and it also
means that you're spending less money
doing it you can also tune your
redundancy so again again with that
front page example you never want your
front page to be down you always want
your front page to be up so you're going
to buy tons and tons of those boxes and
you're going to make sure that they're
multiple redundant such that a failure
of one of them doesn't take yourself
down but your marketing pages you're
probably not so worried you're probably
ok with your marketing pages having 98%
uptime and
you know half an hour to restore them if
they go away so you run your you know
you run dozens of servers for your home
page but only one server for your
marketing origin server and again you're
saving money you're saving time because
you don't have to solve the complicated
problems of high availability for a
marketing server the next technical
advantage is robustness remember I said
in the formal definition that that
service-oriented architecture means a
failure in one part of your system is
isolated from the other parts that's
really great for robustness it means
that if the in turn makes a bad deploy
to one service it doesn't take down your
whole application if if in a monolith if
you know the intern made a bad deploy
and was suddenly throwing a fatal
exception all the way up through the
stack your whole app would be down your
whole company would just halt but in a
service-oriented architecture only the
thing that they were messing with that
day is down and it's probably not the
most crucial thing in your application
because you gave it to the intern so at
most it's gonna take down one service
and that's cool and robustness also
applies at the hardware level which is
just simple math assume that you are
using the world's worst hardware and it
has a one percent chance of failure on
any given day which is significantly
worse than any actual hardware the and
imagine you have a hundred of these
boxes the chances of all of those boxes
failing at the same time is this
gigantic number which I enjoy printing
out it's basically zero but the chance
of one box failing on any given day is
exactly 100% you will definitely be have
lose one box per day with this one
percent hardware because you have a
hundred of them so this means two things
first it means that you need redundancy
in a service-oriented architecture you
can't have only one kind of any service
up because the chances of you losing
that thing are pretty high or if you
don't care about it being down you can
but the second is that you need to be
really good at replacing hardware
because when replacing hardware when you
have five boxes if there's a thing you
do every couple of months and it's okay
if you have to relearn how to do it and
you're like oh where are our app servers
we don't even remember but in a
service-oriented architecture this
becomes not a daily thing not even with
you know the world's crappiest hardware
it becomes like a weekly thing probably
so you have to automate the hell out of
your deploys otherwise you were going to
spend all of your time doing that but
the payoff is that you basically you
know all of these things are a lot of
work but the payoff is that you'll
basically never be down you'll be this
thing
which is really cool since prior to 2014
npm would go down for hours at a time if
it went down at likes you know 10:00 at
night we wouldn't notice until the next
morning and so would be down for 8 hours
which was great for our reputation but
as of 2014 when we actually formed a
company and started doing this NPM
registry of time has been ninety-nine
point nine nine eight percent which is
ten minutes per year it's probably going
to go down right now as a result of me
making this post and a talk another
simple but invaluable advantage is debug
ability it's really simple it's it's it
seems like an obvious thing but because
only one one box only ever has one
service you know that if that box is in
trouble that services in trouble and
vice versa you know if there's something
weird happening on that box it can only
be that service that's causing it you've
eliminated a whole step in your
debugging so their services are easier
to debug before that reason but once you
get into the service because the
services are themselves simpler the
services themselves are also easier to
debug because there's just less to them
they're smaller there's only a certain
amount of unique code in each service
because they're each doing do something
very simple
so debugging it is usually pretty simple
you're like oh there's 200 lines of code
and this one you know has a semicolon in
the wrong place but strangely even
despite those technical advantages which
I like the real advantage of a
service-oriented architecture for us and
I think probably for you isn't about the
technology it is about the organization
that builds the technology if you've
ever heard of Conway's law
Connolly's law says that software
reflects the structure of the
organization that built it so if you
have a small fast lean team you will
tend to produce small fast lean software
and if your team is you know an
eight-way Byzantine feudal war then
you'll have you know Windows or
something but the reverse can also be
true you can structure your software
such that it demands that teams be in an
efficient structure you can demand that
you can demand that your software is
built in a way that makes for efficient
teams so the first organizational
advantage is simply that simpler systems
are simpler
each individual service is a small
isolated domain of understanding it has
limited limited and easily understood
inputs and outputs and that makes it the
make makes the whole service easier to
fit into one human brain and that's
really important because the human brain
the size of a human brain the capacity
of a human brain is one of the hard and
immovable limits of software development
you cannot make a system that is larger
than one human brain without things
going rapidly off the rails which is not
a rails dig but it should mean so
because your services are smaller you
can give those services to smaller teams
and that is important because
communication within a group is another
one of those unfixable pre people
problems in software development that we
cannot get rid of so imagine you've got
this team of five people ABCDE and
communication within this group is not
an it is not the number of people in the
group it is not even N squared or n
factorial it is basically infinity you
can easily imagine a has to talk to B
and C and then they talk to DNA and they
discover that he had some information
that that they didn't have before so he
goes back to a and a talks to C again
and then B is like oh I was sick that
day and I missed it and suddenly
everyone is angry and confused and this
will go on for a little while and
eventually the information will
ping-pong back and forth and you know
maybe a day later everyone will reach
equilibrium and suddenly everything will
be happy again but if your team is
bigger than this if your team is even
twice this size that basically never
stops if you've been part of a 50-person
engineering team and I really hope you
haven't you will understand what I mean
when I say that the the anger and
confusion is basically continuous
there's no way to get a team of that
many people all on the same page all at
the same time it just can't be done
there's only 24 hours in a day to be
talking to people so the smaller your
team the more likely you are to
eventually reach equlibrium and actually
be able to get things done without
getting people very angry upset so
because teams smaller teams have better
communication they can move faster but
there's not only that because working to
get because that team is working
together on a smaller system because
they can fit it all into their brain at
the same time they will have a better
sense of ownership if the team feels
they own the code and they can fit the
whole system into their brain they're
going to be more fearless about
refactoring they're going to be fast
debugging they're going to write more
comprehensive tests and they're just
going to be writing better software we
are better at writing smaller software
so the solution there is not to find
some magical way of writing big software
it's to make sure our software never
gets big so that is the fly through part
of why SOA is great and this is where we
are entering unknown territory because
this is where I threw out the rest of
the talk that I'd written yesterday
because in the previous version I was
just talking about all the pitfalls of
SOA and the things you need to avoid and
I was like that seems like a real downer
to go out on the talk wit so how about
instead I say what I think you should do
to actually make this SOA work for you
what are the things that we found that
works and the things that we found to
avoid but before I go into that I said
at the beginning that node is
particularly good at SOA and why is that
so firstly and most obviously note is
just good at web services
when Ryan Bell invented node tiny web
services were exactly what he had in
mind they're native to node it's what
node expects you to do if you're not
doing anything else but you know the the
hello world in node is like build a web
server that prints hello world and note
is really great if you're if your
workload looks like a web app if your
workload is is highly concurrent at an
i/o bound then you're really going then
you're going to be really good you're
going to be writing node that is really
working with the grain node is really
good at being high concurrent and i/o
bound because that is what we were
trying to solve at the time and that is
a perfect fit for an SOA and the next
reason is nodes cultural pattern of
creating small and simple modules that
we use together in other languages
because libraries are hard to use you
tend to get these big kitchen-sink
libraries only two or three of them per
project and they do a bunch of stuff
which means that you know per my example
early you have a lot of stuff in memory
all the time that's not doing anything
it's just sitting there up using
resources for no reason so simpler
modules that do only the thing you want
mean really fantastic efficiency but
finally the big reason is that shared
logic is easy in node and the reason
that shared logic is easy in node is
because not to you know toot my own horn
or anything because of NPM and because
of the node module loader so part of the
reason that node has small modules is
because small modules are easy in no
and the reason small modules are easy in
note is because of NPM and the module
loader and the way that they were run
they were built at the same time with
the expectation that they would both be
there NPM put stuff into the node
modules folder in a pattern that the
module loader is expecting and the
module loader load stuff out of that out
of that structure on disk in exactly the
way that NPM was expecting it to and
they work hand-in-hand and that is a
unique feature of the node runtime
system no other runtime system was built
with the expectation that a package
manager would be there package managers
were an afterthought or a secondary
feature of every other runtime so people
often credit NPM with this idea that an
NPM eliminates dependency hell but it
doesn't the node module loader -
eliminates dependency hell an NPM just
sort of helps but because you can load
multiple versions of the same library
into memory at the same time with a node
module loader it means that dependency
hell doesn't happen and that means that
you can be fearless about including as
many libraries with all of their sub
dependencies as you want because you
know they're not gonna fight with each
other because it's literally impossible
for them to fight with each other in
node it just can't happen so because of
all of that node an NPM let people share
libraries frictionlessly
but you still have little bits of
internal logic not all everything that
you publish not every module is a global
module that you want to share with the
world so if you have stuff within your
company that you want to keep within
your company but you still want it to be
a module because you want to share it
within different parts of your SOA then
NPM has always let you doing do this
using private git repositories you can
just set your dependency to be a git
repo and it will pull it down but in the
last year we have introduced NPM
organizations those let teams have let
you create teams of people within the
NPM registry and share modules privately
- only that team that is really great
for smaller companies but if you're a
bigger enterprise company and you want
to use your internal sign-in or you have
really strict security requirements we
have strict licensing requirements about
which types of software you can use then
we built NPM on-site which I'm going to
talk about very briefly later which will
do that stuff for you so it's all very
well me telling you that you should
build an SOA cuz it's great and that you
should build in a node because node is
graded essays but how
exactly so like I said we spent two
years building a SOA in node and we've
picked up a few things that I thought
would be useful to share and they apply
at the application level at the
architectural level and at the
operational level the first application
level principle is isolation you should
isolate your data sources each data
source should be talking to exactly one
service you should not trust your
services to respect each other's data
integrity because that usually doesn't
work out especially when you have a big
team that are fighting with each other
so if you do that if you set one service
per data source how do you square that
would the idea that your service should
have only one task your service should
be as simple as possible what if I have
two types of tasks that require the same
data source and the way to get around
that is to be rigorous about splitting
the data the example that I use is if
you have two services that both need to
talk to the data source but their
functions are not really aligned but one
of them is editing and writing to the
data source and one of them is only
reading to the data source you don't
really need them to be talking to the
same data source you can create a mirror
or a copy of the first data source and
have one service talking to that and one
service talking to the other you can
just have replication or some other form
of copying to make that happen which has
other advantages which I'm going to talk
about in a bit and another hard lesson
we've learned in an environment that has
17 services that is what makes up the
registry is that those services need to
be consistently designed or you will
send your whole life confused you will
be constantly going oh how did we invent
logging in this one how did how does
this one find its configuration and how
does this one remember who the user is
so you should be logging consistently
not just there is no quests for the
results of those requests logging
failures is great but logging success is
important because if your node
application crashes and all you've seen
is a request and nothing after it that
looks like that looks like success
because nothing happened you didn't see
a failure get logs but what actually
happened was a terrible type of failure
where was such a big failure that it
didn't even manage the log of failure
because success is not merely the
absence of failure and speaking of that
we have developed really strong opinions
about how error handling should work if
your service doesn't know what to do if
it gets into a corner that you weren't
expecting if the programmer was like
this can never happen your program
should
crash that is what it should do and it
shouldn't just crash and your whole
service should go down a parent
processor should be watching it for
crashes and restarting it as soon as it
crashes because that is the best kind of
recovery any kind of recovery where
you're like alright well it crashed so
we're gonna have an exception handler at
the top and we're gonna try and recover
state and put things back to how they
were and start again it is doomed to
failure because if you could expect how
it was going to fail it wouldn't have
failed that way so by definition the
only way the only reason you're gonna be
hitting a crash bug is if something
really weird is going on and you won't
expect what that weird way so you won't
be recovering accurately from that state
so instead just crash because then your
program will start again and it will
start again from a known state it will
start again from the beginning and go
okay this is point zero I know how to go
from here obviously if you have you know
if you've designed a system that just
crashes all the time and restarts all
the time that leads to a situation where
you can just be like oh we didn't
realize it crashed three hundred times a
second and that was fine so you need to
put some men at some monitoring and some
metrics around that you should need to
know how often your services restarting
itself so that you can check if you've
got a crash bug but most importantly
your services must share logic I said
that that was easy
so you're logging should be a module
you're monitoring should be a module how
you load configuration should be a
module they don't have to be a global
module that somebody else wrote if you
need to do something weird and specific
to yourself or you just need you know
you just have your own requirements for
doing that make it your own private
module but it should be a module and oh
the code that is part of your service
should be only the code that is unique
to that service the smaller you can keep
the volume of unique code in your
service the easier it's going to be to
debug I was talking at the beginning
about how it's only 200 lines a lot of
our services are only 200 lines and
that's great it doesn't mean that we've
you know being profligate with a number
of services it means that we can debug
things with one screen of code which is
super useful so the last unique code
would be easier to debug and the easier
to understand and next we come to the
architectural principles first and
foremost get used to being asynchronous
many fewer things need to be
instantaneous than you believe you do
not need to be transactional about
everything
be as eventually consistent as you can
possibly get away with use cues
liberally both for input and for output
we use CouchDB which turns our entire
database into basically an event queue
which is basically the only thing that
couchdb is good at and that's an
incredibly useful pattern that I'm going
to talk about in a second and you should
also be handling back pressure when a
downstream service says that it is too
busy to absorb your requests right now
your upstream service should be able to
queue those up back off and say okay
I'll start sending these again when
you're ready because your architecture
is distributed and networks are
inherently flaky things you need to
expect that and you need to handle that
you need to detect a network timeout you
need to detect a network hang you can't
just assume that everything is going to
work the way that's supposed to you have
to expect that sometimes you know
Amazon's gonna have a hiccup and this
thing that you thought was an open TCP
connection it's just gonna hang for 60
seconds and gonna be like all right I
need to drop this because nothing has
happened so and when you've done those
things you need to recover automatically
you need to retry automatically you need
and once you're doing that you need to
avoid thundering herd's which is when
you have dozens of boxes that rely on a
service all of which have seen that that
service has gone away and when that
service comes back up they go oh thank
god and they all jump on it at the same
time and it goes down again they have to
be backing off they have to be expecting
that there's going to be other services
around competing for the same resource
so you should also be failing softly can
you serve stale cached content if your
services down a lot of the time you can
if you can you should you should fail
safely if your authentication services
down but there's some class of things
that it does that don't require any
authentication its failure mode should
be well this doesn't require
authentication anyway so I'm just not
going to ask the authentication service
sits down I'm just gonna go merrily on
sip serving this public content and the
last architectural thing is that a
distributed system has race conditions
it will have lots and lots of race
conditions anything that can happen out
of order will happen out of order and
stuff that usually takes one second will
take 40 seconds unexpectedly sometimes
people will try to publish the same
version of the same package at the same
time from 30 different boxes that was a
thing they were like when we designed
the system we like no and
we're gonna do that it's no problem that
there's a race condition about that
house with no no people were doing
exactly the same publish from 30
machines at the same time because that
was their build farm and every single
box in there built farm would try to
publish the package at the same time
we'd put like you can't do that you can
only do one public one package publish
of one version and the other twenty-nine
are gonna fail and they were like we
don't care which one I'm like okay I
guess we have to handle that now but the
problem with race conditions is that
there's no magic bullet there's no
there's no piece of advice they can give
you it's like and this will mean that
you never run into race conditions the
only thing you can do with race
conditions is be aware that it's nearly
always going to be a race condition
finally there are the operational
lessons we learned your configuration
should have a central source of truth we
tried it every other way before we tried
that way and all the other ones sucked
we use at CD to save our configuration
data at CD is itself a distributed
system so we cram all of our distributed
information to this other distributed
system and hope that those programmers
were better at distributed systems and
we were and your services should pick up
that configuration at deploy time not at
startup time and definitely not at
restart time
your service should only change its
configuration when you were explicitly
expecting it to because any kind of
system where you can push configuration
to all of your machines you're going to
accidentally create a bad configuration
and you're going to destroy all of your
machines at the same time a distributed
system doesn't work if this components
don't fail independently and if you have
a system with where all of your services
are constantly getting pushed
configuration or there occasionally
polling for configuration then you've
created the single point of failure that
is your configuration and getting it
wrong will take out all of your services
at the same time so as I mentioned
earlier deployment in SOA is constant
it's no longer this thing you do once in
awhile it's this thing that you do every
day whether you want who are not boxes
are going to fail frequently so you need
to automate the hell out of your deploys
we use ansible to do to automate our
software deployments and we are moving
to terraform to do the hardware
deployment as well which is a really
cool system so now you can just say okay
this system exists on a box of this size
and it has all of this software on and
I'm going to hit a button and it's going
to create the whole box and put all of
the software on it and plummet into
place with all of the networking which
is super cool and eliminates a whole
class of
at NPM we also find Canaria extremely
useful that is where you deploy new code
to production but only for two to three
percent of traffic because you have code
and you've tested your code but you tend
to test code with the data that you were
expecting you test code with the data
that you thought would be that you
thought would be there and the problem
with production traffic's is people do
really really weird things in production
people like yeah I know that you're the
your NPM but I was expecting a maven
repository so I'm gonna send you
thousands of requests for Java files and
see what happens we used to throw a lot
of 500s for misconfigured copies of
artifactory which for some reason
thought that we were a maven repository
so putting that putting the canary in
for 2 to 3 percent of traffic it means
that deploys take longer because we have
to sit the canary there for 24 hours to
make sure that nothing really weird
happens but it means that if we've done
a crappy deploy the worst that can
happen is we temporarily inconvenience
2% of our users and the other 90% of our
98% of our users don't notice that we
did that terrible deploy and there's a
one other trap which we found it crucial
to avoid
is cold starts this was the when github
went down last week for two hours this
was the problem that they were having if
all of your services are down can you
bring all of your services back up
that sounds like you should be able to
do it right but once you're running a
really distributed system where there's
tons and tons of boxes you get used to
them being there and you begin to
optimize for the case of deploying one
new service inside this sea of other
services you what github did is they
ended up with a service that was relying
on its Redis servers to already be up so
that it could start its application
server but instead there was a power
failure that took everything down at the
same time and so the Redis server
couldn't come up and the application
couldn't server couldn't come up because
Redis wasn't there and Redis was relying
on the application server to be there to
be able to come back up and that is why
they were down for two hours because
they had to fix that so to solve this
problem for us there is a tiny little
copy of the registry which exists only
to allow the registry to deploy itself
because if the registry is down you
can't install the node modules that make
up the registry so there's a tiny little
registry that only deploys the registry
and it's sat there for two years and has
been used exactly once in that two years
but that
one time was extremely important the
next thing is metrics metrics are
crucial to running an SOA because
there's so much more of your system to
understand and it can fail in so many
more ways so over time new hotspots are
going to emerge services that used to be
fast are going to slowly slow down as a
new code is added the poor the
performance characteristics will change
in other ways so you need to capture
everything that is going on in your
system like request sources and
frequency and size and your response
types and their size and how fast they
happen and just every type of event that
you can think of that happens in your
system you should just be throwing it at
some kind of metric server and once
you've got all of these metrics you
should be doing stuff with them and you
should be doing stuff with them in
advance you should be creating real-time
dashboards in real-time dashboards feels
like this sort of enterprise-e thing
that nobody really needs but the fastest
form of debugging is to be able to pull
up a dashboard of graphs and go whoa
that one has a huge spike in it that
wasn't there yesterday what is that
spike that is how we debug stuff about
half of the time we're like oh one of
the one of the pretty pictures is really
weird looking today that must be the bug
so you can do it that way you can do it
just by visual inspection but if you if
you really want to get fancy you can
start putting monitoring around the
normal values of your metrics you can
say this is the range in which this
metric usually exists and I'm just going
to trigger alert as soon as it drifts
out of that you don't have to wait for
the system to actually fail so that is
all of the stuff that we learned about
running an SOA and how to run an SOA
well and I figured that showing you how
that actually works in NPM is a good
idea but I left it in till last in case
the rest of this was overtime which it
seems it's not quite yet I have like
seven more minutes right so what is NPM
you'd think I'd have had to cover that
first but you all sort of you know just
winging it and PM's this thing in the
cloud NPM is four things NPM is NPM the
CLI the command-line client that you run
every day NPM is the registry the public
registry at registry at NPM JSTOR org
which is where the client downloads and
publishes of the packages and it's NPM
the website which we call dub dub which
is the primary NPM website where
everybody reads packages in
documentation and then it's read and
then there's NPM on-site which is a tiny
copy of NPM which runs inside the
firewall of big and hopefully price and
sensitive corporations fun fact we did a
poll yesterday and found that's
something like twenty one percent of NPM
users think that NPM just downloads
stuff from github all the time so if
you're one of those people now you know
we run a bunch of servers and they have
the tar balls on them and that is what
NPM is doing it's downloading them from
us I kind of want to want to run like a
follow up poll which is like what do you
think all of these people I hire do like
do you think they all run the website
because the websites not nearly as good
as twenty seven people would expect but
back to the architecture what may not be
immediately obvious from those four
things is that they're actually really
one big thing they're a single gigantic
service-oriented architecture which
shared services and shared logic and I
can show you how that works this is the
simple version you can see users talking
to the CLI on the website both the CLI
on the website users are CDN the CLI and
the website both use the registry on
site users hit their own copy of on site
and on site itself talks to the registry
here is the less simple version I should
be honest that this diagram is meant to
be deliberately confusing its file name
is shitshow it is accurate but it's not
even complete there's actually more
stuff than this in this diagram because
we tacked on a couple more worldwide
servers recently and there's a couple
services I didn't picture but I can
break it down for you first is the CLI
it's sort of arguable whether you can
consider a command-line client to be
part of a service-oriented architecture
because it's not a server right but the
reason I do is because there is shared
logic there's not as much shared logic
as we would hope in fact basically the
only thing that is shared between the
CLI and anything else is the bit that
validates what is the valid name of a
package but it is shared everywhere it's
the command-line client thinks that the
website thinks that the registry thinks
it and also the CLI is the largest
consumer of the registry so when you're
thinking of creating contracts between
the services in your service-oriented
architecture you have to think what is
the CLI going to do the most complicated
portion of our of our architecture is
the regice
three in simplified form it looks like
this with the bottom cut off there's a
CDN that there's a ton of caching which
is why everything is nice and fast and
all the cache misses go to our front
door service which is essentially a
router the front door calls the off web
service to authenticate every request
and a lot of interactions with the
registry are anonymous
so that's often very simple I was saying
earlier that if you can get away with it
just don't talk to your authentication
service and that is what we do for 99
percent of requests 99 percent of
requests are for packages that are
obviously public and will always be
public so we just don't bother to talk
to our authentication service which
means that it's our reliability is good
and our hardware requirements for that
service are really low behind the off
service is the access control list which
if you're not a public package it's like
which of the users is allowed to see
this and further behind that is the
license API which is if you are a paid
customer can you actually have you
actually paid for all of this stuff that
we're doing for you
continuing our lightning registry store
our lightning registry tour other is the
delightfully named validate and store
service which as you imagine validates
and stores packages it stores them in
two places in the binary store in the
metadata store depending whether it's
the package.json or the actual binary
file and the binary stores are literally
just you know computers with very large
hard drives that we went with lots of
other complicated ways that you can do
that and we were eventually like you
know file systems are really great and
they're really efficient let's just cram
everything onto a file system and put a
lot of replication and backups in there
and see if see if everything works and
it does if you're installing a package
then it's just going to go straight to
the binary store and pull it straight
out of there and send it through through
the CDN without talking to anything else
tacked on to the right you will see that
there's a set of services which are
relatively recent edition called the
followers I said that we use CouchDB is
an event queue and this is the followers
or what are using CouchDB is an event
queue they basically listen for every
single publish event every change to
have that happens to every package on
the registry and they look for things
whatever those things are that are
important to that service so there's one
called the credentials follower which is
unpacking packages and seeing if you
accidentally left your password inside
the package or an off token of some kind
this used to be a big problem with the
registry there were lots of people who
were accidentally had dot files in
side of their packages that had all of
their credentials and now that doesn't
happen anymore if the credentials
follower finds that you've accidentally
leaked your tokens it unpublished is the
package and it sends you an email going
hey you did that faint that was pretty
dumb there's also a tarball follower
like I said we're a really distributed
system and we had this problem which is
that if you publish a package that
package needs to go to all of the
servers worldwide which meant that
publishes the more worldwide points of
presents we added the slower the
publishers got because it had to copy
them not just to you it had to copy them
to you know the west coast and the East
Coast in Australia and Asia pack so the
tarball followers how we fixed that the
Tarbell follower lets you publish to
just one of the locales whichever one
you're closest to
and then the Tarbell follower listens
for that event and copies it to all the
other ones that creates obviously a race
condition where it's possible for
somebody in asia pack to ask for
something that hasn't yet reached asia
pack and we use some fall over logic in
the CDN to go if you can't find it there
try all of the other servers first doing
that made the registry publishes twice
as fast which was a pretty cool cool
thing to have done two weeks ago nearly
out of time next is the website and this
is where SOA really begins to pay off
because there's almost nothing new here
everything else here you've seen before
the only new things are the registry API
and elasticsearch these are two new
followers the registry API is following
everything in the in the database and
it's turning it into a relational
registry because couch is not a very
good database it's really only good at
being an event queue so you can't really
query it very efficiently but relational
databases they're really good at being
queried so we copy everything into a
relational database and that is what
serves the website the other one is
elastic search elastic search is another
database optimized for search and
there's a follower that fills it up with
stuff without having to do a direct copy
all the time I'm gonna go a little bit
faster now finally there is NPM on site
and this is where I get really happy
about s away because NPM on site is
literally a copy of the registry
architecture it's exactly the same
services exactly the same code just
crammed down into a couple of docker
containers and deployed wherever it is
that you want it to be which is great
because it means that when our customers
find problems in NPM on site we fix them
there and suddenly that whole registry
works better and vice versa when we fix
something in the global registry NPM on
site works really well and it also means
that we can be super
confident about the scaling abilities of
NPM on-site because until your
corporation is as big as all of the
other JavaScript developers in the world
NPM on site is going to be able to
handle your load there's a couple other
cool things going on that I'm probably
going to skip through because I'm pretty
much out of time I think so some
takeaway messages SOA is pretty neat
node is pretty good at SOA you too can
be really good at SOA and NPM is pretty
neat thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>