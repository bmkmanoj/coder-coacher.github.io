<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Best Practices for Developing and Deploying Java Applications with Docker | Coder Coacher - Coaching Coders</title><meta content="Best Practices for Developing and Deploying Java Applications with Docker - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Best Practices for Developing and Deploying Java Applications with Docker</b></h2><h5 class="post__date">2017-10-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LJNKYW6Qls0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well my watch says it's time to go so I
guess we'll get going thanks for coming
I am very impressed we got a full house
on a Wednesday afternoon usually but
this time at a conference people are
getting tired and hitting the bars thank
you all for coming my name is Eric small
I'm a solution architect at docker I've
been there for about three months now so
I'm kind of a newbie there but we're
gonna talk today about a very very
nicely long title that barely fits on a
slide and really barely fits in a 45
minute presentation so bear with me if
I'm going too fast tell me but we're
going to talk about best practices
developing your java applications with
docker and deployment so Who am I and
why am i up here on the solution
architect as I said which means I go out
to our enterprise customers and make
sure they're happy with our product help
them docker eyes their applications and
do all sorts of things to keep the
customer satisfied my background is
software development a lot of docker
guys came up from the infrastructure
side I came kind of came in the other
door I've been a developer for give or
take 25 years various things doing
architecture of version control branch
strategy all sorts of stuff Java C
Python whatever's needed the last ten
years of it kind of centered around
build and test automation and a lot of
the things that we throw under the
DevOps umbrella which is a term I hate
nowadays because everything that anybody
doesn't develop any more really but a
lot of that in Jenkins see I work see
ICD pipelines and while doing that I
discovered docker that was about 2013
2012 when it was really really raw it
was pre 1o days and we were using a lot
for making selenium testing grids stable
which is a job in itself
I've been around Java since before the
Java 2 days back in the early early days
when it was kind of a crazy tool to be
using but so I've been around in a while
haven't been doing much development
lately outside of Jenkins plug-in work
but still know a good bit hopefully
today's agenda before I go into this
actually I want to get a feel for my
room
what is your experience with doctor how
many of you are new to doctrine haven't
used it before okay how many are aware
of it you've tinkered with it on your
laptop but you're not really using it
professionally in your in your company
how many are using is like a first-class
citizen in your company you're using it
in dev tests QA what about prod okay
cool
it's a very good cross-section the first
half of this deck might be a bit of
review for some of the people to kept
their hands up but I want to try to get
info to everybody here we're going to go
a little bit over like a doctor 101 just
quickly then we're going to show a
simple Java web app how to how to create
an image for one how to run it in docker
we're going to talk about some of the
cluster concepts like services and stats
and how to deploy to them then we're
going to get into some more of the meet
of application management
troubleshooting your java app in
production well in any environment
really and how to handle application
configuration across those environments
and yes we're gonna try to get some QA
and let's go so some vocabulary just a
level set so everyone's aware of some of
the core concepts of docker there is a
thing called a docker image the docker
image is the basis for a container it
represents the full application it's a
it's a file system if you will or
collection of file systems really but
that is is - the docker container like
in the Java world of classes are to an
object kinda-sorta you define it you
define what you want your container to
be in that image and then when you run a
container it's based on that image the
container itself that's the standard
unit in which the application resides in
execute right so it's what provides the
isolation from container to container
it's we'll get into what it is more as
we see it more the docker engine is kind
of the meat of this whole thing it's
it's the the software that creates ships
and runs docker containers it's - it's a
binary that's deployable on physical
machines it's deployable on virtual
machines you can use it in your on-prem
on your laptop in the cloud it doesn't
matter where you run it
it's acts the same everywhere
and it allows you to run those
containers everywhere the registry
services out there are a kind of a
managed repository for the images if
you're again if you're coming from a
Java developer point of view this is
kind of like your artifactory nexus your
manage maven rep oh it's of course tuned
for docker images as the stage feels
like it's going to break there's the one
you're probably most familiar with if
you've done any docker work is docker
hub or Dockers store which is kind of a
cousin to it the docker hub is an online
repository with hundreds of thousands of
images out there some of them official
images some of them a lot of them images
that you or I might push out there
ourselves docker trusted registry is our
enterprise product that we provide for
your if you want to run your own
registry which most companies do with
their own internal software that
provides all the enterprise-e things you
want like role based access control and
signing of images and whatnot so let's
talk a bit about these in these images
and how they're made up so an image is a
logical file system that groups layers
together to present a unified file
system for the running container we
could better picture this in a few
slides but each branch in that that
image is a separate layer that's like
filters on top of each other when the
container runs it actually constructs so
that if you were to go into that
container and get a shell in that
container you could move around in that
filesystem just like any other file
system you can do your LS you can do
your CDs you can move around and see
everything when the container is running
99% of the time you will get a write up
a read writable layer added on top of it
the image itself is immutable once the
once you've created the image and you go
to run a container on it everything in
there doesn't change while you're in
there and actually I don't think I'm
going to my next slide as I say this it
uses a copy-on-write algorithm to say
okay let's I'm in this image I'm in this
container sorry and I want to change a
file that's in the image it doesn't
actually change the file it copies the
file into that read
lair that's at the very top makes a
modification to it now when you're
looking at it if you think of it as a
stack of layers you're seeing that file
instead of the one that was in the image
new files get added to that rewrite
layer as well the container itself then
honestly doesn't take up a lot of space
on your file system when it's running in
the docker host the image has size but
if you say hey three containers running
on the system all using the same base
image you're not going to if that image
does say let's say it's 200 megabyte
you're not going to have 200 400 600
you're gonna have 200 plus whatever each
container has added to it as their
rewrite layer just points to the top of
it if I'm this going to skip back and go
forward the next thing you want to deal
with with containers is if this image is
immutable and the files you're changing
on the container are just in this little
read/write layer when you stop that
container and get rid of it well so does
everything in that read/write layer how
do you persist your data most
applications I mean unless you're
writing a micro service that's a fully
stateless applicational you probably
need something from it log files are the
usual big one you want to keep your log
files if you're doing something like
Jenkins work Jenkins keeps all of its
state in file systems so how do you do
that well there's a concept called
volumes and they can take different
shapes and ways to use volumes basically
it's a way of saying I want this to be
persisted outside of the container file
system and you can mount it just like
you wouldn't mount a volume in a UNIX
file system right so to take that
Jenkins example there Jenkins home
directory if you're familiar with it
it's just a file on the file system that
all your state's getting written to you
would mount that as a volume you shut
down that container start up a new and
employment it at that same volume that
state will still be there so it persists
between you can also use volumes just
share files between two containers just
it's just like an NFS honestly guys so
these volumes can be created by docker
file which is how you build images or
CLI and I know I'm kind of flying
through this but we're
slow down in a sec this is what we call
a docker file this is how images are
constructed it's with code there's
actually two ways to construct an image
this is the way we would like to do it
there's a manual way using a command
called commit but this is this allows
you to construct the image as code and
then check in that code with your
application source code so it's
versioned code reviewed and you know
infrastructure as code kind of a thing
this example is a very very simple
contrived actually Java app that it's a
tomcat server that's going to take a war
file that's sitting on my file system
and deployed in Tomcat the first line of
any good docker file is gonna have a
from that's your base operating system
layer in this case we're basing on a
boon to 1604 every line in the docker
file other than obviously whitespace and
comments are instructions that you as a
developer you as a user would be doing
to get your machine ready to run your
app if you were doing it manually but in
this case what you're going to be doing
is you're going to be writing those
layers I talked about on top of the base
of bhutesu so here we've got you know
apt-get update app get installed you
into getting the open JDK curling down a
version of Tomcat and so forth so each
run is actually running that command in
a kind of an ephemeral container that
comes up does it and then puts it on the
image over and over and over during the
build process copy is another type of
line you can have that will copy files
from local file system where the builds
being run from into that image and
finally the last thing is a metadata
that it's added to the image file to say
what do I want to happen when somebody
runs a container based on this image
this is over rideable at the command
line but by default somebody runs my
image I want it to go ahead and run the
catalina sh run command now if you build
this now if you can see it in the back
because it's kind of low you would see
this made a 333 megabyte image that's
everything from the abouttwo filesystem
and up all combined together and it
would look something if you were to
conceptually write it as layers like
that so every layer above Ubuntu is just
contains just the Delta that was done at
that layer so the update app catalogs if
you were to look at that layer which you
can if you want to get into it you'd see
just app catalog related files being
changed the JDK and curl install you'd
see open JDK being installed and the
curl and of course the apps related
things that happen during that and so on
and so forth for instance at the copy
web app it's basically a one file change
the war file is getting copied in to
build these things that's a simple
docker command docker build and some
arguments and we'll look at that when I
do a lot of demo in a second to run it
it's another docker command docker run
some arguments the name of the thing I
just built and it will start up a
container on that image so enough slides
let's go ahead and take a look at this
really so here I am and I'm gonna get to
the right step
so I know this is not the easiest
projector to read in the back but we're
looking at the exact same thing you saw
in the slide I think the only difference
might be the Tomcat version has been
updated in this repo but I would do a
docker build I'm gonna tag it which
means give it a name if I don't it's
just gonna live with just a hexadecimal
address that I would never be able to
remember so we'll call this something
unique we'll call it job a one-sample
and I'll give it a version number lastly
I give it a path to where the docker
file and the context of this build is
going to happen which happens to be the
current director so I'll put it done
this is gonna be very fast because I've
done this already I don't want to wait
for it to do things if this was the
first time I had built this what you
would see here is as it goes through
each step sorry something's trying to
call me while I do a presentation each
step followed by output from it so the
from if I didn't have that already you
would have seen it gone out to github
I'm sorry doctor hub and pulling down
Kubuntu the next step
you see run apt-get update and again if
I hadn't done this gun my machine before
and it didn't have a cache of that you'd
see the whole output of you've seen
you've done apt-get update before
probably you'd see all of that flyby and
so on and so forth each layer is a step
being run here and finally at the end
you can see it's done it so I can do a
docker image LS it will grip for and
we'll do it right
of course I've got many things I've been
doing in my as I prep for this there's
one I just built though so 334 megabyte
image now I can also do a docker image
history on that and I can see the layers
and what happened at each layer to build
it
the missings this is what happens when
you pull an image from docker hub you
don't you don't have hashes for all the
piece of the layers that made up that so
it's just showing you from that's from
starting point now we built an image
that's fine
actually I'd go ahead and let's run it
docker run that means give it a TTY and
make it interactive so if you can't see
in the back of the same docker run - TI
- - RM means destroy the container when
I'm done with it I don't want to keep it
around for any you know post run stuff
and give it the name in the version and
that's it and what we should see but see
flying by is your normal Catalina start
up and if we hit my local host on the
8080 it can't be reached
nice why it happened because our
presenter forgot that when a container
runs by default it has no access there's
no network port that can get to the
inside of that container because it's
isolated so we add another argument to
expose port 8080 on my host machine any
traffic going to 8080 into the container
at 8080 run it again
refresh the page and we get there's our
standard Tomcat manager well I know that
the contacts sample and yes that's all
it is and I'm in my app right now now
when you build these images you can make
kind of make sense to you that layers
get built up right so we ended up with
an image that had going to plus all of
those things if you do that a lot you're
going to end up with images that are
huge and you don't want to do that this
is the first kind of a best practice I'm
gonna tell you right now you don't want
to have the world in your image because
first of all you're gonna have to ship
that around as you deploy to different
environments and if it's a three
gigabyte image that's gonna be a pain
for people now luckily docker does do
some magic around the layers and it
understands if I pull a Ledge and I
already have some of those layers let's
say I had a boon to 16:04 already he
wouldn't go get it again it would just
get the layers that laid on top of it so
it speeds things up that way however
each one of those layers contains
everything that happened on that that
line so at the end of that run that we
did the apps that the first there's two
layers in there that have a bunch of
stuff from apps that I don't need at
runtime don't care about it so a
practice you'll see a lot is people
Moulton making a run line as you see
down in the lower right where they
combine things and at the end they go
ahead and blow away anything they don't
want this is contrived this is a small
one but this is just an idea if you if I
did that right now to what we saw that
would shrink my image from 333 to 294
Meg a small decrease but decreased
nonetheless and the layers would shrink
down to that the next thing I could do
is like wait a minute I don't need a boo
- I don't need everything a boo - 1604
is gonna give me because I I don't need
anything other than what Java needs and
what Tomcat provides so if you switch
your base to something smaller like an
Alpine based OS which is if you're not
familiar you minded as little as you
possibly can it as small of a footprint
as you can have so that's you know you
don't have and could be exploited and
just that isn't there anymore
besides what's in alpine this is an open
JDK 8 image from docker hub that's based
on Alpine so it's Alpine Plus open JDK 8
and that's it and then if I were to make
a change there and then change the where
I'm getting curl from like that if I
were to do that build you'd see we
dropped 160 126 Meg now we're getting
some sizeable decrease now the layer is
the number of layers only went down a
little bit but the size of them what
does a lot
now the fully optimized version in this
case would be well you know what why am
i installing Tomcat why do I need to
manage the code that goes and gets a
copy of Tomcat installs it and and runs
it people have done this already for me
and it's a tested thing so there is a
tomcat image on hub an official one
that's a version 85 based on Alpine you
put that in there and your your dagger
file literally becomes two lines besides
the comments and your sizes all the way
down to 113 Meg and if we look at that
that's literally the whole thing you're
now saying I want the Tomcat those guys
developed and I'm gonna put my web app
in it and they've already got a command
in there their image that runs it or I
could override it if I wanted to so if I
built this I'm just gonna call it food
because I can type it fast
and of course I've built it before so
it's fast doctor run I'll just go up
here just to prove I'm not making this
up same kind of catalina start up and
we'll do a refresh on the page it's
there
you had obviously didn't work
and there's our manager now in your
company you probably aren't going to use
the docker hub Tomcat because most
companies have security policies that
they want to know what's in them and
they want a lot of companies want to
build their own bases that's fine you
can instead of using that one you'd use
my company's official Tomcat secure
guaranteed happy-go-lucky image from the
security guys either way for instance I
know that the build I just did because
of what version I'm using there's an
exploit than that Tomcat so we wouldn't
use this one we'd go do our own or build
or use another one now size is
interesting it's like okay cool we can
save a few seconds on deploy we can save
you know space on our hard drives but
not that big of a deal what's more
interesting really is if I go look I'm
using earlier this is my own docker
trusted registry that is our enterprise
registry and I built all those different
steps that we went through on the slides
and you can see the sizes going down and
these are smaller because they're
compressed in the server but take a look
at the vulnerabilities DTR will do CVE
checking of all the binary fingerprints
inside of your images and when we were
based on a boon to and we're pulling in
a bunch of other stuff we've had twelve
critical and thirty-eight major let me
grow that vulnerability is known in
those images when we drop to alpine we
dropped all the way down to four now yes
we would want to figure that out before
we went to production this is a demo so
I'm not going to worry about that right
now but just by reducing our footprint
if somebody did have an X found in that
find an exploit in Tomcat and the JDK
and got into your container there's that
many less things that they now can
attack and use use in an attack at
runtime so smaller images are more than
just size it's it's security okay
clone clusters so some more terminology
swarm swarm is a concept built into
docker engine as about about a year and
a half ago they rewrote swarm a used to
be an external tool and they brought it
in and rewrote it completely it is a way
of grouping your doctrine hosts and
connecting them and running them as a
cluster so that it presents just like a
large compute you know ap docker API
endpoint for you to run your containers
on it's made up of 1 to n managers that
figure out where or one you're in for
containers and workers to run them on
they can coexist a manager can be a
worker but you've got to have at least
one manager you really should have three
so that you can survive an outage of one
the managers share a wrapped consensus
group so to keep the state saying a lot
of big swarms will have five managers
just to make sure they can survive a
couple dying without going crazy when
you start talking clusters you're not
really dealing with just raw containers
anymore either we have another
abstraction level that we call a service
a service is usually what wraps an
application or part of application that
provides a specific function for
instance let's say you've got a
three-tier classic application where
you've got a patchy or an engine X or
something on the front doing your images
and and whatnot
you've got a tomcat or whatever web
server in the middle app server and then
you got a database on the backend each
one of those would be what we call a
service and it would be represented at
runtime with a container services have
some more metadata around them that the
swarm can use to understand where to
schedule them you can tell a service you
need to reserve this much memory you
need you can have services connected by
logical networks and a bunch of other
things you can do to for the swarm to
know where to run them how to run them
and whatnot a stack is the next layer up
and that is where you define if you've
used doc
compose the stack is the evolution of
docker compose it's where you say these
are all the services that make up that
application so in that three-tier
example you'd have three services in it
and you would also then be able to say
and these services the front-end can
talk to the web tier on a network named
front-end or something and the the
back-end can talk to the web tier what
are the time gets over whatever you call
it you can talk to the database but the
front ends can't talk to the database
only the app servers can you can specify
that kind of stuff you can specify all
of the memory things I just mentioned
you can specify CPU utilization you can
say that oh this service is special and
we're going to tag it in a certain way
so it has to run on machines that are
tagged this way so let's say you have
PCI compliant things and you've got a
cluster of docker hosts that are PCI
compliance so you only want to run them
over there some of this blurs into our
enterprise product where we have a lot
more role based access control around
that but it's the the concept is you
define your stack which tells you it
tells the system how the services are
wired together how many of them to run
so if you want to scale out you say I
need three of these running and then
later you want to scale up you can
change that number and it'll blow up and
make more if a container dies or an
entire host dies that swarm is smart
enough to reschedule any containers that
were running on that host to keep
matched to whatever you've declared in
your stack as far as how many replicas
of that service to run so I have real
simple one to show you here this is a
snippet of a stack file and again if
you've used docker compose it looks very
similar it's a simple j2ee app that has
a react front end and a Java back-end
each in their own container and you can
see here the way it's defined is you've
got services and there are two of them
in this case there's a movie plex seven
and a react client the images for them
are defined there and that's what tells
docker where to go get the image for the
container and what ports to expose and
what network to run on and in this case
network is kind of superfluous because
if you don't provide a network it'll
create a a default one but just to show
it it's on there
and let's jump over here
and there there that is so we're gonna
do now I've actually been running this
on my laptop and I have a laptop set up
as a single node swarm so we could see I
have one node in my swarm that's what
docker node LS is telling me list nodes
in my swarm that's it so I'm going to
tell it to tell doctor I've got a stack
that I want to deploy and it is defined
in Oh complete this docker compose file
and I want to give it a name I'm gonna
call it job j1 for Java one it's created
that dub-dub-dub network and the two
services now if we do a docker service
LS list the services we can see that the
react client has one replicator one
running movie plex hasn't started yet
probably is pulling from there we go so
it's probably pulling from my repository
and now we've got both running if I jump
over to the browser again and this one
actually hosts on port 80 there it is
running on my laptop so I'm a developer
I've created this we're happy that we've
produced this image we pushed it up to
our repository and now we want to push
it to a cluster now I don't have time to
show you know 18 layers in a CD pipeline
and a Jenkins server and whatnot so I'm
just going to kind of jump forward and
show you okay well all the things
magically have happened in QA is happy
we're going to go production now so this
is my cluster running out on AWS
and you can see it's a bit bigger it's
got o where it says manager status
that's got three managers and the rest
are all workers I'm in the same
directory I'm just going to do docker
stack deploy
the exact same file and we'll give it a
same name
now this shell is set up to talk to that
stack that's why it's not talking to
local looks pretty much the same right
so let's go over and we're gonna go
ahead and jump into this is the the
universal control plane which is part of
the dr. data center it is a fancy swarm
I'll just call it that allows me to look
at the services that are deployed easily
so there's the two services single
replicas of each I know the react client
is you know what I want to hit and I'm
sorry the fonts really small back there
it's kind of hard to make this UI big
and it's published endpoints right there
that we don't have to memorize the AWS
endpoint and now there we are running an
AWS so that's interesting let's do
something here let's do a docker service
command which acts on a service right
I'm going to say hey that react client
let's make it scale up there you go
let's have five of those so we'll jump
back over to my swarm viewer sorry too
big and we see it's starting up the
other replicas now so we've got four or
five and if I go look at containers I
would show me all my internal containers
sorry so you can tell up three months
with the company I don't know the UI as
well as I should so there we go so it
started up all of these and the app is
still running I can go ahead and hit it
again oops that's the wrong one that's
the one I want to hit what happens
though if that container if it's time
for that to die now I've manually
punched it and I said container kill if
I did that for the command-line it we'd
the equivalent of a docker kill kill
that container
well I'm gonna jump back to the command
line we'll take a look at that docker
service actually do a dr. stack docker
stack
show me the sorry dr. service it's
already in the time it took me to retype
that it already replicated and put a 5th
one back out there on one of the nodes
somewhere so anytime anything dies like
I said swarms gonna keep that running
now that's that's handy it's nice but
what have we seen here we've seen the
same container the developer used
running locally put I didn't do the push
in front of you because I don't want to
attempt to the network gods here and see
how long that would take that same image
was pushed out to my repository and then
run in AWS exact same container not you
know oh well that water file came from
him and it was built from this tag and
then we built it again from that tag
over here not some oh we deployed it and
the the machine over here is kind of
like the machine over here no the
machine is alpine linux tomcat alright
in the order comes sorry that was my
other one whatever linux this is using
exactly the same so how can we manage
these applications once they're out
there there's a thing called health
checks in docker health checks can be
declared either in your docker file when
you're building the image or at runtime
as part of the service declarations
there an instruction that is if you're
familiar with load balancers like in a5
or something you can say hey this is the
health in point check this every once in
a while and if it goes bad take it out
of the pool same idea here the health
check whatever you declare in that
health check will be run periodically
and the docker or engine understands
that and will show you if you pull up
lists of them the health status in
parentheses if it has a health check so
if it's not healthy you'd see unhealthy
and there are as many instructions you
can give the doctor system as to what
you want to do when a container goes
unhealthy might make more sense as I
show you the the arguments so a very
very simple one would be this make a
health check that is a command curl the
localhost and exit if it doesn't come
back with a 200 right
that'll get run I forget the defaults in
doctorates I think it's every minute or
so and if it fails for a certain number
of times you'll be marked unhealthy the
swarm will detect that and based on how
you've configured the service it may go
ahead and start a new one up and take
that one down because it realized that
one is dead and it's not coming back you
can change those configurations for
instance this example is saying on an
interval of every 12 seconds with a
timeout of 12 seconds and a warm-up
start period of 30 seconds meaning the
first time you bring the container up
don't check for 30 seconds just give it
time to settle run this node command up
sorry this node.js come in so this
javascript code will run every 12
seconds and it'll and the docker engine
will get the result back of oh it's
healthy it's healthy its unhealthy
kill it and again you can specify a
command line in many different ways of
handling that you can say go ahead and
bring it out of the cluster and leave it
so that will be in a dead State but we
can at least do some post-mortem on it
you could say shoot it dead and make
another one you can do there's several
different arguments you can do full
documentation on this is on the doc
Doc's docker
website in the engine if you just search
for helps health check you'll find it
also one of my colleagues Alton who's a
prolific blogger it's gonna blog every
day it seems like just wrote an article
on how to do really good health checks
that aren't just simple curls or in the
windows world iiw ours and these slides
I will be posting by the end of the week
I'll give you my Twitter address you can
follow that and you'll see when they get
posted so you'll be able to get all
these lengths I'll wait for the pick
Elton's a great guy to follow - he's
genius JVM and memory finally some Java
stuff right so this is the probably if
you take anything away from this today
as far as what to do about JVM apps
running in containers this is probably
the number one thing that we get the
most support calls on Java including
unfortunately Java 9 not that I have a
lot of experience with 9 but does not
really look at memory constraints and
CPU constraints aspect of what's that
what the container is limited to so when
you run a docker container you can limit
it you can say you only get 2 gig of
memory you can you can say you only get
one CPU or whatever when the Java VM is
running and it's figuring out its heap
space if you're not using - X MX to set
your heap space
she should be most you most places do
but if you're not it's gonna use the
good old you know either one gig or 25%
of the memory whichever is smaller but
it's the memory of the host not the
container because of the way containers
work it's not going to look at what we
call a C group and the C group is that
limiter now there is some awareness
that's been added in Java 8 131 I think
it was and Java 9 for some CPU related
stuff but it's it's not enough to not
worry about this it's a good idea to set
your heap anyway honestly so you should
be using the docker CPU reservations and
limits reservations allow the swarm to
not over schedule a box
so you could say start the server up and
reserve 4 gig
so whenever the swarm goes to start
another one up it's gonna look across
the cluster and look for some node that
has at least 4 gig available to give you
rather than to sing well I'll just start
it up we'll see what happens see what
the CPUs and everything else if you are
limiting your CPU there's another
argument and if you can't see it in the
back it's the - double X parallel GC
threads if you're using the parallel GC
which by default most people are it will
still set its thread count based on the
number of
CPUs on the box not what's limited in
the container same kind of an argument
so if you if you run a lot of Java
containers and they all have sizable
heaps those GC threads can start to
overload the machine even though because
they think they have all these threads
that they can be spawning and they
shouldn't be so those are the two main
things you want to make sure you're
doing in any Java app that of size
running in undoctored containers because
again the swarms gonna own is only smart
enough to know to put things based on
the reservations you've made and the JVM
really doesn't know that it's running in
a container
mostly logging this is the second
biggest troubleshooting and management
thing questions we get is how do we how
do we handle their logs across these
clusters they're a good buddy of mine
Andrew wrote one of our reference
architecture documents out on our site
and there's a short link to if you go to
doc early docker Dudley slash logging
it'll take you to his document it's very
voluminous it's very big very
encompassing but it talks a lot about
difference logging from both the point
of view of the server's and the
applications and the applications seem
to be where people have the most
questions so some highlights from that
that are a from that reference
architecture are don't output your logs
to the containers read/write layer that
slim layer I told you about the top it's
not very fast it's not the most
performant thing because it's doing all
that copy-on-write logic while it's
going and well plus if you put it in
there you're gonna have to either exec
which is a command in darker that lets
you jump into a running container kind
of like an SSH kind of sort of not
really you have you either have
permissions to get into a container to
see the logs or you're gonna have a
queue have to have access to copy them
out with the docker CP command and
that's just not scalable so there's a
few options there's tons of options but
the three that I've seen mostly used are
if it's if it's not a lot of logs that
your applications small service and it
doesn't do a lot of logging just send it
to standard out set up your log4j or
whatever you're using for logging spend
up to standard out those are easily
viewable with any docker logs command
you can say docker logs and the ID of
the container and you'll see every log
that's happened
to stand it out in standard error you
can also see it if you're using if
you're a customer using UCP the web
interface I showed you there's a place
in the web interface you can pull it
right up another one is to send it to a
volume and this is probably the most
common usage so a lot of shops already
do this on non-doctor as hosts where
you've got your machines you've got a
shared and a fests volume for all of
your logs to go to so you don't have to
give your devs ssh into your production
boxes same idea here you can mount that
in any one of a number of ways into your
containers and then send your logs there
it's the same process you're using today
for your non docker eyes job apps and
finally there's a bunch of logging
drivers that docker has that are kind of
a plug-in architecture if there's a lot
of them I'm not going to list them all
off here that's the list as of this
morning and the latest list is always
available on our website if you go to
Docs docker calm and look for the
supported logging drivers and my
favorite is none just thrown away don't
care but a few of these some highlights
about some of these if you have Splunk
there's a Splunk one you use it syslog
and Splunk are actually the two drivers
that are good options if you have highly
sensitive data in your logs because they
can be configured to use TLS for
transporting that data so you want to
consider that journal D I'm not a UNIX
admin the journal D is like what UNIX
admins used all day long for viewing
logs there's a journal D driver will
send all the doctor logs to journal D so
you have your application writing the
standard out and use this driver and
they all go to journal D this do all the
things you can do with journal D you can
do with them then if you're running an
AWS exclusively or Google Cloud
exclusively we have drivers for them and
I actually haven't used them but I I
believe at least the end of us will
throw it to s3 not positive on that but
it'll do throw it to one of the eight of
us storage and that means and finally if
you have a no-spill database somewhere
in your environment that you can store
the logs in there's a couple drivers
that allow you to do that and again go
to that reference architecture and he
talks a lot about all of these and most
of these points came straight
they're troubleshooting your Java app
really is not that much different than
troubleshooting your app outside of a
container with some things you got to
keep in mind so you're not going to be
able to get on an sssh generally into a
container so if you do have exact access
or if your admins do you can use that
tool to run your standard J stat if you
want to see your heap behavior or your
GC behavior you can J map do all those
things I don't know that I recommend
doing J map remotely pulling an entire
heap dump down but you could expose your
JMX ports and those service definitions
so if you are always using j console or
some other JMX compatible tool you can
make sure that those are exposed and use
them as you do today make sure your
health check sir are intelligent that's
kind of repeating what I said before
more than just hey let's that TCP ports
open well once you hit a webpage that
maybe does a little bit more checking to
see if the app is actually healthy so
that we can take it out if it's if it's
misbehaving if you've got third-party
monitoring tools check just check the
version you're using make sure that
their container I I'd say we're in my
lab but probably the container friendly
and what I mean there is there are a lot
of tools that you have a client library
that you load at part of as part of your
JVM as an agent and there's licensing
concerns then because some of them
charge you by how many hosts you're
running that on well a container to that
kind of a library if it's not been
updated to understand that it's running
in container is going to report pay it's
another host take it out of the pool of
number of hosts you've licensed so you
check with your vendor make sure that's
the case
and there's also docker specific
commands that are useful docker stats
and ANSI top I'll show you those real
quick are two pretty simple commands
docker stats will basically there's
gonna be it's reaching out to AWS to
pull all the stats across my whole
cluster right now it's kind of like a
top and my fonts kind of big right now
so you can see it it's showing every
container I got and all of the usage
stats for it see top is similar it's
just prettier I think it stands for
container top but
an application side and not as much of
the infrastructure so I getting that
will come back eventually it will go
back and look at in a second
we got application configuration Multi
config environments so there's ways to
have different configurations across
your environments and I'm sorry I'm
talking quicks I know I'm running out of
time build your artifacts as docker
images not as wall files or something
similar to have an image that gets
pushed down the pipeline that way you're
guaranteeing the same things running
everywhere build them in your CI server
that's and it's Stormin s trusted
registry to deal with different
configurations across environments
there's a few ways to do it
a common way is separate stack EML files
so you define a stack differently for
each environment docker secrets are a
way of putting credentials into the
docker system that are insanely
securable if I get to all talked about
in a second go look it up if we don't
have time application configuration via
volley mounts mount a volume that has
your application configuration files in
it's a different volume gets mounted in
a different environment or there's
third-party tools console has console
template which is very useful Joe and
has something that works just like it
called container pilot boy your own with
your own CMDB example of an environment
specific stack might be a prod one that
looks like that this is what we just
looked at and a dev one that might
actually have a sone database that gets
started using you know a known good copy
of the database and in Deb it runs
hitting that database and prod it runs
hitting this and you either because the
host name is movie DB as it indicates
there or you can feed an environmental
variable in to say hey your database
host in this environments this secrets
we're not gonna have time to talk about
secrets look it up there very awesome
you can store secrets in the swarm and
they are fully encrypted everywhere once
you're in there you can't even get to
them unless you're a container that's
been given the rights to read them so if
you put a secret in there and you want
to know what's in that secret I can't
tell you you have to have a container
that's allowed to see it
look look into the details on the docker
dock site on on Secrets
volume mounts we kind of talked about so
don't store your secrets in property
files ever ever ever
but mount different volumes across your
different environments and you pull your
configurations off that and there's a
bunch of links so there's the login
stuff I talked about there's really good
training at training Gawker comm the
self faith stuff is genius it gives you
right in your browser a full docker
environment it's not a demo it's not
like you limited it's a full docker Cee
Edition that you can play with with
tutorials there's both tutorials for
developer centric people at operation
centric people or Alucard all you know
all sorts of tutorials that blog at the
bottom I added is just an interesting
blog I ran into while working on the
slides
square pasted earlier this year and if
you have Java apps that you're trying to
modernize and get into containers and
you're having trouble take a look at
docker comm slash MTA it's the big one
of the big pushes we're doing at the
company right now to help companies do
that modernize them and get them into
docker and then you can start carving
them apart if you want to make up micro
services later and I think I'm a couple
minutes over but that's what I got if
you want to follow me and mess I will be
sending the slides out if you have any
questions I'll be outside I'll probably
head out to the open area out there you
guys I can't answer them here I'll give
you my card you can email me I'll get
you somebody who can or tweet them to me
at that address thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>