<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Practical Continuous Deployment in the Enterprise | Coder Coacher - Coaching Coders</title><meta content="Practical Continuous Deployment in the Enterprise - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Practical Continuous Deployment in the Enterprise</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pGVfdx6ZXdI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone my name is Steve Smith
I'm from atlassian some of you may know
us primarily for a lobby will know JIRA
and also some of our other tools so my
background is that's I have been a
company for a long time eight years and
I've worked in a couple of different
areas of the company which i think is
kind of call the company to let me do
this and all the guys i've been one is
in a second originally joined back in
the original days of the company as the
original sysadmin in the company
although my background was originally
development i've also since then moved
on to back to development on our
internal systems as it was called Dennis
now called business platforms and we our
job was to build the ordering systems
that some of you may have used if you
ever bought JIRA confluence or any of
our other tools this is the systems you
would have interacted with the this
isn't kind of important because a lot of
money passes through these systems and
we're we're very concerned about
integrity and I want to talk a bit about
how we've ensured that integrity and why
doing some practical aspects around that
with regards to continuous deployment so
another cool thing about this is as well
as I've worked in in both the Sydney
office and the Amsterdam office which is
when you're newer ones and it's kind of
the company's or let me move around the
world and try different places and come
to things like Java one which is kind of
kind of cool now it's is up there not
too professional speaker as you're
probably going to find out but a funny
thing happened on the way to Java one
today is why first real day on a new job
where I'm at with the development
advocates team and our job is to reach
out and educate and helping
prove the processes around development
and the development tools bamboo stash
we're very big on adopting get at the
moment and I'll talk a little bit about
that so this kind of fell out of doing
some talks to you user groups in this
spirit of the lat do you know the
elation motto or one of them is open
company no this talk was
originally desire for user groups the
sum of our our user groups occur locally
I recommend going along to them they're
really good fun and this is where we can
discuss our products and tools with
their real users on a one-to-one basis
and we get some of our developers along
there I'll support guys who know a hell
of a lot about our stuff so this there
will be some mention of our commercial
tools but this is not a sales pitch and
in particular all everything I'm talking
about here applies to a lot of other
tools of course you know if you want to
buy our stuff would be very glad if you
did so based on that I'd like to have a
little saucier in the room how many
people here are developers cool how many
people here are in operation since that
means anything like that for a few any
management here cool so we'll cover
different aspects of this one of the
area's this covers is the this new idea
of DevOps which is really an old idea
which is what we try and turn around the
original idea of DevOps was or failed to
be cooperation between developers and
operations and move and the idea that
there's no sort of war between the two
breaking down the silos is the term used
and there's a lot of stakeholders
involved in continuing in continuous
deployment and one of the area's we've
had adopt is how to deal with the
difference of all most often conflicting
requirements of different parts of the
organization when doing continuous
deployment
and continuous delivery and so we're
going to so this is also tries to cover
some of those areas arm unfortunately
every company is different there is no
simple answer to this so but I would
like this in particular to be not so
much me standing here and give it
telling you how to do things because
every company is different and every
continuous deployment setup has to be
different to deal with the problems
inherent in each organization or the
problems you're trying to solve by
taking this adopting this methodology so
please feel free to heckle question
and/or generally in the arm interrupt at
any time and there'll be time for
discussion afterwards as well hopefully
so what this could this talk comes out
of is a project I was put on to not long
after i joined the amsterdam office of
converting our order systems i mentioned
to continuous deployment it took longer
than you'd think theoretically this is
simple there's a lot of tools out there
now we sell 1 i'll talk a bit about some
of the ways we support that a bit later
but also there's a lot of questions need
to be answered and some of those are
practical and i'm going to try and dress
those and some of those are
organizational and i'll address those as
far as possible and highlight some of
the areas you might have problems with
this in so before we start up with like
to clarify what we're talking about here
there's various shades on a spectrum of
continuous deployment a continuous
integration continuous integration is
the automated build and test this is
bamboo does this Jenkins does does this
you can do this with scripts and that's
how originally how agile did this the
idea of you constantly build of course
an original agile manifesto they talked
about building every day of course now
we talk about building multiple times
per day in fact on every commit in fact
we do this on branch levels so we're
literally running hundreds and
the bills at any given time and i'll
talk about again about ways of
automating that but the base level you
can do this with a bunch of scripts
they're just constantly checking out of
gear subversion with it or whatever so
but continuous integration is about
testing initially unit testing but also
for us and hopefully more organizations
increasingly it's about different levels
of testing so you can start with unit
testing as we did and we moved into more
and more integration testing not just
testing the individual modules testing
the modules together and then various
servers bring them up bringing them up
with real databases that's always a fun
one to do actually firing up postgres or
something and actually running against
that and uncovering as much areas of
testing as possible continuous delivery
is comes from elf from that if you have
good test coverage and you trust your
tests theoretically at any point you
should be in a position to release the
code now it's a little bit more
complicated than that because work and
be in progress about ideally you would
keep that works separate and again I
will discuss that in a bit on how to do
that but the idea is you're constantly
beliefs ready if Suzanne ran tomorrow
and said we want to release you can do
that whether that's necessarily the best
thing to do at any given point then
that's is you know open question that's
up to your product manager but it should
be at least in a working state now this
is this idea generally comes into with
cloud software but you will also see
this to a degree with desktop software
some desktop software will do is form of
continuous delivery into by having early
access releases and we have something
similar as well we are early Developer
Preview so you can get access to the
pre-release versions continuous
deployment compared to delivery is the
final logical step in this if you're
ready to release all the time why not
release all the time why back batch up
dozens hundred
it's thousands of changes and then dump
them out all at once why not release
what you have on a regular basis now
that can go on a spectrum in itself as
well so on one hand you can say we're
going to release every week we'll just
take whatever is there and we'll release
within this release window women can
bring the system's down to the extreme
cases and some people do do this we're
moving close to it on our team is where
every single commit ends up out on the
search server in a constant flow now
that's extreme and that doesn't work all
the time it does necessarily work for us
we're still working through the
processes of this but it is possible and
people do this etsy do do this they were
they were they release 20 times a day on
average i believe and they're really at
the bleeding edge of this this
methodology etsy have a really some
really cool blogs so we're going to read
them there they are good quite good one
to follow Netflix do a lot of this stuff
Netflix really are there they're at
their they're beyond this now they're
into a whole other area where they're
basically they're running they're
constantly feeding information or
releases out into the system and
actively breaking their own systems and
they I heard an interesting story
apparently no one can keep up with
Netflix at this point in terms not even
in terms of keeping up with their blog
posts power IBM have a guy whose job it
is to keep up with Netflix blog posts
analyze what they're up to so they are
they are so far ahead at this point
whether whether they've gone too far is
I is up for discussion but they're doing
some in some some interesting stuff out
there so the idea is and there's a
common theme to all of this you have you
do QA and you trust your QA that's the
hard part and that's the hardest problem
biggest fit change it change that we
made and this is something for us
continuous delivery took what is not
something that took six months as I've
just said really it's something that's
taken about about three years when i
joined the original team we had a
30-percent code coverage of unit tests
I'd be embarrassed by that but
I was talking to people today and
apparently haven't even got you unit
tests on that system yet there is all
talking to us about how they get can
actually get that over time we've added
integration tests full functional tests
selenium automated systems we're moving
into staging servers are separated a
test contractual test for AP is that's
always fun so if you eventually have to
get to a stage where you trust your
systems and you trust your test in
particular you need to know that when
you change some something that isn't you
can push that out there a high degree of
confidence I'll talk a bit about that as
well about ways that we we do that not
just in terms of testing but in terms of
constants perpetual QA so to go back to
a the original idea again is why would
you do this at all is a very good
question you're going to get a lot of
pushback inside your organization's if
you want to do this and people are going
to say why are you doing this what's
there there's a risk what's the reward
and that is a very good question there
is it's not something is this is be
taken and taken lightly the bigger odds
because answer for me is this here in
this hit hit us was releases need to be
automated they should always be
automated if you've got a human doing
something that computer can do you are
going to eat it is you're eventually
going to break things anything that is
repeatable should be done by the
computer and for us we really want to
drive this automated one click very
simple simple releases it was also about
organizational issues as well we are
having a problem where okay you're
releasing once a week you schedule time
with the sis admins and sis admins do
the releases if you're releasing every
day you're getting very hard time
getting a sysadmin time and more often
you release and the sis happens are
doing this manually although we had a
various scripts in place it's
not a great way to to work and it
creates lots of attention that we were
having to slow down our release
processes because we were not able to
get this app in time if we can automate
the this process that's obviously a big
improvement but there's other people in
the organization who are going to go
well what's in it for me this is this
quite interesting and the sysadmin one
in particular is kind of is kind of cool
and I will expand on that a bit the
quote so the customers is kind of fairly
obvious if you got a request for a new
change to the system so for us our team
they want a new pricing structure for
jira or something there they are going
to get it sooner if you're leasing once
a month and you miss that our release
window then you're not going to get it
for another month if you're leasing
every day that's fine you can deal with
that you leave if you're releasing when
it's ready then that's obviously the
best for management this is actually
very good as well predictability is
something the managers love and I think
this is really why a July adopted so
well because it gives you much more
predictability if you're doing if you're
doing it right sure to release cycles
sprints you're getting constant feedback
about what is going on how your release
cadence and your your devil or with what
we call dev speed so management love
this if you'll release concert releasing
stuff out there you're getting results
back faster particular things like
features switches you can get new ideas
out there fast as well you can you can
go let's try this let's try this one so
it doesn't work and roll roll it back if
you've got a if you have to do that wait
wait a month to roll back or make a
change that's not really possible for
devs and then this something gets
doesn't really get highlighted very much
it was very much from a personal one for
me is I hate death marches and I hate
that constant grind you've got a day
you've got to meet that that date
there's a there's a release window in
two weeks you've got to get your stuff
done or you're going to miss it and then
you're going to have to wait longer and
your managers going to be breathing down
down your neck
if you get to the stage where you can
say okay I'm not going to meet this
release window who cares there's one in
24 hours time that's a lot better these
things become no no sweat and if you're
doing it constantly you get good at it
as well it's again as one of the the
agile I ideas is that if something's
hard you should do it more often and if
it and then it becomes easier it becomes
automated so that's going portent and I
personally hate the death march aspect
of the industry and it's nice to be able
to go we don't have to do that if you
miss a window let's find the window is
tomorrow or in a couple of hours or when
it's ready or and also if you do if you
do have problems you roll them out into
production then you can roll the back
fast as well so i think is really good
since that means are probably gonna give
you the biggest push back of all they
often don't like this and as having been
assist admin i can entirely simplifies
and alas excess i've been also mean up
operations in particular what's cool
about this if you take it to the extreme
level and i'm going to talk about this
particular extremely level we're working
towards is that every release that you
do contains one change and one change
only that is a powerful powerful concept
because if you're doing ops well and ops
is getting better and ops is improving
and options getting tools right now
DevOps in some ways is driving and a
whole set of news of the tools and who's
their practices there lad gives you high
visibility into your systems that every
single thing is graphed again X you
doing cool stuff with this like stats d
you can basically just create new
metrics on the fly and you can aggregate
them in new ways users developers
everything kind of pull up their own
view of what's going on in the systems
so if you roll out a if you write a new
database dryer driver a dependency and
at the same time you're rolling out a
change to your hibernate code and the
same time you'll roll roll up rolling
out a new query or
new API and suddenly the database load
spikes what happened well now you're
into either digging through tickets or
digna through commits or you're going to
extreme cases using things like git
bisect to find out exactly what we're
what the individual change was but if
you rolled out one change of one change
only Steve modified the hibernate query
and suddenly the load spikes right at
that point and you can actually inject
this information into the systems so the
cool thing we can do where when you do
the release you'll actually tell the the
monitoring systems and the your graphing
performance systems a release occurred
at this point and even tagged it if you
look at your graphs release spike in
performance or quit queries or disk i/o
or whatever then suddenly you know
exactly what's happened because only one
thing went sour out there there's one
branch and you can roll that back or you
can decide to roll forward you can make
an intelligent decision about what
you're going to do you're not going to
madly roll back half a dozen change
changes because you don't know what's
going on is going to take you three days
to find out so sis admins and ops love
this if it's done well even if you don't
do that stat every single feature the
individual change is a separate release
you still the smaller that window is
less craps going out ever nothing has
been on that horrible death march
project where you just dumped six months
or whatever the hell was done at any
given point out to the cust customer and
it's not a great way to work this gives
you visibility into what's going on by
having fine grain releases so I have
gone backwards
okay so how do you actually do do this
stuff so a lot of the discussion about
you see out there right now is still
very much focusing on high level stuff
that I've really just covered there is
how why do you do it do it and a high
level what are the benefits of it but
what I wanted to do really is talk a
little bit about the actual nitty-gritty
of doing it starting or maybe a bit of
the process around it and eventually
actually the tools that we are
personally using although they are not
necessarily what you want hopefully at
least raise the order the questions to
help you answer your own particular
problems so I want talk about
development workflow this is
particularly good because I actually
because I didn't skip Oh over this bit
when I talk to other people because it's
mostly operations tend to turn turn up
to a lot of user groups so it's good to
have some some devs in so clearly when
you're dealing with this kind of
workflow you need to have a different
development workflow as well if you're
going to be releasing so you need to
know what's going out you need to have a
fine-grained process in terms of what
changes are being made so you go if I'm
releasing I know exactly what I'm what
I'm releasing you and this is an area
where get really helps I'll talk a bit
about that I'm calling this release by
feature I don't know where this an in
the industry term or not it's something
I made up on the flying little man
manifesto I wrote about a year and a
half ago and it's what we're gradually
working towards but at the base of this
is this is you need to have a clear idea
of what is going to be changed so you
need to have what some a common tag that
you work through if you at the end and
you say or we've just deployed version
blah blah blah out what was invert that
version this where we use we use tickets
for this and this is not something we're
particularly in vented you can even see
this with Mozilla or Ubuntu use this
idea of every single time
ask has a ticket against it so we
obviously use JIRA for this so every
request and every individual piece of
work everything that's going to result
in committed code or all changes to the
system should have a ticket against it
these can be grouped into epics you can
release it you can lose a whole epoch in
one go if if if necessary you want to
make your work more fine-grained and
your commits but you should absolutely
have a single ID for the change is going
to go out now obviously for us is just
create a dirty ticket that's your unique
idea use that end to end and that
enables in our tools some cool
integrations but i'll cover clothes
towards the end so this is where get
comes in how many people using it cool
how many people are using subversion or
something else right get off it
seriously I I loved subversion when it
came out because compared to CVS it was
an absolute godsend you knew wheelie she
knew what you were committing and then I
lost tons of code to subvert version was
less enthusiastic about it though you've
know the early days you had to done each
version of subversion was incompatible
with the previous version of subversion
and you had to dump and if you lost that
binary version you it was dead so but we
are pushing it hard because we believe
this stuff for the future of it in
particular its ability to branch is very
very powerful compared to subversion in
particular when we rewrote running
subvert version we didn't really use
branches because after a couple of nasty
experiences I imagine most people here
have had probably something similar
where you've created a branch is lived
for more than half an hour and suddenly
you cannot be merged get does not have
this problem and it's get is not it's
not magic you're going to get merged
kamote conflicts and so on and you can
get some into some tricky situations but
guess you can solve those problems you
can't redo with subversion we we are
have a bunch with information on our
website I don't to segue into a get talk
at this point we have a bunch of
information on our website about
moving to get and I recommend having
read of that or any any of the sites out
there to talk about that by this and
play a very it was it was an absolute
godsend for us we start adopting it and
people on our team were actually hostile
to it till he started using it and then
they went ok actually this is a better
way of doing it you you actually know
you know what you're doing at any given
point you don't really know that with
subversion and particularly trying to
merge so so we welcome on Bronk branches
exclusively in fact you cannot commit to
the main branch the master branch trunk
in subversion terms so you create a
branch and you work on that now we tag
that branch with the jira ticket ID that
i mentioned at the start now there's a
cool integration here don't say don't go
of just into a cig into a sales pitch
here but we do we dis enables some
really cool integrations between stash
and bamboo and JIRA that allowed them to
sort of communicate with each other and
about information about a state of the
branch that as is relevant to them so
JIRA is interested in if it's been been
committed and so on so you will only
merge that branch when it's fully
complete and that II and we have rules
around that the rules are that you must
be a you cannot merge until all your
bills are green and you can't merge
until you've got a code review against
it again we use stash for the code code
reviews that other people I doubt
talking w again the Garrett and other
tools but we obviously first dash it has
some nice code review aspect of it but
there are rules around our merges that
say you cannot merge until the bills and
all tests are passing and it goes back
to your trust in your tests again if you
don't trust your tests this isn't going
to work so you can definitely move
towards that but and then you have code
reviews so someone else must have signed
off on this and at that point you can
merge as appropriate
so to talk about that testing again you
need to automatically test your bra
branches as they created so what we we
do are you using bamboo I'm sure this is
possible in other tools as well every
time branch is created the main tests
are copied to the to a new branch build
and that is automatically triggered so
the moment you commit and push that
branch out onto your server you're it
gets picked up a new plan is created and
starts testing so as your they are
working away on your code you're
committing you're pushing then your code
is being constantly tested and we run
the full test suite now that takes a
long time but we are exceedingly parent
paranoid about this sort of thing now
you can do is paralyzed certain tests
you can chain them and say well you unit
test first none of unit tests pass then
you want to integration test and
successively longer running tests so you
fail fast on the testing but at the end
of a it's about running the tests so
what happens is you're constantly
running these tests and as your work
working you have confidence that what
you're doing is not going to break the
main branch when you come to merge that
change so again this feeds back into if
you can feed this back into your get
system or your your version control
system and let it know that it cannot
allow the merge until the bills are
passing then that's obviously a major
benefit as well again code reviews this
is necessary as well co does not exist
in isolation code exists in in
conjunction with human beings who use it
and who wrote it so one of the things
that we promote internally is code
reviews and every single branch before
being merged has to have a certain
number of code reviews against it the
way we do
is it obviously just sorry to say way
bank backup and interesting about about
this a lot of people really hate the
idea of code reviews because they will
go back to they were kind of forced on
people from higher up in management for
us we adopted them organically because
they give you something that's very hard
to get particularly dealing with highly
critical systems which is confidence and
the ability to sleep at night something
we've all been been there we adopted
internally because we would make a
change on this this system so about
eight hundred million dollars as
password or code that we write so we get
very nervous we are changing that core
code so if I'm making a change on stats
mythical or you know theoretical change
the pricing and are making on this code
on working on right now and it's
touching some of the core business logic
I'm quite knows but like I'm very good
at the business logic stuff I i'm good
at code i'm good architecture but i'm
not very good at understanding how does
fit into the larger organization isn't
well I think however there are people on
a team who are very good at that so for
instance i was making this change i
would create a code of you and pull in
Allison Allison really understands the
business logic very very well so I put
her in and say look I'm changing this
can you review this she'd look at I can
go have you considered this that and
that and I go out right small change bit
more garlic guarded handle a corner case
better whatever and then suddenly I'm
more confident than what i'm doing is
going to work and it's not going to
break things when it gets out there so
we end up adopting code reviews
organically and without really any one
pushing it down from us a lot of
developers really don't like code
reviews I'd strongly recommend looking
into them again because they really do
give an ease of mind that is often
missing when dealing with critical code
I was talked about this briefly this is
the testing in
I mentioned you can see that there are
certain bills are green and you can see
what's going on in terms of bamboo it's
feeding back into stash but I don't want
to drag us into a sales pitch so on if
you're doing an extreme version i'm
talking about about and we are moving
towards this what you do once all
reviews and tests are complete then you
would merge your bills Go Go Go Green
your people have signed off you go in a
new I've Emmanuel emerge or press the
button in stash to merge and that puts
it onto the master branch at that point
we have a separate bamboo plan that will
do the release for us it's maven release
prepare release perform we have certain
agents which are capable of doing that
they have the necessary setups in May
maven settings.xml to perform a a
release at that point it will just do a
complete rebuild it will rerun all tests
at that point because obviously when you
merge the master you don't you want to
make sure that what is going out has
been fully tested as well not just
trusting the branch to merge completely
at that point it will do the full
release and that gets pushed up to nexus
for us but whatever you're using but
will push out Nexus but also will pass
the the artifact around between
different build processes as it goes for
the release process what we do
automatically and without any human
intervention is then deploy this out to
our staging servers that gives you the
the next level of testing which is the
human testing so will often go to the
customer in question this has been
released the staging can you go out
there and check that it's what you want
that's more in terms of more you I level
change changes but this is when you
would get the humans involved so what we
do is promote we
have these idea of a golden build when
you create the war or to be pushed out
or set it was in our case they need to
be pushed out of it various deployments
then we it gets the same one that is on
the staging server it's promoted up to
production wheel into a separate bill we
don't do anything anything else so sorry
so we have a system of promoting so you
what is all what are staging you press a
button it goes up this is we go we're
bamboo has this idea of environment and
it has the concept that a bill goes
through certain processes or certain
stages goes from dev to production to
soda staging to production and the ends
goal is getting down to production but
you can at any point roll back to a
previous release again you need to
automate this and I'll talk a bit about
how this automated process occurs at the
end but this is not true continuous
deployment as as I've described it there
as in we do have a final stage this the
promotion from staging to production is
involves making a decision in some cases
people leaving don't do that i think
etsy for some of their systems will
literally just roll out whatever is
currently is there they trust their
testing systems that much and
particularly a trust toss it's just
their monitoring systems that much as
well that's it did anyone would see axl
Fontaine's talk this morning yeah he
talks a bit about one summer here so i
don't go into too much detail he talks
he talked a bit more about the how of
what i'm talking about here which is if
you're releasing 10 times a day or even
every day what about the down down time
related to this this one reason why did
this this final sprint to continuous
deployment took six months for us
because our systems will not fully
clustered at this point we were doing
releases about once a week and and being
in Australia that's a convenient time
time zone for us we just doing them on
monday and the rest of the world is
pretty much asleep well if you're going
to start releasing every day or even ten
times a day or 20 times a day in extreme
kate cases then you're going to have a
lot of doubt down time around this so
really if you're going to do this
properly you need to have highly
available systems of clustering we
rolled out we're using hae proxy and we
suite with multiple back ends and we
switch between them we will bring one
out the cluster upgrade it bring it back
in take the other one out etc I said I
don't go into my into this too much
because it's very it's a complex project
a question in of itself axel farm flop
contains talk today was quite good about
this and talks about things like blue
blue green they date database
deployments and so on which are again a
tricky problem around this as well
anything about again automation of this
is very important and we do have we do
you some tools and I'll talk about those
in a bit now this is the bit the car
really inspired me to talk about this
because this is the question nobody ever
really answers for me is how you
actually get this stuff out onto sirs
servers now this is going to be very
much depend on each person's
infrastructure but there are some common
questions you can answer that will help
you decide how to do this bit so I call
this the last mile which is the it's a
telecommunications term I don't feel for
how familiar you are with that which is
that it's very very easy to get dates or
telephone calls from country to country
getting them from the exchange down the
rows to your house is really really hard
and this is this affects the internet
and everything as you can need to
deliver that last section this last mile
is always a tricky put trickiest part in
any system so we have to get this
release out onto a server sometimes
through firewalls sometimes through
socks compliant or PCI compliance
sections
from other systems which or the
development you're talking about your
development environment in some way
talking directly to your production
environment so you need to be careful
around this and each organization will
have a slightly different way of doing
this I'm going to talk a bit a bit about
how we've sold this particular issue
there's a couple of different ways of
doing this now the sis admins he'll will
probably be more aware of what I'm
talking about here which is a puppet and
chef or tools for configuration of
servers and deploying them there a way
of saying that these servers should have
this software install configured in this
way and it should be the same across all
servers or all classes when you first
come to do this this when you're talking
to your sis admins about this they'll
probably their first fort will be let's
use puppet and chef to do this sorry the
problem is if you're doing a clustered
environment which you absolutely should
be then it's very very hard to time this
puppet and chef are not really designed
to have timing involved there a
decorative system they said you state I
wish the server to look like this how it
gets to that state is entirely up to
puppets in the one that I'm most
familiar with you don't necessarily want
that you would want to say I need these
servers to be upgraded in this order
only and that each step along the way I
need a set of operations to be occurred
before and after for instance to bring
them out at a load balancer and put them
back in to load balancer I want database
operations to be performed as part of
the upgrade so Papa tionship did I have
as a fort experiment I've kind of worked
out how you might do this with puppets
are I gave us a very headache doing so
so I probably would not recommend taking
us this path however it should really
its own up there really its completeness
because it will come up in a discussion
if you're talking about doing continuous
deployment the next one is you can do
this yourself which is like just
scripting as we all learned we've been
been following this last week or so bash
scripting has its own little sets of
problems as well and on black magic
there's a very nasty vulnerability when
it came out in bash it turns out to
affect lots of things you would not
think it should be affecting as bash
scripting is he is a tricky beast you
can do it you can also in bamboo and i'm
pretty sure in other servers you can
just run scripts inside your a your
agents doing the build because i do to
build right run this script that will go
off and ssh into various servers and so
on and you can do that arm i would
personally not recommend it but there
are other tools you can use that are
designed to solve this problem at a
slightly higher level there are a lot of
them we happen to use some compensable
but i recommend investigating what's
best for you and your sis admins will
hopefully be able to help you with
choosing one another way of doing it
that we investigated was the hand to use
the aging itself so your agents and
you'll build agents just be clear boot
buildings in this case i'm talking about
bamboo I don't know what the equivalent
for other tools is but you spread your
load you build around the system so
there's tools are there who's little
asian today's job it is is to pick up
and run code on your behalf so the
question is why not use those to do it
so you can for instance put an agent on
each one of your servers and have the
agent do the upgrade for for you these
are necessarily particularly secure it
depends on the on the tool of what was
using SSL or other encryption through
firewalls where firewalls even allow
this depending on the transport
technology day using magnetic we have a
pass through a firewall in a reliable
way we really look into this and it also
suffers from the same problem that took
about four of being having ordered
operations these
london systems are designed to occur at
a coordinate with each other they all
eternity or generally autonomous so it
works for a single node app if you have
got one thing that's not particularly
critical you could possibly do do this
and say put an agent on there could find
that agent only doing the upgrades and
then just push that upgrade out onto the
agent but I don't finger really scales
very well there are other agent based
systems so some of the tools I talked
about before capistrano would be one I
think saltstack might work this way is
you have these tools are designed to run
commands on your behalf on remote
servers but in an automated way but in a
coordinated way so you say you want to
run clean up the temp directory when you
want to want to run it on 200 different
certs servers then you can have a right
a bash scripts to do it or you can use a
tool that does this for you and you can
have classes of hosts and does a lot of
the organization for you so the these
are fine except your back to this
security issue again I is what you are
the communications between the master
server and these agents servers are
executing the commands on your behalf at
least secure I think I pass through
firewalls reliably so on and so forth
they require a set amount of setup as
well you better get them out onto the
servers in question you've got to get
the sis admins to do this for you there
they have their head there their place I
would not really want to do this because
it they are going to be very susceptible
to changing network topologies and
changing operating system stacks and so
on again this is similar SSH keeps on my
transports SSH is always there or almost
always there unless you're dealing with
ex servers which you should be deploying
to anyway so SSH is very much the
transport of the web now
for a lot of things other than HTTP
basically so ssao you can basically
manually script ssh commands to go in
and automate the upgrades again I don't
particularly recommend doing this but
there are tools that will do this for
you the other class of these automated
scripting tools i talked about don't
have agents they use ssh directly and
need this is an improvement because
you're using the secure protocols your
sis admins have already sets set up your
your leverage existing infrastructure to
do your work for you so for us to skip
forward a little bit weird up choosing
ansible ansible is a python frame
framework for automation of tasks across
one large numbers of nodes it has a
couple of advantages one that it was
designed for this kind of work
explicitly it has the idea built in do
you do things in a certain order and
there might be prerequisites and Prost
requisites to that to what you're doing
so if I'm pushing out a war before I
push the war I will take the server out
of the load balancer afterwards I will
put it back into the load balancer it
has the concept that you can you can
have a certain number of failures across
nodes or it will back out you can define
how it back out backs out what error
conditions are there how to deal with
them uniting about it is a user's
existing SSH technology it's it
leverages that to connect to servers it
can copy files up it can unpack files it
can create symlinks and automate a lot
of tasks you would do manually on the
command line or wire a Python script or
whatever the way we do it we actually
because it requires so little low level
infrastructure as long as your Python
and a couple of Python light libraries
on your agents any agent can perform
this so we do is actually just check out
ansible directly from the github
repository we actually get be actually a
mirror of it for
reliability purposes and this runs
directly from the directory you've
checked out then we have a bunch of
scripts play books in the ansible term
that say perform an upgrade on these set
of hosts and it will go across the hosts
in turn take each one out of the load
balancer perform the upgrade restart on
tomcat put it back into the load
balancer it does a bunch of tests around
it as well so for instance we will take
it out the load balancer bring it down
wait for it to come down and make sure
it comes down coherently if it doesn't
come down coherently that's a failure
situation and we will will back out and
raise an error at it will then unpack
the wah restart Tom Tomcats creates
symlinks as necessary and clean even do
cleanup and it runs a bunch of tests
afterwards ago like connect to the
server is the status page up is a
returning something coherent well one
thing's nice to do that is to check that
the version that has gone out there's
now responding to requests is the same
version that you Raschi upgrading to
funny story about this is ova knight
capital you will know them lost an
absolute fortune I don't forget the
magic number but it was a ton out there
the shutdown turns out they were doing
they're rolling out code and releases
and someone with faith failing so half
the servers were using the new version
of the code half the servers are using
the old version of the code turns out
sometime along the way the business
logic changed and they ended up bleeding
cash out of the old version of the
servers because it didn't get updated
that ran for about three days I think
and basically burn through a company
capital so checking for the versions to
go out is kind of important so we also
just check our playbooks into into get
as well and just do it full check out we
also run tests against our playbooks
themselves so is this another thing is
these scripts should be treated as code
themselves and should be tested if at
all possible vagrants quite nice for
doing that that kind
testing you can just fire up and vagrant
supports ansible directly so you can
just run a bunch of simulated
deployments into a vm and enjoy throw it
away so this is a going to go into a
little bit about management I can only
really talked about atlassian tools at
this point as I only really know how
this works we do have a couple of nice
new releases new features in bamboo 5 in
particular explicitly supporting
continuous deployment we have these idea
of development environments or
deployment environments that you can say
for a given piece of code the order
engine in my case there are different
places that can go to it can go to a
development server and you might have
continuous integration when that build
occurs it will deploy it directly out
onto the server you have staging in Viet
environments which you might do
automated or you want to semi automated
and then there's a production
environments where you want to promote
up CW deploy to the staging environment
promote up to the production environment
so this is kind of what it looks like as
you can see here there is a hams in
question is our is the name of our
ordering system and you can see that
there's been a there's a ravine release
and which servers been deployed outs or
onto there was a failure on the dev
instance but that's the dev instance we
expect to break that on a regular basis
however the you can see which version is
deployed on to the production and the
staging environments they are very much
like build plans in the sense that they
run pretty much the same a asian scripts
or the the agent systems you can have
stages and jobs and different tasks the
they have permissions which is very very
nice and I'll talk a little bit about
this at the end which allow you to
define who is allowed to release to what
and that is kind of important
it comes to sew in the chink time I'm
Cordia magical Harry through this went
on for way longer a fall so so
environment have permissions which
defined who can release the water and
that's important when you're dealing
with things like sox compliance and so
on so again this has some nice
integrations so this goes back to JIRA
and JIRA can be aware of what has been
released where so this is these are
deployment status and you can go back to
JIRA and that original juror ticketing
this comes back to there was a point to
that original statement about having a
single tanker plunge into end back in
JIRA the person who's raised a ticket
can now see that their their code change
the requested has gone out the staging
environment now this goes back to an
ulcer saben fing amount of mine give
people visibility and they will leave
you alone there is nothing pisses people
off more than having been kept in the
dark even if you're working away as hard
as you can they don't know know that and
they were going to come and egg alina on
you and say what's going on what's going
on if you give them the visibility back
to what's going on where it's been
deployed and JIRA will do this you can
see ok it's create Oh someone creates a
branch for my for my request oh the
request is now two commits against it
always out on the staging server always
looking to it it's going to go on to
production you get this visibility
they'll be happier and they'll leave you
alone either things on going well people
leave you alone is if they know what's
going on so i'll talk about procedural
issues i skim really likely through this
because every organization has different
issues we are moving towards a sox
compliance and that created a whole
bunch of issues for us we in particular
had to have this question of who does
releases the person who's writing the
code is not allowed to release the code
that must be somebody else whose goop
revised a
a stop and a final level of QA to ensure
that what's going out is what is is is
valid and it's not going to manipulate
the system in any way problem is the
sysadmin wouldn't could do that but this
is that means on part of our process so
what we've done personally is we use the
business analysts as our final arbiters
of what goes out this is because it
business analysts are there from the
start they're often talking to the
customers and helping them raise these
tickets in the first place they're the
best people to decide if what's going
out is in the business it the best
interests of the business however in
different organizations this could be
different some organizations have very
large structured QA they might be the
best people to do this in some cases the
operations team if they're very if you
dare very specialized and highly
knowledgeable about the system's
themselves and how they work how they
fit together then they might be the best
people to do defiant the final step but
this changes in every organization and
people people have talked to about
different opinions about the right
people to make that call so it's a bit
of change ability there it's a we we
also have another issue which is that we
are an open company that open company no
 thing and we tend to just have
visibility of everything but we're
working on systems was deal with money
and they're different so what we've had
to do as well is create a separate
infrastructure for our continuous
deployment so if you've got a bunch of
build agents which have the ability to
connect to your production servers and
make modifications you don't want those
visible annoying the company to be able
to connect to those and run arbitrary
code which is what a build is a bill is
run is essentially running arbitrary
code to some greater or lesser degree so
we've had to create a separate
infrastructure that is off in a
completely separate VLAN on in our
virtual virtual networks and we've had
to limit access to that and in fact this
point did developers can access this it
if completely separate known as admins
can access this or our automated systems
can access this because the automated
systems are our more trusted than the
develop developers because you can
inspect what an automated system is
doing so we allow that so everything so
now we no longer have the rect access to
our servers we ensure that code that is
checked in and reviewed and tested is
what is making the changes to the
certain servers in the end again this is
access controls I talked a little bit
about so this is the business analysts
for us works other people who make that
final q a decision about what is allowed
to go out onto servers or not again if
you have a QA team dedicated to your to
what you're building and deploying they
would probably be good people to talk to
or if you're talking or if you have your
operations team are deeply involved in
development process and hopefully of
DevOps is taking off and that might be
the case they have much more visibility
what's going on they might be good
people to do this as well so that's the
end though it actually went far longer
nice I expected so I hope I don't know
how much time we have for questions
anyone any discuss yeah so the question
there was a what's world thoughts on
having requirements for code coverage
that's that probably depends a lot on
the coding in question if we're talking
about you I systems are we talking about
critical core systems we are trying to
move towards that so sonar we were using
sonar to track some of our our metrics
code coverage itself is not magic as I
alluded to you know you can have perfect
code coverage and coastal does something
wrong which is why we have the the pull
requests and code reviews I it's
probably a good idea for course
systems though you having is tracking
code coverage is kind of tricky as well
because you're different levels of
testing unit testing can hair could have
a hundred percent code coverage or or
near zero but maybe your boot that's
being picked up in the integration tests
or the full functional tests then you've
got different layers systems and you've
got increasingly more code in the front
end than the back end they're just
really sort of servicing microservices
no good aren't a good answer that I'm
afraid but obviously more testing is a
good thing so high your future includes
something you for your database table
the schema whatever measure you yeah
pretty data into the system is that
extracted out is that part of your
script or is that stick strictly a dbhs
doesn't happen the question there is
about database migrations basically our
fingers would be be be correct hello how
do we handle that it's not even my
gracious a new feature which requires
all right yep so basically modifications
that they database required as part of
the release we personally use fly away
for this and Alex fontaine talked about
this today as well using fly away it
works well for us however we do not
always use flight Flyway I wants to ask
Alex about this at some point and
generally people in general database
migrations are difficult one thing you
can do we talked about you can you can
automate changes by basically copying a
table making the modification that table
have the code mirror to take the tables
or the columns in in those tables
problem for us is what our code our
database is large very large and these
migrations can sometimes take hours a
half a day so sometimes what we do is we
say we write the code in fly fly away we
test it with fly fly way but we identify
in state staging the changes are going
to take a long time and then we'll just
comment those out in fly fly away before
the final release and do it and get the
SIS admins to do it by about creating a
pre-arranged script
they will then run the reason we comment
out rather and remove the migrations
because you want you want a history of
your migrations to go to accompany your
code as well again this is one of those
questions it's good it's it's tricky it
depends a lot we will say we like to
automate it and we like our migrations
to be code you'll change it should
ideally be code talking about automating
the releases rather than manual steps
it's code your you can then then test so
as much as possible it should be and as
Flyway works for us but there are other
tools out there as well but in some
cases we will then separate that out
having tested it and particularly on a
similar similar with the actual
production database and get the dba's or
the sis admins to run that separately if
possible ince extreme cases we do need
to bring to have actual down down time
for more complicated tasks we try and
minimize that as much as possible we are
increasingly trying to move towards a
more static database structure that
allows you to requires less and less
changes Oh over over time but obviously
knows knows what no one-size-fits-all
for a day beta basically do need to
migrate database migrations are the most
complex part of any release cycle and a
continuous deployment in particular no
SQL databases do give some hope for this
micro services are definitely a major
help here because what you do is you
create a micro service and everything
and give lots and lots of databases have
one very small area that they work in
rather than one big database which is
com complicated and heavily interlinked
microservers create their own problem
problems but that's way outside the
scope of this tool hey so the question
was do we consider pay pair programming
to be a replacement and additional or
can be equivalent to peer a peer review
confession we don't we our team does not
heavily pair program are not best person
to answer that I
like the fact that you have much more of
a record with pull requests and peer
reviews and so on you have a history of
what happened and when you do need to go
and triage the inevitable problems that
will happen and it's not this is just
you know not do continuous deployment
just the reality of development it's
nice to go back and see what what
happened all the comments were and have
a paper trail that said pair programming
does have a lot of benefits many of
those been benefits have nothing to do
with code quality or and really about
sharing knowledge of in a team I would
not I don't clearly be an expert on on
pair pair programming it's all something
I've had I've done extensively so I'd be
interested if anyone else has any
comments on the house with that sorry
that's not much of an answer but sir is
it it's a good question yes yep the
question was i with the BB BB a is being
the final arbiter of what go goes out
what sort of testing today they do it
varies depending a lot it's really a day
judgment call at this point you've gone
beyond algorithmic testing its heuristic
testing its does it feel right is it
right does it look right is it doing the
is it doing what the business needs it
does logic make sense at varies quite a
lot so in some cases we do thing it'll
be the VA has has a look at it and
checks it out and make sure it does what
the customer requires of it in a manual
way in some cases will run we call blitz
tests and basically half the team will
pile on to this particular change and
make sure it doesn't break anything and
so on really this is why the human is
involved because it's ultimately a
judgment call not a suddenly you can
basically put a magic number on or a
final decision so that's why we have
humans involved
last probe process is to say it is big
or is it small is it look that's fine
you're just changing the words on the
page through to you know I had like a
light or out three thousand line at
lines of code recently that felt good by
the way sir and it when I that's really
cool we're so blitz testing this one and
everyone pile on and found a bunch of
problems because you know you can't rip
out three thousand lines of code about
breaking silence at something and that's
fine that's then that's why humans are
involved ultimately software is for
humans by humans eventually you need to
complete that that loop I think and
there's no magic answers of that but
obviously if you're any anything a
computer can do for you is better so any
more questions yep yes we don't really
have a separate QA team in that sense
developers write their own tests by and
large so and we try and encourage
test-driven development I don't think
test from development is as the quite as
magic as it's often made out to be but
its its its ultimate aim of having more
less coverage as a good idea so we try
and encourage developers to write their
tests as they are writing the code and
ideally and if you can spot any gaps as
well go and feel for load those along
too so we don't really separate testing
from development in that sense and we
don't we don't really have a QA team who
write test separate separate we would
like that we'd like and we are moving
towards that and possibly hiring a
full-time QA developer who's job it will
be to enforce these levels of coverage
but ultimately sooner or later the
person is writing the code for the best
person to go is this code covered
correctly I think it might be time for
us thank you run for Camilla</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>