<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NoSQL, WTF! Let’s Talk NewSQL | Coder Coacher - Coaching Coders</title><meta content="NoSQL, WTF! Let’s Talk NewSQL - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>NoSQL, WTF! Let’s Talk NewSQL</b></h2><h5 class="post__date">2015-06-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Blrd9BVNZbs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so good morning everyone thank you very
much for coming to this talk all sequel
no sequel what the let's talk new sequel
just as a show of hands how many of you
know what new sequel is one person to
two people three okay all right so Who
am I
my name is Karthik sham cinder I'm a
principal technologist work for a
company called Verisign as many of you
know Verisign is a company that does
domain name registration we manage about
120 million to 130 million domains
worldwide on the.com net dot CCTV gov
databases we also do about 70 billion
queries a day the DNS queries today
that's what we do so I do a lot of work
in terms of big data processing using
Hadoop you know I've given talks on
Hadoop I teach a class called
distributed computing using Hadoop I
also serve as an adjunct faculty at
Johns Hopkins University teaching
courses on distributed computing and
recently co-chairing the big data and
the cloud concentration classes you have
my email address over here so you're
welcome to send me an email if you want
I also have a Twitter handle I promise
you I do not tweet about what I ate for
breakfast I'll send you information
about you know good things that's
happening in the field of data bases and
computer science computer science and
things like that ok so what is the goal
of this presentation I actually have
three goals first to introduce you to
the new sequel concept and then the way
I'm going to do this is I'm going to
compare and contrast all sequel new no
sequel and new sequel and then hopefully
I can get you thinking about new sequel
and then you can go back and start
thinking about how you might be able to
use some of these new upcoming
technologies in your applications ok so
here's the agenda first what's the buzz
I'm going to talk about the buzz around
new sequel technologies then I'm going
to talk about the state of the database
as it stands right now in that I'm going
to talk about the old sequel database
the issues they have and also the no
sequel database the issues they have and
also
good things that both the databases have
come up with because that's going to
lead me into talking about what new
sequel lists will define new sequel and
then I'm going to talk about a couple of
new sequel databases volge DB and neo DB
so I just you know there are many of
these things available I'm just going to
pick a couple of them just just to kind
of give you an idea as to what these
databases are all about and what they
are doing and then somebody and then Q&amp;amp;A
so hold your questions till the end
please okay so what's the buzz so on
April 4 2011 451 research group which is
a group that does a lot of work on
databases and technologies and things
like that they wrote an article and in
the article they used the term new
sequel it was actually Matt a slits
article that talked about neo sequel and
in the article he said how will the
database incumbents respond to no sequel
and new sequel right now we see the term
new sequel defined over here at least
used over here for the first time no
sequel you've heard of all the no sequel
databases that are out there and then
this this term called database
incumbents when he talked about the word
database Inc events he actually talked
about the old sequel guys which is the
traditional database guys Oracle sequel
server Informix Sybase the traditional
databases that were invented in the
1980s in the 1990s
so when he when he when he made this
article when he presented this article
he had a whole slew of questions that
came about that said hey what do you
mean by new sequel and so a couple of
days later he actually wrote a blog that
said what we what we talk about when we
talk about new sequel so there it is the
new sequel revolution has started
happening there and by the way I have
provided source links for all of these
different articles I strongly suggest
that you download these links and read
it now the other interesting that
happened was in May 2012 Google
presented the F 1 relational database at
sigmod for those of you who don't know
what Sigma is Sigma is special interest
group for databases this is where all
the database vendors the database
researchers
the professor's the company
organizations the companies that working
on databases present their new
technologies and Google presented that
f-1 database which is a relational
database technology which is actually a
globally distributed relational database
technology we know how important it is
in today's world to have a globally
distributed database where you can have
one table that can span across multiple
data centers multiple regions and things
like that they talked about this
database and then they said that this is
actually a successor to BigTable which
we know is the you know is the
foundation for many of the databases
such as Cassandra and HBase submitted
the no sequel databases and they said
that it's based upon another technology
called Google spanner right so they you
know it's very interesting that they
talked about this in September 2012
Google released a paper on spanner
you know globally distributed database
they said this is the underlying
technology and they talked about how
they are doing multi data center
database and multi data center
replication and how this particular
technology is the foundation for
relational database which is the Google
f1 database that they built now we know
this and by the way this paper won the
Jayla Pro award and we know this in 2003
Google released the GFS paper which is
the Google file system paper and then in
2004 they released MapReduce for big
data processing in 2005 they released
the HBase paper we know the frenzy that
it created in the marketplace
the whole hadoop revolution came about
we have a whole bunch of no sequel
databases that are out there at this
particular point so you know you know I
used to think you know and I do a lot of
work with Hadoop and I teach a Hadoop
class and I used to think wow you know
if Google released this paper you know
what are they really doing you know they
gave this people away but what are they
really doing it so happens that they
were actually working probably on this
the spanner database and the Google f1
database and that's the database that
has replaced the my sequel you know
database that they have for the
ad-serving platform which is a
thirty-five billion dollar industry for
them a paper that's worth reading and my
prediction is this is going to become
the foundation for some of the new or
upcoming new sequel database products
that are going to happen especially in
the open source world
okay so high scalability comm reveals
that new sequel is in and no sequel is
out right so now we have a new sequel as
one of the things now mad at mad Haslet
who publishes several articles on
distributed databases he published this
map or Metro landscape again there's a
link at the bottom that talks about
various databases and the interesting
thing is if you look at this this Metro
landscape you'll see that the stuff
that's in white in between right in the
center is all the relational databases
that are out there and then the stuff in
blue is all there no sequel databases
and the stuff and in green is all the
grid cache technologies that are out
there if you look at the stuff in the
center over here there's a new line that
he draws which is this line right here
which is where the no sequel databases
actually sit sorry the new sequel
databases actually said so there is a
new trend of databases that are correct
that are coming up in the marketplace
which are you know which is again under
the umbrella of relational databases
okay so in order to talk about new
sequel database I have to actually talk
about the state of the current database
and explain to you what is going on and
then and then let's define the new
sequel database okay so let's talk about
the state of the database now let's talk
about ole TP well no I'm not talking
about you know log file scraping and
things like that I'm talking about OLTP
so if you remember how we used to do
transactions in the 1980s I know some of
you are probably not born in the 1980s
but if you were doing transactions in
the 1980s or your parents were buying
tickets in the 1980s they would actually
call an airline agency or you know
United Airlines or whatever it is Pan Am
and they would basically you know make a
call they'd say whatever the ticket that
they want to buy and so the transactions
were being made through an intermediary
which is a professional terminal
operator the took your order entered the
order into the system and so the
transactions were being done on behalf
by this particular operator so you know
the commerce was really being done at
the speed of this intermediary operator
and at that time 30 transactions per
second is what people did that's what
people did you know that's the kind of
database transactions that people were
doing so you know in 1985 HP TS which is
high-performance transactions workshop
was created that basically said we
should create you know as you know a
kind of a you know a bar for databases
which should set the bar to be about a
thousand transactions per second
thousand transactions per second you
know we know that our iPhones do more
than that right so that's what they said
thousand transactions more than enough
let's do that that was an incredible
stretch at that time right
but we know we know how OLTP has changed
in the last 25 years right the end users
are initially in initiating the
transactions now it's not this
professional terminal operator that is
handling the request for you yeah
everybody is doing a transaction your
cell phone is a transaction originator
right and this is sending volumes
through the through the group through
the roof I think your name is Cecilia
yeah she was standing outside and she
was telling me hey you know what I don't
know if I should come to this particular
session and I said come to this and I
said what do you do she's like she works
for a game company can I tell you which
game company it's EA yeah she works for
EA and she's like we're trying all these
different you know databases in a
MongoDB and all these different
databases we are looking for you know
high-volume databases you know I don't
know which one to and we tried to see if
new sequel is one of those things so the
point I'm trying to make is devices or
initiating transactions at this
particular point right everything is
being geo positioned your phone is being
just positioned your car has is geo
position and it's initiating
transactions or insurance companies are
trying to figure out how fast you're
going and you know just your insurance
rates based upon that every day all
these things these are not log files
guys these are real transactions that
are happening marathon runners have bibs
in them and those bibs are geo position
that is giving information as to where
people are and who's running and how
fast they are running and who's winning
that who's winning the game who's
winning the run so gaming systems are
coming up you know millions of people
playing game together all these things
are sending online transactions through
the roof
right the application architecture has
changed in the last 40 years more than
web and non web applications that we
build today or build to scale out we do
that right we know how to do this thing
it's common sense we launch a server if
that server is not good enough to handle
our transactions we know how to launch
the second one the third one the fourth
one and so on and so forth this is
common and in today's world when we are
doing cloud computing you know we do
this thing even you know in a in a cloud
way and automatically start some of
these servers
so scaling has become a common tenant
for computing models now when it comes
to databases what do we do well we start
with a relational database and then we
vertically scale the relational database
right so we scale the relational
database
by simply adding more memory by adding
more CPU that's what we do
so if you look at the you know if you go
to Amazon Web Services you try to you
know you want to do cloud computing you
are able to bring your more application
servers online but when it comes to
databases you'll use there RDS service
and then you'll go from tiny to small to
medium to large to extra large machine
that's what you end up doing because you
want the transactional capability but
you know the old sequel guys the
traditional database guys have some
options one option we have is sharding
right so shorting is the idea where you
partition the data typically you do it
manually and you spread the data across
multiple servers when you do that when
you fill a shard it's disruptive because
now you have to recopy everything reshot
everything so that's a problem you also
lose some of the benefits of the
relational database model you have
multiple servers
how do you do transactions across
multiple servers you know I think it was
a Saturday I was you know as one of the
sessions and and one of the guys was
talking about how there is a my sequel
database where it replicates across
multiple machines you can do
transactions across multiple machines
you have to create and maintain schema
on every server you know that's a
problem too and then you also try to
look at options like denormalization you
ease out some of the strict No
we have the first normal form the second
normal form of the third normal form now
the database guys are not BBS are not
very happy but you got to do it for
scale but then that introduces
duplicates in your database right and
then you again you lose some of the some
of the move important benefits of the
relational data model the other option
that we take is distributed caching so
we would use some kind of a caching
technology like memcache which is great
for reads so it accelerates reads but
when it comes to writes you or when you
restart the server you get into what is
called a cold cash thrush and if you
think about it it's yet one more tier
for you to manage right so you have your
web server you have your application
server tier you have your cash tier then
you have your database tier lots of lots
of more tiers to help manage so all
these solutions they almost seem like
band-aid on top of the traditional old
sequel databases so if you take a
comprehensive look at the old sequel
database guys if you think about it they
were build in the 1970s in the 1980s and
they were built decades ago and they
were built on hardware principles that
were prevalent in those times in the
1980s you had a little bit of memory you
had you know you had a disk that was not
reliable he had met your machines they
were not that reliable your networking
was not fast enough you didn't have
distributed computing as much and you
know everything that you do anytime you
did a transaction you have to first
write it to the disk for for durability
so you know and you had single coil
single core a similar CP machines so you
have to do multi-threading because you
have to do the processing and then you
also have to do the i/o we have to wait
for the i/o so they decide design the
architecture in a certain way the old
sequel vendors are actually up against
what is called the innovators dilemma
the universal innovators dilemma is a
wonderful book by Clayton Christensen
that basically says that you know the
big idea here is that it's very
difficult for market leaders to innovate
on a new technology although you know in
the technology is becoming obsolete
but they cannot change it because if
they change it that is going to upset
some of their customers they know that
the new stuff is coming but it's very
difficult for them to do this and some
of them will work through it but that's
the idea but the traditional data basis
you know I don't want to bring them down
the point I'm trying to make is they
have done a great job in the last 3040
years and they've actually gotten a
couple of things right they got the
sequel part right which is secret you
know the query language so we never have
to worry about which database we are
talking to it doesn't matter whether
you're talking to Sybase or Oracle or in
you know or Postgres you talk to the
database using this higher level
abstraction language so that's really
nice they also got the transactional
aspect of it right who wants to manage
transactions in their application so
that is also being gotten right and we
never do transactions in our in our own
you know in our applications right so
those two things are really good so here
comes the no sequel guys and and I like
no sequel like I said you know I work
with Cassandra I'm a big fan of HP is
all these you know I teach all the stuff
and I work with all these things at
Verisign but if you look at the no
sequel databases you know you got the
key value database
you got the column-oriented database you
got the document oriented database you
have graph you know you know graph
oriented database and this probably
someone that's writing a brand-new
database as I'm speaking right now right
so got all these different databases
that are out there they all have
different data models they have their
own data models they all have their own
query language they all have their own
API right but you know they stay all
pretty much scale horizontally well you
know that that thing that they have
right so if you if you look at the no
sequel databases you know the no sequel
guys you know they'll say that they are
no no sequel is no sequel or is it not
only sequel there's all these games on
the words right there but the no sequel
guys say give up sequel alright give up
sequel well no sequel guys are really
misguided in thinking that sequel is
actually a problem when it comes to
performance and scalability and
availability when you write code in
sequel it's common sense that
equal courgettes trunk gets compiled and
then gets its executed inside the
database so it's never a performance
problem it's never a scalability problem
in fact it's a really good thing to have
sequel and one of the reasons why they
don't have sequel is because their
database models are slightly different
and they also have you know data columns
that arc you know it can be changed on
the fly sense because there is no schema
it's very difficult for them to give
some kind of a query language on top of
that but if you think about it now the
Cassandra guys are now coming up it's
something called cql which is a take on
SQL which stands for the cassandra query
language and I think the MongoDB guys
are coming up with something called you
uncle you and QL which is I think
unstructured query language so you know
there's all these different innovations
that's happening in terms of query and
they all understand that query is
important right but we all know that
sequel is very important to us too it's
been around for 40 years and it's been
very good so when it comes to
transactions give-up transactions well
give up acid you know we don't want to
do that well I don't mean that kind of
an acid by the way so you know if you
need accuracy in your applications you
need acid you need transactional
capability you don't want to be doing
this thing in your application all the
heavy lifting that you have to do is
like pulling your head out so if you
really think about what's happening in
the marketplace and if you have a long
term look at the no sequel guys no
sequel guys is great for certain class
of applications it's appropriate for non
transactional systems you know if you're
collecting logs putting it together you
know you have you know we have access
logs that are coming in from different
databases from different systems we have
we have you know DNS queries that are
coming up in other we can negate and we
can do MapReduce processing and Hadoop
processing and we can put it in a no
sequel database all that stuff is good
it's appropriate for single record
transactions if you want to do a
transaction on a record level given a
key you could do transaction so that
level many of them suppose that but it's
not fit for all TP systems where you
need to do gaming where you have 150
million 20 million 40 million 100
million people there are doing
transactions right now and you need to
figure out like
she was working on in the gaming system
well you need to figure out who's
winning the game right if you want to do
transactions to that level then it
doesn't work so purchasing systems order
management systems and I already talked
about how with 8 billion people that are
going to be online on board we need a
transactional system on you know
worldwide we need a transactional system
so if you really think about it the no
sequel got guys got a you know got write
a few things they got the scalability
and the availability aspect of it right
the horizontal scalability aspect of it
right and the availability concepts
right but the no sequel guy's got a few
things wrong which is you know give up
asset and get a give up sequel ok so
that means what we need to do is we need
to now define what a new sequel is so a
bunch of new startups are saying now
that hey sequel is good let's keep it
acid is good we want transactions in our
system so let's keep it let's figure out
a way to make our old sequel databases
perform better right so and I'm gonna
talk about what are the issues with the
old sequel databases based upon a paper
by Michael Stonebraker basically you
know like I said they are built upon
technologies that were done in the night
you know in the 20 in the 1980s so
they're saying let's get within a single
machine let's make it scale better let's
make it perform better and then let's
make it scale like no sequel horizontal
scalability and also make it available
right that's the idea that's what they
want to achieve so there are several
mender vendors that are there in the
marketplace
each distinguishing themselves by
implementing the concepts slightly
differently in their own way some of
them have their own proprietary
techniques you know some of them have
you know their own patents on it so
there's a lot of different solutions
that's out there here are some of the
new sequel databases that are there in
the marketplace neo DB is one the volte
b is another one
there's scale DB scale based genie DB a
Caban just one even my sequel cluster is
in a way put in the new sequel arena
bi mát a slit
what I'm going to do is I'm going to
talk about a couple of these databases
I'm going to talk about the Neo DB
database and the Volt's DB database you
know from an architectural perspective
right the one thing I do want to tell
you is that if you're looking for you
know code examples and things like that
that's not what this presentation is all
about it's about trend in databases and
how databases are going to change in the
next 10 to 15 years going forward so
it's good it's good for architects for
technologists for technical leads for
startups that want to do things in this
particular field so what is new sequel
I'm not going to give you the full
definition that's defined in Wikipedia
but the most important thing about new
sequel is that it's a relational
database scalable performance of no
sequel transactional processing
capabilities of old sequel acid
guarantees of the old sequel broaden
together into a new system that's what
the new sequel is okay so that brings up
an interesting concept which is the
Brewers cap theorem so dr. Eric Brewer
you know in in 2000 he gave in and gave
a talk and in the talk he said there's
something called the cap theorem which
is the you know which is the Brewers cap
theorem where he said C which stands for
consistency means that the all clients
will always have the same view of the
data and P which stands for partition
tolerance says that no set of failures
less than the total network failure is
allowed to is allowed to cause the
system to respond incorrectly which
basically means that if you have a bunch
of machines that are working together in
a distributed environment then if you
have a few machines that crash not a
problem if your system should be able to
run properly but unless your entire
system goes down of course in this case
there's nothing you can do so that's
what partition tolerance is and then
availability is that all clients should
be able to see read and write within
some maximum latency right there's a
possibility that you could get some
errors in that particular case so
according to the Brewers cap theorem and
I think it's a misunderstood theorem
basically he says that you can at most
get two of them what that means is you
can get either C and P or P and a or a
and C okay the way you look at this is
that you look at the area between let's
say you do
CNP and let's say that that that shape
over there represents the area between
it represents the area of C and P what
does what Claire cap theorem is saying
is that it's a balance it's a design
balance you can organize it in any way
you want so that you can you know you
can get a little bit of everything right
but you're not gonna get a hundred
percent of everything so there is a
possibility that you could get some
errors especially if you're going to be
doing multi data center updates okay so
what are the key principles behind the
new sequel architecture minimize or stay
away from locking you know that's how
you improve performance and there's a
lot of ideas that are around for this
their basic concept is don't do row
level locking or table level locking you
process the transactions in time step
order with no no locking or minimum
locking that's one of an option another
option is what is called multi-version
concurrency control these are all
technologies that have been around for
many years in distributed systems and
then the other one is called optimistic
optimum optimistic concurrency control I
think the the the first option which is
processing transactions in timestamp
order is what the volt DB guys do and
multi-version concurrency control is
what the neo DB guys do and optimistic
concurrency control is what the Google
guys do with time vectors and things
like that okay
heavy reliance on memory so what they're
saying is that we need to take advantage
of the memory that we have today today
you can buy for $6,000 128 gigabyte ram
16 core 4 to 5 terabyte hard drive
machines it's not like the good old days
where you had like you know 512
megabytes of RAM or one one you know in
the 1970s and 1980s but he had one
gigabyte of RAM or two gigabytes of RAM
so let's use heavy memory heavily to the
extent that some knows new sequel guys
are going to say that they want to keep
the entire database in memory and do
replication for creating a new key
factor in fact what I heard was I think
yes in key keynote speaker yesterday
Larry Ellison announced that there is
going to be a Oracle version which is
going to be an in-memory version of the
Oracle version all right so the other
option is moderate use of the memory so
you use memory heavily but then you also
use persistence for durability
use some kind of a solution to avoid
latching and locking and also use the
network heavily if you are working in a
distributed systems you know now we have
you know good distributor data you know
networking that we have take advantage
of all those things ok so let's look at
a few of the new sequel databases I'm
going to talk about - native the - new
sequel databases in particular one is
volts DB and the other one is neo DB I'm
not here to promote or do any of these
products I just want to tell you what
these products are and you're welcome to
contact those vendors and see if you
want to use them I think there's also
going to be some open source projects
that are going to come out and you know
in the future probably soon probably
somebody's already working on one so
let's look at volt DB vote DB is an
in-memory horizontally scalable acid
compliant database the most important
thing over here is that it's an
in-memory database they everything is
done in memory alright and so basically
it's architected and or and backed by
Michael Stonebraker Michael Stonebraker
is a pioneer in database technology he
has launched several database companies
you can look him up on Wikipedia he's
the architect for this particular
product this is an open source project
it's poor Java pot C++ so which means
the demons run part you know the demon
run in Java but then there's also a C++
native native C++ part of it the
official site is voldie be calm this
particular database is available in two
editions one is the Community Edition if
you use the Community Edition then what
you have is you know you can have
partitions within the database but they
all have to be done within a single
machine if you want to do a Multi multi
machine distribution then you need to
have you need to go with the commercial
Edition that of course requires some
kind of a licensing mechanism okay so
the the key principles behind the volt
DB database is based upon a paper that
was released in 2008 really wonderful
paper to read at some point it's written
by Michael
Stonebraker and his colleagues at MIT
it's called OLTP through the
looking-glass and basically what Michael
Stonebraker did and this team did was
they took a traditional database the
database the old sequel database and
they could not take a traditional
database like Oracle or post you know or
sequel server or Sybase because they are
all proprietary solutions so they they
actually took an open source database
called Shore and then they you know they
put it under load right it was built
upon the technology principles that were
done in the 1980s they put it under load
and when they started you know they did
what is called the TPC see you know load
generation and what they saw was that
the database was only performing 70% of
useful work only performing 7% of useful
work basically what what they found was
that most of the work in the database
was happening in terms of buffer
management because when you insert a
record you have to make sure that you
write the record you know you write the
record to disk you have to also write a
Nordic log you also have to update the
sequel
you know buffer manager the data
structure you have to do some latching
and locking if you have to if you have
to do riu even read only has latching
and locking going on when you update the
data structures in memory the Metreon
structures you have to you know like and
also you have to do logging of course
for persistence so there's a lot of
stuff that's going on in the database
you know that is that is taking too much
time so they said what they did was they
actually wanted to keep the
transactional aspect of the system they
also wanted to keep the sequel
principles of the system so they started
changing the architecture so they
started modifying the code of the sure
database district database and started
getting higher performance and higher
throughput and the way they did this was
they kept all the data in memory for
durability they actually you know they
replicated for availability and things
like that and that became the foundation
for the Volt's DB database okay so vote
DB database avoids the overhead of
traditional databases by keeping all the
data in memory so yes that's correct
your data has to fit into memory right
you can you
you can partition it you can partition
it across multiple machines and then you
can have what is called the que safety
or the que level you know where you can
set the que level to one or two or three
but it will be replicated across
multiple machines but but but if you
need to do 1.5 2 million 3 million 4
million transactions a second then this
is one way by which you can achieve that
that's what the that's what the volt DB
guys are saying right so which means
they don't have to they have the data
all in memory they don't have to do any
logging anymore right to the desk
because they're going to do what is
called que safety when you update the
record when you insert the record
they're gonna make you know they are
going to make an update record
synchronously in another machine also
make if there are three copies they're
going to update all the three copies so
in memory operation because they're
doing all the operations in memory your
lock you're talking about microseconds
or milliseconds for your transactions
there is no buffer management that you
need to do anymore all this complicated
data structures that don't have to
happen and they have partitions so when
they partition it what they can do is
different partitions can operate
autonomously so if you have let's say
you can take a machine like if you have
a machine that has 16 cores you take a
couple of course one core for your
operating system and one core for users
to log in and then you have 14 course
you take 14 cores and you run 14 daemons
14 volt DB daemons each votes DV daemon
is actually a partition and each
partition is going to operate on its own
in a single threaded way so one of the
things remember they were trying to stay
away from you know multi-threading so
they actually work on a single partition
and a single threaded way now you might
say wait a minute how can I do multi
multi-threading and I'll talk about that
in the next slide so typically one
partition works on its own data so they
don't have to do any locking and
latching so really what they have done
is they've tried to improve the
performance of a traditional database
they have changed the architecture of a
regular database that we have so that
you can get higher throughput from it
right and also they want to scale it
horizontally by adding more machines
into it so the way they they scale this
is that you have one partition per
physical CPU core like I said if you
have six
tene course use 14 course you have 14
partitions that are there and then when
it comes to your database tables there
are two kinds of database tables you
have tables that are partitioned because
these tables are big and so you need to
be able to partition it across multiple
shards within within the machine or even
across multiple machines and then there
is also the concept of replicator tables
there are certain tables that might be
reference data that can fit in memory
and that can be replicated across
multiple partitions so you can you can
also do that you know I do want to tell
you that you know you know I'm gonna
talk about volt DB and then I'm gonna
talk about neo DB I mean you have to
think about what fits for you right I
mean this is if you think that you need
2 million 3 million 4 million
transactions a second this is the way to
go this is one way to go right so so
they have single partition so when it
comes to when it comes to work when I
say work I mean transactional work acid
work you have transactions that are done
within a single partition or you have
transactions that are done across
multiple partitions right but the work
within a single partition is done in a
single threaded way ok so let's look at
that so let's say we have you know one
machine with 16 cores again we have
actually made let's make it simple right
now we have a machine with 4 cores and
we use one core for normal operating
system stuff and we have 3 cores so what
you're seeing over here is you know the
3 cores running 3 different demons which
is the Volt DB daemon and partition 1
partition 2 and partition 3 have two
tables in it so that is the orders table
and there is the products table notice
that the orders table is the partition
table so when you create the table you
have to create it with a partitioned
schema or option and the order the
products table is the one that is that's
a replicated table so notice that each
partition partition one partition to
partition 3 has the products table
replicated we put the the orders table
there is a portion
fit in partition one there's a protein
or portion of it in partition two and
there's a portion of it in partition
three okay so now if you do a select
count star from orders where customer ID
is five that means this is going to
affect a single partition now we love
I'll talk about how it figures out which
partition it needs to go to but what
that means is now it goes to that
partition and it'll get you the record
from that particular partition so only
one partition is involved so you know of
course every partition is working you
know in it's in a single-threaded way
but in this particular case this
partition gets the work for you if you
do a select count star where your
recruit you're getting data from
multiple partitions then clearly one of
the partition is going to be the global
coordinator which is going to coordinate
the data across the different partitions
put the answer together and give the
answer back to the client right so of
course in this particular case all the
three partitions or being or being
called upon but all the three partitions
are working in a single threat every
partition is working in a single
threaded way when you insert a record
into the orders table if it affects the
one partition which is partition three
then of course the insert will take
place into partition three the
transaction will be done only within
that particular partition if you insert
if you update and if it's going to
update all the three different
partitions in that case all the three
different partitions is going to
participate in a transaction and so one
of them will become a transaction
originator and then the other three will
be you know they did the other the
transactions will take place it will
coordinate the transaction and give you
the answer the point I'm trying to make
is you have local transactions and you
have global transactions the local
transactions are working within the
partition in a single-threaded way and
the global transactions are also single
threaded but there's a total order there
so looking inside a volte be partition a
single partition is going to have two
portions in it one is the table data
which is the data structure that's the
one that's done in C++ and then there is
the execution engine that is the Java
based engine that is going to execute
your sequel query so they're doing the
c++ for data at the data management and
Java for execution
the point I'm trying to make is within a
single partition the work is being done
in a single threaded way so if one
client is working on a single partition
then that would be is one transaction
another client will be working on a
single partition another transaction
other clients you know that's a third
transaction you can have 14 transactions
going on if you have a 16 code machine
with 14 your worldy be demons that are
running but if you have something that
affects three transactions then of
course all those three transactions will
become a single transaction you know
that that's how they have done this so
in this way they're actually avoiding
the multi-threading and the reality is
that you know with an adult's log with
more and more cores coming in if you
have a machine that has 100 cores if you
start doing if you have a you know if
you look at databases databases actually
share you know share the data structure
if you have a hundred code machine and
if you have to share the data structure
if you have to share the b-tree and then
you have to update the b-tree that is
going to become expensive and you're
going to spend most of your time you
know managing the locks in the LA you
know all those things and you're gonna
do less work and that's really the idea
behind this let's war to work in a
single-threaded way in a single
partition you know shared nothing
architecture in terms of the you know
the programming model itself it's a
little you know it's it's it's slightly
different you of course we know that
sequel is important so you write your
schema as you know sequel scripts so you
create you put a schema file your DDL
file that has the create table and when
you create the table you can say it's a
partition table or you can say if it's
if it's a replicator table but then you
have to do all the work in terms of
stored procedures everything is the
stored procedure and the idea here is
that you know stored procedures are not
only are not only great in terms of you
know doing processing on the server side
it's also it can do optimization on the
server side so whenever you have your
tables you you you you you you have to
write cards for that if they also
automatically generate the crud for you
that's because your schema and stored
procedures go through what is called a
project or XML file which runs through
what is called a world DB compiler and
what that generates is a jar file that
gets distributed to across all the
different machines right so it is sequel
from the perspective
that you write your database logic in
sequel but it is all stored procedure
sequel you can surely do some basic
sequel but if you want to do
transactional you need to go through
this this kind of an approach there
right so you know so when it comes to
scalability you increase the RAM within
a server you add Rams across the
server's you add more machines you know
so you get the performance and
scalability and if you want redundancy
and availability then you do what is
called case safety you set the key
safety to three which means three copies
of that particular data will be kept
across the three different across three
different machines so what if a machine
crashes right and then if you want
durability you have the option of doing
what is called command logging you also
have the option of doing what is called
snapshots so from time to time every
minute or you know every 30 seconds or
you know you know consequently you can
say take a snapshot of the database so
that if you ever crash completely you
can bring it back up but if you want to
do that kind of a gaming system where
you have to do those kind of
transactional systems where you do need
to do multi millions of transactions per
second you do it this way and then the
old order is old transactions you move
it out into other kind of a you know
database that's the idea here okay so
now let's talk about neo DB neo DB is an
elastically scalable asset compliant
they call themselves 100% sequel new
sequel database the key here is
elastically scalable so in fact they
have some patents related to this which
they are working through it is backed
and architected by Jim Starkey who's
another pioneer in database databases
and database architecture again you can
look him up in Wikipedia this is a Java
based database it runs completely on the
JVM the official site for this is an EOD
be calm but it is a proprietary source
project right so what are the
architectural principles for this they
have what is called a tiered
architecture so they have what is called
the transactional tier which is the one
that does the transactions for you
manages your transactions global
transactions there is also something
called the storage here that's the one
that's responsible for the durability of
your database and there's something
called the management here that kind of
spans across the transaction tier and
the storage tier so that the clients
which is your application clients can
figure out where the data where the
database need you know where the
transaction tiers are so you can
actually talk to the transactional
database it is a multi-tenant database
it's not a one-off database which means
you can create a database you can create
a schema you can create multiple
databases you can do all those things it
it uses memory heavily heavy use of
memory which means the transactional
tier actually has some some caching
logic that's that's built into it but
for but you know unlike volt DB remember
all the database has to fit in memory
here you can actually persist it to the
database so important things are kept in
memory or they're more relevant things
the hot things are kept in memory and
the rest is kept in cold data and
persistent store they use the word
object-oriented they have this thing
called atoms which is the way they do
their messaging which is asynchronous
messaging so remember I said to you that
you don't want to have a row level lock
you want to have a cell level lock you
wanna have a row level lock yeah man our
table level locks with transaction so
they have all these different kinds of
trends you know atoms that you have you
know the only what I want to tell you is
that you know this is a closed source
project so I really cannot look at the
source code and figure out what's going
on so you brought you know my
information is coming from looking at
their documentation and playing around
with the product and you know you know
and looking at some of the videos that
they have in YouTube you know if you
want to get more information you are
welcome to contact them they also have
what is called partial on-demand
replication because they replicate the
data you know across tiers or even
across data centers only on-demand and
they use what is called the
multi-version concurrency control to to
manage concurrency across the different
tiers okay so the transaction tier is
responsible for managing transactions
which means it parses your courses your
you know sequel
statements compiled it optimizes it you
know organizes it and executes the
sequel statements on your behalf it also
stores some information this is where
the memory caches this is where some of
the caches is going on it maintains the
the in-memory cache for the data that
it's managing at this particular point
it also has a map of all the different
transactional tiers all the other
transaction tiers that are there and
also how to find them any transaction
engine can talk to can get any piece of
information you can have a transaction
engine that is running in London and it
can have access to the data that is
located in New York and the most
important thing here is that they they
have this scalability the throughput
scalability of transactions by adding
more and more transaction engines so
each transaction engine can do so n
transactions and then depending upon
what the app you know your application
profile is you can add more transaction
engines they also have something called
a Storage Manager Storage Manager is
basically the one that is responsible
for the durability aspect of your
application so you can you know remember
when you have a database you can store
it store the data in sanh which is the
storage area network with your raid or
you can store it in this particular case
they have heterogeneous Storage Manager
which means you can even store the data
in HDFS for those of you who know what
HDFS is we don't know what HDFS is it's
a Hadoop distributed file system where
when you insert a record or when you
update a file the copy of the file is
made three times by you know but the
copy of the data is made three times
across multiple machines so you can use
HDFS and you can get you know durability
and availability from that particular
perspective you can also store the data
on s3 so now basically what I'm saying
is that your storage doesn't have to be
local disk it can be cloud-based storage
it can be HDFS it could be Amazon s3
it could be Google compute engine and
their data store that they have right
and you can have more than one Storage
Manager per database which means you can
say you know this particular date you
know this particular database has both
San and s3 or both San and or and and
and HDFS
they also have management tier which is
the one that has what is called agents
and brokers agents and brokers are the
ones that are that keep track of all the
different demons that are running you
know when they say elastically scalable
cloud-based database basically what
they're saying is that when a machine
goes down or when you know when you know
when a demon goes down they'll
automatically restart the demon it's
almost like the my sequel safe process
that you have that launches the my
sequel server and also the it's much
more than that the transaction engines
and the storage manage communicate with
each other the agents know where this
transaction engines are so the clients
basically are connecting to the agents
and the agents are telling which storage
manager that you need to go to but from
your application perspective it's pretty
straightforward all you need to do is
write your Java code with JDBC URL that
they give you and all the underlying
drivers will do all the work for you
automatically yeah
can you hold on the question because I
have a few more slides and towards the
end thank you so in terms of scalability
so let's say you have a machine you have
a customer database that you create so
you'll create a transaction engine you
need a transaction engine demon you also
need a storage manager daemon
so you launch the two demons now you
have a database going so that's the bare
minimum that you need in order for you
to create a database right so you got it
a single machine a single database ready
to go okay so now you look at this and
you say remembers scalability you know
that's the basic theme that they have so
you have a machine you have a
transaction engine and then you have a
Storage Manager engine so now what you
did was you basically split into two
different machines so now you're you
know you have two tiers now one tier
that's doing the transactional aspect of
it and the second tier that is doing the
storage management aspect of it so now
you're able to cheer it up you know
scale it that way but then you have your
transactions are increasing so now what
you're saying is that you need a second
transaction engine there is nothing that
stops you from from launching a second
transaction and Jen so the idea here is
that you could if you want to launch a
second demon that is going to be part of
the same customer database so now you're
launching a second transaction engine at
this particular point
okay so now you're like okay that's good
but if my if my top machine crashes then
I lose my database if my bottom machine
crashes I lose the database so let's do
something a little bit more creative so
now you have one machine that has a
transaction in djenne and then I have a
second machine that is going to have the
storage manager that of course will talk
to s3 or HDFS or San and then I have
another machine that is going to do the
transaction engine so basically what
I've done is I've created you know more
machines for doing transactions so the
idea here is that if one machine crashes
at least I have the second machine that
is going to be doing transactions for me
okay so now we can do it slightly
differently we have a customer database
that has a transaction engine and then
we have a you know the the back-end
storage manager the Storage Manager has
storage manager one it can also and then
we have of course second machine that is
that has a transaction engine too and
now we can have a second storage manager
that could be inserted in the same
machine assuming that your database can
have you know has enough capacity to
start a second source or imagine don't
forget both of these things the
transaction engine and storage manages
all processes that are talking to the
underlying file system okay so now you
you you know you you see what I'm going
here with this now I can have a
transaction engine running in a single
machine I can have database servers the
storage manager running on a single
machine and I can have it under the
transaction engine on a different
machine and I can have a storage manager
running on a different machine so now
what I have done is I have multiple
transaction engines I have multiple
storage managers now so when you insert
a record you know they get they get
updated and so everything is kept in
sync now and don't forget one storage
manager may go to san the other storage
may go to s3 or HDFS ok so now they have
also multi-tenancy so when you have you
know we are used to this thing when you
have a database server you can have
multiple databases that are in that
particular server so it's not a one-off
database so you can create your schema
so you have a you know customer database
that has a transaction engine and a
storage management engine and then you
have another transaction engine that you
have you can also have a catalog
database that has its own transaction
engine it also has its own store
manager again one machine with multiple
schemas multiple database inside it and
then now you see where I'm going with
this you can have you know a machine
that is its own transaction engines for
you know what both the database is and
then I have you know again storage
engine at the ball at the bottom and
then I can just keep on scaling this as
much as I want I can scale in any
different ways depending upon how I want
to scale my database instances this is
where this is like I said this is where
they have their patents and and and and
and their architecture and their
technology alright so now I can I can do
things like this where I have you know
multiple machines with multiple
transaction engines with multiple
storage managers and I hope you actually
the you know the when you see the colors
are not that great over here I don't
know if you're able to see two different
colors the sn1 and sn2 are actually two
different colors the sm2 is dealing with
a different dealing with it with
different database actually in that
particular case so now you're able to
score you know scale heterogeneous
machines multiple machines that can
scale for you right and and so on and so
forth you just keep going and going and
scale it across multiple machines in
terms of the technical architecture
there what is today object oriented
architecture which is what they call
atoms they have catalog atom database
atom transaction atom atoms are the
smallest unit of work that they do and
they communicate between these different
machines these different layers using
these things called atoms like I said
these are all these all the proprietary
technology that they use you know again
you can talk to them to get more
information on it
when it comes to acid they use what is
called multi-version concurrency control
notice in voltage DB when you update the
update all the copies instantaneously
write at the time and the transaction is
done here they do what is called
multi-version concurrency control which
means when you update or delete they
create new versions of it and then they
replace it and of course they have to
transact all these things together and
you know you know they make sure that
the transactional consistency is there
and also they need to in such cases they
need to prevent that there is there is
no distributor dead log and so like I
said that in the cap theorem there is a
possibility that when you do this you
may end up with a deadlock at some point
then this is where you need to figure
out what is the best way to organize
your system okay so when it comes to a
neo DB guys when you compare nuodb to
old sequel they're elastically scalable
even across data centers even across
data centers and I'm going to say this
to you it's just a question of time when
you know your customers are going to say
I want you to create a database table
where the data that is in Switzerland is
going to stay in Switzerland and the
data that it's in the US is gonna stay
in the u.s. they're gonna say this to
you are you going to create two
different instances of the database with
the Snowden case this is already
happening you know seven years ago I was
working on a project where we we had to
sell do some service to I think it was
shell where you know they basically said
seven years ago they said to me we love
your you know real-time
you know real-time database real-time
news database which is a you know blog
news database that I built and they said
we like it but we cannot host this in
United States we have to host it in in
you in Europe because the European laws
say that we need to have the data and
it's not subject to the European you
know us loss so the point I'm trying to
make is that kind of model is already
coming it's coming issue if you're a
global company you have to keep the data
locally so from that perspective this is
great new DB is hundred percent C equal
100 percent asset they have they have
good administration to its developer
friendly they have heterogeneous
database and its users they just rather
than having an in-memory only option
they're using in memory and also on disk
right so it's simple you create a table
just a normal way you know just a normal
way you do everything nothing new there
you insert records just like the normal
way you select statements like the wrong
way they have an interactive SQL
available for you will DB guys also have
an interactive SQL available for you in
terms of technical you know overview
from a developer perspective they have
drivers they have JDBC driver ODBC
driver and dotnet drivers for you so all
you need to do is you know you know pass
to this driver and start making your
JDBC calls they also have community
drivers for nodejs and J Ruby and Python
and Drupal all these different databases
and for Java developers if you're
interested in doing JPA right we don't
want to do JDBC
ourselves we want to do JPA you can do
ORM tools now you can do your JPA and
you can have a elastically scalable
distributable database at this
particular point and they also have
migration tools available okay so in
summary what I'm saying is that new
sequel is acid compliant sequel based
scalable distributed highly available
relational database systems it is a
trend in database technology to watch
for carefully a few commercial vendors
have already started implementing it
maybe you can start an open source
project if you want to there are a bunch
of references that I have you're welcome
to you know you know I think the
presentation will be available thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>