<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CON1780 - Microservices and Conversion Hunting: Build Architectures for Changeability | Coder Coacher - Coaching Coders</title><meta content="CON1780 - Microservices and Conversion Hunting: Build Architectures for Changeability - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CON1780 - Microservices and Conversion Hunting: Build Architectures for Changeability</b></h2><h5 class="post__date">2015-12-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/DYX64Thqu8M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'd like to welcome you to my talk mic
service and conversion hunting my name
is Dan ceuta and I want to show you the
way how we implemented software
architectures for changeability some few
words about me I'm an IT consultant and
I'm working for a company which is
called code centric we are located in
germany and i work in munich and i spent
most of my time with implementing
individual software for our customers
and today I like to show you what I'm
doing let's take a short trip out into
an HR here you see a crow witch wants to
open a not wish to speak and but
unfortunately this little guy is not
strong enough to open this nut so he had
to find out a way on how we can open
this nut so he looked around and he
noticed that there are cars driving
under the electricity cables and what he
does is he led the not fall to the
ground and wait until a car drives over
this nut and open mid and so he can eat
what is inside the nut for companies
this is a rule as well which we had to
do only these companies which adapt
their customers need will survive on the
market in e-commerce the e-commerce
business is mostly driven by one major
question how they can increase this
health and it's like open the nut for
the product managers in this area they
had to break the nut down so let the
customers by their stuff what they can
do is they can take a look to the
crystal ball and
what their customers need but nobody
really knows if a feature I would like
is like by other people as well so the
only way to find this out is to test
with real customer feedback because only
the customers can tell us what they are
really need when you would we find a
mere you wouldn't change the whole
recipe at all you would try out new
spices and then surfed in a mere to your
guests and ask them about feedback on
how the meal looks like to measure these
stuff there exists a metric it's called
conversion rate the conversion rate is a
portion of a number of course which
should be achieved divided through our
visit of the website sorry and the
basically describes how many customers
did an action beyond to visit our
website when you take the submit order
as an event it describes how many people
could be converted to a real paying
customer let's take a look how you can
use the conversion rate and to increase
your revenue here you see a Cabana
dashboard which basically shows us log
aggregation and i created the dashboard
which shows a check out final here you
see the users which was it the product
page then go into a check out and if
this up it an order they got an order
confirmation page as you can see there's
a very high bounce rate
on the left column and now we can make
assumptions why there is so a high
bounce rate and do some hyper taste what
is wrong with our website so let's take
a look to the uninsured on a left-hand
side you see a mobile which can be
browsed and on the right hand side
there's a very big recommendation panel
if you add items to the card the proceed
to checkout button isn't visible anymore
now you can make the assumption that
perhaps the recommendation panel is
responsible for the high bounce rate in
our conversion funnel so you can try out
to remove it and now you can deploy both
versions to two individual servers and
measure again how the conversion looks
like and as you see here we got a little
uplift when we removed the recommended
the recommendation panel you can use
this technique for other features as
well perhaps you want to try out the
color to change the color of the buttons
or change completely the design of the
website as you see it here and so you
can evaluate which one is really good
for our customers
for this easy features you can use a
design pattern that's called the future
toggle pattern here you can see wicked
panel which shows us how these pattern
works in this panel there's spring been
injected which holds the state of all
our features and in this life cycle
method called configure this feature
toggle beam is used to set the
visibility of this panel so it's really
easy but it only works for smaller
features when you want to try to try out
a completely new processes you sometimes
has to fight them with the application I
guess the most of you knows the
following situation you start with a new
project everything is fine you can
develop features very fast the product
owners are really satisfied with your
work and then the project is growing and
growing and you ask yourself what have
we done you have created a huge software
monster and if you change something on a
one hand side of the application a
completely other side can break and when
new people comes into your project they
basically asked how does this work
so we asked some disadvantages with our
way of development as well Emma Lee from
the development side wasn't satisfied
with our long future development cycles
it has several reason one reason for
this we saw was that at the beginning of
our project we could start the
application server in 30 minutes 30
seconds sorry and so we only need to
wait 30 seconds and then we get feedback
about changes as the project is growing
and growing and nearly takes five
minutes to do this then our bill x
increases
at the beginning of the project we could
build our application in five minutes
and then we add tests and tests and a
bill took 45 minutes that means if we
only want to deploy a wording change
into production our way to wait with a
45 minutes and two until we could
release this change and as I said before
sometimes when we implemented new
features we had stretch behaviors after
these changes and what for us wasn't
satisfied as well we know that during
the lunch time our catalog is visible
more often and but we only could scale
our application as a complete monster
our product management has some
disadvantages with our development
practices as well the warden isn't
satisfied this a long time to market for
some features which really can make
money and as it wasn't satisfied with
the way that a be testing was really
difficult we wanted to try out new
processes and we couldn't implement it
it's so fast as they wanted and like all
project managers and they had meaning
that putting new people into the project
made the project faster and so there
wasn't satisfied with the missus a
scalability of our workload so we had to
find a way how we can build our software
smarter and then we looked around what
are the terms which are in the market
two losses and we found the term
microservices for me and micro service
is basically a kind of functionality
which provides its own data and I
surrounded by a context so us singer
responsibility principle one micro
service only doing one job we defined a
stream major properties for these micro
service
should be small enough to fit in one
brain so when I'm in vacation and as a
co-worker should easily be able to
understand there's a micro service and
should be able to make changes on it but
for me the most important property of
mike services it should be replaced for
a design for real possibility as I said
earn in the beginning we don't know what
our customers really want we had to find
it out and perhaps we had to remove
certain kind of functionality and or we
had to add some new kind of
functionality and so we had to be open
for already stuff and the last important
factor Microsoft should be our turn
animals in case of organizational stuff
the best way is you only define
interfaces with another team and for you
it shouldn't be necessary needed to
understand the technologies which they
are using behind that you should use the
technology which perfectly fits to the
problems they had to solve around the
term of micro service you can bid and
taxonomy as I said the implementation of
microservice contains of business logic
1 and data when these micro services
should be communicate with an arbitrary
or each other you need some interfaces
or which can be used for the
communication like HTTP and rest and yet
to define some contracts on how the
message should look like and we define
for us that when microservice can
contain an application front end here we
saw the most differ difference to the
term service-oriented architecture or
frauds or because
the service-oriented architecture is the
same view of dividing functionality in
in small services but what you mostly
find is one monolithic front end on top
of these services then we thought it
would be good when we could these
service could put push these services
into an repository from where we could
easily orchestrate our machines when we
do this we need some kind of service
discovery because we won actually we
want doesn't want to know where these
services are really running we only one
to ensure that they are running and if
there are errors which can be a be done
and then we need some kind of monitoring
and logging to find out what is wrong so
let's do a short few over the project as
i said i implemented an e-commerce
system it was basically an online shop
and we found out that there are three
major use cases you had to provide an
catalogue which can be browsed from the
customers from this catalogue a cart
must be able to create it and this cart
must be finally ordered by the customers
on one day our product manager comes
into a grooming session and presented us
a completely new catalogue we saw a Cell
pro con mobile phone contracts and
mobiles and you should be able to
configure your whole contract with
specific mobile and everything should be
done fancy and we decided ooh this looks
really hard to implement this with our
current front-end framework wicked we
want to try out because of the whole
interactions a new JavaScript framework
like angularjs which provides us better
ways to implement these kinds of
interactions so we thought about how we
can integrate this in our current
architecture and how we can do it in a
way that we can easily remove these new
implementations I guess it's a little
bit too big and so we thought hmm we
have our old application and this can
take the check out part as it is and we
only had to add a new catalog we decided
to do this with in JavaScript single
page application which is delivered by
an engine X and gets us data from two
main services which should be deployed
within fecha which easily can be
executed with Java minus jar here you
can see the product and the card service
to perform the checkout we need the
connection to our card service and then
we could get a vivir we could proceed
our check out in our old application so
we decomposed the UI in a vertical way
let's take a look how these loops like
in the second demo here you can see a
reimplement ation of the online shop
with angularjs um when I put something
in the cart and their rest holds made
and when we took a look take a look in
the source code here you can see the
directive ng app which basically means
that is an angularjs application when we
now proceed to the checkout
we see the application looks the same
and we only edit and request parameter
which identifies our card and when we
now take a look in the source code we
see a completely different structure and
we see this thesis and wicked
application and here we can submit an
order as well okay so we got flexibility
we could choose the technologies we
wanted to choose to solve our problems
and we improved our feedback times
because this is a JavaScript application
there's no need for restarting
application service you only it needs to
make a change in the source code and
then can you can press f5 and see your
changes and we got a scalability from
now on we could scale our catalog as
well as our checkout process but we had
some challenges with this approach first
these micro versus needs to communicate
with each other as I have shown you in
the example one way for the
communication are links when these
microservices contains UI elements you
can link to services together and then
you can integrate this stuff when you
had to change to exchange data there are
mostly two ways to do this you can use
synchronous protocols like rest or
asynchronous protocols like aim to pee
and then these services can share data
if they need to chair the database or if
we define that it shouldn't be it's a
better approach to replicate the data
because so the teams can change the
database independently and the only
thing you have to do is to adapt the ETL
process
between these services so when we take a
look back to the three properties i
defined we got autonomy in case of the
organization's hi you might wonder how
you can deliver this stuff without
deploying three and more services
together because when you need to deploy
free services together they are not
loosely coupled we search a little bit
around and we found a law from a guy
called pasta and he has exact the same
problem as we handsome as he developed
the radio control protocol in 98 e so
this laws all of them me basically says
be conservative and what you do be
liberal and what you accept from the
others so let's take a look what this
mean here you see in west entity which
shows a user has five properties first
name last name sweet city and zip and
now let's support let's suppose we are
the client side and our cloud our server
gives us a new property which are our
birthday what we r do wed way now do I
have to do from the client perspective
is Billy be a liberal in what we accept
from the others so we basically has to
ignore this field this new field and
everything will work fine when we deploy
this service in production when we make
a bigger change like a completely bitch
I'm asking a change like we putting the
address in an array and add some new
field when we would deploy this
introduction our clients couldn't ignore
some stuff
everything would break so we decided to
duplicate delight the data for one
release mark this is deprecated define
some mapping rules from the neutral old
structure and write some tickets to our
clients please remove these fields and
restructure your API and so we could
deploy any service at any time
independently from the others there are
some alternatives to this approach the
most rest guys says the only way to do
it is to put a version number I know
where L or use a rest and accept errors
but we didn't choose this approach
because of the maintaining we wanted to
remove this old stuff as fast as we can
because everything which is in the code
and littles only sometimes used it costs
money ok let's take a look what change
this has to be done on the deployment
pipeline here you see and Jenkins I
don't know if anybody can with us in the
back is it better the build only
contains earth to earth for part sorry
the bill was made where all the tests
are executed then the application is
deployed to test system on this test
system we do some sanity checks in the
UI we all always wanted to ensure that
all shopping flows can be done
successfully and because we had some
trouble during no chain and
don't know if anybody knows spring of
you you can set these at cashable
annotations and then the application
gets really fast because everything will
be cached and when some one will move
this after emerged the application
performance can decrease and so and this
is not good for the conversion so we
decided to add some of these tests for a
monolithic application this is really
easy you only had to do these steps and
everything worked fine when you to take
a look to the build server and when you
have decomposed the application into
microservices you have several real
bills here you can see the catalog
catalog spirit and it's published and
then it did it's deployed on a test the
system as well and if you can see this
all these steps are done on the other
services as well like the product and to
check out service what does is basically
mean from now on we had a multi
deployment pipeline we could build our
software and parallel as you can see it
here the product service is built and
it's test I execute it and then it's
pushed into a repository and has the
same folder catalog view then the bits
of a deploys it like kikuo depending
which which fork is the first one who
pushed the artifact and then you can
execute your eye tests and the load
tests as well so we improve our bitch
times because there wasn't there's no
need to build a whole application
anymore but our deployments get more
complex so we had to find out a way how
we
and packaged our software in a better
way and we wanted to have a way how we
can describe our whole application as
you might imagine on this picture here's
the point where dockers comes into play
for us it provides us a very good
environment to build skip and run our
applications so let's see what does it
mean with this docker you can provide
the following workflow you can build and
docker image which has all dependencies
you need to run your application this
image cat you can push in a repository
on an atom machine you can pull this
image and run it and but you basically
get is a running process on this machine
if you want to connect multiple
containers you can use a concept which
called container linking what you have
to do is you have to name a container
and then you can use this link and what
what you for when you start another
container and what you basically get our
environment variables which are injected
in these containers and gives us the
position of this this this works fine on
when on one machine but we wanted to
distribute our application so we had to
find out a way how we can distribute our
containers and we thought about how can
we build and distributed system our idea
is you have some executor nodes which
gets a docker image from the repository
and started when they are needed
producers
it's some kind of scheduler which
schedules our applications and done and
resource allocator which searches the
free researchers in our cluster and paid
so node please start the following
container or this container is not
running please started again on the mark
they are currently 24 familiar too
currently two big players which
implement the solution for this one is
google scuba news in case of
coordinators the RP server provides the
scheduling mechanisms and you have a
couplet infoservice which do the
resource allocation stuff in the cluster
then there has to be some an agent which
is called couplet agent installed on
these executors nodes and then the
cluster is able to start and pull these
images ok Google uses three main domain
objects in cuban ages one as a pot the
pot is a single deployable unit which
came contains on multiple containers
what this basically means is you can
deploy a pot only to get as you you can
deploy a bunch of containers only
together a use case for this might be
you have an application and you want to
deploy together with a lot skipper which
needs to access the log files to do this
these containers has to be on the same
machine when apart dies on one machine
it's not restarted again for to do this
you need the replication controller and
you can tell this replication controller
a replication factor so you can scale
these pots across the cluster from the
client perspective you only want to have
a single entry point to these pots from
your side it's a real
land which part is chosen for your
request therefore in Google implemented
the concept which is called service and
I have on the machines is an agent
installed which the Pew proxy it
provides the excess from the client and
it's talking to the AP server and nose
on which hosts these pots are running
and redirects or load balance to
requests in a way let's take a short
demo how you can work with go bananas
here you can see the command line tool
from Cuban errors I have deployed the
whole application I had shown before in
a coup benitez cluster and as I said
during load times we wanted to scale
only our catalog now I can show you how
easy it is to scale the catalog you only
had to resize the replication behavior
of the cluster with the cube control
resize command and then new machines are
started in the cluster here you can see
that we got three new catalogs and now
we can try to access the IP addresses in
our cluster and as you can see all three
nodes has a running version of our
catalog now and we can submit an order
as well let's design decrease the size
of the cluster as I said at the
beginning we had to find our term what
our customers basically need so let's
see um how Co bernetta supports us for
deploying our be tests AP tests and in
rasta I'm now deploying another version
of our catalog in the cluster which uses
an alternative implementation of our
check our so we should see and Aeterna
to check out design when we exit exit
accessing the classic here you can see
that the pot is running on these IP
address and now let's access these IP
address and when we enter the check out
you should see a completely new design
okay oops sorry kinetis has some advice
advantages for us are you need care
where work is executed you needn't care
about dependencies from the deployment
side you got service discovery as I said
with the service abstraction and who has
a process supervisor which with a
replication controllers which checks if
task are running in the cluster and when
this task are not running in a cluster q
they are we started but we saw some
disadvantages when we take a look sorry
how you this one how you define these
pots and replication controllers you got
a lot of fires for already stuff
everything you see here is needed to
deploy a coup the whole application in
our cluster you have a card catalog and
we wanted to have a solution which is
like dr. Campos where we easily can
define our application abstract
from our deployment in in the cluster
some other disadvantages we have seen is
that the failure analyst of course will
get harder because now you had multiple
machines you don't know exactly where
this machine where where a scar running
and at the moment to Benitez the
kubernetes master is a single point of
failure when this master crash your
whole cluster will not work and at the
moment there are only few tools and
documentation available for it so we had
to look around a little bit more and we
found a combination from marathon and
measures in case of these two tools
marissen does the scheduling part you
have the measles master which can have
standby masters and when one masters
crash election is made and the new
master is spin up and you have some
slaves which do the orchestration and
executing stuff from local repository
but we wanted to we want to describe
release scenarios for us it's really
important to test a new feature first
whistle with a small amount of our
customers this technique is called can
release you basically have to when you
don't work with containers you have to
infrastructure groups this might be
changed for your specific use case in
the most use cases you have an
application server and the database and
it allows you to deploy an old and the
new version of the software as it so you
can deploy a new version of your
software on completely different
infrastructure environment
and in case of a Bluegreen deployment
you would switch from the old to the new
one and in case of an cannery release
you only route the traffic here you can
see we mostly take five percent of our
traffic to test with our customers and
with the ninety-five percent we make
money so this is what we want to have
for cluster configuration and medicine
medicine doesn't provide this alone so
there's a new of framework which sits on
top of this container manager it's
called when or very awesome micra
service platform it provides us and dsl
where we can describe our Microsoft's
application as a if it's all is it is it
all like in like it's done and docker
compose here you can see how such a
description looks like if someone close
to dr. Campos he might see that there
are really strong connections to each
other what you does is basically you
define our name of a version which part
should be executed and then you can
define these services independent from
their deployment because you don't know
where these services I actually deployed
you can use placeholders which at the
end will be will be replaced by when and
injected correct in the containers from
marissen you can choose a scalability
and you can define routing rules let's
take a look how such a routing rule can
look like
you can choose a percentage or you can
choose filters here in this case I
choose that only Chrome users should see
a new version of our catalog with the
alternative check out design let's take
a look how these works here you can see
in Marathon and now I am deploying the
application which basically opposed to
the AP I server now wimp is
orchestrating our application as you can
see this is done really fast
and now we can x now a container started
and we can access the application and
proceed to checkout I hope done add some
new stuff and finally submit an order
okay let's try it again the design is
same not now let's deploy and a/b test
into our cluster to expected behaviors
now on that when we are in here we see
that the class with Nelson is actually
deploy a new container and expected
behavior now is when we enter to check
out in a Chrome browser we should see
the green design so let me show you that
I'm really in chrome here this is the
chrome browser and i'm being going to
check out again you see it's green now
let's do the same with firefox entering
the website put some stuff into our card
now proceed to the checkout CC now we
had the white design let's do it again
to verify that there are no other stuff
around when we enter the check out we
had to write design as well now let's
remove the chrome filter and Route fifty
percent of our users to the versions of
the software is this means on every
entering of the the check out we should
see a new design as you can see nothing
is redeployed and the class
and if you enter the check out in chrome
we got the right design now we enter to
check out now again you should see the
green design and the same should be
undone in Firefox now entering now we
have two green design when we do it
again we have the white design ok that's
the presentation yeah all this
orchestration stuff is done by a web
core and the routing rules are used by
web browser which is programming and HR
proxy this HR proxy is responsible for
the bridge from outside this cloud meets
basically this is the internet so this
our user requests it comes in to our
cluster and these requests are routed
over this HR proxy and then goes
directly to the container to collect
metrics web has a component which is
called them pulse and this component is
responsible for collecting metrics for
the routing or what you can also defined
in the DSLRs la's when response time
goes down they are automatically is new
container spend up and if the response
size increases again then this
containers are removed so when provides
us a description of our whole
application and we could describe
deployment scenarios from now on we need
in care where work is executed we got
high availability of our masters we has
some kind of process supervisor which
shakes if our applications are running
and we got service discovery but what is
not so good you have many components
which has to be understand and as it is
by eight Cuban errors the fella analysis
will get much harder so let's take a
look how we can avoid this problem so
how can we keep our Microsoft soap clean
as I said in the beginning there's an
tool which excess exists which called
Cabana banner is part of the x tag which
stands for elastic search which indexes
our log files which are collected by log
stash log stash is kind of ETL tool
which can extract your text files pull
the data out of it and put it to
elasticsearch so that it's easily
searchable and on top of elastic search
they're sitting Cabana which is this UI
which you can see here here I have shown
basically in histogram of our HTTP error
codes okay how you can use the X tech in
a distributed environment let's suppose
we have to follow a ring process we our
checkout submits an order to an auto
service these order service requested to
payment by premier provider and the
payment provider concerns are confirmed
our payment and then the order service
can send
and skipping request to the ERP system
when you want to track these it's a good
approach which is not new again the guys
which promoted the service-oriented
architecture and to use it dis
approaches where is you had to put an
weak correlation ID to each HTTP request
and then you can easily track it in
cabana to do this this is really easy
with modern lock frameworks here you can
see an example of a lockpick you can use
the map diagnostic context to put data
in it and then over the whole request
this wrestler this request ID is stored
in this context you only had to do your
lock info or log debug stuff and you can
configure the console appender that this
correlation ID is put on front of each
block message and this log stash you can
easily extract this ID and then it's
searchable in cabana ok what are the
takeaways of this session microservices
supports a be testing very well you can
choose efficient technologies for
solving problems and this for me means
them that you come back to a solution
orientation you mustn't care about
technical boundaries and for me as a
consultant it's really important that I
incrementally can migrate the
architectures ahead when a customer
calls me we had this pain point I can
focus on these pain points
take care take a look how I can
integrate me in his current architecture
what I need what what you need for this
microsoft stuff is a good kind of
monitoring as i have shown a centralized
logging i fully automated deployment
pipeline and which i am at the end of
the day talks to an cluster management
tool but what I am mostly see is you
need an organization which is which is
ready for this microsoft stuff when you
have a department which is used to
deploy mafia them with a hand room they
see that they will use data values their
jobs when you introduce a cluster
management tool and so you have to do
some political fight let me close with a
short this complainer Microsoft's
doesn't guarantee more conversion only
the experiments with your customers use
it but microservice can we do for you is
to make it easier to do these
experiments okay then thank you for your
attention all these slides are available
in github as well as the example I have
shown here I guess we have 10 minutes
time for questions so are there any
questions okay then thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>