<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>結局、最近何が流行ってるのか？ Graphによるトピック分析 | Coder Coacher - Coaching Coders</title><meta content="結局、最近何が流行ってるのか？ Graphによるトピック分析 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>結局、最近何が流行ってるのか？ Graphによるトピック分析</b></h2><h5 class="post__date">2017-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Q4QCRSTVi-Q" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi welcome everybody thank you for
attending my talk today so I like to
talk about graphs and in general my
topic is what are they talking about
these days and I want to go through a
demo with um to analyze topics with
grass first of all I would like to thank
the immediate video Bertolini and Daniel
Henry who prepared most of the slides
and W also presented the very similar
demo in Prague and in London at their
local code comments so my name is Daniel
Anglican I'm working at our collapse
endowment in the US and our collapse is
the research and development from Oracle
so you have to present to the safe our
statement slide and everything you see
here is still in the old development
it's research and we're not sure whether
or not it will be released in the
product so don't make any buy any
decisions to buy products based on this
presentation today so in a nutshell um
what am I talking about today so I want
to show you okay what what are the most
weakened topics people people discuss
and how do they evolve over time and
then I also want to talk about and who
are the experts in a given topic and all
this space on the stack exchange firm I
don't know if you know it and it's one
of the most popular programming forums
for software developers and I
specifically want to talk about the
movies and TV section of Stack Exchange
so people will ask questions in this
forum and other people can answer them
and then you have accepted answers if
you answers good people can accept it as
an answer and so on and in the demo you
will see more of the of the slide on the
right from the right side so you see
that topics evolved over time you will
see okay who is the most actual in the
different topic and I will go into that
good later so the session agenda is that
first of all I want to start to explain
okay
what is the data set like the suspected
change firm and what are the objectives
what is it it would like then I want to
explain on one single slide and what is
topic modeling and then I want to look
at this as a graph in general and then
in the end I explained to you the tools
we are using and I will demo it for most
of this presentation today so what is
the data set like I said before it's
from Stack Exchange from the movies and
TV site which started in the early 2011
and the BAM was created March 2017 it's
available freely under archive.org
so you can download it you can play
around with it and the objectives are
that the topic modeling I want to see
okay what are the most discussed topics
of this tech exchange firm and what a
popular text and then I want to see how
how they evolve over time and then in
the second part I want to see okay who
do I talk to if I want to if I have a
specific question to a certain topic of
the state exchange firm so I want to
find out okay who are the experts in a
given topic just a few work to the topic
modeling in general the KPD assess it's
a type of statistical model for
discovering the abstract topics that
occur in a collection of documents so
what does that mean one of the classic
approaches is Lda which essentially
takes in as input a collection of
documents and then you also take as
input a parameter okay how many
different topics do I want in this from
this collection of documents so for
example collection of documents can
include the word cat in banana and it
goes into this model example this lde
model and then in the end I will get an
output I will get certain documents
designed to topic and in this a classic
approach you get the percentages from
documents to topic so you know okay
document one we are 100% certain it's
about topic number one
however in documentary for example you
can see that 30 percent of the
it might be related to topic number two
and 70% might be related different topic
our data set has a slightly different
structure so it's not just a collection
of documents it's the SEC exchange tab
like I said before and the tech exchange
stamp is available in XML files every
single category of the section change
stamp is available and as you see in the
structure so we have we have a lot of
XML files and we only look into the post
text and users today they are also way
more other areas of this circuit change
down and you see that there is the world
ID there's an accepted answer creation
date the body in the title and then the
most important part is good text and
then in tactics mluc ok this is the tag
name they have two occurrences in this
case and so on then the user context
model is similar so you have properties
assigned to these XML files so in
today's demo we only show a certain part
of the exchange form so we only care
about the users the post in the text I
mentioned the comments blend in very
similar font we ignore them as you see
later on in the new you see the
relations between the users and post and
text so users right in general post post
can be questions can be answered can be
comments and a post can also have an
edge to itself so if we transform to a
graph you can see okay this post is the
question and then there's another
positive answer and that's the answer of
this previous question or it can be an
accepted on so for example and then you
have the texts which are essentially
every question can have a tag puntos in
general cannot have texts or own
questions will have text I won't go into
detail how we pre process this data so
you can just assume that we equated
we're out of this and the result is
actually a graph in the form an edge
list which is one common format
to load into graph analytical engines
and for the IP within which we will
apply later on we edit we birth edges
from text to post and post to post stuff
to highlight the structure of the square
because it's essential for the algorithm
to work yeah and then we looked at the
topic analysis part of this presentation
so and the approach is that we want to
find communities within these let's
graph and for this we're using the map
equation algorithm I don't go into
detail here
and we're actually using a parallel
version of this code relax map so it's
highly efficient highly performant and
it's non-deterministic so if you execute
it again then you might get slightly
different values but overall it's quite
quite a good algorithm to visualize this
and so we use this relaxed map approach
for the graph structure so essentially
what it's doing is it's looking ok I
have this question I have certain text
assigned to this question and there are
several other questions designed to the
same text so we kind of can figure out
ok there has to be like a community I
want these two questions and texts so
this example here is so the I think game
of some Game of Thrones question where
you see ok and it has the text casting
the Great Gatsby and I love this book a
lot Game of Thrones but yeah you see you
see the structure it's just a snippet of
the graph we actually look at later on
and whereas the other approach said ok
ok this topic is 70% assigned to the
document 70% assigned to a certain tag
we have only clear cuts that means that
the document is only in sign - so we
don't have any probabilistic mixture
it's always hundred percent so post Xin
to one and only one topic in the end can
have multiple text but it's only
assigned to one topic
yeah so I'm working at Ulta PGX in
Belmont in the US we are a graph
analytics team where we started
developing this five years ago I joined
two years ago and it's an easy
application for graph analysis for the
dataset and it's already integrated in a
few broad project like the Big Data
spatial and graph team special and
graphs and a DBMS and it will be in
upcoming releases of example advanced
analytics in general we are working with
property graph the graph properties and
labels and there are two major
approaches if you if you look at graphs
in general so you have the computation
the graph analytics 101 you want to
iterate over the graph and compute
properties or statistics but then you
also like to have some kind of pattern
matching some kind of like sequel like
experience when you when you look at the
graph you want to see okay giving all
the notes with a certain attribute give
me the connection between certain notes
in T Jex we sort of both approaches we
have a Java API for this we can write
algorithms in green mark which is in
language also developed within our team
and then we have P gql which is the
property graph query language which I
will look into later on as well and to
use to use PGX we have several different
ways we have the GUI shell so you can
just write Java in the shell and execute
algorithms and then we have the Oracle
apps data studio which is still on the
development and it's not a product and
to mention that again and we were
looking to their own collapse data CD
now so for the demo like I said our
collapse data studio it's a notebook
like environment for the people here who
don't know what north of side note books
are and collaborators interactive
documents so you can just write code in
the on the front inside you can let it
be evaluated by the server and then you
can visualize the result in what you see
here with the percentage of percentage
PGX and percentage spiritual our
interpreters and interpreters are
essentially
they're written in Java in our case and
they will evaluate the query or the
information we passed into it so if we
do some select statement and pgl it will
be sent to the server and then the
server will take care of the we go
yeah and we're planning to release this
in the next upcoming tech reviews on otm
so if you want to try it out or contact
me or just look at the or GNU aside from
PGX
and might be available in a few weeks
and again we're looking at the movies
and TV firm from Stack Exchange today
okay so the headers cut off but the
Jesuses or collective data studio can't
show it right now so what you see here
is we minimize a bit again what you see
here is this white rectangles here these
are paragraphs so-called paragraph this
is one notebook
one example notebook I prepare for the
demo and if I look into this so this is
knockdown if I show the code here you
can see that what we did here is we end
up in the first line you see percentage
MB which is a mac down and then we can
just define okay what should be executed
so here we say okay I'm just an overview
of the of the demo today why this
because usually we don't want to see
markdown code so our demo starts with
just initializing a few whoops you can't
let me improvise
okay now you think the edge of it so
what you see here is we just defined a
few functions we will use later on in
the demo so just to get the average of a
long long area long and without set or
get the max value or min values and if
we want this to hopefully say notebook
successfully initialized it will stay
like this okay now we have initialized
the first part so what we do now is we
start writing the code to to load it
into it into the graph so what you're
doing here is
okay um seconds
okay I can't show you the last line of
this private but what we're doing here
is every node forgets its own session so
if you work on the graph you are sure
that if someone else works on the same
graph in a different notebook then you
don't interfere with it so you have your
own graphics loaded in memory it's one
of the features of bgx and then you can
work on it so what we're doing here is
we read the graph with properties which
is called movie stock exchange and
recycle exchange is the configuration I
showed you for earlier on the slide and
we saved this in the variable USU PT and
then what we do is we create filters for
this this graph so vertex is essentially
just looks at the at all vertices of a
graph and say okay is the filter applies
then we include it in this is the graph
otherwise we will just throw the node
away and then edges which are linked to
note that it's one away as well so what
we do here is we refer where vertices
which have the vertex name plot
exclamation or identified this movie and
we do this because I found out during
the demonstration that most of the
questions have this tag is identified
this movie or explain the plot so if we
keep this vertices in there then the
algorithm will not work that good that's
why you for something module and this is
essentially the graph with which
includes user posts and text and then we
create a second paragraph the second
graph called just graph PT so it's only
the post in text relation so we skip the
users so what we do here again we create
a vertex filter we say okay we're only
interested in the vertices that have the
label post or the label check and then
essentially we would print out the
result it's a only hidden you can see
right over here so you see that in 200
milliseconds we load up the graph see
some some information about it that the
note size there's 75 thousand notes in
the first graph with users and then we
filtered out 30,000 notes to only show
the power some text in the second graph
okay so let's jump to the first wheel
coding paragraph which you can see here
so this is the P gql the property graph
query language which I mentioned before
what we can do here is essentially we
can ask for results of the query by also
in some way visualize it as a graph
itself in the query so what you can see
here is the demo interesting part is the
where statement here and where CN e and
M and you see that the ends kind of
formed like it's like a note so this is
a node called N and it has a relation an
edge which is in bracket so just the
name of the edge and then we have a
second node called M so we want to have
all the nodes that have matched to
another node and you also see the
direction so you see that okay from n it
should go to M and what we do here is
well we group it by the labels from this
node from from the first note the second
node and from BH as well and just to
show you a summarization of the graph so
in the end what you see is that what
without shown here is that a few notes
with the powers of question have to have
an edge to another node and the edge is
called hash tag and it goes to a tag of
course which is the label of the second
node and this is actually the most
frequent occurrence in the graph so
there are 20,000 questions to tag
relations you see that other texts are
other labels are not that frequent in
the graph such as the tag tag off the
post it's not that frequent here so if I
want this that we have it here and then
you can you can like query something
similar to a sequel so if I do a limit
10 I only get 10 elements instead of 11
and you can you can play around with it
then if I look further down just another
way to visualize it 1 2 3 ok give me all
the give me the number of occurrences
for certain labels in the graph so what
you see here is we do select ended
labels a count star in the end and then
we say okay I'm not interested in the
edges at all that does have to be an
edge between and we don't
there's no Ian there we just want to
have the notes and let's go into another
note and then we group by the labels and
what you see here is that most of the
notes are from tied user because we are
using the user post tech graph here if
we query the PT graph then this will
only include post some text and yeah
some kind of visualization here too to
realize okay how when your crimson so we
have and then we can play one with the
visible visualizations like you've seen
in Jupiter and Zeppelin for somebody you
can make it 3d you can change the order
you can have titles to it and other
other things
okay so a few more power graphs to just
get information about this direction of
the graph so what we're doing in the
next paragraph is we list all the texts
and how many posts are associated with
that check so again we do a select
statement we say we want to have two
texts that name the only transit in the
name of the tag and whenever count star
followed by the where statement where we
say okay the text you see here in this
images but it has to be of type tag so
this is a node which has to be of type
types of tag and there should be posts
going into this text and then we go by
the tech name to get the number of
occurrences and we also Aude it to not
show too much information what you see
here is that um we extracted these
identify this movie and the flood
explanation earlier so now the most
frequent tag is character and then
followed by analysis identified the TV
show which we could have also extracted
and other other text and now we are
interested in in seeing okay so who's
the most active user based on just the
written post it doesn't have to mean
that this is also the most talented user
and yes the most knowledge is just who's
spending the forum the most so what
we're doing here again is we have a
comma style followed by group later on
and we want to have to end up this play
name and in this context if a user
because you see it's a type of user
and again the H is not interesting so we
skip that and we want to see okay this
user has a post as written post and we
group it by the user so if I execute
this okay there are too many others who
are limited by for example 10 if you
only get a few values so what you see is
that Walt here was 20% so 20% of the
posts from the form of written by Walt
that's quite impressive the world seems
to be very has a lot of knowledge about
this forum about movies and TV or maybe
he's just aren't asking a lot of
questions and he has no knowledge at all
so let's jump to the next paragraph so
what we're doing here is we just
the users by the reputation so this is
just a good indication to see okay has
another to do the knowledge in psychic
change firms it's like if you ask a
question and someone uploads you then
you get points so called reputation and
if you have the accepted answer then you
get extra points so asking a lot of
questions don't help doesn't help you
here but answering questions will and if
we execute this might take a while then
we see that world is still very good so
he's not just spamming the firm with
host group questions but he's also
answering a lot and here we can also
play around with the visualization and
can say okay I want to have it like in a
vertical display here and what I forgot
to mention in the beginning this is all
written in JavaScript and Oracle Jets
we're using our cadet for this all the
visualization library with the
visualizations you can see here from
Oracle jet and accept the graphical
civilization which is based on d3 which
I will show you later on so yeah so you
can play around here with the
reservations you can say I want to have
it as polar coordinates I don't know the
extent in this context but you can
potentially change the visualization and
if we if we just clear another example
here we just want to list the user apply
accepted answers so who has the most
accepted answers again it's just
defining the where statement we want to
view this they'd have an edge which is
called white post which goes to an
accepted answer and then we just group
by this user and because of the count
style and the display name we get the
user and the number of occurrences so if
I execute this we get this visualization
here of the line shot and then you can
scroll in or can only so certain parts
of it
okay so now what you want to do is we
want to see okay how are text and users
related to each other who is an expert
in a specific tech so what we are doing
here is we have the Select statement
which gives us the number of occurrences
and then the user with the according
tech so if in what areas of the sex
change form for example is world and
expert in and what you do here again
what we do here again is the group it by
the users in the text and ordered by the
answers in a destiny order so we get the
this kind of result I can execute again
to make sure that this is up-to-date yes
we get that Walt has answered hundred
fifty six questions and identified this
TV show and he's also the second in the
list with 120 answers in the category
horror so he's an expert in power and
then you can visualize it as a tree
diagram here although this information
so there's no user information in this
sort of reservation so what we do here
is we add the user into the groovy so
currently we only group by the tech but
we can also say okay I also want to
group by the by the user name and what
you see here now is still the rectangles
all have the same size with the text but
now you see okay in the text
character CDE the user CDE is the most
expert in and then you see that Walt is
for example in identify this TV show
here the expert and you can also switch
it around to say okay I'm interested in
the user and then in the text so you
just switch the order here and then you
see okay Walt is the expert in
identifies this movie in a horror in
science I guess something else so you
see a good visualization about what text
is specific use is knowledge
okay now we come to the first
graphitization so what we're doing here
is we just look at the graph and we only
int was around interested in the post
and detect that it goes to so then we
have this rare statement we say there's
no it should be of type post and it
should has an edge which is called
hashtag so I'm going to only include
questions in text and then we want to
have a tag which is of type tech so if I
execute this we see that here we get
certain documents I can right-click on
it to get more information about it so
here this document had the question why
did Vader
oh you can't see it too bad okay now you
can see it so the title is why did beta
dislike quench that's probably a Star
Wars question and then you see that this
is linked to work one so this is a check
to word one so this is in the most
recent Star Wars movie
okay what you can also do is you can
look up answers to random questions so
what you're doing here is we want to
have the answer for one question and we
limited by one so we only get one result
and in the West I mean what we define is
we want to have the answer which is some
type post and it should have an edge
which was type accepted answer office
and then we have a question which is the
post again from time post again and
which also has text that we have this
relation from from an answer to the
question and then to the text that's
what's essentially what we're asking you
for and what you see here is that in
this line where you say dollar and then
a bracket tech name this is dynamic form
it's also relevant level n for example
so what it allows us to do is it allows
us to hide the code nobody should see
the code but you should still be able to
to decide on your own methods of taking
unlike so in this case it's the walking
dead execute it then I get this random
question why does Eugene from the
walking dead speak in this manner and I
think I right-click on it I will also
get a video yeah
and in the question itself there was a
video about Eugene how he's talking for
you you see that in this tooltip as well
and then you see the answer is because
using a socially awkward so if you do in
this graph okay so this was just the
first part of exploring the graph itself
what does the graph look like now what
we want to do is we want to find the
communities that are spoken of in the
beginning so what we're doing here is we
are running this relaxing algorithm
which I explained earlier just to find
like a common structure of the graph I
won't go too much into detail of the
code here because we will except in
green written remark is quite
complicated just just for you it takes a
few input parameters you take the graph
as input and then it will just calculate
the relations in the communities so I'm
skipping the rest of this paragraph I
can just execute it hopefully yeah
hopefully it says that this of the
compiled program it's called parallel
weighted relaxed map and what you can
then do is let me quickly change the
size because it comes full screen what
we then can do is in this first line of
code we can say okay give me this
program which are just defined to you
and earlier in this paragraph but this
paragraph share the same context and
this is actually the movie so what you
see here in this percentage projects
this is all written in Ruby so we get
the parallel rated relaxed map we save
it in this variably relaxed map and then
what we do is we have this graph with
posts and text and we create a copy of
all of it so here in clone we just
created it copy out of it because we
don't want to change the wheel we're
going to create and extended extension
so we save this new graph into the graph
GPX
for extensions and then we create new
attributes to these vertices so
everybody attend support property like
you've seen like a name like the
question for example or the creation
date so we had more properties such as
PageRank community IDs and rates and
further for the weight part we also
initialize it with be followed with
other ones obvio value and what we can
then do is we can we can run
arguments on it so what we say here if
we say analysts that our algorithm
engine so to say where we want PageRank
on this graph which we just created and
what you see here we passed the truest
probably just overwriting the previous
value we passed the PIL property in
there and the PR property is just a
PageRank property which we just created
so now we fill this value with more
meaning and then we we proceed and we
run the relax map algorithm on it and
the relax our algorithm has a towel
which is just to to configure ok how
many what is a degree of them of note I
should include it into the community and
then we have the tolerance value which
is similar so the values are just
experimental that is we tried and we had
good result with so they don't mean that
much and because of non determinism
non-deterministic we executions may be
of slightly different without we say ok
there's an boundary and upper boundary
which is dirty so if the ID was in
Dublin and after 30 iterations we would
say ok we stop here and you take those
those in there and then we just print
out a few informations we teach from
there so application is just to print
out the result so if I execute this this
might take five to ten seconds the goes
over the entire graph so you see that ok
we found two thousand two hundred ten
communities so these topics and in
average every tag every topic has 1.3
text only and I average the topic has
5.5 posts ok so let's look at the
communities what can we do here we can
say oops sorry you can look in this
paragraph here and we say ok give me the
5 communities in terms of number of
texts in there so if we executed we see
ok community number 70 80 s 31 text in
there so this is quite large community
we can also look up the next paragraph
okay what community does a specific Tech
belong to some harry potter fan so i
will just execute this command with
Harry Potter and say you see ok Harry
Potter belongs to the community four
thousand two hundred eighty six I will
just copy this because we will read it
later on and this again is just using
the dynamic form so we can type in
anything we want to we can play here are
examples I think Star Wars is quite
common community okay after I was three
thousand format fifty nine and then we
want to see okay what are the specific
texts in in this one topic which you
just created so if I report I we just
had four thousand twenty eighty six so
what we do here is we execute it and
then we see that common text in this
community the community doesn't have a
name but the common text in the
community I sent essentially are all the
few books from Harry Potter I think all
the movies yeah the movies to go to just
a Hello has to pass there so if he is
here that the community works out very
good in this case of our reporter we
have a quite good quite good text
community relations so if you look at
dialogue for example three thousand four
hundred fifty nine type it in here in
the topic ID executors then we get the
Phantom Menace for one the Clone Wars
and you hope which is also quite a good
fit I think and then what we can do is
we can look at certain answers to a
question so let me just look up Harry
Potter again because of about thirty
four thousand two hundred eighty six so
what we do here is we can execute this
again I mean make it a bit bigger
okay so what you can see here is one of
the most frequent questions is why I
didn't have a himself during Polyjuice
potion instead of all the others in
Deathly Hallows Part 1 and then you see
that from this question they go there
are a lot of etches going away from so
this question has a lot of answers which
you can see here and it has only one
accepted answer which is a blue one you
can see here in the in the highlighting
of the legend and I'm interested in the
answer so I'm just white clicking again
okay there if you move too much text I'm
not skipping that
what you can also do is we can verify
that every question has its maximum one
and one accepted answer so we just want
to verify okay this Decker change form
is not some our Hecht and s multiple
answers and what we do here is we select
the question title and then the number
of answers add a link to this here we
use for the first time the concept of
path so what you can do in PG QL from
the first time you can you can define a
path what should the path look like and
this path is called we play two and we
say okay it should it should go from the
post to an accepted answer to another
post so from the question from an answer
to a question and only the accepted
answer and we can reuse this path in the
Select statement so what you do here is
we ask for the title for the number of
occurrences and then we have this
website and we say okay the answer
should be of type post it has we play
two parts in there so there should be a
path from the answer to there to the
question with this structure and then we
group by the question title just to make
sure that there are no duplicates in
there and we confuse that the count out
from the maximum is 1 so our group this
the form is not multiplied okay so this
was the second part the community
section now what we want to do is we
want to find experts in a given topic
and how do we do that
further well we we only worked on the
graph post in tech this is one of the
created graph what we want to do now is
we want to include the users into this
so what you can see here is and we again
we create a new graph which is
essentially a graph of wanna modify next
from the user post tech graph and then
we want to create a vertex property
called community ID which you see here
in the next line for this new created
graph and we also define a new vertex
filter which says ok give me all the
text so the vertex folder will just
essentially filled out all the other
nodes it will want to include the text
and then what we do is we iterate over
every vertex of this new created graph
and what we then do is we to let you see
here which will get text vertex filter
pest so we only get the text from the
new graph and for this tag we get the ID
we get the topic using the previous
created graph where we passed the idea
of this vertex and then what we do is we
assign this community ID which we
previously have calculated in this
smaller graph with postal text and
assign it to the value of this new graph
you the Coast tech graph we did this
because of the structure of this
algorithm if we include the users to
this algorithm then it might return
different results that we cannot really
use so we execute this I wasn't only on
the post tech side and then we extract
information from this graph and add it
to the news through the post tag left
and let me quickly look up the community
ID again my brother's with photo 286 so
what we do in the next paragraph
let me quickly change the sides again or
I haven't executed this and this might
take 30 seconds so I can explain the new
paragraph in the tweet so what we're
doing here is we get the top five users
with the most accepted answers within a
certain topic so previously we asked for
the most accepted Antle from the user
for tech now we're looking into the
topics so what we're doing is we have
the Select statement again which returns
the user display name the count star for
the number of pulse it has he has
written and then the community ID as the
community ID and in the website when we
define again we have a note of type user
which has written a post which has an
accepted answer to a question which is
all from that post of course which has
text with specific this community ID
which we pass into the topic ID here so
if I do Harry Potter here in the topic
ID what we see is that Walt is also a
Harry Potter fan
yes certain posts written certain
accepted answers in this Harry Potter
community and we see that 88 also quite
close to what and now we're interested
in okay so in what specific text of this
community has world answered to so what
we do again is we extract Walt here from
the table and we say okay we add this at
the username in this dynamic form we had
the topic ID from Harry Potter again and
we execute the query and what the query
is doing is its selecting again the
number of accepted answers in groups by
the text from this community so it's
similar to the previous paragraph but
it's more details about the text so he's
a more general fan we answer to Harry
Potter as attack a few to the charm of
secrets and then one each for the
Deathly hello
okay so now I'm also curious about what
what what questions the world answer to
so we can we passed the username in here
and we bought the topic ID from before
and we define the path in the beginning
what they accept the answer again and
instead of grouping it by the user and
topic we also group it better I will
remove it by the user and that returns
us a list of answers he has a question
see a Santa too so we see that he knows
what the nature of sabe what what the
nature of wdl and all the other
questions he was able to answer
okay and then in the last part of the
presentation we want to look into the
evolution of these communities what
happens if we do the topic and another's
over time so in order to do this what we
do here is we split the whole graph into
three different epochs so we look for
the first written post from this forum
and the last written post so that we
know the min and Max values and this
using the get min longer get Markland
functions which we have defined in the
beginning for the initialization so we
get the first data of this paragraph we
get the last date and then from there we
can just calculate how long in one
Airport is supposed to go
so we execute this and then what we do
here in the next step is we create this
new graph again which is called graph ki
te box which is also the clone from this
graph with post in text and we had new
vertices to it
we had the epoch vertex to it the
community ID patient in rate shortages
and then thus for the visualization
purposes we print out the report lists
so what we see is that the graph is now
divided into three twenty bucks ranging
from 2013 from though the first one is
from 2011 to 2013 and to 15 and then 270
so two years each epoch
okay and then in this paragraph you see
the offensive statement the beginning I
don't execute it today it will stop
executing because it's already defined
because this one once a few minutes and
I don't have these few minutes but what
we're doing is we're creating a change
that from this graph we created before
and a change that allows us to add edges
and vertices to the graph otherwise it's
not allowed to put up internal
structures of the graph the words will
change that we have a separate graph and
then we can wait over these epochs and
what we do with the eg boxes we define a
vertex filter here which gives us all
the posts that are in this epoch so we
have this min date and maxilla of the
feedback and we filter out all the other
vertices so we're only interested in
this specific time so here we apply this
in the filter method and and then what
we also do is for example we want to
only see all the posts from this import
so we create a new vertex filter to get
all the vertices with the labeled post
and then essentially what we do is
exactly what we did before just on this
small portion of the graph so the whole
entire graph we won PageRank and the
relaxed map algorithm just on this epoch
of the graph we passed the same telling
tolerance values in there the same
maximum situation and what we want to
have in the end is we want to have the
community IDs just collected from this
one portion of the graph from the entire
graph and again this time like you've
seen before the topics name will just be
the just the union of all the texts that
are separated by a comma
let's also join that you can see it
later on
I don't one this paragraph okay let me
okay now we want to see what does the
topic look like in one a park and what
does it look like over time so what
you're doing here is we want to have the
topic name the topic epoch and then tech
names so we want to see okay how did one
is the topic evolved over time from 2013
over 15 to 17 and you see here again the
very long bracket here which defines
that we want to have the dynamic form as
a combo box so whatever I type here you
have the information here as a combo box
so then you can just use pre-configured
tech names so I'm especially interested
in The Hunger Games in this case I will
run this paragraph and don't worry about
the positions I previously won it and
set the provisions so it's hard coded
for this specific tech so for the
younger guys you see that in 2013 or
2011 2013 they were post about Hunger
Games and that's it there's no other
posts about something else from The
Hunger Games trilogy and then you see
that in 2015 people started writing
about Mockingjay and catching fire to
the next two movies from The Hunger
Games and in 2017 from the most recent a
park we see that also Mockingjay 2 is
now quite common topic we can do this
with all these different areas so let's
do x-men 1 X 1 and also take a few
seconds so in x-men you see that in the
first epoch you see ok the x-men
Cinematic Universe that can be seen at
the community name more or less explored
applied free context and then over time
it evolved into including other texts
that are really not mentioned so you see
that in the second part your text like
Logan that didn't appear in the first
type because nobody knew about this
movie Logan
and then just a different consolidation
form again we use Harry Potter on this
case
we check the names of topics for given
tech and see how many posts were
actually written in this ebook what you
see here is that in the first three
books there were 30 answers 30 questions
to this check Harry Potter and then in
the third year 815 might be related to
the new Harry Potter movie might also be
related that the form is not that old so
that army it didn't get too much
interaction in the beginning and now
more people are using it so it can be
both right and you see that the first
part yeah essentially most of their
potter movies were mentioned in the text
and in the last part almost all of the
Harry Potter books are mentioned and in
this next paragraph we can then see okay
giving the title from the specific post
in the given topic so what we do is we
can pass the epoch number and we can
pass the topic ID to it the topic ID for
example for this epoch viewers 3029 okay
already in there so if we execute that
we see that in the first epoch of this
era photograph comic questions were when
it each our crops get destroyed in their
butter movies and so on and so on and so
what text is belong to
and then in the last paragraph it's
again looking at the evolution of the
community so we're starting from a tank
in this case attack of the Hunger Games
and you want to see okay how does this
tech it was across epochs so again we
have the path here which defines okay
there should be a connection from attack
to two nodes and if we want this for the
Hunger Games we see that it started in
the first part with the Hunger Games and
then it evolves into Mockingjay one
Catching Fire on the Hunger Games and if
we look at the back view here and go
into the second epoch so in 2017 we see
that now it includes Catching Fire
mockingly - in The Hunger Games
okay I think I'm almost done with my
presentation
um if anyone has any questions I'm happy
to answer them thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>