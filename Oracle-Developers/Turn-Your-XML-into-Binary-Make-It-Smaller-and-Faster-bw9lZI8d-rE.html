<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Turn Your XML into Binary: Make It Smaller and Faster | Coder Coacher - Coaching Coders</title><meta content="Turn Your XML into Binary: Make It Smaller and Faster - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Turn Your XML into Binary: Make It Smaller and Faster</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bw9lZI8d-rE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is John Davis I'm going to talk
to you about some of the technology and
some ideas we put behind really speeding
up performance in not just XML xml
something if you put down in a in a
title it's sort of much easier than
explaining XML plus Jason plus this
model bless that plus the other etc so
what I'm going to talk about sort of
chorus goes right across the board I'm
going to start by giving it a little bit
of an introduction on something far
simpler than XML I know you will
understand XML but the process behind
this turning it into binary is it's not
that hard but it's it's much easier to
understand on a sort of smaller scale
and we'll look through some code play
with a little bit of the codes some of
the demos take a little bit longer to
run so I've stored the outputs of those
we can leave them running in the
background so we can go through so
hopefully you get more time with the
code it's pretty simple to understand
but what I think is the thing that
hopefully you'll take away from this is
you'll have been to many talks where you
can do this that and the other and it'll
change the performance by twenty percent
fifty percent something like that we're
looking potentially at fit 20 to 50
times more performance out of this some
cases even more so I think you're going
to be quite surprised there's a number
of you I can see either losing your hair
getting gray hair or combinations of
both like me and you guys I'm assuming
if you're technologists would have been
programming back in the 80s 70s 80s etc
so this for those programmers that are
should we say experienced with decades
as opposed to years this will this will
bring back a lot of memories so this is
sort of stuff we used to do for a long
time do feel free to ask questions
during the talk if you don't understand
anything I think it's fair to assume
that other people might not have got it
as well so feel free put your hand up
shout out ask a question it's a small
enough audience that we can make it a
little bit more interactive we'll also
have time doing during the demos as I'm
switching over the the monitors and or
the monitor mode and bits and pieces I
don't think I'm going to get any chance
to pick up messages on Twitter or
anything but
that's my Twitter handle if you need it
i'm going to start this with a question
for you i hope some of you all most of
you know this how many bytes does it
take to store a small string like john
everybody less than less than 10 bytes
in java less than 30 bites well less
than a hundred fights let's just make
sure your arms work first and you just
put your arms up good okay good i just
do you want to think you're all sitting
there like this okay come on somebody
shout out give me an idea how I'm does
it how many bytes does it take to store
a simple string like that yeah we'll
call it utf-8 well it doesn't really
matter that much yep utf-8 12s Arab it's
about 48 bytes in Java if you take a
small string take ABC wise three
characters relevance may I work in
financial markets and obviously
currencies of three-letter codes ABC GBP
US dollar UD USD etc they're all three
letters every single one of those takes
up 48 bytes in Java now yes the
references can be reused multiple times
you can get multiple references and we
get a little bit of advantage after a
while but if this is arriving for
example on a network card Java's not
clever enough to realize that it's the
same string it's obviously not going to
compare the two strings and say oh hang
on these two are the same therefore i'll
create one and create a reference to it
so as you read them off it'll actually
put 48 bytes each time so you imagine
now if we've got a lot of data coming in
on network cards we're picking up stuff
off of databases and we're putting this
into memory you'd be surprised how
quickly this builds up it's not just
strings doubles dates big decimals we
use big decimals a lot in financial
services it's absolutely critical we get
the numbers accurate down to the down to
the the sense even if we're dealing with
trillions of dollars the government will
quite happily lose a trillion dollars
but if you if the accounts are wrong
wire sent somebody gets into trouble
so you know what I'm talking about and
you've only got to create something
relatively simple and this is the
example I'm going to use on this it's
really really simple and very very
quickly we we end up finding that we're
using several hundred bytes for
something which would normally well from
coming back to the 70s and 80s you'd
imagine that it shouldn't really take
that much space but if you're a Java
programmer I mean one of the reasons
that Java was sort of invented came
about was that people got fed up of
managing the the sort of microbe parts
of the memory and allocating memory and
managing the memory so the whole idea
was it's an object-oriented thing here's
a strange story put it in an object and
and the the JVM deals with it for you
and that's this one of the the parts of
design of this so this is the example
I'm going to look at relatively simple
just purely fictitious data is made up i
used to use credit card data and then
when i sent it to people that worked in
places like visa it pingol the alarm
bells because if you put a 16-digit
number with starting with a 4 and into a
if you've got any friends at work in
visa just send them an email with a
16-digit number in it it says they serve
all the alarm bells that's quite funny
so we're going to use this as an example
I'm going to use the work work through
this and show you exactly with very very
simple piece of code and enough code
that we can see on a probably one or two
screens of this sort of resolution the
huge difference it makes when we move
across to an alternative format so
looking at this as a comment delimited
files is very very common format that
we'd see receiving a in my industry in a
bank and i'm sure i'm pretty much vast
majority of other industries you'll be
very very familiar with comma delimited
files Excel spreadsheets outputs etc now
it's not ideally machine readable
because yes it could be in ascii it
could be in utf-8 and it's not in the
perfect format for the CPU to use the
first digit is is obviously an ASCII
binary and if that we wanted that in a
cpu friendly format that would be an int
and it's not in this case so it needs to
be positive
and if we wanted to distort the looks
relatively simple and I hand-coded this
one a couple of weeks ago and it's I'm
sure it's almost identical to the sort
of thing you guys would come up with its
I've just taken every one of the fields
you probably wouldn't have put some of
the amounts as big decimals you might
have used doubles but again going back
to this sort of constraints of put a few
million of those in and you start ending
up with rounding errors and things so we
need that precision in there but this
this is not unusual and I think you'll
agree that's a fairly fair
representation of an object for for this
comments and imited file and if we want
to deposit again an equally simple piece
of code I'd use a splitter I'm a big fan
of regular expression as well so I might
use a little regular expression thing it
has a little bit more syntactical
checking inside there we're not
particularly interested in performance
tuning this but bait formats one of
those things that once you've used in a
multi-threaded environment you simply
realize that it screws everything up so
the date format in this particular case
is using a threadlocal it's one of those
things you learn in multi-threaded
environments just to make sure that it's
thread safe so all this does is
basically pass the string that you've
got and chuck it into the data again I
think you'd agree it's relatively simple
and as I said before this is exactly
what Java was designed for and the codes
beautifully readable there's nothing
wrong with the code at all we can all
read it all understand it and that's the
whole sort of tick in the box designed
for this if well if you're taking
pictures of this absolutely no problem
with that at all but I'm more than happy
to give you the slide deck straight
afterwards so to save you you know just
just tweet it and all I send it off to
you just save you clicking on the
buttons then you can do the text
searches and what have you but as as
things go on and on you know this has
been running for some while everything's
successful in all of a sudden we find
we've got a hundred million or billion
of these things somebody decides those
little things working well everybody
starts to use the same thing and all of
a sudden it starts become problematic
and what do we need to do well we can
stick it into a database yes it runs
horribly slowly and again putting 100
million
a billion rows into a database does
start to cause a few problems we could
put it into a distributed cache we could
use coherence for example put it into a
distributed cache but then we start to
have problems about stuff going across
the wire we could send out queries to
our distributed trades these very
simplistic ones that we're using here
and the real ones are quite a bit more
complicated in this but then when we get
the results we've got to serialize them
send them across the wire so we're
actually also quite conscious about not
just how much space it takes in memory
but also the serialization across the
wire of these so as it goes on the
problems grow our 70 lines on average of
this text in ascii i'm a stress not in
utf-8 in ascii about 70 lines here
become about 328 in that little
simplistic java program that we got and
now it varies slightly again depending
on the sort of the way that it handles
the references in the way that you fill
it up especially about six hundred odd
bites when we serialize it because the
serialization is basically tank value
pairs with the with it i'm standing on
one like there we go i want to disappear
a bit of tail so this is this is quite
important these 70 bytes get very very
quickly much much bigger and all of a
sudden we're going for something
relatively small we've already bloated
it four times and it gets bigger still
as we start to serialize it and there's
my attempt at bloating our little friend
here I found an open source version of
of Duke which you can render in blender
it's a wonderful 3d rendering program so
you can sort of move them around and
blend it so i fattened him up a bit the
obese jook so this is basically what's
happening in java they again if you're
working in small programs you're working
in your average environments your your
little little things that you've been
working with for a long long time you're
probably not going to notice this until
you get towards the boundaries of
performance and this is really if you
think we're java's come from obviously
from Sun you can know they're basically
creating something which is using up
lots and lots of memory and what do they
sell they sell hardware all they did
they used to sell it but
right to sell it in a particularly good
job and obviously they were bought but
go back to the to the early 90s when
they were looking at this the last thing
they cared about was how much memory you
use because of course the more memory
you use the more cpus you need the more
RAM you need the more tin they sell and
eventually they make more money out of
it so it's in their interest now I'm not
suggesting that Java was designed to to
sell more hardware but it did come from
a hardware vendor so it certainly wasn't
in their targets to actually reduce the
memory footprint of this so it's
basically hardware vendors are not going
to go out of their way to to optimize
this Nora companies that are selling
product based on the amount of CPUs that
you need to to run their the software's
what you need obviously is to get more
business small sort of data and an
application running within the existing
infrastructure you've got this is not
unique to Java this is you go across to
any of the other JVM languages it's not
a case of just saying okay I'm java's
bloating everything for am I going to
use scarlet because it's got lots of
nice syntactic sugar and it looks much
nicer on the screen it's still
generating these massive objects and in
fact your one level a further away yet
again so you've got the same problem
there's a garbage collector and it keeps
people like Kurt over there cook can you
wave your hand Kirk is the world's
leading expert in Java performance
tuning and it keeps him busy because
he's going around shooting all these
things when people go off and write
classic code so anyway let's sort of get
a little bit closer to how we're going
to design ourselves out of these so
these are the sort of vendors which are
selling superb products absolutely
superb products now whatever the
solution we come up with with this with
turning it into binary it's not going to
solve the problem it's going to reduce
the problem it's going to reduce it by
an enormous amount but ultimately you're
still going to need to use these sorts
of technologies when when we get yet
another scale but it's going to give us
a huge advantage so if we get back to
classic binding now in XML you'll have
these technologies which will be
familiar with like jack's b and g of x
castro etc that take your xml schema
used to be the DTD of the schema and
generates Java that will imagine we're
doing something similar here with the
comma delimited files we're going to
comma delimited file we're generating
this is the one that I came up with it's
very very similar again the idea here is
to give you the sort of understanding of
what we're doing so we take comma
delimited file put it into our nice fat
joke java and it uses up a lot of ram so
what other things could we do this is
one of the things that I come across
quite frequently in banks they've got
several hundred million of these XML
files which define all of these
derivatives and now because they screwed
up about six years ago they're actually
mandated and to to look after all this
stuff and actually reported so they have
to report all of their derivative trades
and have to identify who these trades
are with etc so they create these
massive repositories of hundreds of
millions of these rather complex trades
which they have to search you in with
some considerable level of performance
because if they want to do a trade
executors trade or closer trade or find
out what their position is they need to
trawl through these several hundred
million in fractions of a second or
certainties low seconds to be able to
find out what where they are now we
could put the XML or the data in as a
row so we could just now create a new
string trade but the XML in it has quite
a lot of advantages obviously in size
we're back down to 70 bytes now when
we're serializing it it's just too
effective got two classes the actual
wrapper class of our date plus the
strength it's a huge advantage so all of
a sudden we've got massive advantages in
this and in some cases this is actually
a in many cases actually a better
solution than turning it into Java
however if you are now searching through
a hundred million of these you've got a
hundred million strings in memory or
distributed in memory that's that's fine
it takes up less space than the objects
do but if you want to get the data out
of it you've got to go and pass every
single one of those so if you wanted to
get we just knit back to the comma
delimited file if we wanted to get the
second amounts there the one at the top
rows 67 million two hundred thousand etc
I've now got to count the comments as I
go across to find out where
to read the data back this is common to
image file it's not in a fixed length so
it takes quite a long time I'm now going
to seek a cross looking for these things
find it then translate that using a
string to int ends or string to double
etc and put it in so it's time consuming
so it's great for storing them but it's
very time consuming another thing why
don't we use compression personally I
think compression is sort of a with a
few exceptions as a poor man's tool
again you're using a lot of CPU power to
to compress put the data in if your data
is relatively random in fact if it's
random it doesn't compress at all there
are situations where you can compress
something that actually comes out bigger
than when you put it in take a zip file
and run the zip file through again and
it will often be bigger than it was the
first time all it does is look for
common patterns and build those patterns
up at the beginning and it creates this
dictionary if you like the main problem
with the compression here is there's
your data needs decompressing so it's
not dissimilar from the problem as
searching through the text it needs to
be decompressed so again if you've got a
hundred million you've got to decompress
all of those on the fly you need a lot
of RAM to do that so you can either
decompress the whole lot which would
just be back to square one again or you
decompress it in a in a stream so not
ideal and it uses a pod a lot of CPU
power now we looks many many years ago
we tried to do this we were sort of some
way off what was it it's an awful lot of
work it was just for this example it's
it's quite simple but when you get into
sort of more complex models it's it's an
awful lot of work and of course as a
small company with sort of 50 employees
you want to look for something that
someone's going to pay for we're not
like one of these California businesses
where they Chuck a hundred million
dollars at you before you've even got a
product off the ground we prefer to have
the products and then make money out of
it afterwards so what we're trying to do
is this is what I'm saying is the the
idea has been around for a long time so
we try to get this into binary let me
show you what we did on the left hand
side is the classic getters and setters
from our library
now any time you generates if you
generated that simple class we saw most
ideas you can select the the fields and
you can say generate getters and setters
and it'll do your hash and your your
your equals and all the bits and pieces
is quite neat and so the bit on the left
hand side gives us our getters and
setters and we get an API effectively
now we could build an interface out of
this or an abstract class which is the
parent if however we change the
internals of that we don't change the
API tools all the code that we're using
for our class remains exactly the same
so the code on the right we just zoom it
up a little bit it's the trade date and
now this is this is not the way to do a
trade dates or the way to do a date it
is just an example of a date often you
just want the date you don't need the
minutes and seconds you're just
interested in the bait now you could put
the date in in sort of day month year
format but that's actually quite big
it's still got quite a lot of the bonus
in it and then sort of weird system of
Americans writing the dates the runway
around interferes with it and everything
goes pear-shaped this however if we take
off the minutes seconds and even
milliseconds that are in date we get a
resolution of about a hundred years out
of this and it's reasonably good you
could you can compress it even further
if we just wanted a date from this year
365 days this year you'd only need 9
bits to store it you just need 0 2 202
512 job done so if you know a little bit
of information about what you're storing
you can optimize it a little bit further
so in this particular case I've just
given you an example of a date what I've
done though I've gone from a 48 bite
date which contains milliseconds minutes
seconds hours and and the dates and a
lot of other stuff in there that we
don't particularly care about and I've
reduced that to two bites and that's
quite important and that two bites as
you'll see from the hand coded eight and
nine at the bottom there is in a very
specific location so when we go off and
get the trade date or set the trade we
know exactly
where it is now this changes slightly as
we get into XML because in XML we have
recurring elements elements can can have
unbounded arrays of different things and
of course you then need to check
everything before to find out where our
stuff is but for this comma delimited
file it sits nice and fixed so again
this is why I've introduced you to this
because it's much simpler very very
important again or distress it is the
same API so we can use this in coherence
gemfire gigas basis neo4j hazel cast all
of these technologies we can still use
the same code but it takes up a fraction
of the footprint because the API is
exactly the same it works beautifully
well with spring with any of these
things that basically work across using
reflection across the API it works
exactly the same all we've done is
change the implementation so we've gone
from a classic java objects and we
changed it into binary what I'm going to
do is give you a quick demo some code
here so I'm going to take a few seconds
to get the screens organized as much as
i can i will also zoom in some little
bit so for those of you at the back for
the oldies with failing eyesight myself
included i'll zoom it in for the
relevant bits so you should be able to
see it quite well what I'm going to do
here is going to create a few million
trades what I've done is take their
comments limited file I've sort of
randomized them I put some random dates
made sure they're not weekend so put
some sort of random amounts and now we
create some random exchange rates that
are based within a sort of a range I've
it's just creates a big list of these
trades and then I'm going to do a little
filtering through them now if use Java
ready to do this because I've sort of
got completely hooked on the lambdas and
Java right so we'll have a quick look at
that and will basically soar through
this and we'll look at the object
version and we'll look at the binary
version and I built a an abstract class
on top of this which means that the same
demo works for both the object version
and the trade version again this is
something I want to sort of stress to
you to show that you that there's a no
difference between them then we'll come
back to the slides and look at some of
these sort of performance details
hopefully any questions while I'm
fiddling around I know you can't see it
yet we'll be there in seconds no
questions yeah I wouldn't little thing
there's a number Kirk will be a good
person to answer this I've got one bill
with me one second sorry oh sorry yeah
absolutely is there an easy way to to
measure the size of an object in memory
several hard ways of doing it the
several hard ways of doing it there's no
sort of easy easy way I've got a couple
of I've got one here is called size off
and it basically just builds it looks at
the size of memory you're using puts a
couple of thousand or ten thousand in
their books how much memory using / ten
thousand something like that there's
another handler that you can put in at
the command line which gives you a
little bit more information on the size
but to answer your question there is no
easy way of doing it there's nothing
that says this is how big this is
because also with strings they have
references to other things as well and
it's not necessarily always obvious and
I also discovered what I was creating
lots of strings for example that because
it was the same string it was creating
the reference to the same string each
time so I had to do this little thing
this is how I cheated I did USD for
example US dollar dot substring 13 and
it returns the same thing but Java
wasn't intelligent enough to realize it
was the it was the same string so it big
created a new one each time so each of
the benchmarks you do get slightly
slightly twisted right where we're good
to go and I will stress as I always do
that benchmarks this is not a benchmark
this is just a demo to give you an idea
so don't take this down as if I do it
this way it will give me exactly this
many milliseconds difference this is
just a give you an idea now here's my
object trade some of you may I saw this
as you're coming in it's basically it
extends a basic trade it's serializable
and it's got your usual getters and
setters in there it's got an equals the
equals was generated by my ID which is
IntelliJ just did it nicely the reason I
use the equals is because i'm going to
serialize these things and i'm going to
put a million of them in there and I'm
going to bring them back out so I'm
gonna put them into a second array and
then i iterate through both arrays to
make sure they're exactly the same to
make sure obviously that it's worked now
if I look at my basic trade again it's
relatively simple I've got a two string
and a pass the pass you saw in the
slides to string same sort of thing just
basically outputs the trade and that's
that's pretty much it here's my thread
local just the thread safe teenis and
I've got to implement two interfaces one
is mutable ones immutable mutable allows
us obviously with getters and setters
and immutable is just get as the reasons
for that whole I'll explain a little bit
later they finally my binary trade which
naturally extends my basic trade what
I've done here is note down just roughly
the size and this is how I was sort of
hankered in this and took a couple of
hours to think about it and just put it
down this was the roughly the size of
the bites that I'm putting in there so
the ID it's it's going to be large
because i'm going to create lots of
millions of them so i needed to be
fairly large so i've used eight bits on
eight bytes on here trade ID you saw the
coding for that i've also done some
clever things here with thee and this is
quite important we can have commonly
used strings so this occurs frequently
and a lot of different source of data if
data is used frequently you can create a
lookup table for it and if i put static
string in there and i put in my
currencies and again this is just a
example for you there are in fact any
163 currencies so why would i ever need
to have all possible versions of three
letters 26 to the power of three it's
not it's not required so there's only
163 I can fit them in one bite it also
leaves me a little bit of space that if
I wanted to add an extra currency
because some countries splits up changes
the currency or whatever gives me a you
know we could have had the new Scottish
currency gives us that possibility of
adding this new one without changing the
or breaking everything so going through
this I just show you a few of these
things here's the trade dates that you
saw before buy sell indicator we could
use a single bit we might find a bit
that we've reused somewhere else again
we could further optimize this I've used
the whole bite just just for a boolean
which is sort of rather overdoing it but
again it's an example currencies same
sort of thing I can basically take do
pretty much the same sort of bits i can
divide them a currency which has see the
two or three decimal places none of them
have more than three decimal places so
we can do some sort of clever bits with
that multiplying by 100 by a thousand
etc and then store it as an integer or a
long and again this is not the de facto
standard way of all lungs or all big
decimals must be replaced by this this
is an example to sort of demonstrate you
so we basically go through this we've
got all the getters and setters
utility method that I use several times
over so this is basically taking Long's
taking along and stick it into our vital
ray and then we got words and bits and
pieces so it should give you an idea and
more than happy to share this code with
you that's give you an idea of what it
does so let me show you the demo test
trades so what I'm going to do I'm
hoping this will be relatively easy to
just see in straightforward I've got a
any create a million of these things now
I've got two different types i've
created a factory just as so I can sort
of create one type or the other all the
factory does is just compare the trade
type if it's one of these it creates
object trader it creates a binary trade
and returns any musical trade which is
obviously my interface in this
particular case I use immutable because
I don't particularly want to use any of
the setters and good coding practice
means it knows it can optimize it and it
knows it doesn't need to to rights to it
I'm going to run a simple query I'll
show you that in a second I'm going to
test the serialization and this
basically what I'm using is Java
serialization I'm going to write it to
an object output stream and read it in
from an object input stream we're going
to test that and then if it's an
instance of a binary trade I'm actually
going to do a little bit more clever
stuff because I know that it's a bite
and array of bytes I can actually write
that out directly to disk and if I got a
million of them I can basically
pre-allocate the whole lot right the
entire lot in one go and you'll see the
difference that makes because I know
exactly what I'm doing in terms of size
you'll see I think you'll be surprised
otherwise we test batch civilization all
that does is because I put everything
into a an ArrayList I just write out the
ArrayList rather than iterating through
the arraylist and sterilizing each one
individually again sort of performance
so here's my serializing deserialize
let's just throw that up a little bit
originally I wrote it out to disk and I
thought it's a little bit unfair I mean
it's a SSD is pretty fast but I want to
sort of eliminate as many bottlenecks as
i can so i just use ram sitting in there
basically writing it out two bites a
right bringing it back in its always
doing is testing civilization d
civilization
here's my list creating the trades again
this this time using Java rate and all i
do is his my little trade creator here
and i'm using a stream i create a limit
of those and i collect them into an
ArrayList there's hopefully now familiar
with java right I just find it so you
know got really into it that's cool so
what am i doing it's my reading for a
file writing for file we're going to
kick this off in a second we have a
little thing that checks the results so
when we read them and write them out it
just goes through iterates for each one
just check the results so here's my
little query so I'm going to run this
three times again sort of typical habits
because the compiler comes in takes
10,000 iterations before it kicks in
it's just common practice for me it's
you know get it running and time it
after a while so I've got my trades I
got a stream of those I filter them I do
the get the currency from one check
whether that matches GBP Great British
Browns check what the second one is
equal to US dollars check whether the
buy-sell indicator equals two x and yeah
there we go I then sort it and then I
get the top one out of those so and each
time I do that you might argue that it's
not sorted each time but I do somewhere
I thought unsel them okay CSS is same
it's effectively the same set which
would be unsorted each time so let me
just run this I'm going to run what I'm
going to do is going to run the binary
version because the object version takes
so long I've pre captured the bit of the
bottom otherwise we'd be sitting here
watching a rather boring screen for a
long time so that binary trades keep it
at a million let's kick that off and let
me show you while that's running you'll
see it running at the bottom there let
me show you the output of the objects
so we just show you this stuff coming at
the bottom so million trades has created
those it's basically run the query it
took to brute-force search through those
using the the lambdas it took point
three seconds was pretty quick gone
through the the lambdas again as you'll
see from the second demo I'd actually
unbelievably quick and as they've said
that an optimization answers quite
surprising time to serialize 1 million
of these this is iterating through the
array took 40 seconds and the serialized
size for each one of these is 673 bytes
imagine we gone from 72 617 hours we got
up tenfold now if you were doing this
query on a remote machine using a
distributed cache or something yes there
are optimizations in this but it's
basically it's you stalk quite a bit of
code in there check the results we do a
batch civilization this is quite a quite
a bit quicker takes eight seconds now
but this is serializing the entire lot
in one go now let's look at the binary
version and we'll keep that up here so
we can see it you can obviously see a
little bit so what it's done it's run it
again I is actually quite surprised
about this is actually faster a big
reason why it should be faster because
it's just basically getting objects back
which are already already there so it's
not having to do any extra sort of
computational work in XML again because
we have to calculate the offsets a
little bit more complicated it is
actually slightly slower retrieving
these because it's got to calculate
where the data is that it needs to get
back time to see relies on deserialize
individual ones this is we're down to
three seconds so we've already got an
increase of over ten times in this the
CRI size 91 bytes why is it 91 because
we started with 39 well the extra bits
is actually the package name because it
remembers tag value pairs as they go in
but when we do this is a binary right we
can write them in point one over seconds
and we can read them back in 46
milliseconds now we've gone from 40
seconds to 46 milliseconds now 40
seconds of writing it through one by one
just to 46 milliseconds
I think you'll agree quite a substantial
increase even if we do write the entire
object array as an ArrayList we go from
68 points 76 seconds down to 46 and
there let me just show you the code on
that just so you see that I'm
everything's cheating in code but you
know what I mean so basically what I'm
writing out of file all I'm doing I know
the size of these things now the size
varies slightly if we're doing
run-length encoding and we're doing and
we got variable size of rays inside XML
the size is going to change so we need
to be safe so we need to store something
a little bit bigger because what if we
want to get the 500th elements we want
to know exactly where the 500th element
is and not have to pre calculate each
time or all read through otherwise we're
back to where we work with the comma
delimited file there are optimizations
we can do with this but in this
particular case this one doesn't change
its always 39 bytes so I've decided to
call it 40 bytes and I allocate enough
memory using a byte buffer I fill those
up with 10,000 of them and I just write
them out to disk and basically Java
niÃ±o nice and nice nice and quake and
that is exactly the same if I'm working
in a distributed environment so i can
now replicate these things across across
the network of quite considerable
performance increase remembering now
that we're not putting seven or six
hundred and something bites on to the
network which again this is a really
simple example when we get to the xml we
taken an average derivative trades about
seven or eight k in size in xml it
becomes 25k once we bound it to Java now
25k across several across the network
hits several mt use which are the packet
size and the network typically about
one-half k that message has been broken
up into little bits it's extremely
inefficient we can get that down to just
a few hundred bytes that makes an
unbelievable performance in this so let
me nip back to the slides now
hopefully we get the right one so give
you a little bit of an overview that
sort of performance we're looking on
there's we got the bytes used internally
in memory we've got the bytes used for
serialization and customized
serialization again we're not talking of
twenty fifty percent we're talking this
very significant amount in this and then
finally when we get to the batch of
civilization we're looking literally
it's quite easily 50-plus to several
hundred times now these are
optimizations which I would expect
people to come across but they're not
the sort of thing you can get unless
you're working in binary and that's
Worthing but if there's parts of your
code you can find and you can change
those two binary you can start to see
these sorts of performance levels so I
mentioned before sort of the size of the
network packets this is particularly
important as his disk is what we call
mechanical sympathy we start to write
stuff out this is all the staff Java was
designed to abstract it was designed to
take us away from having to worry about
this and it was good but when we get to
the edges of performance we now need to
come back and start and start to worry
about these things because if you've got
a one gig Ethernet there's a certain
amount if you can get about 700 mega a
second across it but that's it sorry 70
megabytes a second and that's it and if
you're dealing with that inefficiently
it's going to be if you literally we've
just seen it's ten times the size or
larger you get significantly less data
across your Ethernet and while as you
might have it might be lucky enough to
have 10 gig Ethernet or something you'll
be going from country to country we'd be
working from a cross to a data center or
something you'll still be bound by your
network so being able to get these these
things across its significantly faster
ten fifty hundred times faster makes a
massive difference it's exactly the same
when we're writing two disks as you seen
from here another interesting thing is
because when we write them to disk
they're in binary when we read them back
they're in a format which is already if
you like past it's already
understandable by the CPU it's not like
the comma delimited file where we net
then need to go and pass it so we can in
theory take our entire memory and just
dump it to a file and it's immediately
readable so we can all of a sudden start
to scale literally onto disk and you saw
how quick it was to read from disk we
read a million in in a few milliseconds
so it can really start to scale this out
and looking at putting this sort of
stuff onto SSDs we can start to look at
very high billions of rows of data
because when we read it back it's
already ready to go now I use a tool
which Kirk introduced me to she wrote
which is absolutely invaluable for the
sort of debugging this sort of thing so
when we were working on this earlier
this year we we thought we're getting
some pretty good performance out of it
and but wasn't quite where we wanted to
go we had a client a very large telco in
multiple countries they averaged 88,000
messages second 24 by 7 so there's
average across all the time obviously
goes up and down they have Peaks that
last for half an hour where they have
ten times that so we're looking at about
900,000 a second for half an hour and
they have pigs for a few seconds or 30
seconds or so or they reach a hundred
times that so we're talking eight or
nine million messages a second now there
are laws now in the United States and in
Europe that say if you get the sum of n
to terrorism or something like that you
have to be able to the telco has to be
able to find those those details within
a certain amount of time now if you
can't handle the throughput of that you
put everything into a message queue is
sitting in RAM remembering you've got an
awful lot around a million a second
you're not going to be able to identify
these things so it is it's it's actual
mandatory requirement to be able to
process these things at 1 million a
second because we cannot set these
things in a queue and then process them
later so we need to get the
up to a million a second we were we were
around i think 80,000 a second perk or
no 2 I think was 200,000 a second perk
or and we thought we can bond multiple
calls at it but you're then using sort
of ninety eighty ninety percent of your
throughput your capacity of your machine
and it's running hot and most businesses
like to run less than twenty percent
thirty percent is a real maximum on
these sort of things and it's so what we
needed to do is increase the performance
now watch i'll go through these pretty
quickly this is the missus look at the
heap size so this is basically
allocating the the data as we go across
with an eight gig heap and this is the
object version and you'll see this goes
up to very quickly to three and a half
from gigabytes just for a million
records we move this across to the
looking at the allocation rates so the
the pause time on this we can see right
at the beginning while we're creating
these things pause times up to half a
second not really noticeable if we're
sitting on the service there's nothing
we're going to see stopping but typical
post times we got into these sort of 100
150 milliseconds and this while we're
assured processing it this is with the
binary version it's almost sort of
sitting on the bottom and I've got
another version where I've decrease the
heap on this this is the pause time as
you can see the maximum on this we're
sort of averaging around 110
milliseconds because it's because we got
a large heap size so I'll show you the
next ones where we sort of reduced that
this is now two gig heap size and it's
still proportionately less than the one
we had with the eight gig heap space
much tighter and this is now the post
time because we've got less ram to
basically go through and garbage collect
we've now got pause times down to 35 40
milliseconds on average because we're
now putting our data in binary we're not
needing to create nine or ten objects
for every single allocation of one row
now go back to this XML which I'll show
you in a few more slides this XML has
three to four hundred objects for every
single message that makes a massive
difference so this is the really easy
version that we're looking at here
compare the two it's not quite like for
like so the graph on the left is an
eight gig heap the graph on the right is
a two gig heap you'll also notice that
on the left it takes two hundred seconds
to run through this on the right it
takes 40 seconds so we've we've gained a
huge amount we've gained a massive
amount of RAM we've gained a massive
amount of CPU time as well it's running
much much cooler this is another
interesting one on the on the GC pause
times the first rung on the left is
higher than the top one on the right so
give you some idea of the sort of scale
on this so it's again massive
improvements and sort of through puts on
this so that's again you'll have the
slice at the end but that's a little
plug for cokes gadgets that we use for
this we actually sat three of us in a
room for I think couple of days so coke
would be analyzing it and driving it I'd
be running the test changing the tests
and our head of development was busy zor
reprogramming the internals and what was
generated he'd generate a new file I'd
loaded up rerun the tests and kirkwood
being who's not it's not good when we
actually what we did was to to generate
we made a binder for the models and we
actually use so we basically generate
the Java code that's example that I
showed you with the trade so we got it
down to actually it's typically out of
the box is actually 33 bytes because we
do actually is one bit for the buy-sell
indicator and we do actually use
run-length encoding run-length encoding
means basically you use part of the of
the bites if the top bits set you use
the next one if the top bit set it's a
bit like the way utf-8 utf-16 work it's
just a little bit more efficient more
efficient for memory less efficient if
you're reading it back which is White's
I was surprised by the results of the
binary should be slightly CDs slightly
slow with XML but that's basically what
the generated code string so this is
where we move on to the XML side so the
what you've seen is the comma delimited
file its hopefully given you some sort
of understanding of how it works
all we did really all say all we did it
was a couple of man years of work was to
extend that comma delimited file into a
far more generic xml schema to be able
to look through the schema to do things
like ID ref substitution groups and all
these nasty stuff that XML has and be
able to implement this in a binary
format we took caster we rewrote
completely rewrote the internals of
caster and created something that
literally just creates the binary out of
the bottom of this so looking at an
example this this very small snippet of
XML is out of F pml-f pml has something
like 13,000 elements in the definition
as eighteen sixteen thousand thirteen
levels of hierarchy so this is just a
really small snippet now not every
message uses all of that so we're going
to reset frequency we got a period
multiplier on a period so okay what does
that mean well period multiplier is one
of d WM q and why as you see from there
it's basically day week month quarter
and year now they're in fact only five
values in there now we know that because
it's an enumeration if there's any five
values how many bits do we need to store
five values for okay so take your number
take the log of the number divided by
the log of 2 and that's the number of
bits you need to store it's one of those
things that as old programmers work
remember so the periods multiplier at
the top the largest number that can be
is 30 so we're gonna need five bits to
store 30 in there so queer to need three
bits I got it wrong too too old too much
drinking three bits for the first 15
bits of the second one three plus five
is eight I'm gaining on winning on this
one and we can store basically that in
the entirety of their XML snippets in
one bite literally now when we bind it
classically we need one byte for the
reset frequency because when it
generates a class we don't actually need
a class we just need to get it a getter
that returns the content we don't
actually need a class for though because
it doesn't actually have any
content we just need the functionality
behind it generously another one for the
period multiplier it Jones another one
for the period and it's generating
enumerations for each of these as is
generating in this particular case 144
bytes just for that one little bit which
is why your XML goes from 7.4 k for your
average derivative trade to 25 k with
400 objects and then performance
accordingly goes crashes down then the
binary version it's very very similar to
what i showed you before there is where
it says int offsets equals 1 2 3 then as
she can get pretty complicated we can
get a good page couple of pages
obviously calling different methods and
things around because what it's doing is
calculating everything above it to work
out where the data is going to be if we
had repeating elements above it's going
to have to work out where it is that we
don't store intermediate results because
again if you're doing a million or ten
million of these things you're storing
intermediate results you're creating
lots of crap basically that the garbage
stretch has to come and pick up so weary
calculated each time on the flight but
we get the whole thing in there this is
roughly how it works this is sort of
schema now the two boxes on the left is
basically classic Jack's be jib X Castro
etc so we take our F pml document
financial products markup language if
you interacts ml it's very well designed
it's a very good example of how to do
schemas we pass it into a classic object
it's this big 25k object and we have a
source and a sink because there's quite
a lot of work that needs to go through
this the sources and the sinks
effectively do the compacting back down
into the binary objects now the binary
objects only have getters the reason
they only have get is is because if you
can imagine that you've got run-length
encoding or you've got repeating
elements if you are to add a new one in
there you've then got to offset
everything else and you you've got the
same problems you have with strings
being immutable you've then started to
create more and more so the way we chose
to do this is
you wanted to change something you go
from your sto sense for the simple data
object CDO is the complex data objects I
think of the complex one is the object
version the sto is the binary so if we
want to add something we rehydrate it if
you like put it back into the into the
object form there we can change the
variables and then we bring it back into
the binary version so that's a sort of a
the way we did it most of the time
you're reading you're not writing so
it's it works pretty well i'm going to
give you another little demo what i'm
going to do with this one let's be the
last demo then we would pretty much
closed up I'm going to take an XML
derivative trade in fact again I might
just show you the output of this but we
can run it in the background it's 7.4 k
we can if someone wants to shout out a
number we'll put some actual data in
there so you can see it's reading it out
we're going to pause it and we're going
to mutate a few variables a little bit
like I did generating this stuff before
so I'm going to mutate it a little bit
not a massive amount because it is it is
pretty complex as you'll see we've
generated million of these and through
that schema that we saw last time we're
going to generate these binary versions
of this so we'll go from 7.4 k 225 k
down to a few hundred bites and then
we'll store the few hundred bites and
we'll store there's a million times now
once we got those we're going to run
again through a few lambdas on these and
we're going to retrieve some values now
the interesting thing here again this is
the stuff that where we really were
working sort of really tightly with Kirk
the XML typically generates an interface
where you're returning big decimals you
remember I said we use big decimals and
dates it doesn't return these primitive
types it returns big decimals so
unfortunately if you're iterating
through lots of these regardless of how
efficiently you've formed it it's going
to generate lots of big decimals if
you're aggregating them or doing
something with them so whatever we do
with it even regardless of how efficient
it is it generates objects it's just a
function of the API so what I've done on
this particular one is I've changed one
field in my xml regenerated the code and
that one field returns an int just a int
not an integer in it and will run
through that and you'll actually see
that it runs through at a pretty
impressive speed I went to do now
because I'm hoping to hear it runs
through pretty impressively but what it
doesn't do is it done it doesn't
generate a single object and we can do
this millions and millions of times
there's not one single object greater
than there so you imagine if you're
running this now on a financial services
system or in a telco environment or an
environment if you're not generating
objects you've got no garbage collection
you're right there on the on the peak of
performance so that's what i want to
show you all right let's get back to the
code that's IntelliJ not the trades we
want the other one
so this one is called a interest rate
swap test so let me show you the XML to
start with and I'm going to ask somebody
to give me an integer because I could
cheat with this I could say oh let's put
something random in and of course I put
in something which is Kevin
cleverly-contrived so this is the field
here that I have told the being into the
schema and I've told it is not a an
enumeration it's actually an integer and
this is the one that we're going to pull
out so if somebody like to give me a
random integer thank you six you win
bingo that'll do the other number of
them sort of changing the one that I
mutating is is this one here just a sort
of this is the value of the trade this
is a typical this is an example of the
is de site which is the institution I so
it's not ice over this institution that
basically defines these things again
it's a very very good well-managed xml
schema but horribly complex as you can
see so it's give you some sort of idea
of the complexity of this that's all
freely available in the internet and
this is what every single derivative
trade in the world is defined in at some
point it can be defined in something
else but eventually it goes into this
and this is what gets reported off with
the DTCC and the veracity of and
organizations around the world and this
is mandated so everybody has every bank
has lots of these so this is where all
your mortgages and things disappear to
did disappear to probably this is not
the money you were looking for so let me
show you the test again we're going to
do a million of these now some of these
things happen so fast that I actually do
it erations 20 times again just a sort
of pressure up now I'm just going to
show you the quick java right part of
this and then we'll kick it off so i
basically go off the the set up
basically creates the trade it's create
a million of these things i do a size
tests and a look at the size there's
also a little thing in there that dumps
out an ascii version of the text
the binary then we go after the little
Java rate demo this give you an idea of
what we're doing so and just enlarge
this very slightly so here's my simple
data object list I create a stream of
that I'm going to filter it just get
ones from July I'm going to get the get
initial value now well how we're going
to the details of the way streams work
well there's a few things if you throw
exceptions you can't put them into the
lambdas it's a real pain so you have to
wrap them to take the exceptions of
etcetera so this all this is doing is
basically it's down here somewhere so
get initial value so you can see all
it's doing is a here's my trade get
documents SGS substitution group gets
the trade we're treating this just like
an object which is being generated it's
exactly the same as Jack's b-joo backs
etc i'm getting i'm using the index
going off to get the calculation peers
the amounts and that's basically getting
the data out that you saw in there so
it's carried back on with where we were
and i'm doing a map and then i reduce on
this and i'm basically adding up all of
those values now as I said I've
randomized those so it'll add up to
something sort of relatively random but
will check it because it'll print it out
at beginning I do another one and this
one I use a parallel stream so we'll see
it run a little bit faster and then I do
another one and this was coke and I
working very late last night strangely
completely sober which is probably why
it didn't work so well this one we
couldn't think of how to do the
MapReduce on a primitive type until this
morning so I just did a full loop so all
I'm doing here is basically i'm getting
the this is the type which is generated
by the trade from the xml through my
list I'm getting that int value which
was six we put in there and I'm going to
basically total light up and print out
the results and this is basically a
single threaded loop then this morning
the instant stroke of ah I remember we
can do a map to int and a sum on that
and we do exactly the same thing I put
it in there because I thought it was
quite amusing to see that
between the two one is a for loop one's
just using a lambdas in here and then
what's really interesting is that
because I've now used the lambdas I can
actually use a parallel stream so i can
now do a parallel strain through the 1
million records and add them all up and
that's the one I think you'll be quite
impressed with so let's kick this off
and it'll take a take about two minutes
to run so i'm going to take some
questions while while we run that if we
have any otherwise you're going to sit
and watch a number counting up for two
minutes and that really does get fully
dull so any any questions at all I can't
be that exciting surely questions
anybody using XML here director where
the wrong talk otherwise jabber 8 out of
curiosity nobody we still have we've had
most of the investment banks as clients
and we still have two very very very
large banks sort of we say federal
agencies in this country sort of narrows
it down somewhat who we've only just
managed to insist they come off Java 1.4
so finally we can put them on to
generics so getting on to Java rate is
they're really interested you know
they're interested in seeing how it
works and the talks but unfortunately
getting in his bruk shin is going to be
hard i was i was chatting to some of the
other speakers the other nights I think
Java rate is the difference between six
and seven and has been very little and
has not been enough to to justify moving
five was a huge change of the language
and so people moved to five and they
stuck with it's a bit like this sort of
you know pain that Microsoft has trying
to get people off something that works
or doesn't work but make up you know you
know what I mean and I think job rate
has been a big enough change that I
think people will just skip and they'll
literally go from 1.5 to 2 8 so I think
this Java it's going to be a major
catalyst to seeing certainly I hope my
customers and banks moving over to
is so this is now finished so those are
that's the entire trade now from that
now it's just got little dots in that
little dots is basically anything that
doesn't display its binary you'll be
used to this I'm sure if you've used hex
dump that's entire binary there the 370
bytes I can completely reinstate the
entire complexity to every fine level of
detail except the white space in this
particular case that original trade now
one of the requirements because their
derivative trades and therefore legal
documents was to actually have the white
spaces in there as well because they
must be binary compatible so we did a
little thing on there what we actually
do is we use a 7-zip we actually compact
it because you you don't need to
uncompacted unless you want the original
document so we sort of piggyback that on
top of this and so what you end up with
is somethings about 600 bites but not
everybody needs that but it was just the
only way we could manage to do it so
this is the speed that it took to run
through the first one it is about 1.4
million a seconds now this is running a
query and trawling through remember 100
times 1 million records now this isn't
the speed for 100 million mrs. to speed
for 41 million but it's running through
these brute force there's no indexes on
this at all it's basically running
through these brute force and extracting
complex data right out of the middle of
this XML and aggregating it now we look
at this this is the one that returns the
big decimal and here's the the total
that it calculates this is now running
it in paradoxes using the parallel
streams now the reason that's so slow at
five million a seconds is because it has
to create a bigdecimal and it has to add
them all up so it's sort of slow this is
my little loop here if you remember I
wrote a little for next loop this is a
single thread for returning a one item
which was an int and I again was adding
it up and the number you chose
somebody chose a year was six and
naturally a million of those times six
is six million so that's proof that it's
hopefully proof that it's worked that's
managed just under five million a second
in a single thread then we do the lambda
and I was quite amused and surprised
that in fact the lambda for the same
thing is actually quicker than the the
follow it had if you remember the code
one light had nothing in it so again
another tick in the box for lambdas then
look at this 21 million a second through
complex XML which is only now 370 bytes
in size so i can actually put easily 10
million complex derivative trades on
here which is actually more than a large
multinational one of the top five banks
and the planet put in four hundred
machines across 17 tera bytes of ram and
i can do that on this laptop and fall
through them quicker than i can get
basically distribute these things so
that's we're basically going through
1,000,000 trades in 21 million a second
and then finally it's some other little
bits writing these out I was able to
write these 1,000,000 trades out to two
discs in 3.9 seconds and read them back
in under a second that's 800
milliseconds to basically read these
back in so again I could read the Mackay
enough disk and process them in about
about a second at this sort of level so
I've hit the end of the time I'm just
warming it over so I just wanted to say
thank you very much i'll put the last
slide up and it just says thank you and
if there's any question is obviously you
can ask later and but thank you very
much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>