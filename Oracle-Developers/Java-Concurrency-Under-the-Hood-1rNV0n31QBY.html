<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Java Concurrency Under the Hood | Coder Coacher - Coaching Coders</title><meta content="Java Concurrency Under the Hood - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Java Concurrency Under the Hood</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1rNV0n31QBY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">we're going to talk about today is Java
concur see under the hood as you might
see on the screen the topic is mostly a
difficult one so the rationality behind
of today's session is that sometimes you
end up with some weird problems which
you do not quite which you are not quite
able to put your finger on sometimes gel
memory model is not enough to realize
what the phenomena that you are
observing are actually caused by so this
is pretty much what we are going to talk
about today I wonder if everyone is
already here and if we can start can
someone give me a go ahead yep we can go
great so my name is glitch smirnoff i
come from russia currently employed
deutsche bank but it's really not quite
about me but it's more about Java so
let's keep this part and get on oops now
taste better please try the vent if you
are familiar with the concept of a leaky
abstraction ok maybe about 10 or so
people so the general idea is that when
we are creating something we tend to add
more and more abstraction levels and
while that might help us it at the same
time obscures quite a number of
implementation details so in that way
some of the things which happen on the
lower levels still affect the high level
behavior the easiest example of that is
say if every TCP standard but your
neighbor's dog has bitten the cable and
now the cable is torn the TCP standard
says nothing about the dog and its teeth
and how it compared the cable but there
is no connectivity so they need
abstraction that TCP gives us has leaked
and the setting is that some phenomena
the dog cannot be explained in the jumps
of your abstractions like in TCP and
because of that we sometimes have to
wave our neat and tidy abstractions
forget about them and go to a deeper
level the level which is usually
obscured by them and that's pretty much
what happens with Java all the time we
have a virtual machine which is accused
alcohol and on a multiprocessor
environment and well most of the time we
can accurately predict what's going to
happen some of the phenomena especially
the performance ones are not easily
explained in terms of gel memory model
here's a simple example we have two
threads which are concurrently executing
two blocks of code so one thread says
that value is 10 and the finish is true
and the other thread checks for the
value for the finished flag and when it
is true it asserts that when you is 10
so the question is can this assertion
fail please raise your hand if you think
that it can but if I out my head ok what
how many of you think that it will not
fail nobody know ok so here's another
question and what if you run this on x86
architecture can it still fail what do
you think just one person thinks that it
can fail ok let me not torture you by
the questions let me actually give you
the else part there are several
approaches which we can take first is
the theoretical one so we go deep into
the Java memory model and we read in it
the door is this volatile keyword and if
we use it it is not going to fail but if
we do not use it there is going to be
some sort of a race condition stuff like
that and it can fail but it doesn't have
to it may work and the problem is that
JMM only contains high level
abstractions and the second part of the
question about x86 Jeon doesn't have a
word on it so we cannot answer the
second question in terms of JMM and if
we actually open the Java language
teller and list to the seventeenth
chapter of all threads and
synchronization and stuff like that we
will find out a definition that a
volatile right happens before all
subsequent reads of that thing how many
of you have are familiar with their
happens before thing okay how about the
synchronizes with how many of you are
familiar with this way two people I
thought you said you knew JMM come on
okay so here's an excerpt from German
because our real subject today is not it
if you go ahead and retry to read it
there are going to be quite out of pages
of these definitions definitions
definitions and stuff like that and
today we're not going to really go deep
into this because well it's not our
subject we think which is written there
is quite important but it is not quite
easy to grasp so we're not going to do
this because we can't do this in five
minutes the thing which we are going to
do is take the other approach we're
going to try to actually run the thing
well except that if you run it once now
it's not goin t that if rather another
time it's time going to fail because you
know there is in determining not
deterministic behavior so we could run
it lots of times actually a real lots of
times to see because if it doesn't fail
a photo we have run it
times and it probably shouldn't be
failing at all and the funny thing is
that the java community which is really
awesome and there is this guy alexei
tupelov in one familiar with him not
really Oh several people are okay so he
has created this awesome tool which is
called the JC stress and what it does it
finds out some scenarios under which
complicated behavior between different
rates can be tested it records all the
outcomes and gives us a statistical
distribution of what has happened how
many times more hour it does contain the
very test which we are trying to do and
now it's time for a first live demo so
we fire IntelliJ IDEA open up the JC
stress and fenced acquire release test
can everybody see this on the back rouse
give a thumbs up if you can no you can't
okay let me try to zoom it better okay
so what we have here is a value never
mind this just ignore this one no
content today so we have this value and
we have this finished we have two actors
basically two different threads in which
the first one writes 12 value then 22
value then 12 finished which is
essentially true and then right 32 value
this is slightly more complicated than
what we have seen before but pretty much
the same and then we have another fat
which reads both of them in the opposite
order and stores them somewhere so
basically we have one pride which
publishes values and we have another
thread which reads them or in other
words this one releases them and this
one acquires them so basically we should
expect that at this point if we have
read finished as zero and then we could
probably have either one or two right
and if you have read it as one we can
only have two but you might also have
free but we should not have zero right
because if we read this one then it
means that we should have observed
everything before that correct now
exactly because there is no volatile
here if they're very volatile then it
should be working but there is no well
some people say that it is not really
needed say on x86 because things are
going to work anyway do you believe
these people well I personally do not
and the best way to prove someone wrong
is to actually show them how it is
broken this is precisely what we are
going to do so here we have a compiled
version of JC stress and we're going to
run this very specific test which we
have just observed on the screen and
it's going to do some computations quite
a lot of them actually now it's done we
are going to open the result and see how
it goes so we have here an unfenced
aquarius test and what we have here is a
list of possible outcomes which we have
observed so 00 is that finished was 0
and X and valuable 0 as well 01 etc etc
etc but this table is not really
understandable right let's just use
something different I have a grave for
you which pretty much summarizes the
results which were in the table so here
is what has happened so eighty-four
percent of the time we had observed why
in our case it was finished as zero and
all the almost all the other times like
ninety-nine point nine ninety-six
percent of the time we observed xa0 if
why or finished as zero as well but in a
very small number of cases we actually
observed through you so let me get back
here see we have written this and this
but at this point we have actually
observed this value of free this thing
is called a race so we have read this
value via a data race this is kind of
expected but this is not what we were
looking forward what we're looking for
is actually observing a different thing
in this case when we have observed
finished as true in most of the cases we
have also observed the value to be three
which is okay it's perfectly fine it
should be two or maybe three but in a
very small number of cases we have
actually seen X to be zero which means
that while we have actually seen this
right selected does everyone see this
should i scroll maybe like so so while
we have seen this right we have not
observed these ones and that means
exactly what I've been telling if we do
not have a volatile here it means that
we can actually get some broken stuff
out ok that's an experimental proof but
that's not enough we're going to go a
bit deeper and run this on a different
processor an arm and we can see that
here the general shape of the graph is
similar but the number of cases in which
the result has been broken is waste way
less smaller and then if you run this on
not on the server compiler buy it on the
client compiler we can notice that
suddenly there is no more instances in
which we have observed 0 here and that
is peculiar
that means that our understanding of
Java concurrency is not enough what we
have read in JMM does not explain this
behavior which we have just observed
which is why we need to go deeper again
so let's look at this a bit more closer
we have this code and we want to see
what happens to it when we actually run
it so the first thing this happens is
oops sorry about that is that Java does
something to it well that's not the
deepest level of course after that comes
the operating system because the trades
make two operating systems rights and
then comes the hardware and there can be
lots of hardware there can be different
architectures there can be different
vendors of processors and even then it's
not limited to eat it could be run in
the cloud and we would not even know
what processor we're running on and that
is why it is extremely important to not
rely on specific hardware will you are
writing Java and the problem with that
is that nobody on the execution chain
not the operating systems not the CPU
not java nobody wants to be the slow one
everyone wants to be fast so each of
these layers might try to apply some
clever optimizations to make things run
faster but the optimizations are a
double-edged sword so they might make
things run faster but on the same at the
same time they might actually cause the
code to change its behavior the observed
one and sometimes it is perfectly
acceptable that we change something but
some other times it might actually break
our expectations of how the code is
wrong so the problem with it is that the
hardware or the operating system or
whatever the JVM they cannot know in
advance what you exactly you expect of
your code so you need a some way to
communicate this let's take a simple
example
cache coherency does everyone know what
that is hands up okay about half of the
audience does just let me clarify except
accession of the realm is an expensive
operation in this day and age you can
make like thousands of additions while
you're trying to access ram so we have
things like cash on the cpu l1 l2 etc
and the data that you use most
frequently is stored locally so you can
access it faster and if there is just
one cpu it's okay but if you have
multiple CPUs then there stands a
question about how exactly those two
cpus can communicate with each other
they are locally cached venues so for
instance we have one cpu which has this
finished variable and this it's stored
as false and another cpu which does not
end it does not have the current value
of the value variable and then we have
another cpu which does not have finished
but only has the value and now when you
have the two of them concurrently
execution cold so for instance the first
processor says okay I think value should
be now 10 and he goes ahead to the other
processor because he does not have it in
his cash and says hey I'm gonna update
the value field please remove it from
your cash it's called invalidation in
the protocol and then it has to wait and
then it has to wait more and only then
it's going to get the response that okay
I have invalidated this right and then
it goes on to saying that finished is
now true and the problem is that but in
this place you see this art of dots it
means that a lot of time has come it
means that the CPU was told nothing was
executing them and that isn't fun I mean
we can do better than this so let's do
it we don't like stall CPUs it's time to
do optimization everyone last
optimizations so what we're going to do
is take the
assignment and actually executed a
synchronous where we are not going to
wait for the ants were we are going to
assume that the other CPU has correctly
replied to our requests and we are going
to write finished that's true
immediately and you know which is also
going to be executed asynchronously and
where are there are a lot of agents
which are doing asynchronous things
without actually waiting for the answer
from each other without any mechanism to
regulate their behavior well bad things
are going to happen and nobody wants bad
things we want things run smoothly
exactly as we expect them to and this is
why we need a memory model software
engineers like us we do know how we
expect our code to work but the hardware
does not know this so somehow we must
relate this knowledge to the hardware
and this is exactly what memory model
does and it is important to understand
that a memory model is a trade-off
between several things the first thing
is that if your memory model is very
difficult it might be very difficult to
write code in a language if your memory
model is difficult then the implementers
of the language say the engineers who
hacking our hotspot are going to have a
lot of trouble actually implementing
your memory model and another thing is
that the hardware engineers might have
troubles actually coming up with
hardware which suits the memory model
and the guy who authored this quote is
again Alexis appeal of who is an
engineer at Oracle does a lot of
performance work and just knows his
business you can trust him if you don't
trust me okay so one of the key concepts
of a moment memory model our memory
barriers so suppose we have this thing
here and
we want to make some statement which
does not allow the run time to actually
reorder this one's we should want do not
want value to be written after finish
this written we really don't want that
so we add some magic unicorn except that
the problem is that if you try to
compile this it's going to say that
there is no such thing as a magic
unicorn so we need to specify a little
bit there are two types of memory
operations that are commonly used its
write and read also commonly refer to a
store and load and in hotspot sources
you are going to see a lot of st and LG
which are short for store and load and
it is important not to to give the
software engineers some ability to
actually specify which of the Rio
jennings exactly should not be allowed
so sometimes it's perfectly fine to
reorder a store and a lot and some other
times it may not be acceptable to
reorder two stores with each other so we
need to give us some fine grained
control over the behavior on and off
what the compiler and runtime and the
jail is allowed to do therefore we have
memory barriers which our company types
is x y where x and y are store or load
so we have four types of memory barriers
store stores down load load load load
store all right actually he if you
suddenly realize that i'm going too fast
and you cannot keep track of what i'm
trying to say don't hesitate just I
don't know give me a sign is it clear
for everyone so far great because we
have quite a lot of stuff to go into so
for x and y in store load a memory
barrier of kind XY mean that all X
operation CX must complete before any y
operations after the barrier
that doesn't seem quite understandable
so let's get to an example suppose we
have a store store memory barrier and we
have some store operations and it means
that we cannot take this store of value
and put it later after the barrier and
these two stores we cannot put higher
than the bear it's not allowed because
we have this store store memory barrier
right okay and on the other hand if you
have this store store Barry we can
freely reorder the loads we can take
this load and put it here it's okay
because the store store memory barrier
does not limit us in terms of reordering
clause so there is just one more thing
of importance that we should get
familiar with it's just a quote from the
JLS there is a synchronized with think
which just several people out of here
have a familiar with and basically for
example let's take an example this is a
right to volatile fire variable and this
is a read of a volatile variable and it
synchronizes with basic rise with each
other so there are some order in terms
of mathematical order on them and the
source is called a release so you start
the variable and kind of release it for
anyone for the taking and this read
acquires what you have just released
okay that's just a bit of terminology
keep that in mind please if you suddenly
find out that I am saying some words
which are not familiar with the game
please don't hesitate to ask I might
have missed something okay now it is
time for us to actually go into the
hotspot sources and see how the stuff is
implemented in there because we have
been saying quite a lot of words but we
really really want to see how it's done
but before we are ready for our trip and
adventure we need to just have a small
outlook on how hot spot is implemented
there was this talked yesterday about
hotspot internals anyone
attended it several people three or four
okay it should be much easier on you
well for the others I have drawn
together a small class diagram of how
hot spot is implemented so here it is
it's pretty understandable so we have
this whole overall wait wait that's
wrong how did this even end up here I'm
sorry this is the class diagram of my
most recent startup project you know
it's very awesome it can print a given
phrase to the output and it can at the
moment it only prints hello and world
but I think in the future is going to be
awesome okay let's just consider this to
be the source code okay this tab hotspot
so this this our crops that this is the
source code and what happens to it when
we want to it to be run is that we run
Java see it produces bytecode on the
output then comes the front end of the
JVM the front end is something that
takes the bytecode and kind of par sis's
parses it and on its output it produces
an hir what H AI R stands for is high
level intermediate representation it
means that it's some kind of a data
structure inside the hot spot which is a
high-level explanation of your code
which you have written then this hir is
fed into the JIT optimizer you see
there's actually a stack of optimizers
so gradually step after step the thing
becomes more and more low-level so on
the output you get an li are low level
intermediate representation it's much
closer to the hardware it's rid of many
of the things which are in the high
level and representations it is pretty
much like native instructions but not
quite the thing which translates lir to
the actual native instructions is the
back end it produces machine-specific I
mean the hardware specific commands and
on the output it gives native code
and after that we have some more
mysterious steps and then we get the
profit after all we are writing for
profit okay so that about sums it up and
now are you ready to go into the sources
or maybe you have some questions before
that because it might be confusing
anything right now something that wasn't
clear at all not really okay that's
great now the question i had when i was
first trying to do this is okay the hot
put sour space is actually pretty large
you know if you just take the hot spot
sources and check them out there are
going to be a lot of stuff in there i
think which okay the most far away row
do you see this right put your thumb Bob
can you see what's written here not
really let me zoom in a bit pardon okay
let me try this that might be not is
easy I thought I thought maybe like so
can you see what's here hello is that
clear okay so basically we have quite a
lot of stuff in here and what we know is
that we are trying to hack on a hot spot
so we would go to the directory and see
what's in here and still it's quite a
lot of stuff in there okay SRC it might
stand four sources and in here we have
again some directories and it is not
quite obvious about where to go to find
the thing there are no real
documentation which states that if you
want to say look how a volatile store is
executed you
go and look into this class that's not
something that happens so we need to
improvise and we are kind of
investigating what's going on here so
the thing is we're going to try to do a
little magic so I have a small agenda
here just in case what we're going to do
is find all the get filled and put field
oh hold on I actually forgot something
important so what we have here we need
to find an entry point we need to find
someplace or something which we can
start from so basically a hotspot is at
the moment mostly a black box for most
of you it was for me as well so there is
some thing which we need to do to
understand where we can start so the
easiest thing to do is get our source
code and translate it to bytecode which
we're going to do right like now hold on
a second please ok zoom in
java concurrency handsome we have here
an appendix which has a so here we have
okay let me first show it to you so what
we have here is a simple class volatile
example which basically is what exactly
what we have seen right so if we take
this and get its byte code which is
exactly what we are trying to do so this
main blah blah blah volatile example
right so what we have here is two
methods one of them executed on cpu one
and the other on cpu true so we have
here a put field which is probably
storing something into a field and then
we have a gap field which is probably
getting something for a field so
basically these are the two instructions
of byte code which we are interested in
we want to see how hot spot actually
translates them to native code okay so
once we have these ones we can start
actually looking in the sources because
the sources must contain something like
food field let's do this so we can do
some grip
for a good field and the problem is that
we are getting quite a lot of output we
should somehow narrow down our search
and so as we know hotspot runs your code
in a number of different modes so first
there is the interpreter then there is
the client compiler and then there is
this charger compiler the interpreter is
too easy for us it's not interesting and
the shower compiler is really really
where a hardcore it would take ages to
go through it so we're going to stick
with the client compiler because it
perfectly fine explains what we are
interested in at the moment if we were
to go into the server compiler we would
take some pages and we might get lost so
let's go into the client compiler and
see what it goes client compiler is
commonly referred to as c1 so let's try
to find it well we found it ok let's go
there and run our grep again and finally
that's all wrong cities ok so finally we
have found that we have only about four
occurrences of it and it is actually
great now let's move on to an IDE
because an IDE is nicer it's more
convenient than a console is our don't
yep it's open its gate so as we have
known it's a SRC share we m and then c1
great the file which we were interested
in is the graph builder no idea what
this but if we actually remember what we
have seen in this in the presentation in
the slides I can actually get it back a
little we have this front end and front
end is the graph builder it takes on the
input white hood and produces hir in
return a graph of what your program is
so basically we are going to come here
and take the graph builder and ok zoom
in right like so does everybody good the
bottom rows thumbs up naturally ok zoom
in a bit more better okay now we're
going to look for this food field thing
okay okay so we have some switch on
about it and we see that if we have
encountered encountered a put field in
the bytecode we're going to do some
staff do some stuff and then we are
going to append to our graph the high
level intermediate representation of our
program we are going to append some
store field to it so basically a store
field if we go inside it is a instance
of a leaf so basically if we have an
abstract syntax tree it does have leaves
correct so each individual instruction
is a leaf on the tree and store field is
one of those instructions great now if
we were to go into the gate field it
would basically be the same thing now
what we want to do is see all the
currencies of store field and how the
lower levels process store filled
instructions right does everyone follow
me still okay don't ask me why I'm doing
here it from the
so but we're going to use grep again and
we see it in quite a lot of places but
what we are mostly interested in is the
our generator because well I are is what
we have just seen as the low level
intermediate representation so we want
to see what happens on the next step so
we're going to open up the Li I our
generator class in C++ and by the way
does everyone here have a bit of
understanding of C++ okay great so we're
looking for store filled oh yeah thank
you that explains why it's not found
okay starfield doom store filled that
does sound like something that we want
to happen and there is this comment
which explains what's going on but I'm
going to do it as well because well it's
not fun to read comments right in the in
a conference you're here to reason for
the speaker explain it for you so what
we are doing here is we process this
thing and we want to do something to it
we want to generate assembly code out of
it right so the thing that draws my
attention here is this one so we are
checking if the field which we're trying
to store is actually volatile and that's
great I think that's what we are here
for so let's see this is volatile flag
and check all the occurrences of it in
the method let's scroll a little okay
this one we really are not planning to
go deep into this it really has
something to do with class loading that
it's not important in this context so
we're going to skip this if you are
interested we can talk about this later
after the main session is out and this
one is something that we should be
interested in so if the field is
volatile and we are running on a
multiprocessor NY
event then we should insert some member
release that's great actually there is
the fun thing about the EMP think there
is a way to deceive your jvm into
thinking that it is running on a single
core instead of a multiple core and if
we do this this check is always going to
return false and many of the memory
barriers are not going to be in place in
which case the JVM will crash in about
several milliseconds after you run it
that's fun so we have this member
release and basically if we go inside it
we are going to see that again we are
doing some we're doing some append so
memory better release is a air operation
which is appended to our lonely low
level intermediate representation it's
almost a machine instruction but not
quite yet so we realize that if we want
okay let me get it a bit straighter what
we had on the high level was a right or
a store of a volatile variable but what
we have on the in on the output from the
low level intermediate representation
generator is not just the volatile right
we have something more low level we have
one memory barrier here at least one
then we return to it and we do actually
a field store and then we do some other
stuff so instead of having one
instruction we're now with several
instructions which are more low level
than they were before okay is that clear
basically what has just happened is we
have transformed the bottle right
instruction in 2 Samuel structures and
we have just seen the first of them the
memory by release we do not know at this
moment what it is so we're going to see
it later but first let's see the other
instructions which are generated so
here's another check we are checking if
the field is volatile and again some
needs patching but it's not relevant
right now and we are going to do some
volatile field store but if it's not
volatile we're going to do some other
storm but hey that doesn't make much
sense right we have just checked if it's
volatile but now we're doing this again
that doesn't make sense there must be
something else special about the portals
volt our fields what is it can anyone
tell me other than the memory effects
not really ok let's go into it and see
that if you have a long field as
everyone might remember if we have a
long or a double if we write it and it
is not volatile it might be actually
written by 32 bytes at the park bits at
a time but if pardon yeah so but if you
have a long or lab of fuel that is
volatile we must actually make it atomic
but so this is exactly what happens this
is sort of some black magic you see this
is actually already specific to x86 to
the hardware and what we are doing here
is we are using the coprocessor to do
some magical operations which make the
right atomic and for general fields we
do not do this by the way it is quite an
interesting topic it is a bit of off
topic at the moment but I think we have
a couple of minutes for me to cover it
it is a bit of a legacy you see if you
want your right to be atomic you have to
add volatile but isn't volatile as we
have just seen also adds more overhead
rememory order effects so that is not
fun right and the guys who are familiar
with lexie shipping love i really
recommend that you read his blog and
maybe even had a talk about it he did an
experiment in which he checked what if
we made all the rights atomic regardless
of whether the variable is volatile or
not and it turns out that in this modern
age most
of the hardware can actually handle it
with next to no performance loss so it
is probable and not an oracle employee
but so I'm not under any constraints but
I think it is quite probable that in the
future versions of Java all the rights
are going to be atomic regardless of the
volatility of them that's good news
pardon okay the question is what is the
rule the dump if the right is atomic if
the variable is long or double and it is
not volatile it might be written not
atomic layer if it is volatile that is
it is guaranteed to be written
atomically all right okay now we can get
back so we have just seen that volatile
rights are quite a complicated thing to
do but there is another thing which we
need to do for the volatiles after we
have actually executed the store
operation let me hack on hot spot a bit
for you scroll scroll Scroll scroll what
we have just what we just had was a
store bottle store of some field right
but instead we got oops
what we got in return that that doesn't
look good does it ah anyway what we got
in return are already at three
operations so it is a memory barrier
then is to the store and then comes the
memory barrier just whoops just a memory
barrier right so one operation of high
level intermediate representation was
actually transformed into three ones
okay that sounds understandable right so
let's get a quick look of what mod fuel
does because it is right here next to
store field again where chicken if the
field is volatile we are going on and
what we have here is a volatile field
mode which is basically the same atomic
thing about the Atomics and then after
that we insert a new memory barrier
which is acquire this time now we have
heard about this memory barriers and we
see that it just generates new memory
barrier instructions in a low level
intermediate representation and we what
we want to see you is how they are
implemented in the hardware right so
let's go for it we take these and how do
I do this I'm not quite a lot bins user
I don't exactly recall how we can find
usages right okay let's go for it okay
so we have we have here a little
assembler which sounds exactly like the
thing which generates assembly code
right and if we have a member barrier
then we are emitting some instructions
and the fun part is that if we click
here we are going to see oh pardon me
we're not going here yet what we had
first was the release correct so we had
a memory by release
then we had the store then a memorable
but the fun thing is if you can as you
can see you it's no operation is just an
empty instruction but now why might it
be any guesses okay I'm not going to
torture you because will not have that
much time so we have we see here that it
is a x86 specific code already and the
engineers which are creating the x86
hardware they made their hardware have a
very specific property it's called the
TS o or total store order it means that
every single right that happens on a x86
machine are ordered in some specific way
so at any point of time you can tell
which right has happened before each
other and that is precisely why we do
not need on this particular hardware to
add anything to do this which explains
why on 8 not on x86 we almost never have
this bug pop out if we do not add
volatile because this memory barrier
from the hardware point of view it does
not do anything the same thing applies
to acquire because of the total store
order on x86 it does not really get to
be important it does not emit any
assembly code the last thing is the
memory pair of which is emitted after
the store this is the only one which
actually does anything so if we go
inside it we are going to see that
whoops not that way we are going to see
that it emits a single instruction what
it does it is is it emit and looked at
operation basically what we want to do
is to force the hardware to not reorder
the right which we had with
any other as we can see the store that
we had we do not want it reordered with
any loads that come after it so finally
for a x86 there is a specific hardware
instructions in the processor called
friends or infants which does exactly
that but instead we're doing something
different we're asking the processor to
add 0 which which is basically do
nothing to the current stack pointer but
do this in an atomic way it has memory
side effects which give us the same
guarantees which we want but finally it
has better performance than executing
the very instruction which was designed
to do what we want to do that is a bit
strange but it is explainable there are
several papers well Oracle engineers are
not idiots they're clever people so they
did this after running some careful
benchmarks and it turns out that the
other instructions it has quite a lot of
other side effects which we do not want
and this one has fewer of them also at
the moment in Java 9 it's probably going
to be changed to add 0 to n location a
bit deeper in the stack I mean after the
stack because otherwise we can have some
contention issues in the performance
which suffer but basically what we see
here is that we have just one
instruction on x86 which gives us
volatile security for volatile fields
and the fun thing is that even without
this instruction it would still more or
less work because what we have seen in
the graph you do remember it right I
will not scroll back to it but the thing
is that without this instruction almost
never do encounter this issue and if we
run the client compiler we do not
encounter this at all and the thing is
the difference between the client and
the server compiler is that the server
compiler is more clever in applying
optimizations
you do recall that i mentioned that
optimizations are more or less the root
of all and inexplicable behavior that
your program exhibits so the server
compiler does more optimizations and if
it does not see the memory barriers
which we have just seen I should stress
it again that this memory buyers are not
just limited to the hardware they are
there on every single level on of your
code so did optimizer which we see in
this code if it sees a memory in this
slide sorry if it sees a memory barrier
it limits the number of optimizations
which it does as does the hardware as
does other things so if we own it the
volatile it may be broken and the most
important thing which you might take out
of this presentation I'm just running a
bit short of time I'm sorry about this
so we are going to oh I have forgotten
the most important site of my
presentation live demo time sorry about
this yet it was I was playing to go like
ma hahaha but ok so the important thing
about this talk is that when you are
writing concurrent code you should never
ever unless you are sure you're an
absolute expert and I'm absolutely sure
that I'm not one and some more people
that are more clever than I am are sure
that they are not experts you should
never really rely on the hardware
specific things you should learn JMM you
should understand it really well and
only then you should try to use it to
explain or understand how your code
works if you come into a performance
problem only then you might actually
look deeper into what is going on under
the hood but otherwise please do not
expect your programs to be correct
because even if you think that the
hardware or the implementation has some
specific detail which makes your
concurrent program correct it might
change it might end up right
in different processor it might end up
running a different version of a JVM
which has another optimization and which
breaks your code so the rule of the
thumb bees do learn JMM really but
otherwise big heroes and go do not be
afraid to go deep into the hotspot
sources or whatever it is for that there
are several papers which are mentioned
on this slide and several blocks off
Aleksei Chappelle off needs on what
pattern mechanical sympathy which people
Randy familiar with need some workers i
also have a blog and generally people
are the best sellers so yeah that's
pretty much it if you ever want to view
this presentation again please scan this
QR code or follow this link i'm also
going to post it on Twitter we are the
jello one hashtag feel free to look at
it and feel free to contact people with
any questions i'm going to be at the
exhibition hall you know there's this
stint with the robots I'm trying to
teach them to wield a lightsaber and
block incoming fences if you feel like a
marine s more hackathon just coming over
and we're going to have some fun if you
have any questions come over I'm going
to try to answer them other than that
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>