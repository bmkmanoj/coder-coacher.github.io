<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Patterns, and Antipatterns in Docker Image Lifecycle | Coder Coacher - Coaching Coders</title><meta content="Patterns, and Antipatterns in Docker Image Lifecycle - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Patterns, and Antipatterns in Docker Image Lifecycle</b></h2><h5 class="post__date">2017-12-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7Kp56f8Ctac" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello and welcome to these patterns and
Amity patterns with docker image
lifecycle Oracle code simulcast my name
is barb Sikorsky and developer advocate
who is jefra l.j borrow from the
internet and twitter as well and that
will be a good time to follow me on
twitter very interesting and have been
interesting because this is what I do I
drink and I know things and after I'm
done with this single cast I'm going to
drink and I recommend you do the same
now after grabbing your attention
hopefully comes the most important slide
of the day and this is the link to
Jeffrey to come slash show notes it is
the important side of the day because in
this page you will find all the rest of
the slides and tons of different
materials links to restart that we are
going to talk about today so if you want
to learn more or get back to what we
spoke about it will be good place in
Jena frog is I mentioned we help you
release faster by managing your
artifacts and binary files and Jeff
Roberta factory did you probably
familiar with is our flagship product a
universal artifact repository bean tray
is a distribution hub for any kind of
your distributable software and Mission
Control helps you manage a huge
installations of ours Factory is servers
and Jeffrey x-ray is the universal
software composition tool that helps you
realize the component graph do you have
the inner track 23 and in find
interesting stuff about it and act
according
before we get to the real content I
would like you to participate in a poll
and that will be a poll about your
daughter usage we're obviously going to
do it online so please go to a Jay
Baruchel or a code and feel and one
question a question you're there then
after we do that check the previous
responses because this is the important
part
once you voted and looked at the
previous responses hopefully we'll have
some by time you you're voting a please
get back here and we are going to talk a
little bit about the results
you
you
welcome back so obviously I don't know
the results because you are voting now
but let me assume that we have less than
15% of votes for usage for using docker
in production and this is what this talk
is about we are trying to analyze why
people not use this is a sanctuary
technology as docker in production
enough and I guess there are a lot of
different reasons for instability being
one of them and many others but there is
another one which is very important and
that's an issue of integrity and Trust
and I'm not talking about security
notary good that does a very good job in
this regard and there are other security
measures that help docker to be better
with that what I'm talking about is
making sure that what you intended to
put in your poker image is indeed what's
inside it right what we want to
establish is this kind of trust and
integrity in which in every point in
time of your a continuous pipeline you
know exactly what's going on inside the
docker image that you are going to run
in a certain file and I believe that we
as a frog his grade levels of
artifactory
help this credibility of talking about
this stuff because we have a very long
and loving relationship with docker so
if you weren't sure this is the heart
frog
and we'll so one of the examples where
we integrated very well whose daughter
is for example in the usage of daughter
with other stuff so this is of course
Holmen Heights a standing on stage of
dr. Cohn two years ago 2015 and asking
this question who's using doctor novels
and and of course you can think whether
you are using doctor nothing else and
the answer will be known and this is an
answer that everybody give including all
the old people in the audience if the
skin out and that's because this analogy
of daugher to a transportation container
works very well here as well there is no
reason in the world to sheep empty empty
containers back and forth and there is
means there is no reason in the world to
do doctor only you always have something
in it and when you have something in it
that will be another piece of software
that you built and used the same
pipelines can give names to the bishop
with nipples delivering pipelines and
their relationship with docker are very
very important so this is exactly where
we where we come to help and when we
think about building the pipeline with a
new tool and as software engineers the
first thing they ask do you have an
existing part and then we have an
existing pattern do we need to adapt it
the answer is obviously we have existed
but continuous integration and
continuous delivery pipelines we use
them for years and we use them for years
when exactly how it works this is our
kind of promotion and normal promotion
that we use we have huge amount of
beetles with very fast tests that either
passed or fail and if the builds of the
builds pass they are promoted to the
next level when we have less builds and
longer tests and this is how it goes all
the way to the top of the pyramid when
we select only the chosen few to be our
production artifacts to be actually a
product and that's because they passed
all the tests or looking at the same
diagram from another perspective this is
the same pipeline going through your
artifacts are going through different
stages and you can see here that we have
those planners that are promoted from
one environment to another by moving the
artifact through quality gates we're
going to talk about quality gates a much
more that's a great diagram from a great
book a July LM by my dear friend and
Oracle code champion Michael hood Roman
and very very recommended so um the
problem is docker and the problem wine
we even have this talk and why you can't
just use the same patterns of continuous
integration and delivering talker is the
talker built command and and the problem
is dr. booth command is the release
Chuck Norris it's extremely powerful you
can do everything in docker build and
that's of course a good recipe for abuse
because when we have such powerful
command our in instinct is to docker
build all the things and we end up with
something like that instead of promoting
artifact through the continuous
integration pipeline we will promote a
docker file through the spotlight and
run docker built in every environment
well that may sound like a very good
idea because it actually guarantee is
very simple promotion with promotion of
the text file is just a matter of
tagging it differently or maybe
branching it and moving through the
branches but it's definitely more easier
than promoting artifacts it is actually
a very bad idea because fast and cheap
peanuts are not always the way to go and
that apparently was a fast and cheap
building built that just felt on
completion a on its side that's actually
true picture so yeah transom tube builds
are not always doing too well and the
reason is that so and what you see here
is a typical daughter built file in
every line of it except a creating of
directory and running the command is
actually in a dependency on the latest
version of some artifact now and when I
build this talk I thought okay I need to
create this time of this type of
ridiculous bill file and I will say that
of course no one does this in production
and you actually shouldn't do that as
well and then I just went to the
internet and googled and I discovered
that internet is full of such blogger
files now this one is not fake
this is a real example and in the
different homes they shall not a
language he will find a link to this
specific buffa it is as horrible and now
people specially did their 15% or or a
those people that voted for daughter
introduction need to start healing on
their monitor and well it doesn't have
to be like that right we can fix it and
and and this is true we can actually fix
it and let's try and fix it
and now so first of all we can nail down
the version so for example we can use a
concrete version of our base image
instead of saying boom to latest let's
say 1 2 1404 forgiven for was a very
good and stable version and a lot of
people still use 1404 although it's been
like three and a half years by now as
their base image just because it is
successful version so why not and and
this is in apparently looks like a
solution for our problem just because we
know that when we manually release
version we always refer to the same
binary but is it so so since april 14
when punto 1404 was released couple
things happened in the area of security
one of them you must remember it was
heart bleed a horrible horrible
venerable 'ti in OpenSSH component that
actually all the wind installations of
1404 and and here's canonical great
company they are the maintenance of
Ubuntu have this dilemma from one side
1404 have to mean have to mineral is
immutable or whisper from other side we
know that people want update the image
use all versions for example now in 2007
I still use a boon to 1404 if the
release was immutable I would get a
vulnerable base image now but what they
continue doing is patching the release
version with security updates without
updating without increasing the pressure
so what we actually see here is that 40
mph or 3 years ago is not 1404 of today
and that means that we still rely on an
unknown ver we can fix that as well so
we can use a shot to shot 226 to 256 a
checksum of the image now this is very
reliable
every time I will use this from
statement I will always get the same
image the only question is which engines
which image is that is this the same
1404 or maybe it's 1710 or maybe I just
hit my keyboard with my fingers and this
is what I got right we actually don't
know this is a reliable but completely
unusable because I don't really know
each version I prevent and that's of
course a and better now
also what about those and if you are
familiar with up with up get you know
that you can nail down the versions
right you can say I want this version of
Python where I want this version of
nantes and and this is good it actually
solves the problem but it requires your
familiarity with up get so how about
this one now we run maven install which
uses pom.xml as their dependency
declaration in which we might or might
not have final versions for dependencies
which in turn might or might not relate
to other different versions of different
software so we actually don't know if
the version that we are using if the
bill in the version of the dependencies
are stable or not would even work very
hard and we can eventually make doke her
to do the right sorry make maven to do
the right thing and make it very stable
and immutable a maven build but we need
to know Megan for that and how about
this I mean here we have no idea at all
what's going on my point the reason why
I take you through all that is actually
to say that rebuilding the docker image
from a docker file will almost certainly
in some point of time sooner or later
generate different results and with that
this is our fear that when we rebuild
from docker image
in our different environments we will
end up with different versions of our
software slightly different but still in
our daughter image in everyone and this
feeling of you know what I'm not sure
that what I run in production is what I
tested in the QA stage is one of the
reasons we hear a lot that docker aim is
not taken to production yet right and
this brings us to another pattern and
this is a very familiar very famous a
Martin Fowler pattern called immutable
server and the immutable server is about
how we used to use servers to treat
servers back in a couple of years ago
persons how we actually treat them now
traditional server hundred means you
have a server either
it's a bare-metal server or a virtual
one but still you take care of it as it
was your pet you patch it with security
inner abilities when you need to change
to check a configuration change a new
version you go and change the
configuration is the server and you keep
this server alive as long as you need it
making all the adjustments in on a live
server and this means that this server
is mutable what we see nowadays and this
is what imitable several pattern
actually in cold food is using those
servers as interchangeable pieces of
software and hardware combination so we
treat them as cattle not aspect we won't
name them we don't care about the match
and every time we need to make different
change will make a change to our
software blueprint of the server and
then kill the old one creating new one
with better configuration and that gives
tons of benefits like 110 ability and
think about changes that need to
propagate through thousands of servers
how do you do that is immutable server
pattern you change the blueprint the
generate new servers until the old ones
filled up and this notion of
immutability this is exactly what we
want to take into our promotion pipeline
instead of building every time a new
image and actually making your CI final
immutable because in every step of your
CI pipeline you can end up with
different changed image we wanna promote
this notion of immutable and stable
banners you build the ones they never
change
you take them through your continuous
integration and delivery and immutable
as immutable buttocks and here it's
exactly what we are talking about you
build it once and then you have this
image that you promote through security
gates you pass it through sort through
quality gates from one environment to
another it was in temp then it is
production when it asked those quality
aides it's actually graduates for the
next Empire and I'm keeping talking
about those quality gates almost like
some other people obsessed with walls
but I do have a good reason and those
quality gates are extremely extremely
important because
humans shouldn't test they have images
which are not worthy to create just to
rest a third time not tested images
shouldn't be staged that's the waste of
stage incompatibilities and the most
important not staged no tested or deaf
time images shouldn't end up in
production just because there are no
taste tests they're not staged and
they're German definitely not ready for
production so how can we build those
quality gates into dorker pipelines and
that sounds like a real question for and
all of us come from a traditional
software development because we know
exactly right you take a repository like
factory or others and then you have
different depositors into your
repository manager and you promote your
artifacts from one repository to another
then once all the checks and and the QA
is completed this is your promotion
pipeline normal stuff not so fastest
daughter in don't care we have those
trapped up limitations almost like the
six 640k memory limitation that a
Microsoft introduced back in the days
which are not mandatory by anything but
just exist with docker we have the same
and the next limitation is hidden inside
an anatomy of daughter time so here we
have and documentation about daughter
time and you can see here the format and
the format is having the registry most
inside the tag of an image which is a
decision it has pros and cons and pro of
course is that it's very you can very
easily see where actually your your
image comes from is that the canonical
image that comes from dr. knot or it is
the flavor of it that comes from other
registry it was of course and has been
on downside we're going to talk about
that and then you have the user name the
name and the person and the biggest
problem here is that dr. Todd he uses
four slashes as separators between host
and the rest of the image the problem
with it is that separator between /a
separator between a post and the rest of
the context is already taken this is how
we build URLs so what it actually means
is that we don't have any easy or
reasonable way to implement multiple
repositories or registries per host
because after the slash of the most when
we should provide a name of our registry
dev QA staging production instead we
have a doctor a docker image or a user
eminent doctor image we don't have this
slot or multiple slots for celebrating
between different registers so how can
we support someone work with that how
can we use a multiple registries and and
it would be beneficial to use in context
context the URL as well to implement
multiple registries to build those areas
inside your
host:2 then promote artifacts on docker
images from one to another how do you do
that
and and that's a limitation that exists
it exists for for everybody for any
implementation of docker registry
including the official and distribution
and docker registry as well and this is
of course the first reaction that you
should have because it basically means
that you cannot build any sensible
pipeline with hard quality gates because
you cannot separate between the
registries on the same host but there is
a solution for that and the solution
will be virtual hosts or ports that can
actually solve the product so whatever
we do is take this docker tag format of
host port and then tag name and and this
is by the way how the request looks like
translated to something like that and
this is what we actually wanna have we
have a help would wanna have contacts
name just because why not we want to
have a repository name this will be a
registry for different environments they
have a QA staging prod and then the same
tab name and we can actually do it with
mutual ports or virtual hosts and this
is an example of three virtual port
implemented in nginx that's example of
ingenious config and you can see here
that we have a virtual port it's not a
physical port on machine and on this
virtual port engine mixes listening in
knowing how to rewrite the URL to
actually forward this request into a
certain
repository registry in our example it
will be dr. death so we will have those
virtual ports for each and every in
repository or registry that we have
inside out factory and all that going to
host with five thousand and one will end
up in dr. death and going to the host
five thousand tooth will end up in
doctor staging and shelter etc and so
this of this problem but here is another
one how do you this promotion at all if
you have the host name and the host port
inside the tag you need to do retaining
andrey tagging is a client : so every
time and in the promoter tag you need to
pull it retag it and push it again and
that sounds like a horrible idea because
the very images are huge and you don't
actually always need it on the client so
virtual repository another solution can
help who's that and here's an example of
how its implemented live not factory you
can see here that the developer actually
only interacts with one registry our
docker virtual when the developer first
time pushes the artifact it will get to
a doctor Deb level dr. Deb local which
is a development time registry and it
will be done by maintenance factor
integration and then what we actually
will have is a promotion pipeline going
through different repositories or
registries by using the artifact of the
REST API you don't need to pull retag
and push again and each and every one of
them for their environment is a
full-fledged docker registry so if you
have a kubernetes source water or just a
single machine that means to pull from
each each and every environment to do
their testing they can do it
successfully by using those those
registers and then it is exposed again
to the outside world one is ready to
production whether for pulling or going
to production environment through this
docker virtual repository inking so this
is now sold and before we conclude this
session let's talk a little bit about
how we design a proper poker in docker
image and for that we need to understand
how a container works and not this one
but docker container and so the example
that you are going to use is a java
application that has a base of Centaurus
for this example we used two previous
one and then we will have some kind of
application server in java virtual
machine just for the farm layer and then
we have our application and in our
example will be a war file does
something to be crouched in so we have a
number of bills we actually have two
bills one of them is the frame of the
Fredrik build takes a verified based
image and it's verified multiple layers
it is compatible with the rest of your
application
secured
it has no problems and you are allowed
to use it and then we have system
dependents in our example system
dependents will be the JDK and our
applications and we will add those
dependencies from a trusted source and
of course you should have this trusted
source in house and again in our example
it will be it'll be R to Factory and
once we use Center s it means we use rpm
images RPM packages alert factory is of
course an RPM registry so you can just
go ahead in your build file and to RPM
cam installs for 3d cake and wildfire
the most important part of the federal
build is that you own it it generates a
stable base image that your application
will be will be reliable and the minimum
frame total file looks like take the
verified based image and own it because
now you are completely protected from
any changes that red head will introduce
into Center s7 because now you have your
own layer that you refer to and this
mayor will always be stable and mutable
it doesn't mean you shouldn't updated
once in a while you definitely should
but you do it on your terms and whenever
it's comfortable to you your application
built first of all uses the framework as
your base and as I mentioned this is
very important because there
that won't change and you are not prone
to the changes of the base image then
you run a Java build because that's the
application that we build in our example
you add one file to a base or file and
then you are done so our application
daughter will file will look something
like that we add one file in our example
would be a war file to our deployment
directory inside our and here you should
have a lot of questions so first of all
why were using here a release repository
now there are two different approaches
one of them and basically the question
is can we test these job applications
than the one without the container if
the answer is yes this application will
have its own continuous delivery
pipeline and in this continuous delivery
pipeline of its own it might have dev
and QA and staging and then release
repositories through which you promote
your a java application and then it will
take it from release if you always test
your wor application inside the docker
image then of course he will take it
from there from the dam because it will
only have depth and then it will be
promoted with the docker image through
the pipeline and daughter will have the
rest of the reporters doesn't question
is are we relying here on the latest
version the answer is yes we do rely
here on the latest version and this
placeholder release actually means give
me the latest version in our Factory and
that's because this is exactly what we
want right we want to either take
the latest stable a war file if we have
by applying for its own or we want to
take the latest any war file because
we're going to start the pipeline now
and take it through tests so taking the
latest here is completely justified
another question is didn't we just
mention that we should rely on the
latest base and the answer is yes if you
are not in control of your latest base
and this is not the case here in our
case we know exactly what the latest
base is because as you remember from the
previous slide we control it
so now let's test about let's talk about
testing there is a new term that you are
going to learn today and it's called
sandwich testing and sandwich testing is
completely a thing and you know it by
when you google you have this google
selects a definition if it does that
that means of its that's 100 central
right there is no doubt about so it's
completely thing in sandwich testing and
what it actually means is a mix of
bottom up and top bottom testing when
you test two different parts of your
application lose another and that's
exactly what we do here so those are two
part one foreign word appears we have
the flatlands that we used we have the
framework pipeline and education
pipeline and we are going to use one to
tail to test the other so we will take
the land the latest frame latest good
know
framework and run our development
application built on the latest
framework these guarantees that we are
actually testing the application and the
other way around
once in a while we want to update our
framework build we will take our latest
good known application and test our
framework that now will be compatible T
so for example we're talking about a bag
we're talking about Java so now we have
our base which has a stable Java 8 for
example and every time we have a fresh
build of our application we will run it
on Java 8 and we'll test it and we'll go
through the pipeline now Java 9 is out
we want to update that framework we will
update our frame to geralyn and then
take the latest known good application
to test whether it works or fails on
Gemini this is how you guarantee that
you have both pipelines will test now
sometimes you may not in a deadlock when
the latest change in the application a
conflict with the latest change of
framework and they don't work together
and this is solved by making sure that
you have the right three years that
every time in your application version
is produced it is tested with the
framework and every time a new framework
version is produced it is tested
who is the application because this is
how you can you can guarantee that you
won't have to control
making a new versions that comes with
the job
so with that and all I want to say a to
you is of course release faster die and
and this means that you need faster
releases and for that you need to have
modular software and full automation
that's what these tokens amount so just
to remind you and I'm NJ powerful
teacher Greece's Oracle cost code single
cast and you have these different curves
are shown on so resource in which you a
go to get all the links about all the
stuff that we spawned today and who's
that now we have time for questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>