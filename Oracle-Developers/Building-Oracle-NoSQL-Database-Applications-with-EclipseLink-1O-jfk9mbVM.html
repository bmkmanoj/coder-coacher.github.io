<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building Oracle NoSQL Database Applications with EclipseLink | Coder Coacher - Coaching Coders</title><meta content="Building Oracle NoSQL Database Applications with EclipseLink - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building Oracle NoSQL Database Applications with EclipseLink</b></h2><h5 class="post__date">2015-06-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1O-jfk9mbVM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">there's a number of us up here today
they're going to share some information
with you about no sequel technologies
and basically you know where they're at
in their life cycle where we'd like to
see them head towards down a road of
standardization eventually and just what
some of the challenges are in that
regard I'm Robert Greene I'm a product
manager with the Oracle no sequel
database team and then colleagues of
mine will introduces as they take over
some of the more interesting part of the
presentations actually there is a caveat
that's the you've probably seen time and
time again you can't believe anything I
say until it actually makes it there
into a product just in case accidentally
slip and say something it doesn't exist
so again we're going to talk about a
little introduction to no sequel and
just give you guys a chance to
understand the backdrop of what we're
talking about here how many of you are
familiar with them have been already
playing with no sequel databases okay
good good percentage of the crowd got to
say that's a real pleasure because I
done a number of sessions over at oracle
openworld and you'd be surprised how
many of the folks hadn't really been
playing with the technology yet so I see
it quite a different situation or at the
Java one sessions which is which is nice
and then we're going to talk about
eclipselink for no sequel and talk about
you know what's there in in the existing
downloads that are available and
ultimately what some of the more
interesting things are that have been
being played around with give you an
idea about what we're thinking about and
ultimately go into a deep dive where we
actually John will take over and take
you through some examples that were
built to really give you a fuel for how
to use this stuff so first the backdrop
and since so many hands went up this is
probably a little you know yawning here
but you know just just to give you an
idea to you know we started out with
traditional business systems it 10 or 15
years ago and you know basic well driven
models that we all understand accounting
systems CRM you know and largely you had
guys inside companies typing away
entering that that that information you
know the
an HR department new person comes in you
get person types away at that right puts
his contact information in and adds them
to the employee system well these days
you're getting a lot more data that's
getting generated because of the
technology that's emerged namely in the
networking space and the emergence of
the Internet so you've got all this new
data coming in it's not really people
generated anymore so it's coming at
massive volume and it's it's semi
structured lots of textual stuff coming
at you but just also lots of very
structured but high speed data from from
things like sensors and and just you
know machine machine generated data not
just human stuff and so companies are
reacting to this saying how is it that I
take advantage of this technology and
all this new data how do I stay
competitive and that that's leading them
to think about house I could become a
smarter more agile business and in going
down that path they're thinking okay I
can I can use this data to get better
program management in place I can be
just just in time in my manufacturing I
can be just in time in my ad delivery I
can be basically more real-time and
deliver higher value to to the end users
and so that that's really kind of pushed
everybody in a direction where their
existing database technologies have been
cumbersome to them in that process they
want to get much much more rapidly
turning out the different different
services to their consumers into the
customer base and the traditional
requests change queues and all of the
the adjusting of the sequel statements
all add back in the application space
has made that challenging and so a
number of companies have emerged
creating this new database technologies
which with some trade-offs mind you give
you a little bit more agility and people
are starting to take this technology and
use it at large and you see a number of
companies that are very well known using
this stuff you know amazon and linkedin
of those guys sort of pioneered it but
you see it showing up in places like
disney and ericsson and cisco so it's
it's getting into basic corporate
businesses and it's not just in the
startups it's not just in the
bleeding edge companies anymore so it's
making it into enterprise so I'm going
to talk here about Oracle's no sequel
database and its architecture but it's
fairly common what you're going to see
here a lot of the other no sequel
database technologies will look a lot
like this and this will lead into why
it's challenging to to map this into
some of the current programming
paradigms if people are accustomed to so
this is a logical view of the
architecture and basically since you all
are fairly familiar with this technology
you'll understand then that it's it's
it's really based upon a hash mechanism
every single one of these technologies
data comes in there's some part of that
data which you could think of as a
primary key and it's hashed across a
number of servers and and if it's if
it's a good product then you know it's
the number of servers of all can grow
you know to hundreds and it can grow
over time you just add some machines to
it and it will simply scale out all the
data will balance itself out and you can
in fact even shrink them right so it's
very very flexible and it's a logical
design where it's elastic these
partitions are split and get wider if
you need more write throughput they'll
replicate more to get more read through
poor read throughput lower latency
response and in this architecture in for
organ listicle in particular some
particular node in one of these shards
of data will will take all of the right
operations and then it will replicate
out for reliability and for lower
latency response but you can read from
any node in the system so you can
imagine you know hundreds and hundreds
of nodes out there and the read requests
coming in and just split off socket
connections to each of those nodes and
so you can get very very high
scalability for large numbers of
requests if you look at the physical
architecture and actually switch it a
little bit onto its side and you'll
notice that those partitions the logical
partitions are actually being split
across physical resource
and that's for availability purposes and
so whether it's a data center as I have
shown here or maybe everything inside a
data center but you may be looking at a
rack you basically want to put these
processes in a smart way on different
hardware resources such that if you have
a failure you kind of minimize the
number of processes that are being
impacted and and so we we do that in
order to give you that highly available
system where any note can go down and
the system just keeps operating one of
the things that we do which the other
vendors aren't really doing is we're
putting a lot of intelligence into the
driver is a library that you link in
with your application which is aware of
the topology negative and it's
monitoring all the latency response at
the different notes and so when a
request comes in it doesn't just hash it
into you know wherever the right server
is the right set of servers that would
have that data or when to read request
comes in at this and just direct that
reading to any particular node it is
actually paying attention to what the
response queues are looking like an
apology and it's setting it to the to
the one that's going to give you the
best response so it helps work with the
underlying physical infrastructure and
its current state of operation to to
direct the request and give you the best
performance and throughput like I said
it's an elected master system so at any
one point in time some node in your
partitions are going to be responsible
for taking right operations what if that
note goes down when the other notes will
take over and then the reads are on any
node and the replicas again are simply
placed on different hard work so that
they're out bowling or bowl to an outage
question sure what up so do you
no very great question so I'll go to the
next slide because that's a perfect
question for the next slide so so the
question was since we direct the rights
to a particular note a masternode really
for a short of data do we hold a lock so
that only that particular note can be
written to you know by one transaction
at a time and we block others and maybe
you're referring to the you know the
MongoDB block you know if it's
classically known I'm going to be holds
one log for server so no we don't do
that we actually have a granular locking
structure that goes all the way down to
the to the value level and and so we
don't block we allow much higher
concurrency through into the into the
key structure hopefully that answers the
question another question since you go
to
this that architecture seems to describe
what they were saying in sections mysql
they talked about
way as well so does the Oracle database
have this feature as well no it's an
entirely different database this is if
you're familiar with the evolution of
the nocebo technologies I've noticed
some papers written by Google and then
amazon created something called dynamo
and and that implementation that amazon
created with facebook Homburg leading be
okay berkeley DB is a database
technology it's a b-tree based database
technology which Oracle acquired quite
some time ago so LinkedIn then popped up
with Baltimore they built that also on
top of Berkeley DB and so you know
Oracle took a look at that well there's
clearly a need there's a different
workload here so there's a different
kind of storage technology that's
required these companies aren't just
doing this you know for fun and they
looked around the Berkeley DB customer
base and they found you know folks like
well I'm being recorded major financial
institutions that build things very
similar on top of Berkeley DB of folks
in social social media I think it's
public the Yammer built their whole
social infrastructure on top of Berkeley
DB and so it's a very very complicated
set of code they had to write over
Berkeley to be to get the whole
distribution on it so Oracle in 2009
said well that's kind of there's there's
a real need here so why should I
everybody have to do a one-off and now
we're seeing all these other little
startups that are building similar
things and it just makes sense to go
ahead and deliver something which is
backed by a bigger company that can
really support it long term and deliver
it to market so that's where this is all
coming from its berkeley DB way down at
the core and then it's a whole bunch of
new infrastructure and management layer
that's on top of it so its features are
it's got a flexible key value data model
so i'm sure you guys are aware there's
several categories in this space there's
there's key value there's document
stores there's there's graph databases
there's a number of different categories
this is on the key-value side so it's
closer to an H base closer to a
Cassandra closer to react really however
it's not just a pure key value store its
value type can take on many forms i'm
going to talk about that in a couple of
future slides it's got transaction
capabilities but it doesn't enforce you
to always use the transactional model so
much like the other technologies there's
options that you can use on an
operational operation basis to say you
know this absolutely has to be
consistent and transactional or you know
I don't care you know it could be a
dirty read just get me something from
from anywhere I want the lowest latency
response and from a transactional
perspective we're not just a Tomic so
that a lot of these are the technologies
that are out there they're just atomic
in their operations we're actually
transactional and will operate on
multiple transactions with within what
we call a minor key space and I'll get
into the details of that but the bottom
line is I imagine you have multiple
documents it's most people are familiar
with the document terminology and you
wanted to update values across multiple
documents you can do that in some
contexts in a transactional way in our
system and if something goes wrong which
happens in these networked environments
will actually roll roll things back with
popular back mechanism which doesn't
exist any other technologies and the
rest of it is pretty pretty much the
same very plastic in a simple
administration all that stuff that you
are expecting from these technologies
easy to deploy in the local basis so one
of the things that we're also doing is
its Oracle so unlike some of the other
vendors that are out there we don't you
know all they have is their database
well we've got a whole stack of
technology and we're delivering
solutions not just delivering an
infrastructure technology and so we're
taking this no sequel database and
integrating with the other things that
people are using in Hadoop is the
obvious one and you know a lot a lot of
times you'll see
and no sequel in concert together in a
solution space but we're also
integrating it with things like Oracle
spatial and graph so if you need to do
art RDF analysis there's actually an
option where you can store all the RDF
inside the pork with no sequel database
instead of the Oracle database we have
an integration with the event processing
system so if you're familiar with an
esper that's kind of equivalent in the
Oracle stack Oracle event processing so
you can query on a window of time as the
data streaming across the network and on
all of the data that's that's been being
generated in those streams are being
stored inside the Oracle in sequel
database we have integrations with
coherence which is there caching
solution and the big box and the right
kind of really what it's saying there is
it this is comes out a couple of
different flavors so one is just like
everyone else it's a community edition
it's open source it's free and if you
want commercial support for it there's a
per server annual subscription support
so it's exactly the same is is is
everyone else it's out there but if you
happen to be one of those customers who
you know is trying to build something
super mission-critical and you want a
whole bunch of connectivity and bells
and whistles that gets you into the more
of a solution space or you want an
engineered system we have an enterprise
edition and so we actually announced a
month ago and quite a month ago the no
sequel now conference the big data
clients now can come as a no sequel
database appliance and so it's an
expandable hardware platform that goes
along with this expandable database
technology just keep adding more boxes
and it just keeps expanding out to
accommodate community it's available
Natalie yes yes both the community and
the Enterprise Edition they it's
actually been out since 2010 spending
developments in 2009 it's been in
production since 2011 with various
customers and is just increasing
Oracle's just been basically selling it
to its customer base it's not Oracle's
such a big company and it has such
strong relationships that it's not been
actively out marketing and selling it in
the way that you classically see like a
start about marketing and selling its
technology so it's it's been around for
a while it's not really new and it's and
it's fairly widely deployed at this
point does Cisco have a license Cisco
may I don't know the answer deaths just
commando license because we did a 300
node cluster test with Cisco on there
there was at UCS platform so there's
there some relationship there with Cisco
great numbers in that benchmark by the
way and that's it for those of you in
the room a 300 note test you know
there's a lot of people that talk about
that kind of scale with these
technologies and there's only a few of
them that are actually doing it right so
that's that's a pretty substantial test
so getting a little bit more technical
off-premise doing all the time here the
problem with this technology if you want
to call it a problem is is that in order
for it to be really really fast you know
it's it's a fairly simple structure and
imagine if you had a data is nothing but
a primary key going and looking up you
know a blob may be fast but you know
there's obviously some some issues that
go along with that well we mitigate some
of that because the
is a little bit more complicated than
just you know a digit right a uuid we
have some structure to it we have a
major component a minor component the
major component you know I want to talk
to people but disease think of it as a
tree pull the tree up out of the ground
and you've got the trunk of the tree
that's the major key and then you've got
all the branches that are coming off of
that major portion and then you get all
the leaves which the values right and so
the trunk is the major key that's what
we use to hash out to some particular
physical server and then the branches
are a structure that you can place on
the minor key and it's localized data to
that major key and it allows you to put
some expressiveness in there that you
can then get the values out with a
little bit more intelligence you can get
aggregations you can get ranges you can
do some interesting things but yet you
don't you don't have to have secondary
indexes to do that so it's really really
fast as efficient in the storage side
and and also you know people categorize
this this no sequel technology into
buckets like key value and document and
etc are even inventing new names for the
analysts or inventing new names for it
now because some of the vendors are
changing their storage types I think to
Sandra in the last year year and a half
they introduced a table structure so
that analysts felt like it needed a new
name or coming up with units so but the
bottom line is every one of these
technologies do the same thing now they
scale by moving it out to lots of
commodity boxes but the data is
spreading the data and how do you do
that to the hash partition every single
one of these are using a key hashing out
to a server somewhere it is a key and
the value or hey foot weather and so you
know we support JSON just you know we'll
call ourselves a document store but you
know we support JSON as a value type in
the database for binary types we support
as I told you graph operations so
already have triples are being stored
and we're also coming up with the table
storage structure and so when you look
at this in terms of housing you do data
modeling to develop an application you
know you you're gone how do I
translate this into a select from you
know where clause kind of you know how
do I kind of white query that and and
the way to think about it is again you
have these two components separated by
the hyphen a major key and a minor key
and the major key it it's a way to sort
of think of it is that that's the table
identifier that's the major space for
the data and and then you've got
qualifiers in there which will give you
sort of primary keys within that table
space and you can actually if you if you
create it the right way you can get
ordering in things like that even at
that level right so you can be range
based operations even up there but you
go down past the hyphen into the minor
key and you can you can put as many
components to this as you want whatever
your model looks like whatever hierarchy
makes sense you can split that those
keys out and then at the end of each of
those branches you have a value you have
a leaf to the tree basically and so in
this case we're talking about a subject
of sensors right so there's a pressure
sensor and here I'm saying well imagine
i'm doing a car crash test right and so
I I'm 4-door I'm BMW or somebody and I'm
doing crash tests and I wire sensors all
over the car so you could slice it up
into quadrants and stuff right here I
just put an LF to the left front you can
majan left front right front left rear
right rear or you know there could be a
hundred zones there and and then you go
down into will the specific pressure
sensor ID within that zone right and
then okay well that sensor is capable of
measuring not only psi but also
instantaneous rate of change alright so
you have different almost like columns
coming out in your table and then get
further those are samples are taken from
those sensors like you know every you
know 100 milliseconds or whatever it is
right so you've got tons of time stamps
of that data going on in there so you
model the key space
that way and that allows you to do
various queries you could basically do a
full table search if you if you were to
go up to the PS level or you could go
down my sections they give me all the
sensors in the right rear of the car
okay or you could say give me a specific
sensor by combining the section and the
ID and then you could do things like
will give me all the measures of a
particular like just give you the
instantaneous rate of change or you
could say now I want to know from from
200 milliseconds after impact to 500
milliseconds after impact what did my
instantaneous rate of change look alikes
you could actually get a time slice of
data ok and now how do you translate
that into sequel right because um yeah I
mean how would you know how do you stand
it I guess the real question is how do
you standardize that and and other
people are trying to do similar things
you see a lot of people doing time
series type analysis for example on no
sequel data stores is fairly common
these days how do you how do we start to
get some commonality there so that we're
not all speaking different languages and
that's where some of the work 'it's
that's been going on in the eclipselink
project has has started to ask some of
those questions then those are hard
questions and um and starting to you
know to bring out some potential
solutions
in that regard just a quick note on
Avril why outro why JSON I think you
guys are probably pretty aware that you
know it's becoming pervasive as the data
interchange format right so it's ending
up on all the html5 stuff and I think
that battle is done everybody is don't
even Adobe everyone is html5 is pretty
much the future right so JSON is
important from that perspective but but
also it's its storage format in the form
of a bro is really a highly efficient
storage format because you don't have to
duplicate in essence they think about
Java serialization all the class
information all that with every piece of
data you get it's really efficient a
schema representation that gets stored
is a simple integer and so it becomes
very very compact and it has a lot of
synergy with the do because it was
basically introduced in order to
compress them to the storage for people
who are trying to put semi-structured
data in to do also once you start
getting schema addition quick note
people talk about schema lists all the
time schema-less team let's do you know
as a no sequel guy up here I'm telling
you is the marketing hikers is just
unreal sometimes in this in our
technology space there's no really such
thing except text right and and even
that you know you it's worthless to you
until you put some structure on a logger
anything log records or unstructured you
know now there's a very definitive
structure there right and in data in
general it doesn't become very useful to
you until you understand what's the
words the value structure in there
that's your whole goal in life is to
figure out some structure so so once you
have you know a JSON and a virile type
of storage you have structure and now
you can start talking about versioning
and now you can start talking about
mitigating how it is that one client
deals with data versus another client
which are running different versions and
it adds a lot of power architectural
attempt to know something about that
schema and so for all those reasons you
know we are embracing an average type of
storage inside the Oracle
database and so as we transition into
what these guys are doing on in
eclipselink so when you abstract the
data modeling stuff that I was talking
about I I related the problem in terms
of queries right how is it that I form
an SQL statement to get at the data
because that's what people are so
customed to that in a relational world
but there's a whole nother level of
beyond that which is when you really
start getting into complex program
circuit into object modeling and you
start getting into you know inheritance
hierarchies and you start getting into
one-to-one relationships and one to many
relationships and yes those translating
tests to all operations but but they
really say something about the overall
connectivity of a model and and if you
could take in and ultimately that
connectivity imagine a one-to-many
relationship you guys know how you model
that in java rifle you know you're going
to have a list somewhere right the
government attribute which is the type
list of something right and so there's
no reason why that just can't be IDs
inside that list and then when you get
them into you do you need to ask the
database server to calculate a join to
do that I mean you've got the all the
IDS or right there right you most of
time you want to do lazy loading on
those kind of relationships anyway so
you don't you know you want to defer
that and so later on you you have all
the keys you just do to look up so there
even though these data needs new no
sequel databases are fairly rudimentary
in their data modeling they still lend
themselves to very very powerful
abstractions and and so there's no
reason why we can't take some of the
lessons that we learned in the past in
the relational space and how is it that
we abstract away from that relational
database and and pull it up a level so
we create more interesting more powerful
applications and and then you get all
the advantages of the transparency in
the relationship models that exist in
your java definite your class models
right so with that
to talk about how we're bringing some of
that power into yeah he's recording like
so my name's Todd Smith I'm morph also
and i work on clothes thing which is
source project at the close foundation
okay okay yeah and so we be need some
work not specifically at this point
about any particular no school database
in fact I'm trying to cover a lot of
them what we're trying to do but let me
sort of set the bar but I or start at a
higher level so how many people here are
using jpa or hibernate or public or
something so most okay so i might go
faster through these slides you have a
really detailed demo John listen me I
was a demo guy in the last talk so so
our problem this problem space we are
dressing here is what we call you know
java persistence so how do we take in
memory jab objects and put them in a sub
durable format whether that be
relational in the past or XML so you
know translating to have objects through
ajax be into context ml or JSON as we go
forward with like a json vine inspect
what we're looking at now is how do we
take java in memory java objects and map
that into no sequel databases so non
relational data stores essentially and
it turns out that in an eclipsing
project we had some code that we used to
have for interacting with non-relational
systems we called it enterprise
information system so mainframes
packaged apps through jca it turned out
when we started thinking about
interacting with no sequel databases we
realized it's very similar what we did
in the past and finally funny thing was
that technology head sat on the shelf is
a PC noti'm the framework with lots of
options also features those features no
talked about for years took them out the
slides never talked about them and
suddenly it was like hot again right
like oh
well Dennis towards something with a hot
topic so we went back into that code
base brought it back and I guess we've
rebranded it as Eclipse ain't no sequel
so we're coming in from a jpay
backgrounds the J pace back is
relational spec we're trying to take a
we're trying to see how far we can go
with a jpa style API for interacting
with no sequel databases so jpa if you
don't know you know it's a common
standard that was arrived at by the
meeting of the minds of the Poggio
persistence community have another java
ee five time frame i was hard to have
any five who works in java SE to have an
ee it really is quite popular at this
point now we're revision 2.1 just
shipped in java ee 7 so it's pretty
mature at this point standards covers
most of the major features that people
are looking for and the basic idea with
jpa and unfortunately that slides a
little bit less clear for you than is
for me on my screen here the idea is you
have java classes you have some sort of
database and you have mapping metadata
so here's a metadata that describes how
do those classes map to the table
structures and back and forth right so
it's bi-directional so wrapping and
really that that mapping metadata is
picked up at runtime by a jpay provider
which is like eclipse link in my case
and it does the reading and writing and
since between your application and jdbc
driver and move data back and forth it
gives you the abstraction of dealing
with java objects when really you're
pulling in relational data including it
and putting it back or creating new data
so it's nice it's nice standard it's
very simple as a very narrow API has a
rich query language and which is a great
thing for for JP because no sleep o our
sequel databases have a rich free
language in their map together I will
see that's a bit of a challenge for us
going forward into no sequel space so
the cleansing project specifically the
thing I work on it was actually created
by oracle open sourcing toppling so we
took all the toppling code the test
Suites everything went out there was no
secret go fast bits that Oracle put you
know in the
pocket and puts into a Blodgett that's
not true we just everything's open
source you can see all our guys working
open source we implemented JP a 20
references entation we provide the JP 21
that's just shipped in glassfish for and
beyond the standard sort of the spec
alludes to the possibility that is
something API round l2 caching or
caching we have a very sophisticated and
mature caching infrastructure so
flustered caching l2 caching is a lot of
caching functionality in there which
actually i'll show you how that's going
to be an advantage to you and we also
actually have a JAX p22 implementation
which is called moxie and that sounds a
bit strange what we discovered was if
you've got our mouth a high-performance
mapping engine mapping from java objects
to flat relational structures could also
let you map from java objects to xml
structures hierarchical xml or even JSON
and now I'm of course going forward to
no sequel structures also there's one
more feature here called JP RS not going
to talk about it it's a bit of an aside
but we're going to have in the demo and
you'll see the sort of advantages of
once you start using standard java api
zor near as you can get you can leverage
that to your advantage by integration
with other frameworks and then we'll see
that in the demo so what JP RS does is
it simply lets us take java persistence
units and expose them via rest so
without any coding with eclipselink GPRS
and if you I'm repeating myself then you
our talk on Tuesday but if you weren't
there this is like the five second
version if you have persistence you did
you give it a war you drop a little web
fragmented into your war you deploy and
boom you've got rest services right no
code you can get put our entities we
generate resource mappings with links
and you can look it up Google except
thinking of Eclipse linked JP RS and you
can fight web page some examples we'll
see it in here but it's basically a sort
of a 0 code way to quickly get your data
onto the to arrest for clients so what
happens is when you make an HTTP call
you're looking for Satan voice number 4
and your accounting persistence unit the
URI sort of
encodes what you looking for so you say
well in this case here i'm looking for
accounting invoice jax-rs Maps
everything from so the persistence path
here over to us we take that and say oh
you're looking for accounting
information we figure out which
persistence unit that is which is a
collection of objects and we find the
objects looking for and we can go and
fetch that for you so it also is very
simple way of navigating down from a
very general API down to this data
you're looking for and then into jpa so
that's great and what's nice about it is
j pers this is kind of my point which we
get to the demo GPRS sits on top of
eclipselink in a sense that it's a it's
a layer on top between the backend JP a
sort of component and the front end and
so you'll see the advantage of this in a
second here but we're told looking at
here today as a jpa style API for fresno
sequel so let's go here i will go
forward hicks were a bit shorter on time
but the caching means a diffusing JP RS
you're using rats to get the data the
casting applies clustered caching scales
up quite quite nicely okay I'm going to
go forward to the the meat of it okay
enough aside so we looked at adding JP a
style API to interact with no sequel
databases and of course there's a number
of issues right so there's no common
style or structure types right so Robert
said you got graph databases you got key
value stores call nor databases document
databases all over the place right not
like relational then you're done right
is that there's more than one type some
of them have career languages some don't
that's a bit of challenge because we're
used to write in gdq all queries to
create databases and you know what what
can we do with databases that don't have
career languages there are no real
standards I don't know there any other
any standards of any kind I don't know
anyone
okay nothing right no standards it's
early right that's the thing it's early
this is why this is kind of interesting
it's early work or trying some stuff out
there are no standards so what do we do
what can we do and every database has a
different driver API and I know that the
Mongol guys have talked and about this
and everyone has their own API my try to
make it as good as possible that they
can't possibly can as expressive as they
can but it's their API right so if your
developer working on those sequel you to
learn that product and then you get to
learn that other product if you ever
decide to change it's a huge investment
so there's like zero probability right
like it's you're buying in so this is
probably the case way back in relational
right you new post crafts or you know
ingress or in whatever so what we've
done the clips link is again JP style
access we're trying to use our non
relational data stored data storage
support we use to have we go through jca
or we go through jdbc visit JDBC driver
I which some do and we've done is we
just simply added a few annotations a
few bits of metadata to help us really
sort of identify jpay entities that
we're going to be CAD story no sequel as
compared to relational so we had an ad
no sequel annotation and there's XML for
this too so you don't have to either my
vacations but you put at no sequel that
tells us this object is not relational
keep key feature we took this approach
of not trying to make every no sequel
database look the same so if a database
has a feature we will use it so if
there's a query language we will try and
map JP ql2 that language we've done
there's a couple of times we did it with
coherence which isn't really a no sequel
database but similar idea data grid we
map j PQ el to their career framework
we've mapped JP q l into mongos query
language if it's there we've got it the
database doesn't have a career language
well then you can't use jpq out because
it's just no query language so we're not
trying to add value we're trying to let
people get to the technical leverage
technology that you've invested in each
selected easily so initially as you can
see we started off with MongoDB and
Oracle
sequel ya know this is just this this
will be packaged an ear or war and then
you're going to detect through jca or
whatever so this is self is not the
source adapter
opposed no sequel yeah okay John will
get that gets that good question okay so
just in terms of jpa some things make
sense something some things do not make
any sense at all all right this is kind
of the problem for JP that's why it's
not really jpa is JP a style right so
persistent entities make sense
embeddable the idea of aggregation
that's very common in fact in the sequel
element collections are collections of
embeddable again make sense a one-to-one
relationship even won the mini these
things do map perfectly well too no
sequel career language queries may make
sense may not depends and some things
don't make any sense right like so what
collection table anything to the tables
and columns it really doesn't make any
sense so you know parts of the jpa spec
that don't apply at all some things
actually are surprisingly
straightforward at generator which is a
way of manufacturing primary keys can
make sense if the database is giving you
a HemoCue manufacturing we can map right
to it so there's some things that make
sense and some things don't and this is
kind of the challenge for us with jpa
we're not suggesting jpa should be a no
sequel database interface but the style
the question is as an experiment here
are the as a framework is it working for
us ok so there's let me get this over to
John we're gonna talk about oracle no
sequel support specifically and some of
the challenges so let's say we've worked
with MongoDB Oracle no sequel they're
quite different one being document I
won't be key value and then as we dug
deeper there's a lot more richness it's
not just simply key values that were
like oh like you say a brewski everone
complex key so there's a lot more going
on than initially we thought so there's
a lot more work here so I'll let John
talked about this and this is work sorry
this is where he's me work it's in
progress so you're getting like you know
he'll be showing you code that's working
today so no guarantees right stuff out
work on hospice yeah
so cross your fingers for demo yes you
I'm doing you thought oh there you know
I think I wrote I broke it
now I don't know I don't know you'll see
this very well I think you'll be okay
giant funds right time Fox thanks all
right everyone I'm a engineer on top
Lincoln eclipselink the G engineer with
this the person they've been having a
try to decipher we need to do here so
I'm going to discuss this in terms of
the challenges we faced and kind of just
dive into the code and give a demo and
you guys have questions feel free to
jump in at any point the major
challenges we faced is you know how to
handle major keys you know Robert talked
about that it's it's two things it's a
way too hard to partition data and it's
also way to identify it so doesn't fit
in with the traditional primary key
paradigm we have a relational where I
have a column I have a name I have a
constraint the other thing which is very
important is a bro the Oracle no sequel
team is invested a lot of effort and
time and supporting it and it's very
good fit for those that need a document
based database you know when they're
working with Jake's on and things like
that um native keep native minor key
support this is just you know dealing
with serialization to native binary
arrays and warpless equal and then of
course squaring so that would be jpq
Olin what can we support I'm going to
start with the web demo just show you
what I have and that will hopefully
describe the kind of domain model and
what we're doing with the annotations of
metadata but we have a very simple demo
here and it's basically an auction you
know sorry domain malls we have an
auction bids we have users
now I'm going to go into Eclipse so
major keys I have this text file here
just to kind of describe what a major
key would look like so we have an
auction you know we want to partition it
based on some kind of identifiers so
we're saying all of our options go in
auc need a way to identify it just using
integers armed with bids same thing we
have a bit big key value store we want
to on partition them by auction so for
every auction we're going to have
another part of the major key where we
can group them together and if you could
extrapolate this to large data sets you
can see I would be nice to partition
things that belong together with on the
same node in the cluster now as I
mentioned with jpa you know you map
primary keys or IDs with with columns
and things like that but it's just not
applicable in this case so we've
introduced this idea of a key index
because really you're specifying and
index in that in a major key path that
you want to map is this ID so an auction
we have one key index it's pretty simple
and bed as you know we've partitioned it
by auction ID and by bid ID so this is
where the index part of it comes into
play and the nice thing about that is i
can query on it so here i have a query
called you know find auction by ID or
five bids by auction ID and as you can
see because I've been able to map this
major key part I can then query on just
the auction ID and get all the bits back
associated with it so that's kind of
what we've done to support major keys um
the other thing I mentioned which is
Avro which is very important to a lot of
people for a lot of reasons um for those
of you not familiar i'm just going to
give a quick overview of what one of
those schemas looks like so now tomorrow
i can define just with json itself
basically the structure of a JSON
document i can define types default
values you know i get validation on with
a bro i can also do nested records so if
you're you know one of the big things
with the this equals data aggregation
you want to write as much as possible
one row um and then the other thing you
get out of it is scheme evolution so as
I add new fields and things over time i
can define new schemas and I can do
what's called evolving them so I can
still read data through my old schemas
um and yet still kind of move forward
with new schemas so we've introduced
this idea of annotating an entity is a
fro right what does that mean well in
your average schema you specify a name
space so you need a way to identify it
um you know in traditional jpa fashion
we're going to have some defaulting
behavior so if you haven't specified a
namespace we're going to just use the
fully qualified class name the other
thing is a schema path now like I said
you know people will evolve their schema
so you may have many different versions
of schemas and you may want to read your
jpn and ease through a specific version
so you can include and packages schema
and use that if not we're going to go to
the data source in this case being
horribleness sequel and we're going to
load the most current version of the
schema so you really don't need to do
much more than just annotate it as at
Avro if you're happy with the defaults
and what this means is aside from your
major keys which are seemed to be mapped
into the major key set everything that
you're mapping inside is assumed to be
mapped within that ever document so by
doing that I can just not this just like
a regular JP entity and effectively
mapping that average schema now there
are some cases where you would want to
store things and in minor keys natively
and not use our schemas a good example
would be binary data so for every
auction I have an image um you know
writing out binary data inside of an
avid occu- be efficient on would let me
take advantage of
you know Oracle's no sequel support for
handling large binary data so I'm at
this as a native minor key so without
avro everything in here just gets mapped
as a native minor key and because we're
using gapa and we have this concept of
associations you know we can do some fun
stuff with effectively joining from
minor key to minor key or even from
something inside of an avid document to
something inside of a minor key
someplace else so here we've mapped mark
image as a one to one we're using a
field called image inside of the average
document arm and then we're joining
across to a minor key in another place
and you know j'ai pas grey has a lazy
loading so um you know the fetch type is
lazy that means that I'm never going to
load the image until I actually access
it so that join if you will will never
happen until I try to get hold of that
image for the first time um querying you
know we talked about that you know by
being able to map major keys i can do
queries based on major keys um you know
we had the ability to do kind of read
all queries and select one queries and
few things the the essence of that is
anything that or panoz sequel supports
and it's querying with ranges and you
know select queries you know we can
support and support that through jpq Oh
so as i mentioned i have this running
demo you know as we can see i'm loading
images this is all being done to JP RS
which which sean talked about earlier
and because you know I've done my
mapping and it's all kind of done
through java persistence i can treat
this as if it's just another jpa
application i can use JP RS so my wet my
love application here is just built
using HTML jquery Twitter bootstrap up
and nothing fancy and I'm just making
rest calls back to JP RS to give you an
idea what that looks like um you know I
have my chrome advanced restaurant
client here and this is the root for on
JP RS on the server so we have a nice
metadata API where I can kind of start
inspecting you know what rest api is
available so here i can see that i have
a persistence unit named auction so take
a look at that and i can see my
different entity types right let's take
a look at auction
and here i can see the structure you
know it probably looks a lot like my my
average structure and this is really
just drive from you know the structure
of the ND um it's been a scope but i
actually have the weight a way to map
and shape the json produced by Kennedy's
as well so I can exclude things or
transform things you know i can see that
i have effectively the same API i would
have on the ND manager kind of reoch
spreche taz rest operations so get put
post bleep persist create merge just
like the ND manager and then i can see
the queries i have so let's hit one of
these queries so this is auctioned on
this is just a final / a for auction and
as you can see I get back my JSON kinda
in a way that it would look like my
editing and over end of the server
console you don't see sequel you see
operations yes yeah and so here you can
see with relationships this is one of
the more powerful features is do you
know we're not going to read the whole
world we're going to treat things lazily
so we kind of snip the relationships you
know in this case the one-to-one we have
to image out and then we give you
another rest endpoint that you can hit
and load that whenever you need it arm
not going to hit it because it's a large
binary object and it's going to crash
home but that's the story and that Sean
was saying if we go back over to log and
this is quite chatty you can see that
we're you know just doing adapter
operations directly into the Oracle nest
sequel API nothing too special so so the
the classes look like jpa classes the
two extra finally annotations
application code looks like JP
application code any manager factory any
managers get in you'll get query as he
queries and then the the fact that it is
JK means layered frameworks like JP RS
just work
so that's the advantage of course of
mapping from his non-relational space
into us of a standard flavor of API it
means that it's compatible other
framework so there's a huge advantage
here for so the ecosystem of Java EE
another kind of random thing you can
even map embeddable data so aggregate
data within your Abra document a good
example would be a user has an address
you know it's marked as an embeddable we
have a dress and it's just assume that
that's not within the the average
occupant because it's been declared
within an entity that's macabre so
that's about all i have i guess i'll be
floor to questions and feel free to ask
anyone up here yep
there are different notes
differently the state's at a time
whatever the Oracle no sequel fine NP i
tells us yeah so I I think what you're
asking me is you know what you get a
consistent read from that from the
database depending on what the state is
from the different notes in the store
yeah okay so um so that actually would
go one step one step beyond what has
been talking about here but in essence
you can set default durability and
consistency policies for the date for
the database store overall and then you
can override those on operational
operation basis so more than likely you
set up the common configuration is that
you you set up so that you want
durability you want things to right
through to to at least the Masters disk
and some majorities memories but or some
majority of replicas memory space and
from a read perspective you want to read
from it from any node in the system and
that's typically how you set it up as a
store default but you can change it on
operational operation basis that makes
sense and so the way that we exposed in
Eclipse think would be a curry hit so we
have a way to pass hint into a crate you
say I wouldn't want to run a query and
meets the durability to the policies I
want to apply that's typically the way
we can approach that
yes supporters in JP is
yeah just your standard you know any
manager API I mean that's totally yeah
we got fancy yeah but yes try to get
everything in you know which i think is
caching yeah so every piece of caching
that you have in eclipselink today is
applicable here as well and you have all
the fine tuning and things that you can
do with caching there
lenses of the nest and
get flat file from the mainframe there
which is lots of rose blossom this
happen if we were to use something like
that with those files it would it would
depend depend on what you're trying to
get out of it by moving it from that one
format and storage to the other it um
you know if you're just if you fear for
processing framework that's kind of file
structure aware and you're just trying
to find a more flexible way efficient
way to take parallel lies access to it
they need to store the file because we
have we have a special law of API that
binary object a file will split it up
into chunks and we parallelize it out
into all the commodity servers and on
read it just it looks like a string we
actually in parallel will pull the
chunks back up and it just it's a stream
for you you can pause it it can restart
it and so there's some efficiencies in
storing and loading large binary objects
in that regard but if what you are
really trying to do is to impart some
structure to it so you didn't have to
load the whole file that you wanted to
be able to load pieces of the file and
all that then you could trick you could
do a translation of that structure as
you just described into a key space and
store those values underneath that key
space structure in which case now you've
got you know you've got freeform access
to different elements of data what they
do now
2 chainz yeah comes every night they
loaded into that and then it just hours
and hours of peel sequel code going
through each row and updating basis what
comes in yeah they have to date these
yeah
just wondering honestly you run out of
life
right put that it may be it yeah maybe a
good a good use case where we can can
take a side conversation talking about
sure
so I
as much an earlier this is code I wrote
last week so this is kind of the the
very tip of things I mean I will
eventually be in the product but it's
just a question of scheduling and when
but hopefully in the very near future um
it's undetermined at this point yeah
closely has regular basis as code hasn't
made it in yeah but but there is a
version of no sequel database
compatibility that is an eclipse link it
yes if you download it's there and it
will work against oracles of our
database MongoDB just doesn't have all
of the things yeah like fancy multi
multi he stuff that's new but in md any
of our stuff isn't there either yeah
yeah but that there is something you
could give a shot today you all of you
face I see you got a job yeah just down
the jar and Oracle no sequel yeah I'm
Northland which is which is a jar yeah
punjab de by DT yeah yeah yeah the whole
server everything is Java
oh you can actually do a dual
persistence unit that has has a
connectivity to both sides because it
from it from an object perspective
they're just all objects but some of
those can actually be backed by the
relational database and some can be back
within this you do is we call it
polyglot persistence but yeah it's one
of our things is you can use eclipselink
to work with both your relational and
non-relational database and to some
extent compose persistence units that
both these both datos visit is it so if
you go to the club slank website and you
go to the examples the git repo there is
an example of doing polyglot persistence
between relational on mouth and nose to
you all yeah give the idea yeah yes yeah
this this actually does not reply like
JTA or even ja ve so it would work on
Tom category yep
one point 16 probably 11 sites you have
a 80 Jenna eh well left Linda but this
is this is my life right here is not
good aspect I this is not spam this is
yeah at this point and then we had a
panel actually bought this week of
hibernate guys and I you know like how
do we deal with no sequel because
there's no right answer at this point
right so we're going to trying to feel
it out so if you try it out and go you
know this part works you know really
needs this feature like I say I had no
idea about the aggro stuff until you've
gotten deeper but as Creek its key so we
don't know until you look and so if
you're trying these out you can say you
really need to look at this this space
yeah we would love everyone sweetness
it's far too early in this attic
Christina standard any kind we're just
trying stuff out right now see what
works yeah what's up okay understand
charge of that sir job yes yeah not all
not all the Nestle databases will but we
actually will respect the transactional
so I mean we have the concept of ND
manager-level transactions and that just
means we're going to group changes
together to be persisted at one time and
the transactional semantics really
depend on the underlying database all we
guarantee is will write on all those
changes at once when you call commit and
you do see strange things so sorry
talking about Mongo but some of our
forms complaining they would write and
commit transaction d'mongo and read it
back and didn't contain their change
it's because eventually consistent you
know eventually it's in sort of a sink
right you know if you wait long enough
it's there so you have to know this
right but ok the world has changed its
not relational committed it's safe I can
read it back you kind of have to know
what you're doing yeah you know ok I
think we're out of time cool all right
thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>