<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Deploying Cloud Native Applications: VMs, Containers, or Functions? | Coder Coacher - Coaching Coders</title><meta content="Deploying Cloud Native Applications: VMs, Containers, or Functions? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Deploying Cloud Native Applications: VMs, Containers, or Functions?</b></h2><h5 class="post__date">2017-07-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gWS_P5YYW80" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">later so thanks for coming it's the end
of the day I'm sure you're all worn out
my name is Shawn Smith I'm a product
manager with Oracle and in the cloud
team and I will talk about deploying
cloud native applications and
specifically about where to deploy them
you know the cloud is a big thing the
different options you have and there's
more than one choice and so there are
like well I've divided the world up into
three three chunks here like where can
you deploy your your cloud native
applications so this should be pretty
familiar to people you've got virtual
machines right you deploy to virtual
machines pretty easy to go to any cloud
provider and get a virtual machine all
right I mean it's it's compute
networking storage it's a machine
and we've all seen this for years right
we had VMware we've had VirtualBox on
your desktop it looks the same after
that you've got containers and I've also
put a pads or application platform as a
service and I realize that this is
actually quite a few shades of grey in
between those two things I kind of put
them together for now and I'll point out
as we go sort of difference between just
pure container services and application
platform as a service providers but
really it's it's virtualization of that
machine right into a smaller smaller
level so taking a big machine slicing
the smaller chunks virtualizing the CPU
memory all the things that you would get
in a virtual machine but in a smaller
package and a lot of people will think
of this as synonymously with docker and
I'm guilty of this too I will kind of
use doctor you know that got docker on
the brain so it's not just
virtualization I would say that when
we're using containers people are
thinking about more than just raw
containers are thinking about packaging
your applications in this of docker
format which is really include you know
a file that contains your your code you
deploy in a container so the idea of a
container image so those are kind of
related things and the last I think
functions which I think people become
very aware of because it's things like
Amazon lambda right so functions or
server lists and really it's under the
covers functions are built on containers
typically so this is the idea that
rather than having your application
sitting there running all the time
logically it runs just when it needs to
the handler
it comes in from you probably on an
event-based so some some event fires you
call the service system spins up your
application to handle the request and
shuts it down that's logically what
happens probably it doesn't do that
there's lots of cooling going on all
kinds of stuff but in the reason that
it's thought of this way is because
you're only paying for that service
while that code is running so one when
your code is idle not having services
you're not paying for it so this is kind
of a way of paying for just the amount
of processing you need but it's it's
it's a refinement or a finer grained
version of containers into in some sense
so some examples of these these
platforms virtual machines we all know
AWS right Amazon as your Oracle cloud
has them IBM we've all got them
everyone's got them right where you go
that's the basic unit of measure right
virtual machines I'm a container side
there's a lot of toys so in terms of
container services IBM bluemix does
offer just containers Oracle container
cloud service itself is a container
based platform on the APIs or
application platform as a service sales
forces Heroku is probably the most well
known this cloud foundry I actually work
on the Oracle application container Kyle
which is another a pads platform so
they're pretty common - and they're all
kind of similar to a large degree and
actually part of the talk we'll see why
they're kind of similar they're all
meeting a certain need and lastly on the
function side there's actually quite a
few functions and either existing now
we're coming soon Amazon lambda this
Apache Open whisk that IBM is kind of
backing Microsoft functions and Oracle
function so there's a lot of this going
on so there's a lot of choice and
there's commercial products out there
Open whisk is an open-source framework I
try to download and run it in vagrant
and there's all kind stuff I had some
troubles so right now I don't know
there's a good open source solution but
I think open risk is you donate money
game is called these few things but I
couldn't find anything beyond that so
those are the platforms the question is
you know what is a cloud native
application so is anyone a building what
they call what they consider can convert
all the building cloud native today no
yes one not too many okay so the
question is what is a cloud native so
what I decided to do for this talk
anyway is talk about 12 factor apps
anyone familiar with 12 factor
too much okay so twelve factor app you
go to twelve factor net you'll find a
descriptive justice webpage here's a
screenshot
the guys from Haru ku the team from
Heroku tried to introspect what did they
do how do they build haru-kun what like
what how do you do how did they write
their application to run on Heroku and
they wrote basically what they were
trying to do I think like a pattern
language but it's really it's more of a
manifesto almost or set of principle so
the set of principles describe how to
build an application for the cloud and
how to make it scalable and reliable and
so on so forth so it's called twelve
factor because they have twelve all
right they can't with twelve things so
I've just grabbed the names here and
there they're one-line brief synopsis of
what those features are what I'm going
to do is I'm going to go through these
12 factors say this is if we assume this
is our definition of cloud native we'll
take this for this for this case of this
discussion if these are the 12
principles of what's cloud native let's
go through these and see how those
target platforms implement or support
these principles other words if this is
what cloud native is can I do this on a
VM can I do it on a containers can I do
it in functions this is kind of the this
is what I'm going to try and do today
we'll see if this works so the first
principle is code base and some of these
are kind of motherhood apple pie kind of
stuff you probably know it's not
necessarily cloud native but they said
this is an important important point
which is you should have one code base
one git repo one subversion repository
all your codes in one place and you will
build it and deploy that build to
different environments so you get a
build you deploy to testing develop
environment to prod optimally the notion
being that those same bits that you're
testing is in development and then tests
to go to prod are unchanged all right so
once you know they're working in tests
or in staging then go to prod they
should continue to work all right no
changes whatsoever the same binary if
you've got their argument is if you've
got multiple git repos you've got a
cluster you've got you've got a set of
services you don't have one you have you
have a set so not unreasonably have set
those services but every single
individual application should have one
code base and we'll sort of see how this
sort of builds up this actually is an
underlying principle that
it underlies a number of other
principles of book we'll get to here in
a second so this to me is probably one
of the biggest and most important thing
which is dependencies applications
should declare and isolate their
dependencies in other words everything
this out your application your code
needs needs to be explicitly stated and
the reason we want to do this is because
two things one if you deploy
applications into an environment we can
say eh the environment does not meet
your requirements that's the first
possible use of this the second thing is
that if you are stating what your
requirements are it could be that your
requirements are automatically
provisioned for you in that environment
all right so it's really important to
explicitly declare this the the first
line talks about system-wide packages so
if you're deploying to a Linux
environment say don't assume something
is installed
I don't assume that the latest version
of curls install you call out to it
probably isn't there you have to build
applications where your code knows
exactly what it needs and you're stating
it very explicitly now let me just so
step through the stack of an application
so here's your code right this is your
binary this is this is the thing you
wrote below that you've got your library
so you might be using in Java Jackson
you know log4j whatever lodash in node
and the nice thing is if you're building
applications this isn't that hard right
today we've got all kinds of dependency
mechanisms within our programming
language frameworks right so you've got
gate Gradle you've got NPM rubygems and
so on so we have frameworks on top of
the languages to let us declare our
dependencies so when I'm building an
application it's very easy for me to
using maven for example I can say these
are my dependencies the code compiles I
can gather all those dependencies and
actually build a bundle binary bundle
contains my app and all my dependencies
completely self-contained it's
straightforward to do the same with node
with NPM is very easy to do so this is
the key thing so this is easy to do
you've got libraries it's easy to
declare them and gather them together
below that might be a container so
you're building some sort of web service
you're probably going to run either in a
container or use an embedded container
like embedded tomcat jetty grizzly
Jersey and node
might be using express your code you
know your writing your code and you want
your code to be called to your building
the CRS service well who's propagating
the call into your code right there's
some sort of container if you haven't
looked at the embedded containers and
this is a big thing in cloud native I've
been using things like an embedded comm
cat which rather than you have Tom can
you deploy your code into it your code
actually says new instance of Tomcat
first thing it does is instantiate the
Tomcat instance and then tells Tomcat
listen on this port and here's my here's
the code I want you to run so it's kind
of like you've embedded Tomcat in your
app as part of it it's in the MS in the
user space simply to the program space
and that's much more lightweight the
smallest app I've had with embed Tomcat
on five Meg sort of your your basic like
hello world so it's pretty good anyway
so the applications that libraries you
got your runtime language right so you
have a node whatnot and then you got
your operating system at the bottom this
is what you need to run your app so the
question is of those three targets were
deploying into how much of that is
covered for you how much do you have to
do to provide the stack or what of it
what if this stack is provided for you
by these these environments so the first
off will be functions and I think I
asked me to change on a slide later I
think I've raised the bar so functions
cover if you deploying into say Amazon
lambda it's kind of put a typical
example the operating systems inside
there there's a language runtime cuz you
go to say I'm going to run a node
application the service itself is kind
of the container they they tell you you
implement an endpoint and we will call
your endpoint they're kind of interested
implicitly kind of like an application
container and then you can bundle your
application with the libraries you may
need some libraries are actually
included in within the environment but
you're only responsible for the top two
pieces everything else is taken care of
for you
so deploying your app means you don't
have a lot to do right get your app get
your dependencies it's all just going to
be there when you deploy your app into a
functional function of the platform
containers are a bit less typically and
this is a bit fuzzy in a container based
platform again thinking of a docker
environment you typically get the
operating system in the container the
language runtime you may actually get
the container so there are docker images
available with Tomcat embedded in them
already available for you there was a
rails there was a rails image
it's been deprecated it's just part of
Ruby so you can sort of it's a bit fuzzy
there but it covers quite a bit of what
you would need for your application and
then finally in sort of the VM it's a
bit sad but really on the VM you kind of
just get the operating system it's like
a blank slate like you know you install
Java you install a node yourself you
install whatever application container
you need and then all your libraries and
your application so basically this full
stack here you know the arrows here sort
of say that's all the work you have to
do in that kind of target to get your
app running so and it I really encourage
you to try these out if you go off and
try some of these services look at their
how to's and look at what it takes to
deploy an app and it's really amazing
how little you need to do let me look at
the functional examples there basically
you write a function you write a piece
of code you deploy that piece of code in
an application platform as a service
example you have a small little let's
say node application you bundle up and
basically upload it and it runs the code
right because all these bottom pieces
are provided for you so you can get code
running in minutes right in the VM case
you're going to be working a long time
before you get to even running your code
right because you're installing a lot of
pieces okay
let's move on so that's that's that's a
big topic it's really kind of important
the second piece here is config so
you've got this binary Bruce by your
single build right codebase says you
build a you build a single binary but
you're going to deploy it in two
different environments and that means
you're going to need to have different
configurations per environment so 12
factor says your application
configuration is separate managed
separately and distinctly from the end
of the application so don't check it
into version control don't have
configuration file to say if dev one if
prod if whatever I go to some frameworks
actually have support for these kinds of
things that's a bad idea because it
doesn't scale right you've got n
possible deployment environments they'll
have unique configuration so really the
configuration as part of is not part of
the application it plugs in and you need
it to run the application but it's
separate and anything like a config
means anything like environment
variables it could be the name of a
database you're talking to anything you
need this environments
specific should not be in the code
anywhere now here's a couple of
screenshots the top one is Amazon lambda
you'll see here that you're they're
allowing you to define the environment
so you create an instance of a function
you say I'm going to run this in my prod
environment and you can configure that
environment there so your code is
separate you've deployed the code but
this is you configuring which database
you're going to talk to right now on the
bottom this is my service application
container code it's the same right it's
like I'm going to go in and define what
some environment like the twitter ID I
want to I want to tweet as or a timeout
value what you see is in terms of the
function listen a function environment
or a may pass container platform they're
actually fairly similar you know that in
a VM world you're going to be basically
sponsible for creating some sort of
shell initialization populating the
environment area Buhl's writing a script
whatever it is what's kind of manual but
this is pretty common behavior and it's
it's it's nice to declare that we just
declare it and you for each environment
you can define a different set of
configuration there's also typically a
file you can write the similar but you'd
probably just upload it I want to
mention this one this before I move on
so summarizing some of this but this
notion number four here of backing
services if you're talking to other
services you want to treat them like you
want to create local and remote the same
the idea being that you should always
treat all of everything you talk to as
an attached service so we talking to a
database that's a local let's say my
sequel database and then you want to
move to a one that's provided by a cloud
provider or somewhere else
just want to change the config right you
don't want to have to repackage anything
it almost be just declarative like that
database I'm talking to is is that this
coordinates and that's how you should
treat everything everything is external
even other applications you may write
for yourself that you provide service to
yourself are you a micro services style
you should treat everything as some sort
of external resource you just basically
plug into and here's a couple of samples
there's a textual version this actually
there's a GUI for this too but example
of how you could just declare this so
here's an example on cloud of Cloud
Foundry on the right this is a part of
the manifest things my application I
have some service
is I need to be able to communicate to
test my sequel oh one right so you're
just declaring that the database you
would change this configuration file per
environmental course on the left you see
an equivalent thing for from application
container cloud where you actually
initially add what type of service it is
but they're basically the same so
everyone's got the same kind of approach
and this is in a container or
application platform as-a-service
approach where your application is
associated with this kind of
configuration info so I have a bit of a
cold so I'm going to have him a bit
sorry so so just to sort of summarize
that if you're you've got this
configuration you've got your program
what are you going to do well in a
virtual machine case it's your problem
right you're gonna have to try and take
that config and take that binary and
install it somewhere
if you scaled out and added more virtual
machines to a cluster it's on you to
basically propagate those that
configuration around right this is this
is basically it's roll-your-own right
this is full control in the the a path
and the function list there they're kind
of the same in that as you saw the UI
there or even the underlying files
there's a way to capture your your your
environmental config or even the backing
services that you need and then when you
attach it to the service if you had to
do things like add more containers of
scale at your application that these
platforms will typically propagate what
they do they just propagate the
configuration so you'll basically get
instances of your application just
created all perfectly identical note and
if you make a change to a configuration
that configuration will basically be
rolled out to all of them again so this
this is the kind of thing these
platforms offer right it's like managing
these configurations
so number five here and actually I do a
bit out of order I think so far it's
almost an order until I get to the end I
switch them a bit because it just makes
more sense principle 5 is build release
run and this sounds also very kind of
motherhood apple pie it's funny how the
she read these independently they all
seem like common sense when you put them
all together they form a reasonable sort
of pattern language the notion of build
release run is you will have a build it
will spit out a binary that binary is is
unchangeable right it's a right once it
never changes you never tweak it it's
built you take that application you
combine it with the config and they
determine that or release so when you
take the dev or the the test config and
the application put together deploy
you're deploying a release into
production or into an environment so
this release idea if you're if you have
an application running in production you
should be able to know what release it
is what config did I use
and what's the binary version right so
you can go a full traceability back to
hopefully if you if you deploy your
application you've added a few bits of
metadata like what get commit even the
built and what build number you have in
there you can go take a look and see
which build you've got running and you
can also take a look at the config so
this is a very simple approach and
actually if you look at this screenshot
here this is a this is from my service
and this is the deployment history is
basically the list of the history of the
releases so you see on the left the
version is the binary those cruised by
the build this is build 15 1 0 and on
the right you've seen these time-stamped
releases as the configuration was
modified and you made it you apply to
change that that configuration is being
tracked so you can go into and download
and take a look at and say we know what
did I what did I deploy Thursday you can
see what you had deployed Xen so you
have full traceability so that notion of
build release run is actually real fight
as a real thing in some of these
platforms so it's it's it's very useful
it's a nice simple model
now number six here processes that in a
cloud native environment what their what
the twelve factor says is that all your
applications are just one is a process
it's pretty sis terms seems overly
simple yes of course I will run my
applications a process but they're
saying that you want to process that
stateless but you want to raise the
stateless process where all the storage
all the persistence any kind of
procedures and data requirements are
pushed out somewhere else so for now if
I had a bunch of instances of the office
application all stateless they could be
talking to these backing stores so if
you had incoming traffic let's say your
this is your application it's some sort
of web or rest service you've got some
kind of incoming requests any of them
can handle it because the data is
outside right so I can I can easily
handle any incoming requests the data is
outside stateless it gives some nice
properties around scaling up and down
which we'll talk about
but stateless is the key thing here the
key word in this discussion of processes
so now that we've got these stateless
processes the notion here is that given
they are stateless share nothing it's
easy to scale alright so while I handle
more load I just add more of these
things right so they all talk to the
back-end database
you know I pop my applications popular
sometimes just scan it you know scale it
out I can scale out let's say this this
front web tier here to handle the amount
of load I'm getting it's pretty easy to
do what's nice about this model also is
that maybe I've got multiple tiers so
I've got multiple services so maybe this
web tier first here is talking to a
backing back-end processing tier I've
got a bunch of other processes which are
acting like attached resources they're
just some coordinate I talked to and
these guys are are also independently
scalable so I can scale out pieces of my
application so rather than the old days
where you're building heavy I shouldn't
say that I'm an Oracle guy right
heavyweight Java EE applications it's
like one big thing I can now take
different pieces like different
applications within that application
architecture and scale out the tiers
elastically as I need to because I got
these little stateless little disposable
little guys easy to spin up
it's an easy model alright so if this is
really really simple like they gone down
the atomic level then let's just make
some simple principles and combine them
to achieve complexity so this will
summarize these two so virtual machines
if you had say a cluster of virtual
machines and you want to scale like had
a whole bunch of processes your problem
is it's you're on your head to figure
out like manage those processes start
those processes even place the processes
where would I put my application so I
want to spin up a couple of instances of
Tomcat to serve my app well which word
they go right the other issue is another
issue you might encounter is processes
interfering with each other you know you
do things like you went to into the
Tomcat by default the booklets on 8080
and they're both what the second one
won't start so you have this problem of
they're both in the same environment so
that's again a problem for you to deal
with and if you are going to scale out a
number of processes you're going to have
to deal with routing traffic right load
balancing is an issue that you have to
start taking on for yourself if you're
talking about a container platformer or
even more specifically an application
platform as-a-service
kind of kind of platform it's not
required but typically is one process
per container so almost like they're
equal equal right so you're talking
about processes example containers so
it's easy to start up a container it's
fast these platforms will do container
placement you hear a lot about
kubernetes you hear a lot about mezzos
that's those kind of things they're
basically container placement
infrastructure so these kind of
platforms typically place your
containers where they need to go you
don't have to worry about where they go
because they're wrapped in containers
they're independent they don't interfere
with each other right they won't be on
the same ports it's all taken care of
and and it's kind of necessary like it's
almost like it's a given that you're
going to have a load balancer in these
in these platforms so a pads platforms
container platforms you're going to be
using a load balancer in most of the the
platforms you don't even notice it's
there so again if you fire up Heroku and
start scaling up or you fire up my
service scale it up you don't notice it
but there's a load balancer the tap is
handling routing traffic to all your
instances it's just sort of sunk in the
platform and the functions again are
kind of similar because functions are
really again a specialization of this
container platform right single
functions are running in a
single-process they're placed wherever
they're placed on some sort of computer
brecht it's not your problem
right again these are stateless these
functions take an input and then they do
some processing and then it is disposed
of they better be stateless because if
you're thinking you're storing States
somewhere for the next request it's not
going to work they're going to be killed
right or at least logically they're
going to be killed off and again of
course is load dancing but the functions
in the containers is kind of kind of
similar okay now I am just going to jump
to like nine because this makes sense
talk about here at disposability so if
you've got these stateless processes the
idea is it should be very easy to scale
down alright so if you have stateful
services and you want to scale in you
want to kill something well what about
the state that's in that running process
like that's a problem so by using that
stateless process model scaling in is
very easy now this is something you can
just do and in fact the pro notion of
stateless services is universal right
where it's on the via that part is is
the same same thing with suppose ability
so you're hoping that you know if I just
in a sig term to one of these processes
it's going to shut down gracefully close
any resources it has and go away there's
no need to back it out there's no need
to do any kind of worry about what what
state it's in so this is a nice process
nice a nice principle Oh awesome
graphics that I did and then port
binding talks about how you expose the
services and again this one's kind of
kind of a generic statement that your
applications just serve up it's its
service whatever is offering over some
kind of port right now it's in the
container space what you find is that
the environment or the platform tells
you what what portal listen on and the
issue is you've mentioned before right
needs a function case right you don't
even know where you're listening but
you're you're deploying your application
into a container it's being placed
across some kind of compute fabric and
somehow someone's talking to a load
balancer and talking to you somehow
right so what you find is if you use
docker you'll know they have its port
mapping we can say inside the container
your applications listening on port 8080
but traffic coming to containers coming
in on like 80 90 right so there's a
mapping
what happens is these container
platforms create a bunch of containers
put them in different ports but inside
the world you're in you think the
world's the same you hope you're
listening on this port they tell you
listen to you don't worry about what
you're listening to so it's more of a
this is kind of an architectural issue
where they're saying that your
application needs to be flexible enough
to just listen on whatever port you're
told to listen on because someone's are
coordinating all this port and all this
traffic to you so this is something
these application platforms and service
platforms do for you it's not something
that obviously it's going to happen for
you in the VM world you can have to do
this yourself keeping track reports and
keeping sure that all your application
processes are getting getting traffic
appropriately alright how are we doing
oh okay so this this principle dev prod
parody I I kept you know this one didn't
really first read this like start wall
to see sometime ago but when I read this
it didn't really jump out of me like
super important like yeah of course make
sense I want to keep my development
environment as similar as possible to my
production environment because when I
move between I want the application to
keep working right this is like you know
motherhood and apple pie so these guys
the team of Heroku who wrote the
principal said well we want a small time
gap we want to make it really easy to go
take it from my desk and have this thing
running in production the time between
development and production should be
small they kind of suggest that it's the
same people who are doing this of a
DevOps approach right so the tailor the
the personnel gap keep the team working
on this small say all understand what's
going on and then make the tools gaps
use the same tools same team runtime
stuff between environments and this all
sounds like it's perfectly reasonable
principle and then I realized that this
is actually that one of the major
driving forces you hear when you go to a
conferences and hear people talk about
docker they're going to actually use in
indirectly refer to this principle
because this was kept a head to the
differences here so jump to the middle
here docker what that value of docker
and what docker did was it said it can
take an application and all this
dependencies and the runtimes the
configuration everything you've got is
in this container and I can move from my
desktop I can hand it to the office guys
who can take it they don't have to worry
about oh you know which version of some
runtime library libraries in prod versus
top right maybe we have the same the
same package installed in that
environment of a different version so
some of these things don't work so
doctor said if we just basically make
everything Eclair ative and
self-contained we can move code between
environments so this idea that dev tests
and prod are similar or have parody is
actually sort of encapsulated in that
hold the whole raison d'etre of docker
right that's what they were trying to
achieve stop it so when I give it hand
off my code to the next team it doesn't
break so a she's quite it's quite quite
key so this is something that you see
with docker wrapping up your application
with its with its requirements and the
configuration is changes in configs are
externalized right and he passed them
into the container the function
environments are fairly similar but they
have such a constrained environment as
you saw an article today someone's
talking about developing for Amazon
lambda and they were complaining that
you know dev test Prato all in the cloud
and to doodad they have to keep
deploying this thing in the cloud
because it's great in that dev test pod
look identical because it's you know so
constrained the overcurrent chronic up
to some clever scheme to like
short-circuited and run some code local
you know try and be more productive but
this is actually a value right dev test
pod are looking pretty much identical
and the VM side this is the problem that
people were trying to deal with right
because this is your problem on VMs the
environment can vary and can break your
code is pretty hard to do it it's even
worse if you've got different teams
owning different environments right so
that notion that you have a small team
responsible a lot of corporate
environments you've got development
you've got operations you've got the QA
a team they all have their own
environment so testing code it may vary
you may get different results in
different environments so it's it's
error-prone so this principle of keeping
it the same has a really significant
significant differences in terms of
implementation just to just two more so
number 11 is logs and this is this again
this is a principle that I think is
independent of these architectures I
don't think any one one of them actually
solves the problem or addresses the
problem
or I should put this I don't think any
of them would not choose to do this
treat your event logs of streams and you
find this on VM is what our containers
stream your output put into a capture
those logs into external service and
then you can go digging through it as
necessary don't keep the logs on the
local VM don't keep them in some special
log file to stream them and send them
elsewhere alright so for a VM great if
you're in a container great it's all the
same right so everyone should be doing
this the one thing you do find is in the
application container platform services
and even the eventing services our
function services that were this has
happened this happen typically
automatically for you is nothing for you
to do but the notion is is pretty much
the same this is just good principle ok
and the last one this is an interesting
one I always have trouble with this one
I'm not sure I totally buy it but I can
see the value but it's a little bit odd
the notion that you want to be able to
run one-off jobs so let's say you've got
this binary your build produced you've
got this configuration ok I'm going to
deploy my app this principle says I want
to take that same binary and config and
kind of run something else like maybe
you're buying maybe your application has
different entry points maybe one of them
is something like migrate data or
something you know some other non
production tasks so you want to example
they give as migrating data which it
seems like a bad example but the idea
that you want to be able to use that
configuration and do some other admin
tasks so you've got the right binary you
got the right configuration right
database connections you want to run
some extra stuff and so I have had
people say to me yeah that's a good
feature I could use that I don't have a
strong support for this but it turns out
that obviously if you got a VM your apps
installing your configs install you log
into the VM run a job and it'll pick up
that environment you can do this
straightforward if you look at cloud
foundry and Heroku they have support for
this we can run a one-off job that's not
one of your cookie cutter like
replicated principal replicated
processes it's a special one it run the
list for a minute runs your little
special tasks and then it dies
so this is kind of esoteric I find and
so I I think they were kind of
describing for ruku rather than
necessarily cloud native so that's a
crash course in 12 factor apps and sort
of how they work on these platforms and
the question is you know what does this
all mean and what's the value of these
these twelve factor apps well we needed
it to try and help us figure out what
whether these platforms we're trying to
deploy to can support our cloud native
applications but I think that when
you're when you're picking these
platforms I think you have to ask a few
questions so I've got this application
yeah it conforms to these principles but
like what's really what's really the
trade-off between these different
platforms right and I think it's I sort
of summarized it in this sort of
completely non-scientific I made up this
chart it's like guys analysts would do
here's my chart of like control versus
productivity so it's a trade-off how
much control do you need so this is
software we can do anything right all of
these are the same in the sense that
they're computationally equivalent I can
do whatever it's a whole matter of how
much control do I want to have versus
how much productivity do I want to have
so if I need super fine-grained control
then I'm gonna get a virtual machine I'm
responsible for everything installing
the runtime installing the VM you know
everything is my problem but I get like
ultimate control I can do it everything
I want as you move towards the right
you're trading it off these environments
are to become more prescriptive more
constrained right so your codes being
stuck into a container the world is
being sealed around it
it's environments being injected it can
do things like listening on prescribed
ports you can do all these kinds of
things but I get a I get I have less
work to do right the function case is
even more on the productivity side and
it offers even even more practical in
that you can write a piece of code you
can go though typically in the web
console write some code and say apply
and like it runs but you get no control
like it's way down there like you're
basically if your code fits in that box
and that's great so so let me sort of
decide you know what would I what would
I use so yeah the virtual machine is out
like I am too lazy
for that I mean we've all been there
with all users for years and there's a
reason why these other platforms have
evolved because we just want to run our
code right so I want an environment
where I can declaratively say I want to
run this on node six nine one and here's
my app and here's my libraries and just
go right I want to scale it out it's all
very good so I can do that lose
containers I can do with the function
function on surplice platforms - the
only problem is as long as your code
fits in the functions model as long as
you have a fairly straightforward
application where you have essentially a
single entry point it's it's got a
function like behavior and it performs
some computation and then it quits right
so you're not going to run a WebSocket
chat server on functions because I don't
have long-running you know state I'm
going to have a conversational State or
connections to the client that's really
not a good fit so functions are really
cool if you fit into you know if you're
the if you're a round peg and that's a
round hole and that's good but a little
bit constrained so I would lean towards
the the container-based or preferably
the application platform as a service
which really orchestrates those
containers a little bit at offering me a
number of things like automatic load
balancing and that kind of stuff now I
showed Bruno who was here when ago
Bruno's on the organizers of the
conference and he's stuttering around
and I mentioned I showed Bruno these
slides he goes oh yeah did you see my
Twitter poll I'm like yeah I saw your
Twitter poll but might I remember the
results he goes oh yeah because he made
me look right so here's his Twitter poll
how do you prefer hisses actually not
this is actually funny he did this how
do you prefer to manage and deploy
microservices he says right so people
said do-it-yourself ruminated
infrastructure so it's a microservices
infrastructure its container base but
it's going to roll your own container as
a service like just a container service
the third one is basically application
platform as a service which is really
managed container service product and
then functions and so my choice was
containers our application platform
as-a-service who's kind of middle - so
if I add those together I kind of get
60% so again completely unscientific but
the world agrees with me that really
contains are really good but
exactly what micro-services it's not
quite the same thing although you know
iBM has a red book on microservices and
you crack it open and then you start
reading the first Czech section to go
what's the micro-service let's talk
about 12 factor apps that's exactly what
they say they just start listening 12
factors and sorry explain to you what
our microservices so there's a bit of
fuzziness
I don't think cloud native means
microservice but I'm going to take the
his results as kind of reasonably
indicative of the general trend I think
that containers are probably your best
containers and application platform
as-a-service are your best platform for
cloud native development they automate a
lot of what you're going to do make your
life easy if you can fit into the
functions world and that's that's even
more constrained but also more more
productive but for general purpose
computer I think this is where we're at
so and that is all I have and we have
five more minutes for our six so any
questions out that is like I'd like to
have poured like this info I scared you
oh okay
oh yeah it's fair enough so the so in
these platforms people do just spew the
standard out they do and they capture so
for your benefit yes you can you can
format something that you can then
process it makes sense you find that
they they will typically be
automatically tagged with so which
instance of like you know you have 12
instances which one of them produces
this log record timestamp it you know
this is a few other things you typically
see in the front of those each line but
really it's application specific and
it's true they just spew so it can be a
firehose right so what you tend to find
is in the small networks and then in the
large people are streaming these into
logging services right they're not
they're not keeping them even in the
platforms are on they're going somewhere
Oracle we have the log analytics
platform right we just spew all this
stuff up and then they go through and
they do so machine learning to try and
find weird patterns in your logs and
it's not for humans at that scale so the
data is good right
where do I put an elastic Beanstalk it's
funny because it's it's kind of like an
in-between because Beanstalk is it looks
like a container or looks like an
application platform of the service
product you deploy your app they just
don't go in containers they go in VMs
because Amazon has these teeny tiny VMs
right so they do have container support
so it's kind of a Paz II it's kind of
like that it's all you know it's it's
it's a weird product just because they
were able to leverage their
virtualization to give you this tiny
shape everyone else would use containers
I wouldn't I wouldn't say a server list
no it's not service because you're
running a full application in a VM right
so you can write whatever entry point
you might serve up whatever you want
write whatever you could listen on you
could set with XM keep XM t TP XM that's
alright anyway yes you can set up I Oh T
protocol servers on that one you do if
you want not just whatever Amazon lambda
takes you know so it's open it's just
general compute but yeah it is a bit of
a funny funny hard to categorize that
because it crosses lines yeah anywhere
else yeah
oh gosh I don't want for Google so what
do I think a Google Cloud I don't know
they're these they're awfully similar
like this is kind of what I'm saying
here is that there's these categories of
products and they all are so amazingly
similar so really when you when you say
to yourself okay I want to deploy to a
container I want to void contain
container oriented right you'll find
they all look similar they differ in
terms of certainly Oracle's percept
perspective is that you know we have
cloud services you want to talk to so
it's about the ecosystem so yeah you've
got containers but I have all my data in
an Oracle database I want to talk to
that or Big Data appliance or I have a I
want to integrate that with with ICS or
integration products right or so a cloud
service all these things can talk to
each other and so really when you're
picking a provider you're going to save
yourself Who am I talking to this is a
container thing I can put on Google
cloud I can deploy it on Amazon and
deploy anywhere because they're all kind
of similar but what are you talking to
because these things are just like
that's just a small piece right but
everything else ecosystem that you have
to be worried about so Google's about
their services Amazon's got some
services as your services Oracle's got
services so who do you want talk to
that's how I would probably pick yeah
you know snow okay well there's beer
wine and snacks in the section lounge
thanks very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>