<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Java EE 7 Batch Processing in the Real World | Coder Coacher - Coaching Coders</title><meta content="Java EE 7 Batch Processing in the Real World - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Java EE 7 Batch Processing in the Real World</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sOLcW957gwM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everyone welcome to this session
about batch Java e processing let me
start to thank everyone that's here we
didn't expect the full house so it's
quite overwhelming to have so many
people here and also to thank you for
coming so early in the morning at 30 so
it's quite quite awesome thank you so
much by the way so who's first Java one
here this year well I'll call it quite a
few are you enjoying Java one right so
hopefully we can deliver a good session
for you guys so you can make your time
so if the atomic very it worse anyway
I'm gonna just start it out and thank
you so much for coming anyway so my name
is Roberta Cortes I'm actually from
Venezuela but I live in Portugal for
many years I do work as a freelance for
like the last couple of years and but
I've been working all my life on sectors
like finance and insurance and health
and government as well so it's quite
natural that a lot of my work is being
done using Java EE technologies and as
you probably guess stuff on finance and
insurance sectors use a lot of batch so
I do work a lot with bad stuff I'm not
an expert on JCP stuff or belong to the
to the expert group but I don't think I
have what some knowledge on the matter
since I use it so much on my daily
projects other than that hi to start my
own speaking career a couple of months
ago so it's also it's my first time here
on Java one but this is my first time as
an attendee or as a speaker I mean I'm
also a rebel of our other noise you know
rebel ops bulk blog but if you don't
know it just search it if there's some
very interesting articles and I do have
my own blog that I just write random
stuff about technology okay so hey
everybody my name is Yvonne and I work
for it
it was Bulgaria in my spare time I'm a
JBoss Forge contributor and I'm also
driving the adopt openjdk initiative in
our Juke in Bulgaria so anyway we want
to make this a little bit interactive so
instead of like saving questions for the
end if you have any question in the
middle of the presentation feel free to
raise your hand and try to grab our
attention
I usually don't see very far because my
eyes are very bad so try to like send me
from your shoe or a phone or whatever
just to grab my attention or Yvonne so
we're just gonna see how this work out
but still if you have any question just
interrupt us and do it then we try to
adjust to whatever question you're
trying to make okay so this session is
so much right and what is bad if you
search Google you'll find that but is
processing a group of Records that
usually as one unit usually without ever
requesting user input so let's see batch
is not only in the computer science
engine in the industry it's also in our
real life so let's see what we have in
our life so in our in our real lives I
mean you probably heard about this
phrase before
have you ever heard about I'm gonna make
a batch of cookies have you heard this
expression before so don't be shy come
on I mean right so when you're going to
place some bills you're not going to
like wait for coming like the first bill
you're gonna pay one bill then gonna
wait for like one hour and then you're
gonna play the next bill right you're
gonna usually like pick every bill I'm
gonna play them all at the same time
because it's more efficient to do it
that way the same time the same way when
you go to the grocery shop you're not
gonna like buy one product at a time
you're gonna just put everything in the
cart and then you just check-in
and but everything in a single time
right I'm just gonna go there and test
by Ron Pollack and gonna return home and
take it there and then gonna go there
and you have one other product and gonna
go there so and so on chocolate is the
same look at that look at the traffic
lights right it's like they don't light
like one cargo at a time they'd light
like 20 30 cars to go at a time because
it's more efficient the same thing is
like cooking food when you're like think
like a bakery it's more efficient for
them to like bike 100 breads or 1,000
brats at a time that one one only only a
single one so batches actually even if
you didn't think about this batch is
using three sticks to our own life so
it's very natural that we actually
needed testing software as well and why
why do we why do we need batch well
because it's more efficient
let's robear to set when you when you're
on the traffic light you don't want to
be to let just one car we want more cars
to be to be light on the green light as
well as when you cook cookies you don't
cook it you don't cook one cookie per
time because it's more efficient then
you focus on a single problem when when
you do but you don't you don't you don't
have context switches but you just focus
on look on the problem that you want to
solve and finally this reduces costs
imagine how much would it take if you
want to cook a cookie buy my cookie so
it would take you five hours maybe and
you pay the electricity for five hours
instead of just one hour okay so now
looking at the state of the art as you
probably know the j-bot API is were is
really new to the
Java environment or the Java environment
but that is actually on the technology
side for many many years and started
with mine frames for instance but at
Java level we do have a couple of
technologies that gave us batch in the
last few years one of the most known one
the spring batch who have heard about to
bring batch before a lot a lot of people
awesome and spring batch to use it as I
guess all of the you as well okay not
lots of you also IBM WebSphere as their
own implementation of batch so really
much disconnected just as a curiosity
ever everyone anyone here in room ever
used the IBM WebSphere batch stuff oh we
have like a couple of guys oh four guys
so quite quite quite a few I mean I was
hoping like zero are you happy by the
way okay Austin I never use it before
but I when I saw when I check it out it
seemed a bit complicated then we have a
dupe so who do you think I'd look for
bad stuff one guy two guys okay so if us
and one of the most use cases actually
instead of having like a batch framework
we just use plain Java see with the
scheduling sometimes doing like chrome
tabs on UNIX boxes and he in-house
framework so who's using those kinds of
stuff yeah most of you you know as I say
I've worked as a freelancer and most of
most times I do is consulting work so
I'm actually excited to have this new
API because I look using to I don't know
Steve seven eight nine projects of my
customers and most of them they have
like in all frameworks to doing all this
kind of stuff with bad stuff and you
know the pain that I have when I reach
there and I have to relearn everything
again how they do the bad stuff I don't
have to learn everything so this is
really painful and I think that we were
really missing a standard way to do bad
stuff so then I can come to my customers
and but
okay please use these so you don't have
to relearn out all the stuff again or
train your workers to know how to do
that properly in that sense so here it
comes the chaser j-15 yeah so we are
here to discuss exactly that the javi
batch implementation as of Java 7 we
have a new jsr it's 3:52
and its purpose is to specify how we do
much applications but you think about
this this jsr is that it's the thing
that is specified you should not you may
not run it in the in the in your Java
environment you you may write outside in
a standard edition java application and
as for better to mention we have quite a
few employment area we had quite a few
implementations before that in the
industry so it's heavily inspired by
spring batch so what are what are its
its features so yeah next one ok so
since some of you have known spring
batch basically these API borrow a lot
of the concepts the spring batch already
has so for everybody really needs to
have a task oriented thing and as also
chunk oriented style processing we're
going to look into this a bit in detail
in the presentation we also of course
have the regular style of processing
like sequential stuff that's usually
what's most used but we also have
parallel execution which pretty awesome
using partitioning plans and we're gonna
have a look into that in into the
presentation as well another thing
that's very interesting is I
checkpointing have you ever happened
like I don't know like processing a file
forcing a large amount of data and your
process just crash right so what happens
you have to move we start all over again
so these these this API gives you a way
to not so you can deal with this kind of
situation so you don't have to
we start all over and have you can do
checkpointing on your data and you can
start a process the data where the point
or the application crashes or some other
problem might have arise we also have
like a style of workflow that you can
implement in an XML file so you can have
like we're gonna have a look into that
in the in the presentation as well but
you can have life steps where you can
just say what you want to do in each of
those steps you can do the sizing stuff
so we're gonna have a look into that in
the future of course you also have stop
and restart stuff so for instance
imagine that your job takes like 20
hours to run and you only have like a 8
window hours to run it so you can just
run it for 8 hours
stop it and we started Slayer again and
finish this the the processing in a
later hour so it's quite useful feature
as well and of course exception handling
so whoever process stuff without having
exceptions I know sometimes data is
corrupted sometimes we don't get other
data that we not expect to get so we
have all these kind of features that my
opinion are very important for doing bad
stuff and we have it all here in these
IPI ok so before we dive in yeah there's
a question yes
yes so these features are available as
JSR fitted to a specification so they're
post available to Java EE and Java SD
environments so basically there is no
difference between an AC edition of the
J's at 32 3 5 2 or the new additions
wanna same well I mean the bunch of
using Java EE you might need some other
specifications on Java EE to use it
I mean we're gonna we're gonna do demo
here but we're using some servlet so you
don't have service on Java C at the coop
so I can you can mix it out with servers
or some other specification from ecology
and watch that it's is a very really
wired with CDI as well so you can get
the advantages of CDI on Java
okay so before we dive in into the API
let's see what is the domain language
the what what are the terms in the jaw
very much so we have a job repository
and in this job repository we may have a
job operator we have a job operator at
the job of the purpose of the job
operator is to execute jobs so a job is
what a job is the sequence of steps
right so a step is Roberto mentioned the
step may be a simple task or it may be a
chunk step which is really more complex
so what does a chunk step here 14 step
have had three three phases so each of
these item reader item processor and
item writer writer are responsible for
doing the job in these three phases
later on we will see will dive into even
into more
about all of these so what how are these
covered these terms composed in terms of
each other so first a job a job yes main
steps it's a sequence of steps that are
executing sequentially or maybe in
parallel then a job when a job is run
imagine a job as a class in your in your
Java program so when a job is started it
is initiated and actually when when you
want to start first the job is initiated
so you get a job instance then when you
start it you get a job execution if the
job fails then you might want to restart
it then you get a new job execution of
the same job instance at the end when
the job execution errors it executes a
step execution for for every step so if
a step inside the job fails and you may
want to repeat that step only then a new
step execution is is created okay guys
well what you usually do is like you
have scheduling stuff on Java so you can
use like the schedule stuff from Java to
run those kinds of stuff so but you are
asking your like using external
scheduling like crontab yep I mean you
can you can probably can run a crown top
that just invoke a static void main
which involves but the the batch
operator and pass the job there but you
should usually to execute a job you need
to get from the batch runtime the job
operator which we'll see later on and
then ask it is no different than my
for instance instance creating a
persistent context programmatically or
or the cd-i context so any way in which
also sorry we have a question here I'm
so I'm sorry can it can you have a step
execution context methods that you can
invoke and you can have all the
information there I can show you
something later
so I hope they're not much bored so
we're just gonna start driving in show
some code so let's see how we can
implement a very very easy
GSR 252 job can get so this is like a
bassinet phoenician it's watched a lot
just a regular Joe Joe as you might seem
the only thing that we have she just
extends an abstract Bachelet which is
part of the API in here
but what is just like the most simple
kind of step that you can have for a job
in here is just override the method
process and we're gonna do some logic
there at the end we're gonna return
status for the for the for the Bachelet
and we're done with it this this is not
enough we also need
to specify these on the java cache in
language XML file yeah I'm sorry we have
XML here but I think it's for a good
reason
so we can have some workflow building
here anyway is not it's not so boring
it's very simple to do which is
instantiate a job have a step and let
the button if you want to run start the
job just called job operator so this is
like pretty API because color call the
start and the name of job actually this
much of is not the attitude that you
have here it's actually the name of the
XML file so this is a bill two years on
the API but still it is that it is and
we can just call Java secretion and get
an object called job execution that we
have all the runtime information about
the job sorry sir I have a question
okay so you having problems like
interesting all the jobs that are on the
batch operator environment
DJ Barrett you can actually get some but
the thing is that where that they have
some you're not using API stuff so using
underlying implementation stuff from
them right okay yeah are you that there
are things are still missing on the API
usually what I do is like just get job
execution IV and ice everything like a
map so I can access later on if I need
it
yeah yeah so the API is not perfect have
you seen so we can actually go to the
jsr and suggest a few improvements on
that actually they're going to do a
revision on that or for Java e8 you're
gonna have much 1.1 I'm not sure if yes
you'll done with the details so I'm
actually having other fuel poverty parts
have when I show it later and I'm
actually trying to suggest some of the
stuff there so maybe there's a concern
that we can suggest both of us there or
if you're not if you're not familiar
with JCP and the j-stars
we can help you with that but thank you
sir
I'm sorry can can you speak a bit louder
Oh an API so the question is at an idea
for Java monitoring I know that glass
dish you can you can you can check the
monitoring of the job stuff there is
something there I'm not very familiar
with glasses because I don't use it that
much
but I know that it's there for wildfire
definitely there is none because for the
for all the service that we have batch
it only glass dish well fine there is
another one this juice that South Korean
one but I'm not familiar with that one
either but at least glass fish you know
you can have some monitor in there
monitoring is being part of the spring
bad stuff for a long while for quite a
while now last couple of years but is
making to the specification because I
mean the spec lives as far as I know
they didn't want to put everything in
and they were running out of time and I
mean we didn't even have generics
because they run out of time on the
readers and writers so but that's
something that I think that's on the
roadmap as well but I'm not I don't
think so that's gonna be on the next
badge iteration probably only Java e9 or
later so as so this was the the most
simple batch that you can make so that's
what is very task-oriented way to do
stuff in my opinion this is usually
suitable for very short executions that
you want to make kind of like end all
system resources I use it a lot when you
want to copy files from one place to
another or just create directories or
clean up log files and all that stuff
there's some other use cases as you can
use them but usually these are the most
ones that I usually mo use so for the
most part the batch jobs process big
records of data right we want to spend
the idle resources on weaker processing
bigger records of data so for that kind
of processing we have the chunk jobs so
the junk steps so what what is a chunk
step a chain step how how many of you
have heard about an own data warehousing
so yeah in the data warehousing what we
usually get is three stages so in the
first stage we we read the data that we
want to import but usually this data is
not structured or it's not in our domain
language so the second stage the
processing of this are all data is its
idea is to transform this unstructured
or in different domain like different
domain data into our own domain into our
own language then the third step is the
idea of the third stage is to import the
already processed data into the database
so basically the state the chunk steps
have the same idea what else do you have
future steps is that some big crack
records of data you don't load them in
memory once but you do it in chunks so
you process first the a part of this
data then import it into the database
then process the the next part and so on
so forth so we have here a diagram that
shows basically the process but I'm not
sure whether we'll have time to go into
more details so you see the most
important part is that the data is is is
processed in chunks so you usually you
read and process one item per per per
iteration and then the end you import
the whole chain all the items that were
read and process into a database and
then you continue to the next chunk
so how do you define a chunk step it
uses nearly the same the same XML so you
have the step ax does the step element
but instead of a Bachelet you use a
chunk a chunker element and you set up
here
what is the checkpoint policy which
means how do you want to divide your
your records in chunks the default one
is the icon policy so in this case where
what you see here we will process and
import three items per for iteration or
perching so inside yeah yeah we're gonna
I'm gonna show them show it yeah so we
also can adjust just twelve you thing we
can have like a custom checkpoint policy
here so we can implement your own enroll
your own if you don't like the item
count a way of doing chunk stuff but
this is like just very simple you can
just look at the API later to have those
kind of stuff and I'm actually gonna
sorry sorry yeah there is probably a way
to do that like doing like light
injection
I actually I usually don't need to do
that because mostly what you're trying
to do these kind of things you want to
like have a very good environment
control so I usually don't recommend
like change that on run time but that's
definitely possible actually if you want
to switch on and switch off balance
steps there is another way but in my
opinion in my opinion if you want really
want to change it is probably easier to
just implement a custom checkpoint
policy which you can implement like a
class file that's gonna be used as a
checkpoint and you can just do whatever
you want there yeah so we have the
reader the the processor and the writer
you
see these are and you don't seem very
well because of the yellow color but oh
yeah that's the name it up these are CDI
maybe so they can be referred to with
their names not with the Fuqua
classified to qualified class names so
again we have a item reader that
implements the abstract item the item
user interface or extends the after
title reader so we here read an object
per iteration and return it then in the
next stage and next slide please
yeah there we have the processor which
receives as a parameter this this object
which is usually usually not part of our
domain that was read from by the reader
it processes it and it returns the
result usually the returning object is
part of our domain domain model and
finally when when all the chunk is right
when unprocessed the per set the writer
is involved it's write items may to this
code which receives a list of already
processed objects which again are part
or should be part of our domain model
maybe you noticed if you go back one
slide over to this maybe you notice that
our writers readers and processors that
they throw exception which means that
the framework that executed the steps it
has inside some logic to handle this
exception of course we can interfere in
that logic and this is with the
exception handling
please thankfully I'm sorry this is here
thank you this is with with the
exception handling there is declarative
exception handling for change steps we
put it again in the job XML inside the
step element and you can skip steps or
retry or retry steps based on on thrown
exceptions then you could have include
and exclude so basically the the API
yeah
I'm sorry yeah so the basically the
chunk is all all run in a transaction
it's part of the API so you can just do
whatever you want with transactions
there well that's not that the
underlying the driver that you're using
so and any I mean you have to use a
driver that supports two-phase commit as
well and implement to check the a
transaction that implement not implement
but use it on the user's use an ATI that
supports it so while it's using a
application server you're gonna have
that yes sir well I actually was
searching for that a couple of days ago
and I did found some emails switching
between the jerk we not joking the JCP
the spec leaves and as far as I
understand they run out of time
integrating with world or the CDI stuff
so they prefer to remove it altogether
that only have it for a couple of things
because well basically they just run out
of time and they were having some
difficulties integrating with CDI stuff
but I think they're gonna look into it
again I'm not sure if it's gonna be
available on the next iteration of batch
but definitely is on the roadmap as well
so as we are also running out of time
very quickly this is this is the XML the
definition in terms of XML how you can
define the policy on drawing and
skipping and we trying upon exception
upon to an exception yeah so this is
very similar to the chunk that you have
before but you just have like a skip
limit annual tri limit that means the
numbers that you can use to retry or
skip and imagine that you have like
rest api then you have like a timeout so
instead of like giving an error you can
just skip that or you can just retry it
after like 10 seconds or 1 minute so
you're not gonna discuss this year but
actually the batch has a lot of hooks
where you can add listeners and you can
execute random codes not only in code
but your logic to end those hooks
happened so one of the books you can
have is like when you have like an
exception on with items or an exception
on process item and so on then one of
the most interesting things on batch
application is the ability to partition
stuff so partitioning is actually
running some of the bots are shaking in
multiple multiple threads usually we
have like a thread per partition but we
all can also like to send the partition
plan the way as we wanted
and I can gonna show you how you can do
that checkpointing is also for frets of
that meaning that when you have like
multiple threads running all the same
points gonna be in a single thread and
then you might actually have to make
like an aggregator in the end but
usually you don't me that when you're
doing most of the stuff so just usually
for complicated stuff but I'm not going
to go into much detail here just gonna
show you the most general stuff so to be
fine define a partition just gonna do
this so this is actually going to the
inside of step definitions so but you
just remove it just for to being easy to
see in this case just we had a partition
with a plan with two partitions and then
we're gonna pass some property so these
properties are useful so we can then use
them to pass them to our readers and
then do something to like split the data
between like someone start we're gonna
read the first element of what we are
reading and then on the partition one
you're gonna start from element eleven
but I'm going to show some examples in
the future of the session but you can
see this much clearer this is the chunk
using the partition so actually we're
going to do like some light binding on
properties from the partition plan and
here we're just passing to start
properties that we just defined here and
this is useful so we can know how to
split the data on the reader so all the
batch can go smoothly
this is this this is just an expression
this define on the on the API so you
just use like a cardinal curly brace
partition plan and just use the variable
name of the property that is just a so
this not it's not like an expression
language diversity or something like
that it's just like something used to
batch sorry no no no no this is just
like panning of properties it's very
very simple you don't have you don't
have like being property access you just
property access and that's it it's just
like actually it's just like a map of
property value it's much easy to the
start
property in the previous slide this is
this start comes from here yes yes you
can have a rather valise okay then
we've mentioned that the steps are
executed as a single unit but you can
also group a lot of steps into their own
execution units and these execution
units are called flows so basically in
the flow the flow is executed as one so
if a step inside this this you this flow
fails then when you repeat it the fall
starts executed from the beginning how
you define a fall actually we have
together with the split okay so a split
what is pretty nice is that you can have
two distinct flow to be executed in
parallel so Roberto showed you a while
ago how you can split a step in parallel
now the splits are how you execute flows
in parallel so let us let us see how
this
so you define a split and then he sells
a split you have a couple of flow
element you may have more as well and
then inside the flow you define defined
steps by the way all these fights will
be available after after the procession
so you may you may not take pictures no
no it's fine I know that some people
like to take pictures for they own notes
oh you're you're okay with it okay enjoy
it so I don't know if you really did get
the difference between partitioning
splits but I think this is gonna be much
easier to understand now because when
you have a partition you you apply that
partition to the same chunk so usually
what you're doing is just partition it
at the data level when you're trying to
read stuff now with the split if you
look like here we have a flip with two
flows and you can actually find
different ways or different steps or
different chunks or different tasks you
can make these are also on the
split-finger also we're gonna run in
parallel but you can actually run
different stuff while on the partition
as you can see here the partitions
applied to the chunks so you can you you
just gonna apply it to the to the wheels
right in the processor so usually the
way I usually explain these to people is
that partition is usually used at the
data level so when you want to split
data and then process the move the same
data very multiple threads and please
use that business level when you want to
split stuff but you want to execute
different steps stuff at the same time
so sometimes you may not want to execute
a certain step if if a condition is true
or false so you want to actually make
decisions whether to execute a step or
flow or not so this is where the
decision elements kick in so maybe if we
go to the next slide yes sir
real-world example
yeah we can show you one later okay so
how do you find a decision so when you
define a step you should specify where
this step which is the step which is
executed afterwards but it may not be
only a step it may be a decision it may
be a flow and it may be a split so when
you when you reach a point in your job
execution where you want to decide
something then you put their decision
element and inside you you define an
implementation of a decider interface
which really takes the decision and
based on on its result a different step
or different flow may be executed so
what is this decider interface it has
one method which is decide and it
returns the string so if we go back
again in the previous slide the
depending on that string it will meet
the the framework we try to match it to
the own attribute here on the on the
next sub elements of decision and we
will go to the to the step or float with
with that ID my footstep or my bar step
okay so yes sir look that the the API
really defines that you cannot look and
actually it's going to throw an
exception if you try to loop it so we
basically saw on all the elements that
we can apply to the to the workflow so
usually now have transitions that you
can make when we define that the batch
workflow on the XML file so usually they
are applied to step source and decision
so we can just move from one to another
and you can also apply like imagine like
we were having I think here
yes so we have like a step and you say
like next to the other passes so this is
gonna to define the book the workflow
that we're gonna follow for for the
batch and oops I'm gonna go yeah here we
go and when when we've defined this
transition we can also like send like
the Nexus tariffs like file and let's
top to terminate the job so this is like
just to work for stuff that you can
implement on your xml stuff so this
usually develops that you might have is
like starting start with stopping stop
so and so on I'm not going to read them
because you know how to read and it's
pretty boring for me to week the slides
but still this is uses for you to know
where the job or where job is on the
execution steps or the education flow
and you can use them for multiple stuff
okay so far we've seen what we've seen
how we can define our steps then we've
seen how we can declare the the jobs the
sequence of steps that are executed and
we've seen how we can execute jobs using
the job operator so but you don't want
to to run the job manually you don't
want to wake up at 2 o clock in the
morning
connect to your company computer and
then press the button to to run the job
right so this is where the scheduling
kicks in so in the Java EE world we have
a few ways to schedule running something
in this case a job the first the first
way to do it is using the add schedule
notation on an enterprise javabean
usually singleton enterprise javabean
and then the other way is it comes with
java 7 it is the main schedule it
Secutor service where you could call it
it schedule my 2:10 define there on what
on what
period of time you want to to execute to
execute something in this case it's
horrible
the which are all runnable actually
which runs and start the job okay so yes
sir oh yeah so that's that's that's the
way the timer is implement I mean as far
as I remember if the job takes longer I
mean that's not exactly for the job
because it cannot send me the logic that
you put on the timer so it's not a batch
problem but as far as I remember if the
timer surprises the the next execution
is gonna skip it and gonna run it later
when it happens again I'm not exactly
sure I don't remember but I think that's
the one
probably oven can help me out on that
one we remember about it on the timer
when when you have a timer any surprised
and when you have to execute it again as
he passes the execution time it's just
going to run it the next time in its
accuse right yeah but I mean if you like
you have the time out for like for
instance like one day and it's the but
still running for one day it's gonna
skip that the next day and gonna buy it
again yeah yeah exactly yeah
thank you oven
there is a schedule in the ad schedule
no schedule execute us whether the
damage
I mean it's just like a matter of
preference you know they would work
pretty much the same way usually with
the manual service you can just like do
programmatic stuff with it yes sir so I
actually have this gentleman over here
talk to me in the you know the session
about the costuming stuff and possibly
we don't have clustering for for batch
yet so let's hope if we can make it into
this profession in the future so maybe
some vendors might implement it on their
own but as far as I know it doesn't you
don't have it yet so basically each job
it's gonna run on their own no then you
have to make sure about it so anyway
currently we have a couple of
implementations already so we have the J
patch from IBM actually IBM was the one
the guys leaving the specification if
you some velocities and juice then we
have revit implementation with J Barrett
and actually the the spring guys also on
the last version of the spring batch
also have the implemented the API so you
can also use screen batch if you like
and replace J batch IBM or J Barrett on
your application servers or use it as a
SC environment so but is not batch is
great but also as a few problems in my
opinion we are already in for some of
those like the generic stuff
one of the things I find me the most is
the lack of readers and writers so when
I say lack of it is right is that I mean
when you want to process like adjacent
file you like the glue code or the
boilerplate code to read the Jason and
write - Jason is always the same right
but the thing is the API only provides
you interfaces and after classes that
you have to implement and do the stuff
so I mean if you want to reuse the code
you have to like copy paste it from one
project to another so you don't have
that on the API I know that Jay Barrett
I already have some of the readers and
writers already implemented to like read
stuff from Mongo database is to read
stuff from JDBC databases to read Jason
stuff you know and so on but these are
not standard things spring guys they
also have a lot of readers and writers
already do a lot of work for you but
they are only they are not available yet
to the screen batch API MJ star 352 so
they it's only on their own in their own
counterparts no non-standard no genomics
as we already saw importantly partitions
only work on a single chunk on a single
step so if you want to have like the
flow with multiple chunks and multiple
tasks so you cannot have like a
partition there something I already
notify the speculoos about and I think
they're working on it and no sync mode I
mean currently the bad synchronously so
if you have like an acid environment and
do the start of the job if you don't
have like a Fred waiting the the je
viens gonna die so we cannot have we
cannot render them a synchronous sync
recently so only sync
I mean might some people might have some
problems with it but still these are at
least the the the one of the stuff I the
placement the most on these IP I so I
hope we didn't bother you that much with
all these nations since it's a new API
we thought that was important to look
into some of these stuff but now we're
gonna
- we don't have much time but this let's
try to make it more interesting now so
they're gonna do some demos
can everyone recognize this image don't
know which amused it is okay we have a
few people oh I am are people they
recognize this so basically this
screenshot is from a game called World
of Warcraft I don't know everyone knows
everyone heard about world Warcraft at
least okay a bit more so about the
Warcraft is a messy multiplayer game it
has more than 500 fibers around Europe
and us and I told before I'd work with
finer stuff and I when I was trying to
do a demo here I was about to like
implement a very boring stuff we'd like
transactional finance from stock market
but I thought it was going to be very
boring so I actually found out that well
the Warcraft
they have like a REST API where you can
just download most of the data that they
have there and do something with that so
basically they have like any survey they
have like two option houses where the
where players put items in so this is
game related but you can think about it
as like a stock market or a stock
auction and bicep either each server is
around 7k items per server per hour so
doing the math as far as I remember if
you want to load all the data and it's
are all the servers on Europe and us
actually just for I think I only did it
for Europe just around 50 million
records that you have to put on the
database just to do something there and
this is and they changed half an hour
later so you have to like load 50
million records each half an hour anyway
you have like these doctors available
download the idea here is like this
process this data extract some metrics
so the data is just look at the Odyssey
the evolution of the items like like a
stock market they see when they are low
when they
hi the median price and all that stuff
and now I'm gonna ask for help and pray
to the demo gods to beast work so let's
right hands and leave them oh god help
us
don't let me fail okay so I didn't want
to do some light clothing and let's see
if I have time I'll do it but still I'm
gonna show you a few stuff so this is
actually one of the files that I can
download from wall of Warcraft they have
like these adjacent file with all the
options as you can see it's gigantic
I don't know if you can see my scroll
bar here but it's still here on the top
so this is like ATK or hand 100k records
Jason file now I actually built a really
small application here that's showing up
here so this data is actually loaded on
the on our database that we have here
and basically I'm just gonna clear this
okay so now actually gonna search like
an array on here like this so this is
like one of the arms I use one of the
giant I usually play and I'm gonna
introduce you to like an item ID so I'm
using like angularjs you know sometimes
I'll go chase know some like some of the
stuff I boot so I'm going to do a search
and then you can see I have like a graph
here we have old historical data in some
of the data that I just loaded now
hopefully I'm gonna try to load a new
snapshot of data and actually have
something here that I can execute so
actually running a server here this is a
wealth for server and
like this process job actually now we're
gonna run this file job
this actually was generating a lot of
code basically it's just connecting to
all the servers around the world
checking if there are any files and
though and downloading the files to my
into my to my application so then we can
process it later one of one of the
coolest things I found here is that this
works pretty well with the streams API
so I'm using Java 8 here so using
parallel streams to like connect to a
lot of servers at the same time in the
world data so it's working pretty well
so I actually already done that this is
actually download the files yet just
don't wanna do where L where I have to
download them because like all the files
take like 200 mega or something and
these actually took like 3 or 4 minutes
before are using parallel streams now it
takes like 20 seconds so it was awesome
now let me just process like one job so
now it's a part that Ivan's gonna dance
to entertain you because he's probably
gonna take little time so maybe I will
not days because we will scare you away
but what this does is so remember we had
our data download it from the server and
this this is really raw raw data all the
options on the server now we want you
can see here what we have we have some
statistics like minimum maximum average
the bay out the bay out the bits and so
on so what we want to do in this
processing job is read all this data
engines then process them and turn them
into our own data data model our own
domain model of minimums maximums and
averages and then import them into the
database so this is basically what this
step is doing so we're student all in
the area and if we just check something
here
let's just see all the fell it is seven
mag 7.99 it Meg
so I think the file shall be around 12
the night I met is slow I mean I'm in a
wireless connection but maybe maybe we
could show them some live coding yeah I
will do this almost done importing sound
way to do importing reporting reporting
Oh like I was doing now well the thing
is I'm just moving out just unloading
the file so I mean it's like it's like
you have a dog manager and see how the
percentage of the file is but this is
actually already done so I'm gonna do
like a refresh here so we have like
September 29 was the last one so see now
I just updated our ax and we like
October 2 so you have like this item
over here you just like call tremendous
don't care whatever and here like the
start of the item it just got low for
one of the auction houses and all that
stuff so let me show you like a bit of
code that I have here so what I can do
this so this is like the way I just
process the that file so actually have
like a download step here which it is
that just like a basket these taxes
moves this file to an input folder just
to have it safe and then I just actually
gonna process send 100 items at a time
and are either a processor and writer
and when I'm done I'm just gonna copy
this file to process folder and then I'm
just gonna run this statistics job it's
going to run this in partition
and actually split the data which you
have to auction houses and it's gonna
fit there are a between lots of stuff so
for us to have a look at the code as
well so we can actually never get here
so this is actually the the data item or
either
so actually we sorry larger can you guys
see here okay because in a presentation
mode I cannot put it well confirm but
this Ariens be able to see so actually
to means it just open stream for the
file from JSON file and process it in in
a stream way this is very important
because you want to reuse items in a
chunk and only a few atoms at a time
so it is just only the the reader part
when just going to use the the stuff
this is the boss is just closing up the
resources and then reads just going to
read the stuff building objects and
going to pass it to from a processor
item which is here so we just get this
is painful because I have to cast stuff
around but basically it is just like
having the option stuff setting the real
Mary I am so this is actually just it's
kind of like me doing ETL style
professing like extract transform load
stuff so just extract stuff now it
transforming stuff and finally you can
you can build a dashboard looking into
stuff of the job repository now about
the other thing about the clustering
stuff you don't have clustering so but I
mean I think it's possible it might be
possible to have like a central server
where you have all that stuff and then
have like multiple servers connecting
and running and stuffing jobs but the
jobs need to run on the same machine yes
are we done two minutes okay let me just
show you a couple of more things
so now finally the writer this is just
like very very simple I just do for each
and Percy stuff I just want to want to
show you a few more things so process
job because I think those a lot of these
things are important so this is the this
is actually then the process that's
going to export this pieces are going to
pick up the deduct some device and
struck the metrics so we're actually
doing this on the database using the
query tool like all the sounds and
average and all that stuff now if you're
looking here I'm actually using a
director that EBC and I don't you think
API for this and why because JPI doesn't
have a scroll over it's offset I mean I
will night as but JP Adams have a
standard scrollable result set and it's
very important to do it this way because
you can now control the pace of the
wheeler and with only three items at a
time or another happens at a time and if
you want to do that concept PA you will
have to like do a genetic query when
each time you execute the reader it's
going to execute like the person is
query so basically you're switching here
like one query for like unfasten queries
you're gonna do one Tek da so there's
pretty much it let me just show you this
writer here and this pretty much very
easy so still have one minute yeah no
I'll be done I'm sorry</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>