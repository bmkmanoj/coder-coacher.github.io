<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Future of Development and the Cloud | Coder Coacher - Coaching Coders</title><meta content="Future of Development and the Cloud - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Future of Development and the Cloud</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/oGHb2mBfNsQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">um pretty ambitious title future of
development what kind of cocky redhead
is doing that that's crazy talk so I
rarely talk about me and I don't really
want to necessarily but i think it is
germane to the subject I last year was
asked to head up research and
development for Sabbath which is part of
CenturyLink yes within six months they
laid us all off which is pretty cool but
I worked with a pretty stellar team and
our mission was to figure out where the
cloud was going to be two to five years
from now which is again kind of crazy
right like I don't I love studying human
behavior love it some some of my recent
favorite books if you're into that thing
is mistakes were made but not by me
Mohammed oh it's great stuff but this is
on the same line as predictably
irrational and freakonomics things like
that and what we know is that humans are
terrible at predicting the future just
absolutely terrible because they pretty
much start with what they know and so we
went after it we started figuring out
this was all last year and I will
summarize right off the bat real early
on we we thought docker which was at the
time point three so it's pretty crazy
and a vicious thing but they are
definitely on the right track at least
well we can talk about it I'm going to
get into a lot of detail but doctor was
definitely on that and it's not
necessarily docker it really is
containers it's really about containers
it has very little D with dr. no doctor
added some things which are really
awesome the other part is mace Apache
mesas now with that said I've been in
some pretty interesting awesome
high-tech crowds and I will have a
conversation similar to this and
everybody has heard of dr. and they
shake their head and nobody has heard it
makes us so I'm going to spend some time
talking about that and we'll talk about
some theory and we'll talk about how
that's going to change what we do
because I absolutely believe that the
world of continuous delivery the world
of DevOps it's
going to change and it's going to be
based on this kind of thing and I'm
actually a believer so obviously i have
my opinion and I'm willing to debate if
you have a different one in fact it just
matures my own opinion if we have those
debates I'll try to leave some time at
the end for that if not you can beat me
up out in the hall or something right I
have sense in what the end of June
joined a company called Mesa sphere
which is their whole focus is on mesas
I'm just really that much a believer I
actually submitted this talk before I
joined the company so I was a believer
well before joining the company I just
think it's got an awesome future so with
that said I am a solution architect with
mace if you want to tweet anything Mesa
sphere is the is the term you can tweak
to that if you want hit me up we've made
publicly available a USB stick which
includes what we call makes us fear on a
stick it's going to include the ability
of run docker instances in a cloud
environment obviously within a vagrant
VirtualBox environment so let's get
started step 1 ones the last time you
saw the fail whale it's been a while
there's a couple of things that solve
that problem probably widely widely
circulated in the dev community was the
switch from rails or what they refer to
at the time as the monorail a monolithic
architecture that Twitter had to a
java-based solution which is awesome
right because we're here at javaone and
and there was some claim that dynamic
languages don't scale and I think that's
hogwash I think that's a little bit
silly that aside that's not entirely the
full picture the real picture includes
that they move to Apache mesos at that
time I was a couple of things that
happen Apache mesos was a project out of
UC Berkeley if you combine that with
some technology or some awareness or
some philosophy that came out of Google
a number of people came together to
improve that product and everything that
is at Twitter that scale is running on
on May sews so that kind of is the the
road we're going to go down let's let's
have a commerce
station for maybe 10 15 minutes and try
to understand where things are at and
what we mean by legacy so let's start at
the data center it's my belief that
there is a perfect storm in the data
center and it's a combination of a
number of subjects the first is looking
at today's legacy data center how we
define legacy that's always a
challenging where a guy here's how I
define it if you know what IP address
your service is land on then your legacy
data center if you know what port your
service will start at then you're
probably running a legacy data center so
one of our huge problems today is that
we have static partitioning and that in
that problem is it it's more than just a
small problem so let's talk about it
what do we do today well we get a number
of hardware machines and we break those
hardware machines into virtual machines
we take a slice of that virtual machine
we say that's going to be our Hadoop
cluster so we have zero through eight or
nine different instances we're going to
say we're going to be running a new pond
we of course have this data center of
lots of things we need to do so we're
going to put a top cat instance a rail
census some kind of web service we're
take another slice of 10 and the way
this is normally run as an admin goes oh
yeah 038 that's just Hadoop 0 Hadoop one
who dip too and you run up a puppet or
chef recipe up against those instances
and what happens when you want more what
happens when you need more well you just
say well we need more so you take
another set of instances and you say
okay let's let's put them out there now
there's a couple of problems with this
and one of the big ones is an issue with
utility resource consumption and one of
the solutions with that of course is 20
/ fit over provision a hardware device
with multiple instances of VMs we're
going to talk about some of the problems
associated that VMs are a terrible
solution by the way although it's an
awesome solution right we base our
entire technology of infrastructure IaaS
is all based on virtual machines if we
look at ec toots its virtual machines
and we love it but it's somewhat
problematic and we
to talk about it so the first problem is
that it requires humans if I need a
scale out if I need this elasticity I
have to go and add I have a human it
goes out there and says do this or you
could go to right scale and give them
some kind of recipe and they'll do it
for you but the point is it requires a
human you might be able to automate some
things or our API is to be able to
automate this it's problematic we'll
talk about more details the other is is
that we have an own IP address and port
and it's an ugly word to compare this to
a desktop application it would be like
this what if we wanted to run IE on our
windows box and then you were prompted
with this well what cpu would you like
that to run on this is what we do in our
data center today this is a legacy data
center right where would you like to run
that on what machine what node what port
that's the question now how do we switch
how we change this so that applications
of the data center or just as simple as
they are on our laptop and I realize in
a distributed world we'd have a
challenge with being able to remove this
cross-cutting concern of scale we'll
talk about that we can also talk about
resource utilization the best picture
pictures say a lot right so when we look
at the web service you can see that
there's a nice little hump we have some
off-peak times we have some on peak
times we see we have wasted space in
Hadoop as we have analytics completing
jobs and then spinning back up what if
we could combine those things now
there's a company nearby that's been
doing this for a long time and in fact
they have probably the greatest amount
of experience as a whole on containers
and that is google google has been doing
this since 2008 from my understanding
and they had something internally
referred to as the google Borg so the
Google Borg did something like this
there's a bunch of web services that
they have and during many periods of
time during the day there's a extra
amount of utility available on any given
machine what if we were able to tap into
that we could do more with the existing
hardware we could just consume the
existing resources
and if if we have a spike in web service
traffic we will just diminish the
analytics because we we don't care we
just want it if we can get it and in
fact there's a term that we've started
to use with the Googlers I've been
privileged out of being some of their
circles and it's tier 0 and tier 1
services at error 0 service is a gear a
guaranteed reservation of resources
however often times when you have a
guaranteed reservation of resources
you're not consuming at all so what if
you had a Tier one set of services and
the Tier one set of services are best of
available which means now will consume
it and if a Tier one comes in and and
basically resendes an offer we would
refer to it as as far as scheduling is
concerned so the Google Borg is a pretty
big deal you can see there's a link
there when you get the slides you can
follow it up and what you'll see is that
Mesa sphere has been credited with
bringing the Google board to the
enterprise we're taking the technology
and the solution that was there and
bring it out to everybody make it in
fact it's completely open source today
everything we do is in the open source
space which is cool the other challenge
we have is time to production my CEO is
the person who wrote user search at
Twitter when he finished writing user
search and all my developers out there
are going to know exactly what I mean it
took ten weeks to get it into production
he's done he would love some feedback he
would love for people who use it but he
can't why well you know we got to create
a chef recipe we gotta wait till we not
just have one thing but maybe three
things so we can get the most economy of
scale of humans because it's all about
humans at this point so we'll add three
things into a staging environment we
have to set that up and it takes time
may have to provision some new resources
to make that happen that eventually gets
to prod its challenge it's a real
problem what do they do at Twitter today
well they have a cluster and it includes
stage and production just switch right
we'll talk a little bit more about that
so the driving forces continues delivery
or DevOps whatever term you want to use
the need is to be able to get feedback
faster from the clown all right let's
talk virtual machines for a second well
we're dealing with virtual machines
what's the problem we have two different
models that I see as far as building out
your data center if you want to call it
that or your cloud solution your paws or
whatever right is that you can two
different models you have a puppet and
chef model where you recreate an
instance from some recipe or you have
what i refer to is the netflix model
netflix they spin up an instance they
test it if it's tested good that image
moves around it's not a recipe it's the
image they will hydrate it as much as
they need so create multiple instances
from that image it's a tested image now
in the one case it takes a long time to
provision thousands of servers I can't
give away details at Twitter but I can
tell you that they're running tens of
thousands of servers and at the high end
the pins which is unheard of for most
solution sets that I've seen out there
if you're going to provision with puppet
or chef it's going to take you a good
amount of time and then you're going to
have to test it because we never really
trust the scripts we go through if there
are admins out there they're all smiling
at those points they know it's it's like
you're building a cookie cutter and you
have to just make sure that the cookies
you know good the other model is the
netflix model where if i have a one-bite
change i get a new 2 gigabyte image it's
heavy the challenge we have is this if i
change of an admin I have a challenge in
production I go out to the image I make
a quick change I did the right thing
potentially you know that's why I'm
there I'm an admin I I know what I'm
doing problem is I can't ask the vm vm
doesn't know anything i can't tell me
what's changed so lots of times we'll
lose that information because the vm
doesn't have this metadata you're
responsible if you have any metadata at
all you're responsible for it doesn't
exist so we want more a couple things we
want a lighter weight solution to we
want we want to have metadata for this
thing and we want to be able to
communicate with it it needs to
understand its state if you will
so there's some real problems with
virtual machines here's another problem
that I hadn't even brought up yet in our
research virtual machines consume about
thirty percent of the resources roughly
so the consumption between the
hypervisor and the vm itself is about
thirty percent this is challenging
because I'd rather give you names and
talk as developers and have you under
friend da right but one of the largest
tech companies in the world has taken a
cluster of the data center and they have
removed themselves from virtua from
vmware licenses totaling lots and lots
of money i don't go through numbers
either but it's a lot of money they
moved to mesa as a solution without vm
so they're just bare metal and they
gained more than forty percent utility
so they not only did they remove
licenses but they have gained almost
fifty percent of their current platform
so so VMs have a cost to them they you
know again if you're on ec2 there's some
great value so some challenges that we
have when we talk about the legacy data
center and this whole this perfect storm
we've kind of nailed it it's not
developer-friendly it's statically
partitioned the storm we can also talk
about where things are going so what are
the direction of things well one there's
the list there but one direction that we
see the data center going is instead of
having one hardware machine with a bunch
of VMs with a number of apps on each one
which was more of our client server
model we're starting to see apps that
require an aggregation of services this
would be like your Hadoop where you spin
off a job and you want it to go into the
cluster and just and do a job you don't
care where it just comes back with an
answer right this is a model of things
we begin to see and you can see it with
yarn you can see it with Cassandra you
can see it with a number of different
applications that are out there all
right so this is a model a direction
that we are seeing things go in so the
idea is that we aggregate things we
regret CPU we aggregate memory here's
the
cool part it's not out yet but within a
few weeks because of i think i can say
their name because of Groupon and when
their needs they require a constraint on
Io so within a few weeks we're going to
release the ability to aggregate or
basically isolate io for a given
application and right now it only works
for egress meaning outbound so I can say
this application will get or this
container by a docker container this
container gets one gigabyte of the
hundred gigabyte up bomb I can actually
isolate that all right so that's some
sweet stuff that's coming um interesting
thing I don't know if you've heard of
hubspot but hub spots completely on ec2
there in the Amazon space they they went
to my sauce for a completely different
reason they wanted to consolidate their
admin screen and their administration of
their cloud what they realized in the
process is they actually cut their
Amazon bill in half and the reason for
that is we have the ability to bin pack
create services on on just a few nodes
which means there's a number of nodes
that are idle and they're not they don't
need to pay for those idle nodes yet we
still have fault tolerance and failover
so one of the other benefits even in a
virtualized machine world is is to be
able to bend pack and gain utility from
existing services so that's more praise
from Twitter I don't know if we want to
go into that really not sure what I want
to talk about their so docker we know we
need to go towards containers this is
one of the directions right as I
mentioned we started I started looking
at it version point three pretty much
put your neck on the line when you tell
your boss hey this is the future its
version point 3 and by oh by the way by
you know the first commit was last
January right which was at the time like
three or four months ago like yeah this
is the future what do they do now first
of all note the technology underlying
docker is lenna lenox alexys the Linux
containers lennis containers have been
around since 2008 so a lot of people
think hey these bits are two new there's
scare
what's what they get proven out and the
reality is what they enable is something
that's been around for a very very long
time the challenge has been that you had
to be a rocket scientist to make it work
and what I mean make it work I mean to
integrate a bridge Network or to
integrate your your standard didn't
standard out to your environment the
connectivity of things was problematic
beyond that there are two really cool
things that doctor added two containers
or containerization the first is just
the management style of it it's so
simple that anybody can do it which is
awesome right that's that people look at
it like I'm not impressed as i know
that's impressive it does all this stuff
and you don't see a lick of it it's
perfect the second is is they created
this image format which is super cool
it's good stuff which means what it
means if I have one byte change I have a
one-bite impact right as opposed to a
one-bite change in a vm which means a
new two gigabyte image I get a one-bite
change as one by change it's a big deal
or a small deal depending on how you
look at it point is is they added some
great value now there's some things if
we want to get into some discussion and
argument so you'll have to hit me up
later buy me a drink and I'll divulge
what doctors trying to control this
environment much bigger than what what
we currently see from them they're
pushing something they refer to as lips
warm and I'm just right now i'll just
say that it's it's not reality it's talk
it's a pis and it's it's an
encouragement to get multiple people in
the environment to participate and so
it's not real eventually maybe it's real
the whole idea of lips form is
orchestration there's all another
component to where we see doctor and
that is lib container lib container is a
smaller component of what essentially we
look at with docker they're currently
rewriting this piece and I have high
hopes for that I think it's the right
way to go I think multiple platform
providers will be looking at lib
container eventually and not going
through the doctor API but we'll see
we'll see that's all let's all crystal
ball that stuff's a little bit misty to
me but dr. as a solution is def
Lee catching on and in a big way and
what it looks like is something like
this so we have and I don't technically
like docker in the lair there because
dr. is just a orchestration or
management tool for these other
components but within a linux kernel
when we added NC groups and namespaces a
long long time ago and the same with
alexys again it's not new stuff alexis
is exactly what Heroku used in order to
provide Heroku they've been using that
for years so if you've used Heroku at
all you've already been using Alexei's
they just call them dinos so so it
changes this if you were to install
something as a developer you know what
this is like right do a nap get install
and in this particular case I'm doing
some Python stuff to create a repository
to hold docker repositories it's a lot
like nexus in the doctor world well what
if you want to do that with docker well
this is the answer you say run this
docker thing and start it up at five
thousand thanks like this is the future
right the future is that as us as Java
developers when we want to use CouchDB
you don't have to do an install and then
oh crap i need this patch and oh yeah i
need this you just say dr. Ron CouchDB
and it pulls it down for you and it
starts at whatever port you tell it to
that is the future the question is is 11
dissolve the enterprise catch on and
start doing that right but we have
something that we were referred to as
immutable containers that's a pretty
amazing concept in other words I have a
sha that represents the instance of a
container just like you wouldn't get if
i have a get Shaw it represents a commit
which represents the change exactly the
state of that thing so now i have a way
that when i start something up even if
it breaks i can just go back to it and
say okay start it up at the shaw again
and we're done it's an immutable
container which seems weird I know but
here's the cool part like there's
something that I have ideas that I think
we should be driving to that I don't
hear anybody talking about it yet like
what's the hardest part about continuous
integration
it's slow why is it slow because we have
data that we are setting up in the data
store and then we have to reset with DB
unit or we have to unroll you know we
have to roll back on a commit of some
sort what if you add a database inside a
container and you just spun it up it
takes milliseconds to start up as
opposed two seconds within the vmworld
so I could see this being used in other
ways now where I love to see it is this
like there's been many attempts to
create a virtual machine that you as a
new developer on board into this
enterprise you just spin up this
instance and you work within that VM and
we all know that stinks right I have
another word for it but it's takes it's
terrible it's slow it's in your way but
you kind of want it what have we had
api's into the containers such that our
IntelliJ or eclipse would spin up a
docker instance of the exact version of
Ruby the exact version of Java that you
are previously using and it actually
integrated so that the environment is in
the container but your editor is at your
host level it's possible it's not there
yet I I actually theorized around that
at in Denver a half a year ago someone
tweeted it and Solomon who's the one of
the he's the leader of docker said that
he's he's seeing a direction that way so
we'll see I haven't I haven't seen any
further the other thing is is that it
understands change over time which
sounds weird right we have something
immutable and it changes what are we
talking about so I'm going to make a
quick assumption but there are some
people who have never seen this thing if
i can get my mouse back there we go when
i'm near things for a second so we can
all stare at the same stuff why is this
running all right
uh guys can see that ok so i've got a
docker instance i'm going to say run a
boon to when i run it with bin bash i am
now root in a new container that's how
like that's amazing right it's like what
there's nothing amazing about that what
happened I spun up a new instance of a
boon to it connected my standard in a
standard out to my terminal and in this
particular case I'm in host boats going
to do anything terribly magical but i do
have ports running on that that i could
expose which is pretty cool but i could
do things right like I can actually
let's uh
so I have this food thing right I have a
file that's not exciting because I I did
that out of order but you get it I can
come over here to this terminal likes a
docker PS what's running I can see that
I'm running another container by the way
this is it Shaw that's the Shah of the
instance in time of this container I can
I could commit it give it a name if I
want it cuz I want to use it for
something cool uh I could do this I
could go you know what docker diff on
that Shaw oh you've added a foo file I
can actually tell that an admin change
something because I can ask it it knows
i can now based on any change keep the
show that it's currently running at and
say that's the show i want right the
future is that will create containers
that have java a version of java in it
and it will create another container so
these are stacked technologies in the
same container right I have another
container which has tom cat 7 in it with
the Java 7 on the first container that's
actually going to become one container
and then for your project you will have
you'll have a war project and you will
mount the war file inside the web apps
directory in the container and the only
thing you will have as far as a build
distribution I mean think about it for a
second we've been using nexus in our
factory how do we use that as java
developers well we build something and
then we have a jar and i put it in nexus
and the metadata that's there is useful
because as a developer i can understand
the API semi-intelligent intellisense
and my editor tells me a little bit of
detail I can see the transitive
dependencies there's value there but
there's a great number of us that still
take a war file and push that into a
nexus server why for one as a jar the
the reader the consumer of that is a
developer for a war file it's not I
needed to deploy it now what are the
things i don't know that i need to know
well you know it obviously i can put it
in tomcat but i don't know anything
about whether it has any roles i don't
know that i need to change this
xml file I don't know any of that but
what if we could put that inside of a
container that already has it defined so
that when I hand it to an Operations
team they don't need to look at a wikia
read a word document they just say spin
that up because all the details are
built into the container itself it's
immutable so you know it works as soon
as you made it work and you test it in
your debt or your QA environment it
works in production alright so those are
the things that we're talking about
probably had more to share but yeah you
guys can direct conversations as we go
oops okay so the first question that
people have when they look at doctor is
like wow that's cool that is way cool
how do I use that in production now this
is over stack overflow second stack
exchange you don't talk about you can
see that there's an answer here the six
of them but that first answer is like
lengthy it's like oh there's fleet oh
there's lips warm oh there's core OS oh
there's and you could go through the
list of things that are trying to do
this in other words orchestrating
containers into a production environment
none of them have an answer yet not a
production answer and to be honest and
to be completely transparent it's new
within makes those as well we've just
added it in although we've had three
versions of it we had a version last
year we had a kind of an add on external
container i sir the year six months ago
now it's in our core so I believe that
we have a great answer and again it's an
open source project Apache mesas let's
talk about Cooper Nettie's if you're not
in the container space you may not have
heard this and if you're not the docker
space you may not have heard this but at
dr. Khan Google came out with something
called Cooper Nettie's oh there was a
bunch of there was a storm going on at
that point why because the marketing
gave the impression that Google was
releasing their secret weapon their
Google Borg
or they were releasing their new secret
weapon message called Omega if you go to
Google research you'll see Omega is the
next version of the board none of that
was true this is a completely new team
there's no cross team stuff going on I
don't know if that's still true but
there wasn't at the time so it's really
new code but here's some things that we
could we could glean from google I think
they've been doing containers for a long
time they probably have some experience
that we could learn from so there's a
few things that they've added that I
think are really brilliant the first is
they don't tend to run a container
without having a side container by it a
sidekick or a sidecar goes by different
names but a container that rides next to
the primary container so they come up
with a concept that they refer to as a
pod now the challenge with that is that
there's this idea in most developers
heads I think of oh well we bundle
applications together inside of a pot
and we release a pod and that's not what
they do what they do is they have a
primary service which is the container
and I have a sidecar container which
does analytics which has a mount to the
same to the same mount point and reads
logs it is essentially a helpful service
that is helping the primary service what
they also did within the pod is they
they have essentially a land so that you
have an IP address every service within
the pod is NAT 'add out so one IP
address for the entire pod not one for
every container which is an interesting
concept the challenge we have and this
is the biggest challenge in this whole
subject matter is service discovery we
could talk a lot more about it if you
like but service discovery is a real
challenge oh so the challenge you have
in that space is it's not a it's not an
answer for everything right and it
probably works for a great many of
solutions but they have one IP address
for the whole pod and everything any any
service or container within the public
needs to communicate out
be represented by that same IP address
is essentially like ngata in a land
versus LAN environment if I remember
right they give a slant 24 to a note
though and that that level of scale
probably works for a great number of
things but not for all things and so
there's assumptions that are baked into
their solution which which I'm
interested in seeing how that where that
goes I don't I don't know where that's
going to go we are working with them in
that we created a project called Cooper
named asos which takes the Cooper
Nettie's ideas and concepts and puts it
on asos and that would be the pods it
would also be labels so giving labels
where you can say these containers all
have the front end containers or the
database containers or whatever you want
to label things with is just a tagging
system so that's Cooper Nettie's
remember we're talking about the things
that are moving forward right so the
first one was containers I'm sorry
aggregated services and we got into
containers this next one is this change
from monolithic architectures or even
layered architectures into micro
services and if frankly if you pull out
the Java one agenda you'll see that
microservices have hit a high point and
probably not the highest point yet it
will continue my fear is this my fear is
we've done this before except we called
it so at the time ten years ago 15 years
ago whenever it was and we did not do so
well in that space entirely some did
well and almost most of the failing
applications that I've seen in the so
aspace was largely because the the level
of granularity of services was not well
understood it was just all objects on
the bus right and that just is
ridiculous so I think we'll run into the
same problem here with microservices
truly understanding how to architect the
right level of granularity of the
services such that it's meaningful we'll
see where that goes but so what if we
were to start over again where we start
from scratch what would we do so we have
this desire and Tennessee and this need
to give up some control a movement from
on-premise to infrastructure services to
a platform as a service one of the
things i commonly
see and I'm from the Midwest one of the
advantages I haven't be in the Midwest
is I find out what the cool kids are
doing on the west coast I learn it and
three years later I'm really in need in
the Midwest right it's been my career
plan for years now the problem is as I
start I'm not working with the startup
company in the bay area and I don't give
any of that advantage anymore but but
most of my clients previous clients
they're all trying to build a pas
solution inside of their own data center
and what is that essentially it's giving
up control that's something to know when
you go to Haruka which is a great
example of a pile solution you give up a
tremendous amount of control you no
longer have you can't just give an a as
far as domain name is concerned you live
in a global namespace so you give up
some of that control every app that I
know that has scaled successfully on
Heroku eventually fails because their
load balancer is terrible you can pay
them lots of extra money and they will
put you on the fast track right so they
have a solution for you but their basic
solution doesn't work it will eventually
fail so you're giving up stuff to
combine well-known services together and
that's kind of the goal it seems so this
is our goal we're trying to build out
these services what if we hit the reset
button what would we say well the first
is we'd say we want to be lightweight
and I almost hate that term because it's
too subjective and I get it but there's
a huge difference between a vm starting
up in seconds usually in tens of seconds
and a container starting up in
milliseconds there's a huge difference
in a 2 gigabyte image versus a few
megabytes of a container image is a huge
difference in being able to talk to a
container and understand its state
versus not having a clue because it
doesn't talk it doesn't have any
information after you've made a cookie
you don't have any insight into what's
in that cookie any longer all right so
lightweight would be a goal we would
need metadata we need to be able to ask
you things what's your stake why are you
here and in fact one of the things we
start to see in the doctor space is it
build out of metadata beyond
what's included in the doctor repository
and there's good reason for that we need
that information to automate services
all right the other is weak we need
total elasticity so what does that mean
I need to be able to spin up multiple
instances without a human involved I
need to be able to spin it up on any pie
p address on any port and we get into
some really interesting challenges right
well if I don't know where this lands
how do I administrate it that's becomes
an obvious question we'll talk about
that in a second hopefully get some of
these demos I don't think we'll ever get
to the point where we eliminate pagers
but we should be able to reduce it
Airbnb has two different clusters one is
their web services cluster the other is
their analytics cluster the analytics
cluster was built out by the two
co-founders of Mesa sphere so it's based
on macios they have less than one admin
for that entire cluster the web services
side is a typical web services side and
it requires eight admins on that and
then they're roughly the same size
cluster so eight to one I don't know if
that's reasonably comparable but it
seems off enough to question it so we
should be able to reduce ops there's
great value in that i'll show you how
and why the real core again a goal we
would have is to eliminate snowflakes
now I again I don't think you can
eliminate them but they should be rare
they should be extremely rare what's the
difference what are we talking about we
should be able to have instead of 400
recipes to build out a data center there
should be a master and a slave and all
slaves are the same it's all uniform
across the entire cluster whenever I
want to use something I just spin up
into that cluster they all look the same
now there's always going to be
specialized hardware I get it so
occasionally you're going to have
another recipe but it shouldn't be 400
should be more like 10 it should be the
whole data center 10 recipes or less
that should be our goal right the other
thing that we would want is this I would
want to have true elasticity and this is
what i mean by elasticity i want to be
on
hours I still want to do some analytics
and off-peak hours I want to increase
and ramp up my analytics I want to have
full utilization of my cluster I was
lucky enough to be and I conference
similar to this in August and Jill Jill
John Wilkes was there and John's
considered to be the Godfather of cloud
he's the main guy at Google you'll see
his name come up in the research papers
and stuff like that and he showed he
showed this really interesting graph and
shows how much resources are being
consumed by what and then there was
little white bars that were jagged along
the top and his words were this white is
evil and white means that there's
capacity to do stuff but it's not being
done but they want to tap out and use
one hundred percent of the processor
always it's fascinating so that they're
on a drive to do that I think we can
still do better than we currently are
doing on the enterprise and gain a lot
of value out of it because I'm telling
you you're not using your data center I
just know it I've seen too many so that
would be our goal we also need process
isolation we need to isolate I oh we
need to isolate memory we need to
isolate CPU what are the other things
there's got to be able to isolate disk
now we don't have an answer for this yet
and there's a quasi answer but there's
more right if you use like accumulo
Apache accumulo are you use apache kafka
both of those services chew the heck out
of the OS page that they've micash there
they're paging things in and out of cash
constantly at the OS level which means
what it means that if I had a container
that's running one of those services I
certainly wouldn't want more than one on
a node I would want to be able to so
there's the combination of containers
that we want to have like these things
should be close together because I want
to be close to data and then there's the
repelling factor of these things should
never be on the same node I eventually
see this is way futuristic but I reef
way I eventually see almost a DSL of
describing containers and how they're
related I want these containers to be
low latency and these containers really
shouldn't be on the same node eventually
we'll see something like that but that's
that's way out there because nothing is
called close to that today
what and so the whole idea is to stop
shaving axe I don't know if you're
familiar this term but what I was when I
was doing this at savvis one of the
challenges I had as I needed we were
working with chef and in order to use
the latest version of this recipe I
needed Burke shelf in order to install
Burke shelf I had to have a certain
version of Ruby which I wasn't out yet
and I needed Burke shelf I won't take
you down that whole path but it was a
very frustrating two hours and in the
process i did a brew update of a burke
shelf and along with Burke shelf came
openssl holy crap why did I need openssl
i don't i don't know why i needed that
like it was required as part of the
dependency set but now if this was a
production node what just happened I
what's broken what's working I don't
know any of that we're going to
eliminate all of that and in fact this
almost sounds scary talking seeing these
this phrase at a Java one conference but
we'll have write once run anywhere right
it won't matter what version it is it
won't matter what version of Java is at
all because it'll be isolated in its own
container it's a separate thing it'll be
an interesting exercise to understand
when you would upgrade it because if it
works as a service and it works as a
service does it matter I don't know
we'll see what happens because we don't
understand that yet if there's a pain
point here where people are trying to
figure things out it's this what goes in
my ship recipe now well I obviously have
to spin out of an image that includes
Java may include a couple other things
has some roles in it but it's not going
to have anything that's in the container
so the granularity of things at the chef
and puppet recipe level our model level
depending which model solution you're
going with is going to be different it's
going to change oops I hit the wrong
button again all right so stop shaving X
so let me tell you let's let's walk
through a solution with Mesa sphere and
talk about what it is so our stack is
May sews with marathon and it can
completely create a pause type solution
including docker with H a proxy so what
is it it's open source
it scales to tens of thousands of nodes
interesting exercise most environments
that I've I'm aware of that use yarn
tend to fall down around a few hundred
notes they certainly don't go to
thousands we see people moving to basis
for that and back here so here's a cool
thought when you have a Hadoop
environment one of the challenges you
have is you upgrade to the next version
is I almost need to provision a whole
new cluster because it's a different
version they don't play well together
right and the reason you would do that
is I want to compare analytics one
version of version wanda version to
essentially and I need that before I
offload all these things and repurpose
the cluster that was v1 within may so's
we can actually run Hadoop and we can
run multiple versions at the same time
within the same cluster so in fact we
just added the ability to do rolling
upgrades we're assuming you have a tight
environment you don't have a whole
nother set of clusters to go v2 on you
can actually say you know what bring
down ten percent of v1 bring up V to do
a help check on it and if it's good
continue the rolling upgrade so we call
it carried employees but the canary
employees have been newly added into
marathon which I haven't showed you
enough about so let's talk about it so
the idea of may sauce is this that we
take a cluster and we make that cluster
look like one machine what is your
operating system do your operating
system takes a process and it decides
which courts going to run on it's got a
number of course we do the same thing at
the data center level so we are
essentially a distributed or data center
operating system since scheduler is what
it is it's a two level scheduler to be
exact so the idea is not to worry about
an individual machine or VMs now here's
the cool part you can be on VMS we work
in the MS obviously on ec2 we work on
bare metal and you can do slowly to an
upgrade and just consume services as you
will it doesn't matter to us at all
which is awesome so the concept is that
we have a number of different resources
cores memory and disk and just like a
biological system where you have some
in the cell level your real interest is
at the higher level so the aggregate
that's the way we want to look at the
data center so this is what Mesa sphere
does is create one instance Benjamin is
we call Ben is quoted as wanting to
create the ability to create apps for
the data center just like the laptop he
recently just in fact within the last
week it was announced he moved from
Twitter to Mesa spheres who's actually
joined the company so what is mesas the
idea behind a sauce is that you have a
master you have a slave or a number of
slaves and you have this framework and
that's the part that really screws
people's heads up is what is this
framework thing the slave does the
execution and isolation the master is
the coordinator and it coordinates the
met the frameworks so let's let's
demystify that look at the topology the
standard topology would look like we
have a quorum of zookeepers this is an H
a mode like a high-availability mode
right we have a quorum of zookeepers and
a quorum of mesas masters which will do
leader election through the zookeeper
quorum eventually we'll probably move
away from zookeeper but today we can't
there's not a really great solution etsy
d is supposed to take over the space but
it's not it's not stable enough my
opinion so we'll see and then we have
coordination of the slaves if you want
more capacity you just add another note
with a slave on it and it's added you
have more capacity so the idea here is
that I have thrus it three zookeepers
and three masters I have some framework
we're going to just call it marathon at
this point and a bunch of slaves the way
the framework works is that I'm sorry
the way the whole system works is that
the master will offer up to the
schedulers hey there's some there's some
services available our resources
available do you want them and the
framework could then consume them and
say yeah schedule these things on the
slave side the executor will launch off
a task it actually launches technically
a couple of tasks and away you go so
just like when we talk about an OS
kernel it's a great comparison to look
at this diagram here linux and bsd at
the bottom kernel level and we have a
init system or upstart or system d at
the anit level as a programmer you don't
tend to code up against the kernel level
unless you're building drivers you're at
a higher level and you have it ran your
application is run by in a net system
well we do that at a distributed level
we have may Sosa's the colonel and then
we have marathon as the anit system so
the anit system manages it sees events
within the kernel that a failure
occurred and then it decides what to do
with that here's the cool part you can
build your own meaning you can build
your own framework why would you want to
do that well I have some examples in a
few slides so the two core products that
are again are all open source that we
tend to use a lot is marathon for any
long running processes like Java or tom
cat and then another project called
Chronos which does all the batch space
stuff it's truly a distributed cron so
application a batch is dependent upon
another batch is dependent on another
batch all that is managing a distributed
fashion because cron doesn't really work
at a distributed world but Cronus does
that for us uh yeah some some verbiage
is read through that let's talk about
frameworks for a second there's a number
of different frameworks we run with
Hadoop we run with Jenkins by the way
there's a great article out there where
ebay has a build cluster with Jenkins
Jenkins plugin for mesos so essentially
every slave is a build box and if you
want more you just add it so there's a
great story there with Jenkins we work
with Cassandra you can see the list here
spark and storm are very popular it
doesn't exist today but I know I've
actually worked with some people working
on the kafka framework so we'll see what
that looks like in a few months and we
have Chronos as we talk to spark we talk
marathon so marathon marathon is that
place where we can have a service
discovery world this private paas
solution it's not a complete solution
and you know what I'd rather actually
show demo stuff so why don't we do that
so uh let me kill this
get some things out of the way so I am
running a vagrant I did a vagrant up and
then I did a vagrant SSH so we'll talk
about that in a second this is marathon
exposed through that and this is Mesa
exposed to that so i can see that i have
a may so server up I can see the number
of slaves that are out there so there's
only there's only one slave currently
has two CPUs you can see the constraints
that it has frameworks that are attached
well that is marathon that's attached
you can see some of the things that have
been completed in the past and I can see
here that I have one active slave so I
have a general idea of the ecosystem
that i'm in i have one master this is
not an h a mode environment right i have
one master i have one slave and i have
one marathon or or framework running
this is marathon marathon I could use
the UI as you see here which we're going
to do ah let's call this sleep it's
probably fine we're just going to do a
quick command I don't know if you can
see that but it's sleeping and print
something out nothing magical there
right how many instances do you want I
don't know when we go with three and say
create so you can see in this world I
have an idea of sleep I have a command
that's running out there I have three
instances 03 at this point I have one of
three if I click on this you can see
that I have instances coming up to their
started there's a third that started
here's the cool part again just this is
a simple thing just a simple thing at
this point if we lower to Mesa so i can
see that i have three active instances
of things running when it runs yes not
yet i'm driving to docker containers so
at this point i just ran a can I just
ran an instance of something so that's a
great question and it's worth
clarification so at this particular
point i ran a linux command
and that lettuce command lives within a
sea group that is controlled by what I
told it so in this particular case I
think it was point one so i get point
one of a cpu that I'm constrained by
based on C grips yeah I know you live in
a sandbox you can see each one of these
processes right here sleep and get some
crazy grid type names on them right but
there's a sandbox associated with that
and each sandbox and this particular the
case is super simple it's just the
command there's a standard out in a
standard ear all right but check this
out here's what i want to show you
because very few people are aware of
this and its really kind of cool stuff
we just came out with this within the
last month or so and we have some
command like tools because admins like
command line so i can say mesas PS and
it says oh yeah within the cluster and I
can do this remotely like I just it's
just a JSON configuration to say oh yeah
that's the IP address of the master of
that cluster so here I know that there
are three instances of sleep running
within the cluster I have tab completion
on it so i can say i want to tell sleep
tab tab and i get sleep dot nine but
they're all dot nine right or at least
there's two yeah they're all that night
what if i just said a tail on that what
do i get i get a tail on all three at
the same time it just went through the
entire cluster gave me a tale of
standard out what if I didn't want
standard out what if I wanted instead
standard air well I do the tail now of
all three at the same time of standard
error what if I actually knew that I had
a problem with a particular one so let's
pick one let's pick on that one I am now
in the sandbox somewhere in the cluster
where I can go oh yeah what's the LSO
their standard error and stared out and
for this particular example it's too
simple right it's just standard out in
standard error but we have the ability
to from an administrative standpoint to
not know where this thing is at and dive
into it and administrate it and try to
understand it okay so let's back out so
now I'm back in the fifth
i won with doing this work is oftentimes
you're inside of a virtual machine which
spun up a container which is now
building a container and it's like
Inception where you're like where am I
it can be confusing alright let's go one
step further with marathon and say I
want an instance of tom cat now this is
a little bit bulkier and maybe we should
give it some memory and so there's the
command we'll talk through that in a
second and there's that and let's start
it now I have to actually be online for
the downloads to occur but what's
happening well we could talk through it
I need a command that's going to run and
I have a URL down here which what I
pasted in there was a tomcat tarball and
it's going to pull that down and if it's
a tarball or a zip file its going to
auto explode in the sandbox then the
command is going to go through there and
say you know what its standard output is
8080 make an adjustment to the
server.xml file create a new one where I
put in a dollar port what is that well
all containers are in this i'm calling
it a container it's not a docker
container but we live within a sea group
space a dollar port will be a random
port that's assigned to us and it'll
just start there so let's go out and see
if it's up and running and it's not
salute there's a little bit of a
challenge here in that people may be
using the net and I may not get my share
of it all right well you know what
though let's let's save ourselves some
time and let's do this I'm going to go
out to google that makes us that I 0
which is going to tell us whether we are
I have the ability with the services
that we have to create a new cluster on
Google compute
Oh
yeah I used to have that there yeah
we'll see if this can get running before
we before we expire our time I need a
building project for me but for my other
me and we're going to use the big panda
now here's the cool part if you want to
check this out a couple of things first
of all we have the ability to create a
cluster what of whatever size out on
Google compute and we charge nothing for
that so you're going to get charged for
whatever you use on Google compute right
now the Google's offering a bunch of
people using mace those clusters like
five hundred dollars of credit if you
want to hit them up or hit me up and
i'll point in the right direction the
cool part is spin up a cluster and then
use it for whatever you want right they
have no control or any of that but we
literally are just provisioning mesa
master and three slaves in this
particular case guy pick the smaller
development environment we'll see if
this starts up before we finish but
essentially it could take five to ten
minutes depending on things let's go
back over here and see if we're up and
running it I really want to show you
let's ship over here real quick and look
at frameworks oh oh the top get thing
failed maybe that's all right that would
explain a lot huh
me oh by the way scaling things I want
five now and now I've told sleep to go
to five now here's the cool part
everything that we have all of the tools
were looking at mace and marathon they
he'll have restful api stew them why
well if you want help you just go to any
one of them and you say slant help that
will give you documentation on the
RESTful API of exactly how to use it in
this particular case we say get apps
here's how to make the invocation here's
the JSON that will come back if we get
rid of help just for a simple get you'll
see an example of what you get and
that's that we have some JSON it comes
back why well you can actually build
your own monitoring tool on H a proxy
see the number of requests coming in per
second based on the load increasing you
could spin up through a put the number
of instances of a given application and
on-the-fly spin it up faster or meaning
more so a common question I get in fact
which is worth the dressing is what if
can I grow a container can I grow a
container and that's not the answer
that's that's not realize that seems
weird but that's thinking differently
what you really want is because it's
problematic if I said as an offer that
you can have a gig of ram and a half a
cpu if you consume more than that then
I've lost control of my scheduling
capabilities but what's the difference
between one app that grew to one gig or
two apps that are each a half a gig each
so it's not the size of things it's the
numbness of things so we just increase
the number we just scale it to the
factor that you want right and put H a
proxy in front of it have some
front-loaded services what I wanted to
show and we may not be able to get it
let's let's go in here real quick and
I'll just use this as an example if this
were Tom can't running oh go ahead I
keep
yeah let me go out here too again I'm
vagrant environment and I am at the
simple docker so if I do a cat on launch
you'll see that it's nothing more than a
curl post so everybody see that a curl
post of local host and I have to hand it
whatever script I want it to launch so
if I want it to land here is essentially
the simple simple dr. JSON this is what
we would send if you're sending restful
api I want you run this dr. instance I
want you to consume a quarter CPU and a
quarter gig a ya quarter gig of ram and
in this particular case the command is
still sleeping but I'm sleeping now
instead of a docker container so it's
nothing more than saying launch and we
want the simple JSON and that should
have spun up an instance within docker
so there it is it does do a pull against
the docker public repo it is possible to
put a docker config file and use a
private repo if that's what you want
which I would expect you would and now
we have one of one doctor instances
running you see it so now I've spun up a
doctor instance if I want more I say
scale at up to five here's the cool part
now this is just sleeping so it's not a
it's not impressive you know what let's
do this let's go back out here i have a
JSON file which is pulling from local
instead of going out to the net so this
should work right i have a tarball local
and all this other stuff so i just
launched off a tomcat instance you can
see this dollar port being replaced here
so that's a different port I can see top
cat is preparing to run that one should
work let's hope when we look at an
instance I can see that I have a port
here so 31,000 848 is this particular
one people get confused by this but
there is a config which specifies what
port i'm at that's 10,000 that is my
application port the expectation now is
that you would have a load balancer that
would be listening at ten
in this case and take all instances of
tasks that are running and combine those
so you would discover through marathon
the things that you would then load
balanced on top of 10,000 so the load
balancing does not magically happen for
you today although we have scripts that
match that do that we have a H a proxy
marathon bridge it's not a great
solution it works that's what we're
using on Google compute you spin up a
tomcat instance on google compute it
will it'll magically load balance across
all instances the reason why it's not
perfect is because it's using cron to do
refreshes things like that what you
really want to do is listening two
marathons event services and that is
going to be coming shortly so let's see
if we are up and running or not so I am
out of time I will just say that there's
a there's a number of slides here that
we're bypassing but I'd rather show you
a live demo than than anything else
these are the companies using apache may
sews Oh the one thing I did want to
share with you is this why would you
might why might you want to create your
own framework we had a client that came
to us and they are with a hedge fund I
can't bring up names but that hedge fund
takes their agents and if you create an
algorithm that is better than anybody
else's in other words it makes more
money you get more weight as far as
resource allocation on your next runs
for that week so they have a scheduler
that schedules everybody's algorithms
like analytics and the better you are
the more resources you get available to
you some cool stuff right so with that
hopefully there's something of value
here I think the whole world is changing
to containers and it's up to you whether
you want to be bare metal or not but at
fair mental level you gained about
thirty or forty percent utility out of
your existing resources and that's it
thanks
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>