<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Taking a Leap Forward with JavaFX | Coder Coacher - Coaching Coders</title><meta content="Taking a Leap Forward with JavaFX - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Taking a Leap Forward with JavaFX</b></h2><h5 class="post__date">2015-06-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Rl84RyKdyeo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so what we're going to do is we're gonna
spend a little bit of time talking about
how the leap motion works and how you
can use Java JavaFX with the leap motion
and then because we have a large number
of people with excellent demos to show
you we'll spend a reasonable amount of
time talking about or showing you actual
demos of the leap motion in action with
Java effects now because I'm an employee
of Oracle unfortunately for these
gentlemen they have to have the slide
because I'm an employee of Oracle this
is intent not intended to give you a
clear picture of what our product plans
are so because we're using leap motion
we're probably pretty safe that this is
not going to be an Oracle product any
time soon so you've had time to read
that we'll move on now in terms of the
agenda for the session I want to talk
just a little bit at the beginning about
the way that we interact with computers
so the the way that we use the
man-machine interface then we'll look at
the the details of what the leap motion
controller is how it works they're sort
of internals and so on talk about JavaFX
how that works the ideas of 3d
programming with JavaFX and then how you
use java with the leap motion so the api
that's been provided by the leap motion
people and how you actually use that and
then we'll get onto the demos so
starting with the man-machine interface
so it's interesting to see how we
interact with computers so here is how
it all started it's a typewriter this is
really the original man-machine
interface trying to put words onto paper
mechanically and one of the interesting
things about this is that we have this
layout of the keyboard and for what
english-speaking people
the layout is qwe rty and so on
QWERTY there's a bit of a misconception
about one a the keys are laid out that
way some people actually believe that it
was designed that way to slow down
typists because the original design of
the typewriter had these hammers
that hit the paper in order to print the
letter on the page and people got so
fast at typing that some people think
that the arrangement of the letters is
designed to slow you down it's not
that's actually an urban myth it's
actually designed to help you go faster
so it's it's an ergonomic design in the
sense of the way the letters are
organized now sorry obviously as time
has gone by we have the computer now and
so we've made some progress now we have
a keyboard which has more keys on it so
we have a numeric keypad we have
function keys
we have insert delete all those extra
keys and we have a nice plastic feel to
it and then along came the mouse now I
don't know if you saw but Douglas
Engelbart who was the inventor of the
mouse died recently and so there's been
a lot of coverage of the original
invention of mouse this actually dates
back to the first prototype goes back to
1963 and it was developed not that far
from here at Stanford Research Institute
doesn't look much like a mouse today
does it it's a nice wooden box with a
button on it and it's got a connector
which you can use but it really
demonstrates how the way that we can
interact with machines can change
radically before we had this there was
no way of controlling movement other
than using things like cursor keys which
is very unintuitive so now you have this
thing where you could actually put your
hand on something move it around on the
desk in two dimensions and get movement
reflected on the screen screens in two
dimensions tables in two dimensions it's
a very natural way to have interaction
and clearly that's been progressed in
some ways so we now have a nice smooth
feel to it we have a scroll mouse on a
scroll wheel on there there's extra
buttons depending whether you use a Mac
or not I honestly don't know why Apple
insist on believing that there only
needs to be one button on a mouse I
think there should be at least two but
anyway now the other thing is that as
we've seen over the last few years
multi-touch has become a lot more
popular so Microsoft created this thing
called the surface that was the original
surface not the one that they're now
selling as a tablet so this was the
original surface which used infrared had
cameras underneath and then when he
touched the surface it would disturb the
infrared light that was traveling across
the surface and you could detect
multiple points on the table and you
could put objects on it and actually
pick up the shape of the objects and
then be able to map that to data and you
could do all sorts of interesting things
by flipping things across and moving
data from one place to another and
obviously that's become very popular in
the sense of the the typical kind of
tablet interactions that we have now
with the iPad with Android tablets and
all those sorts of things so we're very
familiar with this idea of gestures
where you can take a picture or a screen
or you can use your fingers to make it
bigger or smaller you can rotate it
we're very familiar with the idea of
those gestures in terms of multi-touch
now if you look at gaming gaming is also
driven a number of different interfaces
in terms of how we interact with the
system so who remembers this yes the
Atari joystick good old 8-bit computer
and so this this gave you the ability
now to have a more natural interaction
in terms of games if you wanted to do
something like flying a plane or flying
a ship because it allowed you to move in
a more natural way than you had the
button for fire then obviously Nintendo
came along and they started building a
game controller that was designed to
give you more ways of interacting with
the system so you have this kind of like
little cross for moving in different
directions more buttons so you control
different aspects of the game and we
also have things like the dance pad so
you can put that on the floor and then
you can jump around like a loony and
play a game and interact with this game
in a particular way and then again
Nintendo decided that they would go
there the dated glove very
Rajan's kind of look and feel to it so
that you could actually have some sort
of hand gestures and things like that
and what that's really kind of led to in
terms of games controllers is the the
very familiar gamepad and so anybody
here a gamer right so a few people I
gotta say I find these things that you
watch younger people and they have this
incredible dexterity with their fingers
that can move all these different
buttons and the joysticks simultaneously
and do all sorts of magic things with
this and then I pick one up gonna go and
it's you know it's not quite the same
for me but it does show that you can
create very complex interactions but in
that sense you actually have to learn a
lot in terms of using it it's not a
natural way of interacting with a device
yet you have to learn how to do it and
then most recently it's become more
about gestures so not just the idea of
interacting with a particular device and
using that device to control things but
using gestures in terms of how you
control things so that we really
introduced this whole idea having an
accelerometer in the controller so that
you can interact with games in a
realistic way so if you want to Bowl you
know you can move the controller and
actually swing your arm it detects the
motion feeds that into the game and it
becomes like a real bowling game where
you can put that information in and have
a much more realistic simulation and
then Sony okay took the same idea but
put this kind of coloured blob on the
end of the device so they could also
track it with the camera and give
positioning data not just in terms of
relative movement but also tracking the
position of something in the field of
view of the camera and as we all know
one of the things that's become very
popular recently is the Kinect and
that's giving you the ability to track
people's bodies in front of a games play
machine so now you don't have to hold a
controller you can simply move your body
in the way that you would to interact
with the game and the Kinect will map
the three-dimensional aspects of your
body pick up where your hands are where
your head is all those sorts of things
and feed that into the game
you make it much more realistic
hopefully which brings us to the leap
motion controller because the leap
motion controller is like in many ways
the Kinect
it's about tracking things in three
dimensions but rather than taking the
approach where you stick a camera on top
of the games console and then track the
whole body this is about tracking hands
and tracking your fingers so you've got
much more fine level of control for
certain aspects of games or applications
so it's really sort of the combination
of the connector type of approach the
mouse for interacting with the screen
and things like that and all those types
of ways of interacting with the system
so the basics of the the leap motion
controller is that this is what any
motion controller looks like it's it's
pretty small it's very light it's just a
small box that has a USB port on it and
in terms of the way that you use it you
basically plug it into the USB port it
is powered off the USB port doesn't need
any external power supply there are
drivers for the main desktop operating
system so you have Windows Mac and Linux
unfortunately there isn't a driver at
the moment for the Raspberry Pi
so they don't support the ARM
architecture and the magic is not in the
data that's coming from the device so
the magic is in the driver because I
know people have actually tried
intercepting all the data that's coming
from the elite motion and then try to
figure out how to use that on say a
Raspberry Pi but it just you can't do it
the magic is actually in the driver
rather than in the data coming from the
device and it's pretty reasonably cost
pretty reasonably priced
it's about $80 for the device at the
moment in terms of what you get inside
this thing like I say it is similar in
some ways to the Kinect so what you've
got is set of infrared sensors and
you've got some infrared lights so the
you can basically project infrared onto
something measure the return reflection
take that information feed it into the
magic driver and get information about
what's actually going on a couple of
things about it
one is obviously because it uses
infrared it is a little bit susceptible
not too bad but it is a little bit
susceptible to bright light quite often
what you'll find is if you're using it
in a brightly lit room you're gonna the
message that pops up and says it's
bright to write in it we're adjusting
the the way that it works and in fact
what we're going to do is I'm going to
turn the lights down we'll get to the
demos because I think there is too much
like here and it is interfering a little
bit with the the sensors the claims and
the seems to actually hold up when you
use it is that can track to very very
high levels of resolution so they claim
hundredths of a millimeter in terms of
resolution now I don't know you actually
need that for many applications but it
does show that you really are getting
very fine information and so you can
have very subtle interactions with it
doesn't place a particularly heavy load
on the machine so it's only one to two
percent CPU load so it's not like you're
saying okay you need masses of
processing power and it puts fifty
percent the processor on there and
doesn't require the GPU at all so it's
just taking the information doing some
clever stuff that's the proprietary IP
and then figures out where your fingers
are and where your hand is now from a
point of view the details what you
actually get is the leap motion detects
hands and fingers and what they also
called tools so if you're using like a
pencil for example it will detect the
pencil and it will give you the position
of that pencil if you've got a pointer
same thing it will detect those things
the way that it works is if it captures
frames so you can think of it as so many
frames per second and it feeds that
information from the the driver and the
controller into your application and the
frame really contains all of the
information that the leap motion
controller can actually give you so it
gives you the information about your
hand or hands the fingers associated
with those hands
it also gives you the ability to
tract gestures so if you do a particular
kind of gesture which we'll talk about
in a moment it will also give you
information about any gestures that is
recognized in that frame and there's
quite a complex set of data that you can
get so it's not just about position it
also gives you some sort of his I
suppose historical or temporal data in
the sense that you can see the velocity
that something's moving at as well
so we'll track over time and tell you if
you're moving your finger how fast
you're moving your finger and it gives
you a three-dimensional vector to say
which direction your your finger is
moving in in terms of the the the sort
of way that it works you use these
frames you can set up listeners in terms
of getting the events when a frame
arrives and then processing it and then
as I said the controller is really the
connection between your application and
the controller coordinate system is
pretty straight forward so it is a
right-handed Cartesian coordinate system
which means that the x axis is where
you'd expect it to be so it's left to
right positive being further to the
right the y axis is up-and-down with
further away being positive and the Zed
axis I guess that's the only one that
may not be totally intuitive is so that
the closer you are to yourself that's a
positive number rather than further away
being a positive numbers that's actually
I don't for me I would have thought it'd
been logical to have it the other way
around but that's the way they decided
to do it and I'm sure they're smarter
than I am
field of view it will track up to about
60 centimeters and that seems to be
pretty good so if you're doing something
with the application you've got a pretty
good range of motion that you can use
with your hands it does about 150 degree
field of view in the x-axis so left to
right and about 120 degree field of view
in the z axis so front to back I
mentioned the idea of gestures so there
are certain predefined gestures that the
system will recognize there's the idea
reverb as a circle as the idea of a
swipe there's the idea of a key tap so
if you if you've got your hand like that
you can actually do it
DTaP like that and it will recognize the
the motion of your finger and so that's
a y-axis type of gesture and then
there's also the idea of a screen tap
where you can actually tap by going
forward and backwards there's also some
other things that you can do in terms of
turning twisting tilting so the three
axis for your hand and even making a
fist can be recognized as a gesture so
if you've got your hands expand got your
fingers extended you can then make a
fist and that will be recognized as a
gesture as well and like I say you also
got all sorts of information about the
orientation of your hand the velocity
and fingers and so on so let's talk a
little bit about jar effects some of the
basics of that and also the 3d aspects
of JavaFX
so JavaFX is really the way we describe
it as a replacement for swing it's the
way to create rich internet rich user
interface applications now and what
we've really tried to do with JavaFX is
to look at how people are developing
graphics applications how they're
developing user interface applications
and make it simpler for them to do those
kinds of things swing was was very good
in its time but it had some limitations
and a lot of the limitations were that
in order to apply a lot of effects that
people want to be able to do things like
translucency things like rotations
colors and all those sorts of things
most of the time you ended up having to
subclass the swing classes and create a
new subclass which could then support
those things and that wasn't really an
ideal way if you wanted to provide a
rich set of controls and rich set of
things that you could use so what we did
was we decided okay let's start from
scratch will create a new graphics
rendering engine called prism that takes
advantage of the hardware that people
have in their desktop systems now things
like direct3d on Windows things like
OpenGL
on both Linux and Mac so rather than us
trying to do the rendering through
software we actually tie into the
operating system capabilities the
hardware capabilities of the GPU and we
can do a lot more
with that similarly with things like
media rather than us trying to do
software rendering for media and all
those types of things we use the codecs
that already exist on the system and
that way we can take advantage of those
things we don't have to do it directly
in JavaFX
there's a lot of different things that
go into JavaFX a lot more than you have
in Swing so there's things like charts
that you don't have in swing where you
can do graphs of data you know point
graphs or scatter charts bar charts all
those sorts of things that are standard
components in JavaFX and the big thing
with java effects is that rather than in
swing where we use a container component
hierarchy the way you've got your your
room panel or your window or your frame
and then you add components to that
using a layout manager what we do in
java effects is to use the scene graph
and this would be much more familiar for
people who are used to using
three-dimensional programming and 3d
programming what you have is a directed
acyclic graph for your scene graph
basically what that means is that you
can add nodes into the graph in a child
parent relationship but each child can
only have one parent so if you've got a
button or something in your scene graph
you can only add it to one parent can't
add it to multiple parents and the idea
behind this is that it allows us to do
some very useful things by grouping
nodes together so we talk about
everything in the scene graph as being a
node and so you have this graph where
you can have parents which have child
nodes associated with them if you want
to do something with all of the the
nodes that are in a group rather than
having to do that individually to each
node you simply do it to the parent of
the nodes and it has the effect on all
of the child nodes I mean if you've got
a set of nodes that you want to say
rotate you rotate the parent node and
that will then rotate all of the nodes
in the group similarly if you want to
apply translucency or you know clipping
region all that sort of thing you could
do that simply by applying it to the
parent node rather than having to do
to each node individually and that makes
life a whole lot easier one of the other
things that's very powerful about a
JavaFX is the idea of binding often what
you want to be able to do is to change
values that affect some part of your
user interface and the traditional way
of doing that is to set up some kind of
listener pattern where you've got to
register your interest on something then
you get a call back that says
something's changed then you have to
change that value they didn't have to
call repaint to redraw the screen what
Java effects does is it says well rather
than doing it manually like that let's
use a binding where we say okay let's
say the the size of a circle we want to
be tied to some value so you bind that
value to the radius of the circle and
that way whenever you change the value
the radiuses automatically changes for
you and you don't have to decor repaint
or anything like that
you simply change the value that you've
got and it will automatically update the
radius of the circle for you that can
give you again some very powerful
features the way we do that is through
two different api's there's a high level
API which is really for most of the
situations that you're going to use it
covers all the sort of common situations
that you find in using binding very easy
to use you just say bind and that's what
you get but if you've got a more complex
situation then you can go down to the
low level API and that gives you lot
more flexibility and you can write some
very complex bindings if you want to do
it that way but as I say most of the
time you don't need to do that it's only
if you've got particularly complex
interactions that you're trying to deal
with properties are they the main part
of how bindings work so you have to bind
a property to something in your UI so
you create something like a double
property or a string property and then
when you've got that you can say okay
bind this to something else so if you
want to bind the radius you create a
property and you bind it to the radius
you can also bind both unidirectionally
and bi-directionally so you can save
with one thing change affects that if
that thing changes it affects the the
first thing and you can find out if
something is bound to something
else what that then leads to is the
ability to do animations so we use
timelines to allow us to change
properties over time and that way you
don't have to do like things like loops
where you've got to do you know thread
sleep for a certain amount of time in an
update of value you simply create a
timeline which has a number of key
frames and each key frame has key date
key values associated with it so for
example I've got this little diagram at
the bottom where I'm creating a timeline
which is going to run for five seconds
that's going to have two key frames and
each one at 0 seconds and one at 5
seconds and then I say that the key
values of that are that the beginning at
0 seconds is going to have a key value
of radius of 30 and at 5 seconds the key
frame will have a key value radius is
300 when I run that timeline radius the
property is going to change from 30 to
300 over 5 seconds and clearly I could
put other key frames in if I wanted to
make it just an nonlinear change and
then if I bind that radius to the
property of my circle then the radiuses
will grow over five seconds and that
will happen automatically again I don't
have to register any listeners I don't
have to call repaint it just happens
almost by magic then to make life even
easier for you as a developer we've
taken the idea of timelines and provide
you with some transitions which are
really kind of prepackaged timelines for
certain operations that you want to do
so quite often what you want to do is be
able to fade something out quite often
you want to be able to rotate something
or scale something over a particular
time you might want to have something
travel along a particular path in your
application so all of these have been
provided as like I say prepackaged
timelines that we call transitions and
then you can mix those things together
so you can have parallel transitions you
can have sequential transitions so you
can do say fading out and or fading in
and a growing at the same time so
scaling and fading simultaneously or you
could do
and then fading sequentially so there's
a lot of flexibility in terms of how you
can use these different things in terms
of JavaFX now the thing that's coming in
Java FX 8 which will be part of Java SE
8 but no sorry that's not strictly
speaking true Java FX 8 will be part of
JDK 8 so the part of the bundle download
it's not going to be part of Java SE 8
because Java SE 8 is a specification I
must be very careful what I say so it's
not part of the specification therefore
it's in addition to the Java development
kit what it's gonna do one of the big
features is add 3d support in terms of
the shapes we're providing you with four
fundamental shapes that you can use
there's the idea of a box which can be a
cube or can be any box type shape with
different dimensions there's the idea of
a cylinder there's the idea of a sphere
and then there's this thing called a
mesh view which basically covers
anything which is not a box cylinder or
sphere and then you can specify all the
different points and you can make
whatever complex shape you want in terms
of 3d and these are all part of the the
Java effects scene shape package and the
nice thing about these is that it's a
scene graph remember so when you want to
use these things in the same way that
you've been doing 2d programming with
Java effects up until now you simply say
ok I want a sphere or I want to cylinder
you just stick it into your scene graph
exactly the same way that you would do
before obviously you need a little bit
more information for 3d so one of the
things you need is a I thing called a
foam material and the foam material
allows you to have the the coating of
that object represented in some way now
you can do that as simple as say a color
or you can make it more complicated so
you can wrap an image around an object
or you can wrap you know some sort of
texture that you've created around that
object there's a lot of different things
that you can do with the foam material
so it is a way of covering an object
with a surface or a color or whatever
and it also does smoothing so rather
than you getting sort of lumpy looking
polygon effects it will do the smoothing
for you and you get a much more natural
looking kind of sphere one of the
important things with three-dimensional
applications is lighting because
obviously you need to think about where
the lighting is coming from the third
dimension it's not just a
two-dimensional representation so the
two fundamental things that we give you
in terms of lighting is the idea of
ambient light which is really what you
can think of as being like sitting in a
room where you don't know exactly where
the Lighting's come from so it's just
lighting everywhere and then you've got
the idea of a point light which is where
you can think of it as a spot light and
you can say this is the direction I want
that like to point in and you can
specify things like the the field of
view so how much it spreads out and
things like that the other thing for
three-dimensional programming is because
you're not simply looking at a
two-dimensional space you need to figure
out where are you looking at the the
scene from so you need a camera and you
can specify a camera as being a
particular position in your application
and then you can point the camera at a
particular place so you can see the
different objects in the field of view
there's two different types of camera
there's what's called as perspective
camera which is what you'd expect so the
the field of view spreads out and by
default it's 30 degrees you can change
that if you want there's also a parallel
camera which won't deal with won't
render using perspective correction I
guess you don't tend to use that so much
this perspective camera camera is a more
natural way of thinking about how you
look at things but that allows you to
change that the view that you've got
over a scene so you can move the camera
around to change the way that you would
look at things in the same way that you
would in the real world you know you
think about this room you know you can
move around the room and look at the
three-dimensional objects from different
points of view a little bit about the
the leap motion Java API and how you use
that this is the sort of fundamental
idea I kind of covered some of this
already
you've got the leap motion side of
things and that provides a controller
and the controller will then feed
with frames which contain the
information about what the controller is
actually seeing in order to use those
you register a listener so it's your
classic listen and pattern and then you
can feed that information to your GUI
components your nodes in your scene
graph and you can use things like
binding to say ok when I move my fingers
use the information about where my
finger is to move the position of
something in my scene the basic approach
is to create a controller object so
there's a factory method that you can
call static factory method you then
register your listener to say this is
what I want to be able to do it's
interesting the way they've designed
this because I was expecting the way for
it to work was typically you know when
you use this kind of thing you implement
a listener interface but they actually
extend a listener class which I'm not
sure I really like but that's the way
they do it so that's the way you have to
do it and then there's a method in there
on framing which gets called and that
passes you a frame so you get the frame
and then you can do something with it
you can also pull if you want so if you
don't want to use the the callback
method then you can actually explicitly
pole at certain points and that would be
suitable I guess if you if you're sort
of doing something a bit slower all the
data is contained in the frame as I said
so you've got the hand position the
orientation or the fingers point
positions orientation all that sort of
good stuff in terms of the frame by
frame processing what you get is a set
of hands so it can track different hands
obviously if you've got two hands in the
field of view you'll get two hands if
you've only got one you're gonna get one
hand then from that you can get things
like what is the direction of the palm
of your hand
what is the fingers or what are the
fingers associated with that hand and
then you can process the information for
those fingers the finger is actually a
subclass of pointable so you can either
have a finger object or you can have a
tool in the form of a pen or a pointer
or something like that and what you get
for that is the direction that your
thing
pointing in you get the position of the
tip of your finger you also get the
velocity as I said so it will track
temporal data you can get the length of
the finger the width of the finger and
you can also get how long it's actually
been visible to the controller so
there's quite a lot of information that
you can use and you can take advantage
of that in whatever you way you want to
do in your application handling gestures
I explained the idea you know you can
have circle gestures and swipe gestures
and so on and in order to get the
information from that you need to
basically say okay give me the gestures
loop through those gestures pick out a
particular gesture say what type is it
and then do something with it so you
basically say okay give me the gesture
then do something with it so very
similar in terms of the way you get
information about fingers and hands so
before we get onto the the
demonstrations just really sort of
conclusions and further information leap
motion is is very interesting piece of
technology it does add some interesting
new ways of interacting with
applications I think it will be
interesting to see how it works out in
practice because I've interests to see
what the other presenters say because I
found that you kind of get a bit tired
holding your hand up in the air and then
trying to manipulate things it's it's
not a completely intuitive way of doing
things because also you're trying to
sort of get hold of things in the scene
and there's nothing actually to get hold
of which again doesn't isn't intuitive
in the way that we interact with things
in the real world but it does give you a
lot of potential for all sorts of
different types of applications so we'll
see how that works it has got a pretty
clean straightforward API so from the
fact that like I say the the listener is
a class rather than interface one thing
I did find and I don't know if anyone
else is spot-on or had this problem was
that there's two ways you can get the
list of things like fingers so you can
either get the the list of fingers and
then call get a specific index on that
or you can call give me the particular
finger on that hand and I found that
like if I did it one way it gave
data and if I gave if I did it the other
way it just gave me an empty set of data
guess which way I used first that's
right the one that gave me empty data so
I was like why am I not getting any
information from this system you know
it's like nothing working and then I
tried it the other one it's like aha it
works
but anyway so further information leap
motion comm is a good place to start in
terms of looking at the the leap motion
itself
there's the JavaFX website on oracle and
then jose's got a blog entry with lots
of really good information on the way
that you can use the leap motion I have
a blog which I will actually write a
blog entry about this at some point in
the future when I get back from Java 1
so you can have a look there and with
that I guess let's look at some demos so
I shall go first
right oh good yes so nice now right so
just as I said a simple starter
application what I did was I thought
okay let's let's just have a blank
screen and then as I move my hand in you
can see that I put a purple ball in the
scene to represent my hand and yellow
balls represent my fingers and then if I
move my fingers around we do seem to
still be getting a bit of IR but that's
ok and then if I rotate my hand you can
see that it sort of rotates around one
of the things that you do find is that
because obviously the the device is
underneath the moment you start moving
your hand in in a way the way you sort
of hide things you find that the the
fingers do start to disappear and it if
you join your fingers together they also
disappear as individual objects so that
just gives you a sort of a simple idea
of how you can sort of see the hand in
the field of view right so then I
thought ok let's use 3d and let's try
something a little more interesting so
I've got a cube here and what I'm going
to do is I'm gonna try and pick up the
oh yeah okay I'm gonna restart my
application first
I don't wait does that it's just
occasionally it just stops okay so what
I'm gonna okay we'll try that one more
time oh no oh yeah oh maybe there we go
right so if I if I move my fingers close
enough to the box then what happens is
that it recognizes that as a vector
gesture of picking the box up and then I
can move The Box around hopefully you
know why this is that's right yeah so I
can I can move The Box around using my
fingers and then if I move my fingers
far enough apart it recognizes that as a
letting go this is why I say it's kind
of funny because I'm not actually
holding anything in in the real world so
it gets a little bit tiring after a
while to try and figure out where I
should be putting my fingers in order to
and then the last one that I did I
thought I just thought okay let's let's
take that one step further in terms of
let's put two objects in the field of
view and then what I can do is I can
actually pick up my if I can do this
yeah and then I should be able to pick
up my cylinder and I can get this dead
okay let's try that I'll move that the
idea is that I can move the things
around then I could oh there we go yeah
and then we can stack the two together
because what I was really trying to do
ultimately was to put a game of put a
game of drafts or checkers together so
you could actually have a board and then
you could move the pieces around using a
grasping motion with your fingers but as
you can see you kind of get that
three-dimensional aspect so as you as
you move it around it the the field of
view sort of twists or not twists but
angles things around so you kind of move
it around so anyway so that that's
that's my demo so I'm going to hand over
to Johan so you on three are you
throwing skills I can't make user
interface that's a bit of a problem for
Java vex that's a bit of a problem for
doing something with the leap motion but
I insisted doing something so the
gentleman next to me that have a pretty
user interface skills they told me hey
you on why don't you make a business
application you don't need a nice user
interface for a business application I
said yeah I can do that so I'll show how
you can use the leap motion in a
business application so what we have
here is a something that we will were
working on with La Jolla it's a meme
quest it's actually a quest for best
memes a quest is sort of a question you
can create a quest and the users can add
memes which is actually your answers to
the question I have here I first have to
sign in you can sign in with Twitter
credentials okay I have a quest and the
quest is Jan 1 2014 what could be
improved which have won 2014 as a
preparation are already submitted for
memes for example not only the keynotes
but all the sessions and blah blah blah
should be back in Moscone I'm going to
add one more meme now for example give a
free hotel room for each registration
you'll be lucky that's I think that's
easily done no no that's I think
actually
Oracle is gonna the best mean is gonna
get a reward from Oracle so that's gonna
become reality so now the reason that I
just did it on the website is now I'm
gonna start my Java vex application with
the leap motion it's going to the to the
back end and it's going to retrieve all
the memes there and the goal is you have
different ways of voting on different
means one of the options is well they
can inject some JavaScript in their
website
blah blah blah boring stuff but I can
also use leap motion and then they can
they can use their hand for this is
actually a chav effects control that
unit and charles created so you can say
do you like this or don't you like this
so how many stars do you give so the
higher I move my hand up the more stars
of this so I said for example everything
in Moscone yeah I I pretty much agree
and then did you see yeah the problem is
if you watch the screen you don't see
the gestures of course but if you watch
me you don't see the screen but what I
what I do is I move the head up and down
for thinking about how I can vote also
mark that I move my fingers open because
the moment that I move my fingers close
you won't see no difference anymore
that's because in my application and we
will further proof look at it I check if
the hand is open if I can detect more
than one finger why did I do that
because otherwise it would have be very
difficult for example is it more
embedded to all cases in sessions yes
that's three and then if I want to swipe
that question away if you noticed all of
a sudden it became four stars because I
was still manipulating that that rating
so that's probably a personal difficulty
but it's I find it often hard to find
the tomb up the correct gestures on the
actions especially here we have two
completely different actions one is vote
and second is go to the next one
just voting
is probably not true so this is a mm-hmm
this is the one that I wanted to vote on
the top so you see the we got the
questions from the from the back end and
if we now go back to the to the back end
and it is actually a life I didn't
expect this to to be working but if i
refresh this page you will see give a
hotel room for each registration got
five points because I this is an average
overall this course so this is the
highest score that I gave and this is a
so this is entered by the leap motion
application and feed into the back end
just maybe one minute showing some of
the code behind this as a simon said we
use the we extend the listener and i
also don't like it as it's a class it
should have been an interface we
override the own frame method and what
we do here is we check what gestures do
we see if we have a swipe then we get
the direction of the swipe because if I
swipe in the other direction or up and
down it's not gonna move to the next
meme so we check the direction we check
the speed because if you go too slowly
you probably didn't intend to swipe and
if we detect the swipe there we go we
change the JavaFX property which is
called swiped property and we give it
the the speed with which we swiped I
will immediately come back to that but
we also count the hands that we see if
we eat the leap motion detect the hands
it's going to count the fingers and if
we have more than one finger then we're
going to set another job of X property
which is y property to the relative
position which is here it's going to be
a value between zero and one very
briefly the Y property the job of X
property is somewhere on the model and
if I do find usages then you will see
that this property is is bound to the
waiting control so we have a direct
binding between the height of my hand
and the rating control that displays how
many
stars that are shown finally once you
swiped we activate another thing that's
gonna call that's gonna make a call to
the backend and I have to do some
probably publicity for my session
tomorrow we use the data of X framework
to call into back-end systems from in
from within Java FX so by changing a
property
this call is initiated and the backend
system is tracking the the votes so
that's I agree the layout is ugly but if
you ignore the layout there's nothing
like um you can see that you can create
interesting business applications with
leap motions not only games ok thank you
very much well my demos here are not so
good as it should be but I think I cover
pretty much the basics here I Simon said
before I blog about it a few weeks so
you can find in the blog many of the
things I'm going to show you right now
for starters let's just show a simple
scene with a simple note is the very
much basic thing you can do with leap
motion just grab the worship they hand
position and move a node in the scene ok
one thing I want to point out here is
that if users translate directly the on
frame information to the scene there's
no can move very fast and it give you
about sensation so the way you can do
this better is instead of analyzing all
day on frame information it should be
better if you make a list of 30 frames
finished an and date an average of the
position of the hand for every 30 frames
that way the note should move more
steady instead you get a more better
performance here well this other example
has this average as and you can see the
node is moving quite wait
well this is great making some interface
here so okay here I have two two notes
two hands if I make a click that yes sir
okay I get the position and the
background shadow go to to that position
it's not fancy but just to cover the
basic thing you can do with this in way
of interfacing with your application
so now that Tony balik's here with us I
want to show something I did with his
cool to the engine physics he has so I
have this poem sample from he were using
his his engine so I am very bad at games
and for surely the interface is also
very bad but let me just show how
playing with against a computer I used
my my hand to tilt up and down
I moved the bat and also I can use the
rotation of my hand to rotate it but I'm
very very bad as I say before ok well I
will stick here just leave well that was
easy let me just change here to human
vs. human and this is gonna get really
nice now because now I can use my both
hands so my brain is so limited I can do
it that's when it shows how the human
brain is so limited sometimes and this
technology is over over ass so I will
repeat this because it's very bad for me
well I this I can do this better because
with this demo I just need some dynamic
bodies moving around this thing and this
big ball here just going to move it so
this is just to the engine here working
and I just moved the static body which
is the big pole and interface and
interact with this dynamic bodies here
so for a 2d dimensional two dimensional
game it could be something to start with
but sure this is nothing more than a
basic demo
okay hey we can do more things here and
the last API versions gave a wrench
sorry
rents with if you put your honey inside
these runs you get touch like events so
first artists I tried to find out if I
was inside that that drains or outside
so when I am outside or my fingers are
here are in in purple but what I what I
when I am inside the turn turn into blue
okay so it seems like I could do some
touching events for that I try to hack
this thing way of dealing with touch
events with the open source you can find
in the repositories of their so with
Dreamweaver here I would like to use his
great great 3d guitar I don't know if
it's going to work but at least we hope
we could try to have an idea of what we
can do this is a 3d guitar for surely
not touch the screen it works you can
play and move these cylinders with your
hand just by touching them so now let's
try to do it with our hands in a
touchless way the great spheres here are
out of the right but when I get inside
they should turn into gold orange gold
spheres and if they want but maybe they
don't want now I should be able to touch
the strings and at least try to make
something here but they are not working
so
this will do once a while now they are
not okay I would like to finish with two
3d models I have here I'm working with a
guide who take pictures and then use
these pictures to make a model a 3d
model so I'm going to use a hand from
his colleague and I will use this hand
to move mine and try to make something
like an avatar so this could be
something for maybe some future game or
whatever so you can use your own hand
before you should have has something to
to get the picture from your hands and
model your fingers and your texture
whatever and what for the plant point of
your the Javas thing I'm using here I
would like to point out that the leap
motion controller gives you three
rotations it's gel and roll and it's no
easy to translate them immediately to
the same because you need only one
vector and one angle so you cannot say
okay Pete this angle move this angle
then draw this angle move this angle no
you cannot do it that way
I will show you my final demo is this
one so when it won't be long you have to
give these three angles at a time so for
that we have to make a few calculations
and translate them the rotation matriz
you have for the three rotations okay
now the roof is gone so just let me
please
run it again
as I said you need to try to translate
this tradition might read matrix to a
vector and an angle for that you have to
make some calculations before okay this
is the hovel the telescope is a 3d model
and we are using just the three angles
there the limousine controller give us
to make these rotations available okay
I can put my two fingers and try to make
a circle and when the leap motion
controller detects this cycle it is
spinning in a way in the various first
in the very same direction okay
so I make another circle stop and gives
the way around and so on and they set
distance to the limo motion gives me
also assuming possibility so it's not so
fancy after all but you can get an idea
of what you can do yes by giving the
right mathematical information here just
to give you an idea of what it's what
I'm talking about this is what it's
involved here in a simplified way so you
need yes because there are in fact the
rotation matrix are six matrix
multiplied between them because you have
to also you have to then take in account
the angle of the model before you put it
in the 3d s thing because you have to
make first rotations to put the model in
the way you want and then the rotations
you have with your hands so in fact
there are sis rotations applied at a
time so you have to translate this
matrix to an angle and a vector and this
is the way I I did it but you have to
take care of the signals of the angles
and everything and it's not pretty
straightforward but it works so this is
it
okay so let me see is it working
yeah yeah unfortunately my computer
crashed last Saturday one day before
Java one perfect so the Apple Store just
make a clean install and I created this
stuff this morning in the hotel started
at 1:00 o'clock a.m. and the idea was to
create a amazed maiden of boot with the
marble and then we have to find the way
through the maze and you see where I end
up that's all I could do but yeah I
built him son some stuff so this is a 3d
model made out of boxes so this is in
principle very simple if you created
just in JavaFX but you see this sphere
flying above the the maze and yeah I
needed something like a physics engine
right and 3d physics engine is really
hard to find that's what I found out so
I found one and thanks Jose for their
nice equations because I have to fight
with this stuff the whole night just to
get something working and first of all I
added some textures which is very easy
in Java effects you just create the
boxes and then you create a material we
gave it a texture and I just bought a
high-resolution good texture so it looks
like wood and use the metal image for
the for the ball on top and then yeah I
can also switch on some some Lightning
effects to make it a little bit more
fancy and in the end we would like to
see the physics engine right so we
stopped the rotation and the light and
then let's see if it works
so now I can't control the mace with my
hand and now we give it some gravity so
that ball will fall down and let's try
to get around the yes but you will see
the ball sometimes go through the walls
and it's really these calculations drive
you crazy
but it's gone but I detect that so it
will directly come up again so let's see
do you have to see that it the problem
is you have a 3d engine in the
background which has its own 3d model so
you have to model it twice once for the
JavaFX
drawing once for the 3d model and
unfortunately the coordinate systems are
different which gives me another
headache because you have to transform
between JavaFX coordinates and the 3d
engine coordinates so that was really
tough and it looks so easy right if I
see it now it's but it works right you
see the X that was very hard to do so
yeah that's on it came up with this
morning so yeah that's all
okay so I guess that actually is the end
of our presentation I hope you've
enjoyed the the demonstrations finding
out about the leap motion we actually do
have for one minute for questions so if
anybody's got any questions yes
it's well it's because John riff X just
compile it down to JavaScript which is
using Java effects because Java effects
is just a jar file that you can include
with it so you can generate an applet
the will run with Java effects so Jimmy
okay okay come here hang on so let's
just make sure we answer that question
so what was the Houston I would I would
say it's not a competitive WebGL we're
not really targeting it at web
applications it's more designed to run
standalone it can run in web
applications but we understand that we'd
like WebGL you know you can do all these
things anyway so it's not really
targeted at that I think that's probably
the best answer I can give to that
okay so yeah well I wasn't expecting
this and so I mean I've been working
with a leak motion controller for about
five months now and I've got two apps in
their store the most popular ones out
there one for making music and one for
playing traditional 3d a 3d games with
it one of the things that I realized is
that actually you guys are doing is
actually the most difficult thing
because you're converting a flat panel
which is a 2d representation to a
three-dimensional interaction model
which requires both hand-eye
coordination which is extremely
difficult because you've got the latency
of the screen that doesn't correspond to
the physical motions of your hands and
then you've got the mental model that
you have to translate and that is what
you hear yeah where you try to in 3d
space position your hand while you're
actually it doesn't map so what I think
that's just my personal view on it I
think that these early experiments are
gonna result in a whole new interaction
model where actually the screen goes
away and where you get a whole bunch of
other cues which will probably be a
holographic or which will be auditory or
census or use cues that allow you to
actually just use the world as your
reference with the leap motion
controller yeah so that's just my view
on it and then to respond to one of the
things you said so currently the fingers
move away and that's because they don't
have a skeletal model available yet but
in the next version of the API that's
coming out in about a month they have
totally modelled the entire skeleton
hands and they take into account they
predict what your hand is gonna yo this
is a human hand right as soon as they've
seen that you've got five fingers that
can assume you don't lose one in the way
in the mean time so when they know what
your hand looks like when they detected
us first they will kind of interpolate
when there are little interruptions of
light or detections and they there they
will be stable and you won't have these
flickering little things that you've
seen sometimes here in the demos
something yeah one other thing I'd say
along the same lines because what I
found the bug I fixed this morning was
when I was trying to position my finger
so I could pick this thing up the system
would reverse my fingers so I originally
I'd like left finger right finger and
then the finger data that was getting
backwards then suddenly this was the
right finger in the left finger so I had
to ensure that when I got the two
fingers I always had the the left one
being the one that was further over in
the x-axis so I had to do that as a
little bit of excess that's gonna be
fixed also because the the what they do
now is that basically the list of
fingers is just each finger has unique
ID and the first time it is seen by the
system will get a new ID as long as it's
visible and when it disappears it will
become alright again with a new ID which
huge headache to keep the track off and
but as soon as they map that to the
skeletal model they actually know what
your five fingers are and this will
always be 0 1 2 3 4 and it makes it much
easier to go with that ok so thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>