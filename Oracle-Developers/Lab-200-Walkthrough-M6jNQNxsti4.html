<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Lab 200 Walkthrough | Coder Coacher - Coaching Coders</title><meta content="Lab 200 Walkthrough - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Lab 200 Walkthrough</b></h2><h5 class="post__date">2018-02-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/M6jNQNxsti4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to lab 200 in this lab we'll be
migrating data first using pluggable
databases then migrating data at the
schema level using data pump at the
tablespace level using data pump and
finally using database links to coffee
tables back and forth so let's get
started
first of all let's open up sequel
developer and we'll be creating a DBA
connection so go up to the menu select
the DBA panel so that it's visible and
create a new connection the new
connections going to select the sissie
DB connection enter your password it's
the same password you used when you
created the database and will be cloning
the database the existing pluggable
database which is PDB 1 right now we're
going to really take the defaults you'll
see that it's open in read write mode so
you select it you're right click you
select clone pluggable database we're
just going to keep the database name the
same but we do have to override it and
this is because the sequel developer
developer does not support handling
wallets so add the suffix key store
identified by and then enter the
password alpha 2018 underscore will
apply and you'll notice it's put on the
third line there create pluggable
database Clause and once that's finished
let's just have a quick look at it it's
called new PDB and it's open and mounted
mode and let's have a look at the data
files you see that it generated a folder
name it's a cryptic long cryptic folder
name there we took that default to make
things simpler down the road but we'll
be copying that path so that we don't
have to key that long number in you can
override it and name it but then we have
other specifications to deal with
think the easiest thing was just simply
to take the faults in this case I think
in practice you'd probably specify the
location so we're creating a we're going
to be connecting creating an SSH tunnel
so we've gone up to the menu selected
SSH we did not open port 1521 so we need
to tunnel through to it and that's what
we're doing right now
alpha oh one ad VCS created tunnel we're
already using 1521 in the local database
so we're going to use 1530 we specified
that now we're testing it the test
proves out fine so now let's create a
new connection to the remote target
database we're going to use the sis
account in this case we're going to use
that new SSH connection the service name
is ORCL you notice it's complaining it
needs to be at the sis DBA level test
that connection and connect
okay we're going to have to enter some
commands at this point
a sequel developer doesn't support all
the steps to do with migrating a
pluggable databases you that use
transparent data encryption so first of
all we have to remove the the auto open
wallet that is not supported migration
using auto open and so I'm going to take
the auto open wallet out of the
directory we shut the database down
we've removed the wallet out of the way
and we're starting the database right
back up again so it's not Auto open its
password it's a password key store in
this case at this stage we're gonna
force open the password key store
there's the the path that I was
referring to we're gonna cut cop copy
that into a notepad just to avoid the
the keying issue of course you could
enter that manually fairly easy it's
just that in this case that path was
generated the the directory six four
four three oh seven seven etc etc now at
this point we're just going to use the
keypad so that we can quickly copy and
paste into the several key management
commands that we're going to have to
enter support this so change the the
path there and we're gonna export the
password wallet and we have to put that
password wallet into the database the
database directory that holds the dbf
files because we're going to zip that
whole package up and SCP it to the
target database and well import it on
the other side so alter we're going to
unplugging it now again we're just
copying that path statement on the path
directory and it's going into the unplug
command and I will copy the unplug
command
and paste that into the turmoil window
we're going to do most of this work is
done command line in sequel plus
now we're going to tar that file up so
we're going to change directories will
change to the directory that the
pluggable database the cloned pluggable
database resides and has changed that
directory and now we're going to tar
that file up and call it new PDB tar.gz
and we've got to create a target
directory on the on the target side we
have to create a directory for the new
pluggable database make directory we're
going to call it new PDB of course and
now that we've done that we can copy the
database files over into that new
pluggable database directory so we're
going to SCP the file we the new tar.gz
file that we created we a few moments
ago let's push that into the new target
directory the new pdb directory and when
you take a moment and then we're going
to SCP into or we're going to SSH into
the target directory change to the
pluggable database directory and unto
our that set of files so there it is CD
to the new pdb directory on the target
side and let's unzip that to our
directory directory of files there they
are the DVF files and you know notice
few a couple of other files in there
that wallets in there as well as the xml
metadata file is in there so to plug
that file back in again we are going to
go into the enterprise manager manager
Express in the target side and we're
using a local host we've tunneled
already in lab 100 we've tunneled to
localhost and you need to open it
is it telling because we have not opened
55 now you could alternatively do that
open 5500 but we're tunneling through 55
55 why aren't we using 5500 while it's
used on the local database so we have to
watch we don't clash we have to use
different ports all right so let's go to
the C DB and we're gonna plug this we're
gonna plug in the new file the new
database and it's going to read the XML
file so reuse this source database and
it's that XML file that we created that
holds all the metadata for a pluggable
database now that it's plugged in let's
have a look we have some violations what
are those violations well ignore the top
two they're just warnings but the pdb
needs to import the wallet key so let's
let's do that and to do that we do need
to issue the command again that's not
covered through the GUI so we're going
to open a new command window we're going
to SSH to the target directory the
target database instance and we're going
to log in sequel plus and then we're
going to do an alter session to the
container database new PDB then we're
going to import the keys all right so at
that point go back to M Express let's
collapse that front pane so we can have
a closer look and let's we have to
actually close it and reopen it to
recognize the key that we just imported
so let's do that we're closing the PDB
well let's reopen the PDB using actions
open close PDB and we're going to open
and read write mode that's the default
and let's have a look at the messages
you'll see there's still some air
but those errors again not not related
to our activities here that actually
shouldn't cause us a problem we can
confirm by simply going back into sequel
developer and we are going to create a
new connection to the actual PDB this
time because the other two connections
are to the cdb PDB is the data that was
in PDB was alpha and alpha schema so
let's create that connection and do a
quick query on the data there it is
alpha or 1d VCS let's have a look to
make sure the tables are there and yes
they are so that really concludes the
pluggable database migration the next
cloud migration is at the schema level
if you just want to do a schema level
migration this is actually it's somewhat
more straightforward we don't have to
deal with wallets and keys the first
thing we're going to do is export the
data into alpha exp dot BMP file so
that's what's happening right now
that'll take a few minutes and now we're
going to copy that DMP file over to the
target database and when we go to the
target alpha already exists so we really
need to create a new target schema alpha
to where we can remap this remap it into
that so and now when we do the import we
have to do a remap schema from alpha to
alpha 2 and so there it is there very
very simple process doing an data pump
export import it's very popular
the third is using data pump but at the
tablespace level line again this is for
larger data sets and we're going to
export the schema
but to do and then we're going to take
the tablespace offline because we're not
taking the data out we've only exported
the metadata and not the actual data
take the tablespace offline and export
the the metadata and then we have to
copy the files the metadata which is the
DB DMP file and the data itself which is
dbf files we're copying those over into
the target database now let's SSH over
there we're going to create a new user
alpha archive again we can't have main
clashing so create a tablespace I should
say pretty use your alpha Ark archive
and then import the transportable
tablespace and there it is there alpha
archive tablespace so that's the third
and now the final is using cloud
migration using database links database
links are really handy if you just need
to copy tables back and forth and we
need to make sure our tunnels running
because it's going to be tunneling
through 1520 believe it's 15 26 there it
is there in the specification create the
database link tunneling to referencing
local host on port 15 26 and select the
tables remotely so this is really super
handy to do you can create a local table
as a copy of the remote table just show
you how to do that create table alpha
services stats archive a select star
from alpha services so that concludes
our migration lab 200</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>