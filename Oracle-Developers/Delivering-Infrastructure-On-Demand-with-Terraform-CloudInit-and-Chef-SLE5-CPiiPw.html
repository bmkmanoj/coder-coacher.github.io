<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Delivering Infrastructure On Demand with Terraform, CloudInit and Chef | Coder Coacher - Coaching Coders</title><meta content="Delivering Infrastructure On Demand with Terraform, CloudInit and Chef - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Delivering Infrastructure On Demand with Terraform, CloudInit and Chef</b></h2><h5 class="post__date">2017-08-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/SLE5-CPiiPw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm Jim Khaleesi I am I'm a product
manager at Oracle I my area focuses
infrastructure as a service within our
infrastructure portfolio I spend my time
focusing on our our modern cloud
infrastructure bare-metal cloud in my
role within the the product management
group I spend a lot of time with
customers so I'm sort of customer facing
and listening to customers helping solve
their problems helping them understand
how to use our platform feeding
requirements back into our engineering
team and in I've been in this role for
about a year I've been in other roles
within Oracle and always customer facing
and what I found over the last to say
two or three years sort of my story is
that you know my journey to the cloud in
terms of how I adopted the cloud and how
I started thinking about cloud from my
background was adopted through a DevOps
point of view you know the the the cloud
is an enabler for DevOps when we think
about infrastructure as a service or any
of our platform services really being
API first being enabled to be
provisioned on demand sets you up for
success within the DevOps world so with
that as the enabler every customer that
I've talked to has said well how do we
automate this it's great that you have a
console that's great that you can go
click some buttons and I can you know we
can walk you through the steps of using
the service but that's not how we
operate in our world we've we've been
running WebLogic server we've been
running Oracle database for the last ten
years and we don't do anything we run it
in silent mode we kick it off we spin it
up on demand how do we spin that up on
demand under and on your infrastructure
so that's that's been my journey so I've
been primarily focused on solving
customers problems and helping them
understand how to apply the technology
and out of it what I want to walk you
through today is we'll get you through a
hopefully quickly through some slides I
don't want to bore you with slides and
then I want to get you into a real live
example that I've built the number one
helps me this is sort of how I deliver
demos to customers is how I get
customers started using our
infrastructure and seeding services on
their platform and using a combination
of the technology that Cece here from
terraform as my my orchestration manager
that gives me the blueprint of the
foundation of what my my cloud
environments going to look like I use
chef to configure all of my servers join
a web servers donated databases
configure do I need application tier
whatever is going to be running within
that environment that terraform is stood
up for me and then from an automation
standpoint I'll talk about a few
different options I chose to run Jenkins
for this demo but there's there's a
number of different options you can run
out there and then towards the end and
I'm going to caveat upfront that the
demo is a little bit finicky with this
part but although provisioning the
management side of it I think this is
from one of the lessons that I've
learned over the last few years with
customers have been the the devops world
the ops is sort of like almost silent
right it's the developers are driving
the charge operations are being dragged
along and the the focus on management
tool and how do I actually manage what
I've spun up sort of is the laggard
right it's it's the last in its not much
thought of given so I'm going to show
you within the demonstration a
perspective of using you know one of our
tools so Oracle management cloud to
automatically manage the servers that we
spin up so that's a bit of the
background so that was the intro so 45
minutes
we've only got two sections of slides to
go through about 10 slides I'll keep
I'll keep the quick ultimately what's
the goal
the goal is to deliver something like
this a running on the cloud
infrastructure a virtual network a
virtual network that's configured the
way that we want with subnets with their
dresses security lists software with
firewalls and then within those subnets
the different services that we need to
run bare metal servers VMs containers
databases path services along with
identity audit and an object storage
connected to the Internet through neck
gateway connected to our VPN or
connected through fast connect back to
our on-premises data center so we want
this and we want it to be on-demand
fully configured and completely managed
so this is what we're going to work
towards so so by the end of today's
session we'll be delivering something
that looks like this with a clickable
binding if it all works we'll see the
other thing I've learned as part of this
journey journey to the cloud and
thinking about it from from a customer's
perspective is that so this is a
Developers Conference I mean how many
here are developers hands on the
keyboard every day ok awesome
so you're the new decision-maker so you
hold the keys of the kingdom for Oracle
for AWS for Microsoft Azure the
decisions are being driven from the
developers perspective and that's that's
a positive the value prop right that
we're getting to with this on-demand
fully configured managed environment
right this cost reduction we're an be
able to do things faster and cheaper
risk reduction so we know what we're
getting I mean I don't know how many
times even than building this demo and
figuring out how to configure the server
how many times I did it wrong before I
finally just got it baked in my cookbook
and I could forget about
it that's my favorite part of this
lifecycle is when I finally get it the
way that I want it to be and it runs
right I can just stop worrying about it
check it into my source code control and
just let it be and then the last part I
think that's the major benefit right is
that it's freeing you up from these
details of running worrying about how to
configure WebLogic server or worrying
about how to configure and set up an
Oracle RAC database you can focus on
higher level things within your
organization provide more value back to
your corporation so that's a value but
along with it comes a lot of decisions
and that's what I'm hoping to just give
you my perspective on throughout the
session today how I looked at the
decisions in to be made along the way
right so it's is it one cloud provider
or is it a multi provider option at your
company right when you're looking at it
what are you actually building towards
I've been a number of customer
conversations where you know it's it's
three cloud providers and they're trying
to standardize across all three and you
start the decision point there now is
what layer of abstraction do you go to
what are you building towards right you
end up having to build towards the least
common denominator across all three
providers is that going to provide you
the right level of value how can you
make that decision that drives you
towards which orchestration tool am I
going to use something from the vendor
itself does that drive me towards vendor
lock-in I'm going to look to a
third-party configuration management so
a wide landscape we'll look at some of
the options there and I'll give you my
view on why I chose chef and what the
fit was for me within this world
automation so the delivery you know your
build servers and what that and the
different choices their management tools
again it's it's another decision point
I'm going to show you the perspective of
Oracle management cloud and then lastly
something I'm not going to touch because
I know this is this is not my area of
expertise but I know it's part of the
decision processes development
methodology and how best fit so I think
when you look at holistically across all
of these factors you know this is going
to guide you down your decision tree to
coming up with what
the right suite of tools to help enable
my DevOps practice so let's start with
something that is near and dear to me so
from a cloud provider choice so from the
demonstration where we're starting with
bare metal cloud as our provider so bare
metal cloud fundamentally you know we're
going to build it from the bottom up so
we we talk about our cloud we move have
regions within a region we have three
availability domains so three separate
data centers except through floodplain
separate networking separate power grid
so this provides us a fundamentals to
think about how do I start building hae
based architectures so within a
particular region
I can build a highly available
application to distribute it across data
centers but let the high speed
interconnect between them so I have low
latency so I can do things like active
active databases with active grid link
across data across two different DC's so
from my decision point my decision
process around thinking about what's the
best cloud provider for my practice well
if I look at my portfolio of
applications that I'm running within my
enterprise right h.a becomes is a big
group of them so I wanted to choose a
cloud provider that could that could
that could support that moving up the
stack from a from a data center
standpoint physical networking
consistent performance is one of the
hallmarks of a bare-metal cloud we give
you consistent performance along with
peak performance from a networking
standpoint because of our physical
networking architecture the physical
networking architecture based on an old
pattern basically a an architecture
design from the 1950s out of Bell Labs
so this is something that AT&amp;amp;T proposed
and and we've we've taken we've taken
that and implemented this class
networking design which we completely
fly really flattened the networking
architecture internally within the data
centers so that gives you full bandwidth
between any two nodes in the data center
so within our phoenix region today
phoenix in the united state
we have up to a million computers in any
one of our data centers so imagine the
room that fits a million computers pick
one that's in that corner and pick
another that's in that corner full
bandwidth between them sub 50
millisecond or 50 micro second round
trip time between the two nodes
guaranteed all the time so every
computers turned on everyone is running
their peak end of month end of year
workload you're still guaranteed that
performance because of the the
networking the network itself has non
oversubscribed
this is a differentiator for us so again
each a consistent performance hallmarks
of what you are getting within your data
centers today from an on-premises
standpoint it is yes yes so the part
that you see moving up the stack is the
virtual network so it'll be the first
thing that we define so our goal right
is to build this our application
designer our environment and has this
virtual network so you get a virtualized
layer 3 network here that you're going
to interface with and we can talk about
some of the things that we're doing
different around specifically giving you
some layer 2 virtualization capabilities
at this layer but for our purposes today
a fully virtualized layer 3 network
private from one another so in the what
this enables for me is that within my
own tenancy in my own environment within
the cloud I can spin up one to ten a
hundred like identical environments
because they're all private from one
another so we have same address Rangers
same IPS assigned but in separate
environments so from the DevOps
perspective you know what this starts
enabling for me is you start thinking
about a/b testing Pradas up and running
we've just pushed a change let's bring
it up side-by-side with prod let's not
think about we're not going to take prod
down we're going to leave it up and
running in this second environment we're
going to start
leading users over to let's do some
validation in the cloud it looks good
let's switch it over at the DNS level
and start sending our traffic over to
our second VPN and then we can take our
existing production environment and run
our destroy job and take that that
completely out so that the notion that
the network itself is private gives you
that flexibility that we can just
continually spin up and kill
environments and then within our vcn
flexibility of the services that you can
deploy you know bare metal cloud is a
bit of a misnomer at this point we
started off as a that's our
differentiator right so you can you can
provision physical servers within this
within the cloud edge-to-edge a box
that's yours 36 cores 512 gigs of ram
direct-attached nvme storage giving you
four million i ops bare metal server so
you can you can run and configure
whatever you want on to take the work
that was done you know if you did the
the docker hands-on lab so now think
about taking a docker environment
spinning up two nodes two physical
servers one in 81 182 putting dr swarm
across that so now you have scalability
of 72 pores a terabyte of RAM available
to you to run countless containers scale
it out on demand as you need it
VMs so if you want smaller shapes we can
spin up VMs we provide our own container
service load balancers of servers block
storage object storage database as a
service database as a service gives you
the flexibility to not only provision
single node databases in an automated
fashion
but if Exadata is part of your
on-premises footprint you can bring that
into the cloud so on-demand through an
API fitting the same DevOps practice if
Exadata is is the service that you want
to spin up for your database that can be
part of your your blueprint that you
design
so the question now becomes okay we've
made a decision on the cloud side now
how do we want to build this how do we
want to configure these resources and
across the board you have these options
right I think you know there's at the
very base level is going to be a REST
API every cloud provider has that you've
got that choice at your hands REST API
czar okay you know it's great you can
curl an API you can get a response back
and say look there there's my services
it's there but ultimately you're going
to have to code against that you're
going to have to write a script write
some procedure start this then that if
this fail do something else so it moves
to the SDK layer is that the right layer
of abstraction for you so from a bare
metal cloud standpoint we've got SDKs so
that could be my choice there right I
could say all right Amazon has an SDK
Azure has an SDK bare metal clatters an
SDK we're going to stand it out it's on
Ruby or Python and that's going to be
arm we're going to build our own
configuration definitions there again
there's value there you're going to have
the most amount of flexibility and
control of that layer but we're where
I've seen the number of customers go
where I've seen this space really move
is is looking at third-party providers
and that's what we've done from a
bare-metal perspective we partnered with
terraform early on and we have a
terraform provider so now from a
terraform configuration standpoint I can
plug in my my bare metal cloud provider
I could plug in my AWS provider I could
provide I could I could plug in my dime
DNS solution my Oracle public cloud risk
which has path services today on it all
in one configuration file and manage
that and and manage that within source
code so terraform was the choice for me
when it came to when it comes to
configuration so vendor neutral again
you know moving beyond just API is in
SDKs there are options where you can go
and look at you know cloud formations at
AWS for example but is that going to
give you the right portability and
flexibility if it's a multi cloud
provider solution that's that's the
decision point there one of the things
that I that I learned throughout this
whole process
is that the devops world just loves
overlap of two within the tools you know
I got I've talked to customers where
they said no no it you know we use
ansible for configuration management and
orchestration or we use you know one
tool with another tool and there's
overlap in choice so for me I like the
idea of separating concerns so
orchestration like that terrifies
terraform is a great provider young in
nature but focused on orchestration so
that was the right fit for me
declarative so we're going to describe
what we want I think from a from an
audit ability standpoint and it gives
you the most the best view of what you
want you're describing what I want in
the cloud within a configuration and
that's what's going to be delivered and
again it gives you that and I the the
abstraction from the API so I don't have
to think about it in terms of what's
happening under the covers that's going
to evolve over time I just need to worry
about what my providers giving me in
there's some advanced features that I'll
show you within what I've configured
that we can take this we can take
terraform and make it a bit building
block in nature so there's a there's a
concept of terraform modules if you're
familiar with it where I can manage
different pieces independently for one
another and then import them in
basically into a single environment or
single configuration file on use so
different teams can be often managing
different parts of the configuration
specifically when I think about it from
an enterprise view when we start
describing environments it's you know
we've we've built a team that's going to
have cross-disciplinary skills right
we're going to have server guys we're
going to have network guys we're going
to have Ops guys but from a building the
configuration standpoint it still might
be the responsibility of the network
team or set a set of people that are
going to focus on how do we describe
what the network rules are do they fit
the corporate standard so they can
manage network as a module and make that
reusable across all configurations so
you can drive that standardization in
the weakness
it's young there's lots of bugs I have
spent time reading by you know spending
time on did have looking at issues
reading through issues trying to figure
things out opening issues its but it's a
good team that they respond quickly so
it's just something to think about when
you look at the market space they're the
youngest of the group so there's the
highest amount of churn here so that
that's probably going to aid in your
decision as to is this the right fit or
not and declarative is being is a
positive and it's also a negative
because it's it's finding that right
balance when you separate the concerns
between orchestration and configuration
management you'll see I'm at the end of
the at the end of the slide I have
everything I have published in in
bitbucket so you'll you'll get the links
to go download all the source from the
demo you'll see a few iterations where I
have artifacts still around that were
the first iteration where I was trying
to be a bit more configuration driven
within my my terraform templates and my
terraform files and while it worked in
very simple small cases as the examples
grew and no let's let's now spin up a
you know a docker container and let's go
now
not just do a web logic instance let's
do a tomcat instance in terms of
configuration it just it led me down a
path where the fact that it's
declarative in nature and not procedural
where I wanted to do things like well if
you sent me this bit of data or this
configuration flag then let me go do
this there's lots of ways you'll read
blogs it'll tell you you can do this and
there here's the ways to do it but it's
very limiting and it's going to get
frustrating so I backed off that
approach and I just you know I put my
you know I put my focus on saying this
is just going to describe my
configuration I should say describe my
orchestration my configuration now I'm
this side of the house I moved it into
to chef chef was the choice for me again
procedural nature now I've got a full
coding environment I can pretty much do
everything that I need to the maturity
is there you know I am a I'm a wannabe
coder I was a coder a long time ago so I
don't know how I coded before Google or
was around because all I do now is just
Google examples and chef has about 12
million examples out there so whatever
you're thinking of you need to do in
chef someone's done it it's on Google
and I appreciate all those people in
their hard work because it's made me you
know given me the ability to put
together configurations the other part
that I really that I like about it is
rapid test dev you know we were talking
to what I've got I set up front where
you know the configuration of the server
I'm not a Linux guru Benny means I know
enough to be dangerous so when it comes
to configuring a server there's a lot of
for me there's a lot of trial and error
and from from my laptop using the test
framework with kitchen and vagrant I can
spin up and teardown instance instances
within a matter of minutes and make a
change you know spin that instance up
test my test my cookbook doesn't work
make a change pick it up where I left
off continue to test test test test test
test test
probably got it working publish it to my
repo and then I know it's going to work
with in my production configuration the
other decision point I think on the
configuration side that that I went
through a bit was the idea that cloud
providers either Oracle included we
provide hooks in terms of cloud and Nick
so if you're familiar with cloud in it
it's a it's a framework that runs on
most OS as a boom - we provided on our
rel in on our Oracle Linux instances rel
has it as well so that you can hook into
the the boot sequence when provisioning
server and provide a yamo based document
that says okay configure the server like
this it's challenge for me was I didn't
have very good control over the sequence
or ordering of things so that a lot of
times within the cloud environment
you're spinning up servers you're
creating block storage you're attaching
a block a block storage volume to a
running instance and then you want to go
to that running instance and configure
it to do something install my bits on
that volume and cloud an it limits me
there so then I went through the the
turret of well okay I won't do that
there I'll do some stuff in cloud in it
because it has a nice abstraction from
the OS right it gives me that hook so
everything is basically it's the animal
based running on Python so I don't have
to worry am i spinning up a taboo to
image or am i spinning up an oracle
linux image so it gives me that
abstraction but now I have my code bases
separated I have some things done in
chef or some things done from within my
terraform configuration something done
within within the the cloud init
framework so for me I again I went down
that path sort of worked for me but then
I backed off of it and I said you know
what this is configuration I want all in
one place I want a single I want a set
of cookbooks that are going to describe
how my server should be configured all
in one place
weaknesses its if you're not familiar
with Ruby it can be a steep learning
curve you know it's it's something that
you're going to have to invest time in
to sort of get your arms around and then
once you get comfortable with it and you
start seeing the the potential and all
of the capabilities of it you have to
manage it because it's going to get
complicated you know there's there's
lots of ways that you can manage
dependencies between cookbooks and how
they interrelate with one another so
it's going to become an extranet
exercise and just you know knowing that
you know with great power comes
responsibility
so it's
something that as you build with this
you're going to have to think about how
am I going to manage this properly so on
the delivery side you know for my demo
and for the work that I do right now
I've chosen Jenkins and for me the
decision is is you know it starts from
the perspective of you know do you want
to host a hosted solution a cloud
service or do you want to run this on
your own from an Oracle perspective
right we have developer cloud service
and we have it so you I could have gone
the hosted route and used that service
the reason I didn't for this
demonstration right now and in the
reason I chose Jenkins ultimately was
the level of control that I needed so
from the perspective of invoking api's
and invoking really terraform
configurations on bare metal cloud it
becomes an issue with from a security
standpoint so a bit of detail so the the
bare metal clouds fundamental api
is uses a symmetric key signing so every
request is fully signed so there's
actually there's no way to just curl an
API endpoint within bare metal cloud you
need to actually load a public key take
your private key sign the request so
it's very SDK driven and then ultimately
terraform driven but what that means
then is that I need to have my a key
managed on my build server so I have
within my my tenancy I have an identity
stored that's my my Jenkins my DevOps
identity there's they have their peer
public key and private key pair one
their the public key is loaded and then
I have to maintain one of the private
key and my build server so when I was
looking at where we are in terms of
developer cloud servers developer cloud
service the the build jobs run our spun
up and then they're torn down and it's
an ephemeral environment we needed a
persistent build job because I need my
key always available and I didn't want
to have to go through the process of
loading my key ever
single time you know so I started
putting things in to get that I don't
want and get just so I can pull them
into my build environment on a one-off
basis and then there's other things too
like there's particular tools like I
wanted to have the CLI installed locally
so that I could easily talk to object
storage within bare metal cloud so going
down that path it just made better sense
to me from the standpoint of security
that I should just run this locally I
can load my keys I can configure it the
way that I want I can lock down my
server the way that I need to so that no
one can get to this no one can access
the the Jenkins user key and make calls
to the server it's all going to be
driven through locally but what does
that mean you're going to sort the trade
offs now is that I'm managing it all so
what you'll see within the demos is
going to be a little there's a red box
atop the Jenkins and it says though
you've got an update now I need to go
and manage and install and update my my
Jenkins server and I got that update
like I noticed it's like four days ago
and I'm thinking about this demo and I'm
like I'm not going to make this change
right now so that's still sitting there
and I'm thinking about what I'm going to
apply that change the cost of running
this server you know it's well luckily
for me and the infrastructure standpoint
I don't have any cost my tenancies free
but for you guys when you're purchasing
the service or you're using it as part
of a free trial I have a one chord VM
that's clicking away 24 hours a day or
maybe I could be more efficient and turn
it off at night but effectively you know
the cost becomes the the the thought
point so where I want to get ultimately
is you know there's enhancements comings
with developer cloud service that's
going to give me persistent build
servers that I can load and configure
once I get there most likely I'm going
to take all of the Jenkins work and
shift it there
the last decision point that that we'll
consider before we get into who run a
long time is is the management aspect
and again it's a builder bike I'd say
it's a host or build and manage yourself
so we have Enterprise Manager which if
you've ever tried to set that up I was
never going to touch that
that's a lifetime it takes two to know
and understand that but Oracle
management cloud made a lot of sense to
me
Asian based deployment I scripted
manages part of my my chef
configurations so now I have a cookbook
that says manages it's my manager Linux
cookbook I simply apply that to
instances that I choose to manage or not
and then from there that's just part of
the mix that I want to manage so from
you know from your standpoint is it I
think that's the the number one question
is can you automate it as part of your
server delivery some cloud providers
enable it as part of just within their
cloud experience you just say I want
this managed I'm working internally with
our engineering team to get that same
experience so that my scripted my
cookbook you wouldn't have to run you
just simply through the API call would
say I want this manager or not and you
advantage it with the Oracle management
cloud so that's what we want to get
there we'll see if this works from it
for the demo of course with live demos
and making things work some reason today
I'm saw me earlier I was sitting over
there and I was just headed down trying
to get this damn thing to work because
when it's installing the agent on the
server it makes a call out to Oracle
management cloud and for some reason
today decided to randomly time out on me
so we'll run through some builds and
we'll see what happens all right
so oh you know what
so let me just walk you through what
we'll do here playfully so I'll build
this out so terror forms going to manage
my environment configuration chef
cookbooks are loaded with all of my
server configurations everything's
managing bitbucket so everything is
stored there you'll have access to all
of the source there Jenkins does a poll
from bitbucket
it pulls not only the terraform
configuration it also pulls the build
job itself it's another thing that I
liked about Jenkins is that I didn't
have to you know custom configuration so
my pipeline that I manage within Jenkins
is actually managed stored in bit bucket
as well so I could pick this environment
up I could shift it to another place
another server easily so everything is
checked out and then we apply that
terraform configuration I'm using within
the terraform configuration there's a
chef provisioner so the chef provisioner
is that definition within my server
config is defining you know which
cookbooks should I go pull down from my
chef server that deploys to the cloud
and then as part of that configuration
I'm configuring the the management
console so you'll see my servers up and
running there so I'm going to kick off
the build first and there's my little
red one there so this is my this is hope
you don't see that
and slideshow
okay there we go yes oh I gotta manage
stuff developer cloud service I wouldn't
have to do that so a couple different
build jobs so Web App a build
environment I'm going to kick these off
they take about four or five minutes or
seven minutes in certain cases to finish
so I will kick them off and then I'll
walk you through the artifacts but a so
web app a this is going to kick off this
just spins up sample application on
Tomcat
but it's builds the network it builds a
bastion host it builds the server that's
running Tomcat deploys and configures
Tomcat deploys the sample application
onto it and then I have a cleanup that's
paired with it so it my build pipelines
one of the things that'll come up within
terraform is where do you manage to when
you run a terraform configuration it
generates a state file that state file
is what you use to destroy the
environment to rerun your terraform
configuration to update it so rather
than have that state file stored on this
server where if I lost this server I
would lose the state I wouldn't be able
to destroy the environment I wouldn't be
able to manage it I actually take that
knife I take the state file I store it
within object storage within my cloud so
object storage is replicated across the
three availability domains highly
durable I'll have access to it from not
only my this Jenkins server another
Jenkins server if I spun it up if all
else fails I could just go pull it down
and I could run terraform locally
against against that state with it from
my laptop so I have that paired so when
I after I build my environment I write
the state and when I clean up the
environment I read the state so I'll
kick that off and I also have another
set of cookbooks that I'll build and
install docker it just spins up the
Ingenix web server but within the
similar configuration from the
environment standpoint so what's here so
let's kick off this build job and I'm
logged out
so there's a I / ammeter eyes the bill
job just to take an identifier just so
that when I spin this up when we go look
at the cloud console I know what's what
and then as a last-minute change to
actually get something to run in case we
time out I can choose to run my
cookbooks that manage it or not so it
gets these parameters get passed into my
terraform configuration and that's what
swaps between what I spin out so let's
let's take a shot let's manage this one
so we'll kick that build job off and
then let's build a new let's build a
docker server as well and we'll say this
one's not going to be managed so we can
get to extend a little bit faster so
while those run the first thing it's
going to do is if you actually take you
back really the three stages check out
from the source code repository bring
down my terraform configuration run a
plan against it make sure that I can
actually perform this function and then
we're going to apply the configuration
that's and that's where the work happens
so if we look at terraform oh let's see
I'll make this a bit bigger for everyone
so if I'm late for my web app a job I'm
checking out and I'm pulling this
tommcatt environment definition so
within my configuration file scroll up
to the top a little bit here so we're
defining all of the resources that exist
that I want to provision within this
environment so it's a virtual network
and Internet gateway so this is an
Internet gateway as a concept it's going
to allow me they'll basically define a
route to the public Internet the route
table associated with that gateway which
is saying any IP address for that
gateway can be routed in then I've got a
security list definition so my Bastion
server is going to allow SSH traffic in
so my bashing server is basically living
in a subnet that's exposed to the public
Internet
this is the only host that you can get
to to actually that's going to be
publicly facing that you can SSH to and
I can tunnel through that
to my application layer so my
application layer lives within the
application subnet and it's security
list has associated with it
port 8080 I should take that out but
port 8080 is open actually ocean port 22
here is only open for IP that live
within the vcn so this is how I get from
my bastion host to my to my application
tier over SSH in my use of modules when
I said things are modular my Tomcat
server definition here it's a custom
resource so I'm using my Tomcat server
it's passing in the standard resource
definitions that it needs like the
display name my host name that I want to
use the shape so in this case I'm
spinning up a two core VM if I wanted to
change that shape I could make it a 36
core physical machine and I would have
now that is part of my configuration but
I've been you know my special my my
custom definition here takes things like
a variable that says do I want to manage
this with Oracle management cloud
what's the bastion host and how do you
access it and then you know how do I
connect to my chef server so this has
given me modularity around my Tomcat
definition so that anytime so I've
defined my Tomcat definition now anytime
any development team wants to build or
create a tomcat server they can reuse
that module we want to drill into that
module definition you'll see here this
is where I'm actually now building the
my my resource and then off of that I am
now running chef so we create my server
instance and now on that server instance
I'm going to connect to my chef server
and run this set of recipes against it
so if the flag and this is where again
I'm sort of I'm I'm balancing out the
line here between you know trying to
take a declarative framework and make it
a bit procedural and I
think this is the happy medium in a
sense so I'm looking at if I'm using
count in my variable of manage with OMC
to say if I want it if I said to manage
this one run this set of recipes or
cookbooks monitor server and monitored
hello world Tomcat if not then just run
the hello world Tomcat so that block
would run or not based on that flag and
you know this is choice and preference
here right I could have done this within
the cookbooks themselves I could have
come up with one generic cookbook and
just said you know this is you know
we'll make that decision there but for
the time being it lives right here so
this is this pattern now is repeatable
so you can see here that within my
module definitions I have things like my
database server definition I have my
Ingenix server if you if you go over to
the hands-on lab session that's that's
going on next to around bare metal
you're going to go through and you know
you're going to build this server I've
taken that and I've made it into a its
own module so trying to build up this
repository of observers that I can then
just plug in play within different
network configurations so the thought
process here is that you can now have
you know I'll have my WebLogic server
here and I could have my JBoss server
here so that team can manage the
configuration how to spin it up the
details around it and then make that
generally available for anybody to use
so in another repo that's why I build
pipeline line to cue so another repo
I've got my chef cookbooks so at a high
level which is BMC servers and and again
from my perspective the work sort of
starts here so if we look at my recipes
this is ultimately what my terraform
configuration is running against so this
is these are the recipes that we're
running in so I have this base sort of
if I want a monitor server I'm always
going to run this recipe bootstrap
allows me to bootstrap a cloud
environment with my base configuration
so there's certain I like certain users
on my machine certain package is
installed there's some baseline things I
do around the Oracle management cloud
with proceeding some of the agents that
so we don't have to download them all
time so anytime if I'm going to this is
a one-time run where I'm going to
bootstrap an environment snapshot an
image of that and then that becomes my
custom image that all of these other
environments will use so my terraform
configuration it's always using you know
from an environment perspective you
don't get the the end users who are
creating the environment or sort of the
developers at the top level of defining
the whole environment they're not
actually making a choice about which
shape or which image to run because
we've standardized that and said here's
our bootstrap image this is the one that
were always going to run and use so now
those gives you know that Mazda
modularity is taken to another level
because now I can just plug and play my
different configurations as I need them
on the servers within the different
environments so if we look at monitors
server I'll let you go to bitbucket and
pull this down and take a look at it but
these are just basically it's just a lot
of when we when I sat with you the
management cloud team it's like they
just gave me this this list they said
here run all these steps against your
server this is how we configure the mat
you know this is how you manage an
instance so I just took that and
iterated through it within my local dev
environment coming up with the right
steps the right checks and gates to make
sure that I don't repeat things that
don't need to get repeated and save time
to build up that recipe and then on top
of that we can run hello worlds for our
Tomcat application pull down tomcat
install the management entity so this
death this step here in the middle so
this provision is Java agent so this
gives me tomcat monitoring out my
instance and then I upload up a custom
server XML a custom start script I
pulled out my war file and again this is
just a sample but then here this is your
war file this would be potentially
another recipe that's or pulling out of
source code control the latest revenue
application deploying it and then
starting the service so with all of that
so what do we got you've got
so our docker build environment is up
and running good let's see that would
unmanage let's say you're managing
tomcat see we failed you this is going
to happen so six minutes in so there
what ends up happening is that during
the the script run the time out and
trying to pull the agent down just fails
periodically so from a while that build
fail let me go back we can take a look
so our dock or build environment so in
the bare metal cloud logging into my
tenancy hopefully
from an identity perspective I'm
managing my users locally but this is
tied in to Active Directory so you can
manage your users on Prem I've got a a
Jenkins user so the night Jen Cannes
user has no password associated no one
can log into the console as that user
but they have their private key of their
public key is loaded so that they can go
ahead and actually you know invoke call
so everything from my Jenkins server
comes from this user so this gives me
full visibility from an audit
perspective so my audit service when
it's looking at the logs of what's
happened how servers have been
provisioned things that have been
created and deleted I can I can clearly
delineate ok this just came from my
build server the Jenkins user kicked
that off so we go to my network
environment so that that identifier
London just gives me so here's my London
docker environment network my two
subnets app 1 and bashing one their
associated security list so now I know
that I'm only allowing traffic in on
port 80 and port 7001 in this
environment for my application here and
I look at compute
let's see London docker so I grabbed
this IP
good so
we've got my doctor container up and
running on the management side and then
we're a little bit over here so from a
management cloud standpoint we would
have seen our Tomcat instance here but
I'll show you some other things that are
running what ends up happening when it
when does deploy successfully
from a dashboard level looking at
infrastructure monitoring you know this
doubt can give me full visibility on my
entire enterprise right web servers so I
do have a tomcat instance that I spun up
earlier that's running Oracle databases
that are running in the cloud
I've got management level statistics on
the hosts themselves that you can drill
down and sort of start reacting to and
start you know closing the loop on that
DevOps cycle so you're pulling out the
management statistics now what does it
mean that you know if our if the CPU
ttle ization
of our tomcat instance goes over a
certain level maybe we want to trigger
an action which runs another Jenkins job
that does scale out scale out that
environment added to the cluster when we
see our metrics come back in line let's
scale that environment back down so take
those instances out again following the
same mechanism it's a terraform
configuration that defines what
scale-out means it's it's chef that's
describing what my server should do
within this so I'll have a cookbook and
a recipe that'll say you know add manage
node and that'll do the configuration
that allow me to join the cluster
successfully whether it be Tomcat docker
you know what you name it and then
manage to close the lifecycle here so I
think you guys get all the slides so I
put the links here I'll get this
uploaded
read up on bare metal this is our bare
metal cloud provider but again it's
agnostic I mean all the work that you
saw within the demo here terraform
samples chef cookbooks
Jenkins builds which I didn't show you
but that's what runs under the covers to
drive the automation you can grab and
download and feel free to give me
feedback I'm going to be continuing to
iterate on these any other questions
yeah yes yep so you'll see my recipe so
not that I'm doing anything that
sophisticated here oh this is what to me
this is the one of the values of you
know driving the debbie the decision
towards chef so this is all it takes to
run install docker so dock nervous
default so I imported I'm depending on
the the docker cookbook that's published
made available so create and start
docker
pull the latest Ingenix image run it and
open it on port 80 so you know that's
not much to be done there and same here
for web logic there's a little bit more
here because I've been initially have
been I was pulling from our our private
registry to run the same steps logging
into our registry pulling the latest
image and running web logic but now that
we have it up on the public store or
just getting that work done I didn't
have a chance to get it fully
incorporated but you know you can take
that and have your web logic your Oracle
database automatically provision within
the environment basically three three
commands
anything else all right great
thanks everyone I'll be around the rest
of the day for any questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>