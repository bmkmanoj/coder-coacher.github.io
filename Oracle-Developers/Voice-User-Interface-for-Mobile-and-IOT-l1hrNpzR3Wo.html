<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Voice User Interface for Mobile and IOT | Coder Coacher - Coaching Coders</title><meta content="Voice User Interface for Mobile and IOT - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Voice User Interface for Mobile and IOT</b></h2><h5 class="post__date">2017-07-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/l1hrNpzR3Wo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm going to talk about a few different
things and I looked at the agenda
they're quite different than what you
may have heard today so I basically am a
UX or UI engineer at Oracle and I focus
on a lot of basically heavily I've been
in the past I've been working on mobile
product so in the mobile framework team
working on iOS Android even Windows I've
done Windows development as well but my
passion is in UI UX and I recently got
this device which is Google home
how many people have Amazon Alexa at
home or this thing Google home some
people have it okay if you guys never
had this before or never seen it before
this is what a Google product looks like
and you can talk to it just by saying OK
Google I can't reach the internet right
now so I keep working on the other
connection and try again this is what
happens when it gives a problem this is
what it tells you so so a problem is
that I was trying to connect on my phone
but the hotel Wi-Fi it makes you go to a
web site to type in the password and it
doesn't like that so unfortunately it's
not going to do it but I have video
which I'm going to show and the same
reason what Raspberry Pi was giving
problems so I have video that I'll show
you instead of that so without further
ado this talk is going to be focused on
UI and user interface so if you like
that you hopefully you like what I have
to say and I'm going to follow this
agenda essentially I'm going to start by
talking about voice user interface and
then I'm going to talk about voice UI in
the context of mobile and IOT then I'm
going to show you examples and I'm going
to show you how to do it yourself on a
Raspberry Pi and then we're going to
talk a bit about box where I feel voice
user interface really fits with box
which are becoming more and more popular
now in consumer as well as Enterprise
and I'm going to talk about designing UI
for box or IOT or something kind of this
is like a chatbot it has artificial
intelligence same thing with Alexa and
then I'll take questions
so but if you have any kind of learning
question I just feel free to raise your
hand I love taking questions if anything
stands out in the slide that you want to
the to get curious I love questions and
just ask me any time so really you know
if we think about it why am i talking to
you about voice UI and why is it getting
to be such a big deal nowadays
especially with the advent of Alexa I
would say started kind of the
interesting voice user interaction
started with mobile voice UI which is
which came in form of Apple Siri that
was like the first one and people got
really excited and then several other
companies brought their products in and
their their voice interactions use cases
in the context but essentially what it
solves is it solved the problem of
information overload if you think about
it when you look around in the world
your eyes taking a lot of input I'm
going to actually disconnect this so it
doesn't bother us our our eyes take in a
lot of input if we think about human
brain we most of you probably heard that
we can only do one thing at a time and
it's essentially like a computer what
we're trying to what I'm trying to show
in the left image is that the brain it's
using so much cognitive power to process
the interface you know it could be a
cluttered screen it could be a
complicated in UI navigation and then
but that's not the goal the goal of the
user is to get something done and that
is just in the way of the communication
so voice basically makes things very
simple and and it helps with cognition
information overload a lot of HCI
problems but it also makes the
interaction and overall experience more
personalised and if you really think
about it the way we were communicating
with each other from back in the caveman
days before tack
or graphic or writing or language and
thing was invented it was mainly because
of voice and then came language and then
and then after that evolved into text go
ahead the right basically it's
essentially showing that in the right
picture is trying trying to show
information overload in the in the left
picture the two images are showing when
your brain is freed up from processing
all the interface it can use that power
think of like a computer processor you
you are if you're hogging all this
computer CPU power and memory processing
or rendering the UI then it is limited
in what it can do in in other areas like
networking or our database transaction
that kind of thing same thing with us
we're trying to get something done an
interface is just a medium so exactly
exactly it becomes natural
exactly and a better example is when you
turn on the radio you can essentially it
doesn't distract you you can drive you
may even turn down the volume and still
have maybe have a conversation with
somebody and the music playing in the
background so screens they have a
different kind of they take on in a
brain in a different part of the brain
which will cortex it's it's basically -
one of the dominating senses we have so
it has its use cases I'm not seeing
those screens at all I'll talk more
about it as we build up so you know for
the more scientific people in the
audience this is kind of it shows the
evolution of basically user interface
for the past 20 30 years we started with
command-line interface just we added a
monitored or terminal to a big giant
computer machine and we interacted it by
typing commands you know developers we
still do and we still like the power of
terminal and how we can get the machine
to do anything without you I bothering
us the graphical UI then the next wave
it came along when mostly the smart
smartphone revolution happened
smart screens
and with the advent of the touch has
been there for a long time but again you
know credit where credit is due Apple
with iPhone really introduced a new
language of interacting with the device
which is just a glass and and there was
no essentially haptic feedback like the
takt tactile buttons but we had to learn
a whole new language of touch a pinch
and zoom different kind of gestures were
initially which were odd but then and
now they're part of everyday usage right
that's what a lot of people were like no
I'm gonna use my blackberry I don't like
that because it doesn't have but
essentially what happens is that were
brain learns a new habit and we kind of
get used to it but it was it it was a
barrier it was a very initially and this
chart is trying to go more towards more
what we call natural user interfaces and
I kind of geek out about these things
because I really like UX and UI so I
research a lot Microsoft has a great
document on natural user interface and
here I'm highlighting talk today and
talk essentially I would put that in the
intuitive interaction bucket it's kind
of the borderline and this is where we
are right now future we'll get to
gesture more advanced and sensitive
gesture recognition maybe even voice
based on your tone your the word choice
or I'm in the same mood recognition
machines will recognize that and gaze
gaze is kind of done right now if you've
tried the VR headset have you appear
somebody people tried a virtual reality
headset yeah and the biggest one of the
biggest challenges is how do you
interact with all this 360 content
companies are innovating on touch panels
on the headset itself or controllers and
and I gave a similar talk at Samsung and
I talked about the use case of voice in
VR and AR another topic but today here
we're going to talk more on mobile in
IOT so in mobile the dominant like input
mechanism right now it's mostly keyboard
so there's a lot of typing and we all
know which which has it's a lot of
problems and and not just typing but
also touch and touch
so in if you've done any mobile design
or UI development you know there's a
specification what the touch target
should be on a screen so that fat
fingers or small fingers can still touch
them without touching something else
which shouldn't be there and and it was
a language you know designers had to
learn users had to learn and and still
it's very limited what it can solve
touches is great innovation the whole
language but especially in the context
of raspberry pie things which are Alexa
where Amazon totally took off the screen
there is no screen now how do you what
do you touch so how do you interact with
that thing and voice in my opinion is is
the answer
I think voice is the best option out of
the many many options right now and then
there's of course gaze which is
interesting but I still kind of out
there's a very limited market I even
have a device that I can plug in on my
computer and as I gaze on the screen I
don't have to use my mouse it detects
what I'm looking and I can click on my
hit on my keyboard and we'll make it'll
click on that on that thing but it's
very limited it's mostly designed for
gamers or playing games that they want
to do or something quick shoot something
they just they're looking at the thing
and they just want to be on the keyboard
and on mouse and keyboard and those
things so so one good thing that
happened like I think we were like six
seven years ago what we all started
talking about mobile first and this was
you know when whole of the websites
basically essentially people had
smartphones and now they're trying to
access the content on their smartphones
and webpages were starting to look ugly
or cluttered difficult to navigate
around so there's got Luke Wroblewski
kudos to him he wrote this book mobile
first and I met him and I got a signed
copy every I was in it and I learned the
whole how to design for mobile and all
that stuff but I realized now that this
device or Alexa essentially it takes
away the screen totally so
what he was what mobile-first was
telling us was that cut down to the
essential focus on the mobile screen
first and then let's add more and then
then it becomes a response if so as you
need it so show it to the user so
basically there's different screens for
tablet form factors or desktops laptops
bigger screens which is great but which
still limits your choices and in the in
the picture to the picture we have many
pixels and one of them is white what I'm
trying to say the choices are unlimited
because I can ask it any question I
don't have to see a screen or navigate
to a different screen swipe my finger go
drill down I can just ask essentially
this is like the smartest person sitting
right here so I can ask him or her
whatever this technology is Alexa or
Google now or Siri that tell me when I
go home today how long is it going to
take and what's the best time believe
now I don't have to go to Google Maps
see and see that transit time public
transit or driving and all those things
but I'll tell me because it understand
because it has an artificial
intelligence and I'll get more to that
so so the options are unlimited so like
I said the revolution or at the
evolution of UI voice dominant UI for
mobile kinda took off when Apple
launched Siri in iOS in iPhone 4 I
believe in 2011 and then next year
Google followed with its own technology
Google now Microsoft few years later
came down with its own technology
Cortana and all of these companies they
have SDKs now where you can use their
technology this this engine that
recognizes speech and you can make it do
whatever for your use case for your
application
so Apple has its own theory SDK and
api's and Google has its own and Cortana
has its own but really the big like the
big elephant in the room is IOT and
there's a lot of discussion on what's
the best way to design for IOT for
to fall I owe t such a big elephant and
the reason it's so big right now it's
because primarily because of three
things number one is Moore's law right
the cost of computing has gone down so
much now raspberry pi you can buy it's a
fully powered computer you can buy the
latest one that came out for ten dollars
it has Wi-Fi Bluetooth have any of you
guys played with the Raspberry Pi or
Arduino these are really powerful micro
micro computers actually they're not
even microcontrollers anymore so so
essentially and and there's there are
other laws and in Metcalfe's law and big
data that's it's it's it's listening to
and it's getting better and better than
I would instead of big data I would add
I would I would say artificial
intelligence so this is the latest
Raspberry Pi release so essentially see
this thing costed me 130 bucks or
something
Aleksei the same thing around hundred
and fifty or something like that
but you can create the same exact thing
I've done it at my home you can buy a
board for ten dollars right now and you
can you spend a few other a few
additional dollars essentially you can
buy a USB microphone or are you doing
you don't need to have USB I have USB
but you can now buy a Wi-Fi mic and a
Wi-Fi speaker and attach to it and use
the same technology that Google or
Amazon is using for their BOTS Alexa and
I'll show you in my video and and you
put whatever case you want to put on a
decorated decorated and essentially you
get Amazon echo so you get the same
product but do you kind of you control
it you can customize it now when you add
Raspberry Pi you can you can use its
other pins to do fun stuff like I'm
working on connecting it with a motor
that that turns on and off my blinds in
the morning as I as I tell it as my
alarm goes off so so because it's a
Raspberry Pi in the
much more than just kind of act like a
computer which will run Amazon the like
sonic so so this is kind of like the
schematic diagram that shows how you
would want to set this up so in this
case the PI is connected to a speaker
and the mic because you need those
things for input/output and and then you
write your code my favorite language
happen to be Java so there is the open
source engine called sphinx it's kind of
does speech recognition and it basically
open source technology so it won't it
won't give you the answer like I can ask
this
okay Google even my this thing you know
we can all talk to it what's the weather
right now so right now it's hard to I'm
running short on time but I'll show you
I can do the same thing here but I can
use this API and run it on a light on
Raspberry Pi or if you really want to go
DIY then you can you can kind of create
everything yourself so so basically like
I said you get the hardware it'll cost
you less than 20 bucks and software you
setup you write your code you install
the PI operating system first and then
you download the Sphynx engine and you
open your text editor or you SSH into it
and do it from your Mac lab like I do
and you just write your own speech
recognition engine
so what's things does is that when you
when I say first of all I don't even
have to say ok Google and this is
something I don't like because every
time I talk I want to talk to it I have
to use this word ok Google
well why do I have to why can't I say
Sam or anything
I made it made up make up a word so this
is something like there's a limitation I
think because these are activation the
word or Alexa they listen for and then
it starts recognizing when you're saying
something but you can if you create
something from scratch you can change it
you can give it a personality make it
funny so and I'll dive into the details
of how to do that
but this this slide I want to show you
so on github you can go right now and
follow this guide to set up Raspberry Pi
and they have their setup and it tells
you exactly what to buy from where but
by givin you the $10 one it's even
better and then and then you you if you
have a Bluetooth speaker at home you
don't even need anything you just you
kind of need a mic I use for speaker I
just connected to my TV so I use the
HDMI cable to so it acts like the screen
and also so essentially when you have
this set up you start talking to it and
they have this whole wiki so I've linked
to that and it basically tells you how
to set up a LexA on the Raspberry Pi so
go back here okay
oops sorry I don't want to do that how
do I go into the presence of
presentation though now
okay I guess I messed something up but
we'll just roll with it so I have a
somebody know how do I go to
presentation mode this is Google Docs f5
yeah now oh okay
I tried command enter that worked great
so the four types of essentially voice
interactions you can have one is command
based this is the simplest one this is
like things that you've seen in your car
when you drive you say call Bob it
understand call that understand Bob
probably looks up your contact and finds
that and it gives them a call right this
is the most basic one that's something
you can really quickly set up and so
something like that would be you have
your PI and it could run a Google Voice
API or something from scratch that you
would create and then it interprets that
command so first of all it listens to
the voice and it converts it parses that
and it gives you the text of what it
hurt this is what this open source
engine would do for you and then you
make it do whatever you want to do so
you look for your activation words call
and then you you open your application
and the Bob or whatever you wanted to do
so turn off the light and then you can
hook up your turn off and then you
listen for light and then you connect
your smart bulb so it's like you create
everything from scratch but very simple
these are commands that are you are
issuing the other way to do it is speech
to text which in mobile phone in the
keyboard we all have something like this
or you can just invoke you can invoke
Siri Siri send a message to
so okay I have I have Siri set up here
but right now nothing is working so I'm
just going to roll with it essentially
what I'm saying is that you can you have
the capability right now the API is to
do simply the second phase of voice
interaction with your speech to text
where it will give you the text output
of what you said the other thing is you
also have the capability for the
computer to read out to you so this is
very common in accessibility use case
where an iPhone and Android Windows you
can have these screen readers read to
you the whole screen or an email and
they also have their API where you can
make it read a book or a PDF while
you're driving you kind of create your
own Audio audio agent or audio book I
guess so this is a web app where you
type something and it speaks to you and
then you see the animated face and
whatnot so there's a force accessibility
now you can turn those things on and and
you can turn off your screen and it'll
just read you whatever and you have to
learn how to navigate through in
accessibility mode I guess and then
finally or what what we have right now
is conversational and now you can make
it funny like you can talk about Kim
Kardashian or in terms of box Facebook
has this whole platform where you can
create box and you're having a
conversation with them now you don't
really have to type because you can have
a you can just talk to it and that's
something you would have to create so
and the last one is biometrics which I
call like when we have the agent having
a conversation with this dialogue then
the other thing would become like how do
you verify the identity so this thing I
can ask it to read my emails or check my
email and whatnot and and you can say
the same thing it doesn't know the
difference between you and me but my
phone is connected to Google home and my
Google account is connected to
would so it'll start reading my emails
to somebody else or sending emails on my
behalf because it can do a 10th ocation
right now which is a big big thing in
enterprise application specially how
many people are enterprise developers
here enterprise software ok and rest
like these consumer apps just interested
ok so security is a big use case and for
example customer service right now you
know we have to tell them all of our
details but what if the technology could
detect your voice but essentially
everybody's voice is unique but we just
don't have the technology is not smart
enough to detect you from somebody else
so if it can detect my voice then it
doesn't need to ask my social security
number or my data birth it just takes me
to my account and solves the problem our
people here have so I'm going to go over
Android in detail only if I have people
Android developers here who ok there's
some rest I believe not so let me know
I'll go more detail but in Android so we
have a lot of functionality in the
framework lot of API is to handle voice
actions voice input voice interactions
so essentially right here it's a command
based way to do it so you're setting an
intent filter that's listening for
that's looking for set an alarm and
that'll trigger an app now it could be
your own app that can come up or
androids a native clock app and then and
then you handle whatever the user is set
set an alarm for 8 a.m. and then you
confirm it on the screen so so this is
voice driven but right now if if you
have a phone
you essentially wanna because it has a
screen already you don't want to
navigate and do this on the phone
but you want to show it to the customer
this is just a human interface
guidelines that always confirm it's like
Siri if I use Siri and I'm driving and I
want to send a quick somebody called me
and I can't take the call but I want to
send a quick text message
I'll ask I'll tell Siri hey Siri send a
message to Bob say I can't take the call
right now but call me a half hour and
I'll show me the text could ask me to
confirm this what you want me to send
because if it just did that and there
was a mistake then we'll create more
confusion right
so so we need to confirm that with the
user and you can confirm the individual
way or you can just speak it this is a
better interface so so something like
that you would create your intent filter
like I have here and then you have
system actions such as system Android
frameworks understands when you say
record a video it nodes what to do how
to handle it which app to bring up and
what's trailer for inception but you can
also create your own actions so if i
said 'what's trailer for inception on
Flixster it'll open that app or or you
can have your own app so you can create
you can customize it or let the system
handle it for you so and the other way
other thing Android provides this voice
interaction API where it's more it's
kind of like more free-flowing dialogue
you're having so you can say this is I'm
showing this as a screen but imagine if
there was the screen you could just have
the system shade this thing back to you
so in green is something the user said
book me a taxi and the system or Android
is confirming okay the taxi blah blah
and you confirm yes so you always want
to confirm is to be make sure what
you're doing system as app developer you
want to confirm and and so the voice
interaction API also it has an intent
filter and and then speed to recognize
your API you may want to look up the
documentation for it there are few
classes Android speech speech recognizer
class and that that has a lot of utility
methods to handle basically when user is
talking to the system and it it parses
the text for you and so forth and then
of course you want to remove the diet
the system UI so in this example
the left is something what Google gives
you but they also use the same API so
essentially on the right you can create
your own Google now and you can have a
button that toggles on which means it's
listening and then you can have a
progress bar or something while the
while you're speaking to it and so it
set a timer and then your conversation
ends and then system process it and
gives you response to you so it's a
simple chat bot very very simple kind of
like a hello world version advantages of
using using the mobile platform because
you can all show you how you can do
these things in using cloud technologies
but the advantage is that the system
already has a lot of voices installed
and it also understands different
languages so you can leverage all of
that kind of provide us offline support
your bar can be offline talk to it
because it has a dictionary
it has languages it supports it
understands this is one slide I pulled
out from my VR talk that I gave where I
made the case for voice UI essentially
in n voice it works both ways it's
listening to it and as well as speaking
to it so you're in you can interact in
VR both ways and this is when you hear
sound it's more immersive when you hear
it essentially it's binaural beats or
it's like 360-degree sound when you go
to these fancy movie theatres where you
feel like things are happening around
you because they have multiple speakers
and you can simulate that using this
this class it has these helper methods
where it's system basically Google has
the spatial audio api's in in their VR
SDK the cardboard SDK where you can
create a feeling of 360-degree sound so
it's the other side of voice interaction
other benefits of voice UI just besides
being cool and you know it's definitely
the number one thing is just it's most
natural I say user interaction and big
benefit is for people who are blind who
can you know who already use voice in a
way
speaks to them but and they heavily use
Siri and those kind of things and and so
so it really helps people who are
accessibility who need accessibility
services if you if you start
incorporating more of the voice services
or voice voice interaction in your
application and then there's
internationalization benefits and
because the system can translate for you
so forth also we carry so many screens
how many people I get are tired of
looking at screens their eyes get red
I am definitely one of them so that's
why I love this thing I can be laying on
my bed or whatever and play music or
read me the news and I don't have to
turn on TV see the ads imagine like
listening to a radio music through this
you don't have the pop-ups to take your
attention or advertising but essentially
just talking to you and you can pause at
any time if it and and you can continue
it if it starts to show ads what not so
it's the intelligent form of radio in a
way you can make it that way so how many
people saw this movie heard those who
haven't seen it I would encourage you to
watch this movie it kind of shows you
it's a science fiction it basically
shows that this guy falls in love with
this agent it's an AI agent but all the
interaction that's happening is
basically to a Bluetooth type headset he
wears and he's talking if you look
closely in the scene they have the
screen they have the monitor and he's
setting up his operating system but he
doesn't need that but right now the
interaction that he is he's doing with
the computer he's setting it up it's
configuring it there is no keyboard or
mouse here and the system is talking to
it and speaking and it's asking I use
social or anti-social so the agent is
trying to personalize for this user and
and he basically talks to it it's
detecting tone choice of words so it's
really smart you know because it's a
sci-fi movie and and it's basically he
falls in love with her so you should
watch that movie it's kind of very
interesting to see what technology could
be in next 10 years
now all of these are kind of examples of
Bach so I want to talk more about
blocked and essentially about the word
comes from robot and it was designed to
do this kind of repetitive tasks but
because of engineering we don't we don't
like doing things again and again right
so we write programs to solve our
problems and of course people use it for
all kinds of purposes so you may have
heard of the Google algorithm right
which is a web scraper which is kind of
like a bot but it's it's bought for a
different purpose or we have box that
follow you on Twitter or their BOTS that
send you junk emails and advertising so
these are there are various types of
BOTS a chatter bot or a chat bot is
essentially what's trying to serve you
at like a personal assistant especially
when you add artificial intelligent to
it and it may or may not be intelligent
depending if it passes the Turing test
and but it's basically basically goal is
to have a dialogue with your
conversation like as a human being so
that it can help you with whatever
you're trying to get help with this is a
really fun example I want to show you
this video so this video is from this
company they had nothing to do with the
number one thing girls are asked
warranty is to have a conversation with
Barbie using Wi-Fi and speech
recognition technology now they can
introducing a whole new way to play with
Barbie full of curiosity and bursting
with imagination girls want to learn
help stories and make friends once you
return to the Hello Barbie app select
your Wi-Fi network and enter your
password after initial set up your smart
device is not needed hello Barbie will
automatically download updates and may
restart Hello Barbie listens only when
speech recognition is activated
press and hold the top button down when
you wish to speak wait for the tone then
talk to Barbie hi Barbie and she will
reply yay you're here this is so
exciting oh we're gonna have so much fun
together you can add kill Oh Barbie
questions and play games what do you
want to be when you grow up I want to be
a vet that's wonderful wanting to take
care of sick animals is an amazing goal
hello Barbie can tell stories and shared
joke
see it tells stories it can do
everything it's basically this thing
packaged in a Barbie doll this company
is a toy manufacturer but now are they
really a toy manufacture these to create
Barbie dolls and whatnot right but now
it's like a technology company because
essentially they've created this bot and
it's communicating using voice and it's
powered by artificial intelligence and
the hardware because of Moore's law
essentially the cost has come down so
that you can put a computer in this in
this doll and it can have a conversation
with you just like somebody is actually
there to tell you stories be your best
friend so so all of these things see how
the fit together it's a great example of
their product playtime on the battery
life is about an hour it's left inactive
automat a really great innovation and I
thought shared this example with you so
okay I'm going to go back
and the other type of bots are customer
service so have you a few so again like
whenever I call apples customer service
it's really hard for me to tell if it is
a human being or it is do you guys have
happened that sometimes like you're
talking to it I'll tell you you know a
lot of them they earlier days like the
IVR it is to be this nasty navigational
tree were press one for this - for this
seven and by the end like you're
frustrate you are ready more mad there
and your problem is not solving you may
give up but now like I think Apple
customer care if you call instantly
somebody answers and it says how can I
help you just tell me and it's not a
robotic computer voice it sounds like
human and it felt and you just tell it
what your problem is and try to either
give you the answer or or then connect
you so so they're solving this thing
using artificial intelligence machine
learning in all essentially it's driven
by voice so so and I don't really care
if I'm talking to a human being customer
service agent really or if just it's a
bot as long as it gives me the answer
solves my problem fast as I can get out
of there I'm done so so so this is one
other use case where box and voice fits
really well here is something this is
this has been since last has become
really popular a lot of companies so
essentially facebook Messenger as you
know you can talk to your friends chat
with them right and more and more people
are using their chatting with people
versus sending messages emails or
calling and and of course you can send a
highlighted where you can open your
microphone and it can take your speechin
and you don't have to type anything or
you can even send the audio file kind of
like you can do in other chat
applications what's happened what not so
here companies have created their own
BOTS which in this in this example you
can if you want to buy something
essentially you're having a conversation
a dialogue with this agent
which is helping you to make a purchase
and you don't have to go to their web
site navigate find what you're looking
for you can just type it just tell it
essentially here you're typing but you
can remove the whole screen if you like
what screens are sometimes useful or or
here you can just you can you can talk
to it and transcribe the text for you so
how would you build something like this
there are a lot of technologies out
there to build chatbot a lot of services
so I work at Oracle and if you guys saw
or were at the Oracle OpenWorld
conference last year saw one of the
keynote Larry Ellison showed a video or
showed a demo of live interaction with
it using a chat bot and so I'm not going
to say anything else about it because I
don't work in that team but I know the
company is working on it actively there
are other companies IBM are doing stuff
with Watson and you can use their
technology to create box Google has
their own bought services they bought
this company API dot AI Microsoft has
their bot builder SDK Facebook
essentially provides you the platform
where you can serve the Box to many many
people who use Facebook Messenger so
there are many services out there what
you may want to look at or if you're
building your own service is something
that solves that is in the top quadrant
if it is if it is the green one
generally I guess the best way to go
basically how in my opinion it's going
to evolve is that will solve
domain-specific problem so bot would be
just for retail example I showed you
Macy's or whoever now it only it has a
limited understanding of its store of
inventory the prices deals and it can
only understand things that you're
talking in that context so that's how
it's going to end then there's going to
be bad for you know your company's
solving your problems what over it in
the end will have something like this or
Iori where we don't even have to do that
but we can it just kind of be one one
thing for everything and you can just
ask it to shop for you I'll shop tell
you the deals you don't have to invoke
different box and or you can use so
that's the hardest problem it's a a I
problem it's the hardest one because it
has to know about everything it's really
hard to do that other things the
rule-based systems are easier to build
so they are charged to the various
platforms and ap is out there right now
more coming every day these this is the
bigger ecosystem and more frameworks so
the key is you want to have the contact
setup so that so that with the problem
you're solving is limited so in an IOT
device when you have sensors you can you
can detect what to use where the user is
location based sensors or sensors
detecting gestures and camera face and
other kind of things it makes the
dialogue it makes the agent more
intelligence of the dialogue can be more
meaningful patterns error-handling is a
big part so something like when I was
talking to it it kept saying I can't
connect to the Wi-Fi this is like
handling an error right like well it's
not in a very good way so what if your
bot doesn't understand something like
the customer asked its what what is the
price of this thing now it may not have
any data it's how do you respond you
can't just keep it silent you have to
give some kind of smart answer that you
hear when you talk to Siri doesn't know
I'll give you a smart like a quirky
answer so it's just the fancy way of
handling errors in using voice they're
of course they're educating privacy
challenges that we all need to keep in
mind and these are just three rules that
I found really funny and interesting on
Wikipedia finally the user privacy is
keep concerned because in the end we
don't want the situation where everybody
is listening all the time and asking for
our data and then the user is left
screaming like where is my data but
everybody else has it about him so so
what I want to do is quickly I only a
few minutes you can ask me more
questions over twitter email me this is
my contact information happy to answer
any of your questions regarding bots
voice user interface or any of any thing
in mobile UI you're doing I wanted to
quickly show you a Raspberry Pi demo
that I wanted to share live but we're
going to show it right here okay first I
want to show you this video
okay Google put a full screen so watch
listen I'll explain you what is
happening so this is my home myself a
Google what is the volume level this is
this thing all you need a level
so here I have I'm working on Raspberry
Pi and I have my terminal and
all right here's the music on google
play music I don't know if you heard
that but I got so excited at this point
because what happened was I'm running a
simple Linux script it took its called
East bigoted to software basically it's
like in that you have something in the
terminal as you type say hello blah the
computer will speak to you so what I did
here was that's okay Google does Google
now this product it listens to my voice
what I was wondering if a machine can
talk among themselves so right here I
have this program running on Raspberry
Pi and I have connected my TV which
gives the audio output and I type what I
wanted it to speak so I just said sorry
the volume is low it says play music and
this will listen to it and I'll start
playing music so it's like I was talking
about privacy and security
I didn't say a word generally you should
listen to me cuz I'm the one who's the
owner the primary music
and then what I do
Liang Shan
I typed here it's really hard to see
stop music the command and this program
was was left very fine will you speak
that
and it stopped so it said stop okay
Google what is the volume look okay so
that's one example I wanted to quickly
show this video this is where I set up
Amazon the Lexx on my pal exa tell me a
joke how many cats does it take to screw
in a lightbulb
really you see tasks are going to do
that Alexa is it gonna rain today no
reason can't insist so okay go back here
this is I don't know if you can see can
be shut
dim the lights it's really hard to see
okay I'm gonna if not it's okay I'm just
going to point out under my TV if you
see that red light that's the Raspberry
Pi that you can buy for $10 and I've
hooked up a USB microphone and I'm just
with my phone I'm taking the video and I
can turn off my TV TV is just showing me
the program where I click on it starts
listening but I can use a wakeboard so I
don't need a TV I'm using TV also for
the audio channel output because I work
on the TV on my IOT device so so that's
what it's doing but I'm running Alexa
and it didn't I don't have to buy Alexa
I could have done the same thing for
this but I wanted to wanted to test this
product what they what they do so I just
bought it but you can create your own
thing package it however you like and
place it wherever you want to place it
you see here you can see this this agent
is Alexa and it's the same thing that
you would get when you get echo so
that's and then maybe I have a picture
yeah you can see this is like on the
side where I've hooked up and you know I
could put it in a fancy case and right
now the cables are also powering the
power but I could use a portable battery
so I can put it wherever and all it
needs is Wi-Fi so that's my talk
I'd love to take any questions I have
links to more resources in my slides
where you can there's a really good book
designing for voice by Laura Klein there
are other resources where you can learn
about creating your own box and more on
voice interaction any questions I'll
take a few questions if you have any I
know we're out of time
frameworks slide this one yeah there are
a lot of them I would say I would
suggest I work at Oracle I should say
but we haven't released it right now but
go out and play with them there they all
have free version free trials so yeah I
would say check out api AI I think it's
one of the simple one to set up Google
bought that company but they still have
their website and everything so yeah
play play with that is really cool
yeah so this is my contact page I think
we're out of time
so I'll be hanging out here please come
to me ask me anything
if you like the talk let me know if
you're not what I'm happy to take your
comments and questions thanks again for
listening to me and hope you enjoy the
conference</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>