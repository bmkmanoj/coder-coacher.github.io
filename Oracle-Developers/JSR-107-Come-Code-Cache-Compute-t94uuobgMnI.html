<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>JSR 107: Come, Code, Cache, Compute! | Coder Coacher - Coaching Coders</title><meta content="JSR 107: Come, Code, Cache, Compute! - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>JSR 107: Come, Code, Cache, Compute!</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/t94uuobgMnI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so this is a cell 107 talk it is a
tutorial so it's two hours and there's
only about 30 or 40 slides so there's a
lot of code so if you're at the back you
may struggle to see just just a warning
there also thank you for coming for the
salt first JavaOne talk of your session
so merchants so that is a you know puts
a bit of pressure on me to make it good
but I'm gonna be doing live live coding
so with all the in trouble like that but
that may cause so if anyone sees any
errors if you ever sat up here and done
one of these things you cannot see an
error when there's a problem which is
obvious so that it shout out if there's
any problems that you can see that are
obvious that I can't see as I start
panicking when it stops working
so this is around jsr 107 so come code
cache and compute so basically we're
going to look at yeah are you waving for
me was it a question
no all right okay let's say it's
interactive just raise your hand and
I'll if I see you I'll ask you to ask a
question it's quite a large group she
said she just turned it down to 68 that
is hot in here
and I'm up front so so we're basically
going to cover the J cell 1 is 107 API
so 107 was went final at some time early
this year and time escaped me and it's
been going for like 10 years there's a
huge gap in between where it's not just
languished and died really so but now is
final it's targeted it was targeted for
Java EE 7 but missed it so it's now
targeted Java 8 I'm on the expert group
to be fair probably a minor member of
the expert group and all the work was
basically done by you know Greg look
and Brian Oliver at the knee at the end
there's a lot of people taking over this
group in over the period of time and so
this this is basically to just take you
through that API from basic caching
through to go looking at more advanced
features like events and computation on
a date greeted so this is all done on
oracle coherence which has in 12 1 3 has
a 107 compliant api and i also tried
this out on the latest hazel caste which
isn't out yet
which sports chairs are 107 and the code
was fairly portable i do to submit sorry
do some problems in hazel cast
interpretation suspect but in liaison
with me they're sort going to get ironed
out before they go GA on that as well so
we'll dive straight in like say if you
want to ask questions just show okay so
what is Jess our 107 as I said it's got
very low number so it's very old spec
that's been hanging around it's official
title is the Jake at Java temporary
caching API so that does what it says on
the tin as they say in the UK so what it
does is it provides an API for caching
objects but it provides a bit more than
that it provides I say events and
computation and it's not a Java EE
specification it's a Java specification
so all the stuff I'll be doing isn't in
an application server it's just raw Java
code in JVM so question really is why do
you want to catch okay there's only one
reason that you want to cash out cache
data not necessarily only one reason you
wanna use a data grid but there's only
one reason that you want to cache data
and that's latency okay if you don't
have latency in your system you don't
need this API fundamentally if you could
access data you know incredibly fast
speeds and there's no need to cache it
if you
pull it from a database in sub
milliseconds as no point cashing the
data so latency is defined as the time
delay in requesting an operation and it
being initiated typically that will be
in enterprise applications that's going
to be date or access so if we look at
latency so if you accessing data over
over the network these are typical
latency sorry typical through ports of
different network technologies so we're
looking at 1 gig Ethernet fully utilized
probably give you 25 30 megabits
megabytes a second 10 gig office it goes
up by 10 InfiniBand maybe give you 6
gigs per second so that's fast it may
not be fast enough for what you need to
do and then if you look at network
distance never mind raw throughput then
these are typical ping times which I
sort of tested while before my last
presentation so you know local on my
piece on my laptop is 57 microseconds
right through two if I want to ping
somewhere from the US from the UK is
about hundred milliseconds so you know
you may have huge throughput on your
network but the latency to access some
data so when you go get from some
resource then it could take up to 100
milliseconds if that resources is across
across the planet
so again network distance impacts your
latency so that's when you'd want to
look at caching the data closer to where
you use it and then if we look at disk
based latency then typical got agreed
that typical disk speed so if you go
into fibre channel isotope was right one
gigabyte second and that's single thread
throughput that is your Mac so if you've
got multiple processors then it's going
to get split between those multiple
processors and a typical
top-of-the-range SSD maybe give you five
40 megabytes a second maybe geek
nowadays went before I threw out this
slide so again there's only a limit to
what you can do
and then when you go into ddr3 memory
then now let's do about 12 gigabytes
second and the difference of our memory
is that memory tends to be pretty
parallel so the more cause the more you
split your numerator texture then the
access to memory is split across
multiple processors so you can get
throughput at that rate across multiple
processes so all I'm trying to say is
essentially that depending on the
technology of where the data resides
gives you your latency if all these
things were you know terabyte terabyte a
second then this API wouldn't be
required because you access this data at
any speed you want and you would need
you would have no latency so just take
away from that is essentially is that
memory as fast compared to any other
access of data and therefore the only
reason you want to use caching is to
cache data remembering okay Bank don't
know about that that's because a lot of
people look at caching and they throw it
into architectures and it's only there
for latency so when you've defied you
have a latency problem then you start
looking at caching api's so we'll dive
into jsr 1:07 jsr 1 sounds actually a
very small spec you wouldn't believe it
from the many years that it's taken to
get there but it's actually very few
classes in it at the keynote that we're
talking about how much effort goes into
an expert group and and it's not the
code that comes out at the end that all
the time spent the time is spent and
debating what the API should look like
so essentially this is our hierarchy of
classes that we have in JSON 107 so at
the very top you have a caching provider
that essentially is like a product like
hazel caste reference implementation or
coherent then with that caching provider
creates cache managers which we'll go
into a little bit each cache manager
then has many caches
and each cache effectively has cache
entries which are key value pairs so
this is a key value API
so like I said so cashing provider
managers cash managers Kalina cash
managers essentially a configuration
it's basic configuration of the product
and that provides methods to four
different your eyes to define identify
different cash managers and the cache
manager managers caches and it creates
and destroys caches and then the cache
contains your objects pretty simple so
we're basically going to start looking
at how you actually use this API so what
we're going to do is let's say you're
using an oracle coherence so if you're
brave you can potentially follow along
I'm basically going to build the whole
applications up from scratch from the
raw NetBeans so if you've got oracle
coherence on your laptop or you need to
download it you could you could do that
like so you may struggle to see code at
the back I'll try and zoom it up as much
as I can without it been unable to edit
it so we're gonna create an application
that uses oracle coherence and we're
going to it's going to be a distributed
cache from day one so we'll create a
write will create a cache nodes we're
going to create a process that just
fires up on oracle coherence cache node
and then we're going to write some code
that gets an object from that cache and
a different process that puts objects
into the cache so these are going to be
three different Jade so basically Java
processes so these aren't Java EE this
will just be straight Java SE
any questions for I dive into code yeah
the okay the question bars can you
define an in-memory cache or distributed
and replicated that will depend on the
caching provider so for example a
reference reference implementation is
just a straight at min memory cache
whereas coherence hazel caste and others
will provide replicated and distributed
caches and that will become that setup
in the cache manager so that's where
you'll provide a configurations specific
to that product so okay so I've need to
set up a little bit so so we're going to
basically dive into some code on
NetBeans or move over here okay yeah
it's gonna be tricky in it that one that
one's on can you know okay
so I have to drive to laptop so bear
with me okay so we've got a clean
project here I've obviously got one that
works as well and just in case it all
goes horribly wrong so we've got a clean
project the only thing you need to do in
here really is set your libraries up I
know it'd be quite difficult to see at
the back but essentially we've got we've
only got one library which is coherence
twelve on three that includes a J cache
API within it we've also done something
in the run settings so again I can't
read on that but it basically just tells
coherence to set the cache up as
partitioned but their specific coherence
thing to set okay so it's just a minus T
which says to run when you run something
to run it in a partition mode and that
create a distributed cache so across
multiple machines with a data
partitioned across multiple JVMs so the
first thing we're going to do is
actually create a object to actually
store in the cache so to create a new
Java class I'm going to call it stock
because everybody does you know
financial examples for caching
okay so try make this bit bigger I know
you want bill to read at the back and
freight
okay so we're basically going to create
a straight POJO which is going to hold a
stock object so because it's a
distributed cash it needs to be
serializable
extends what am i doing okay
influence but yeah it threw me off there
like I first bit code wrong so it's
going to have a double which is a price
and a string which is a symbol
they sing go be the best code in world
so we'll create a constructor rail crate
bunch of getters and setters because
obviously you like to break
encapsulation straightaway and then we
create a to string as well okay
yep plus a shrunk it down so I could see
red lines three difficult matters and
it's zoomed up okay so we got this
something we can actually put in our
cash
we're now going to create a cash piece
of code that's going to basically start
up coherent so it's going to be a cache
server effectively but it one of a
better word so if you look at basically
create the class that the class that
starts that that thing up this is
basically essentially that will have the
standard bootstrap that you will need
for any J's r107
application
Center create a new class just called
run cache server
okay
I mean sorry zoom in started create a
create a mane
okay the first thing I'm going to do is
do basically use the caching provider
and there's a utility method in json 107
called caching which provides a bunch of
so boilerplate for a bootstrap sort of
methods so it has methods to get the
caching provider but based on the class
loader so you can scope classic cache
caching providers to class loaders the
default method which we're going to use
basically looks for a Java service that
so looks for a jar that contains a meta
in with a specific file
well entry in it so I can show you I can
remember where it is
mm actually can't actually no I do it
eyes look in the wrong place so I
basically show you the coherence jar and
how it works out basically how JSON 107
works out that it's coherence and it
needs to bootstrap so in the coherence
Drake a char in the minute in services
there is a specific entry that's defined
in a specification which is Java X dot
cached or SPI - and provider and if you
look at that that basically tells
basically tells it to what is the class
of the caching provider essentially so
that is coherence based cache and
provider so so that basically gets his
coherence in a sort of standard way
without having to put in coherence code
so that's a standard API we then
basically the cache manager
okay so in that hierarchy show you a
question provider which is a product
we're going to get a specific cache
manager there are a bunch of parameters
to that which are a URI which can be a
that's could be your I to a
configuration file for this specific
product which will tell you how we want
to configure the cache manager and again
a class loader which will be the default
class loader for loading and storing
objects into the cache manager and
properties if the product needs
properties well we're just going to use
the default and then I'm going to create
a mutable configuration so the API can
be a bit long-winded but it's basically
a configuration of the cache so there's
a lot of generics as well so it's going
to be the cache is going to hold string
stocks it's going to basically hold key
values stock objects keyed on their
symbol
okay so that's configuration object
okay
and then on the config is basically
where you can set some standard J's are
107 configurations so we're going to set
store by value so that basically tells
the cache that it should be storing
objects by value run by reference
hence it needs to be serializable and
it'll use the class loader that if you
define a scope it to a class loader to
do that and because we're having a
distributed cache you can't obviously
store by reference because it doesn't
make any sense because it may be on a
different node store by values actually
the default but put it on there so we
could talk about it then you can set the
types that the objects going to the
cache is going to store you don't have
to but it gives you compile time sorry
runtime checking the case another class
another program put the wrong classes
into the cache obviously if you use
generics it's going to get compiled time
checking but if you specify in the
configuration you'll get run time check
as well because this is a distributed
cache you don't know what other
applications are accessing it
then we're essentially going to set
management which will create jmx for us
they're also set statistics to being
able to be true to so that we can look
at the statistics so it will have
management and monitoring they still
built in to jsr 107 is part of the
standard and now what we want to do is
actually get our cash
so we're basically going to create a
cache we call it J 1 2014 so a cache has
always got a name we'll give it a
configuration so essentially that will
use the configuration that we've set up
there
and that's essentially it to bootstrap
JSL 107 so I'm just going to put this
into a loop because we want to create a
caching node that runs all the time
okay so that's it essentially that's
going to create a process that
bootstraps coherence and get and creates
a cache within it called j1 2014 so
we're going to write separate programs
to put and get from that cache so I'll
try and run that the demo God's work
okay so you can see that that's now
bootstrapping coherence which is pretty
verbose and it's bootstrap but
essentially it's created a cluster of
itself and so this bit here basically
says what the number of members in the
coherence cluster so this is going to be
coherent as a clustered cache so it's a
big distributed hash map respectively
and it's got currently got one member in
okay
and what I'll do is if I run a second
one you'll see them join together so
this time run a second server so we've
got two JVMs together create in a
basically a clustered cache and you will
have seen here when it boots spec spat
out its cluster configuration you can
see we've got two two members in the
cluster member one number two and the
other two processes I've just run now
okay you can also see messages like
asking member one for primary ownership
of partition sets and this is
essentially coherence balancing where
the data is across the two different
nodes okay so
but any questions on that yeah
multicast okay so it by default here
it's a multicast each other okay you can
use well-known address or something like
that to discover each other but this
one's just multicast
sorry but the next line they go yeah
yeah
but is whatever it stops the process in
exiting basically all of them that in
there is really to stop yeah otherwise
it'll just end and then it will come out
the cluster so no knows whatever your
application does to stay running
basically that's just yeah it's just
there to stop the JVM exiting okay so
basically we're now going to write a
class to get stuff out of the cache
sorry I couldn't hear sorry yeah this is
all just JSON 107 code there's no
proprietary code in this so it work on
any provider yeah I can make it to
download later yeah okay so so we'll
create is a simple piece of code to get
data from the cache so effectively this
needs the same bootstrap as the cache
server because it's it's effectively
just a another node in the cluster
they're all most sophisticated things
you can do with client server but where
these each process we're going to when
we start one of these caching processes
it's going to boot up and actually join
the full cluster as a full cluster
member not ideal but it's good for
demonstration so the get code will do
the same what the mean is
he this yeah I'm gonna create I'm
creating the I'm doing now is creating
the client which is in a different JVM
yep yeah cuz really boring showing
memory cached so right so my my get
simple kept motes on my code that's
going to bootstrap drawing the cluster
get the data route
it's basically look the same as that
that cluster note code because it is
essentially just another cache member
so what we're gonna do is get an object
out of the cache and print it
so on the cashier obviously got cash yet
and we've got some others which I'll
talk about later
so we basically print out from the cash
we'll get just resume in a bit people
comes back and see okay so basically
that line there it's gonna just get get
an object out the cash pretty simple key
value store and we'll print it out and
then we'll basically close that clash
cashing provider which will then close
the caches cash managers and the caches
so if I run that so bootstraps it joins
coherence and print out no because
there's nothing obviously in the cache
okay yeah
oh so different okay so if I go back
yeah so essentially I've got one JB I'm
running as a this is a little basically
crate and distributed cache so we've got
one JVM running holding the cache data
I'm creating a new JVM to get the data
out the cache you do and what no yeah
it's a bit the beginning is just the
bootstrap so that's bootstrapping the
percussion provider so you will need to
do that on a different JVM you would if
it's the same JVM you won't need to yeah
it's cuz this is separate process
I'm in this way he's depending on the
caching provider to get out at J&amp;amp;D I
threw in a Java EE situation or things
like that yep
toy can you say that again okay in this
case it's gonna get a chunk of
partitioned data cuz I'm doing a very
simple code so you'd need to set up in
coherence you need to set it up as a
client server so we have for you a
client of a server-side cache if you see
what I mean this is just a full cache
member of the cluster okay so now we're
gonna write the code that basically put
something in it
so essentially is just a cash dot put
the key and a value which is our stock
okay the wrong hands
okay so it's just cashed output
obviously I'm making this a little bit
more complicated will different JVMs you
could just be obvious just write cash
stop what gosh not get in the same line
of code you know in the same main but
it's I think it's not as interesting
okay
so it's gonna break what happens there
okay that's Cassie Fiza cashing provider
so that's basically closing the question
provider when that happens that will
close the cash managers that the cash
money providers cashing providers
managing and then from that they cash
manager will close all the caches that
it's managing so it's like cascades down
through that hierarchy we saw before I
just be nice it could just exit a JVM
yes I think it is
sorry in a normal you want to create it
once yeah I mean one thing if if we've
got that cache manager again they had
you can just get a cache it has already
been created you get it rather than
create at each time in fact if you're in
the same application in the same if I
did create and then create again it
would actually give me an error in the
same application yep
yeah you'd only close it when you finish
with it okay cuz it basically it's
creating you know a hole if it's
distributed cache to create the whole
connectivity to the cache and provider
bill I did it you know JDBC or something
okay we've got later on there's a
section about annotations so I'll come
to that then okay so this is basically
going to put an object into the cache so
if I run that they won't do anything
other than bootstrap coherence because
it hasn't got any prints in it so but
now to that face East are tied up bump
them into the cache and finished if I
now run the get again
we can see that that JVM starts up and
gets the object out the cache okay
fairly simple stuff
all that red stuff that's coherence
dumping a load of info log messages
sorry but it's yes just in folks just
info log messages no it's a distributive
cache partitioned so it's living on one
node not all of them but you could
configure coherence to be fully
replicated but that's not in the API
that's in how you set the cache manager
up I was going to do that okay hang on
actually so currently you'll be sat in
this server you know I run the cache
server before so it's sat in there at
the moment what I can do is if I run a
second one maybe we've got some
redundancy so that's just running a
second cache server you can see it's
asking someone for partition set so
that's whether two servers are
negotiating if I run that again we
should be able to get the object there
we go briefly saw it so it still got it
if I then so we go around the bottom of
here so I kill the first server it's not
dead now okay so that's finished
I remember I get again basically the
date is still there okay so it's
basically filled over to the other node
and coherence
by expiry yeah I don't cover expiry in
here it's their expiry set on the cash
man and cache configuration default
values infinite yeah so yeah it's not a
per entry expiry it's per cash it's per
cache yet so there's nothing in the API
other than when you could do the I'm
going to bring the code back up it's on
this configuration when you set the
configuration you can set expiry yes it
basically something they're called set
expiry policy factory okay so the API is
and that basically you can set your own
expiry policies classes
okay no you can create I mean mix it
comes with a bunch of default expiry
policies where you can create your own
so you basically give the configuration
expiry policy factory which creates your
object and that will determine you know
what your expiry policy is but it comes
with like infinite and timed what basic
time ones as default you can create
multiple caches with different expiry
policies yeah yep
no thinking either reference
implementation in your class path so
it's a separate jar file yep
yep so all the all the stuff above that
there is boilerplate stuff really so
it's just that
yeah this distributed cache so that's
creating the connectivity to the
coherence cache called j1 2014
so it's joins the same cache is one big
cache across all the processors and so
it's got the same name okay yeah when I
come to listeners I love a look because
I can't remember going there and one
more good no over here sorry
these exact same variations and servers
is there any way to differentiate yeah
that depends on the caching product
caching provider so in coherence you
could set it up in lots of different
ways and you could set it up as client
server so they're not using these JVM
memories but it's all that's all product
specific stuff it's done when you do get
cache manager there you've got a URI is
one of the parameters and that can be
that's whatever it you know the
percussion provider wants that to be but
that can be a link to a configuration
file which is like hearing specific or
something like that which would then set
up all that cache manager how the
product wants it okay so better move on
yeah it's just info logging whatever you
do set up and your logging will get rid
of it I put it on here
so that you can see it okay so that's
basically that is the API for getting
put I won't talk through that again
so there are other methods obviously on
the cache that you can use but it's very
very map like methods essentially so
there's replace which will do the
difference between money got these
methods is that each one of these is an
atomic operation so replace will do you
know change the value of that key in an
atomic operation rather than if you did
it get a sorry if you did a I get an
apart
separately there'd be two different
locks resistors it in one single lock
and replace a lonely replace if the
object is there otherwise you just do
put there's remove obviously which moves
the key
there's get an put which essentially
does a put but also gives you the old
value back as a atomic operation
there's get in replace which Center
replaces the value and returns the old
value back as an atomic operation if
isn't if there's nothing there I'll
throw an exception because you're trying
to replace as a virus but whereas put
will put something in there as an old
key let's get in remove which removes
the key and gives you the value that was
in there and then the final one is put
if absent which will put a key in there
if it wasn't on there already and if
there is one there I'll throw you an
exception and then there's a next letter
that's not and then there's a delete all
and for all and get all which is bulk
operations you're back first
difference between pot and replace
replace will throw an exception and get
this right if there's no value there
already it's in the API is an optional
feature
Wow
you have to go into the trunk it's an
optional it's an optional feature that's
pet transactions so you have to look at
the product and whether its support
transactions no there's no a lock API
okay
I'm gonna dive carry on because I'm
gonna do an hour I'm gonna go on then
now there's a remove and then there's
removing get getting removed getting
removed returns above you because you
might know because it cuz it distributed
cache it might be expensive to actually
bring the key back the value back if you
don't want it you know you just want to
get rid of it because it gonna go up
across the network okay so that's simple
cache we're gonna look at events so
events are core to the API and what
these allows you to do is put listeners
on caches today why there isn't it there
is an expiry one and and then basically
you you you subscribe to events that
happen on specific keys so the basic the
core interface is a cache entry listener
and then there's a bunch of sub
interfaces that you implement for
created expired updated and removed and
in addition to that you can put a filter
on that as well so if you don't want all
keys and that's your specific filter you
create a filter subclass and that'll
filter events essentially before they're
delivered because as well see in the in
there when you start writing the code
this is this is in potentially
distributed cache so therefore could be
expensive to send events across a
network but you're not interested in so
that's useful to reduce the network
traffic when you get into large-scale
distributed caches network is typically
your your limiting factor how much stuff
you're flying around the network and so
things like filters helped reduce that
and the next thing we'll do after this
which is entry processors reduce that
even more so we're going to write some
events code this is what we're going to
set up so eyes before we're going to
have a single server node running so
basically it's not in specialist just
another cache that's not doing anything
and that'll store the data effectively
but then they're going to create a list
a class that register
a listener for a specific key so the
pikey
and then we're going to run a JVM which
keeps updating that key and we should
see it receive events across the network
essentially okay okay
OOP
okay so basically going to create a
class called price ticket that's just
going to push random updates into that
key
again it's just gonna be straight Java
class and it's separate JVM so we have
to do the same
bootstrap stuff
so in the loop we're just going to put
object on that key because before with a
random number for the price that's
probably an accurate model of the market
okay so that's basically that's like
that's how a simulation of a stock
ticker feed okay on this particular
stock
so what gonna do first I'm gonna see
what's running
just going to kill everything just to
make sure it's clean then I will let you
run my cache server again don't actually
have to do this I'm just doing it it
doesn't it's not necessary to be there
the stock ticker could actually work on
its own because it each one is it as a
equal member of the cluster and then if
we run that because that will basically
run continually playing updates onto
that key okay not really exciting where
you should be able to see if we use the
get so obviously without events you're
gonna have to do polling with a get so
you can see that time it was fourteen
one five five nine if I run it again on
the get this is running the get it's two
point two eight okay so you can see that
it's without an event you have to keep
polling obviously wouldn't need to keep
starting up a new JVM but you need to
keep polling the cache to get updates so
now what we're going to do is create a
event listener which will listen on that
key to get updates
okay
so I'll create a new Java class actually
no one take click create first is
actually the listener rather than the
class that attaches it to the cache
so this is going to implement the cash
entry updated listener because we're
interested in updates
all right I'm just that's why it's not
coming up thank you
okay so there's lights and there's
different sub interfaces we're
interested in updates so we're going to
implement cache entry updated listener
and again its generic so it's a scoped
to the types that we want
so the method we need to implement is an
updated which has really scary generic
syntax for me anyway
but we're going to do when we get an
update is we are going to print it out
so we need to get an iterator because
basically you get an iterable as your
input because there may be you listener
may be registered on many keys some of
you many events could do and the codes
not like that now don't throw me
only it is wrong
awesome
yeah I know I went for old style
okay so ya know why I'm an old style but
that's what's on the sheet so that's
what I gonna do okay so basically
iterate through the events you've got
and print print out the stock values I
got that we got sent
so they'll battle billion base in the
updated value in the cash shrink its own
sleeves any errors think it's okay okay
so now we're gonna write the class that
basically joins a cluster adds this
listener on to the cash and then sits
there
which is essentially that's gonna be our
stock ticker class the listener because
it may have to get sent across the
network into other nodes and attached to
their cache nodes so depending on the
product
sorry
can you say that again its core of the
coherence commercial sorry it's Oracle
yeah yeah very much commercial okay so
this is basically going to this class is
the one that's gonna join the cluster
register the listener and then listen
for updates so we need the same just you
know
so we we need the same bootstrap stuff
in the main to join the cache during the
cluster
okay so all that stuff above is the same
as for all of them so that's just you
know bootstrapping JSI 1:07 so we need
to set up a basis in an entry listener
configuration which is a very long class
name which is mutable cache entry
listener configuration we saw again
building a sentence and a class name
good question no idea they might just be
cash empty listen configuration this bit
is very long-winded there's reasons
which have mainly technical provider
reasons which is this stuff may happen
across the network so you need factories
and things to create the configurations
and they all need to be serializable
so it has to go through a factory
because it may be getting created on a
remote node
so stop listener is the one we created
before
miracle okay so some of the
configuration set on a listener is
whether you want the old value back or
not when there's an update whether it's
a sink or a synchronous so with
essentially in the same thread as the
update occurred or not so that's so we
have a that's hence hence we have the
configuration class yeah is fortunately
that's the configuration of the listener
actually so you'll cut and paste it I'm
sure
well is there are spring maybe so
actually the register is just pretty
simple it's because you don't actually
create the list me you need a factory to
create a listener because the listener
may not be on your local node it may be
remote and the product may need to do
some stuff so it's hence that's what
happens when you go through expert
groups so hence it's you know through a
factory because the product may need to
do some things more than just you newing
up a listener and attaching it
it's all Java because it was targeting
Java EE 6 okay it right
seven then its dependence on Java 7 - no
well there's no API specifically with
lambdas and thing rather you could cut
or not I don't know
dr. Greg Lee did a eh cash and was the
spec lead so if you want to complain
about it he's doing this table later so
sorry
no it has to be Matt I understood the
question correctly so this is it's only
it's only two lines of code all right
when the lines are pretty long but okay
so that basically creates the listener
configuration which is going to factory
that's going to create a stop listener
there's probably default actually but I
just try to put this here to show you
can change the configuration on here
like say to send key back or not
cemetery sent about updated value with
the event which you may or may not want
okay so that's basically the register
the cache entry listener and and then
basically go in a loop so we don't exit
the JVM yeah you know I do need quite a
number so I was just checking it right
what if we got running the next question
forgotten okay so
okay so we still got a price tickler
running so I'm gonna get rid of that you
mean that's the right one and if we go
back to the source
okay so we will run this and it'll do
nothing
but it's joining the cluster then if I
run this one so this is the one that's
gonna do the updates so have a seat
during the clustering don't updates and
we should see that the events are
combing in that JVM okay so this is this
is a listener basically getting the
event updated event and spitting out the
price so if I stop that process then we
get a load of stuff saying someone's
left the cluster but essentially our
update stop okay if I run it again then
obviously the updates will start again
okay so that's actually seems quite
simple but it's obviously quite powerful
you'll get in events fired across the
cluster based on updates on certain keys
all using the standard API and obviously
that can be a large-scale distributed
cluster that's sending these updates to
you yeah
they are on their order the key was
updated so yes in that sense not
necessarily on across separate keys okay
so if an update there's no it what's
atomic so on the same key you get the
same order on different keys not
necessarily in the products in the US
where it says in the spec you can do
things in coherence differently but over
that first
yep absolutely yep
I think he was best
you have a very large gas
okay this is partitioned so the keys
actually only rather to be felt it'll
have a primary inner backup so the more
nodes you add the more memory you have
it's not fully replicated cache so the
more the more nodes the more memory the
more data you can store only well it is
backups so you'd have to lose two note
and it's clever enough not to put them
on the same host so obviously
virtualization can cause issues as in
you know machine virtualization for
product problems like that okay
that's the product specific well it
depending on how the product balances
date or across partitions if it's a
distributed cache I mean
coherence will try and spread it out as
far as possible to equal on each node so
no sorry a simple question in Vincennes
yeah yep
well the spec says that updates on the
same key must arrive actions on the same
key must arrive in the same order so
therefore yeah sorry there forward to be
compliant then it should happen yep
yeah I mean it's probably question for
offline actually but uh you could this
you could write a memcache implying or
any of these it's a key value store you
can write whatever provider you want
actually enough to move on so otherwise
we've run out of time we may have load
time at the end I'm not quite sure how
long this takes
see what I mean when you do one of these
things you have no idea how long it's
going to take let's take two hours or
four hours of ten minutes okay so so
that events I'm gonna stop everything
so it's got a code just in case so
there's a bunch of listener interfaces
that you can choose to implement as part
of your listener and if you implement
the interface you'll get the events and
that's why I have to go through that
Factory because this thing gets sent
across the network and created on the
different nodes and then that listening
will be set up by the product in
whatever way it does it so we have
created which way obviously you get
events when a key with that value gets
created expiry which is one of the
questions so when if a key expires
you'll get an event so you could refresh
the key if you wanted to removed and
updated and again these are fully
distributed events and the so so doesn't
matter which JVM in coherence and in
hazel caste and things doesn't matter
which JVM you register the event on you
if the update occurs in a different JVM
you'll still get the event ok so these
are the actually semantics which might
answer some of the questions straight
out the spec these lines are so
basically the event happens after the
entries been changed changed if it's
synchronous when you set up the
configuration then you get the right for
a given key the order will be correct
obviously if they sync then out may not
be true ok if your register is
synchronous then the thread that does
the mutating will actually hang until
obviously the this all events have been
delivered to all listeners it may not be
what you want for a fastest speed
so in for asynchronous obviously is
undefined what the order is except for a
single key obviously if you got
synchronous then the thread stopped
anyway from you taking thread so we've
also this is two years ago I sat here
and did a demo of coherence with
WebSockets so just to show what events
can do with html5 and things like that
so if you go to that URL which may or
may not work and with whatever device
you've got you may see an updating stock
ticker and I will see if it works
it's dilip all right I'll get it open I
think I've got Network here
so basically that's using cash events to
update a browser based on you know as
the price ticket exactly the same piece
of code that's doing that random update
is doing a random update on a web
application so the web application has a
listener which is listening for events
on the cache and then those events it's
pushing down a WebSocket to the browser
so you can build quite large-scale push
just using these cash events push
architectures if you think of you're
building an html5 application that
session that the users using wants to
see certain data then you could register
cash listeners on that data when the
event comes in you could then use
WebSockets or something to put or
server-sent events to push down to an
html5 client so it's quite you can
create quite sophisticated applications
yeah question sorry I can't hear the
question what events no don't think so
no it's just the simple updates deletes
yep
I don't know I don't know there is any
defined order in this back so okay so
what girls look now is compute so this
is actually running compute tasks on the
datagrid and again this is all JSON 107
so none of this code is coherence code
that I'm showing so what we're going to
build is a system will of two or
multiple cache nodes are going to be
containing the data we're going to load
them up with stock objects and then
we're going to send an entry processor
so what an inch processor is is a piece
of code that you send across the network
to the different cache nodes and execute
on those nodes on specific keys okay and
we're gonna use two we're gonna first
we're gonna just put that single higher
key and then we're gonna send a piece of
code across the node print it out across
the cluster to print out where the key
is
and then depending on time we'll load
the cache up with say a thousand stocks
and then send a piece of code to update
the price on all of them by ten percent
okay and you'll see see it executing all
the individual JVMs that make up the
cluster and what compute allows you to
do obviously in a single in-memory cache
is not the most useful thing in the
world from an efficiency point of view
but in a distributed cache it's more
efficient to send the mutating code
across the network than it is to do it
through get input there's two reasons
one if you need to do multiple
manipulations on a key then if you use
getting put each one as a group is there
a network round-trip if you use getting
put here each one each get and each pot
will be a network call and each one will
do it is atomic in its own way so
that'll be one lock so the log could be
potentially on the depending on the
product quite a lot of not lock overhead
as well on the network calls to lock and
unlock the key one inch processor does
is you take the code from here you send
it over there and it will do everything
it does within its method as an atomic
operation from a locking point of view
okay so the key methods that you have on
the cache itself for support entry
processors are invoke which takes a key
the entry processing object itself and a
variable arguments to send whatever you
want into the process then there's
invoke Hall which takes a set of keys
and it's an inch processor and then
it'll operate on all those keys across
the cluster and then your class just has
to implement the enterprise R interface
which has one method which is process it
gives you a mutable entry which is
something that you can update and then
your object args variable arguments okay
so
so make sure there's all finished I'll
just make sure everything shut down and
that's because the enter processor has
to be on the classpath of the remote
node otherwise it won't obviously be
able to find it to run it so I've got to
make sure that my cache server is shut
down because I haven't created the entry
process yeah
show me too difficult there's nothing in
the spec to do that but it shouldn't be
too difficult to write yourself to be
honest I've also seen we did something
once for a customer where we pushed the
classes into the cash in a different
cash and then you could class load them
right with your own class load they're
basically out of the cash so okay so I'm
going to create the entry processor for
a that just print out a object first
come to the time
so this is going to implement intra
processor which is scope to string stock
string strings and return value and I
don't know which ones which
the other ones the cash value in key so
different classes
did I bring in Ryan for your right I
didn't sorry
that's the one
okay so basically we just implement
entry processor and then we do our
process method and all I'm going to do
here is print it out
so that'll basically just run on a
remote node and print out the value you
don't need your return but I'll return
okay so that's that's the empty entry
process implemented pretty simple one
it's just gonna print out the value of
the key sorry the value of the value and
now I'm going to create a piece of code
that attaches to the cache and then
sends that enter processor across the
key yep yep
yep
which shot
sorry Hank okay this one here these it's
just a very blog pin so you can pass
whatever you want you'll see that in the
next and not this one but the one I do
now afterwards because I'll pass in the
update I want to make
so basically I going to create a class
that runs that inter processor
essentially to print out which node in
the cluster that object is living on
so again this needs to do all the
boilerplate stuff because it's a
separate JVM
and all I need to do now to cash in a
VOC so that's the one that'll send the
entry processor across the grid the key
I want which is the key of the object
and then the entry processor and this
time you don't need a weird factory
syntax because it has to be serializable
I don't want any arguments and that
should essentially that'll send that
enter processor object here across the
network to whichever node contains that
key and then it'll execute this process
method
yeah it has to go in the classpath
that's why I shot all my nodes down okay
so I'm going to basically run a couple
of the nodes if I can find them why do
you need to invoke entry processes yes
so it'll basically send it across the
grid to cut to execute so I'm gonna run
a couple of cache servers so this is
distributed casually when when I insert
the object they'll only be in one of the
two nodes I've just created so I've
created to basically nodes in a in a
cluster you can see in the second one
that there are two nodes in the cluster
one and two I will just do that put
again to put the object in there and
then we'll run the find the stock class
okay so there should be a object in
there so this code is now going to send
that entry processor across those two
cache nodes and they'll execute on both
well it'll execute on sorry it won't
it'll execute on the one that has the
key so if I run that we should see so
you won't see anything on this this JVM
which is actually sent the entry
processor into the grid unless the keys
actually been balanced on to this JVM
just to be awkward but it hasn't so what
you should see in one of these two if it
works they there you go okay so that
meant the actual object was on that
cache node the first one because it
prints it out but it's not on the second
one because it hasn't printed me out
there is but it won't execute on the
backup it'll only execute on the primary
because they're a bit weird to run it on
the backup I'm the primary so yeah there
you go right I'll do that so that's the
primary so I've killed that and then
I'll run it again and it's printed it
out on the secondary because that's now
the primary yeah actively yeah and if we
run a new one up it maybe may move okay
we we do a workshop sometimes well okay
everybody creates a cluster in the
workshop and then you sort of follow it
around but it could move so if you bring
a new node up it may rebalance the
cluster and move it to a different node
but from a client point view you don't
care where it lives
yeah exactly yeah you don't know where
it's gonna be but it's there somewhere
okay so that's a pretty simplistic use
so I'm going to create another entry
processor now which basically will
revalue a bunch of stocks but first I'm
gonna create basically a class that's
going to fill the cluster with a bunch
of a bunch of objects
so I'm going to create a class that
loads the grid with a bunch of symbols
inch processors know it's to do
distributed calculations to one is to do
compute distributed computation because
you could you can added new entries into
the cache things like that like you want
so you're sending it out across a big
grid on a date grid you couldn't you
could you could do like calculations
locally and then push them into the grid
and bring it back it's only doing in one
node now because I've only got one key
so you'll see in a minute that will do
on across two nodes yeah questionable
yeah yeah the process is done atomically
yep
no no it's perky yeah yeah it's fine
yeah and events get fired as well but
cuz it what I mean it's atomic is it's
not seen by anyone else until that
process methods finished yeah yep
other than it has to be serializable no
yeah so I'm just gonna load the grid up
so I'll do my bootstrap back
you probably all know off by heart name
in mr. Brackett
okay so I'm basically gonna create a
bunch of entries
so we'll create a thousand entries into
the greed lock in sophisticated
so just crate run to price
okay so that's basic just gonna load
this this bit coach is gonna load a
thousand entries into the grid I need to
run my custom ever again not real not
yet okay so now we're going to create an
entry processor that will update a price
basically
called operate
so in a implement the inch processor
interface as before
so it's in the generic string and stock
of the cash key and value and the double
is the return for the entry processor
and what we're going to do in this
method is basically we're going to take
a value like we get past and up up the
price by that value so we get a stock
object
from the mutable entry the percentage I
wonder increase we're going to get from
our basic variable arguments list here
from the first argument
and then we'll just print out what we're
doing
so we're just gonna print out basically
for the processing that we're doing the
terrible plus and their mind
so they basically update the object and
I know this code is horrible
look at it now mr. Zale and I might be
like this
okay so basically going to update the
price the other thing we need to do to
make sure a bit like in a session you
need to actually rather than just when
you take the object you get out you need
to actually set it back into the entries
is the new value otherwise it doesn't
happen and then we'll return basically
the current price okay that makes sense
so basically essential process is going
to get get these stock check its price
and add a percentage that I get passed
as part of the process and then sit back
into the cache yeah
yeah
I've got some slides later which will
answer that question hopefully get to
there okay so then we're going to create
the basically the code that is going to
yeah okay he's returned today you'll see
that actually the next bit okay I'm
running out of time
so we're going to create a class that
actually runs that intra processor
so I busy got the same bootstrap to join
the cluster house before I get rid of
all that stuff and so it's going to
create a set of keys that it's
interested in
okay
and then basically do the same for we
did before to create the keys because
you need to pass into the invoke the
keys that you want
okay so
just make sure that's right
and basically the you mentioned about
there is turned so I'm gonna do the
invoke call now so basically the return
is sent as a map of results based on the
key
so it's basically a mat and so for every
key that this gets interested gets run
on it returned the double so it returns
back to the invert invoker as a map of
keys against the result okay which is a
double so we call invoke all sending the
keys that we want the entry processor
which is the one I just created and then
the arguments which in this case will be
the double that we want which is 10%
okay
okay so what I'll do is run this so I
will which ones
that's the parameter so there that's
that there are morons but at the end
that's going to go sent to the processor
so what I'm gonna do is I'm gonna run
Hey
yeah okay you know it certainly looks
all right okay and conscious the time so
I'm going to see what I'm going to do is
I'm going to create I'm gonna run three
cache servers
so we basically have a grid of three
then I will fill that up with 1000
objects
okay and then now I'm going to basically
run this entry processor across those
keys okay and then it's going to
increase the value of each one by 10%
hopefully so if I run that that will
basically create the enter processor
with the same set of keys all right okay
not so you realize what it's using the
same set of keys yeah right I need to
shut them all down though because of a
cut okay do that again
so basically run three cache servers
and then load it up
okay and then you're on this
and why should see on here is each one
of those servers is basically its ran on
all three in parallel and revalued all
the keys in parallel right across the
grid okay so it's these on the three
cache servers we've got the revaluing
methods coming out from the printout
from the enter processor so essentially
it's created one object sent it across
serialize across three nodes and all the
calculations have been done locally and
all the different nodes okay
so just to sum up so that the other
features that you get in J's are 107
which I haven't covered in the code is
you mentioned around back-end persistent
stores so jsr 107 has classes called
cache loaders and cache writers and they
provide read-through and right through
to back-end persistent stores or
resources so that when you do these
updates to enter processor for example
it could then be written through to a
persistent store has statistics which I
want of tanks show thousands for right
behind in spec know right behind would
be a that to be honest is not really an
API difference I'm right behind it to
have to be configuration I'll just run
through this very quick I'm conscious of
time so there's also CDI integration or
dependency injection integration doesn't
have to be CDI could be spring and there
are it depends on the CDI implementation
to build the driver but the annotations
are defined so cache loaders and cache
writers essentially integrate with
external resources so you could use it
for JPA caching you could put mem cache
D or no sequel behind that if you wanted
to and they do read through and write
through so for a cache loader you just
need to implement load which is a key so
basically what happen is when as a get
for a key and it's not in the cache
I'll call the cash loader to do the load
and that could be a whatever persistent
store you have there's a load all four
in case it was if you do a get all call
and you set them up by adding them to
the cash configuration when you set the
cash up and similar for a cash writer
there's a write write all delete delete
all and that's four and then when you do
a put or replace then that will trigger
the right to the right all to the back
end and then there's also annotations to
find which I've got a few minutes to go
through so these are the core ones
really which are cache result cache put
cache remove cash remove all and cache
defaults so I've only really got a quick
example of what this is straight out the
spec this example
so basically annotating a POJO you have
cache defaults at the top which
basically just set some of the defaults
up for the other annotations on the same
class for example the name of the clash
and then we have a cache result here so
what that means is that get the main
method what will happen with this
annotated as cache result it will first
check where there is already an entry in
the cache with that key in the keys
created as a composite of these two
parameters and if there is already a
value in the cache then it will not
execute the method it will just return
the value
no no it'll just come combines whatever
parameters you want they'll combine all
the parameters by default there is
another annotation called cache key we
can use just to mark a certain parameter
as the key cache remove will basically
remove the object from the cache at the
end of the method and basically that's
just an example showing how you can use
cache result with a specific parameters
to set the different cache names okay
and there's a similar one on on cache
put so that it will basically update the
cache with the two that aren't marked
with a cash value annotation will be the
key and the one with like value is the
one of the annotation cache value will
be the object I gets put in the cache
okay okay so these some URLs where you
can see the spec so there's obviously
there's JCP to org you RL get help calm
has all the code and all the code for
the reference implementation and the
Java and they suggest I wanted seven API
code there's a Google group as well if
you go to github.com dear some 107 and
the readme it has links to the spec
which is on google docs so you can see
it there
hazal cast not yet but very soon okay
any questions crawling on the back first
yeah yeah I'm sure Red Hat will do
similar I don't know what that timeline
is sorry yeah they've they're part of
the expert group I think yeah
know all about all this mess will get
called that in this inspector is a big
table that says what events get fired on
what methods so that's the definitive
answer but if you do delete all yeah all
listeners that registered for those set
of keys will have to get events in
individual events per key okay thank you
very much probably get help at some
point but know how I tell you that so
yeah we have a payara github repository
so it will be on there you should get
the slides anyways but Java one
I suspect that'll have to the next
revision like I say amiss Java EE 7 so
it got two years to do it so</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>