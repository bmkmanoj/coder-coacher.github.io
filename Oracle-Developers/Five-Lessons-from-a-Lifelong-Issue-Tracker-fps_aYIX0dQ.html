<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Five Lessons from a Lifelong Issue Tracker | Coder Coacher - Coaching Coders</title><meta content="Five Lessons from a Lifelong Issue Tracker - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Five Lessons from a Lifelong Issue Tracker</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/fps_aYIX0dQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I am Dan Radigan I work at a company
called atlassian I am the senior agile
evangelist for a product called JIRA and
issue tracking has been a core part of
my career path sort of worn many hats
from tests to development to product and
now I work inside of a marketing team
and have built a number of homegrown
issue tracking solutions as well as have
been an admin for a number of
commercially available issue trackers
currently I focus on building great
experiences with JIRA but a lot of the
themes around issue tracking within
software organizations or universal and
we're going to focus in on five today so
how many teams are agile looks like most
about everybody in the agile manifesto
one of the the first tenant really
focuses in on individuals and
interactions over processes and tools
and and as we think about how people
work together one of the concepts that
comes up is workflow and I've got a
workflow that many software teams use
where work is either open or to do and
then the team will take action on it
there will be some type of review or
test phase and then the team deploys and
then closes that issue but one of the
things that particularly new teams or
new administrators miss is that workflow
really isn't about work workflow is
about people and how people interact
with one another it's the individuals
and interactions and whenever a team
brings on a new issue tracking tool the
questions come up of how do we use it
how does it work and I always recommend
you know find out each of the
stakeholders in the process bring them
into a room and diagram how you want to
work together
what are the phases of work that your
organization goes through you know and
make changes don't necessarily the
defaults don't always work for everyone
if you need more flexibility go ahead
and add it but the key thing is is to
understand who's involved who's impacted
and what do they need out of that shared
team or organizational workflow so agile
teams often think about the definition
of done ISM as a metric of completion I
would challenge that that it's a metric
of transition there are a number of
people that will work on a particular
issue across your organization and
within your workflow there's a series of
handoffs a common one is from in
progress when somebody is working on an
issue to a code reviewer and there's a
there's a definition of done that
happens between an in-progress issue and
a for review issue does that mean that
the code has just been written is it
checked in is it on master is it billed
to unit test pass to integration test
pass all of these different things as
you clarify your workflow and you
clarify what done means for each and
every step it allows the organization to
become more efficient because people
know what they're expecting and then
what they're expected to hand off to the
next person in the workflow so to sort
of bring it together is that workflow is
the repeatable part of your culture it's
how you scale your organization as you
bring on new engineers new people and
test new people in product the workflow
is the piece that allows new
participants to jump into the fold and
scale as the organization grows and
always center workflow around people not
necessarily the tools that you maybe be
using because oftentimes straying from
the defaults can be a really good thing
because it enables your organ is
to work more naturally so the
counterbalance there is that you know a
number of tools do a number of amazing
things and as you roll things out I
always recommend start slow and iterate
much like you do in an agile culture
rather than over feature proofing
everything that you could possibly do
and you have a system that's very
complex one of the things that software
teams focus on is fields what data do i
need from my users are from the field to
work on this issue things like
environment or reporter or other
variables that's important for deaf to
to have so you know oftentimes things
will start light you know we need a
summary we need a description of what
happened but then then it's things grow
you know each team has their thing that
they need and somebody who then comes to
the system is like hey how do I file a
bug what does all this mean why do you
need this data reporting issues becomes
difficult and typically what happens is
people don't report issues or if they
don't know what something means then you
get bad data and it can be really hard
to scale this type of solution so a
couple of things I recommend if you're
an admin of an issue tracker if somebody
comes to you and says hey we really need
this new field for my team coach the
person through and understand why do you
need this how does it how does it move
the business value for word what is the
cost of getting this data is it simple
do people need to be trained so that
each ad is a very strategic ad for the
entire organization or scope it down to
the teams that particularly need it a
very simple one
it you know in all of your forms make
the data flow logical don't put the
summary of the issue at the bottom you
know as people work through filing a bug
or a story the fields should have a very
natural flow as you're drilling down
into that experience not all of your
data necessarily needs to be collected
up front for something like if you need
to track who is reviewing a bug don't
put that field in the beginning because
the reporter has no idea who the code
reviewer for this issue is going to be
put it somewhere down the line in the
workflow as we learn new things about
our programs we may not need certain
fields either hide them or delete them
don't sort of leave them there to
languish and have reporters struggle
through it and then for the engineers in
the room many issue trackers have a pis
use them automated data collection the
best way to get good bug reports is to
automate if there are things like log
files configuration data state data that
you need have your application connect
to your issue tracker and import that
data the reason why this is what is
really cool is that you then get a very
consistent bug report from the field you
know it's going to have log files you
know it's going to have your state
information and it's going to be there
in a very consistent and predictable way
and as the team learns hey we need these
other couple of data points adding the
adding that into the integration has no
additional cost for the user so you can
grow what you report over time and it
doesn't burden the person filing the
issue because everybody hates issues
that basically say this doesn't work I
started the application where do you go
automating all of that data collection
gives the development team the
actionable data they need to resolve
issues
how many program managers scrum masters
do we have in the room a couple cool so
this one's for you the biggest thing I
can tell you having worked with a number
of different issue trackers is that it
is your charter to really own the source
of truth for the program whether it
comes to release metrics what were we
are taking in a particular iteration
what the velocity is all of that data
that the team needs from release to
release day today really falls to the
project manager scrum master depending
on how things are set in your
organization because if people create
these entities on their own they may not
match yours and then you've got multiple
sources of truth for what means for
what's going out I a couple of years ago
in my career when we were shipping code
some people on the engineering team felt
like you know priority one priority two
priority three issues where was being
resolved the test team had a different
view you know we should fix all bugs
tagged to a release and there wasn't
necessarily somebody driving hey this is
our release dashboard keeping everybody
focused on that guiding light as the
team tracks from where they are to out
to a particular release so it's one
thing to create these types of things
it's a very different thing to
aggressively evangelize and say hey here
are the team metrics I've created them
if you have feedback on them let me know
so how many people in the room are
product people product owners a couple
product owners have an interesting
challenge in that successful product
owners have to learn how to evolve
solutions over time and working with a
set of people to do so and when it comes
to a lot of internal tools they don't
necessarily get a lot of love but they
can greatly benefit from this product
mindset so if we look at sort of the
relationship most teams have with
internal tools there's the software
whether it's internally built or
vendor-supplied there's an admin and
then you know everyone who uses those
tools and particularly with
off-the-shelf solutions you know many
different organizations of types and
sizes will use them so there's a
configuration element that goes through
it and if I can drill to the admins each
end users experience with a particular
tool is the sum of the decisions by the
vendor and as some of the actions by the
admin whether they be good or not so
good and having worked with a number of
people using different issue tracking
solutions you can go from instance to
instance of one vendors tool and have
very different experiences with that
vendors tool so one of the things I
really focus on is much like with agile
development as you roll out one of these
solutions you know that's your build
phase you're building and then you're
your shipping and when you ship an issue
tracker or a continuous integration
system or a source control repository
then take the time to learn learn what
your users are saying what's working
what's not working
you know if it's issue tracking is it
too hard to file a bug if it's code if
it's continuous integration or the build
times too long can you paralyze things
if its source control how are the repost
set up do they integrate well and then
take your learnings and then refeed that
back into the build process so that
you're constantly evolving your tools as
you go and make it easy to give feedback
how many people here admin a tool we got
a couple how may have received feedback
on that tool cool so for those of for
those of you there is in JIRA one of the
things that we've got as the issue
collector it's just an HTML Javascript
island that you can integrate into
either a dashboard or you know any HTML
j/s app that you can click get feedback
and then what this does is that it just
logged an issue and a predefined project
so that then you've got that feedback
recorded and then you can choose to take
action on it or not but it's a
structured way to collect feedback much
like on product teams people file bugs
enhancement requests new features do the
same thing with your tools have people
allow people in the organization to
record feedback in your issue tracker
and then they can follow that
conversation as that solution is either
adopted you have questions or if for
whatever reason you can then you can
communicate to that user and say hey
thanks for your feedback we can't do it
because of XY and Z or thanks for your
feedback we were going to be deploying
this change on this particular date and
then they can see it give feedback and
it just becomes an iterative cycle as
you go
you
so probably the most important shared
understanding across the team most
groups most people here so they are
agile adds all really centers around the
self-organizing team that have similar
or somewhat disparate skill sets
depending on your group but teams that
work well together deliver better and
really understanding the landscape of
the product team helps the teams make
decisions and strong teams are made up
of diverse people but they bring a
consistent set of priorities to each
decision and whether that's within a
particular discipline or across several
disciplines it's that shared mindset
that gives the team a strategic
advantage because they're making
decisions with one mind in different
contexts but how do we get consistent
about priorities if we look at the
software team we've got a wide variety
of people it's not just developers
developers are certainly a central part
of that but you've got product owners
you've got designers you've got
marketers you know program manager scrum
masters database people and one of the
things that you know I was sort of a
little bit skeptical about but atlassian
one of the things we do is everybody who
joins the company creates an intro post
and after joining the company and seeing
a couple of these go by really getting
to know not only your own team but sort
of other other people within the company
really gives a very personal touch to
the relationships you have at a
particular organization because no team
truly sits alone there's an integral
part of what we do whether it's
atlassian different product families
different product teams we as agile
build one part of the story but we
integrate with a number of other teams
to complete the story sprint planning
issue triage is a really important part
of the software development process and
you know a lot of times in many
organizations this can be held by a type
view but really the value of triage
together is that everybody gets that
shared understanding of what's going on
you know as product owners say hey I'm
going to move the priority this up the
natural question then becomes Y and then
having that discussion across the team
has impacts for design it has impacts
for dev it has impacts for test and as
the rest of the team begins to
understand the ethos from product then
they're better able to make decisions on
how they develop and how they test
likewise you know one of the core
disciplines from the engineering team is
learning how to estimate work and one of
the challenges in between developers and
product owners is delivering stories in
a way that the engineering team can take
action on them you know lobbying over a
giant piece of work and saying hey
what's the estimate for this isn't
doesn't necessarily put the engineering
team in the best position but to break
down that work and saying hey this large
mound of work actually is going to be a
series of you know six different things
and as the product owner gets insight
into why the engineering team is
breaking up work in a specific way then
you can have whole sets of discussions
around well hey if this you know first
thing is three story points but this
next thing is 13 there's a discussion
about well do we really need that 13 and
if if we want to deliver sooner then you
can have a collaborative discussion of
well 13 there may be something that's 8
that we can
liver but this extra five is going to be
pushes out we really need it why do we
need it so that the product owner is
getting feedback from the depth the dev
side so that as both parties work
together it becomes a much more fluid
system and expectations between both
groups become smoother likewise if test
people aren't involved you know testing
is a whole different discipline and how
something is implemented very much
affects the testing side of it which
we'll get into in a minute but if you're
not involving all of these disciplines
in your planning and organization I'd
encourage you to take that next step to
open up the conversation because all of
this really is about conversation and
it's about getting information between
people and learning what drives
everybody in the organization because
ultimately we're all here to do good
things it's just about getting on the
same page and these agile ceremonies
really help the team understand where
each person's coming from so at
atlassian we tend to focus people around
triads so the make triad really brings
together engineering design and product
management and those three really are
focused on delivering the product they
make it but there are other people
within the organization that also
contribute so in the operate triad
you've got support and operations who
really works with the dev team and
product management handling issues from
the field and deploying code out to
production likewise on the sell side the
marketing team is mostly going to work
with design and product management as
they bring that product out to market it
doesn't mean that say marketing doesn't
work
engineering it just means engineering
isn't necessarily a primary customer of
the marketing team I know for me I reach
out from to engineering from time to
time but as we bring new releases to
market my role as a marketer really
focuses between product management and
design so many of you know that
transition isn't cheap it's hard to
transition work from somebody to
somebody else there's a ramp down from
one person ramp up for another person so
one of the things that's really
important is learning how to efficiently
transition work so that you're not
incurring a huge cost of ramp down and
ramp up and if we go back to our triads
the one I really want to focus in on is
the engineering section and how we can
scale development to development so that
we're getting more and we're empowering
our engineers to do more within the
software team so looking at the make
triangle between dev design and p.m. one
of the things I've heard from many
different teams is that design tends to
be a really scarce resource they're hard
to find or get access to so one of the
things we've done with the design group
at atlassian is come up with a set of
design guidelines that the engineers can
use and bring together predictable
design elements in a very consistent way
for those of you that know our product
family JIRA confluence and stash one of
the big movements was to bring the user
experience together for those products
so that our customers would have
consistent interactions as they move
from confluence into JIRA into stash
rather than having sort of very disjoint
user experiences and if we look at any
particular feature
there's really two paths that that
feature has to go through before it gets
to two done one is that there's a
workflow with that feature the user has
to do certain things or behave in
certain ways such that that so they can
achieve their goal with that feature but
there's also a discussion about how it
looks where you know where fields
positioned what's the visual treatment
what types of colors do is what types of
buttons do we use and one of the things
that the to get to done and one of the
things that the design guidelines does
is that it takes the looks discussion
off the table it tends to be the most
aggressive discussion people have
because they get very attached to well
it needs to look this way or it needs to
look that way whereas our design
guidelines give a very consistent look
and feel across our product families so
it you're not having those discussions
about visual design you're having those
discussions about information
architecture so what actually is the
design guidelines it's a set of colors
icons ways to indicate status ways to do
announcements and sort of all of these
core user interaction paradigms that we
typically see in our products there's a
solution for it in the adg so that as
the development team and the PM team are
working through they can reuse these
paradigms over and over and design is
involved as an advisory but they're not
necessarily a blocking issue in each and
every discussion as the dev team takes
more and more of the design on the
design guidelines for us are delivered
really into sort of different ways the
flat-pack which is engineering centric
and the keynote pack which is product
centric the flat pack
no gives examples of all the different
controls how to use them sample code so
devs can easily markup and interact with
it and then for the product people who
aren't necessarily code focused can use
a keynote version of the flat-pack and
there are keynote implementations of all
things like banners text controls
dropdowns so that they can build out
different experiences that they want to
build inside of keynote and it is the
mac version of powerpoint so you know
you can you can do pretty incredible
things with keynote you know and walk
through how a particular flow may work
say search and JIRA you know some of our
our product managers have done demos
with keynote and most of the team you
know was fooled that it was a actual
product but if you're savvy with
technologies like keynote and PowerPoint
it can really save a lot of engineering
time because a product owner can build
something out get feedback they may
decide hey this isn't right and then
you've not burned you know a couple of
weeks of depth time building something
that wasn't necessarily right so for
those of you that know sort of the fail
fast fail often recover quickly
methodology building things in a
lightweight manner like with keynote can
really help hone in on the desired
experience much earlier so that the
interaction between p.m. Devon design
becomes much more efficient
so secondly dev and QA is a very
strategic relationship on many software
teams one of the things that we've
always looked to do evolve how we
develop software so you can do it better
more predictably and more efficiently
and if you look back seven years you
know JIRA was developed using a very
traditional paradigm development would
work on new features QA would test them
QA would then send bugs and feature
requests back to development and there
would be a series of you know spins on
this as the team headed towards release
but you know then after a certain amount
of time there'd be a hardening phase and
then we'd release and you'd have these
sort of giant release cycles that were
many many months you know in time but we
wanted to do better we wanted to be more
agile more responsive and one of the
things we found is we did some testing
between the test team and the dev team
is that both groups were very on par
when it came to validating fixes and
making sure that bugs actually were
fixed by changes but one of the things
we did find is that as we got into more
complex stories the test team was really
good at figuring out where are the bugs
that are actually worth fixing and the
challenge was how do we leverage that
skill in that insight that the test team
brings to the process more broadly
across engineering so many of you have
heard the the acronym quality assurance
and I think one of the the misnomers is
that QA doesn't necessarily assure
quality they will tell you you know the
status of software but it's really the
development team that assures quality
the development team is the one that's
writing and owning their code and we've
made a slight shift here that we use the
term quality assistance the QA team
members at atlassian really bring a
value-added perspective to the quality
process but the development team is the
one that that owns the quality part so
how do we do this what are some of the
things we do so each story that comes
into the pipeline from the product owner
very early on in the process the quality
assistance engineer will take a look at
that story and think through what are
all the different things that we need to
be aware of as a team in this particular
story we call them testing notes they're
short they're directed and focused about
this particular feature they're stored
right inside of JIRA so that the
developer has a very strong context as
to what the the quality guidance is the
development team is really good at
implementing features solving problems
and we're just adding the test metrics
within that you know and I was working
at my last gig you know development
would write feature code and the test
team would focus in on writing
automation code and when bugs would come
up and automate a test began to fail you
know it was very quick for the
development team to say hey will that
other thing you know isn't working my
codes good you know the test engineer
would have to dive in and figure out
what's going on whereas when the
development team really owns the quality
process when an automated test would
fail it then becomes a very personal
thing like hey like there's something
red in my code you know jump on it so
we've we've leveraged the expertise of
the quality assistance engineers to
figure out what's the
testing impact and what do we need to be
aware of but the development team really
owns the implementation of the feature
both feature code as well as test code
one question all you make sure that the
test I'm good enough because your
developer you always buy it of course so
one of the things that actually sets me
up for my next point exploratory testing
is a key value at atlassian the dev
engineer and the quality assistance
engineer will pair for you know 30 to 45
minutes and really blitz test a
particular feature and understand are
there any things we missed our the
testing notes sufficient are the
automated tests sufficient and the
quality engineers are engineers
themselves they regularly review the the
automated testing code to make sure that
the tests are good enough if they get
through that session and they find hey
this isn't what we expected then they'll
go back and write post development
testing notes to fortify that process so
there's more guidance if things are good
then you know they sign off and then
sometimes as we were ramping up this
approach there would be a developer on
test that would then take a second look
at a story and look for bugs to
reinforce the testing mindset because
testing is a skill as well as a mindset
it's not necessarily something that's
unique to QA engineers their skills and
mindsets that can be learned and one of
the things that we really used was
bringing other developers looking at
other developers code from a testing
mindset and it would be a coaching
session between the test team and the
dev team to really build those skills
question
question 2 also uncovered requirement
defects the real story originally
absolutely in the very beginning stage
when testing notes come up there's
usually sometimes questions for product
hey how is this supposed to work and
that's where that make triangle really
you know earns its keep is keeping those
stories focused actionable and
deliverable so then the question comes
is you know where are we today as we
released our on-demand suite that pushed
the product teams to really deliver
every two weeks and you know in in
traditional circles QA is very much a
push function I write my code I throw it
over the wall somebody else tests it and
they throw a bugs back over the wall
whereas now we've gotten to a place
where QA is a pull function developers
are actively seeking quality assistance
engineers and say hey like how can I
improve my code how can I what what
areas of the product do I need to really
focus on because the QE engineers really
have a broad view of the code base and
sort of knowing where things break or
you know which browsers have certain
issues and can give good guidance that
the engineers will want to pull that
information out of the test engineers
rather than a be a throat over the wall
type of cycle and what we found is it
you know the best bugs are the ones you
don't code and and the more you can
front load the QE process and empower
the engineer to own their own quality
the better code you get and the more
sustainable software you write and then
lastly looking at dev and ops how many
people are in ops or work with Ops teams
okay
so I'm sure many of the obstacles can
laugh you know we're fine and Dev ship
it down the line not my problem but you
know much like working with design
working with test the ops relationship
is a strategic one for the developer
because ultimately as software teams we
like to see code shipped we'd like to
see out in the world you know that's the
thing I wrote an ops is a critical part
of that so many software teams have a
flow where code is written in some type
of development environment and then
promoted to a test / staging environment
and then out to a production environment
this sort of isn't new but one of the
key learnings that minimizes that
transition costs for code is that coming
back you're learning configuration
you're learning insights you're learning
how code behaves in each of these
insights that come from your ops team
makes your code stronger and having
direct conversations with ops having
developers involved seeing their code in
production when issues come up bringing
the development team into the ops cycle
helps the development team right more
sustainable more shippable code and
again these are conversations these are
these are insights getting people to
talk to people so that both sides are
heard and that these key learnings
bubble from the ops team to the dev team
but also from the dev team to the ops
team is as new features are implemented
if there are concerns or issues that ops
need to be aware of having the
structured conversation so that you
don't deploy a set of code it blows up
and the dev team says well yeah we knew
that you had to set this extra variable
to keep
you know something on track having tight
relationships with the ops team makes a
better software and then lastly as
software teams we strive to do great
things and you know to do anything truly
great courage always dictates turning
ones back on everything that is good and
this is sometimes a really hard concept
to grasp because in all of our spheres
there are plenty of good things that we
can do but how do we know we're doing
the truly great thing so what you see
here is what we call the cumulative flow
diagram and what it does is that it it
takes a nap shot of the amount of issues
in a particular state over time and in
this graph I've got the to do category
the backlog and as you can see for this
particular product you know when it
started you had a very sort of tight
small backlog and then as adoption grew
and grew and grew people had more
requests bigger bigger backlog that sort
of around the midpoint of the graph you
had a new product owner join focus the
team minimize the backlog and then you
know you keep jogging and then you see
this very rapid adoption of the product
lots of people having feedback the
backlog is growing I've heard time and
time again from product owners you know
how do I manage my backlog how do I keep
what's really important in a front and
center and minimize too tough that's not
not as important and you know as a test
engineer I remember a distinct
discussion with the director of
development at the time and he basically
said we're going to close all of the
issues
that were filed in releases to back and
like my heart just sank like how can you
close issues it's still a bug but the
fact of the matter is if it had been in
the product for two years you know
should we spend the time fixing you know
a wide variety of you know issues that
aren't necessarily affecting people
today and I think as product owners
you've got the same challenge in that
you need to communicate to your business
your development team your stakeholders
and your customers what really is on the
road map and the way to do that is to
close issues it's a very brave thing to
say hey we're not going to be doing this
it's not on the roadmap and I think the
misconception many people make with
issue tracking systems is that closed
equals deleted because typically closed
issues we don't look at because there
are plenty of issues that are open for
us to look at but the the reality is is
that closed issues are still there just
like open issues but one of the things I
I always advise product owners to do is
flag it you know have a specific
resolution that says not in scope not on
road map you know however you want to
phrase that and then use your other
fields to classify it if it's in a
certain area of the product or a certain
release so that you can go back to these
issues as you're doing roadmap planning
if you've got a bunch of things that
have collected over the years then maybe
that is an area to evolve in a future
version of the product but you're not
sort of than having all of these issues
polluting your backlog that you're not
going to be working on so that as you
communicate to your dev teams your
customers and your business here are the
issues we were actively considering
here's the backlog that is a product
owner I am owning and then the rest of
it
as an organization we are moving beyond
so I've got one last bonus tip so as
many of you know software teams have you
know a couple of core disciplines
ideation where you're developing ideas
to do putting them in backlogs
estimating the coding process we're
actually developing features code review
test review ensuring that the code meet
the quality bar and then deployment
actually pushing it out into production
and release but remember transition
isn't cheap but it's a necessary thing
that we do that software is a
collaborative thing so one of the things
that we've sort of focused in on
atlassian as we develop our solutions is
that you know there's there's change you
know developers you know product owners
change things out from under people you
know and then you know as everybody's
busy it's like please can you have time
to review my code and then you know the
DevOps cycle but for us in the ideation
phase we really focus on compliments as
the product owner is working with the
business developing hey what's the next
big thing for my product you know we use
the product requirements blueprint but
what's really cool is it then you know
as the requirements are flushed out we
auto import an auto link to JIRA so that
as the development team is working the
product owner and the rest of the
business that have come to know this
page can easily see what's going on
inside of the development team as user
stories or implemented confluence will
hotlink so that the business owners can
Co were
you know 6 out of 10 user stories
implemented for this program you know
we're on track but then you can also
drill in so if a if somebody wants to
see hey what's going on with this
particular issue you can see all of the
major components of it and then for the
developers in the room who you know code
review is a critical transition for
every software team and minimizing the
ramp up for the code reviewer so the
reviewer has the same context as the
developer is really really important
because that's how you ensure you get
the most effective review and with JIRA
it'll search your repo and pull out all
of the different artifacts that are
important to a code review you know
which branch which commits you know any
builds that have been done any
deployments that have been done on a
particular branch and for test users
test engineers you know knowing where a
fix is you know in this case it's been
deployed to staging and minimizing that
hey I tested this fix I didn't see it
where'd you test they tested in
production well it's not there it's on
stating so you're minimizing that thrash
but as you're drilling even further you
can click in like what are the different
you know commits that this issues
involved in and then what's the code
that implements that commit or behind
that commit so there's a very clear
pipeline for how innovation is delivered
and whatever tools you use make sure
that it's easy to see how innovation
flows through your organization from all
the way from requirements all the way
out to deployment because many of us
have had that hey you know what's the
status on this and as a product product
owner or a project manager if you ask an
engineer what is the status of something
you've costed them 15 minutes you know
you've broken their mind space got to
come back and really get back into that
flow and if you've got four pings in it
if you've got four pings that's an
our of time and if you can create that
transparent view using your tools so
that people can self help then it gives
the team much more time to actually do
what they love to do whether it's filled
requirements write code or a test and
deploy and I've got some time for
questions if people have them cool then
hey thanks for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>