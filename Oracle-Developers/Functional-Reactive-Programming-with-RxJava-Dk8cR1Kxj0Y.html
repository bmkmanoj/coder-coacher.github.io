<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Functional Reactive Programming with RxJava | Coder Coacher - Coaching Coders</title><meta content="Functional Reactive Programming with RxJava - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Functional Reactive Programming with RxJava</b></h2><h5 class="post__date">2015-06-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Dk8cR1Kxj0Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I hope to be able to explain to you a
little bit today how I am my team at
Netflix and how we have come over the
last two years to adopt a functional
form of functional reactive programming
and we're on the JVM using it from a lot
of jvm languages so it's not pure
functional programming in the sense of
as claimed by languages like Haskell and
we're not aiming for that so it's
reactive programming which you're
starting to hear a lot more about in the
community and with functional principles
applied to it and I hope to by the end
of this be able to Illustrated to you as
to why it's been useful to us why we've
chosen to adopt it and change our
mindset to to this approach and help you
to understand what this is all about
without delving into category theory or
monads neither of which I actually
understand all that well myself every
time I talk with Eric Meyer the inventor
of rx and he delves off into that I get
lost
even after working on for two years it
doesn't take long to get too lost in
that space because I'm not an academic
so what this is what this presentation
is going to be about really is how do we
take functions that we want to be able
to compose them together and then apply
these reactively to data typically it's
data that's coming from some network
response somewhere and it could be a
scalar response a single response from
the network or a stream of responses
over a network and the interesting parts
are not so much that you can just
receive that data but that you can start
to transform it and you can start to
combine it and I'm going to show how
this can all be done asynchronously
reactively and in a way that is thread
safe and you can make you can have
happen concurrently in parallel by using
functional principles so when I talk
about reactive I'm talking about things
that are asynchronous that we are
pushing values or events down to streams
if you think of data flowing down a pipe
that's keep that mental image I found
that when you're dealing with reactive
or rx that mental image of flows of data
is really where it's it's what it's all
about on the functional side so here
we're going to be talking about lambdas
enclosure so those are the the code
blocks that you're going to see and
you'll see that we're mostly pure in the
example we're going to be giving by pure
what that means in functional
programming is that you have no side
effects you could apply the same input
to a function every single time and get
the same output and that it's not going
to be writing i/o some more or changing
states somewhere we cheat sometimes at
the very end even Haskell does that they
have their IO monad and so they cheat
when they get out the end because at
some point you have to actually your
application is going to do something you
have to do something and so typically
that's held right to the very end of the
chain of functions and then composable
is something that's very important to us
as one of the primary reasons why we
adopted this pattern rx Java supports a
variety of different languages and it's
been targeted I'll explain a little bit
more about it in a bit but we've
targeted the JVM rather than any
specific language and one of the drivers
for that is at netflix we use a variety
of different of different languages so
we're a fairly polyglot environment and
that's increasing over time today
several the examples are going to be in
groovy groovy is a very nice syntax be
able to present with it's understandable
and then because Java eight is around
the corner it's starting to become
possible to play with a little bit more
and because this is Java one I'm also
going to be throwing in some examples
with Java 8 so what is rx Java so rx
it's a library for composing
asynchronous and event based programs
using observable sequences for the java
vm that's the sound byte and what what
where it originated from was work the
Eric Meyer who is a computer scientist
who left academia over a decade ago went
to Microsoft worked on their sequel
server teaming in c-sharp language
design and variety of different things
he created rx reactive extensions of
Microsoft and it has been it's such a
great idea that we're now starting to
see it show up on a lot of other
languages so we decided to port it to
Java to the JVM
you also see poor Microsoft themselves
did one for JavaScript as well as their
net poor a version and then there's also
ones coming out for cocoa that github
did one for PHP and you're starting to
see it come out and to me that's kind of
a sign that the model is one that people
like are finding useful and that's why
we ultimately decided to port it to Java
because we liked its model so much so a
little bit about the context as to what
my team does because I want you also to
understand the actual real-world
application and this is not the theory
of functional reactive and so my team
and Netflix we're responsible for the
edge platform and all the edge services
one that means it's the API is that all
of the devices out in the world use to
to power Netflix and so you're all in
the u.s. Netflix is very well-known and
we're also around the world in over 40
countries and we've been adding over the
35 of sorry all but two of those
countries have been added in the last
two years and so as we've been growing
and expanding we need to start doing
something a little bit more dynamic in
how we handle those edge services our
traffic we take up about a third of the
downstream last mile P internet traffic
and there's over a billion hours a month
a video stream that our that our
customers watch our API traffic has been
growing a lot over the years and the
layer at which my team sits is the it's
the entry point for all these our
interfaces on all the devices there's
over a thousand devices that we support
and they all come in through our API
there's two pieces today streaming and
discovery I'm not talking about
streaming today that has a different set
of use cases and that's connecting you
up to the right CDN and to get the
actual files when it comes streaming
across with licensing the portion that
I'm speaking about is is the one that's
really API driven and it's all about the
discovery how you actually drive the
user interfaces and all these different
devices
well the unique Kay
that we had was it instead of us just
having like a desktop and a mobile split
and maybe wanting to optimize for those
two we ended up with dozens of different
classes of devices that all had varying
different types of requirements and we
were finding that it was making a real
mess of our restful api and so we sit at
that bar in the middle err and all those
devices on top as they access us we were
finding that we were lowest common
enough denominator solution we basically
had a very fine-grained API if following
the restful model resource driven and
then we had ended up adding all of these
expand and for these parameters it would
allow them to start to tweak it to try
and reduce the the bandwidth that what
was being delivered back to them and
then we fan that out to the dozens of
services every single request comes in
fans out into the service-oriented
architecture across thousands of
machines within Netflix and so what we
we actually changed all that I'm not
going to today's talk is not to dig into
that this is all to give you the context
of how we ended up there so what we
ended up wanting to do is we wanted to
be able to optimize every single device
experience so that their requests would
come in get a custom request response it
was for them and we could go one of two
ways we could either have the API team
go and build out a custom one for every
single endpoint device but that just
didn't feel right we would be a
bottleneck and we would spend our entire
lives just trying to keep up with the
many teams with the Netflix all having
their own timelines and requirements the
other way is that we could say we're
going to get out of the business of
creating API s and instead we're going
to build a platform for those teams to
build their own api's on top of us and
that's the way we went but to do that
let me show you one more thing we
provide all the fault tolerance behind
so we're we we guarantee to our users
basically that we're going to handle all
the the failure modes and do bulk adding
etc but at that center point we adopted
this because we wanted to
allowed all the UI teams to build
services on top of us without having to
worry about all the concurrency and
parallelism and fault tolerance and all
those different things and so it really
got going when there was a particular
device that was it's a very popular one
that we as we were profiling their
homepage took over twelve network calls
to run to the page is they were hitting
all of our different granular api's and
we want to collapse that down into a
single network call over the LAN because
when you're going over mobile or Wi-Fi
or the last mile and the latencies are
high you every single one of those adds
up and so we wanted to condense that all
down and instead leverage the server
side for the concurrency the lower
latency LAN connections between servers
and reduce a lot of the duplication that
was happening for every request but what
this meant is that now for a single
request we lost all the implicit
concurrency that was happening on those
dozen Network calls before and so we had
to be able to allow it to happen
explicitly on the server side and
there's a lot of nested conditional
logic that would go on you fetch back
data based upon the response to that
data you would do one or two different
things and you could go multiple levels
deep as in this stack and that becomes
tricky and so we wanted anybody to be
able to implement those type of nested
conditional flows not just the ape you
know quote unquote API team we wanted it
to work from multiple different
languages because we're a polyglot
environment we wanted anybody to be able
to do this without reading this book I
love that book I've read it you know
multiple times but there's this
shouldn't be a requirement for building
a web service and the API team needed to
retain control of the concurrency
behavior so we didn't we couldn't have
people who are building a single web
service decide to launch a thread pool
and you know be doing that on every
request because they did something wrong
or not synchronizing right so basically
if we ever saw the primitives of
concurrency anywhere that layer in our
app we knew we'd failed if you had to be
dealing with anything in Java util
concurrent or synchronize or volatile or
anything like that at that layer of
building a web service
we consider that a failure and so we
needed to be to achieve that to retain
that control we would take a method just
you know a simple method like this go
get data and return the bit data back
well what happens if behind the scenes I
need to flip that around I need to
change it from synchronous asynchronous
because it used to be an in-memory cache
now it's an over the network request and
how should it how should a user actually
fetch that data in a non-blocking way if
they want to or need to well as we start
going down this and the last the answer
the last question Utley not that we want
them launching their own threads you
know at that layer just to wrap
something that we have made blocking
because we weren't thinking it through
so that is not what we want we don't
want threads waiting on threads just so
that someone can unblock their a request
and so some of the the ways that we
started looking are the the fairly
typical ones we said okay so callbacks
would probably work and we could change
all of our API so they inject these
callback handlers into everything and it
didn't take long for us to realize like
the rest of the world that that's a
horrible thing and you get into callback
hell it's not so bad if you have just
the single level of response it gets
really bad when you get to three four
levels deep we looked at futures I've
been using futures for ever and our team
is very comfortable with them but they
have a few problems I'll get into that
and then if we want to have a list of
data coming back a future of a list of
futures really doesn't work very well
and so it was actually at this time that
I was exposed to the Microsoft RX
technology by a member of one of the UI
teams who had come from Microsoft I
would have never been exposed to it
otherwise luckily we had that
cross-pollination of ideas and the first
time he shared with me I mean the honors
honestly my reaction Microsoft TAC that
just wasn't really where my mind was at
the time he can he's very strongly
opinionated and so he kept arguing with
me and so we spent weeks going back and
forth on this
until he convinced me that actually this
was pretty legit and the theories behind
it were very clean and pure and so what
what our ex is all about and that Eric
Meyer Mike Raeleen on Microsoft anymore
but what he had invented discovered or
proven is that the dual of an iterable a
pull based iterable is a push based
observable and that the way that you
next over an iterable is the same way
that you can you can on next on an
observable and I'll push out so
everywhere that in the rest of the
presentation we're going to see the word
observable you can think of it as an
iterable except that it's asynchronous
and pushing data at you instead of where
you have an iterable and you're pulling
it out as you imperative lis iterate
over it and that it that right there
actually is is the theory behind it
which is very simple and elegant all the
magic starts to happen with the
higher-order functions that get applied
on it so what he did is he took the Gang
of Four observer pattern but then
modernized it for our age where it's
asynchronous and can handle a sequence
of values rather than just a single
callback so let's dig into what that
looks like so if I have code like on the
left there that's an iterable it's
becoming far more common including in
java 8 with the stream api that you can
take an iterable and you can start to
apply higher-order functions to it so
for example you can skip and take and
map which in java 8 is more often called
that you then apply in all the other
languages you map something and you can
for each over it well on the observable
side you do the exact same thing except
it's async and so if you take an
iterable it has higher order functions
applied to it you just swap out the
iterable for an observable and then
typically you don't want a for each
because that's a blocking operator by
definition instead you subscribe to it
you have exactly the same interaction
with it except that you're now
asynchronous and push based and so as we
were looking at the different ways we
can handle the data you really have this
grid
so you can hand handle a single scalar
response in a synchronous way as we've
all been doing since the first time we
touched a computer to do any programming
and you fetch the data it blocks wait
for it to get back and then you can do
some conditional logic off of it that's
what we wanted to get away from multiple
values you have an iterable you get back
the iterable and then you iterate over
each one and again you do the logic as
you hit each value where once you get
into the reactive model though want to
be asynchronous and particularly when
you're handling Network calls the async
single response scalar values this is
where most of most of the community
still is at and this is where we were a
year and a half ago and it's the world
of futures and there's a variety of
different implementations of futures the
Java future pre not the completable
future I'll show that in a second the
Java future that we've all had forever
is limited in in its use because the
first thing everyone does is they block
on the thing and you actually can't do
any conditional logic until you block on
it so if you have contested conditional
logic you get this future you're like
great I'm async now and then the first
thing someone does with it is they do
get so they can get the value to do some
conditional thing and then move on and
it turns your you're blocking again and
so this isn't very helpful to us
guava adds something much better the
listenable future so you can add
callbacks to it and you can then have
the on success hooks for brevity I'm not
showing the error handling in all these
examples but they'll you know they all
have their own error handlers etc so
this is much better now I can actually
put my conditional logic inside an
asynchronous Handler and this is all
happening still asynchronously off on
the the callbacks completable future in
java eight much better it's much better
in this space it allows me to do similar
things as what guava and akka futures
allow me to do where I can get this
feature and then chain up all these
functions to be applied to that response
so here I can then
apply which is the equivalent of map
over that value do something to it in
return so I can go from type T to type U
for example I can transform it I can do
things to it a cadet
they are a very well-designed
future and they have all the benefits of
these asynchronous transforms and
combination combinatorial functions you
can accomplish all the things you'd want
to do that we wanted to do but as long
as you stay in that single scalar
response value there are ways that they
have of like combining lists of futures
and things like that and so this is
probably where we would have ended up if
we had not been presented with our X and
we would have been very happy probably
right here because we don't know known
any better and so if you take that s dot
map here where you get back this value
get a future and you're going to map
over asynchronously if you just take
that future and you replace it with an
observable you get the exact same
behaviors what akha does except now you
can work on both scalar and vector of
values so instead of just a single
response you can now also support
streams of data including infinite
streams and so what we decided is that
we want to be in this space of either
future or observable we want to be a
sync but if we're going to be in that
space we might as well choose the one
that would support all possible values
that we have because we have use cases
for both scalar and vector responses and
so observable encompasses all four of
these quadrants for us and so we ended
up choosing to adopt that and instead of
blocking api's we use observable api's
so everywhere we where we be returning
type T we return an observable of type T
instead one of the other benefits
besides the fact that this abstraction
is encompasses all four sections of that
of that grid is that it's completely non
opinionated to where the concurrency
comes from this is another big benefit
for us and so of course you can do you
can have this thing and do it
synchronously similar to how you can
implement your future on top of anything
but
our X does not come with like a strong
disposition to thread pools or actors or
event loops or anything like that but
you can put any of those behind it
because it's just an interface
abstraction so let's say that I've got
something that is already in memory I
return that observable well I can
synchronously just fire hose it back but
the user still consumes it as if it's
asynchronously or I could be doing that
work on a separate thread or I could do
it on multiple threads and as each value
comes back we're spawn back on different
threads or I could do it on an actor so
I could use an actor in place of a
thread pool and the way of interacting
doesn't change or I could use niño so
for example I'm doing a network call
I gotta have niño with its event loop I
could decouple the work from the actual
callback and so I could have a thread
pool or an actor and then an event loop
that sends it back sometimes you want to
do that so you you're isolating where
the work is done and so all of those
things allow us to to have the people
who are consuming the data they treat
everything is asynchronous but the owner
of the API who's implementing it retains
full control over the concurrency
behavior they get to control those
blocking or non blocking and they get to
control what resources it uses
underneath and that was very important
to us because we have in our at least in
our stack we have dozens of back-end
systems we're talking to dozens of
different clients hitting us in the
front and we need to be able to have
very tight control of that while giving
flexibility in consuming this all
asynchronously yes
we know we did not develop our own TCP
layer we use we've got enough
differences you know history in our
stack some of it is blocking a patchy
clients and then more and more
nettie or Apache HTTP async and does
that answer your question okay
most of our threading actually on top of
blocking calls is managed by our
historic Slayer so the history of bulk
heading library that we do is typically
the isolation point between any
consumption of the data and the
underlying work that's a whole different
conversation I'm actually talking about
that one tomorrow if you want to come up
and chat with me afterwards I could tell
you more about about how we handle the
threading apache httpclient
HTTP async client and then more and more
Nettie mmm-hmm so now I'm going to dig
into actually how the thing works and
how you would use it and get into some
code examples um feel free to ask me
anything during if it's clarifying what
I'm showing if it's more about like
comparing it to other solutions that
please hold that till the end because
that can take a lot longer to discuss
but please Claire ask for clarification
if there's anything that isn't clear so
I'm going to use these things called
marble diagrams that show sequence of
data over time and try and show the code
examples so that you can you can see
what's going on under the covers so
there is no magic at all to this and so
when you create an observable what this
is all about is you want to create a
function that is completely lazy at
creation time but at some point after
its creation it will be subscribed to
and you're going to receive an observer
that's injected into it so it's the same
thing as the Gang of Four observer and
observable and in this case once you
receive that observer then the
observable function can be executed and
then it can emit on next events as many
as you want
zero or infinite
as long as it's not infinite at some
point you would complete it now the
oncomplete
thing is the is the trick that allows it
to work a synchronously and for an
infinite sorry for an infinite net for a
vector of values otherwise you could
only ever return a single value because
you need a terminal state and so this is
what allows you to have that terminal
state to say I'm done sending values you
can now stop waiting on the other end
the other terminal state is on error so
these are the three notifications that
an observer waits for in the contract is
that you receive 0 or more on next and
then always one of either uncompleted on
error and nothing after that
unless you're an infinite one then
theoretically if it never if it's
perfectly healthy never errors out if
it's an infinite stream you would never
receive either of the terminal States so
let's show a fugitive ii examples on all
of these I'm very explicit in injecting
the concurrency right inside the the
observable typically you use other
things like schedulers that I'm not
going to get into today so you're not
lacing all your code with executors like
this but I want to be very explicit in
these code examples to demonstrate
you're completely free within an
observable to do whatever you want and
inject the concurrency however you wish
so in this case I create an observable
and again remember that this is lazy
nothing at this point will happen until
someone subscribes to it but when they
subscribe you will then end up with a
executor service executing
asynchronously on another thread this is
typical just Java executors you will
execute this thing which then goes off
and does a network call returns that
video rating Simon Netflix I'm using
that example and then it will return
that
and mark it completed so this is
asynchronous with a single response you
could do synchronous with multiple
values and be careful cos in Java we
don't have anything cool like async away
we don't have CSP or anything like that
and so if you do this you do firehose
and block until this is finished and so
but this might make sense if you're
pulling data from an in-memory cache and
you know it's microseconds to fetch it
out and your MIT it there's no point and
launch in doing anything off on a
different schedule err if I'm just
pulling it from a cache so you just
firehose it
asynchronous observable with multiple
vice exact same way except here now that
now in a real world we would batch this
it's this is not something I would
typically do but let's say you needed to
as you're iterating over doing a
separate Network call for each totally
can and then as they come back then
you're emitting them back out I would
normally do more of a scatter gather
type thing here but for simplicity sake
this demonstrates how you could just
iterate over it so now so that was the
observable on the observer side you
could get videos returns and observable
and then you subscribe to it and the
observable does nothing until you
subscribe to it so it's lazy in the
sense that all you've done is define
this object that at some point will
allow you to interact with it when you
subscribe to it that's the point where
you're telling it go and you've given it
this handler this observer that has
three methods on it there's a lot of
overloads to subscribe as well so that
you can use functional interfaces so you
don't have to do an anonymous inner
class and a lot of stuff you have the
three hooks on next on eronel completed
typically you don't need the uncompleted
for most use cases you can shorten that
down and see more often than not that's
about where you're at all that though is
just a lot of interesting chrome around
the callback and that's not really
what's interesting about our X where our
X gets interesting is where I can start
to compose this all together and that's
what takes it from just a you know a
more formalized callback into something
that we can build pretty significant
async apps with and reactive flows so
here's a subset of the reactive focus
are the higher-order functions that
exist on observable then we're
continuing to add more and more of these
is our X Java strives to achieve 1.0
version 1.0 which we're holding off on
that until we can consider ourselves
more on par with our x net so we're
trying to get parity with all of its
feature set and the community is
actively involved once since we've open
sourced this in contributing and so but
I'm going to walk through some of the
big ones
some of the ones that are just critical
and you just use them non-stop so the
first one is merge so across the top
there you have two lines think of these
as two sequences of data flows of data
and they're both I have the interface of
observable around them so it's two
observables and they're amid the first
one emits two values and then the X
represents a failure so it throws an
exception the second one emits three
values and then the vertical line
represents a cannot complete and so what
happens is that we we want to be able to
merge these two into a single sequence
that emits the four values and then
fails you'll notice that the violet or
purple one will never be delivered
because it comes after the failure so
the way that this looks is that if I
have two observables get data a and B
and that's that they're both of the same
type so if you're merging something
you're merging two observables you're
they're of the same type because they're
going to come together with the same
type T and so those two observables
represent what we saw up top and we want
to apply them through a merge function
and so these two things are both going
to pass through that merge function
which is applied right there so you
merge the a and the B and then this is
what we want to get out of it and that's
where it comes out so we subscribe to it
and then we get a single sequence out
and when will receive the on next for
each of those four items and then I'm
for brevity I'm ignoring the fact that
you would also blow up with an error
here you see you would get a non error
the one just blow up and sorry not that
kind of blow up it would pass it on
error all the error handling is all
handled very nicely you don't just throw
them off on some random thread somewhere
they're always propagated back down the
same observable sequences so you would
also have another handler here that has
the the error and I'll talk more about
error handling in a little bit zip is
another common one
so zip is like merge except I want to
combine two things of different types so
here I've got a circle and a upside-down
triangle Dimond and I want to pull them
together so in this kind of case it's
not obvious we can't just assume how you
want to combine them we could have
something like you zipped a tuple or
something like that but in
that what zip does is it allows you to
define a function so you've got my two
observables two different types and then
I want to I have those two streams I
want to put them through a zip function
and you'll see the visit function takes
those two shapes and then emits a
different shape and that's the the
method signature for zip you take in the
the end number of observable sequences
and then a function that knows how to
combine them and then emit some new type
and so in this case here this is what
you see and so it takes in a and B those
are the input arguments and then it
takes a function and this is using
closure nut closure different language
this is using groovy syntax and so in
Java eight you'd have the parentheses
around the X and y instead and that's
the only difference between them and so
you would take in x and y which is art
which I just renamed a and B X&amp;amp;Y just
for clarity and then I'm just going to
return a tuple of X&amp;amp;Y that's as simple
as possible transform I could do I just
want to take those and return them
combined in an array and so that
function gets applied and then I emit
this new type and then I get they get
printed out and then that pair I call
that tuple a pair and it's just an array
of two items in it error handling is one
of the biggest questions in async and so
the the base handler for is an observer
and the observer has the on next the on
error and the uncompleted and so this is
if at the very end of a sequence you
when you subscribe you can receive the
errors that get propagated all the way
down typically though if you have this
huge tree of things compose together you
don't want one error somewhere in the
entire thing to blow up your entire
sequence at least that's not typically
what we want to have happen but this is
where you would it's like this would be
like the equivalent of one big try catch
around your entire flow of data and
imperative code that's what this would
be this on air at the very end more
often than not though instead of
catching there we want to be able to
inject error handling into the various
transforms along the way and so one of
the functions that allows us to do that
is on air resume next
so it's just another function that you
apply to an observable sequence and it's
sitting there watching the events fly by
and every time if it season on error
happen it says wait before I propagate
this I'm instead going to use this other
function I've been given to it's like
flipping flow it like switches the
streams okay and so what it does is it
says if I have a and B I want to on B I
want to handle errors on B not a not the
combination of them but just for B and
when I have an error on that I want to
resume and so let's watch how that works
with the the marble diagram I have a
sequence of 3 on next calls and then the
fourth notification that comes through
is a non error event that on an error
event will go through the on error
resume next function and then which is
set up in the code there and then that
function is going to do this what it
will say is it will the function I'm not
showing it for brevity but that function
get fallback for v4b returns another
observable that it would subscribe to
and then that one returns the blue and
the and the pink and then it emits it
through and so what you see is that we
skip the error we get the red yellow and
green and then we flip over to our
fallback stream and continue with some
fallback data now sometimes you know
what fallback data you want to have
that's legit some other times you might
just want to do a tombstone event of
some kind there this is where the
business logic comes in but this gives
you a hook to be able to control those
error events at any point in the
sequence a simpler version of on error
is yes pardon me
could on-air resume next also fail yes
if you implement an observable there
that can also fail then it a non error
could be if if your fallback can also
omit errors then yes so like there are
cases actually we're at Netflix where we
have multiple levels of fall backs like
that like you go from online processing
to one from a remote cache and then to a
local cache so in that kind of case you
might need a fallback on your fallback
as well mm-hmm
on our return very similar just simpler
instead of it having another sequence it
just has a single value these you throw
down the pipe so when you get it on
error you just you just omit a type T
bar me yes yep it would so you can see
there that it immediately sends out that
vertical bar the uncomplete yes of that
sequence yes so I'm going to walk
through a simple HTTP case now so this
is a very simple observable wrapper
around apache HTTP async client so let's
create a request we're just going to go
off in fact Wikipedia where I'm ignoring
the fact we've created the client
somewhere there's only so much screen
screen real estate here and we -
observable and this is by default and an
observable a byte array so if I were to
subscribe to this I just get a byte
array sorry actually wrong place that's
not a byte array right there that is an
observable HTTP response forget the byte
array part what I get out of this is an
observable HTTP response so when I
subscribe at first all I get is the
thing that tells me the headers the the
status code those types of things but
not access to the data yet so this is a
two tiered response structure because
with HTTP you get the first thing back
typically which is like tell me the as
soon as the header comes in status code
and then I could get this flooded data
coming afterwards so I want to decouple
those two so in this case they get back
this observable HTTP response
and then I want a flat map over it and
what flat map does is it allows me to do
nesting and I'll talk about flat map a
little bit more in more detail at this
point then I can get access to the
status and the headers but then I want
to get that content which is a byte
strut I'd array and then convert it into
a string in my case I want to string now
I can subscribe to this and print out
that string response or for this is just
a so you can see how you can flip out of
this a sync world you can also step back
out into the imperative blocking world
by going to blocking observable which
exposes a lot of functions like for each
and single and last and those things so
you can step out of it very useful when
you're doing like unit tests or just
simple like you know main method just
examples so you're not like manually
doing countdown latches somewhere to
stop your async out from shutting down
so you can use that but typically we
never want to see those things in
production ABS these two blocking
observables now that was interesting but
that's just returning a single response
where it gets really interesting is
where if I flip this from just a normal
website to something like the historic
stream so hystrix is our fault tolerance
system and Netflix and every single box
in our company that uses it has a server
sent event servlet on it that is in just
a constant stream of data coming out of
it so if I subscribe to that instead
what I'm going to get out of it is just
a constant stream of observable on next
events and it's just going to keep
firing these events at me and so this
starts to get into handling an infinite
stream of data and allowing me to work
with it so I can filter out all the
pings so it sends down these just health
checks every like 10 seconds just to
make sure the connections all happy so I
can filter those out in this case let's
say I just take the first 30 and I'm
done but it could get far more
interesting and for brevity I'm not
showing them here today but you can
start to group and sample so you could
like split them out into the different
metric types and then sample one a
second and do those types of things
merge them back together transform the
data into
format that you're ready for and so this
starts to show where an HTTP stream can
be consumed with an observable and it
just fires events at you all in a
non-blocking way but I'm going to take
you now through as we head into the end
of this walk you through a lightly more
complicated example of how this is this
is the use case that drove our adoption
so at Netflix this is a simplified
version of one of our more complicated
UI requirements which is I want to come
in and fetch a list of lists of movies
so I get back all these these videos and
I end up with a grid on I've actually
have taken away one of the dimensions
here to simplify that but as I get back
a list the movies then for each of those
movies I need to go off the multiple
other services to fetch all this other
data there's metadata and ratings and
bookmarks and all these different things
and do all this spread this all out
concurrently with the variety of mail
recalls and then pull it all back
together asynchronously and then emit it
out the to the device so I want to get
back this observable video so video
service I get videos returns me a video
and so on my code this is actually what
our UI teams write this this groovy code
is just a simplified version of exactly
what we power our our systems with today
written in groovy and so let's say that
that UI actually only has space for 10
devices is 10 on a row instead of 50 or
100 so they want to take the first 10
and so what take 10 does is it chains
off of the first observable it takes 10
of them and then it unsubscribes from
the parent and so what that allows the
parent to do is to stop doing any
further work now sometimes it already
has all that work it was like a batch
Network call so what it will do is it'll
stop sending it but if this is one that
was still doing Network calls or other
traffic it unsubscribes and cleanly
shuts all shuts it down and clinton
tears down the resources you you can yes
there's a lot of multicast operators
multicast publish ref count there's a
whole variety of those as well yes
so I take these and now I want to
transform that video object into
something that the UI is ready to
consume so in this case we want to get
out some JSON at the end and so I don't
actually need that video object just
serialize I want to do something to it
so what map does is it takes type T and
a returns type R and it lets me do
whatever I want in between to transform
it and so we're going to do that however
we need something a little bit more
advanced so we want a flat map instead
so think of flat map is just your going
to map over something that it itself
returns an observable so right here and
it if you ever see map many same thing
map many flat map the flat map is more
common in the Java world in is
particularly in Java 8 and so you
flatten an observable of observables is
what that is so you're starting to get
into these nestings of asynchronous
streams of data and so if my map
function is going to return an
observable of R instead of are the most
likely I want to do a flat map because I
just want to take all those observables
and flatten them out into one sequence
and so instead of me getting a bunch of
other observable sequences here just
going to flatten them all out into one
and so the reason why I'm doing that is
because within this for every single
video I now want to go and fetch some
metadata and then on that metadata
metadata bookmark and ratings and so
just these three things I'm going to go
off and fetch and for each of them I'm
going to do very similar work I'm going
to as I get back that metadata again all
asynchronously I'm going to transform it
from the data I receive into a
dictionary of data so this is using a
groovy literals it fits on the screen a
lot better so that's why I'm using
groovy syntax here so this is title as
the key and then the value and then
length is the key and then the value and
so I'm transforming them into a format
that's ready to go to my device and so
right here this map many are flat map
underneath it I'm doing these nested
network calls asynchronously and then I
transform them look and I do the same
thing for bookmark and ratings and we
squish it all up
is I don't have enough screen real
estate now I need to combine these at
that point if I just leave it right
there
what's going to happen is that those
three things will never actually run
because nothing ever so all I've done is
declare them and so nothing will
actually ever execute them and flatmap
will actually not work all that well
because it's going to implicitly return
a null here so I need to do something I
need to compose these things together
because what I'm actually wanting to get
out of every single video object is a
transformation to the data that I want
to return to my user yes I'll show you
ins is how zip works in just a second
so what zip is going to do is I'm going
to pass in mbnr which are metadata
bookmarked in writing and I'm going to
give it a function that takes in each of
those three and tells me how to combine
it and so what zip does it back to that
diagram is it will take in these streams
of data and give me a function that
allows me to return whatever my
combination is now behind the scenes
there's no magic going on here what
happens is zip is one of the more
complicated operator implementations but
behind the scenes it is keeping track of
all the ones that it subscribed to and
then every time it receives and on next
from all three of them so they could all
be coming at different times and what it
does is it retains just a queue of each
of them and so if the first two come in
they'll be sitting there waiting and
when the third one comes in it then says
I now have new values for all three Co
on next with those three values and emit
them and so yep
you it'll take whatever order they come
in oh it's because it's because when
this composition happens mbnr those are
in context of that single video one
object and then when the next video
comes in it's a separate context and so
you're actually creating three
observables for the first video three
observables for the second video three
observables for the third video and so
on so they're all very light with the
they're fairly lightweight and it so
it's composing these things all together
so this becomes actual if you were to
draw this whole thing out it is a very
big web of types of data flowing around
and so this here for anyone who's not
familiar groovy what this is doing is
it's a literal map ID key and value and
then it's just concatenated through the
three other dictionaries in that were
retrieved from
mbnr so we created up up an MB n are and
then you can catenate them in after
using just side now after using groovy
with this it's really hard to go to Java
eight where I don't have that syntax
which is why Java a didn't make the cut
for the slide because it didn't fit so
zip then M is basically it pulls it all
back oh this is where I scattered out
and I performed in this case it would
have been if I was doing this
inefficiently I'd have 30 Network calls
that went out and I pull it all back
together I get 10 emissions of these
dictionaries that are coming out yes
let me get to that at the very end if I
don't come back to it harass me at the
end and so each of those videos would be
an object a dictionary looking like that
now in real world there's a lot more
data in them than that but that's a
that's what we've just created here with
this code and so all of these
interactions have been asynchronous and
non-blocking
and the thing is also is really nice
about this is it's all declarative they
declare their intent and then at the
very end they hit the subscribe button
so to speak and then it fires it all off
and then we on the API platform side we
worry about is that coming from an
in-memory cache because we already have
it so if so let's just fire hose it or
is this coming from a network event or
we're using n io on this one but
blocking HTTP on this wrap by a thread
and so we have all those different we
can we retain that control and we can
change something like when we get a
back-end system to let's say move from
blocking now or blocking i/o over to a
non-blocking i/o they don't change a
thing because they're still consuming it
asynchronously and so that was a big win
for us yes
so the the ordering of everything in our
ex is retained unless you purposefully
use one of the parallel operators that
allows you to move get out of order and
so it is each of these steps along the
sorry so film like from here to here
what it's doing is its waiting behind
the scenes when I say waiting this is
all async it just doesn't emit the value
until it happens and so it would there's
a lot of implement I can talk to you
afterwards on the implementation detail
but behind the scenes there is retaining
some cues certain operators do have
cueing behind the scenes it's actually
not blocking it it just it won't emit
the new value until it receives one that
it's way that it needs and so it's all
still push based like an early
implementation of concat which is an
interesting one was accidentally made
blocking and it's an interesting just
twist of where you put the cueing to
make sure that it still retains the non
blocking behavior but retain it keeps
order so in our experience what we found
is that by putting this layer at the top
of our of our API platform we
accomplished the goals that we wanted we
wanted to enable anybody to build these
highly concurrent highly responsive web
service endpoints on top of us and our X
and the the functional reactive style
has proven to be a great win for us it
was such a great win that we decided
that we wanted to push farther into our
stack and so we'll you took history
which had been it exposed either
synchronous execute or you know queue
and get a future back and we threw on an
observed method on it and we laced
observable rx all the way through to the
bottom of historic saz well so hysterics
we made it completely non blocking top
to bottom so we're now slowly pushing
these patterns from the top all the way
down to the very bottom of our stack
that's not something we're just like
spinning up projects to go
do that but as we touch new code more
and more removing to this pattern
because we've we found it to be so
successful and so all of the all that
that we want to accomplish they're in
this circle is what rx has allowed us to
do without having to worry about any of
the concurrency primitives some of the
lessons learned are that developer
training and documentation was key we
were taking a lot of Java developers
that had 10-15 years of bias in the way
of how to think of the world I myself it
took me a few months to get my head
wrapped around this thinking once we had
it all once we had the model what we
found is that there was the first round
of developers coming on it took about
two weeks of solid effort from them to
get their head wrapped around it and
there was some wailing and gnashing of
teeth at first and it wasn't until they
got kind of got that lightbulb moment of
oh okay now I'm seeing the data flow
like this and I totally get why we would
want to move to this and then they don't
want to move back for I'm not saying
this belongs at kernel level but at the
level where we where you're just
handling data and moving data around
which is what eight web service is an
API is a web apps you're typically doing
at that level where we're working it
just makes sense and so to help with
this we actually spun up tray just you
know pretty simple informal training
classes just internally and we actually
hired a tech writer to write internal
documentation is the best documentation
I've ever seen for an internal project
and it's been a big help the money was
well spent so that we were able to
actually say to people here's the docs
and how to you know how to think like
this how to use these operators and so
that that was something that we learned
and has been beneficial the other thing
is debugging and tracing still is a bit
more painful and async that's not a
perfectly solved problem yet it's
something that Eric Meyer inventor of rx
is continuing work on I have some
thoughts of them talking to him about
this is an area that we're looking at
putting a breakpoint and something like
this is not quite the same experience
the RX does support things like virtual
scheduler so you can like remove
all concurrency which is awesome so that
when you're doing unit testing and
development you can turn all into a
synchronous model you just have lots of
very interesting stack traces through
all the composition the only rule that
we've had to set and this is because
we're on the JVM where the compiler and
the language itself does not prevent you
from doing this is don't mutate state
outside of a function it just don't it's
never what you want to do and as long as
you obey this rule
it's amazing the flexibility you get
with concurrency and so that really has
been the only rule I can think of that
the people have just had to learn don't
put something like even if it's a
concurrent hashmap outside so it's a
thread safe don't do it your application
probably will not get what it expects
because timing is all non-deterministic
so in closing these two things when
combined have proven to be of great
value to us and they were a big enough
deal to us that we formalized the
project it started out as just an
internal like get three or four of the
operators working on internal thing we
liked it enough there was enough benefit
in it that we decide to once Microsoft
open-source theirs we decided to
formalize ours in an open source it and
over the last nine ish months it's be
the community around has been really
great and we're pushing towards getting
to Wan dotto with it you can learn more
about it all here I've got so five
minutes I think I've got left to answer
questions I'll try and address yours and
back here
so we unit test it the exact same way as
any of our other unit tests a J unit and
all that stuff yep the where it becomes
interesting what our x contributes is it
there are certain operators like for
example sampling sampling only works if
you have something ticking along in the
back and so in that there's a scheduler
that gets into think of scheduler as
this an abstraction over how do you want
to inject concurrency and so there's a
there's a test scheduler that has
artificial time where there is no actual
concurrency and then in your unit test
you can actually just advance time along
and so you can assert what's is the
state what you expect at this point
advance assert advance assert it's
awesome for handling these types of
things it's all yeah it's all in the
Java Doc's and on the wiki yep all right
but what was your question again oh
right how does it go back to so on the
on over on a lot of our devices they're
using rxjs so same pattern on the
clients across the network actually the
cleanest way and the one that I like the
best is you can go WebSockets but unless
you need the bi-directional support the
you don't always need all the setup to
make that work just a normal servlet can
do server sent events event stream and
all you're doing is you're just flushing
after after your events and all you do
is you put data colon in front of it and
it complies with the the spec and then a
new line at the end so if you just go to
the html5 spec server sent events mime
type is text slash event - string and we
use that all over the place for where
we're doing streaming stuff yeah
so typically the backpressure just
naturally happens at the top so it's the
source observable that it would start to
that you can unsubscribe back from it
and typically anyone operator won't do
that naturally so like zip itself won't
do that but you can apply other things
along the way to do that we we use like
hystrix for that because we treat that a
lot lower level but the back pressure
you can input in other places in it I
can talk to you more about the details
of that after
we we use it the same way you're
typically not doing all the combinations
and transforms on it because typically
they're you're just firing it off and
then waiting for the response so in that
sense it's just more that we're
leveraging the same abstraction just for
the async behavior how do I log events
which type of events we go we use lots
of different things come up to me and
talk afterwards we you have whole data
systems for that stuff back there that
would not be the job of our ex that
would be something else to do there's
another system we're working on that
would be reactive string processing
where it has checkpoint mechanisms and
stuff in it for like a scan operation
that's like running weeks at a time for
machine learning and so you checkpoint
that as you're going through but that's
just that would be the data persistence
object rx itself wouldn't play into that
no but that's because we're we're not
the type of app that is like we're not a
financial trading app that's worrying
about microseconds if you're good
functional programming by nature it
creates a has a lot higher object
allocation rate than imperative because
you're not typically you're not mutating
State and there's a lot more composition
but the JSON all the serialization that
goes in and our App far outweighs
everything Rx adds to it I just go
profile your JSON serialize or something
so it hasn't been a problem for us
yes yeah there's a timeout operator
retry operators repeat operators all
those types of things we we use hystrix
underneath because it's a much more
comprehensive bulk etting solution with
timeouts and those things but rx itself
also supports those things with a
timeout operator
it's completely up to you what you do
once you get that event back if the
timeout occurs and emits the on error
you can do on-air resume next as to some
other thing yep thank you everyone</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>