<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Graal: How to Use the New JVM JIT Compiler in Real Life | Coder Coacher - Coaching Coders</title><meta content="Graal: How to Use the New JVM JIT Compiler in Real Life - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Graal: How to Use the New JVM JIT Compiler in Real Life</b></h2><h5 class="post__date">2018-04-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AmiBvU6uL-Q" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello welcome my name is crystal injure
I work for Twitter
obviously I live in Hawaii so I'm
wearing my sandals today because it's
warm outside I like that so Twitter
everybody knows what Twitter is right
who has a Twitter account that's pretty
good I like it so Twitter has a small VM
team the JVM team about four people
three of them are Chi C engineers they
take care of you know all the GT
problems that everyone has our micro
services have and then I am the compiler
guy so I make sure you know code gets
compiled and stuff and and is fast so if
you're going to tweet about this talk
and ice I will encourage you to do that
please add that hashtag Twitter VM team
and then you know my people at home they
know that I'm actually here and talking
to people and not just making things up
being in India so I talked a lot about
Gras and there is there are some one
main reason I mean they're kind of three
but there's one main reason why I'm
giving these talks and especially this
one is I want people to try Gras okay
who knows what growl is let's start
there okay
so we'll get there a little bit later
but it's uh okay let's ask all these
questions now I could ask them later to
zoo you guys know what the JVM is right
you know what hotspot is yes
who knows what a chit compiler is okay
yeah that's really good so JIT compiler
just takes Java bytecode and translates
it on the fly during while you'll run
your application to native code so your
application runs faster that's a chick
compiler
oh yeah I'll talk about this a little
bit later we used to achieve in our
microservices are written in Scala
we do that - yeah but what you're not
talking about this today so the talk the
reason for this talk is I want you to
try it and there are a few reasons why I
want this a number one reason is it's
possible for you to save money to around
your business that's what Twitter does
so Twitter we have many many micro
services and most of them are written in
Scala and they run on top of the JVM and
by using grah we save a lot of money
then I want you to try it because I want
to fix boxing raw and then I want to
make raw better you know if more people
use it you'll find use cases that you
want to optimize for and then we can add
that code and so on and so on so these
are all the reasons why I'm doing this
talk and also after my previous talks
where I talk about how Twitter's using
draw people came up to me and they asked
me so is it safe to use because it's
still an experimental feature how do I
use it right and where do I get it so
these are the questions like I get or I
got and so I prepared this talk and this
talk will answer all these questions and
then sometimes when I got them to try
growl they sent me emails or things like
that later and this they're mostly
complaining about benchmarks numbers so
they were running their benchmark they
were running for the last ten years and
they're running and say all this this
really sucks and there's a reason for
that and grah has very different
properties than the existing check
compiler and we go into detail so I'll
explain to you what you need to look out
for if you do in benchmarks with your
own either application or whatever
benchmark you're running so if you want
to know about the money saving part and
how Twitter is using draw you should
watch my other talk called Twitter's
quest for a Holy Grail runtime
it's like typing in on YouTube I don't
find it they're a bunch of videos so
watch that one so what is growl as I
said it's a java virtual machine
just-in-time compiler right it's
actively developer Oracle apps there is
an official open JDK project on the open
JDK java.net website the source code
lives on github and it uses something
called che vm CI I talked a little bit
about this later but it's basically the
compiler interface between draw and the
VM
and then it's written in Java that's
very important so if you want to take
away one thing from this talk other than
it was really cool it's written in Java
and that's the biggest differentiator
between the existing chick compilers C 1
and C 2 and grow because C 1 and C 2 are
written in C++ and C++ has very
different properties than Java we all
know that right but this is very
important to remember because people are
surprised that suddenly their VM behaves
a little differently than they are used
to it so let's answer all these
questions right so where do I get it
okay so there is a chap called 295 and
it's ahead of time compilation we added
ahead of time compilation in JDK 9 and
there's through that chap we could go
there but I don't have a lot of time so
I'm just telling you the check of äôt
the feature äôt is using draw to compile
a native code to do the äôt compilations
so and in jdk 9 you can use through that
feature you have access to growth but
even better since JDK 10 is out now
there is there's a chap called a 3:17
experimental Java based chick compiler
and that's exactly that so Oracle added
Grau officially as an experimental
feature to JDK 10 and so if you download
JDK 10 you have all what you need okay
so this talk is very different than all
the other talks that I've given I'm
probably different than people usually
give talks this talk I'm trying to do as
long as many demos as I can I don't know
how much time I have left because this
one's not running but I tried to do as
many demos as I can and they do the
demos in an Oracle cloud instance but
I'll do everything from scratch like the
cloud instance is not running right now
we're starting it up in a minute
and I do this for a reason because when
you see talks with demos at least when I
do I always ask myself so how many how
much time did the person spend to set
this up that it actually works them on
stage then and doesn't you know fail but
I thought I'll show you from scratch
what do you need to do to get the che
decay and to run
things with Gras and everything I do
today is basically what you have to do
the cloud instance we're going to fire
up doesn't even have Java installed
there's nothing on it right we have to
do this all by ourselves okay so let's
do this
this also means there will be a few
awkward pauses when we have to wait for
things to happen like download and
things like this okay so I don't have
unfortunately wired in their net so I'm
going through Wi-Fi and we're hoping
that this works fine we'll take a little
longer you know for all this stuff to
load so this is the Oracle cloud
interface I don't know if you guys know
this I'm a I'm gonna go back to the
slides real quick I'm an Oracle
developer champion so through that
program I get free credits on the Oracle
cloud and so I can run stuff on the
Oracle cloud for free which is really
nice so let's go back here and then we
want to create a compute instance and
awkward pause I'm sorry I feel but you
know I want to do it this way because
it's so it's so easy for you then to
follow later what do you have to do to
run this stuff so we're waiting oh well
that would be cool let's try it out
we're getting wired Internet look at
this let's see probably faster
network
how we doing yes much better let's turn
this off and let's see if it works
better okay here we go
do you want to create an instance I hope
I'm still locked in let me reload that
page and we will see if it's faster than
that yeah it is faster that's great okay
so we're back hopefully when it's
loading come on there we go so we
created an instance we call that
instance
Venga I want to type the whole thing a
lure thingy so we created one in this
domain doesn't matter we use Oracle Ling
of 7.4 doesn't matter we use disk VM
type which has four cores and that's
kind of important when you run something
on the VM you want to give it a little
more core doesn't done just one because
you have to see threads and compiler
threads and all this stuff right so then
we need some SSH keys I've pasted one
mind before so I can just edit here then
we have some networking settings and so
on and so on and that should be it so we
create this instance and then it should
be provisioning here that should be
pretty quickly what we're waiting for is
for this public IP address down here so
we need that and there it is very good
so we take that copy it and then we can
log in here not yet because it's only
provisioned yet it will image now and
then it has to start up blah blah blah
you know how this stuff works so this
will take a while and I can't change the
fact so what we're doing in the meantime
I'm telling leave a little bit about
myself so as I said my name is Chris I
work for Twitter that's my Twitter
profile picture I used to work for
Oracle and some Microsystems and so on
and so on like I do a small conference
called lob lob one on Hawaii so we had
it earlier this year in January I'm
working on TV amps for a very long time
so over 13 years and most of the time
actually all the time I'm working on
compilers so that's that's what I do
back in the day I don't know I'll call
out some people you know who remembers
canoe glass paths before some open
source java no no old people old people
yes so I used to work on canoe classpath
back in the day and you know Sun was the
big bad company and we were the Wild
West fighting against but you know they
were they open source java and we all
realized okay they're not that bad after
all
and so i started to work for sun in 2009
I think and then Oracle acquired Sun and
I was always part of the Oracle of the
hotspot compiler team so I was working
on compilers all the time they were most
of the time with c2 I worked on three
major you know chips enhancements thing
is besides fixing a trillion of bugs I
worked on chase our to 92 which is
invoke dynamic support for dynamic
languages so john rosen that we were
working on this for a while and you
could technically blame me if it doesn't
work but a lot of people you know
attached it after me so i think they
introduced bugs and my implementation
was fine so then we did chap 243 JVM CI
a-- mentioned this earlier which is we
took the the interface that growl is
using and took it out of growl and made
it a standalone interface and put it
into jdk 9 and the goal was that you can
download an Oracle JDK or an OpenJDK
build and you can just download growl as
well on the side and plug it in and run
with it so we added that and then I was
working on 295 as well dat stuff that I
was mentioning earlier so that we can
ahead of time compile certain things
including growl itself right ok and now
I'm and the Twitter VM team which is
great Twitter yeah great company love it
so let's see how we're doing here if we
can log in and I was talking long enough
yes we can that's excellent
so we log in here too and then we hope
the legs and up that bad no it's cool
I don't know how many of you have ever
typed a lot in front of a lot of people
it's you know so I apologize for all the
type of stuff will come so what do we
have to do next
we need to get right let's go back here
I told you we don't we don't have
anything installed on that instance so
we don't have Java first what we need
first what we need is we need to get
because later hopefully I can show you
how to build raw from source so we need
that I'm doing I'm doing this here on
the side I do a lot of things in
parallel so you know then we do cheat a
Catan right we download this official
JDK 10 build and over here download it
we hope it's fast otherwise we have to
wait too long yeah 37 seconds that's a
long time so I don't know what to tell
you in the meantime hawai is a nice
place to live who's been in Hawaii you
liked it it's better than here or I
heard Goa is nice
I heard Goa is nice alright so how does
the surfing any surface here yeah you
surf excellent where do you surf
oh you mean in the States
yeah that doesn't count okay here we go
so we unzip that guy and this is almost
done okay so we we set Java home because
a bunch of things we're doing later and
eat this we also know we put it on a
path there we go and we do the same over
here so we do this and do we do this
perfect so now we have a Chava tan if I
can type here we go can you guys see
that at the bottom no you can't because
it's behind me here we go so we have a
cheetah Kattan here now and in let me
clean it in in 9 you know modules were
at it and so it does there's an option
called list modules and it lists all the
modules that the JDK has it's like 75
modules but what we are looking for is
modules that are called JDK internal dot
the M something and I'm sorry here we go
so we're looking for this one here which
is the JVM CI code JDK daughter and
trilled of the m dot c edits JVM CI so
that's the interface you need and then
we're also looking for this module which
is called JDK dot internal VM that
compiler and that just contains grah
code that's really it so if you have at
ATK that has these two modules you're
good to go in nine you only get these
modules on linux x64 but in ten you have
it on all the platforms you have you
know Mac and Windows and Linux only
64-bit by the way okay so we have this
perfect so we know and we have draw
let's go back to the slides
yeah there you go so how do I use it so
you get a shady Kara dad module we check
that yes we have it cool and then all
you have to do is turn it on that's
really it
so let me show you how to use it if we
go to chip 243 this one and it's been
interesting it's been included in nine
and you scroll all the way to block to
the bottom it tells you how to enable it
a compiler through JVM CI with these
flags so it's it's an X it's still an
experimental vm options who you have to
enable these and then you tell it you
tell the VM or please enable JVM CI but
they'd only enables the interface it
only allows you to access the interface
it doesn't automatically turn on the
compiler but and then you have to tell
it or used
see I can pat it so if you if you use
these three options then you're good to
go there's another one where you could
technically select different compilers
that you have but today there's only one
compiler that scroll that's using this
interface so we don't have to do this
okay so I'm also setting something
called Java tool options an environment
variable and this one's being picked up
automatically by by the VM a hotspot and
we are turning on parallel GC because a
g1 is now the default GC and it's it's
heuristics it has too much heuristics
for the things I want to do but parallel
is very straightforward and it we can
read the GC output later so we do this
we set a pretty small heap size we only
use 512 megs
and we set the maximum and the start
size at 512 and the reason for this is C
2 is written in we want to compare C 2
and growl that's that's the whole point
C 2 is written in C++ and gyrados
written in Java so when you start up
with growl we'll see that later when we
talk about bootstrapping
it's allocating memory on the Java heap
so the heap expansion with grab would be
different than with C 2 but we want to
compare apples to apples basically so
that's why we do this okay so we set
that and then over here we do the same
but also at these no copy this stuff
here we go put this in here perfect so
if I run Java dash version and you'll
see oh yes the the VM picks up all these
options and then a prince of version
okay good but it's not doing anything
particular there is there's a
command-line option called print flags
final and we do a version and we grab
for JVM sea ice or a bunch of JVM CI
command line flags that you can use you
know one of them we just saw it as an
alt JVM yeah that's true so we know yes
it's actually tore down and use JVM
tactile that one's to to we're looking
for this one JVM CI print properties and
we do
xx + JV MCI print properties and it's a
long list of properties very long list
and most of them let me make this a
little bit wider so if you go all the
way up you see there are only a handful
of KVM CI properties and a long list of
growl options where you can tune growl
and turn things on and off so we're not
going into this what we want is this in
the timer 1 because it it will print
timing wild Chive EMC I and growl
initializing during JVM startup so these
are our since JVM sea-ice mostly Java
right there's a C++ part as well
obviously but there's mostly chava
and growl isn't Java options pass to JVM
CI and growl are Java properties so kit
- capital D right so we do - capital B
and then we have to turn it off Java
property and we just do a dash version
and we say ok everything's being picked
up but it doesn't print anything right
so what's going on well JVM CI and
corral are lazily initialized so if we
are not compiling anything it's not
being initialized so we can do a print
compilation here if I can type okay here
we go
and then we'll see all the methods that
are being compiled when we run - version
who knows what tier compilation is ok so
tier compilation means I told you we
have C 1 and C 2 so that's the client
compiled into server compiler -
different compilers see one is for is a
high throughput compiler compiles
quickly and C 2 is a highly optimizing
compiler which takes longer but produces
peak performance code so you start up
your VM you'll run your application and
it starts out interpreting your code
which is slow and then you have two
tiers you go through you go from
interpreter to c1 compiled code which is
faster obviously and then you run a
little bit on c1 cone collect profiling
data and then at some point you compile
with c2 so these are the tears you go
through and the tears this the third
column here is the tier number tier 1 2
3
are different see one compilation modes
and tier 4 would be c2 or Gras so when
we run a dash version there is no tier 4
compilation because the hot the code
does not get hot enough to actually do
it here for compilation so JVM CI and
crawl are not initialized so we need to
run something else for this and we're
downloading the scallop the capo
benchmark which we are using later as
well for other things and I really hope
no don't do that don't do that and I
really hope this is fast let's see just
downloading I hope not yeah that's kind
of right 6 seconds okay we can wait that
we awkward pause sorry okay
so now we have that and so we run this
init time a thing again here I think
it's still downloading
where are the Downloads I'm usually not
using here back so Scala
it's called Scala here we go there is um
there's a dash l which basically just
lists all the benchmarks that it has so
we do that and we see oh yeah it's
printing something right so if we run
the same thing just for comparison over
here you know what I'm talking about
so it would just print all the
benchmarks that it has rather but over
here there's a bunch of output which you
know has JDM CI in it so it actually
initializes JVM CI but it's not really
finishing doing this and the reason for
that is that a - L execution exits
before Jaime MC angrel I actually
initialized and could do a compilation
so we need to run a little more to get
code a little harder and run for a
longer time to actually see that so what
we're doing is we're running a small
benchmark run of Aurora here we go
much better a lot more output okay let
me run that same thing over here as well
for comparison
so we initialized shaving MCI that's
this right and then after 77
milliseconds it's done cool and then
there is this compiler configuration
factory which selects the chick compiler
but we only have one available so it
automatically picks scroll and then you
can see it starts initializing graph and
then it actually runs the Mensch mark
the initialization output
I think it's cut off by the but a
benchmark harness so it kind of
redirects output it into a file so we
don't see that but as you can see the
the execution finished in about 5.2
seconds okay off that benchmark run over
with c2 we have about 4.6 seconds for it
for the run time so it is it's usually
roughly about a second difference okay
good
let me go back here to the slides
because now we have to talk about
bootstrapping so bootstrapping Corral as
you know it's just another java
application running in your JVM
so it's Java code that means it has to
load Chava classes obviously it has Java
methods because it's written in Java
yeah and that these Java methods off
grow at some point need to be compiled
you cannot interpret them forever
because it would be freakishly slow and
your startup if your application would
be freakishly stall so at some point you
need to compile these and that process
is called bootstrapping right you start
up your VM at but at the same time you
need to compile your compiler alright so
let's do a bootstrap demo over here
there's something called you can do an
explicit bootstrap this is something I
would not suggest you to do but it's
very helpful to show you what what a
bootstrap really means so we do that
it's bootstrapping every dot is 100
compilations so this should be done in
about 9 seconds and it's it's grabbing
all the CPU cores it can get in our case
4 so it's using all 4 cores to composite
off you took yeah 10 seconds ok we
compiled roughly 2800 methods ok there
is
when we go back to wait was it called
chili I'm see I print this guy there's a
there's a flag called
c1 only and it's a growl flag and it's
set to true and it says compile growl
with c1 only so the way the default
setup is you know remember to your
compilation of it that I told you about
the way it's set up when you have broad
when you replace you to with growl and
you run stuff with growl growl itself is
only compiled by c1 and the reason for
that is if you would compile growl with
itself it would take much longer but
what you want is you want growl to be
compiled as quickly as you can which c1
can do because you need growl to compile
your application right so we could you
know do this bootstrap or was it what's
gone we could do the bootstrap and turn
kit compilation off and if I could type
and do this compilation compilation is a
very hard word really compilation here
we go as well take much longer because
now if we turn off tears and so that
means we only run with the interpreter
and growl so now growl has to compile
itself while it's it it's so a bootstrap
I haven't mentioned this a bootstrap JVM
said what it does it takes all the
methods of of java.lang object which I
think are only five and they are super
simple and it schedules them for
compilation and while it's doing this
growl you know works on this and gets
hot itself and so its own methods get
hot and they need to be compiling more
and more and more gets hot and that's
how we end up at 2,800 methods or in
this case where is it
here 4840 4900 methods so and this takes
a long time right this just takes 30
seconds and the other one took 10 so you
guys must be thinking okay what's this
guy talking about I mean I don't want to
wait ten additional two seconds for my
thing to start up or even thirty right
where you don't have to because if you
remember I told you bootstrap shaving
MCI doesn't explicit bootstrap and it's
something you don't want to do what
you've won is an implicit bootstrap
while you startup and that the
compilations happen automatically in the
background so if we go back to this
example again this benchmark run and we
turn off that that printing thing here
because we don't need that I still have
it over here so it was 46
but 4.6 seconds right and this one was
five point I don't know five point three
that's not ten seconds right so what it
does you have your machine your cloud
instance whatever you have a bunch of
course there right and you I'm pretty
sure correct me if I'm wrong but I'm
pretty sure you don't configure your
containers with just one core because
you all still need cores to do your Chi
sees right you don't you need a bunch of
GC threads to be G sees fit to be the
cheesie's to be fast and so what the
come what the VM does if these threads
are empty it grabs it for compilations
and that's what's happening here that's
why we only see it roughly not even a
one-second difference right but we're
running the benchmark on it
okay so let me go back to the slides
here so what have we learned here so a
bootstrap compiles a lot of methods
right we saw about 2500 4800 something
like this so it's a lot of stuff but it
disappears in the background while
you're starting up so you can either do
it up front I don't suggest it or on
demand during the runtime that's what we
just saw with the benchmark right and
then by on-demand compiled scroll with
c1 only that's the flag I showed you you
could turn it off you would get a little
bit different results but I think for
everyone in here and Twitter is using
also the default setup and we've never
had an issue good
Java heap usage very very very important
because Gras is written in Java right
so when Gras compiles a method of your
application it uses Java heap memory to
do this C 2 and C 1 you
use Malik native see Heep right so it's
somewhere off heap but growl uses on hip
memory that's super important to keep in
mind because it will show up right and
it will produce GCS but don't be scared
because every compiler uses roughly the
same amount of memory to do compilations
it's just it's a different place where
it's allocated in a container cloud
world as we are today you have a cloud
instance with an amount of memory I
don't know let's say four gigabyte a
memory right and then you you tune your
your VM to use as much memory as you can
but if C to compile stuff and uses one
or two hundred megabytes to do this it
allocates them as well it's just off
heap and if you're actually going over
your code or probably your instance will
go down if you do it with growl the same
thing it will allocate one or two
hundred megabytes of memory or much less
depends on the method but it will be on
the chava heap right anyway let me show
you what I'm talking about so we do a
Java heap demo we run this benchmark
here let's remove that we turn on TC
logging and so this is what it looks
like they're a bunch of explicit GCS
here that that's the that's the cup of
benchmark hardness it just cleans out
the the heap memory and then it runs the
GC run so that that was that there was
no G see the Aurora benchmark is very
compute intense benchmark so there's not
a lot of allocation going on but that's
exactly what we want and if we run the
same thing over here with Gras you'll
see okay yeah that's some GC stuff
happening okay and that's exactly
compiling the update the benchmark
methods right so we're doing this let me
run this one again and I want to show
you we want to want to do three
iterations it's quickly so we can do it
so in the first run you compile a bunch
of benchmark methods and then in the
second run you can see okay yet is still
one to see happening and then in the
third iteration
there's no GC happening anymore so after
how much is there's like 10 seconds
we're not compiling anything of the
benchmark anymore and we basically run
at the same speed 4.2 seconds compared
to whether we have over here 4.6 so it's
actually faster now right so the first
one which is 4.3 that one second delay
is the overhead you have by using graph
but it's only during the very beginning
of your whatever you're doing you're
starting your running your benchmark or
you're starting the application you the
maturity of your compilations will
happen in the first depending on the
size of your application obviously but
will happen in the first 30 seconds one
minute two minutes and then you're done
because everything's hot and being
compiled there will be you know some
compilations happening later but the
maturity is in the very beginning but
99% will be at the very beginning and at
that point your application is not even
up yet right it doesn't even accept
requests yet it needs to put in the
Twitter case you know we a micro service
based and so a micro service comes up
and then it needs to connect to a
hundred other micro services to build up
connections and whatnot and then they
usually warm up themselves a little bit
so when they get the first request they
the response time is it's pretty good at
that point all your compilations are
done it doesn't matter and at the same
time you're not at that point doing that
startup period you're not using all that
Java heap memory right because you will
use all the Java heap memory later at
your steady state but while you while
you're coming up and not accepting
requests you're not using all the Java
heap memory so the allocation of grah
the Java heap memory allocations of
crowd don't really matter
we never at Twitter have a single issue
with that and we are running three of
our most important services plus a bunch
more but three of our most important
ones the tweet service the social graph
servers and the user service with
thousands of instances we ran them now
since I think in nine months now 100% in
production like everything you see on
Twitter do and read goes through code
compiled by Gras and I think it's fine
right did anyone lose tweets or
something did it no see works fine
okay so chorale uses Java heap memory
yes that's true but it's not a real
issue there is no heap isolation yet
this will come at some point right now
we don't have it because what we want is
when and this will certainly happen
because everyone is tuning their heap
size to the you know absolute maximum
you can do plus one megabyte more to
have a little bit of room but then when
suddenly and a compilation will come in
and use too and it makes a memory boom
out of memory error right and that out
of memory error will be delivered to one
of your threads that produces the out of
memory error it could if you're lucky
end up on the compiler thread that would
be fine because the compiler will catch
the error and just abort the compilation
and the application will be running fine
but could also happen that your
application just happens to allocate
something and it gets the out of memory
error and then it brings your
application down so this is something we
have to work on and by we I mean the
open JDK community and Oracle but again
this never happened for us at Twitter
never and we have I can't tell you how
many instances but it's in the ten
thousands of instances and we restart
them many many times so as I said most
memory usage during startup usually when
applications are fully up that's
absolutely true and the memory is used
anyway so it's not that suddenly overall
uses my Java eat my memory and c2 didn't
yes it did but you didn't see it right
good how much time do you have left
three minutes
is that accurate yeah question oh
absolutely yes if if this if this slot
would not be 45 minutes but an hour and
10 minutes I could show you but I can't
so it's this accurate the 3 min who
knows no one knows what I know I just
keep going so I could do a few things
let me do this oh yeah let's just do
that I want to show you this so you can
download
growls from github the source code whoo
okay where's all this stuff search here
so you search for 'crawl and then this
one shows up and then we clone that one
here we go and we go here and we say get
clone
I think it's called depth one does
anyone remember I hope this works fine
yeah because then the cloning doesn't
take that long okay and then we cross
our fingers because otherwise I have to
Chloe it again that it actually works I
have to go back we need one other thing
so we go github again and we search for
MX MX is uh there's a script written in
Python and I type MX yes I did where is
it it's usually at the top oh did that
move stuff around again I hope not
and that's the problem when you do left
and Mosin they're not prepared what is
it called oh my god oh here it is growl
the MV of M X that's the one we need
so that script basically handles all
everything everything growl related so
the clone l1 and then takes a little bit
here we go
we go in here and then we put it on the
path so we have it there you go and when
you get down here and we have MX yeah it
works great so we go in here growl we go
to compiler we type MX and we see if
that kind of works yeah it does
let me unset these real quick because it
will produce some output we don't want
right now and then we just MX which is
type MX build we said you remember we
said Java home earlier so it's MX is
picking up Java home from there and so
it's downloading a bunch of things as
you can see like dependencies it needs
and one of my last talks it didn't build
because they broke something upstream so
we'll see if that works but that's all
you have to do you type MX built it
we'll see oh I have depending if you
have Java 8 Java 9 or chava 10
it will either be build a char file or a
modular char file for the module system
right that should be the outcome this
build if it actually the Chava part
works this build will fail
and the reason it will fail is because
it builds a small part for truffle
support and truffle uses Lib FFI and
liveth eyes you know a C++ library so it
actually requests GCC which we don't
have installed because our cloud
instance is completely empty I could
have installed it would have taken
forever but we don't need it so this is
actually what we wanted that was just
here so there should be a directory
called MX build modules here we go and
there's a module a char file here that's
what we want so we go draw a compiler
here
and then you can type MX BM which runs
the VM and then you say - version and
then well of course you have to put a
little path there we go
going back to compiler and we try that
again here we go
so it picks it up and then it just
printed out so if we let me show you
this first
if we run X la classe low so if we if we
look at class loading and then we run
let's say the the scholar the couple
thing we were running earlier because we
need to run something a little bit
bigger because we need growl to below to
write the initially the lazy
initialization issues we had so we and
we grab for growl VM here we go we can
see are a bunch of classes loaded I
can't you'll see that so a bunch of
classes are loaded and you can see you
know let's pick this one it's loaded
from jrt jdk and internal vm compiler so
that's the macho charity is the internal
file system for loading stuff from
modules ok so if we run that same
command instead of Java we say MX VM
then you'll see
control-c thank you you'll see it picks
it up from the file from our modular
char file so that's all you have to do
you can actually do an MX - v vm and
then you can see the command line this
one here and it's just running Java bla
bla bla and then it says up to add
module path to the module HR file so you
can either run it through MX or you
could add that to your command line and
then you could also run with bleeding
edge scroll right and then technically
we can let's do this and then we remove
the logging here and then I always when
I do this I always hope that it's
actually faster than it was before but
it usually it's not so I'm just hoping
that Oregon Labs was cranking on making
the compat about it but it's iPhone 5
there's about the same as we have before
right so this is how you can run how you
can download crawl from github like the
latest version build it and run with it
and that's that's possible because of
JVM CI and now you could if you wanted
to load crawl into your IDE and you know
do stuff with it add better
optimizations whatever you want to do ok
so let me go back to my slides I'll skip
the production demo because I don't have
time for it but I would like to show you
the scala demo and that will take
another 5 minutes and then I'm done
so for this we set this guy again but
now we're using a slightly bigger heap
size we use 2 gigabytes because
otherwise we get to too many GCS and we
are running on oh god lag we are running
factory I'm typing actually so oh my god
that's not my fault really it's
happening I'm still plugged in get the
power go down like the router or
something
huh it did no I don't think it did oh
yeah it did you're right okay let me try
it again
so we we run three iterations no let me
do two two is enough we do two
iterations of a benchmark called factory
don't ask me what it's doing right we
could go to the webpage and well
actually we can because we have time so
if we go back here and then we look at
the benchmarks of where they are here
benchmarks so we go here and then
there's the factory benchmark so it's a
toolkit for deployed probabilistic
modeling to extract topics of latent
whatever right doesn't really matter the
the point is it's written in scala
remember twitter services are written in
scala and gurrah can do a really really
good job optimizing Scala code and so
what we're doing here one of the reasons
not God I forgot something because I was
confused about typing looks I'm working
anymore because what we weren't we want
to run this and we want to turn on
cheesy logging if the internet comes
back yeah it does look great so we turn
on XLR cheese see that's what we really
want okay so we run this stuff we wait
for it to finish a run should take about
I think 27 or 30 seconds or something
like this oops
over here and we make this a little
wider there you go so you see it's doing
a bunch of work and it's actually
allocating a lot of memory it's going up
to I think about 700 megabytes of heap
usage and it's always collecting down to
about 74 max so that's that's kind of
roughly what do you see here we go so it
took us 26 seconds to do this first run
we had a bunch of she sees and now we're
doing a second run and then we'll see
how many cheese's we did takes another
27 roughly any questions in the meantime
not yet good yeah
though is what partly yes not not
entirely but partly and that's what I'm
showing you now so we we run the same
thing over here with growl and it
doesn't work because we're wrong
directory here we go
no wrong because who knows what's wrong
we need to change the heap size there we
go
so we changed the heap size to do two
gigabits and then I'll answer your
question while we're waiting for this so
we say two gigs here boom
and we run it perfect so yes partly
so growl has a better escape analysis
I'm not going to explain what this is
but it has better escape about since
implementation called partial escape
analysis and it can it can escape Anala
analyze more objects it can eliminate
more object allocations than c2 can and
then at the same time growl you would
see that in my other talk growl has also
better in lining heuristic that are in
line me implementation so it can in line
more and that also means if you in line
more you know in lining is the mother of
all optimizations
then escape analysis can work better
that's what we're seeing in this in this
benchmark here right now and then at the
same time if you can get rid of
allocations your code also gets tighter
right because allocation you know that's
a bunch of code you have to call out to
the VM and you have to zero out all the
fields in blah blah blah if you don't
have to do this your code is tighter
okay so over here we started at GC 48
and we ended at 85 these are how many
are these 30 something's like it's
really it's usually roughly 42 seats
let's say 40 it's easier for me 10 and
over here we were doing 20 and we took
only 10 17 seconds to do the benchmark
run so that's that's obviously you know
I'm not stupid that's obviously the best
benchmark I can find to show you how
good growl can be so these this is what
does like 20% better I mean is a
ridiculous right
but atwitter
when we started using Gras and you will
see that in my other talk in in an
experimental isolated setup we saw about
an eleven percent improvement in
reduction of CPU time and that's a lot
of money right in then in in the
production setting it was a little less
it was like eight percent because you
have other stuff going on right you have
more instances of different things
running on the same machine but this is
what we're seeing so it's real but I
have to add again draw does that very
very well for Scala code because it
behaves differently than Java code Java
code I'd like to it's not really
accurate what I'm saying but I'd like
Java bytecode to be a little more static
than Scala code Scala code is very
complicated very convoluted and blah
blah blah so grog can do a lot of work
there but I've seen I could if I had the
time I could show you benchmarks where
growl is also better with with Java code
so what I'm saying is what Scala I'm
very sure if you run anyone running
Scala code in production you should try
it but I'm very sure you'll see an
improvement I don't know how much but
there will be one with Java code it's
I'd like to say it's a 50-50 chance most
of the time there is no improvement at
all but it's also not worse which for me
is already a win because I want to get
away from c2 I want to move to a new
technology like raw and then sometimes
it's faster might be 1% to 3 I've seen 5
you know but depending on how many
instances you have how big your your
business is whatever you run this can be
a lot of money you know for Twitter
we're a big you know it's a lot of money
it really is excuse me
any benchmarking okay it's funny that
you ask because I've never got this
question in the United States I get this
question in Russia and Eastern Europe
and I wonder why no I haven't tried it
yet because I'm constantly at
conferences giving this talk and I
haven't that time to do it but I will
because it will be interesting more and
more people are using Hofmann these days
so we should definitely check this out
if you have coupling code you should try
it and then let me know so this is it I
don't know how much time I have used
doesn't matter the summary is very
simple this is all you have to do just
turn it on I'm really encouraging you to
try it there's really nothing thinking
that can go wrong unless it crashes it
but that would also be nice because then
please file a bug up stream on github
because that means then at Twitter we we
are not running into this issue and so
try it out let me know if it works let
me know if it doesn't work whatever it's
it's different so swapping out the
compiler is not as swapping out that you
see cheap every GC implementation has
its own kind of properties and you have
to keep tune and stuff with the compile
it it's like a black box you're
replacing one black box with the other
one most of you people don't even know
what a chip compiler was before you were
at this talk you didn't care before why
would you care now right the only thing
you care is how much CPU time are we
using for running out of stuff that's
the important thing
and with that that was it that was all
and thank you thank you
and of course I take questions yes it is
yes
no because so the plan my plan my
ultimate goal is to get rid of c2 c2 is
a very old compiler implementation
technology that's that's passed its end
of life and we want to replace it with
something new where we can do more work
and more optimizations in the future so
c2 and grants to completely different
implementations and we want to replace
you - with Groth completely that's
that's a goal</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>