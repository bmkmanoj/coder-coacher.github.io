<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Deploying Cloud Native Applications: VMs, Containers, or Functions? | Coder Coacher - Coaching Coders</title><meta content="Deploying Cloud Native Applications: VMs, Containers, or Functions? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Deploying Cloud Native Applications: VMs, Containers, or Functions?</b></h2><h5 class="post__date">2017-08-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/G5MSuF4AEaA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right dust yeah we're good all right
okay so welcome had a good lunch I
called my down I came down from France
this morning and I didn't know is going
to get here because it was foggy and you
know my my wash SmartWatch is buzzing at
me like your flight is delayed your
flight is delayed so I thought not gonna
be here but then suddenly the flight was
available in the earliest I'm running
for the gate after all that so got here
8:00 I'll try and calm down relax too
much rushing so yes my name is Sean
Smith I'm with Oracle and I'm a product
manager with the cloud team and I work
on the the cloud application of
deployment set of services and I'm going
to talk to you today about choosing your
deployment platform deployment target
for cloud native applications and that's
a bunch of stuff so I'll start off with
like set the context for what are we
talking about what I want to deploy and
then take and give you a framework we're
going to use to figure out whether the
targets we have Velib are good choices
for us so missus flip over here so first
question is if I'm going to deploy a
platinum application to work what can i
deploy it to and so I've got a few
choices and actually I changed this
since the last time I gave this
presentation I added another choice
split them out so you got an application
you want to run the cloud right now the
cloud is actually got a lot of different
options it's not just like the cloud
alright so this is kind of the core this
session today is what do I deploy so you
can get a virtual machine everyone
everyone's heard of Amazon Web Services
you can get a virtual machine you can
deploy your code right it's like obvious
stuff compute network storage right
since you know time has gone on we've
got containers now right so we've got
docker different kinds of OS basically
OS virtualization we can divvy up a
given VM into a set of spaces with
virtualized networking virtualized
storage everything is virtualized down
to the level where your application
itself can run by itself on the same
same given host a version of that are
sort of a layered service that you've
seen on top of Canton containers is
unfortunately the names are over
overused I suppose the application
platform as a service this would be you
want deploy your application to
container but you don't wanna have to
take care of the container specifically
yourself you want your application
containerized run in the container
scaled for you load balance all those
things for you but you don't wanna
necessary be doing the container work
yourself and then the next step up from
that is this whole the whole advent of
serverless or functions right and it's
pretty much like application platform
as-a-service
it's we're going to take your code run
it for you in the cloud it has a single
point of entry we're going to scale it
for you can do all the work all you can
do is deploy a piece of code alright so
sounds a lot like the application
platform as-a-service
except it's narrowed down to
specifically responding to events that
happen in your environment so you know
customer purchases something or
something happens they call your
function you do some processing and the
Amazon Web Services famous example is
some puts an image into a database as
far as it fires an event that the
function is called it resizes it gives
you a thumbnail which you might want
later right so it's basically
event-driven from compute so these are
different targets I can deploy my code
to write virtual machines containers a
pass and end functions and just some
examples right so we've probably mostly
familiar with Amazon Web Services
Microsoft Azure Oracle's gotta obviously
compute or IAS IBM has it everyone's got
it right it's table stakes everyone's
got a compute platform on the container
side you have a lot of choices I guess I
say docker like unconsciously even
because like what can I do right they
off dominate the space right but
meantime you do have things like rocket
run sea which is the the low-level sort
of the bot the base piece of docker is
actually owned by the open container
initiative and docker itself is running
on me on this infrastructure so you're
seeing a open source standardization of
this stack it was kind of eating away at
the docker stack but really it's almost
like docker is concern ominous with
containers I'll probably say doctor a
lot and I'm certainly my thinking is
influenced by docker significantly other
services you may know in the a pod space
Toru KU's very very well-known I was one
of the early pioneers in the fppad space
run your application just your
application no containers necessarily
they have containers inside they're
using Linux
containers but not not docker but they
do it for you
IBM bluemix Oracle application container
cloud that's the service that I work on
there's quite a few there's quite a lot
of these because they're becoming
popular because they're easy to use they
offer a lot of value on the functional
and service side there's all kinds going
on right open whisk is an open source
project that IBM is backing Microsoft
functions Oracle functions and Amazon
lambda right so it's it's everyone's
either got one or is getting one so you
have a lot of choices the cloud is
pretty rich in terms of what you what
you might want to deploy to so given
that all these targets the question is
what am I trying to deploy this is the
key part right I'm going to I want to
build cloud native applications one of
the applications for the cloud I'm not
doing lift and shift right this is a new
world I'm going to build new
applications to leverage the cloud and
so you'll hear this phrase cloud native
so what is cloud native it's a good it's
a good it's a word I like that we use
commonly in Oracle certainly talk about
the kind of applications where we think
customers are trying to build so who's
heard of twelve factor apps ok a few so
it's pretty good so so twelve factor
it's a website twelve factor net you can
go take a look at this describes or has
a set of principles that the Heroku team
put together to describe what they felt
constituted essentially what we think of
as cloud native right applications that
you would deploy the cloud which they
look like how do you configure them
what's their what's the essential nature
of a cloud native application so I'm
going to use the twelve factor app
principles and sort of a way to try and
judge these deployment targets like you
know if I want to do this twelve like
build an app like a twelve factor app is
a VM a good choice for like what value
to offer to me how well does it align
with the principles now given the name
is twelve factor there are twelve and
I'm not going to read all these right
now we'll look at them in turn and it's
going to be the guideposts we'll go
through these these principles here and
take a look at the deployment targets
and I'll explain a little bit about how
these twelve factor principles work so
they all have one liner if you go to
twelve factor net you'll find they have
a larger long description of each of
those principles and some of them are a
bit they're not the most perfectly
organized I would say you'll find the
things
they tend to mix things up a little bit
but the descriptions if you read them
are quite interesting I encourage you to
go to the website and read through this
site so let's just go through these guys
so the first principles code base one
code base tracked in revision control
many deploys this is kind of motherhood
apple pie for a lot of people you've got
a you've got a repository git repo or a
subversion repository your codes in
there you make a build take that build
you put it in test right it looks good
you move it to two you eighty you move
it through the different environments
their point is that you should have one
code base no special code bases that
contain the changes for production or
for dev test it's not you don't have
configuration where it has like if dev
then this if prod then that don't do
that one code base one binary produced
by that system okay and this you'll see
that it's a go to the first three or
four of these principles they kind of
fit together to give you a nice
consistent set of principles for so why
this make sense but one code base deploy
it into various environments so let me
just give you a couple of these things
and we'll also dig into the target
number two dependencies explicitly
deplete declare all and isolate your
dependencies everything that your app
needs has to be fully defined all right
so you can't have any dependencies on
install packages from Linux that you may
you hope we're in vailable environment
you need to at least if you have those
things you need to explicitly declare
them so that they can be either flagged
as not available to you or may be
automatically provision for you but
either way we need to have the metadata
that says your app needs this stuff
that's the same for for packages as it
is for for your libraries now for
library dependencies that isn't the
challenge for most people today right so
we're all using package management
pretty much it's taken over right you've
been using maven for Java NPM for node
or Gradle for Java right
rubygems and so on forth right we tend
to write applications and then write the
metadata describing what modules my
application depends on so for me if I'm
using maven or NPM what maven especially
when I'm running with maven I compile
the code probably doesn't compile
they have the dependencies structured
correctly right if I don't list the
package I need it's not going to compile
so we're doing this now so we have tools
so it's easy to satisfies this number
two dependency right dependencies should
be declared although there's a lot of
different dependencies you may have so
let's sort of walk you through the so
the stack of your basic application all
right so this is give you an idea so
here's your application this is your
code right how percent your code below
that does all those application
libraries are using so you're going to
use a package management system for that
one of the many we talked about and of
course different libraries you might use
we're just samples of your libraries
underneath that to the container and
this is unfortunately that I read this
slide again today we're getting ready
and realized I said container and the
course that's confusing I mean typically
web container or rest service container
so something like a grizzly Jersey
Tomcat something you put your code in to
get something like rest services so node
Express for example offers up you know
attaches your application to the outside
world through the REST API so that
application container you may or may not
be using that typically people are using
these lightweight or even embedded
containers today for their apps to give
to do rest and HTTP applications anyway
and then below that is your runtime
language so which language do you use
it's a it's something that you have to
think about if you have an environment
we're gonna deploy an application you're
going to need obviously your code your
libraries the container if you have one
and you're gonna need the application
runtime deployed who's installing Java
for you right who's putting note on into
into the environment you're the run on
this is something you're gonna have to
consider who's putting it there is that
your job or is it the platforms job and
the same goes for the operating system
right who's who's who's managing that if
I get a Ravi em right I'm going to stall
the operating system possibly a grab get
an image with a given operating system
I'm gonna make that choice so just of
how these things stack up if you're
doing functions or serverless
development most of the decisions are
made for you most of the platform is
provisioned for you in advance right
operating systems there you probably
declared upfront I'm they know that I'm
doing Java is going to be provided for
you
the container is there like you're going
to write a piece of code that has a
single entry point and they're going to
call it this functions platforms that
are called for you therefore you're
running inside of their sort of their
the server list container right and this
probably probably
this is I sort of half drew the line
here on functions there's probably some
application frameworks that they provide
to you in the environment to make it
easy for you to interact with an
environment so it's quite a lot of the
decisions in terms of dependencies are
she covered for you you don't have a lot
of decisions left or things to declare
in your application on the application
platform is a server side there's a
little bit more flexibility so typically
if you're deploying these platforms like
the Roo crews of the world the OS is
there for you the language runtime is
going to be pre provisioned because
you're going to say I'm using node or
I'm using Ruby the container may be
there if you're deploying to Google App
Engine I just been mentioned in my slide
earlier it could apply to Google App
Engine then they're really taking at
least the original original version of
Google App Engine with a web container
they had a container you deployed war
files so they actually had the container
as part of that basic a pass platform
what you're deploying is application
libraries and your application code
right it's all your business to deploy
however you do that everything else is
provisioned for you
containers I'm using docker probably the
bottom two right and go get an image off
of docker hub and get me the go one
eight one one eight one whatever it is
runtime provision for me off of docker
hub like that I may get an application
container but it's less likely typically
that's not what people are packaging
tidy up on the VM side you get an
operating system right it's like a blank
slide like okay here's here's here's an
operating system for you in a VM
everything else is your problem go
install it go configure it it's all your
business right so so you start to see
right away that the amount of work I has
to do in terms of these platforms
differs and really on the VM I have to I
have to provision a lot of stuff I have
to declare dependencies of all these
layers on the other side on the function
side I don't have to do a lot of work
but I don't get a lot of decisions right
I don't get to choose my container you
know I don't get to choose all this
stuff the operating system it's all
chosen for me so but when you're
deploying in the 12 factor you're going
to need to capture all of those
requirements all the things you need and
so it can be satisfied for you
after this is my favorite paper that's
my favorite principle I mean you know
what a geek I have actual favorite
favorite 12 factor a principal config
store the config in the environment so
the 12 factor after model is very
low-tech
it says if your application has any
configuration it should just be as
environment variables in the environment
your applications running and they do
that to basically have the application
that that binary coming from the single
codebase
the single binary from the single
codebase is the same no matter where you
put it
but it's going to put it in a production
environment or a test environment it has
to be configured to talk to the right
database to have the right timeout
settings credentials you know
coordinates for your Twitter account
whatever it is and that's factored out
into the config so the config is just a
collection of stuff that's going to be
published in your environment your apps
going to read environment variables
super low tech what's strange about this
is that people used to config files this
is actually saying config files are bad
they're saying in a sense of packaging
your app together with config files
deploying it is something they're
discouraging they're saying the
configuration you're going to provide in
that config file is going to be in the
target environment your apps going to go
there and pick up the configuration it's
not going to be going with the
application that's to keep the key piece
here they're separate and you'll see
that asking a couple slides they have
another principle it ties it together a
bit so this is just a couple of
screenshots the top one is Heroku I
believe where I'm configuring the
environment to contain a database name
and the DV connection whatever I can
just go and define any environment
variables I want right to have my
application pointing to the right thing
when it's deployed to that environment
in down the bottom that's applications
as Oracle application container cloud
that I work on it's basically the same
thing right key value pairs deployed the
environment application reads
environment very very straightforward so
doing it's fairly straightforward you
can imagine if you're doing it on a if
you're doing this on a VM you're
basically going into the VM logging in
and setting environment but you're
saying the TC shell or C shell scripts
or profiles right it's a little bit more
manual here is it more declarative and
we'll see some more about this but it's
pretty straightforward
number four is backing services this
just says that anything that your
application needs to talk to is just as
again declarative you just you just
connect to it as if it's over the
network so if you talking to a database
it's a network resource telling to
Twitter its network is resource object
storage database mail service these are
just things you're going to speak to so
your application she'll just treat all
external services like network attached
resources this is also true for other
applications if you're building you
micro service style applications then
you want to treat the other applications
as attached resources just you just need
the coordinates of that thing the
Twitter account and you're going to
connect to it so when I move from at
from test to dev to prod
I change say okay well I feel good and I
change which which database I'm talking
to the dev test whatever I'm just going
to change the coordinates but the
application is not going to care right I
got the driver and I'm just going to
point to the right right right database
it's a very straightforward simple
principle and here's what it looks like
in instead of in practicalities so on
the right hand side this is Cloud
Foundry which is an open source cloud
native platform right and in there you
would list in the configuration that you
provide is textual configuration you
provides the test my sequel 0 1 so
they're saying the list of services my
app consumes - yamo config here talk to
a database on the left this is
application container cloud same thing
list of services the name of the service
in this case it actually also has a type
discriminator like what type of service
is that so this notion you can
declaratively say I'm going to talk my
application is going to talk to some
attached service and you just capture it
in text files like that text file varies
per per environment not part of the app
so to sort of summarize some of these
some of these things so virtual machines
is programmatic right you're going to go
write some shell scripts you're going to
go write batch profiles and do that
you're going to go to each VM in your
cluster so imagine you got to pull out
to some VMs and you scale it out you
know make sure that you're your
environment or your configuration is
propagated to all those VMs as you scale
that's a bit of work but it's on your
head to deal with right in the container
case your configuration is typically a
bit either bid program
programmatics are a bit declarative so
you can actually would give a docker you
can create a docker file that's sorry
you can create a configuration file with
environment values you can launch docker
and say and here's the doctor here's the
environment variables you should provide
the application especially fairly
straightforward to boot docker and hand
it to config like those two puzzle
pieces right in the a pads case it's
actually fairly similar except that are
you seeing things like UIs and using all
kinds of configuration around doing that
declare the declaration the other thing
is that with a pads platforms as you
scale out if you want to scale these
applications that configuration is
associated with your application type so
let's say I've got my web tier and my
apt here and I've got some applications
deployed the configurations associated
with the app tiers config the dev the
the web tiers config and as a scale that
that config is also propagated so it's
very important that it easily is easy to
scale these platforms in the cloud and
you want your configuration to come with
you
so as you scale that the each instance
of your application picks up that
configuration that's on the year from a
past and again the functions the server
list is almost exactly the same as the a
path there's really little difference in
terms of the behavior really the
difference between the two functions and
again the application platform is
functions have a very specific
definition of what your application
looks like like it has an entry point
and we'll call it on event whereas the a
path size a bit more flexible in terms
of what you can deploy otherwise awfully
similar in terms of the the
configuration so here I'll be put
together so principle five and again
they kind of build together twelve
factor principle five is build release
run your environment has a build which
produces the binary that binary gets
combined with a config they call that a
release and that releases then put into
into an environment to run it right so
this they're saying that this is how the
world works but you assemble these
things together single codebase build a
single binary your queue and configure
separate and figures combined with the
application a certain version of config
and deploy it into the runtime
environment so this is a fairly simple
model now what's interesting is that
that notion of releases can be a reified
thing can be a real thing in the
environment
this is a screenshot from the Oracle
application container cloud where the X
the release the combination of the
binary and the configuration is actually
visible in the UI so you can go off and
say okay I deployed on Tuesday and I can
go see the version of the binary running
on Tuesday and the configuration has had
if you make a change to configure and
things are trying to act funny you can
go and so compared the working Tuesday
config with the current config and say
what could we change alright so we've
made this concept of the release of sort
of physical thing that's actually in the
UI itself so it's actually it's actually
a good model and you can actually use it
to your advantage
so the number six is processes
so tell factor says you should build
stateless applications and then scale by
just adding any more of them basically
but simple simple idea simple processes
so your application contains no
configuration right from the from the
previous principle plus they wants to
contain no space any state you have
usually pushed out to somewhere else
right so if you think of mostly look
here I'll give you a picture right so
you've got a bunch of applications
running and you got all your state in
your my sequel database or in some
object storage right like s3 type of
thing
and the advantage of this of course is
when it comes to scaling in and out
right we have no state any applications
I can create a new one and the data is
all safely stored in the back I can
destroy an instance and all the data
safely stored on the back so these
applications have absolutely no snow
state and they share nothing there's a
very simple model again it's sensitive
there is almost like their atomic model
for for cloud native applications right
build your applications of their simple
stateless processes and the connect it
booted now what that lets you do is
scale all right so once you've done once
you've got to this shared nothing
stateless model you can scale it very
easily I can just keep adding instances
of my application more and more more
containers are being spun up for me
right I'm staying more containers and
because all the data is in the back-end
another tier or another tier or another
another in data tier or database it
makes no difference how many of these
front-end guys I have so if my
applications get front-end is getting
really hammered I can spin up more web
tier right like in this case here or I
can
back in the middle tier the processing
tier is getting hammered I can scale
that out too right I can add more and
more it's very simple this is a highly
elastic principle right so by building
this applications very small simple
stateless I get this huge benefit of
elasticity and if you think about it I
don't know I'm sorry used to it now so I
don't I think elasticity is like its
basic right scale
boom right a couple seconds later I have
another have more processing power
because I'm following these principles
so it's a it's a great principle now how
do you how do you achieve this with our
possible cloud deployment targets so
when you're building VMs you typically
run a bunch of stuff on it
right so no one's going to spin up a VM
to run one process like one little web
application I don't think so it's kind
of overkill the other issue is that so
really doesn't lie along well with 12
factor principle right you're not going
to do that you're good to course it's
kind of you also if you're dealing with
VM it's your problem to place these
processes somewhere in that cluster of
VMs right that's kind of on your on your
head
and keeping the processes isolated from
each other if you run multiple poses on
the given VM you want to keep them from
interfering with each other you want to
keep them isolated then it could be done
but there's again a bit of work to do
there and also if I have a cluster or
have a scale that cluster I'm going to
have to deal with load balancing I'm
gonna get traffic to those application
instances and that's also something I
don't have to deal with myself now if I
move to containers then this is a more
natural model certainly right so you
typically see one one process per
container it's not required stop you
know nothing there's nothing to forcing
that but typically that's the best
practice one process per container which
nicely aligns with the 12 factor
principles and those containers are like
little sealed units right what's inside
that container is not getting in or out
and in fact people mostly struggle with
getting stuff in and out of those
containers like getting trafficking or
getting getting out of them so they're
nicely sealed off from each other so I
can run a bunch of containers even on
the same host VM and have them have nice
isolation alright so this line of lines
quite well the application platform of
the service follows exact same
principles of the containers it's
basically its orchestration all right so
it's saying give us your application
we'll put in a container for you great
run a single process and we'll do things
like have automatic load balancing for
you so as you scale
basically traffic just gets your
applications right so it's a little bit
more of a user friendly environment in
the API level the function side service
it's actually again very summer right
they're running one process per function
call you call you have a function you
run a process
nothing is going to stop you from
forking processes but it's probably not
a good idea I would stick with it stick
with the model it works quite well again
they're running inside of containers
right so there they're going to be
isolated and they must be stateless
these functions are going to come in
theory right so the model is your
function gets called it gets run and we
get interior container gets spun up it
handles your request and then it gets
spun down it gets destroyed right in
practical practically practically they
don't really do that there's all kinds
of pooling and clever enough going on
but the model is it comes and it goes so
you can't have stayed in that a function
because it's not going to exist next
time you call it well of course the load
balancing is a part of the platform
right as you scale it just handles
handles the load balancing for you so
the flipside of scalability is
disposability right the concurrency
principle if you wanna be able to if you
have a stateless application it's very
easy to scale out the nice thing is you
can also scale in so if I had stateful
applications scaled out and I wanted to
scale in I have you know I have too much
compute power and they're all idle I
really should save some money where I'm
getting needed for this stuff I'm paying
for these things I should kill something
off if they're stateless then then fine
and shut them down gracefully tell them
to close their resorts close their
connections to database whatever
resources they have and then just
terminate them all right so twelve
factor principle nine says that
applications just shut down easily
because they're stateless and be
disposed of so scaling in should have no
impact on the performance of your
application it should have no impact on
the service you should lose no data if
you're sticking with the principal fry
straightforward
as I go through these sometimes these
feel out of order they didn't do a good
job of sort of structuring them together
first fewer together make a lot of sense
these start to get a bit weird but
number seven is pork binding if you're
building these applications for the
cloud really everyone's vending their
services via rest or over over some sort
of socket connection so ultimately you
need some kind of port to reach your
service all right so these are built as
services you're building service based
applications in the cloud typically even
our web service accounts right you're
making a call an HTTP the socket to port
80 and getting your response back so one
of the things you need to do is make
sure if you're taking these applications
in the cloud native application
deploying it is make sure the
application can be told where to listen
right so again it doesn't know what its
environment is this is a piece of code
right so these applications need to be
able to understand that for a given port
they can start they should start up and
listen on the port that they're told to
listen on and this is what how these
work this is this this is the same
regardless of which environment you're
in I think that writing your
applications so that they can pick up
and run the right ports to cut their
configuration is independent of the
deployment targets so 10 10 is a seems
like a totally obvious principle and I
used to kind of go oh yeah this is
really good and I realized how important
this really is so dev test priorities
have keep all your environments as
similar as possible and if you think
about this is the the key driver for
docker right dr. exists because of that
story or at least that's the story they
tell you know I wanted to build I build
my application on my desktop I give it
to the test guys and it doesn't work
over there because they have different
packages of whatever installed and
dependencies aren't satisfied and
whatever so the idea with dr. was to
encapsulate and group all the required
environment to make it so that when I
took that code that runs on my desktop I
hand it to the test team who had to
whatever team to prod team it keeps
running because the environment is the
desktop and prod environments are high
in parity so this is a very straight
very important principle again it's more
of a code it's more of a principle of
how to behave it's not even about your
app it's how you should structure your
team how you should work right so these
12 factor apps do principals do kind of
wander a little bit so maybe time gets
small
cap small make it easy to go from your
desktop enterprise into test into
products fast as possible right if it
takes months and then they call you six
months is a that code you gave it
doesn't deploy you don't remember what
that it did anyway use the same people
they're very much advocating a DevOps
style of approach right you have a small
team who handle everything from the code
to depression and keep and basically
keep the tools very somewhere keep
everything the same so just keep the
world same as it just makes good sense
so this is again kind of motherhood
apple pie now in terms of these these
deployments so I'm building for the
cloud and I want to have desk dev test
parity all right so on the VM side it's
a little bit again a lot of manual
configuration it's it's a computer right
so there's nothing special about this
it's it's actually pretty hard to do and
it's su again this is the problem the
doctor was trying to solve by not doing
it this way the containers again we're
designed to try and capture that
environment to make dev test very very
similar da Paz approaches take those
containers that encapsulate all have
everything you need and then make it
pluggable with it with a configuration
and have it scalable and manageable so
again it's pretty good alignment pretty
easy to do dev to have test parity and
the functions in the function world is
an interesting problem so and you see a
little bit in the a path space too if
you're building for say Amazon lambda
how do you write like what do you do
your code development you do it in
Amazon lambda right so right now there
is no desktop solution
there's no desktop standalone version of
the Amazon lambda you can stall right
the Heroku team who have an a test
platform their solution for for their
cloud service is to give you a docker
container that looks like Heroku so it's
very interesting strategy right use
another container technology that looks
like their container technology so it's
kind of the same so you think you give a
similar experience below cailli I feel
like that solution I think is pretty
good in the Amazon case right now on the
functions case I don't know of anyone
maybe open wisk where it's open source
gives you a solution where the
production deployment environment can be
replicated for your development so you
can build a function locally test it out
and then deploy it
I did try I should tell you this I did
go to open with org
I downloaded all the instructions to
install and use vagrant
to spin up the environment to try it out
locally and I failed so yeah I think the
instructions aren't being kept up to
date in terms of where open whisk is
moving on and the instructions haven't
quite kept up at open whisk has an SDK
for Eclipse AWS so is that so you're
saying that just repeat till you hear me
hear you so you're saying that Eclipse
has a plugin for Amazon lambda that lets
you test the function does it run local
it does one local I'm listening it don't
worry yes okay so we have a simulation
of the event triggering okay it's good
and for Java okay Java only okay that's
good to know because I don't know that
existed and I was going to say that in
the a path side Google App Engine also
has a local Eclipse based environment
same thing I'm gonna clip sky so that's
good I'm all for that I'm tryna get rid
of this pop-up window and my mouse is
like okay hang a drop out of this thing
for a second without trying oh that
worked sorry one escape was enough okay
let's go back so if there's a challenge
though for you right so you do want to
look at these questions but can I build
code and test it and then can i deploy
it so it's a really really good question
something to think about
so last a couple here are kind of not
necessary where I think you you would
let help you distribute this criminate
between should I do run on VMs versus
versus containers they're kind of I
think common things so now a this is
cool when they wrote this principle but
treating your logs from your
applications as streams streaming your
your logs somewhere
I think everyone's doing this whether
you're a on VMs or running in containers
or whatever you're doing everyone's
doing this now in your data centers
you're taking all the application logs
streaming them off for analysis and this
whole convert this products around this
Rises logs
there's a Oracle has a log analytics
component where you if you stream the
logs off to this thing and it'll do like
anomaly detection and look for weird
things in your logs I mean this is this
is how everyone is doing it so I don't
think they especially anything special
here in terms of the looks the log
distinction between different cloud
native targets everyone was doing log
log streaming oh hang on that was number
11 number 12 I might eat well okay what
well so 12 is a weird one this is kind
of I don't know if this is like inside
baseball this is something that the Haru
cool guy thought was important I don't
think it helps us what it says is that
each be able to take your application
and the config for a given environment
and have it available and then run
something else essentially run a
different program or different main
within that environment and why they
want to do that is to do things like
they mention admin tasks so imagine
you've got a database you've got an
application that knows how to talk to a
certain database in the environment the
config says point to database X you want
to do some data migration on database X
well that code knows that database
that's all kind of there for you
honestly I think the argument is a bit
weak because I think that you need I
prefer to run database migration tools
migrate data carefully then just run
some other like entry point in my
application but this so I read 12 is
interesting but I don't really think it
helps us in the question here of what
should i do ploy to so that's 12 like I
say if you go to the website you can
read read in detail what these things
mean and maybe this will help you is the
good bootstrap to sort of get you
interested but I think the question
around the whole dough the questions
boiled down to a very simple simple
problem I think the problem or the
question boils down to control versus
productivity so this is completely
non-scientific I made up this chart okay
so there's no numbers no I did no
studies for this I'm just this is my
best guess at where these dots go but in
terms of control versus productivity
right so you can do anything right we
all know it's just software right you
have an infinite amount of time you can
do whatever you like so the question is
you know what am I trying to achieve if
I want high levels of control I want
control everything down to like the Nick
configuration I'm going to get a virtual
machine now would that virtual machine I
have more work on this my responsibility
right I have to go configure it I don't
have to deal with the scaling the load
balancing the container placement or
process placement process isolation all
that stuff we talked about that's on my
head so if I'm going to go to the cloud
and deploy application on a virtual
machine it's going to take more work but
I will get huge amounts of control so
that's a maybe that's that's the value
on the other side if I really want to
take my code and run it the far end is
the function side if you've seen the
functions are you write a function like
you know entry point parameters here's
my piece of code I deploy web browser I
say make it so and now it's running in a
load balanced scalable fabric and I'd
you know I just did it right now so it's
super low or super high productivity
it's really easy to deploy function but
it's super low control like you do not
get to decide much of anything besides
what your entry point is maybe what some
libraries are going to use are the
decisions are taken away from you but as
T as a trade-off for productivity so if
you don't really care if you know and
this is this is the case if I want to
sort want to write that Lam's on lambda
resize thing that works great I don't
really care about the OS or containers
that's just infrastructure junk right so
there's a good to the trade-off there
now behind those guys is sort of middle
ground and I still got some more on the
productivity side I think that the
containers are a huge step forward from
the from just plain old VM because of
what they allow you to package your code
and deploy it's much much easier again
less control more productivity and the
application platform as-a-service sort
of products pretty similar again they're
focused on productivity they do remove
again some of the control cause it going
to do things like they're going to
deploy the containers they're going to
orchestrate them they're going to wire
them up the load balancer that kind of
gets taken away so they they've
orchestrated some of the the wiring you
have to do with containers so you lose a
bit of control but again you gain a bit
of productivity right so I think these
are these are the these are the key
things I think I just said this seven I
know this is my okay so now time to
choose so like you know it's it's
American Idol right so which one would
you vote for
well if I were building for the cloud
building these cloud native applications
I would definitely not
she was a virtual machine because that
would be just like so tedious actually
recently I did actually spin up a
virtual machine for something that I was
first I had to just feel the SSH into
the container into the virtual machine
it was my step one how do I actually get
in this thing right configure the
networking so that was just ticking me
off right off the bat so I would
definitely not want to deploy to a
virtual machine of building lightweight
cloud native applications it's too
coarse too much work right and it's wait
and I'm too lazy I want to i want
productivity versus control the problem
is on the function side functions look
really good if you're building functions
like if you need a function they're
awesome
right I mean it's it's taken away all
the infrastructural crap you have to do
to let you run that piece of code but
that's the only some percentage of the
of the universe right not everything is
going to fit into the function space so
I'm kind of like functions okay which
kind of leaves me in the middle with
these two so it really depends and these
two really I think it really does come
down to that and they're close in that
diagram of control and productivity I
think is the decisions between these two
if I were building cloud native
applications and it really depends on
how much control you want so myself I'm
an ApS guy I work on a path I like a
pass because I'm lazy I like it to do
stuff for me the stuff I don't want to
do so I would definitely choose
application platform as a service over
plain containers but I could be argued
again I could be convinced otherwise you
know it depends it depends it you know
your mileage may vary so now that's my
conclude in terms of doing cloud native
now at I was talking to Bruno Borges
who's one of the organizers of the
conference and he said Oh funny you
should ask this question because he did
a Twitter poll which is totally again
unscientific okay I don't know if it
means anything but basically he got down
to people give this choice functions
I'm leaving sure a pass for lang
runtimes means I think it maybe it means
a pass I'm not really sure what his
terminology means but the majority
people were leaning towards the
container side right even certainly in
terms of the functions which is already
cool they have their niche they have a
definite value but it's not the majority
use case so so the majority people are
in the container space it's a really
good choice for cloud native
because you want to be able to control
those configure the configuration you
want to let us scale it out you want to
just all the things we talked about
those 12 factor principles are pretty
easy to do with the containers much more
difficult with VMs and mostly doable
with the functions all right well that's
all the slides I have and that's the
content I have happy to take questions I
don't know if we have a mic different
like we do the mic okay great if we have
any questions
y'all gonna run out and like try this
out like should you see most of these
services give you free trials right so
if you go to I'm going to plug myself
now you go to Oracle application
container cloud you go the website
cloud.oracle.com you get three days
field free trial there's lots of
tutorials on like deploying Python
deploying or anything here PHP Java node
applications to an API platform you can
certainly go to Amazon and get a trial
of their their lambda service as a
limited trial so all these things are
free to try so if you are curious and I
would go take a look and check it out
and again hopefully the twelve factor
principles give you some kind of
framework but help you you know to
decide what you want to do right get the
mics handy oh okay you can okay there's
a recording those they want to hear you
yes it's like it's like Oprah now
yeah the free trial under are you all
your chairs just look under you can so I
wanted to explore a little bit more the
the application manifest that you talked
about the top actor yeah okay and I have
another question
so give another person yeah yeah like 13
factor app or no no the other one is
since all the instances are stateless
basically they all do we control
long-running transactions on them
because usually I saw some texts that
said that you should implement
transactions that would undo the changes
but that's not always feasible so if you
have any opinions on that you know how
to control long-running transactions
it's a good question long-running
transactions are problem for everyone
regardless of whether you're doing this
or not right I don't think the 12
factors does anything specific about
this it is the same for micro services
right and you can also view 12 factor as
clickable to micro services right same
problem small services that do one
little thing and how do you do a big
bank transfer yeah alright same thing I
don't think there's anything in here
that's going to help you like it's not
there's no answer in inherent in the
principles at all yeah yeah that's
that's what I thought and can you go
back to the the application manifest
part yeah we're all laying that in a
little bit more detail yeah let me
scroll over there tobey's please yeah
but you know in actual example of what
an application manifest would look like
because oh application data
yeah because usually what we do is we do
monolith applications
you know usually we have our web logic
XML but that's something that resides in
a WebLogic server yes so yeah so the the
you cannot you can almost say you could
do 12 factor with Java EE right if
you're very careful you can view it as
the application has some required
resources some gingy look at their
services it's you know their donation in
declarative like I need JDBC slash
whatever the environments configured to
provide that service so you could do it
it lacks the
at the court because of the coarseness
of the service like this the heavyweight
miss that's not even fair to say that I
get I'll get bad hate mail from my
colleagues it's not fair to say that but
it's up saying granularity right so
you're going to have to if you want to
scale out you're not going to so scaling
up multiple instances of it Java EE app
server exactly you're going to you're
probably to increase the amount of brand
your scale up add more thread pool all
that kind of sound right it's a
completely different model but you can
definitely do that
there's just limits on it in terms of in
terms of 12 factor principles yeah
exactly what we usually do is we make
the Machine larger without having writer
machines this is it this is yeah so this
model works great in the cloud because
is in theory infinite resource in fit
compute so you want more I just start
stamping out more of them alright so
when the service I work on there's a
little toggle up and down arrow like I
want more of them right you hit apply
and it just starts spinning up stuff it
bars the load balancer the traffic just
gets spread across big deal right so any
other thing is in the cloud
typically your on depends on the model
but let's say you're on the the metered
model a model where you're paying per
use so as you scale out you consume you
pay for that service and then if you're
watching what you're doing you can scale
it in when the traffic goes down like
it's it's great right so the point is if
you want to get that you have to build
like that you have to build following
your kind of principle stateless little
applications where you can get that
concurrency principle kicks in or the
disposability principle kicks in so you
can take advantage of the platform yeah
thank you sure
I have 22 seconds the clock is tickin
I'm going to tight ship around here no
more okay well thank you very much I
hope you enjoyed that I hope that's
useful</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>