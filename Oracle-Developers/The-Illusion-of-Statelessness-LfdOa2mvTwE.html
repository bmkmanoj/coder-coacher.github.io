<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Illusion of Statelessness | Coder Coacher - Coaching Coders</title><meta content="The Illusion of Statelessness - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Illusion of Statelessness</b></h2><h5 class="post__date">2016-09-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LfdOa2mvTwE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright so let's get started I have to
apologize to people on that side of the
room I'm kind of tied to the podium here
so I'm not going to be normally I would
walk around but with this thing we need
to invest in some wireless technology
here but I'll have to also have to be
tied to the laptop for the bigger
project presentation I one of the ski be
some background I'm Alexander say which
one of the architects and the coherence
Oracle coherence engineering team here
at Oracle so what I do on a daily basis
it basically building in-memory data
grade building data storage solution
that allows applications to scale a lot
if any of you went to our own Geary's
talk at open world yesterday he basic
talks about same thing why they chose to
use coherence and why it was good
solution for their microservices but
that so this talk in particular is not
about coherence i will use coherence for
some examples i will show some of the
things we did but it's mostly about
architectural concepts architectural
things that you need to remember it you
need to implement if you're building
applications to scale we implement a lot
of these things in coherence i'll show
them at the end it that gives you a
taste of what you can do with our
product but it's you know all this stuff
is fairly fairly general and does not
require it is coherence you build
systems this way using other
technologies as well so safe harbor
statement even I'm sure you've seen
plenty of those I mean anything I show
in the demos and whatnot is not any
commitment and Oracle's part so just to
be clear and then this one nobody forced
me to put in but I have to put in they
see this is topic the whole discussion
of stateless services and what is
stateless and what is not and can we
build scalable systems using stateless
services is very near and dear to my
heart and I do get upset when people
argue with me about it
and then you know it is it is a long day
for all of us I tried to put some light
material in there which required some
explicit constant hopefully you'll find
it entertaining and not offensive so
let's start with the first slide these
are you know when I started preparing
for this presentation I was looking for
things how people describe stateless
system what do they say why is it
important that you build your systems
using stateless services and this was on
one of the blogs on rackspace actually
and their conclusion they talked about
how you should never store state in a
database that doesn't scale okay where
do you store it well they say the bottom
light line is stateless apps are ideal
server-side database right there ariana
enemy if you must save state save it in
the client use cookies in ejects where
appropriate if you follow this rule you
will multiply your scalability well my
reaction to that is pretty much along
these lines as I said I have I i do have
hard feelings about the topic I mean
look at this I mean does it even does it
make sense yes sure you can build
applications that do nothing that you
know why would you even put them on a
server I mean if you if you can have
everything on the client why do you need
server just keep it in the client right
any yes it is ideal but it's not
achievable so what's the point of even
discussing it right you will not
multiply your skill ability or skill
ability will be infinite if you don't
have to hit a server but your
application is just not going to be very
useful it's your call i mean you can
build it either way now the second one
is actually worse even though it seems
to start getting about right the segment
says that services should be stateless
one benefit that you get from this is
scalability you can move expensive
operations to a cluster of dedicated
machines and it does not matter which
one responds to a particular request
since
all of them are independent and on the
surface this actually sounds correct so
my reaction is more along these lines
it's like you're actually making me
think about this one but but but it's
but it's even worse because it does
matter which one responds because what
is what is each one of those things
going to do it's not just randomly going
to answer your questions well usually
have to go somewhere to get some state
to calculate what you need to calculate
so the fact that the service is
stateless is kind of pointless is it
really stateless right if it has to go
somewhere to get a state that's kind of
the whole point of the of the talk if
your service has to go somewhere to get
a state is the service truly stateless
right so yes if you build I mean I'll
show some examples if you build
stateless service yes it doesn't matter
who responds to the request if you build
services that have to go somewhere and
fetch the state it matters and then this
one is actually not too bad this is this
is quote from Twitter which quoted one
of the articles on what is def target
com and basically says that Internet can
be thought of as a stateless system or
machine most computers i would say
applications human beings and elephants
are stateful the reality is everything
around us is stateful we don't have
stateless things I mean everything has a
state I mean we have a name we have age
we have everybody has attributes right
there there not many things around us at
are stateless now and you know and some
will argue even with this one but i'll
i'll give httpd of the fact that the
HTTP stateless everything is in the
payload everything is in response now
where you get the response this
different story right but the protocol
itself carries everything that it needs
but the rest service that you build on
top of it is not right and this is why
this is an example of a truly stateless
service right we have
right is anybody building services like
this I hope not because if you are we
should talk after this session if you're
on but you know if that's what you need
to do you can do it in the client you
don't need to go to the server to
calculate explore I mean you're taking
something literally couple cycles on the
cpu and turning it on tonight internet
were call it doesn't make any sense
right in reality what we usually have is
something like this and this is what we
call stateless right you have your
service that typically our transaction
boundary if you're using spring or
whatnot you fetch some state using your
dao repository or whatever you want to
call it you do some processing on it and
you save it back right that's your
mutating service use case even even read
only services use case you're going to
go to some data store fetch the data and
return it to the client right both of
these things are not neither of those
things are stateless because they have
to go to some data store to get a date
so that's why I'm you know I'm called
going to call it here that you know
stateless services scale better is
basically a myth you don't have to build
stateless services to scale better sure
you can use data services but that's not
going to make your application or scale
better scale worse and to demonstrate
why this is the case we are going to do
a demo and now because I'm kind of tied
to this thing I need couple of
volunteers to come close to me here and
in three four or five people come on
please let's not waste time one more one
more
all right so who wants to be a database
your database okay so you can stand to
the side a little bit so these guys can
talk to you what's your name Eric Eric
well your database we don't care about
Eric yeah Mike Justin you remember that
Eric Mike Justin okay so you're
stateless you don't know what your name
is you have to ask him okay okay now you
go faster at the same time the same time
come on guys can put some load more load
more he's actually a good database is
most people at this point basically say
uh come on this cut me some slack it's
only three names we need more people
come on you want to get everybody to ask
you but yeah you can ruin my demo yet
you ruin my demo you're supposed to give
up at some point but yeah you can
imagine what happens I mean at some
point the state layer thank you guys I
mean you can go back to me let's give
them given o clock at some point the
system that actually stores the state
becomes overloaded and when that happens
your performance suffers your
scalability surprised I mean latency
increase exponentially and basically Ron
scale you can you can add the more
services you add at that point the worse
off you're going to be because you're
just putting more loading system that's
already overloaded so when people talk
about stateless service allowing it to
scale what they really mean is that
stateless services scale only as good as
the state management layer they depend
so if you have state management
management layer that is scalable sure
you can scale but you don't need to be
stateless for that I'll show them of
that later you can build applications
with no stateless services in the middle
that scale just fine because you have
scalable data store in the background so
before we get there the big question is
how do we really build scalable
applications right scalable services and
applications and I have couple rules I
mean those are by not by any means
all-encompassing and the only rules you
should follow but they seem to be good
guidelines if you follow at least most
of them you should be in good shape so
the first rule is that you really need
to separate how you manage state and how
you persist eight most people tend to
think about state management positions
the same the same thing they're not
because there are many technologies
delighted to manage state in a scalable
distributed you know because to take a
step back one thing that you really need
for scalability is partitioning you need
to partition everything right you need
to partition your operations and that's
where stateless services we call them
hell because you partition you put a
little balance in front a bunch of
servers in it partitions request but
unless you partition data that those
servers talk to you're only halfway
there rights you need to partition it
and if you look at microservices
partitioning is about more than just
your architecture partitioning is about
your team as well one of the benefits of
doing microservices is the do partition
the problem domain into into smaller
problems and you have focused themes
addressing each of those problems right
now for performance reasons and you know
even though performance and scalability
are typically are not necessarily
correlated the reality is the better
performance you get the later you need
to scale so the better performance you
have in a system the more it's going to
be able to handle without actually
needing to scale out right so you want
you want to have good performance when
you're building a system so you can
scale as late as possible right and one
of the ways to do that is to manage
state in memory and that's what we do
but
not we are not the only ones who do it
right if you look at light band log on
how many of you are familiar with taka
and logon and your people lagu me is you
know this is actually quite good bull
Jonas Jonas Boehner city of typesafe
wrote this book it's available for free
on o'reilly and he talks about some of
the guidelines when building
microservices and basically one of the
things behind it book is the framer they
published opens the frame are called
logon that builds on top of a clustering
and you know allows you to write
microservices now I don't necessarily
agree and I don't endorse the framework
itself I don't agree with all the
decisions they made but it's definitely
interesting I mean it's it it has some
concepts that I do agree with it has
some that I don't we can talk about
later which ones I don't agree with but
one thing that they do agree with is how
they manage data they use a cur
clustering to basically partition data
set across all the nodes in the cluster
right again partitioning allows you to
scale so you can scale both capacity and
throughput by simply adding more nodes
and your data will get redistributed and
you know you get you have more
processing power for the same size of
the data set right and as I said before
they do that way we do it that way as
well and we doing it that way for 15
years and then you have our open source
competitors such as a patch ignite in
hazel casting whatnot they do it is the
same way as welding we all manage data
memory we all partition data across many
machines and let you look at it as one
big data set so you don't have to worry
about clustering and failover and and
you know where the data actually is you
just talk to the cluster and gives you
the data you need now when we talk about
second aspect so that that's really the
first part of the puzzle managing data
in memory the second part of the puzzle
is ok you have all this data in memory
but if everything goes down how do I
make sure my date is still there and
there are different solutions for that
that's that's when I say you need to
separate data management state
management from state your ability right
and for durability you can't
options as you can see in this slide
yeah and pretty much all of us support @
like logon will store data in memory but
it will write to Cassandra cluster in a
background I think they have that in the
in the picture right so this partition
dating memory but then they write
everything into Cassandra cluster which
is also scalable and distributed
partition so it's a decent solution we
actually have capital solutions you can
write to a database and even though your
database might not the thing think about
this architect is something we've done
for years and that when you put your
distribute estate management here in
front with the database even their
database might not be as scalable as you
need for your front end it might be good
enough because now you're bothering
things right you're replying to all the
reads from your state management here in
memory you are possibly coalescing and
batching writes the database you can
offload database I mean typical typical
use case we've seen you can see offload
on the data you can you can see reduced
load on database by about eighty
eighty-five percent so by taking that
load off the database it might be good
enough you don't need to scale it right
so that's one one solution and pretty
much every product in a space supports
some kind of a cache loader care store
concept which allows you to put
something in a cash or yeah I don't like
calling it cash but that will be all
qualities yeah it's really more like
entity store object store so you put it
into the grid and then great variety
that writes it out to the database so
that's one solution and then in the
recent cookie nurse release we actually
added support for we have built in
persistence so we can write the disc
directly you don't need any additional
product and then another important thing
is that durability is not necessarily
only on this durability right sometimes
you need something you don't need
doesn't iscriviti sometimes you need
something more in addition to it because
in many cases you need multi dental
centers durability right so you actually
want to replicate data from one data
center to another across multiple
clusters sometimes it's active passive
sometimes it's active active i am going
to trip over this thing so
that's that's another way to look at
your ability because you can have the
whole data center go down if you have
replication configured between the data
centers you still have data available
right so that was that was the first
rule the second one is that you really
need to think about your domain model
and you need to design it I'm even
though ddd when it will probably not
agree with me you know they will say
that you need to design your domain
model independent than anything else the
reality is that if you want it to
perform well and if you want it to scale
well you will have to tweak your domain
model based on which state management
analogy are using if i'm building the
application i know that i have database
relational database in the background
i'm going to build the main model one
way differently from when i have
coherence in the background so the fact
that you're using key value store or a
relational database does have impact on
how you design your domain model now
when it comes to designing the main
models i definitely recommend both of
these books first one a little bit more
than the second one because the one on
the left then the one right because for
the domain driven design is the original
it's it's classic made covers pretty
much everything that you need to know
about the main driven design the the one
Vernon's book makes it a bit more
approachable explains a lot of things
that might not be clear from reading the
first book but for my taste it focuses a
bit too much and how you solve some ddd
problems when you're working with
relational database i would prefer to
see more of the other side of the story
how do you how do you do it when you
work with key value stores there you
know the reality is that's what most
people still use today so i completely
understand why he did it but you know at
least for me when i was reading it there
was a lot of stuff that just wanted to
gloss over and get get to something that
actually had more more meaning for me so
that's on the memo the third rule is and
this one is really important don't move
data unless you have to I see people you
know they bill distributed systems and
they decide that network is absolutely
cheap absolutely free network calls me
nothing
bandwidth means nothing they need to
process large data sets and they move a
lot of data from the server or from
bunch of servers even worse to the
client gracias adÃ¡n decline then push
it back that's not the way to build
either a performant or scalable system
that's going to kill you in a hurry so
what you need to do instead just to give
you one example I had I was working with
a customer they wanted to copy the hit
coherence and they wanted to copy one
cache to another I mean we have very
efficient way of doing that by basically
copying data on each data expectation
across many servers we have very small
portion of the data on each one and we
can copy it basically locally within the
JVM on each of those machines whatever
they were doing is instead they were
basically saying cash be put all cash a
ghetto from the client very simple
operation but basically ends up moving
all the data from the from cachet to the
client and then pushing it back to cache
be yeah it took Nikki like seven hundred
megabyte or so cash and they were and
they were doing this and a hundred
megabit network so it took to the three
minutes to do cache copy yeah we changed
the implementation to do it in place to
do it within the grid and it was
literally like two seconds to to do that
whole thing with backup creation on
another note am I losing their okay so
you don't want to you don't want to move
data unless you have to what you want to
do is send operations to data instead
and how you do that will depend on the
product most of the products will
support that acha as actor models you
send messages to actor that then mutate
data locally new to their own state
locally with coherence we call it n
three processors and I have an example
of that bit later each other so pretty
much every product worth its salt in a
distributed data management space will
have the feature that allows you to move
processing into the grid and do their
use it the other thing is it's not only
when you're changing data it's also when
you're reading data so
if you're reading something repeatedly
their benefits and you can think of this
to a certain extent is a very primitive
way of secure s because you're writing
data always to where it actually belongs
to the note one of the nodes in the
cluster but you could have local copies
of the data and we in coherence we have
something to call near caching and
continued square occasion so you can
basically bring either on demand near
caching is when you do a get and the and
you know we'll check local cache first
if it's not there we'll go to the remote
cash bring it to the local cache and
from that point on will serve it from
the local cash unless it changes if it
changes we get the event and invalidate
the cash right we'd continuous query
cache it's actually even better because
you say okay I'm interested in this
portion of the data sets you can do it
based on a filter you say okay give me
all the trades for this ticker symbol
and bring them locally so then will
populate the cache locally and as new
trades for that ticker symbol come and
we'll just push them down to each client
that has that cash so that allows you to
basically improve read performance of
the application without having to go
over the network to to the primary copy
of the data so improving reads using
near caching using CQC is definitely
something that you need to look at i
just recently back in june i was looking
at the architecture one of the customers
did and they had his tiny little cash
literally kilobytes of data that they
were hitting like hundred thousand-plus
times a second over the network I mean
it adds up it adds up in a hurry we move
that to made it to local cache basically
cashed the whole set of data in each of
the client knows each of the application
servers perform as a skyrocket
immediately because that was heavily
used cash heavily read cache there was
no reason and tiny so there was no
reason to keep the data remote now what
I mentioned earlier for implies
processing I mean we did some things in
in the latest release of coherence to
make it friendlier to use from Java Java
8 so we added support for this
you'll understand i have a whole talk
tomorrow actually i think last up one of
the last docs of the of the conference
tomorrow at four i have a talk on how we
implemented distributed lambdas how we
are sending them over the wire how we
are defining them on the server etcetera
etcetera so if you're interested you
know you can you can come to that but
basically what it allows you to do is
you know instead of writing the code
that you saw earlier where you get the
card from the server mute manipulated in
the service itself and then push it back
it allows you to do something like this
to basically say okay process the card
with this ID and on that cart object
called add method with sku price and
quantity right and that's it I mean that
will actually send this piece of code
into the cluster wherever they've cart
is execute it locally and I'll get a
response back right and this works as I
mentioned this works using distributed
lambdas feature that we added in
coherence 12 to one so if you're
interesting tomorrow I believe Hilton
golden gate 23 at 4pm the next one is
also very important do whatever you can
I synchronously especially in the age of
micro services when a lot you have a lot
of service is talking to one another you
don't want that communication to be
synchronous blocking communications
better than anybody I actually have a
good analogy for that that I just happen
to encounter yesterday any of you went
to the men's restroom after one of the
sessions then you know why blocking is
bad so yeah it's the same thing in
software i mean if if the thread is
sitting there waiting for I oh it's not
able to do anything else and sooner or
later you're going to run out of threads
and threads do have cost they don't
really have computing cost as much
although there is some cause to thread
switching but they do have real memory
cost each trade will cost you megabyte
on the JVM so on the native heap which
doesn't really play nice with darker so
you know if you if you have your darker
containers crashing because your native
memory is growing
and you have many many many more threads
and you expect you need to start tuning
some of that and one nice way to reduce
the number of transit to your
application needs is to make everything
non-blocking because then you really
don't need you know because in a typical
I've intensive applications you will
usually size your thread polls to be
significantly larger than the number of
course because you're just going to have
many threads waiting at any given point
in time if you switch to non-blocking
i/o then you don't have to do that you
can basically size it based on a number
of courses you have because that's the
maximum you will be able to process at
the same time anyway right so this also
happens at a couple levels at the
architectural level you have to think
whether rest is really the best API to
use there are options there are
alternatives out there great sang from
google just had a session on gr pc i
think before before this one gr pc is
definitely viable option they just came
with release 10 it it works nice we use
it for some things and works really well
the other option that's kind of that was
the first one that i used for some of
the work I'm doing and I'm actually
going to be demoing later is so cute IL
nice thing about socket i/o is that
actually works in the browser as well so
if you're building applications that you
want to access server from the browser
using async communication socket ale
works works well gee RPC still does not
work in a browser so hopefully it will
but it is not at the moment so you have
to think whether the API you're exposing
I mean in many cases you'll probably
have to expose REST API because that's
what people expect that's what people
want to integrate to it but it doesn't
mean you shouldn't think about ensuring
to expose other API is if they're more
optimal right so so that's at the
architecture level and then those of you
who are at my talk about a synchronous
programming yesterday there are features
for example in Java 8 this feature it
was at which completa belief you chure
not talked about nearly enough
considering how important it is for
building a sink applications it really
makes composition of facing processing
pipelines easy to do it really does
we actually added once once completely
future was available we added the whole
a sync API to coherence and I can do
pretty much anything you can do with our
synchronous API you can do it with async
API as well and it significantly
improves it through but if you if if you
know we frequently had clients who just
had to do a lot of puts populate the
cash read the data from somewhere from
flat files from database whatever just
push data into the cache synchronous API
limits you to about you know on a
typical network you will have about the
millisecond / put so you can only do
about thousand puts per second with
tasting API you can push a lot more you
can basically saturate the band way that
you have so you can push as much data as
you can reasonably read and put on the
network in a given time so that's the
benefit of non blocking and then
complete all the future makes it really
easy to compose different operations you
can basically say okay do this and when
that completes do this or do these five
things and when all of them complete do
it is right so it's very very powerful
API and then the other thing you should
look at and you could use is reactive
model and I have an example we released
coherence rx which is reactive
extensions a nice thing about completely
future and async API is in general once
you have basic a capi built for example
around Capitol future it is trivial to
expose others I mean doing coherence RX
for example was literally less than 200
lines of code on top of our racing KPI
because all you're doing is taking one
ace in constructing wrapping it with
another converting up little future to
RX java observable right so it's very
very easy once you have one to expose
others as well but the reason why is
that you know reactive obviously goes a
little bit farther than what completely
future needs own does completely future
will allow you to compose acing
processing pipelines but reactive will
actually allow you to do a lot more to
do to map them to buffer them to do all
kinds of things to the stream of data
that you're receiving as it comes in so
both on both of them are definitely
worth looking into
this one is probably not as important as
others you can get far even without this
but for some complex especially
long-running transactions you really
need to start thinking about how do you
model this using finite state machine
because you don't want to obviously
don't want to run long database
transactions but you know you need to
make sure that whatever has been changed
is committed and will not be lost so one
way to do that is to model your let's
say order as a finite state machine and
basically as things happen actor model
is really nice for this acha does this
really well because as things happen to
to the order payment this process in the
rotor ship you can basically keep
updating that order object which is safe
backed up persisted and you can you know
if anything fails that order fails over
you can restart processing for whatever
state it is in so that's one to one
thing to to to consider with coherence
we also do this frequently we call it
live object pattern we use events we
have events on the server that we can
capture and then trigger additional
processing so any transition of the
state and an object we can detect it and
then trigger something else so when
payment this process let's trigger
shipping and shipping is done let's
trigger order completion whatever all
right so you can you can model fairly
sophisticated long-running transactions
using finite state machines
and this way if this is really not what
to do but really yeah not what to do but
what not to do I should be so annoying
in some cases it's not too bad some
systems and I have on the second slide
out of these three I mean that CD a
zookeeper do use global counter global
index but they replicated system and
they're they're built with a fairly
limited use case I mean they store
configuration right you can watch
configuration you can store they're not
they're not meant to handle a large
volume of data and large right intensive
use cases so for them it's fine I mean
they're not going to scale the
replicated system so by definition
they're not going to scale right any
problem with replication is that the
larger the system gets the more nodes
you add the slowly right price becomes
so you at some point you're going to hit
the wall that's why you see
recommendations to run 357 up to 9 nodes
when you're running at CD or or
zookeeper and we run no we're on
clusters with thousands of nodes it's
just different model partitioning allows
you to scale much much much farther than
application allows you to scale so in
their use case it might be okay MongoDB
I mean they fixed it after many years
but they were infamous for the for the
right lock I mean initial releases of
mongo head right lock so you can
basically have all all rights are
serialized so that will not scale if you
have any right intensive load right so
it's much better now I mean they fix it
a couple years ago but do not do that if
you're and I said yeah just just because
you're using something that's built to
be scalable I've seen people bring
coherence down to a crawl by using it in
the wrong way they will use we have this
revealed lock feature we tell people not
to use it we have better ways to
accomplish different things but you know
people decide they want to use exactly
that and they basically turn something
that could be paralyzing could be done
in a partitioned way they turn it into
operation that's basically serialized in
a cluster right that's never going to
scale so you know in some cases make
sure that the products you are choosing
allow you to scale but in either case
make
sure that you don't use them in a way
that you'll prevent you from scaling and
they're the last but not least I mean
really rule number zero in the list
don't take everything you read or hear
at face value I mean we've all been
burned by reading something and you
don't really have time to think about it
yeah and that's where the whole
stateless services mantra comes from
because you know somebody said at some
point it yes you can scale these ejbs as
much as you want by making them
stateless and it's true you can scale
the GPS but you cannot scale anything
behind them right so you have to think
through to think about everything you
read or hear for yourself basically you
need to be like this big critical so
they're obviously a lot of things this
presentation and consider it we are Jaya
one that we are talking about a bunch of
these things in different sessions there
are some things we are doing to make
this easier so i would like to cover
them briefly one that you might have
seen if you were at that session i think
two days ago was proposal for state
management API that would basically
provide a standard based way to manage
state that would work both for
distributed and non distributed systems
for no sequel and our dbms i mean it's
it's a it's a big thing to chew on it's
definitely something we have to think
long and hard about but if we can pull
it off it would definitely be as as the
group is an industry if we can pull it
off it would definitely be useful for to
a lot of people so that's one thing the
other thing is in both Java is c9 in
Java inai and I see a lot more shift
towards a sink programming I was at a
session yesterday where they're talking
about new HTTP 11 and HTTP two clients
that will be built in jdk hopefully
inversion and they're talking about
maybe pulling it out but I'm hoping it
will be there that basically allows you
to
to make HTTP requests both synchronously
and asynchronously uses completely
future its editor there was also session
on a synchronous jdbc which would also
be nice because and the problem with
pacing programming is again if you have
data store and you're doing everything a
sink and then you keep data sword and
only has synchronous API you're blocking
right you have to be non blocking all
the way through so in order to do that
basically data stores need to provide a
non-blocking api's so you know we did it
in the latest release but we are tiny
compared to how how many other things
people are using right so basically
every data store needs to provide
non-blocking API and providing
non-blocking jdbc would definitely go a
long way there also some improvements a
very believe paddle talked about injects
j jax-rs in Jersey to make a sink
programming easier and I'm hoping I'm
not sure what the status of that is but
I'm hoping that server support will also
be improved to to provide more asing
support so that's that's where we are so
now is I promised I'll do a quick demo
and show you how you can build
application that will actually scare me
you'll have to take my word for it I
cannot show your scalability on my
laptop but but you'll have to believe me
that it will scale but I will show you
that it's actually built in a very very
simple way and what gives it scalability
is not the fact it has any stateless
services it doesn't it doesn't really
have any services what gives the
scalability is the fact that is using
coherence as the backend store which is
scalable so i know i can create thousand
node cluster or yeah larger cluster and
support many many concurrent users a lot
of data at the same time and it's not
going to impact things much so that the
demo that i built is based on to do to
do MVC we wanted something simple and
purpose are you guys familiar with to
the embassy anybody doing client-side
development
javascript yes to do NBC is actually
quite cool in a sense that it allows you
to compare different front-end
frameworks so they have implementation
of a very simple decent-looking but very
simple to-do list you can add tasks you
can complete them you can delete them
from the list it's a traitor and they
implemented in you know dozens of
frameworks you can you have your angular
and amber and react jes for this
particular damn i chose react Jas and
redux anybody using that anybody
familiar with them okay they're very
simple event-driven actually work quite
well I did not have to write much code
to integrated the demos the day shape
are basically browser only demos they
don't connect to any back-end data store
they store everything in a local storage
they just you know you can edit it in a
browser once you close it you come back
it's gone right so what I did is
basically took their browser only demo
and change it to work with coherence as
a back-end right so let's look at that
and hopefully the screen stays big
enough for me to see anything here all
right
let's kill this
god I can't see anything
so I could do things here I have a
server that's my to do server which is
basically really nothing more than a
socket i/o server again I talked about
socket i/o earlier it's it's an icing
it's a framework phrasing communication
it has javascript native JavaScript API
it has java implementation we integrated
it with coherence and provided coherence
API on top of it which makes it really
easy to use so i started i started the
server and it started somewhere here you
started socket i/o server at this port
so i already have some data so if i
start my client now or actually my web
app it's going to start dev server it
should it should load the data from the
cluster okay so these are to do is I
created earlier finish the presentation
mate with crack all done event-driven to
do them or not quite but I'm getting
there add multi-user support I need to
do that show demo gel one hope they can
complete this shortly so these are these
are basically read from the back and
then I can create new ones
and it will show up at the end right so
this use is the front end I haven't
really touched I mean I'm still using
the same logic they built in the front
and what I did is actually I built in if
I check on it it will be done etc I can
I can filter in the front end see only
active ones i can see completed ones i
can clear completely but i don't want to
do that yet so that's really what the
front end does now the way this is
implemented and again this is only first
single user but imagine that you know we
could have hundreds thousands of users
everybody's using this we are storing
this on the server based on their user
ID based on their credentials at their
identity so each everybody gets their
own list so just giving idea what the
implementation looks like the whole
implementation is actually in JavaScript
so we have this coherent Leia's module
and again this is something that we
haven't released yet we're planning to
but I have no idea when it's going to be
released it basically gives you a native
client for coherence that you can use
from both browser and nodejs so with
that I can create session to buy socket
i/o server I can get cash called to do's
and then I have couple actions here that
are basically the extent of the
integration I did so when my federal to
do is action is triggered when I load
the page initially I go to the cash and
I get cash values and I call you need to
do is that basically populates that list
in the in the model on the on the client
in the browser when I add item I create
is set to request I this is for
simplicity I'm just using current
timestamp as a as an ID obviously that
should not be in production code but it
works for now and then I call cash put
with ID and I pass this JavaScript
object and this will actually get sent
to the server serialize json we can
actually query it in the server as
you'll see in a second do all kinds of
things to just like if it was regular
Java object and then once that put
completes we dispatch this set to do
method to basically update the UI so you
know that the client will send requests
to the cluster in the background crossed
cluster will store the object put it
create a backup for it persisted to disk
complete the promise that we are
basically getting as a result of this
put call and once that all is done we'll
update the UI same thing with update
except in this case we're actually
calling entry processor remembered what
my talked about doing processing in
place we have one of our building and
reply sir is basically update processor
which allows you to update attribute
property on an object so we want to
update text property to this new text
and again updating in the UI complete
does the same thing it up the updates
completed flag delete request removes
the idea
updates DUI and then clear completed
request actually uses a filter so you
say okay let's create a filter where
completed flag equals through and then
for all the objects that satisfy that
filter we want to call this conditional
remove processor and remove them from
the from the grid so each of these
operations make the call to the server
directly from the browser I have no
middle tier to speak of and it will
scale you do not need stateless services
to scale you need scalable data store so
if you expect the Java code I know
you're disappointed but you know from my
perspective the less code I have to
write a better and you know if my java
code is simply exposing api that i
contain calling from javascript anyway
might as well go directly to the data
store right we have to a certain extent
we have kind of come the full circle
right because we get thin client now we
have two clients again all the logics is
again in that yeah now accepting clients
are implemented HTML and jas so if
you're already putting all your logic in
the client might as well make holes from
them directly now I'm not saying this is
this is the right approach for every
application or plot probably not even
for most applications but it's possible
and even if you do it this way the whole
point is it has no impact on your skill
ability because having a layer of
restful services in front of this
JavaScript would not buy me absolutely
anything I can still scale I can I can
provision as many socket i/o services
they want they can provision as many
storage nodes they want they can scale
my cluster in a background as much as I
want and support more and more clients
as my to-do application becomes more and
more popular I do not need a layer of
stateless services
so with that this is done and I can
clear my completed items
and switch back to the slides if this
thing lets me
alright so that was the demo do you guys
have any questions about the demo yes
sorry i did i do not understand the
question now when you when you scale
data storage you're basically scaling
both capacity how much data you can
store and throughput how many requests
per second you can handle right and
because data is partition I mean these I
have only one node here I run only one
server I'm running on my laptop I could
have hundred servers and I have hundred
to-do items they're going to be spread
across hundred servers if I have hundred
million items they're still going to be
spread across yeah thousand servers
right so you scale your data but by
partitioning data across the cluster you
scale your processing by having many
processes that can handle the request
right so I can load balance my incoming
socket i/o connections to all the
servers that they have right and they
will all talk to the same storage nodes
they know which nas to talk to where the
data is right so so I get scalability I
me yeah i'm kind of i'm not completely
honest here I mean I do have stateless
layer but it's implemented as part of my
socket i/o server because socket i/o
server basically implements our API
using messaging so I send message from a
client that message is executing the
server that message is stateless it
carries everything it needs to execute
but there's application developer you
don't think about that you don't worry
about it you're making API call on the
client and it's magically executing on
the server and giving you data back
you're not building you don't you do not
have to build the whole another layer
that is really nothing more than a
glorified data store anyway right
because if you look at what the
applications are doing today typically a
rest api ends like being basically a
bunch of crud operations if i have data
store it exposes a pilot that allows me
to do crud i can go directly to it right
so you know it's not that
there is nothing stateless here it's
just that it's baked in its built-in and
you can actually build your own the way
we the way we design the circuit their
server is you can define your own
request types and your own request and
implement them and basically deploy them
on the server and then call them from
the client and defining extend our
client site API to add your operation
state as well so you know very stateless
but not what you need to do right so
hopefully you did not feel this way you
enjoy the presentation and with that I
will leave it open for questions there
aren't any other questions yes I don't
that's the beauty that's the beauty of a
demo that's the beauty of a demo how
would you deal in real life to be seen I
mean you know we can authenticate
obviously you know we are talking how
are you dealing with security on the on
the rest api that you're implementing
you have ssl you have authentication all
of that can be supported here because
you're a socket i/o is really web socket
so ssl still works any authentication
you want to plug in still works so
you're basically still I'm not exposing
native coherence api's here right I'm
not saying you go and you hit coherence
using native API is from anywhere that
would be a bad idea because you know by
providing different API you basically
control the surface area you control
what can be done you expose the
operations that you care about and
that's it right and then you can still
secure them using SSL and authentication
and authorization all that stuff so it's
it's up to you to define those policies
but everything is configurable any other
questions sorry I feel the guys over
there neglected please somebody say
something
yes the way I mean now we were talking
about how coherent stores data right the
way no no no no if I was using logmein
Cassandra that's how it would be right
with coherence I have options the option
I I chose in this case is i use
coherence persistence so i enabled
positions for this cache and it's
basically writing into my file system
it's right so every node will write it
you know if we care if I have cluster of
109,000 nodes each one will write their
local file system or shared file system
if you configure it away but that has
latency penalty with it yes yes yes and
the way the way we ensure i mean they're
they're a couple couple things to the
fault tolerance right because once you
partition obviously if you lose anything
you're losing portion of the data right
so what I didn't say earlier is you know
we do backups right so we write
something you ready to primary node we
ready to back up north as far as
possible so you can configure sidetrack
machine for each coherence node and we
will back it up as far as possible so we
can we are going to back it up to a
different site which is basically
different data center we're going to
back into a different track if we have
wreck information etc right so if you
lose machine or a wreck or site you
still have backup copy in memory right
if you lose that you still have copy on
disk if you're using persistence right
so we can restore from that so that's
what insurance are you because obviously
you know when you replicate everything
ever for example is you keeper and EDD
do any node can go away you still have
all the data in every other node right
when you're on your partition you
basically need to make sure that you
have backups that your backups are saved
you know persistent resistance is safe
etcetera yes
I think this is fairly small problem
domain there is there isn't right there
isn't there isn't much the partition
normally yes you would have you you know
and again I'm not I'm not recommending
this is the architecture for your next
application by any means not only
because it's not out there yet but also
because probably not a good idea the
whole purpose of the demo was to
illustrate it you can build this right i
mean and it will be scalable is it a
good idea different story right if
you're building more complex things that
you probably as you want to you want to
partition things in some way you want to
have some boundaries you want to define
your bounded contexts and services
within those bound in context you
probably wanna expose multiple API is
not just a single API etc so yes in the
real world you would probably do a lot
more than what I did here all right
thank you guys enjoy the rest of the
conference</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>