<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CQRSに取り組むべき時期、理由、方法 | Coder Coacher - Coaching Coders</title><meta content="CQRSに取り組むべき時期、理由、方法 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CQRSに取り組むべき時期、理由、方法</b></h2><h5 class="post__date">2017-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ajASbq5pzss" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so welcome and konichiwa from my side to
the talk when why and how to see QRS I
am very happy to be here this is my
second time in your beautiful country in
Japan my name is Sebastian - no I'm a
Java consultant and trainer from Germany
from Munich and I'm a regular conference
speaker and a community guy in Java in
the Java field and Java EE field I'm I
hope participating in the JCP to form
the jacks arrest and the JSONP
specification and execute member I'm
also a so-called Java champion and a
last ones Java one double rock star
speaker so about the concept of CQRS I'm
curious so I want to do a short poll who
of you has heard about the term CQRS
before hands up
okay quite a few and who a few has used
it in in some project or while hacking
around oh okay that's that's interesting
and so in my talk I will first of all
show the concept of secure s and wile
developers should care and then I'm at
the second part I will show some code
how to implement it using java
applications and of course a demo how it
runs then so first of all the typical
way how we build enterprise applications
is that we use some kind of crud based
model right we have our application and
a current state of our domain entities
that means we have a state in our
application how all the business objects
look like and if we change something in
our application then we have a new state
and the old state is from
of course this introduced some
shortcomings mainly if we run our
applications for two years then we don't
know all the things that have happened
in between we just see the latest state
right and also and we want to be
consistent in our application of course
and by having these last states in the
craft based model we have to somehow
make sure that the consistency is given
at any time so we have to deal with
competing transactions that means we
have to synchronize transactions that
have that happening at the same time
which is what you're doing all the time
in enterprise applications right and
this is the reason why a crowd based
model cannot scale infinitely because
you have always some point in time in
Europe in your database in your
application where you have to sync all
these transactions and this is the
reason why it cannot scale and now I
want to show you two motivations two
different motivations that finally lead
to the concept of CQRS event sourcing
and event-driven applications and these
two motivations are first of all totally
separate from each other that means you
can use the concept of event sourcing
without needing events driven and all
this I will explain that in a second
what that means event sourcing the way
how events of applications are built is
that you do everything what you're
changing in the application you do in
atomic and immutable events that means
everything that is changing all the
business use cases are restored as such
and you can get the current state of
your application by applying all these
events right the most prominent example
for this are money transactions in your
money bank account
right you start from zero then you add a
hundred or let's say a thousand yen you
deficit and withdraw a thousand yen
again and plus and minus all the time
and if you want to have the current
balance of your account you just apply
all these events right this is how you
my bank account works and this is the
perfect example for event sourcing
because if you want to have the current
state you apply all these events and you
can also have the full history right
because everything that has happened in
your application is stored as is as
events all of them are available and
therefore you get the full history you
get all the context why is the
application in a current state you see
all the use cases that have happened to
your system and all the business related
use cases are more or less stored as
single event use user name changed money
money transfer requested for example and
these are all the event that a data
stored and also you can somewhat
implement what I would call future use
cases for example if your application
has been running in production for two
years and then after two years your
manager comes and tells you can you tell
me how much users signed up on a Monday
for example and if you do a crop based
model then you can say sorry I don't
know because there was never a request
but if you do an event sourced model
then you can say okay sure because I
have all the user sign up the events and
I just see how many there are on a
Monday and calculate them in a crowd
based where you have no way of getting
that information if you don't do a
separate audit log but in event sourcing
this is really the core concept built
into your data model and you can change
something on your functionality later on
right you have any questions so far
I forgot to mention if you have any
questions all the time just interrupt me
we have you can also ask questions in
Japanese we have translators here is
everything clear for the event sourcing
concept okay
now you could do event sourcing totally
without dealing with distributed systems
you can just do events Rossing with one
database in an old way and that's it but
if you have distributed systems if you
have several systems involved then you
have to make sure that you think about
event-driven architectures or at least
two distributed transactions because
distributed transactions are a bad idea
right if you have several systems
evolved and you have system a and system
a needs system B and a root user request
comes in talks of system a that system a
blocks and waits the user requests talks
to system B waits the whole time until
system B respond and then it responds to
the client and this cannot scale because
this takes way too much time these would
be distributed transactions involving
several systems and this is a problem if
you want to do this in a scalable way
and that is the reason why a crud based
model also cannot state a scale and in
event-driven architecture what you do
instead you communicate via events and
you can do so because you split up your
transactions your transactions and that
are consistent are then split up in
smaller transactions that are also
consistent and that will be consistent
in the long run this is what call is
called event being eventually consistent
that means then you split up everything
you have into several use cases and at
the end you will see the same outcome as
if you have had one big transaction but
you can scale more because you can do
just one part of it and then wait and do
something
instead and you don't have to wait on
for the whole big transaction at a time
and in order to show you an example how
this looks like in theory I have done a
nice ASCII art demo with coffee so we
have a coffee shop and now we have three
systems involved an orders system that
is used for order management we have a
bean stem system for bean storage right
we need coffee beans to brew coffee and
we have a barista who makes the coffee
right and especially in Tokyo there are
very good coffee shops I always like to
get a copy there and this is why we do
some coffee example right so now let's
say the client wants to order a coffee
at the very top or the coffee method is
called and now instead of you know going
to the order system the order system has
to ask the bean system are there enough
beans of that specific type and then
comes back this doesn't scale rather
than we split it up into events or place
order the method turns out into the
order of life's events as I said these
events are immutable and happened in the
past this is a fact the order has been
placed this does not mean that the order
is valid or that the order will be
completed or that you finally will get
your coffee there may be some error
later who knows but the order has been
placed and this has to be done in a
reliable way
and now event-driven now all the other
system listens to these events and
consume them so as soon as and all the
place demand arrived asynchronously the
client has already gone away the client
already returned the validate beans
command will be called in the bean
system and then either you have an event
order being validated then it was
possible or you have a failure or
they're not possible due to insufficient
beans for example
and then the order system listens to
that event and says okay that means the
order has been accepted so I will now
accept the order update the status that
it's now possible to brew the coffee and
fire this order accepted event and when
this happens the barista finally comes
and starts making the coffee peculiar
because the barista is only interested
in accepted orders and so on and so
forth and then the order started status
will be updated and the beans will be
fetched and so on and so forth and
finally the coffee brew will be finished
and will be delivered after the barista
has been finished but now you get the
idea right you communicate only using
these events and all of the methods here
like accept order or like place order in
the beginning are just short methods
that are fired asynchronously and
returned quite fast any questions so far
so that means here that we now can do
this in a scalable way with the
event-driven approach and now with the
two motivations event sourcing and
event-driven applications I want to
introduce the concept of CQRS that
stands for command query responsibility
segregation and that is one way how to
model applications that use the
event-driven approach right so this long
word command query responsibility
segregation basically means you split up
the concerns for writing changing
something and reading reading status of
your application in Java that would mean
you have a method that is void for write
that changes something
what void does not return something and
on the read side you have a getter that
only reads what doesn't change something
that has no side effect and in theory
this is quite as simple but it actually
has a lot of implications on the
application side that means the commands
only produce events the query side which
is the read side that don't produce
events but the command it cannot return
anything so it will produce event but it
cannot return data and it's also very
important that all these events are
handled and published in a reliable way
so as soon as you place the order for
your coffee and the method returns you
have to be sure that the event really
has been published that is important
otherwise if and this stuff this is done
in a synchronous way with the event
store otherwise if that would not be the
case that would mean that your order
would get lost and the client comes back
later and then the order is gone right
so you have to make sure that all these
events are handled
and now more FGM on pictures now this is
one way how to model the write and read
site we have a command service and we
have a query service that's that we can
also have several command services and
several query services as they only
communicate over the events sent to a so
called event store or event up and what
I displayed here in the database the DB
means that all of the sites have an
internal representation of the domain
object that means the current state of
the application so these have current
representations of the coffee order I
will show that in a second and the
databases or in memory storage or
whatever you choose can be totally
different from each and every instance
that means the left side database can
totally look different than the right
side database they are just optimized
for each and every use case what you
need any questions so far
are the concepts clear please ask any
questions anytime and now how to do one
example if you want to place the order
the order place changes something in the
application that means we go to the
command service that can do some
validation using its database and when
it's successful it means that the order
has been placed right so this event will
be fired to the event storm and then the
place or the method is over it will
return successfully and that's it
that means that the order has been
placed now the event hub will fire this
event to all the consumers on both the
right and the read side and this read
side the command service will update now
it's internal representation stored in
the database to for example create a new
coffee order object stored in a database
and as soon as the client requests the
status of the coffee order it can output
the current status from the database or
from in memory and as again they only
communicate over these events they are
not connected to the command service
they only apply the latest change which
they got from the event and also since
we finally want to have a coffee that
means there needs to be some component
that listens to these event and trigger
new commands on the command side right
so there will be some kind of event
handler that does something after an
appropriate event has been fired that
means the order place and the order
placement will trigger the beans system
to do something to validate the beans
right and this is done by a so called
event handler
and now this means that the CQRS concept
introduces scalability to our system to
our application because first of all we
can scale as much as we like we can
introduce several instances of our
system they only communicate with the
event hub but it also means that now we
can scale the read side
from the right side independently
because they only communicate by events
and we can optimize both sides
independently only the events that is
only the only thing they have in common
and in enterprise applications the
number of reads normally highly
outperform the number of writes right
when you browse some websites you
constantly refresh constantly f5 and
eventually you change something right so
that means you read far more often than
you right so this makes sense that you
now can be able to scale out just the
read side and having more instances and
more databases there and the the right
side is far less scaled in your
application and it also solves the
problem of the events or things
scalability that means if you if you
apply event sourcing and you have all
your you know bank transactions and you
would calculate the state each and every
time on each and every request this is
very slow because you always have to
wait for the states to be calculated if
you read read and in CQRS since we are
only storing the representation and we
update these four presentations
constantly it solves this problem since
you always have some kind of cache of
the current state of your application so
this will output the current and state
as fast as if you would do a crud based
way right
another nice side effect you can have
read site failover capability because on
a cross based application once your
database breaks down then it's over
right you can't do anything because the
database has gone in a secure s way you
can at least read you cannot write
something since your event store is a
way you cannot publish events right but
you can still read from each and every
instance that is up there and this is a
nice side effect so now I will show you
some some code I have introduced a
similar example like you saw on the
slides that uses a scalable coffee shop
application that runs Java EE 7 and uses
Apache Kafka as an event stirrer and as
you saw in the examples I have three
applications that means I have three
instances running on three application
servers for the order system the bean
system and the barista system and in
order to show a case you how this is
integrated in using Java EE I will
quickly walk through the code I would
want to live code for you but the
problem is that implementing secure s
you need more codes than you would do in
a crud based way so this would be too
much to do it ad hoc here and this is
why I want to just walk through all the
workflow that happens when you for
example place in order when you order a
coffee you have a jax-rs resource here
using HTTP so you can place an order
over rest right
and you do so by posting adjacent to
order coffee here this is one jax-rs
resource to both the read side and the
right side so this will be actually
shipped in one application but it is
totally separated from each other that
means you could if you want have one
application for the resize and one
application for the right side on all
these three modules and you will see
that they are actually separated here
using an command service in the query
service so if you order a coffee then
this of course uses the command service
to place an order and this will use a so
called event producer that will fire the
events to the capital cluster and that's
it as you see it is a void method it
just places the order and when this
method returns successfully and does not
throw any exception you can know that
the order place event has been fired
successfully and this internally
connects them to the castle cluster in a
synchronous way publishes this event and
sends it out and returns and then you
also have the read side I want to get an
order from the ID that I got back while
creating and this uses the query site to
read the order and here I have now my
database my storage with all the coffee
orders that include a hash map that
store all the coffee orders now to
showcase you this whole concept better I
only use memory storage here that means
in a project you would normally use a
persistent database access right here
access probably Maya JPA
and then you would have some persistent
current state here is calculated only
memory
and the way how I integrate Apache Kefka
with Java EE is that I used a concept
that is already there in CDI namely CDI
events that means if I connect to Kafka
as a consumer and some event arrives I
will fire a CDI event and these CDI
events will be listened here or the
place or a canceled order accepted and
so on and so forth and this will then
update all the status in my hash map
that means it will update the current
representations in memory and now I
configured it that way that it will as
soon as the application starts up
redistribute all the events from Apache
Kefka that have been there since start
that means you deploy something and then
all the events arrive and all the events
here are applied to the hashmap using
this logic and then you have the current
state calculated in your memory any
questions so far
and as you can see these I see the IMM
that are fired as soon as we consume
something from Kaka and this is the way
how it is connected in a Java EE you
world the event producer will publish a
new event using Kafka and since we don't
have too much time I will not go into
detail how we access Kafka on the
consumer side
it basically means as soon as an event
comes in at the end Kafka we will fire a
Java EE CDI event and this is how it is
connected another thing that is
important to know as so-called Kafka
consumer groups the way how Casca works
is that for one consumer group the event
will be published exactly once that
means if you have several instances and
all of them want to read that event that
means you have to have a specific
different consumer group for instance
and these will be this will be actually
created on unread them here but it also
means that the event handler that will
then trigger new and command will only
be there once in all the applications
that means if you have three instances
of for example the orders module only
they all use the same and capture
consumer group so that only one of them
will get the order so if you and do one
or the place event then you will end up
with one coffee and not with three
coffees for example if you have three
instances of of your application right
and this is done in the so called order
event handler that means you connect to
it using some some topic that is
configured and it basically means that
you will fire a new
and as soon it is arrived and this will
then go to the command service and
trigger new commands right so this is
more like the integration of Kafka how
it fires events and it how it triggers
new commands for this event handler
consumer group and I will later on give
you some more pointers how you can look
into this in more detail to understand
how the API is used and from Kafka
within Java EE and now I want to show
you a demo that uses Apache Kafka that
runs on the Oracle cloud so you can
either run Kafka in docker or locally or
somewhere on your server or you can use
since the Oracle code event the Oracle
cloud that includes an event hub service
where you can build up well a demo for
apache catholic alaska cluster and this
is what i have done i have here some
instances that a use Casca together with
zookeeper and that are accessed from my
application and now I have three
terminals here to run my three
applications beans barista and orders
and they will run in a docker container
using my fly as an application server so
this will run in Ducker
and then access the an Apache cluster
that runs on the Oracle cloud that means
I have a docker file here that builds a
docker container using the war files
that I have and it is used as a private
image of myself that includes wildfly
with Apache Kafka and if I build it
and run it locally it will rebuild the
application in Maidan I just have a
script here distorted faster and it will
deploy everything on wide fly and do
this a second time for the beans and a
third time for the barista so I have
three applications running on sweet up
and application servers running in three
docker containers and all of them will
access the Apache Kafka cluster so if I
now show in my docker I have my three
applications running and now I can ask
the order system what IP address it has
arrived you will normally use some kind
of orchestration framework for it but
now I can access this and ask for orders
for example right so I can here use this
IP to create a new order
this is rest right cool I can also use
some kind of other red client it doesn't
matter and now I will paste some Jason
that orders a new coffee right I want to
have a coffee from which beans from
sorry I can do this bigger with beans
from Colombia and the coffee should be
in espresso and I post this order and
now what you see that you will have an
HTTP 202 accepted status and you will
get a location back where you can read
the order so if we now ask it it was
accepted that means the order has been
placed and if we ask it it is already
cancelled why because the bean storage
is still empty we don't have any beans
but what now happened is if you look
into the log file that the order has
been placed first order placed
and then it may immediately failed
because there were no beans available
and this second beans application is
actually it's in charge of sending this
event and now the first application
listens to it and says ok it failed I
now have to update to order cancel
because it was not possible so the order
is immediately being cancelled but the
client didn't see this at first declined
have to to accepted and when he comes
back later then it they can ask for the
new status and now it's it's canceled
already so that means we need some beans
first right and what we can do we can
now place some some beans if we ask our
beans system it's empty this is an empty
object there are no beans available that
means we have to post some new beans to
our bean system so we will post new
beans to the beans application with for
example one one type or ten packages of
beans from Colombia right and now we see
if we ask again that our ten is from
Colombia there and if we now order
something again that means we have again
an order that wants to have an espresso
with beans from Colombia it's accepted
again but now we have the URL that is a
different one and if we ask for it oh
it's already finished and if we ask
again this means that it eventually will
also be delivered so now what happens we
have
and order placed but now the events
field is a lot a different order place
has been fired and in the second system
there is already been validated now so
now it's valid and the order now has
accepted has been accepted and this
means that the barista can now start and
so on and so forth and to order status
is constantly being updated and if we
ask again then we see it's already
delivered so at first everything is done
eating crumbs here right I firstly
placed the order and then we see how it
is updated and this was all done
asynchronously using these events which
you can see in these three applications
you have any questions so far on this
so now the way how it works is that I
said this is done all in memory so what
I'm doing and now shutting down all the
applications now it's gone and the
in-memory representations are gone so I
don't use a database here but if I run
it again
and now I will have three new docker
containers with new applications and
totally fresh system it will actually
now access the Apache Kafka cluster and
ask it to redistribute all the events
again this means if I wait now until my
application is up I can ask for this
order that has just been in memory with
a random ID and I can read the status
the order is there again why because my
applications accessed the cluster and
you see installed being fetched order
delivered and so on and so forth you see
everything that happened to the system
before you see the log files again here
with the orders and all the events this
means that all the events from Kafka are
redeliver to my application and now I
can see that status again although it
was just a memory and everything was
down so now you see how this works that
the events are redistributed in a in our
production application you of course
want to have some persistence so this
would be the point where you include a
database right so this does not scale
because if you run it for two years you
have thousands of events and it gets
slower and slower at startup time
because you always need to reapply these
events this is why you want to have
snapshots that means
again it's the same what your bank is
doing with bank accounts you see all the
bank money transactions but probably
only in the last 90 days or in the last
zone so many days and before that it is
just you squeeze together and reapply
from the status and this is what is
called snapshot the events are still
there but you don't want to start the
calculation from day one and this is why
you can fast forward and calculate to
any point in time and you can do so
because all the events are immutable and
happened in the past so everything in
the past can be cannot be changed so you
can take any moment any version and just
commit on that say this is now
calculated once and I go from this
starting at the new zero and then I
commit to that status and tell Kafka
that it should not reapply all these
events right if you have any do have any
questions everything clear please feel
free to ask anything if it is not clear
you can also ask in Japanese if you like
no questions
okay now what we could also do is that
we change something on the application
side because you saw when I deploy it
all the events will be redistributed
right that means I could change
something on the code level here I could
fix bugs or I could introduce new
functionality and as soon as a redeploy
and Irie this triggered all the events I
can change the calculation for example I
could you introduce some statistics
calculation here and saying please
calculate something as soon as one event
arrives and now I redeploy my
application with the new code and all
the events get real and reapplied with
the original data and now I can access
this data in a different way and
introduce new functionality from as if
the functionality has been there in the
past right so do you have any questions
left
this is where you can find the code it
is actually available open source on
github this is my scalable coffee shop
project and it shows you how to include
this concept using Java EE and Apache
Kafka so please check this project out
if you like and if you want to hear that
concept of CQRS
and the Java EE and integration again in
a more you know lengthy manner I've
published a video course that is
available for free that you can watch
that shows all this concept and the
motivations behind it in a more extended
way so it also includes how you access
Casca from a Java EE application and it
shows us the same coffee shop example
this is available for free on my blocks
you can and check this out if you like
you have any questions left on the
concept of secure applications in
general or the application using Java EE
and the Patrick Kafka in particular yes
please uh-huh umm yeah please wait for
the microphone
I think you can act hi it took steps
mushy so I don't this ghetto I know MA
I'm gonna call you chica chica
artistically thundercat about my channel
taking microscopes Oh God
distributed system of the cow manage
that amount iscador
congregate at which they were database
or sliced cut through akira toriyama
fatum on the schedule doors kak Yona
damu mistletoe database night and
imitable night and isolation while
husband so not taking doll head mask
Amanda might like Arizona beans coca uh
no Anthony order no the dilation water
has remembered Asano's Aikido Nakata
Hamish races automated Santosh devil uh
no Margie say no non troppo rejected the
goddess I know say indeed scout or
tables wat mahat port chania Hakata
karma Okada - kini antónio vieira
cassava say no Takeda traditional
Buddhist award on aquatic ecosystem
mm-hm yeah thanks for the question very
good question first of all I'm with the
database relationship you should not do
database relationships in a distributed
system
by doing micro services so what you're
basically doing here are micro services
several ones that only communicate via
events and these micro services are
isolated they don't know each other they
only communicate over the event hub and
the thing is that you cannot introduce
these relations other otherwise you just
tie them together and then you have a
monolith or what is called a distributed
monolith and this is a problem because
this doesn't scale as soon as you have
some relations on a database level this
kind of book so what you do instead that
if you need data from system B you
record it as soon as the event arrives
and the event contains the data that is
needed and then you store that
appropriately but you store it
independently based on every service of
course this means that sometimes you
have supplication in your code but this
is perfectly fine and this is much
better than if you tie stuff together so
what you want you have want to have
loosely coupled services here otherwise
this doesn't scale otherwise this kind
of the concept does not work so this is
very important and to your second
question yes it actually scales much
better than traditional ways of
enterprise applications and why because
everything is distributed here you have
distributed applications that talk to an
event hub that is actually also
distributed so Apache Kefka can and run
in a distributed way and all of them are
scalable so you can introduce as much as
you like hundreds of thousands of
application servers if you like so it
scales much better
the downside of CQRS is that as you saw
in my example it's much more code you
need to define all the events unity you
find the event handlers BCD
and so on and so forth introducing a
simple mjp a craft based example it's
much less code it's much more simple of
course so that is the downside and
another downside is that most of the
developers are not that familiar with
secure s with this new style of and the
distributed application so this has to
be well recognized and learn first
so that ISM that is the other thing and
the very important point is as always in
micro services you have to have some
kind of motivation for doing micro
services don't do micro services just
because it's cool right now and it's a
hype topic you need some motivation you
need to have scalability and I claim
that crud based applications are
scalable enough for most of the most of
the use cases in typical enterprises and
typical companies or you have
distributed teams that want to produce
software that is deployed separately or
you have to have some motivation why you
slice up a big application into several
ones and this was very important if you
can avoid secure s and if you can avoid
micro services please do so this is good
because it's simpler if you can run a
monolithic small application that's
perfect it will be faster to develop and
you have a you cream avoid a lot of
problems but if you want some benefits
in a scalable way then the secure s
could be a good topic for you and as I
mentioned before you can use event
sourcing within one single application
so if you want to have the full context
the full history and these benefits from
event sourcing you can do so without
using secret and without using an
event-driven approach if you only have
one application then this works with one
database as well so if you not have any
other questions then thank you very much
for your attention
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>