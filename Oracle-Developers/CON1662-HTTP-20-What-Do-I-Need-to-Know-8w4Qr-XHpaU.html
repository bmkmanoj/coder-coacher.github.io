<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CON1662   HTTP 2.0:   What Do I Need to Know? | Coder Coacher - Coaching Coders</title><meta content="CON1662   HTTP 2.0:   What Do I Need to Know? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CON1662   HTTP 2.0:   What Do I Need to Know?</b></h2><h5 class="post__date">2015-12-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8w4Qr-XHpaU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so welcome to this session on HTTP
two notices to not to point oh very very
important we'll get to that later but
good like 45 minutes of the session is
why it's too and not to point o kidding
ok so what is this this talk is a little
bit about HTTP to its assuming that you
have pretty much no knowledge about HTTP
two if you've been using it proactively
then I suggest you find another session
although everything is probably in the
other building so by the time you get
there you missed our session so you
might as well just stay here it's just
to give you a general idea of what HTTP
two is why we need it why we're using it
and how it affects you as a developer
how many of you here are web developers
right that's a good thing it normally
this will only affect web developers or
doing any kind of web development or so
so if you've been around as long as I
have you probably remember the world
wide web in 1990 I was going to say 1966
it feels like it 1996 how many of you
were around back then I try and make my
sessions very interactive because
otherwise you'll fall asleep specially
considering is hot in here you'll
probably fall asleep specially if it's
after lunch okay again how many of you
around long time ago you remember this
Yahoo and we used to use yahoo and you
used to go to this page and used to type
something and it was just like amazing
and you would get back all of these
lists of links and then you will click
on these links and go somewhere else and
you would get back a whole bunch of
other links and there was only a couple
of us back then using the internet so as
you can see the Internet has
substantially grown three billion users
and we have facebook to thank for that
because probably about 1 billion of them
are on Facebook taking our precious
bandwidth ah so it has grown and if we
cut down a dike distributed park cooper
region you can see that asia takes up a
lot of internet and then you have
america europe africa and oceania
australia anyone from australia yeah you
probably it's so slow day nobody uses
the internet all right
been to Australia I know how slow it is
still now so that's why and we've got a
lot of distribution across a lot of
countries you know pretty much everyone
is on the internet nowadays and what
this is provide us is with better user
experiences so what we used to have
before with yahoo we have now still
exactly the same with yahoo except we
have some images on yahoo and who uses
yahoo still whoo yeah so but this isn't
an example I was actually trying to see
what this better example and better user
experience they talk about is so I went
to a website I went to Google not yahoo
and I said Google give me award-winning
websites and it took me to this other
website that then took me to this third
website that then told me about this
other company that develops websites has
created this website and I did a small
little video and basically what it is is
it's find a doctor right so let's say
you have some sickness or some disease
and then you look this up and it turns
all the little doctors that are in your
area and then it routes out the map for
you and then you can like see how to get
that from your house and then you can
click on a specific list look up all the
doctors look at all the different
reviews these doctors have and then
select them and see their opening times
and see comments from other people and
basically give you an idea of which
doctor you want to go to to fix you up
some would call it Yelp for doctors and
talking about Yelp a few weeks ago I
think about a month ago I was reading a
an article it was a it was about this
journalist I don't know if you've read
it it was about this journalists that
have created this fake company and he
had called it fake it was freaking
awesome karaoke entertainment and he had
contracted a bunch of hit basically it
paid a whole bunch of people to get this
amazing reputation on Yelp Twitter
Facebook everything for a company that
doesn't exist so when you do do your
recommendations on doctors based on that
take it with a pinch of salt but it's
all good it's all smooth everything runs
fantastic right and nowadays everyone
has more bandwidth
so if you look there's that there's a
guy called Jakob Nielsen did a law
similar to Moore's law except he was
talking about bandwidth and he said that
on average is going to be a fifty
percent growth in bandwidth over the
years if you look at the chart the dots
are what he plot well the chart is what
he wrote and the thoughts of what the
reality is so you can see them more or
less he was right yeah everyone's
bandwidth has gone up if you look at the
bandwidth by country you can see that
south korea's away at the top then we
got hong kong somewhere down there we've
got spain which is where I live and then
we've got us with 11.5 that's the
average bandwidth is that more or less
accurate where you are well who's got
one terabyte and one gigabyte pipes to
their house ok so bandwidth is all good
if you look at mobile networks and the
all of us are spending our time on
mobile networks that is also great
Europe we have 20.4 so I have more on my
mobile than I have on my pipe at home
North America Asia Pacific Africa is a
little bit slow but on the whole it's
all good so if it's all good and
everything is fantastic why are we
dumping HTTP 1.1 real reason is because
we got to keep this industry moving so
we need to invent something new to be
able to then come to these talks and say
you need to move to http 2 and then
charge consulting that's the real reason
but now let's get into the theoretical
reason the reason is the the problem is
no longer the bandwidth right the issue
isn't actually the bandwidth back many
years ago in 1996 a Stuart cheshire I
wrote a paper called it's the latency
stupid how many of you have read this
and basically what he was saying is that
the problem eventually is not going to
be the bandwidth it's going to be the
latency now to make sure that we're all
on the same page the difference between
bandwidth and latency bandwidth is how
much like the size of your road right
when your car is going on how wide are
road is latency is the distance you have
to go right so it's how to get from
point to point what is the limiting
factor for latency
speed of light right until someone
breaks the speed of light we cannot go
faster than the speed of light now if
you take a you know a pipe from
somewhere in Europe to somewhere in the
US and you create a vacuum you will
probably get a speed of 85 mini second
something like that the problem is that
we don't have that vacuum and we don't
have anything you know we have routers
and different things in between that are
causing delays which add to this Dayton
see so you end up with a ping of maybe
like 200 milliseconds so it takes 200
milliseconds to go from Europe to the US
which is clearly unacceptable this pose
is on purpose now think about that it is
clearly unacceptable to have 200
milliseconds to go from somewhere in
Europe 8,000 miles to the US apparently
it is because some of the large
corporations that also have invested
interests have run surveys and these
surveys have said that if people are
waiting too long they get distracted
right so if I go to a web page and I
have to spend more than 10 seconds for
it to load I will probably not stay on
that webpage and I will go to the
competitors web page how many of you
suffer that right good so you're in that
six percent of the population that
suffers that and according to that
thingy I personally have no choice
because I live in Spain I wait 20
minutes for that web page to load
because there's not much else I can do
but eventually what this means is that
latency is going to have an impact on
revenue because if people you know have
to wait too long they'll switch context
and we have things like Twitter to thank
for that you know our ability to focus
has well tldr I'm not going to get into
it so if you look at the bandwidth and
you look at the page load times via HTTP
you can see that as a bandwidth
increases we do get shorter load times
however at some point that starts to
become more or less
right so it doesn't matter how much
bandwidth we have the page is not going
to be loading faster and here's another
chart which shows you latency by
bandwidth and page load return trip
times so you can again see that at some
point the latency will drastically
reduce the page load time whereas the
bandwidth doesn't now the problem with
this is that if you take a page like
yahoo that we initially had in 1996 it
wasn't a big deal because it was a
single page the window server that sent
back a bunch of texts because that was
opening up a single connection getting
some data the problem is that the
latency that we have is per connection
and if you look at a typical web page
nowadays this is for example from a
newspaper in Spain that on average takes
like totally around 56 milliseconds one
minute to load fully fortunately the fur
the contents loaded in five seconds and
then 55 seconds is loading all the
banners with the adverts and then they
wonder why we have odd blocks but look
at the connections that it opens all
right a single web page is opening up
hundreds of connections and in each of
these connections there's going to be a
latency problem right so each connection
is going to add to the time if you take
a break down of the web call in and
chrome you can do this you can see that
basically there's a queue time there's a
DNS lookup time which basically means
every time I want to look up a DNS I
look up a host I have to do a DNS lookup
there's an initial connection there's a
waiting time for the first byte to be
transferred and then look at this it's
the actual content download right and
yet all of this is adding to that delay
yeah there's a web page I don't know how
many of you've used this is called web
page tests you go to a you enter URL and
it gives you what's called a waterfall
model that basically shows you how the
one connection is basically being
delayed by the other for various regions
because of TCP also because of the
dependencies that HTML has on other
resources etc so this is a waterfall
model and if you expand this you
actually see a waterfall and this is one
place where agile doesn't help ok that
was a
very bad joke well if you haven't heard
agile is the new waterfall anyway so yes
it is so let's go back and look at some
basic history the ice is so oscillators
so there's 70 soo see layers how many of
you can tell me where HTTP sits
transport no application right HTTP sits
at the application level and a lot of
times we actually confuse it with
transport and we use HTTP as a transport
whereas HTTP actually offers us a lot of
aspects for application all of the
semantics of HTTP can be use for
application development so and that's
where all the whole rest aspect comes
from but HTTP sits on top of transport
layer if the internet in fact has five
layers it doesn't have seven layers so
we have the physical we have linked
network transporter and application and
application still sits on top of that
layer which is called transport which
everything is on and that is TCP okay
now TCP is a great protocol what other
protocol do we have on the transport
layer UDP we don't use it much for HTTP
well to not say at all we use TCP and
TCP has issues right but will do tcp has
issues as well here's a simple echo
server so this is basically me going to
serve our typing hello and getting hello
back right look at all that so to begin
with like you know the actual packet of
hello is like one of these over here
which is the AG push back push push
there that's it ok and yet we'll have
all of this for every TCP connection and
what is that to begin with TCP has
what's called the three-way handshake
right so every time a new TCP connection
opens I have to throw and do a three
here a handshake how many of your Dutch
ok so in Holland as opposed to Spain you
give three kisses right am i right yeah
it's kind of like Dutch kisses right so
two kisses I can sway you give
so the client says acknowledge the
server says sync acknowledge then the
client says acknowledge back for every
single connection and guess what when it
closes it also does a three-way goodbye
ok so this already starts to a delay so
now every time I open a TCP connection
I'm getting like ninety five
milliseconds here before I can actually
start to transfer any data right and
imagine each of these are per connection
TCP is a great protocol why because it
offers us reliability it offers us flow
control but these also bring their own
issues the three-way handshake is
because of reliability it's to guarantee
that each side is receiving the other
side and then start to process packets
with sequence numbers what it also does
is provide this up aspect of flow
control now flow control is basically
when I have two machines I say I have a
machine here and I have a machine here
how many bytes can we transfer and the
machine says okay you know what I can
handle 100 bytes per second okay I can
process that much send me 100 bytes per
second so we establish that and
everything goes great okay the problem
is that we have two machines which is
great problem is that now we have the
internet and in between the internet we
have hundreds of different machines we
have proxies we have routers we have
gateways we have all of these different
devices and all of these add their own
delays all of these add their own issues
so if we were to just say i'm going to
send a packet from New York to frankfurt
with a hundred bites somewhere along the
line some router some device can get
congested if it gets congested what it
does is discard the packets how do I
know what they are the perfect size of
bytes are should i start with 10 or
should i start with 200 we don't know
and that's why I TCP has this thing
called slow start slow slow start which
basically means I start with small
amounts of bytes and gradually as I see
that things are going well I start to
increase so that's the interchange data
and then I send a reset window and the
window is the actual number of packets
that go okay so this also means that TC
p in order to deal with the congestion
of the overall network and in order to
deal with reliability and not having to
discard so many packages every
connection again starts very slowly and
as the connection progresses it starts
to speed up but that also has an impact
on our web application now back in
nineteen ninety one tcp 0.9 started and
it was really really easy can someone
tell me what's missing there apart from
syntax highlighting we shouldn't exist
back then either headers HTTP 0.9 didn't
have any headers right you just said
index.html and it gave back his chin
that's it was so simple life was great
and then came 1996 and tcp 1 point 0
came out and they added headers and they
said user agent Netscape accept text /
HTML so they started to descend some
more headers and this started to
increase of course the packet size then
in 1991 they came out with HTTP 1.1 and
they added something very important
which was called connection and in fact
connection by default in 1.1 is keep
alive which basically means keep the tcp
connection alive because up until 1.1
every time you wanted to get a resource
whether it was an image index.html
whatever it will open up the TCP
connection get the data close the
connection TCP 1.1 introduced keep alive
they back for today to work with 1.0 and
by default if you wanted to it was open
if you wanted to explicitly close a
connection you would issue a header
connection closed now when this came
along it opened up new possibilities
right because we could start to optimize
and what we did we started to do a
single connection instead of opening up
multiple connection we would do a single
connection and then the server would
just use HTTP / single connection and
not have that three-way handshake to
start not have that three-way handshake
too close although flow control still
plays the game because the resources
that are coming in varies so I was
working more or less okay and then
someone said you know what let's try and
improve on this and they put in this
other thing called pipelining right so
basically now
they wanted to do is instead of sending
requests index getting it back CSS
getting it back javascript getting it
back they're saying index CSS JavaScript
go to the service over pushes it all
back how many of you have used
pipelining right and it's hardly used
nowadays because of all the issues it
caused and one of the issues the reasons
for this is because of what's called
head of line blocking in TCP which
effectively means for TCP to be a
reliable protocol it needs to block
everything that's coming off needs to
treat every request as part of a queue
right so the first in first out because
otherwise it's going to confuse things
and whatever you do you always suffer
from the head of line blocking
pipelining was it was a feature that a
few browser started to incorporate it
caused a lot of problems with proxies
etc and now most of the people are not
using it anymore but what we did do is
say ok now we've got single connection
that's great get rid of the three-way
handshake why don't we open up multiple
connections and do parallel processing
so we started to use multiple
connections right and now we could open
up like a whole bunch of connections and
then what happened this is the the
browser then the server said wait a
minute you I'm dying here because every
connection that you open also has an
impact on the server and on the client
every TCP connection is a resource right
and you're going to draw my server and
your clients aren't going to respond
well so most browsers limited it to six
connections in fact if you use browsers
nowadays you go when you download
software from a single site you'll see
that the seven connection probably won't
start until one of the previous ones
finish okay now what are we come on yeah
we're people okay
I saw Ted 2 on the way over he was a
person as well what are we with
developers right what do we do as
developers we change the world no we
hack so what we did we introduced this
thing called domain sharding we said
fine you want to limit connections to
six will create aliases and open up more
connections yeah if there's a way to
break it will find it and of course this
led to another thing which was called
more dns lookups and we still had the
overhead of creating all these sockets
on the client and the server but domain
sharding is basically used nowadays
other techniques that cut started to
come in were like for example in line
resourcing so in HTML when i when i get
a an image i link to the image and then
it goes to the server gets the request
sends it back how many of you use in
lining in lining is technique basically
where I take the image I base64 encoded
and send it back as part of the HTML
awesome one less connection not so
awesome base64 which is great for
encryption and now gone on the record
saying that yeah that was a joke it's
great for encoding in binary binary in
base in in text format but it adds
overhead right and the other issue that
has is that you cannot use caches with
it because how can I now change that I
mean like if the image hasn't changed i
still have to send it as part of the
page if the page changes what we also
did was to other beautiful techniques
which are called concatenating and
spriting resources now concatenating
basically consists of instead of sending
back 15 different JavaScript files or 15
different CSS files we use really
wonderful build tools such as grunt and
gulp and please note my sarcasm there
that basically take all of those
different files bundle them into a
single one and send them back right
fantastic except what problem do we now
encounter caching right if I change a
single thing in JavaScript and single
one of those files the whole thing is
going to be on
cash I have to invalidate it and send it
back and the other issue is delay in
processing because if I send back three
CSS files the browser can start to
process that if the browser has to wait
for the entire large CSS file to be sent
back it can't process that anymore the
other technique is called spriting which
basically translates into in the old
days we used to have an image and we
used to send that image and if we wanted
to change the image who would just
change the image that's it nowadays we
take 600 images and we put them in a
little like table as a single image and
then we spend about six hours with CSS
trying to position those images and
that's what spriting is right and it's a
very great optimization technique that
web developers worldwide should use okay
just making our life more difficult the
problem of course is that it's not HTTP
that's the problem the problem is TCP
right TCP 1.1 is not made for chatty
protocols and HTTP is a chatty protocol
TCP is made for long connections that
adjust the flow and then just start
getting data back and forth right it is
not made for chatty protocols TCP also
has slow start and head of line blocking
these are two major issues that cause
problems and that is why we give way to
http too so HTTP to really is about
trying to solve the problems with TCP
more than trying to solve the problems
with HTTP the problem is we can't just
rip out TCP and say you know what as of
tomorrow we're going to change protocols
we're going to use something better and
TCP is going there are actually efforts
in trying to do that but right now
they're not which essentially means that
Oh before I tell you well now it's about
performance right it's about performance
tcht db2 really is about performance now
can anybody tell me why it's HTTP to and
not HTTP to point out who said what
it's shorter and apparently 2 point 0 is
too confusing well you know versioning
we can't get it right I mean just look
at Java I came from dotnet and I'm like
so what's java 6 it's 1.61 Java 71.7
what is this JDK done and then one
anyway although donÃ­t they have their
own versioning issue or they have a lot
of issues anyway in a few words HTTP two
is binary right which basically means
that if any of you love opening up
telnet and talking to an HTTP server I
like doing that I have a lot of free
time you can't do that anymore it's over
no you get ppppp little bit like this
spot back at you right kind of like
downloading binary orbit ailment it
provides compression optimization
techniques and we'll see why this is
useful very important it does not change
the semantics of HTTP because it's now
trying to address http issues it's
trying to address the TCP issues so all
of the get put post delete all of these
are still valid right it's not
compatible with HTTP 1.8 speak up but it
can be used on top of HTTP 11 point X
it's not compatible obviously because
one point x is binary sorry it's text
and two is binary so the next question
is is it speedy how many of you have
heard of speedy how many of you use
speedy like everybody should put up
their hand now everyone so no it is not
speedy but it is effectively speedy it's
in that is based on speeded when the
call for papers came in they looked at
speedy and they said speedy is pretty
good that's your speedy as the kind of
black building block for HTTP two in one
slide this is what it looks like it
takes text it maps it to binary and then
it has these sinkholes frames and then
inside the frames well there is called
connections and then streams and then
inside the strains it's got these hello
friends it's called data friends and
it's got a whole bunch of frames right
so it's taking get and it's mapping the
get the request to the head of frame
request and I had
frame request the response to a head of
frame response and I had a data.frame
response and the header corresponds to
HTTP header and the data corresponds to
the data to the body now the question
that might be coming is how can I take a
binary protocol and make that work on a
text protocol how does that work so
there's two ways one of them is called
the h2c upgrade which basically means
using on text and what happens is that a
client makes a request and sends a
header that's called upgrade h2c and it
sends a HTTP to specific header which is
HTTP to settings for once we've learned
how to name things properly and then the
server responds with a 101 who knows
what I want to run it no I want the
exact text I love my status code so you
know I have a talk that is one hour just
about status code it's awesome it means
switching protocols so switching
particles and then it says connection
upgrade if it cannot it just sends back
at HTTP 20 of 200 or whatever and says I
cannot upgrade now everyone understand
is good you're never going to use it the
way that you use it is effectively with
TLS now tell me how can I put binary
over the wire on a text protocol TLS
right no not base64 encoding TLS what
are we doing right now with ssl we're
creating a point-to-point tunnel and
sending data effectively HTTP works on
TLS there should be two works on TLS so
by default everything is SSL now I
worked on TLS with some addition that
extension that's been made called a LPN
which stands for I'll give you a hint
what HTTP it's at one layer application
layer what's the p for protocol i'm just
trying to make sure you're not sleeping
and the n is there you go application
level protocol negotiation if there's
nothing else you can pick up today pick
up that and say i learned about a LPN
extensions
it was also so what happens is that TLS
has this extension point which allows
you to upgrade to a different protocol
now this is now built for HTTP too but
this also means that HTTP three four
five six I probably won't be around by
six we'll use this and a TLS comes in
after the three-way handshake there's a
TLS handshake and then from there on
HTTP two comes in okay now a single
connection that's one important thing
HTTP to basically uses a single
connection and the connection has
multiple streams right and then each
stream has frames and I have a request
message that maps to a head of frame and
a data frame and a response that again
we saw maps to a head of frame data
frame and then I can have all of these
multiple streams if we drill down into
the frame it's very simple it's a binary
protocol so it has a length it has a
type of frame flags the actual data and
then it has this important thing here
which is called ID right and this is
important because the ID now allows us
to do something which is multiplexing
which we'll see what type of frames do
we have we have data header window
update which will see all of these will
see settings priority reset stream push
promise pain go away which basically
means just go away really literally it
means go away now what does a header
what doesn't actually interchange look
like so you can see this is Wireshark
anyone use a bar shark okay by the way
if you're using mac OS x and you don't
want to install the whole courts and the
whole ex platform why short 1.99 which
is in development works great and it no
longer requires that it's not native to
OS X okay and it even looks better but
again anything over X looks better so
you can see that I have hyper text read
text to http t HTTP and then I have HTTP
i have this version 2 and then you can
see that i have the head of frame well
at the back you can see but trust me you
do see i have the head of frame and then
after that i have the actual data stream
that is going back and forth if you look
over here i can say uncompressed entity
body and you can basically come
wireshark with the whole ssl certificate
in order to be able to see this in
action so telnet goes away Wireshark now
becomes your new best friend okay now
because it has a data an ID it allows
proper multiplexing right so you can
actually interleave different requests
and responses and then I can have
requests coming responses coming and
then the client and server sort these
out and define which corresponds to one
so essentially i'm getting rid of that
head of line blocking that I had with
HTTP one each frame has this unique
identifier so it brings in the
reliability right so if you start to
notice a little bit what we're doing is
we're trying to bring the TCP stuff up
to the HTTP stuff right it eliminates
the head of line blocking and it
basically allows for you know a single
connection to have parallel processing
another thing that it does it works on
it has made some changes on headers
right so here are two requests from the
same site two headers and what we're
going to do here i'm going to give you
around 10 minutes and we're going to
play spot the difference okay there
isn't much there's like five or six
characters that are different okay a
little bit more but you can see that the
actual image is different that's 32 this
is 128 and then i have the max age is
the same keep alive the same the date is
different that etag is different but
pretty much everything is the same right
how many of you know what etag is okay
this is actually important because this
is why the header compression is good so
in the HTTP one we have this thing
called wall no in HTTP we have caching
right and caching normally is based on a
max age I say a page comes in and after
X amount of time you invalidate it and
go and request it again that works great
for things that you can base on time
problem is what if you want to base
something on changes let's say I have a
customer record that is
two megabytes and I don't want to send
back that customer record if there's
been no changes so what you can do is
you can use what's called the e-tag
header which basically creates a hash
check some of that entity sends it back
then the browser when it makes a new
request says if not modified and sends
that checksum and if it hasn't been
modified then the server just sends back
a 302 not modified if it has been
modified it sends back the thing that is
normally called the conditional get and
conditional gets are great because they
allow you to not use that bandwidth of
constant constantly sending back the
same request over and over again the
same entity when it hasn't changed the
problem with conditional get is that of
course you get all of these headers so
point being HTTP one wastes a lot of
space with headers it's inefficiently
sending back all of this information
constantly over and over again so what
two ads is header compression and it
uses this algorithm called H pack which
is so complex that it's got its own RFC
good news for you on me and everyone is
that unless you're implementing H pack
you don't need to know anything about it
it uses Huffman coding for encoding and
then but this is important is that it
actually maintains state between the two
entities so effectively it's just
sending back and forth Delta's of what
has changed right in addition to the
Delta with all of the binary compression
it makes it more efficient initially
they use Zed lid and then there was a
hack recent in that thing 2012 which was
called crime don't ask me what it stands
for but the hack was crime that
basically allowed man-in-the-middle
injection for uh HTTP headers so they
invented a new one called H pack now
streams need priorities right what HTTP
allows you to do is since I have a
single connection but this single
connection are going to have multiple
streams and these streams can be
interleaved i can define priorities on
streams so i can say for instance my
images have lower priority than my CSS
and my CSS has higher prior
my JavaScript and it's giving us this
ability to do it we can set priorities
in the head of fields and say define the
priority of these resources now each
stream has a weight and a dependency
because obviously if I have a some
stream that has a priority and that
stream in turn depends on another stream
it's going to impact that other streams
priority and then there's there's an
algorithm to calculate the weight
distribution based on the number of
dependency graphs etc so basically what
what the HTTP is doing is giving us more
ways to screw things up right because
now we can start to play with all of the
different priorities as streams have so
you can see again I'm going back to the
whole it's it's kind of like raising the
you know taking us a little bit lower
down it also has flow control remember
that reset wind window update frame
that's for flow control I can now define
the flow of each stream I can say a
stream that is getting me like data back
like video streaming can have a very
high window a a stream that is giving me
back small chunks of data can have a low
window so I don't waste any amounts of
information so i now am in control also
of flow control ok one other thing that
it adds is server push so usually I make
a request I say index open HTML server
goes and says index HTML ok then the
client says stalled or CSS services
stalled on CSS then the client says
script is so ever sends it back what you
can now do is serve a push which
basically means i send index HTML to the
server and the services oh I know this
you're going now going to ask for stall
and you're going to ask for script I'll
push it back to you right so the server
is now initiating the push back to the
client and the client then has the
choice of discarding that or keeping it
okay but the important aspect here is
that now the server can initiate and
like prefetch things in a sense for the
server for the client and thus avoid the
client
to make an additional request for that
now the server push basically is
replacing inlining of resources so
really effectively it's kind of doing
the same thing except now you have more
control because you don't have the
base64 overhead of the encoding and you
also don't have the disadvantage of
losing all of the caching and then the
server basically is responding with this
push promise and then sending a number
of streams back and as I said it allows
for caching and the client can cancel it
what about security so by default HTTP
to specifications doesn't require
security so you don't have to use
encryption however the majority of the
browsers have said that we're not going
to implement HTTP to without the
requirement for TLS so effectively
everything is pretty much going to be
secure and there was a recent website
which was what is it called Emily anyone
know it came out a couple of days ago
let's get trusted have you heard of that
let's get trusted orb or something which
is let's get start or which is now free
certificates for everyone so Oprah
somewhere is saying you're going to get
certificates I'm gonna get certificates
we're all gonna get certificates I
should have put an image of that there
yeah okay so what is the current status
the RFC is 7540 the RFC of each pack is
75 for one if you are very bored you can
sit and read it as I said it doesn't add
much semantics but in terms of
implementation details it's great what
is the actual current status this is a
website called can I use have you used
it what you can use it and if you go to
can I use and you enter HTTP to it shows
you the actual browsers that are
supported right and I'll show you some
that are not if you actually go to this
website and type speedy you'll see that
a lot of browsers are no longer
supporting speedy all right so edge
which is the new browser by Microsoft no
longer supports speedy google has
officially said that in 2016
going to decorate a deprecated speedy
right so the world has moved to http to
the question is are you ready no mind
okay how many of you you how many of you
are using HTTP to now right how many of
you are using Twitter from the website
so you're probably using HTTP to okay
twitter is already using HTTP to see
you're using things you don't even know
it and now you can go and charge for it
awesome so service support h2o Akamai
edge Apache jetty will wildly Oh Arun is
going to kill me for that well no not
anymore he's a couch race it's wild fry
yes that was our own slapping me um
ingenix virtual stuff and then I is in
Windows 10 and Server 2016 now if you're
using jetty and stuff and I'll show you
a demo you do need these LP extensions
for java 7 and 8 in java 9 there will be
part of the JRE okay but right now you
do need these LP extensions clients are
library support jetty Nettie curl ok
HTTP all of these already in Java world
you guys are awesome I mean you're set
you you've got support and Donette well
there isn't that much support all of
these are using it in terms of tooling
curl already supports it chrome tools
wireshark webpagetest all of these
support it and now comes the big demo ok
i'm going to show you HTTP to in action
and the great thing about this is that
every time i do it is it kind of
basically goes bad so HTTP to tamiya you
go here and you say let's make that full
and then you say click here for demo
okay and you can see that the latency on
the left is eight milliseconds low time
is one point 83 on the seven on the
right at seven milliseconds zero point
82 now the importance of this test is
that basically what this is doing is
trying to replicate the normal behavior
that you have in a normal pet page which
is getting a whole bunch of different
resources from different locations etc
that's what is trying to replicate so
these are like thousands of little
images okay normally when i run this
HTTP one gives me like you know load
time are 5 55 seconds and HTTP two gives
me something like 30 35 40 seconds and
and that point you're kind of like yeah
everything I said is just wrong just
let's let's just pretend we can just
move on with life okay the other demo is
very similar it just loads an image and
you can go to http to demo i oh now the
important question how does this affect
me as an application developer the good
news is that it doesn't the bad news is
that you've just wasted 40 minutes it's
mostly transparent mostly right now
emphasis on the most and the lead web
apps web apps go through a process of D
optimization so in essence everything
we've been doing we now undo right the
saying that said premature optimization
is the root of all evil they were right
multiple TCP connections you don't need
anymore so get rid of that get rid of
domain sharding get rid of concatenation
and spriting get rid of inlining right
so all of that can have essentially kind
of go away because a lot of that is now
handled for you in HTTP two and doing
this can actually harm more than help in
terms of AP is so HTTP is still the
underlying protocol so the semantics
doesn't change if I'm doing server side
of client-side API I am still doing get
post delete head options all of these
remain the same the only thing that's
added is summation
p to settings some HTT to specific
headers etc but when I'm talking about
for example creating api's we no longer
have to worry about what called chatty
ap is right so a lot of times and this
is kind of wrong wrongly founded but
whatever there are there is this some
concern that if I create for instance an
API that does a bunch of different
things every time if it's chatty so
let's say I have to do some kind of I
don't know order purchase an order and I
distribute this into entities and then I
go back and forth and doing all of this
that you no longer have to worry because
it's basically just now much more
efficient however you really shouldn't
be doing that anyway because it's that
really has to be encapsulated on the
server side as part of the transaction
anyway right so you should add a layer
of abstraction on that from the client
call but in essence you don't have to be
concerned really about chatty api's
because HTTP two is try to address this
aspect of chai VAP is in terms of
library api's so how do I deal with that
how do I call an HTTP to server from a
client how do i do I need to know any of
these things that we know we've been
speaking about not really unless you're
diving down into implementation details
unless you want to do things like
prioritization zand frames flow control
support all of these things you really
that again is mostly transparent to you
so you can basically use things like ok
HTTP for clients and client-side code or
Nettie how many of you use Nettie right
Nettie is great at being low level and
with HTTP two it's still very low level
ok so i can show you that for example
here let me open up IntelliJ
so here you can see that i have i have
basically a an ok she TB to clients and
i'm making a request and i'm using the
builder and i pass in the request wakame
and I built the request object and then
I call the request object and there's
really nothing there that is saying HTTP
to the only thing there is I'm passing a
aplng extensions as part of the boot
class path to the to the to Java so I
can right click this and hit Ron and you
can see that if it runs and everything
works I get back HTTP too if you remove
that boot class path you'll see that it
says you're not using HTTP to if it
actually works
so this is the page that you sore and if
you scroll to the top you can see that
it says somewhere it says HTTP to you
see it there HTTP two is the future of
the web and it is already here awesome I
could have just finished my session with
this but now okay now like everything
it's not all roses because effectively
if you think about it it's adding
transport level complexity to
application level right so we are now
adding priorities we're adding flow
control and if you look at what we've
been doing up to now which is hacking
our way around HTTP 1.1 limitations
because of TCP so concatenating sprites
sorry spriting concatenating scripts
domain sharding all of these have been
to over try to overcome the limitations
imposed by TCP HTTP two says you know
all of that you don't need that anymore
we've solved the problem for you but in
addition we've opened up a whole new
world of possibilities in which you need
to figure out what you need to use
priorities and you need to use flow
control what if you need to use them you
need to figure out how to use them you
need to use push how do we know how push
really works you know the problem is
that not everything is being overly
tested right and how many of you have
used HTTP to hardly anyone put up their
hand how many of you use speedy probably
no one everyone has used speedy the
difference is that speedy has been
mostly transparent right sweetie has
been under the covers and we've just
known the speediest some thingy that
makes everything go faster right HTTP to
know that's that's this this wonderful
new thing that's opened for us and like
developers what we can do is find ways
to screw things up right and we probably
will the point being that this hasn't
been tested to the level in the world as
many other things have right speed
the performance optimization protocol
has HTTP on top of that has however
possibilities of priorities flow control
push how will this really work we don't
know you we're going to start to play
with it tested and figure out how that
will work so more information starting
point the best places github com go to
HTTP two and i really recommend this
book by edr gregorich how many of you
have read this very good book which is
called high-performance browser
networking if you want to know more
about all of this at low level as well
there is the application layered tcp i
park on run but 6th edition which is
also good but let me now show switch
over and show you a couple of demos of
how to get started with some things so
let's set that back to okay so
what you need to do is if you are using
a wire shark if you're using wireshark
what you have to do is basically
configure Wireshark show that it works
with ssl right and if you load Wireshark
this is the new version that I've been
talking about so there is a setting
which is on the protocols SSL and
there's a setting here which is called
the key log file so effectively for guar
shark to to work with HTTP two and ssl
you have to point it to a key log file
which is the same key log file that your
browser is going to be exporting right
so what this means is that on the
command line you have to write a
sentence such as export ssl key log file
to a specific location and then you can
say open firefox for instance and then i
will close this down normally there is
an issue with Mac so I normally run
everything under the same terminal
instance under the same show because if
you run the export log and then open up
in a different context and things don't
work every time i open firefox dashlane
wants to do something and then we'd load
Wireshark and now this in principle
should work I can come here and say
Wi-Fi I want to capture and then we can
go up here and we can filter the
protocol to http to write and then let's
go here and do HTTP to demo and you can
see that if i run the HTTP to test i get
HTTP two and we should have some HTTP
requests coming in this is filtering
it's out there go then
where's mine she did he do
and why should it be to come
so
anyway it work it's fine trust me the
fact that I have captured a screenshot
with this proves that it does work no
there is there ism there is this I don't
know if it's war shark or not because
sometimes it does act weirdly because it
is running a beta development version
okay so yeah so that's it oh and with
that I think we're more or less yes done
any questions yes go ahead pardon is
there any talk about using s TTP what do
you mean is ever in any talk about it
I think that some of the work that
they're doing in regard of replacing tcp
might be in line with that I believe
yeah
sorry can you speak under what you need
to include a LPN extensions right so
it's basically a package a jar that you
download that has the new ALP extension
so that HTTP two can work on it by
injecting the switching protocols yeah
but Java it doesn't have that your job
and I'm will have that yeah if it
supports HTTP two in principle it should
be working in the same way yeah so
there's going to be issues in that sense
here okay well everyone's leaving so
we're done I'm going to be at the
Japanese booth if you do have any other
questions feel free yeah</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>