<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Java Performance Is a Social Activity | Coder Coacher - Coaching Coders</title><meta content="Java Performance Is a Social Activity - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Java Performance Is a Social Activity</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vLAwcZSyPCs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so my first day is job performance is a
social activity or is it because other
was writing this talk I realized that
there was sort of like the force it had
a a good side and a dark side so my
title is either job performance is a
social activity or java performances an
antisocial activity and you'll see why
that that duality and that dichotomy
exists in a couple of slides time so
let's talk about the problem what is the
problem with Java performance never
performant enough that's actually that's
very interesting because it actually
placed within that I'm going to talk
about later which is to do with non
functional requirements and and the idea
that if you start getting into a
performance exercise without a clear
exit strategy and what your what your
goals are you end up in a bad place but
we will talk about that in the inner
about 10 slides time what else have we
got so we've had never performant enough
what else is the problem hmm little
little focus yeah sure what else anybody
gonna be brave yeah well there's a
problem is up there it's hard to find
out what's causing it sure that little
bit yep when it's from it's already way
too late and it's in production yes also
very very good yes I don't find the
wrong problem yet we'll talk about that
a lot as well maybe subjective sure one
more button yep okay so there's one
there's a whole different set of views
about what Java performance problems
really are and I think there's one big
one that we've we've missed out here and
it's this one its people as they were
ever heard this quote before no matter
what they tell you it's always a people
problem yeah so this comes from I think
it's actually in Weinberg's book the
psychology of computer programming which
it's like it's like the mythical man
month that's one of these books that
comes from the dawn of time but the fact
that the prolonged books that were
written in
the 60s and the 70s are still applicable
today tells us that it's not the
industry and it's not the computers and
it's not the silicon that's the problem
in create a lot of the time it's
actually the people foot of the problem
java does have some specific
characteristics to a point here which
make it harder to debug into performance
tune than other sorts of languages but
fundamentally one of the biggest
problems of performance that Java has
are the people and the social aspects
okay so that's what we're good but my
view is loosely talked about Java
performance and as you'll see that's
actually not a very useful or good thing
to to do so what is java performance
anyway I mean how can we how can we work
with this thing if we don't really know
what it what it is that we're we're
talking about what anyone like to give
me a definition of what they think Java
performances meeting requirements but
okay so some sort of wiggle permits but
yeah okay anybody else too slow response
okay what else anyway I will not wonder
how to take a take a stab
work is so not not mean expect a time
interval for a given unit of work okay
that's that's pretty good that's
actually getting closer to the sort of
thing that I had in mind that the
definition I I tend to use most often is
probably this one the Java performance
is a measurement driven approach to
understanding application behavior under
load okay now there's one critical part
of this I'm going to draw your attention
to and it's this expression measurement
driven okay if we're not measuring if
we're not doing this with data you know
we're not doing performance you know
performances but as well see is not
fiddling about in algorithms because you
think you can make them faster it's
about data it's about statistics and
that immediately sets us up for our
first clash our first place where people
and data run headlong into each other
because humans are often not good at
being methodical and gathering data and
dealing with it in the in the way that
it needs to so this this sort of
interplay between the need to have
people analyze your systems and the need
to have reasoned conclusions with data
is a is it is kind of where our
battleground where our lines are going
to be drawn it's a huge topic we've only
got an hour so let's try to choose our
Latin ground but before we do that
there's one other picture that I want to
have you term in the back of your minds
there's a sort of scene setting thing
while we while we talk about this and
it's this process of how we actually
learn okay so when we're when we're
studying any topic first thing we do is
we pattern match we start to recognize
you know how where the patterns are and
what the groupings are and then we start
to understand what they mean we learn
what those patterns are for we start to
apply them and then somewhere between
this level and this level something
interesting happens which is we move
from applying patterns and forms that we
know about into actually analyzing the
forms themselves that's the link between
doing something which is pretty
mechanical and pretty
straightforward just applying something
you know inside context within which you
already understand it versus to
analyzing the forms and starting to move
to to actually really being able to to
evaluate one form over another and at
the top of the pyramid as you as you as
you rise through the ranks of this of
this simple conceptual model it's only
at the very top that you actually get
into to starting to create now the
problem that we have is that Java
performance is very much higher level
activity it's the level up here to do
with with analyzing evaluation and even
creating the hardest thing of all to do
a job performance sister is to create
for reasons which I'll I will become
clear over the course of the
presentation this is sometimes called
Bloom's taxonomy if you want to read up
on the theory of how this works but it's
it's quite a general model for thinking
about how we learn it's particularly I
think particularly plick able to to
programming into computer science okay
so with that model in the back of our
head let's talk about two of the
recurring themes are going to come up
again and again throughout the rest of
the presentation and they're these we
have two big recurring themes we have
want to do a distinction between an
outage which is a total loss of service
to customers and a performance problem
which is essentially a degraded
experience to customers but not
something which is Carol II completely
unavailable often algae's are caused by
a change to the prod environment be that
a code change or a configuration change
you know infrastructure changes as well
and but there are examples of
post-release outages sometimes you get
an outage which is a slow burn you
actually got a performance degradation
and performance regression in a release
you've made but until the load reaches a
certain level that that that regression
is not serious enough to actually cause
a genuine outage performance problem on
the other hand you can actually actually
work with so to give you to give you an
example of this this latter one and
sometimes these come about because you
you actually have a change in the nature
of your customer base I used to work
many years ago I was a chief architect
for a online gaming site which in in
England is our polite euphemism for
saying gambling
and with our customer lacework were
predominantly football and horse racing
vets and in Britain people just place
one bet you know the team either wins or
loses dust the type of vetting you do so
the performance profile that we had for
our customers was very linear you know
most customers you know they face a few
bets but we understood exactly how long
it was going to take to settle up and
get the money to customers at the end of
saturday when the horse races have
finished and when the football games are
done when we started to move into a
larger market the Turkish and German
markets we discovered that actually
people in those countries bet completely
differently we found this out the hard
way because the site started crawling to
a halt not quite an outage but massive
degradation every Saturday and it took
us two weeks basically just to even
understand what was going on but the
pattern of betting was completely
different instead of having these these
simple individual bets Turkish and
general customers would have these
incredibly complicated multi accumulator
and multisub accumulated debts for
people that know that about gambling
that the sort of the large Goliath sand
and these very very complicated things
so the settlement pattern and the
settlement process was completely
different far more complicated far more
CPU intensive so we were we were
struggling to to evolve our system to
cope with a completely different style
of behavior from our customers which has
been caused by a cut over into it into a
new market so that's why I want to draw
a distinction between these two because
it wasn't that the site was completely
unavailable we're still taking bets
we're still making money and customers
were still getting paid at the end of
the day but the process and the problems
that we were having were in some senses
as bad as an outage so well this is a
useful taxonomy I think it's so
important to remember that just because
the site's not completely fallen over
doesn't mean you don't have problems
okay so with that distinction in mind
let's think about what we're trying to
do from this why we why we in the
performance game in the first place what
what is it all about well it's really
about four things it should be about
risk reduction so you have operational
risk which is basically the risks of
your operation is either going to be
severely degraded or actually wiped out
there's also the the delivery risk
you're not going to deliver service to
customers there's also one of these
which which I sort of amun-ra backwards
and forwards about whether or no
I'm going to put it on the slides
there's actually a third type of Risk
Reduction here which is reputational
risk the damage to your your your
company's image into your to your brand
if your site is unavailable or badly
degraded because of because of
performance problems sometimes this
matters and sometimes it doesn't to give
you an example if you are in a bank and
you are taking orders from from from
customers they probably have half a
dozen brokerage accounts with half a
dozen different banks if you are
unavailable for a few seconds they're
just going to switch over to your
competitors and then all going to care
and they'll probably trade with them for
months until until they start having
problems okay so in that kind of
scenario the reliability and then and
the risk is it's purely operational and
delivery you know it's going to impact
your bottom line but it's not really
reputational other systems yo you are
gambling with your with your brand and
there are even systems and examples of
systems we're actually performance
problems don't hurt you anyone think of
a good example for that yeah concert
tickets so if you're running a site
which is selling tickets you know some
incredibly popular event like I don't
know glastonbury festival or I guess
burning man in the u.s. here there are
only so many tickets they were scarce
good your customers can't get them from
anywhere else so does it matter if they
have a terrible experience yeah if they
get bored and go away you're still going
to sell out so somebody else is still
going to come and buy that ticket so
that's an example of where you actually
have you know neither operational nor
delivery nor reputational risk
associated with a performance problem so
one of the things I'm trying to I'm
trying to get out here is is that you
need to understand your business you
need to understand what areas and what
would that you have risks in and have
exposure which bad performance can hurt
you by yeah
performance testing yeah what fools
people use are you used for performance
regression question was about about
performance regression and performance
testing tools so I think this is this is
one area where a lot of teams and a lot
of companies don't do enough automated
performance regression testing and there
are all sorts of reasons for this it's
it's difficult to get right it's there
are some cases where I'm going to talk
about a few slides time which indicate
wise difficult to get right but i'm not
sure that i think that there's an excuse
for it i think i think people should be
doing automated tests there are things
like apache jmeter j meters are kind of
a strange one because there are two
tools there's an Apache 18 HP one the HP
one's kind of a okayish GC visualizer
but the the Apache one is is a load
testing tool there's a company called
blaze meter I think you do who do some
some open source cloud based stuff for
testing as well but yeah I mean the
answer is is there are no royal roads in
performance testing you actually just
have to put the dog work in you actually
have to write the user scripts and write
the stories right the scenarios and
actually get it into at all and then you
have to keep it up to date because as we
were just talking about in the example
of the gambling site we you know if the
nature of your customer base changes and
your performance testing doesn't reflect
that you have a problem we'll talk some
more up for messing in a bit okay so so
apart from this production what else we
want well we want reliability basically
outages costs money they cost money in
terms of in terms of cleanup they cost
money in terms of loss customers so the
more reliable you are the fear outages
you're going to have but you can also
potentially increased maintainability
with a decent set of performance testing
I mean I think the example is is twitter
so i don't know if people know this but
but twitter moved about four years ago
from being a primarily ruby-on-rails
shop and they basically got rid of all
of their Ruby on Rails that they only
have like a tiny tiny amount of Ruby
left now everything is switched over to
the JVM everything is a scholar and
Clojure and Java now and what they found
was that not only you know were they
able to meet these
much better performance metrics now but
they were able to do so reliably so you
know when was the last time anybody saw
the fail whale who remembers farewell
yeah I kind of missed the farewell but
and we haven't seen it for a while okay
and that's because the main the
reliability is much better but the
maintainability it has also improved and
in fact to have been able to reduce
their footprint the estate the number of
machines that they need to run their
operations despite the amount of growth
they've had day using ten times fewer
machines than they were four years ago
right and if you think about the growth
in the platform in that time that's
that's incredible so performance testing
can actually save you money if you do if
you do good performance stuff and you
can actually shrink the size you up on
well you know that just think about that
I mean that there's the cost of the
service that's the raw metal or you know
a big chunk of ec2 or however you're
going to deploy that but you also have
the additional knock on costs you may
not need as large of support team you
may be able to redeploy your engineer
somewhere else you may you know how a
different management structure pith is
now you don't need five managers for all
sport teams because a smaller group are
able to take care of the machines is
effectively ideally and this is the holy
grail of performance work is to have a
quantifiable impact okay if you can
quantify how much you've saved hands up
if you if you at your company you could
sort of either you or somebody else in
the firm would know how much an outage
had cost you yeah a few people that's
one thing which you know is is is an
area where I think developers and
engineers can make it a huge impact is
by encouraging the building of systems
which can answer that question because
if you go to a manager and say you know
boss if we were if we put these these
bits of logging in here we do these
types of analysis we can quantify how
much now teaches costing us you will be
surprised what they cost they are
incredibly expensive and the more
enterprises and more organizations which
which actually do quantify how much
they're losing in outages that that's a
great spur to improve reliability and to
improve performance and systems okay so
let's look at a few problem cases
everyone everyone lights war stories
everyone likes anti-patterns right so
these are kind of probably my top seven
seven deadly sins of production and
these are the kind of problems that tend
to crop up again and again in in modern
production environments there's a blog
post and if anyone's read this called
something like why developers keep
making bad technology choices if you
google for that phrase you'll probably
you'll probably find the the blog post
and in it they identify problems and
cognitive biases that developers have
which lead them to make incorrect
choices about technology and it's those
those cognitive biases which I I was
really thinking about when I started to
write us talk so it's it's the things
that are our minds do that play tricks
on us to get us to make incorrect
decisions and to be less than rational
even when we're kind of fooling
ourselves that we are being rational so
start with the first one uat is my
desktop you know how many times have you
have you seen an environment where that
there is no real uat environment there's
just a bunch of boxes under somebody's
desk who's got a uat environment like
that come on we're among friends here
it's it's like Alcoholics Anonymous you
can yeah my name is Ben and I've got
I've got an absolutely dreadful you 88
environment consists of a couple of
desktops okay okay well hopefully the
reverse is going to be true and if I say
who has got an environment in uat that
looks exactly like production okay and
who's somewhere in the middle where it's
kind of a bit that but yeah pretty much
everybody else okay so as is normal for
these kind of anti-patterns first we've
named it EIT is my desktop here is the
description of the problem the IT
environment differs significantly fraud
and here is a sample quote the sort of
thing you will hear if you suffer from
this anti-pattern full-size UOIT
environment would be too expensive who's
heard that from a manager at some point
in their career yeah basically about
half the rope perfect so the reality of
the situation is this this one only
really ever crops up if you're not
tracking what outages and lost customers
cost you
ok I guarantee I have never ever seen an
environment in which outages and loss
customers were tracked where you people
complained about the cost of hardware
the outages caused by environments are
almost always more expensive than a few
more boxes yeah once you've worked out
that buying a full-size 02 environment
is paid for as soon as you've had your
second outage that year then yeah the
argument about we're going to go buy
some more kit it just kind of goes away
and there's one point here which I'm
going to kind of keep coming back to
which is which is this one that Java has
very complex adaptive runtime behavior
was anybody in my talk this morning yeah
it was 830 so I don't blame you if you
weren't there but this ability that the
platform has to to self manage and to
get itself into a state where it's and
it's looking at its own behavior and
modifying itself to run more efficiently
on the hardware this means that this
idea that just doing some uat okay it's
not perfect but it's going to be better
than nothing is actually little better
than a half-truth and quite dangerous
one at that because what you what you
find is that the the Java platform the
JVM will adapt differently to different
environments if you're running on a to
call box and you then move to a fork or
books in production unpredictable things
may happen one great example of this is
we had a UAE box which was was running
for cause but for very fast scores so
they were like 2.6 gigahertz and they
were like well we'll just stick it
straight onto the production box which
has you know 16 cause it'll be fine yeah
except the 16 cores run quite a bit
slower and the critical part of our
transaction processing with single
threaded so what that meant was we'd
gone down from a 2.6 gigahertz 2.2 and
that was large enough difference that
with additional complexity coming in in
the code base it actually tripped over
our RM or SLA for transaction time and
the whole system just went red so this
idea that you and you know it past you
80 it past all the promise of co 80 so
we didn't think we had a problem the
less fuel uit looks like production
the more likely is you're going to have
a bad time when you get to production
here's the next one prob like NATO is
hard you know we are literally comparing
apples which are testing Decter and
oranges which are which are prod data
yeah so this is this is pretty bad and
in fact it's it's normally worse than
this because it's normally more like
this yeah how many people have a uat
database which is the same size in terms
of in terms of data number of spindles
number of hard drives as production yeah
yep well you guys you guys are the lucky
ones okay and this matters it matters a
lot especially with performance testing
so to give you a to give you another
another example I works my system a few
years back which has users basically
being populated from ldap so when when a
customer comes in they log in and
basically all that data was pulled back
from from ldap to to look at the look at
the customer now that's all well and
good when you're doing 100 customers for
a load testing script you know in
mercury loadrunner or or one of those
tools because all of that data fits in
cache and the access patterns of that
data are very straightforward when you
put this thing into production in the
wild all of a sudden it's not the same
hundred users logging in all the time so
the round trip times two to ldap
suddenly become a huge factor and the
system falls over so actually making
sure that you have accurate data and
your performance tests look like
production traffic is incredibly
important that's yet to the point that
was was asked about about about
performance testing you know realistic
proper usage patterns are probably one
of the hardest things to get right you
get that right at you know you still
need everything or some myth you still
need a a u18 Rob that looks like prod
you still need you know full scale and
good data and all the rest of it but but
if you get our final piece right about
having realistic load patterns you're in
a great place so the other thing which
happens is you you have you 80 data
which doesn't look anything like
production later it's a stale copy of
production data from a few months back
when you finally badgett the DBA into
taking a dump of the production database
copying over into a tea and hoping it
will still works and this quote you
turned to hear if you've got this anti
patent so it's too hard to keep
production and uat in sync whose have
ever heard that yeah and this is another
example of the something is better than
nothing even even a small environment
the less stage of the production holes
has got it's got to be better than
nothing right and it does promote this
book sense of security so how do we
solve this one well invested in formal
date to refresh an actual process which
which is defined which swaps production
a two ntie it's one of those boring
nitty-gritty details that the developers
don't like to think about because we'd
much rather be writing code and playing
with new shiny tech rather than thinking
about how we're going to get data from
production to uat the other point is
that when you have an appt scale launch
when you suddenly switch on an order of
magnitude more customers or a big a big
lot of customers in one go you really
need to prepare for that well if you if
you haven't tested that thoroughly in
uat don't do it because that that's
going to be an absolute recipe for
outages okay one of my favorite on
patents next fiddle with switches and
this is the problem that you have when
the team just becomes obsessed with
fiddling with the jvms runtime switches
yeah if you just say change these
settings will get better results and the
reality is that we don't understand the
impact of changes yeah the root causes
for this are really a lack of
understanding of how the platform really
works and a misunderstood problem of
what's causing the issue software
especially Java has this kind of
emergent behavior it's it's because of
the way that we're trained as developers
and computer scientists we tend to think
that what we can do is we can take the
simple basic bits of code and reason
about them about the small big pieces
and stitch them together and somehow get
a sense of how the overall system is
going to behave and most of the time
that
understanding in that sense that we have
is completely wrong it's it's a it's one
of the clearest example of a cognitive
bias we have because we don't know what
happens when we state lots of bits of
code together a single line of Java code
by itself has no intrinsic meaning and
has no intrinsic performance properties
the sort of techniques that I was
talking about this morning inject
compilation things like dead code
elimination and in lining I mean that
you just you know without analyzing an
actual gathering data you don't know
what a piece of code does so this this
sort of propensity that to think that
you know if you somehow tinker about
with how many times a method has to be
run before it can forget to check
compiled or fiddling with with retention
rates and CMS initiating fraction ratios
and all of these crazy wacky switches
which the JVM has I've seen loads and
loads of teams do it the when when
confronted with a performance problem
one of the first things I normally do is
strip out virtually all of the flags
that the accumulated over the years on
the application because the team
probably doesn't really understand why
they're all there and and if they can't
justify it this is a great social
dynamic question about you know why are
those switches there could if I if we
took a look at one of your applications
and the command line that it's used to
actually start it up in production how
many of you could justify all the
switches that are there okay that's
brave yeah I mean I'm more than I
would've expected good so the JVM has
hundreds of switches it's very very
highly configurable and there's great
temptation to fill with it and just
resist it the defaults and
self-management are more often than not
sufficient and if you must make changes
to two switches you do the following
things you measure it in production you
change one switch in uat you test your
change in uat you retest it in the in
uat you find someone from your team to
go and go and talk to about it get a cup
of coffee you argue about what the
results mean get them to recheck your
reasoning and to recheck that they see
the same things in the data that you did
and only then you put that that one
switch change life you want to change to
your switches you do this twice yeah and
so that now we're starting to get a
sense of what Jolla performance the
performance tuning really is it's about
reasoning from data and because our
minds of the way they are that means
reasoning in groups it means it means
actually talking to to your colleagues
not only at your development and
architecture level but also in
operations because you have to get
production later if you don't have
production data to before you do your
analysis yeah you have nothing you're
starting from work from a false place
and yeah so here the JVM flags this is
the debut the JVM swag insist this is
Frank's graphic these aren't even all of
them these are just memory this is just
the flags which the JVM has for dealing
with with how the memory subsystem is
going to behave okay this isn't even all
of the flags that the JVM has to control
memory they are quite literally hundreds
of flags if you have a look in the open
JDK source code you can just see how
many they really really are there are
hundreds you see what concurrent mark
and sweep here pioneer GC you know all
that good stuff so what this means is
that if we're not careful we end up with
this aunty patent which is called
configuration by folklore ok and this
means that the code and switch changes
are being applied more or less blindly
how many times have you heard one of
your one of your colleagues say I found
this great performance step on Stack
Overflow hands up if you've heard that
yeah this is normally a terrible hear
the truth of the matter is that under
normal circumstances quite often the
developer really doesn't understand what
the context and the basis of the tip is
and the true impact is unknown and quite
often unmeasured you know I've actually
seen people blindly turn switches on in
production and without without damaging
any OT and there's kind of a sort of
peer pressure and for some reason I
don't know why job performance tuning
seems to have this kind of image of
being a tough intellectual challenge and
people seem to be quite you know
occasionally quite matter about it and
it's it's it's not really it's all about
data and numbers and it's kind of them
were they call it connects the dismal
science yeah there's lots of dismal
starts in two other performance
so how do we how do we avoid this this
in Japan well we need a well-tested and
a well-understood technique which which
you can directly measure and directly it
affects the most important aspects of
the system because performance tip is a
workaround for a known problem okay what
it means is that here we have something
which we know about in the system which
is a problem and hip here we have a
solution for it so it is it's a solution
looking for a problem tips have a very
short shelf life and they date very
badly so someone will come up we go in
the jvm team or we have a wonderful
group of engineers oracle and in the
wild community who work on the JVM and
let one of their one of their jobs is
finding ways to make performance tips
useless okay so after a while the thing
which you wish you did is at best
useless and it's actually probably
harmful so who knows this old this old
chestnut about setting XM x two x ms who
is anyone still setting XM x two x ms
anybody nobody is prepared to admit to
it one person unless you're working in a
bank get rid of it the adaptive sizing
the adaptive sizing is basically much
much better than trying to manually
handle this so yeah so so this was very
very common sort of six or seven years
ago nowadays it's it's completely
harmful in almost all circumstances
another sort of historian and this one I
sort of struggled to believe myself
sometimes but I promise of it straight
up until about two years ago the number
two or number three hit for Java
performance tuning was a page from 1999
okay and the reason for this can you see
who's awake what why we think this page
was number two or number three anybody
no okay because for this you have to
know a little bit about how Google works
because that pays was around in the very
early days of Google and was was
basically originally set up by someone
who was known to the founders of google
it went into the index very very early
with very very high google rank and so
once it was there of course it stayed
there because that's the one that
everybody went to so it became a sort of
a self-perpetuating island of a top of
the Google index so it contained some
absolute gems of performance in it
because at that time Java's virtual
dispatch was not not great so people
were concerned about the cost of calling
methods so this 1999 page recommends you
write enormously large methods so you
don't have to pay the cost of them of
calling methods and obviously with
today's JVM technology this is going to
react so badly with things like inlining
and jit compiling that it's going to
going to slow your program down probably
by a factor of 10 okay so beware of
performance tips the other thing to be
careful of is admin manuals you know who
here is read an admin manual and seeing
some of the the recommended
configuration information it yeah yeah
okay now that I've actually shipped to
software product which is intended for
end-users I'm going to let you into a
little secret the stuff in the admin
manuals is completely devoid of any
context and you should ignore it in all
cases picking you know why because that
that advice is put in there you are
forced to put it in there by your lawyer
when you ship a software product because
it's it's standard very site this is
entirely true what I want I met with the
lawyers they said we have to have this
information we have to have a
recommended configuration in the minimum
configuration otherwise we can't we
can't write a you know a correct licence
so yeah so be careful admin manuals as
well always remember the performance
happens in a context anything which is
trying to give you overly general advice
is going to be is going to be
problematic so now we've seen some of
the some of the problems that
performance tuning house and we can
we've seen how some of them arise from
entirely human constructions like admin
manuals and weird things with Google so
it's you know it's a different form of
thinking about performance tuning I
guess so it's also good to think
about what it's not performance tuning
is not a collection of tips and tricks
it's not some magic fairy dust that says
you know code it like this use this
super duper magically special very fast
class and it's certainly not something
you know you turn on at the end of the
project to to sort it out it's not
really this sort of province of Heroes
that there's one of the sort of
recurring myths is that that you know
you have a you know a performance guru
stays a whole night to crunch through
the problem and figure out what's wrong
with the algorithm in order to make it
run quickly it doesn't work like that
it's it's actually not particularly
intellectually demanding and it's quite
often quite boring it's lots of
Statistics it's lots of data it's lots
of data analysis I suppose I'm doing
this speaking thing will wrong aren't I
cuz I'm supposed to tell you how
difficult all this is and how terribly
clever you have to be to do it no it's
it's not that difficult okay this is
what I think probably this one is my
first or second flavor of the early NT
buttons it's the blame donkey who's seen
a blamed on piano application before
yeah the quote for this one is obvious
there are certain things are always
identified with as the problem it's JMS
it's always Jove s its hive an aid it's
always hibernate or some other
technology actually it's hibernate if
only is always hibernate so this is an
ant account which is quite often
displayed by management or business
especially if you've got an expert
business user that it's a little bit
technical you see this quite often in
banks yeah you find a quant that's not a
bit of programming tablet in a bit this
stuff and thinks that you know they can
they can come in and have an informed
opinion but technologists are not immune
to this you see you see this year that
the frontier of us engineers who who
also suffer from this entry patent from
time to time and the reality of course
is that insufficient Alice has been done
to reach this conclusion you have no
idea root causes for this again a peer
pressure misunderstanding the problem so
how do we have a fix this well you know
it's really just a question of resisting
the pressure to rush to any conclusions
you can lead to perform analysis as
normal and communicate those results to
all stakeholders
okay oh yeah this is this one's great as
well microanalysis hands up if you write
tiny micro benchmarks for small bits
your programs no good that's that well
you do that you're allowed to but in
general Jar applications are so large
and so complex and they do display this
incredibly emergent behavior I mean you
know the modern-day Liam looks basically
like this right you have you have your
java source code it's fed into J like
spits our class file its class loaded
into it into a JVM which then profiles
it JIT compilers it so there's all sorts
of really complicated stuff going on
inside here especially inside the
profile on the JIT compiler so we don't
really know you know what's happening to
that single line of code that we wrote I
mean there are a number of steps and a
number of processes which which are
operating on it to completely change it
its nature reform before it actually
gets near to execute you on a cpu so
rather than trying to reason upwards if
you actually want to analyze your
applications you have to start a high
level whole systems but yet cognitive
biases developers like to think the way
up there they understand they're in
control so lots of people focus on very
very low-level aspects of the system so
we can just speed up method dispatch
time everything will be fine and of
course the actual overall impact is is
completely unknown gnam you know we
don't know why this is happening so the
basically there is the resolution for
micro analysis is do not micro benchmark
unless you know you're a known use case
for it and if you do if you do know
you're known use case for it talk to
your ears because the the temptation to
to see cently into your into your
results which is not actually there is
but sometimes overwhelming and I've got
a quick case study about that so this is
a true story I have changed the names to
protect the guilty and oblige your legal
advice to say that any similarity to any
project you may worked on is entirely
coincidental so let's take a nap
strategy example people who are there
this morning they've seen the slide
already so we've gots a very simple
Kleist class hierarchies here at the
root of course we have object we have a
bear and pet
and subclassing pet you have a cat and
president only on the interface furry
which is implemented by both there and
cat is this method groom so there it is
on bear there it is on cat cats are too
lazy to have their own feeding method so
they just inherit that one from pet but
they also have a / method okay fine and
dandy so let's use some class the
easiest classes in a simple examples
bear so variable called blue he's a bear
got a cat called turtles do Americans
use tittles as a generic hat name no
okay what would it appropriate American
word for a name for Captain fluffy okay
so okay so cats of course pets have
names and Bairstow so that's why he's
he's got a void constructor so we feed
the cat green the cat green the bear and
then we can we set this new variable B
which is a type furry and then we groom
we bring the ferry okay fine fair enough
here's some some output there we go cat
feeds the camp washes itself and then
don't get too close to the bear because
it's got sharp claws okay fine so let's
see what the this bit of code looks like
when we compile it so you're just going
to decompile this using java p and what
i want to draw your attention to is
basically the the invoke calls for the
cap and the bear when we knew what
exactly what type it was was this this
type here putting both virtual and that
just means general you know run regular
method dispatch do method overriding do
the standard thing for an instance
method but this one down here when we've
actually assigned it to an interface
type actually has a merc interface okay
so what does that mean well if we break
down and look inside the JVM what it
means is that you actually have to do a
special bit of look up because for
things which directly inherit from each
other the vitae was laid out in this
nice clean simple way but interface
methods can't be we don't really know
where they are in the V table you kind
of have to look them up and that's
that's what's indicated by this use of
this slightly different biko here Gordon
bug interface okay so so what right well
so in the bank where this actually took
place
there we had a very bright young
developer who had spent a lot of time
poring over the data and analyzing it
and he'd he'd read up and he'd roll off
about this structure of the V tables and
the fact that there was apparently how
can have to be additional work I got
inside here so he measured it and he
discovered in his data a very very
slight effect we're calling an abstract
superclass method so using an abstract
base abstract class rather than an
interface seemed to be faster than using
interfaces so he got very excited by his
results it took his his his results was
prompt analysis all the way up to the
chief architect means like look at my
data it's um it's rates very very
slightly faster to use an abstract an
abstract class this completely changes
everything was weary my all of the
developer guidelines interfaces are out
we do everything without straight
classes from now on okay can you guess
what happened next yeah that's right
somebody else finally got hold of the
data and have a look at it and realize
that actually the effect wasn't there
and in fact you could reason that the
effect wasn't there because actually if
you give the JVM enough type information
that it can figure out what the exact
type of an object is it will actually
convert all your invoke interfaces to
invoke virtuals and you can show that
that's what was happening in this case
so the effect was completely spurious
and was coming from his benchmark
harness but he'd got so wrapped up into
this this idea and it managed to
convince other people along the way who
just missed that effect was was actually
not real in his data that this sort of
groupthink had developed because
everybody wanted to believe in this idea
this idea that somehow something low
down at the microscale could have this
huge impact on their on their code base
so be careful be cynical about other
people's data and always remember
Richard fireman who said that um you
must you must not fool yourself and
you're the easiest person to fall you
know you have to measure and then you
have to do the analysis and the thinking
about it that the measurement is really
telling you what you what you think it
is okay couple hundred patents throw it
over the wall this one's great basically
it's the idea that everybody just constr
acts into their own individual silos
development says well we've got plenty
of unit tests it works very well
chuck it over the wall QA can take it
from here they should they should be
running the tests anybody anybody seen
this panty button yeah and what this
really means is that for problems which
we could have caught earlier on with
before they actually cost us money
frequently end up in production so how
do we solve this one well we need to
build better cross team relationships
and this is this is another great
example of where the socialness matters
you know you try to understand what your
other teams do you know absolute actress
and releases are a lot less painful if
you understand the escalation procedures
other other teams have the on-call how
they work what the dynamics are and
especially l1 outsourced teams if you
have one operations team you know do try
to get to know them David that they can
be absolute godsend Oh domain at last
authority who doesn't have access to
their production boxes who relies on an
Operations team to touch production okay
yeah that half okay yeah so gets know
these guys because if they trust you you
can you can just ask them drawn a shell
command even if it's out of process they
probably still have a root shell on the
box you know you can tell a lot even
from the command line tools even if you
don't have proper monitoring okay so
there are a few recurring themes here
we've we've got communication problems
we see it when the silo mentality you
know throw it over the wall we see
cognitive biases with the misunderstood
problems that we kept seeing popping up
again and again and especially with
blame donkey and I guess microanalysis
is probably also an example of a
cognitive bias but it also stems from
uneven distribution of knowledge so all
of these things are our people things I
mean I've said virtually nothing about
about code or how it runs this is more
about the dynamics of teams and the the
dynamics of the dwell and the mindset
and the cognitive processes which go on
during the development process but the
good news is that we do have these
recurring themes so that if we address
these these things hopefully we can cure
a whole class of problems at once so
let's do that now the first thing to do
is to collect monitoring data right you
need to have a process for collecting
the data you should retain it you should
centralize it and you should collect
what you need
drowning and data is another anti patent
but not one I've got a slide for but the
thing to remember is is that that some
organizations just get fixated on this
collection of data okay they see the
collection of data is an end in itself
right so what do you used to do well we
build a data warehouse what do we do put
monitoring Gator into the into the data
warehouse okay right now what that's it
so the data itself is not something that
should be collected and audit you have
to analyze it you know the missing link
is that you you know that you need to
actually be able to to work with the
data you've collected to actually
deliver some meaningful conclusions and
data analysis and interpretation skills
may not be the strong point of your
developers who are operations teams if
you do have people have got good data
analysis and good interpretation you
know this is their chance to shine you
know you set them loose on on this data
and they can they can take it a long way
you need to build yourself tools to
generate reporting from this and then
you need to understand that though that
what normal function looks like because
if you don't understand what normal
function is you don't know how to spot
an outlier okay so so understanding what
business as usual what does regular
smooth running looks like is a critical
importance and then you have to make
sure that the outputs though that after
you've crunched the data and you produce
them in our assistance and reporting you
need to get together and talk about it
you need to make sure that people see
the reports you make sure that people
understand what the reports mean
especially the normal ones and then you
need to meet regularly to to discuss
what's happening are there any trends
you know is are we seeing a rise in
order volume are we seeing the existing
customers are ramping up what their day
if you don't understand those trends and
and and you don't have reporting which
can show you those trends in the impact
Sally launch system you know you have a
coming down the pipe that you don't know
that and the best tool that we have is
against our cognitive biases data
patterns aren't always easy to spot by
the amount of data that a medium-sized
enterprise can generators can be
overwhelming and make sure you
standardize the collection processors
too many outages are analyzed by ad hoc
data whether where there wasn't
per data collection process in place
someone has jumped on the box started
running a few commands you know
screenshots of jmx consoles passed
around in email is not a good outage
analysis tool trust me ideally the gold
standard for this is having enough
logging that you can retrace the steps
of any outage you can tell at any point
which transactions were in flight when
when when the system broke and if you
can do that there's a great advantage
you can have again it's not it's not a
technical advantages of people advantage
if you have a billet e to look at the
logs and go okay here are all the
transactions that were in flight when we
broke first thing you do with that is
you how much your sales team okay
because what they do is they look in the
database they see here transactions so
that which customers those transactions
belong to and they phone them up and
this sounds crazy but the amount of
damage limitation you can do if you know
exactly what broken who you need to
phone up and say hey guys sorry problem
with our system transactions getting
sorted out but you know you know manage
those expectations there's going to be a
bit of a delay before before you get
them yeah you are very unlikely to lose
to lose anything but the most ornery of
customers if you can find them up and
tell them that you know within within
minutes of an outage so y mejor well
humans bad at guessing about it we're
bad at lots of things to do with with us
nation will so bad lots of things to do
with with lots of tedious bookkeeping so
that's why we should use computers for
both of those things especially time
there does a great case study I I think
it's done by Apple in the early days
about getting people to estimate how
long a process takes and we're just
really really bad at it confirmation
bias is also particularly important if
we believe that some effect in our
system is it's important then we tend to
act in a certain way as though we know
that that's true where when actually we
know nothing of the kind another problem
that we have as developers is we tend to
think on golden paths you know testers
quite often to train to think about
darker paths you know what happens if i
call this method with nulls what happens
if i if i send in a completely empty web
request what happens if
cut my connection halfway through you
know and modern systems are very very
complex it's not just the JVM which is a
balanced adaptive system but it's also
you know other things running on the Box
virus scanners other applications
backups you know it's crazy how many
times do you find something completely
unrelated to application which caused
your your apt crash okay only ten
minutes going to going to rip through
the basics that stuff really quickly
everybody should know basic stats every
single developer in your organization
should know these standard deviation is
not often not very useful for 4 j.v I'm
applications for reason i'll discuss in
a second and and if you are you know of
a maths or stats event understand the
significance levels for results the
central limit theorem and p-values can
get you a long way into it to get really
understanding what your performance data
is telling you you probably only to go
much past this but that's good stuff
tonight quick word about non-normal
statistics everyone knows what I may
build by a normal distribution right you
know a Gaussian a bell curve all these
terms of equivalent real data especially
for JV on applications is not normally
distributed and from not normally
distributed data the standard deviation
is essentially useless and the reason
behind this is the JVM applications have
this hot path you know your jet compiled
everything works so so that means you
know you have this this Golden Path
which is really really quick and
everything else which could happen to
you just adds latency so rather than
having you know an even distribution
around a central peak you have something
Scoob this kind of long tail so you end
up with a distribution which looks more
like this there's a quantity called the
dynamic range which is basically the
maximum value in the sample / the
minimum JVMs have very long tails so
here is I'm timing a getter method how
it takes me to run one of those after
the JVM between larkin jet compiled it a
getter method will take about 23 nano
seconds to run except that one of them
will be out here in the 17,000
nanoseconds at 17 microseconds to run so
that's that's a huge huge long tail on
the distribution
there are tools for doing this but this
this use of long tail percentages were
basically you just 250 1999 and then go
out by another 9 each time that's a good
way for spotting you know the feel of a
long tail there's also a tool by guilt
any called HDR histogram so if you're
doing a lot of statistics and a lot of
analysis of performance that's that's a
very tool to use as well architecture so
who can draw their architecture from
memory if we had a whiteboard okay more
people should be able to do that it's
kind of it's important even if all you
do is a component diagram a secrets
diagram and a data flow diagram those
three things along with the process map
of what runs where if you have
relatively static assignment of
processes which increasingly people
don't just those three things will help
you a lot especially when communicating
between teams when you're trying to
analyze performance issue if you've got
these three things to hand and you can
you can sit down with your data
architect your network guy and your
operations team you know you will find
that you can you can start pinpoint
where problems are likely to occur much
much faster domain language the naming
the names that we give two things really
matter the old joke about there are only
two problems in computer science naming
and cache invalidation it's truer than
you might think but the other problem
that we have is that is when we develop
a system the domain language changes so
the first version of assistant we
release has a set of names which relate
to this this lovely clear conceptual
model that we hope we have but as the
system evolves and new releases are made
that that naming structure can start to
shift and it's important to as a key
part of technical debt reduction is to
refactor your language to make sure that
what's present in the code actually
matches what you think because if you
don't understand your architecture and
you can't explain your domain language
to other people how are you going to
cope in an outage yeah i mean this this
will back to trying to work for first
principles and and work upwards into
your interior architecture if you don't
have all this stuff easy to have so if
we distill distill all this down what
are we getting at there's no such thing
as perfect performance there is only add
performance and you need to define what
adequate performance means end users are
your performance requirements they
should be the source of your non
functional requirements and you should
specify them and have quantitative goals
related to things that you can actually
observe in the system if you're not
doing this you're not really doing
performance testing and performance
analysis yeah sorry ah the question was
who who's who determines what's
acceptable your end users your customer
so so if you have if you have expert
business users they determine what's
acceptable and if it the first time that
you go through this process they don't
know then you help them and you also
help yourself by setting a goal that
you're pretty sure you can hit because
there is the world of difference between
setting one quantitative goal hitting it
and then the business customer says
actually that's not good enough let's go
round and have another pass and then
hitting that goal as well that is
completely different from an open-ended
engagement of just make it faster oh
it's still not good enough in the first
one you've delivered twice you know
you've done what you said you were going
to do you've delivered to your customer
in the second one it's oh aitee they can
never get anything right it can never
you know they can never do what I want
them to the same processor it's the same
output but it's just frame differently
so for machining is an iterative process
you identify the worst offender by
measurement analysis and discussion what
you do you reconfigure or you refactor
or you change something in the system to
remove that performance bottleneck and
as you've done that you then measure
again if the performance is now
acceptable you're done you know it's
time to go home yeah and if it's if it's
not then you go back you identify the
next thing which is down so what you
should imagine is that this performance
threshold here and you start up here and
bit by bit you come down and as soon as
you're over this barrier as soon as
you're you're meeting your requirements
that's it you're done and in order to do
that you know you do need to do a lot of
this cross functional activity you need
to have prod light uat which means
talking to operations talking to
dva guys took you to network people you
need a realistic data set and you need
to have how to have agreement from your
business and from your users as to what
that realistic data set looks like you
need for proper configuration and
whenever you're planning of the form
assessing exercise you need
representation in that planning meeting
for from every technical discipline that
you have in your in your organization
because everybody is going to be
affected by it once we do that we start
moving towards a what I think of as
evidence-based operations it's about
asking key questions defining the
quantities and observables station or
assumptions and approximations and
proceeding methodically you you and then
finally you need to check your working
at the end so what kind of questions we
talking about I mean I think these are
probably the six questions of which in
which are key to operations and key to
performance analysis what observables
are you are you measuring how are you
measuring them what the goals for them
how do you recognize when you're done
what is the acceptable cost in terms of
developer time and in complexity in the
system for for performing the systems
tuning and finally what can't you
sacrifice as you optimize people often
forget these last two performance
analysis and performance tuning is not
free it takes people's time and you need
to you need to time box how much of that
you're going to give and also how much
additional complexity or prepare
tolerate I normally want to think about
about cost it's it's a matter of
communicating discussing these things
you probably can't arrive at answers to
all of these questions in isolation you
need help from other people when we do
expense and approximations it's it's
always important to state them how much
data do we need how many concurrent
users will there be where will they be
distributed around the world all of
those kind of questions what's your
words you've got those assumptions and
approximations document them write them
down work with the other stakeholders in
your peers and to produce a formal
document of these are the assumptions
this is the current state of the of what
we believe is true about our application
and our user base a memory visit it
because it will change you know the
example I gave you from the print from
the gambling site is a classic example
of that if we'd had those approximations
and assumptions
documented we could have red flag this a
lot earlier there is also a tendency
that some technical people have to try
to pick holes in models and approaches
which state their approximations and
assumptions that's a bad thing to do and
we must all stop doing it because
unknown and controlled assumption is far
better than an unknown one if you do
proper requirements gathering and you
know what your assumptions and your
proclamations are and there where you
can see them if you don't you still have
assumptions and approximations you just
don't know what they are so they could
they they can they can quite easily
sneak up when you bite you okay so back
to this slide now you can see that this
this why this definition works so well
it's because it's about measurements and
statistics and data analysis has inputs
and outputs and it can actually tell you
things it can answer questions for you
like this we will be able to cope if we
suddenly have ten times as many
customers what is the average response
time that customers see what does the
rest of the tail look like what's on
95th percentile how bad an experience
does that is that person having what are
our competitors doing all of these are
questions are quantitative they have
answers which come back as numbers and
that's the key part about about real
performance analysis is that real
science is repeatable you check your
work and you verify your results and you
provide information for your peers to
replicate because if you don't do that
you don't know whether it's it's
something specific about your system or
you know flaws in your argument or you
haven't really understood your data and
the second half of the final quote is of
course after you've not fooled yourself
it's a it's easy not to fall other
science other scientists if you want to
know about how how rigorous you can get
with this there is a paper called
statistically rigorous Java performance
evaluation if you haven't read it I
suggest you do be prepared to be quite
frightened by by what it actually takes
to get statistical rigor into your
performance results and its job form of
social well it kind of is an ism it's
antisocial because it's driven by data
and it relies heavily on analysis and
conclusions which is supported by data
and it if you get really good results
you require to do proper statistics
but it is social because everything that
you do requires a team effort you
discuss with your peers you even for
your results you publish yeah you should
publish full results of methodology even
if only internally and in order to
really understand the performance of
your of your system you know you need to
do some of these things you need to
communicate across teams you need to
share tooling so that so that everybody
sees the same view you just standardized
your monitoring data collection you meet
work through apps that log sufficient
and appropriate detail for you and for
your operations team beware a bit raw
and if you do all of this and combine
that with decent asus and reporting you
will get better result better results
you will get reduced risk you'll get
better decisions you will get more
happier customers thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>