<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CON7101   Taming Microservices Testing with Docker and Arquillian Cube | Coder Coacher - Coaching Coders</title><meta content="CON7101   Taming Microservices Testing with Docker and Arquillian Cube - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CON7101   Taming Microservices Testing with Docker and Arquillian Cube</b></h2><h5 class="post__date">2015-12-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/mIKq973M47Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody I'm very excited to see
you all here still alive after the
appreciation event and keen about learn
what we have to offer when it comes to
testing we actually used if you have
looked at the abstract we used a lot of
Technology passwords to lure you here
and I think we next year we're gonna try
another one which is IOT maybe we're
going to get the ballroom or something
yeah so so the topic of this talk is
taming microservice testing with
doctrine or equivalent cube so just
wanted to first ask you how many of you
have heard about arquillian all right
quite a bit and who is using it all
right cool so before we dive into the
the core of the of our talk let me first
introduce myself my name is Bart is my
sock I'm a comic commuter to our coolant
project I i'm originally from poland
live and work in switzerland for quite a
while don't really speak german that
well but yeah had some ongoing progress
i joined our query on like late 2011 I'm
responsible for a bunch of extensions
the main one is earthly and persistence
which we're going to briefly show you as
a part of the demo work for I work for
Cambridge technology partners basically
doing a lot of java web applications or
some backing things you can see what i'm
up to on github that's my github handle
and if you want to see what I'm
complaining about you can follow me on
Twitter so if you like the top please
follow me and if you didn't then please
follow me anyway because I've just
learned today that my mother has like
five times more full of words so that's
a quiet that's quite a challenge and
that's true yeah all right so before we
dive into the universal of our query on
and show you some details how you can
test the micro services and how you can
leverage docker within our ecosystem
let's just step back for a second and
just make a quick recap about the micro
services in general so the main question
is what is a micro service and I think
most of you probably know because it's
flying her out for a bunch of years it's
the concept is not true that knew the
term might be so microservices in
essence is a small component which does
one thing and it does it well it's a
focused on single of a single concept
from the given domain let it be like
user registration or checking the order
status and yeah you might actually think
what does it mean that the services and
micro service how should we measure that
should it be like counting lines of
codes or to order some other
measurements I mean the the answer is a
bit unclear what I have seen in several
books and blog post is some sort of a
rule of thumb that micro service is a
piece of software which can be rewritten
in reasonable time like two to four
weeks I wouldn't follow it blindly
because that's a bit too strict
especially if your micro service gets
quite a bit of interesting algorithm in
it but I think it's good good to keep in
mind as a general principle when you
think about how to split your software
so there are like at least three
important principles when it comes to
building microservices or well designed
software in general so first one is
single responsibility principle which
effectively means that the service does
one thing and does it good or well as i
already said the other one is that the
services should be loosely coupled and
in brief what it means is that if you
change something within one micro
service the other should not be affected
and on top of that we should be able to
deploy them independently and there is
one quote which I like to I would like
to share with you and I would strongly
advise to keep it in mind when you write
software it's from
Uncle Bob so Robert Martin and it says
that you should gather those things that
change for the same reason and separate
those which are not or which are
changing for the different reasons
effectively yeah so let's talk briefly
about the benefits of micro services as
I said microservice should be simple it
doesn't mean it it should be trivial or
simplistic it should be simple in the
sense that it's easy to reason about it
it's easy to maintain this code it's
actually easy to change when we
discovered that the functionality is not
really fulfilling the requirements or
it's probably implemented and obviously
very important benefit is that we can
scale it easier than manolito
applications and it actually gives quite
a bit of autonomy for the teams or at
least that's what microservices
evangelists are saying it embraces
polygroups you can try a lot of new
things you can try different languages
if you are a bit bored with Java or you
want to try c sharp for example i have
friends who are running your startup in
poland and they use plethora of
languages Java C sharp Ruby Python a lot
of things and it's actually a beauty of
our profession that we can learn new
things constantly and I think this
approach with micro services and giving
that power to the team to decide how
they should be developed it's very much
as an essence of it and the most
important thing is that the
microservices microservices are all
about composing them together so this
little snippet is actually here for a
reason so the whole idea of composing
little bits little pieces of software is
we've asked for quite a while this one
in particular lets you kill our favorite
idea if it's rebuilding the workspace
infinitely yeah but I've seen several
talks by microservices gurus let's say
and they very frequently compared them
to the unix processes yeah so we do have
our microservices in place then the next
big question is how do we going to
deploy them and here's where docker
comes to play and obviously everyone
heard about docker because it's very hot
and you can hear about it on every
single conference what docker gives us
is it can it lets you run your
applications isolations it lets you
scaled lets you fail over quickly and
this is entirely different approach then
with the modern lit environments where
your application when it fails it
affects everything and with dr you can
start new containers on demand you can
scale you can turn it off and then you
can actually react to issues way easier
than with the with the monolithic
environment so just as a very short
recap what is dr for me it's some sort
of a light virtual machine it's not
really a virtual machine per se but we
can think about it like like vm it's an
application container engine which runs
on top of linux kernel which is not
really true anymore or at least it won't
be in the nearest future because there
is a heavy work on going in microsoft
camp where they try to bring docker to
windows and i also heard that there are
some initiatives to bring it to Mac OS
so the docker container is some sort of
like isolated sandbox where the process
owns its own space and network
interfaces for example and it does not
or if you don't define it this way it's
it's not aware of or it can't don't
communicate with the other containers
you will see how to do some sort of
orchestrations later on and this is
actually something which i really regret
was not around when i was working on
some testing project which we had in my
company where what we had to do we had
to test our application against several
different environments so we have to run
it on jboss tomcat I think weblogic and
some
other application servers and then on
top of death we had to provide support
for several different databases like my
sequel postgres and ms SQL I guess so
back then what we came up with was to
have virtual machines as some sort of
pre-configured environment and deal with
snapshots to have built repeatable the
problem with this is that it's very hard
to maintain and evolve because you need
to recreate the vm reconfigure it and
then create a new snapshot but it's also
way more heavy because it's not only a
tiny little layer on top of the colonel
but it's actually a full-blown virtual
machine which also does a hardware
emulation and some other things so yeah
that's that's a lesson from the from the
past so how we can actually build the
docker image with you have several
options we can pull already built image
from the repository such as dr. hub and
then we can actually modify it commit
and then we'll have a new image we can
use the docker file which will see
shortly re we can also use dr. Campos
which is let's say relatively new format
we use the ammo to define your
containers a bit more human readable at
least from my Stein standpoint okay so
how does the sound protocol dr. file
look like first line is basically saying
from which base image we want to build
our new one on yes I mean I'm lazy so I
like to reuse a lot of things this is
tiny little Ubuntu which is like 200
megabytes then we basically create an
directory we set it as our root
directory for the command which we will
about to execute we copy some file into
this container we expose the port so it
can be reachable from the host and this
the next line is actually what is
executed when we start the container and
this is probably the shortest public web
web server code which you will ever see
and if you use single page applications
that's probably all what you need scarce
well well because it's run docker okay
so i can show you briefly the running
sample basically i have a doc the same
docker file here i can build it just a
question to the people in the back can
you see the slight the the code it's
okay alright so basically the first
command is building the the image using
the docker file everything is cached so
at this point we don't rely on the
internet which is pretty good for the
demos and then we can actually run this
what you will see is this is our web
server web application took me a while
to build it because it's a single HTML
file so i had to find this gift and then
encode it in base64 but at the end of
the day it's quite straightforward yeah
but that's a pretty much a toy demo for
for the test for the presentation
purposes okay i was demo and with that I
hand over to a slack who's going to
introduce you to briefly to work William
everyone so I most recruits in L&amp;amp;D
arquillian project lee how i'm the
senior software engineer it red hat it
seemed like um most of you guys knew at
least what alkylene was about that
correct so yeah okay I won't dwell too
much on these parks that's essentially
just introducing the basic for the
people who wouldn't necessarily know
what are killing is so this is gonna be
short hopefully them then we have more
time for demos as well our failures or
failures right and excuse my hi boys
side yeah talk too much this week of it
he was saying
so our Killian is essentially a testing
or it's not a testing framework it's a
testing platform we like to call it
essentially it's not trying to take over
J unit it's not trying to replace any of
those different types of tools but it's
trying to eat to integrate with all of
them and make a more coherent a testing
story around things like the job
application servers or serve the
tensions or in this case I'm going to
say later about soccer and containers as
well and essentially just control and
manage resources for you so from an ER
killian point of view when you the first
thing you need to do is to select some
form of container that this thing is
going to run on is that there can be any
application server whether it's being a
local server or or a remote server on
some other machine in the cloud or in
your staging environment or not when
then our Killian starts up it will
connect or startup the server which is
going to be a target environment for the
application that you're trying to test
and then you need to define the
college's sub environment that this test
case actually needs that means in a
normal java ee world that means to
package up some form of deployment being
a job archive a web archive and press
archive or a or a resource adapter and
fill that in your your classes your
resource files and anything you actually
need then our Killian will deploy that
environment for you and then it moves
that test execution from wherever that
test might might have been started for
instance in your ID or in in maven
surefire and forwards that the execution
know to be executed inside that that
environment that you are defined so that
point when the test run you have access
to all of the different resources that
the container offers you so you can
inject
CDI beans or gem GMS collection
factories or any other thing that would
be in that environment and then of
course it's going to capture the result
in returning back back through the same
chain and be reported up through the ID
or or the surefire report and then an
Honda playin cleanup face so an hour
Chilean in container test would look
something like that essentially this
will be the generated integration
telling j unit to user Killian has the
runner arquillian takes over looks for
the deployment creates that environment
for you and then forwards the whole
execution of the of the test inside of
the container environment and then of
course allows you to in for instance
inject the different resources might be
available there at that point you can
just assert on the state as you would in
any normal j unit type of test and of
course there's still not every
application if you want to necessarily
test from the inside a web page for
instance wouldn't make any sense to be
on inside certain rest type of services
you want to actually do the calls to
know that you get get through the whole
stack so i can it also supports the
option of being a deployment testable
false which essentially means don't
enrich this to do to entertain yourself
and the test message will be running on
the client side essentially huh ori in
your ID instead but since are killing
has control over that deployment handed
environment it allows you to inject
things back into it for instance the
urls to the application application
resources and the likes it will help you
to know where that by bees are you're
needin separate properties file to kind
of know if you're running in a staging
or in production or a run in production
but you get the point
so as far as getting started with with
our Killian and we still we recommend
you use some form of dependency
management system in this case the
example would be mailing base but you
can just as well use and an IV or Gradle
that matter and this is almost a what
you call it a announcement first time
seen then you are killing you are
telling universe bombs which is
essentially taking all of the different
extensions and project under dr tilly an
umbrella and putting into one one common
palm so it's very easy to to add the
different extensions as you logged as
you like to use them without having to
really know what those six those
dependencies that those extensions have
and so on so you have dependency
membership management on the bomb and
then you depend on in this case take j
unit one or this park one or or the test
in g integration or the cucumber
integration for instance and then you
need to have some kind of container that
we can talk going around this on in this
example we're going to use chameleon
which is a proxy container essentially
to start to stop at any of the other
ones following also the the new universe
layout so let's go and look at just the
basics of articulate so I'm
so as we saw before this is just we're
going to run we have a a CD i-beam
archive that has some CDI beans in it
that we can deploy some server and we're
going to inject and verify that those
beans with their and whereas as they are
CDI beans actually work and as far as
the configuration here is set up there's
a little snippet saying oops and you can
see that but that we're going to use the
wildfly 99 application server here and
we're going to have it anymore we call
the managed mode which is essentially
arquillians going to start and stop the
server as part of the test cycle and not
connect to something else is out there
and since we're integrating with G in it
etc the only thing you need to to is to
do a run as a unit and we can
essentially the server starting up it's
doing the deployment and starting up the
CDI container inside of the server etc
cetera so that's when we're running in
the container and yes other example here
is essentially the same but just running
as a as a client and calling the rest
services instead I can run that as well
but technically just going to start the
same server deploy this other all their
environment that contains more and then
you got a green bar which is cool let's
see where are we so principles ever
Killian is essentially just hope to
create portable tests so the your tests
which should not be bundled with
information about your target
environment but it's good focus on the
actual test code instead and and that
you easily test the business code
without having to maintain all the
management and all the life cycles are
all the different things that are using
and to of course execute in your IDE or
in ensure fire or in Jenkins and all of
the different different platforms
has runners it's built to be flexible
and instant and extensible so others can
come and create extensions that provide
news testing services and testings or
testing features to kind of build up on
the same foundation and one of those
extensions that we're going to have a
look at today is the archiving cube one
so back to bartosch back to me even
though we have a working on couplets
here sitting in the second row Alex so
if you have some specific questions he's
the right guy to ask all right so we
have a equivalent cube which is
effectively some sort of the bridge to
the docker world it lets us manage life
cycle of the docker containers which
means it will pull the image if we don't
have it stored locally it will start the
image and then it will basically do
whatever we define it to do in the
docker container and as far as this part
of presentation goes we will see it how
to use our cuillean remote adapter which
is a second kind after the managed which
effectively means that our Korean will
just connect to the running server
deployed the test band will run the
tests collect the results and then under
ploy but the server will still be
running at least that's the Assumption
obviously cube as its managing the whole
life cycle would tear it down and clean
up after the test execution what cube
also has to offer is orchestration which
we will cover in a bit so basically you
will see how to create more than one
container link them together and then
execute your tests in such an
environment and this oscillatory already
mentioned are clearly on is a testing
platform and it's not only for
application servers you can use any kind
of cool tools for building microservices
like drop wizard spring boot the
whiteflies farm nodejs or vertex also
not eat whatever ransom JVM essentially
that noj a switch
doesn't run jpn but we have it covered
as well okay so we're gonna have a look
at the first example how to use our
Korean cube will have a simple JP a
repository test and our image but will
be based on jboss Wi-Fi this is pretty
much the whole content of a docker file
so we extend from the white slide 90
then we actually have to run the script
to add the user so that we can log into
the remote container and deploy our
application and the last command is
basically starting the whitefly
application server and expose it to the
external world and this is how it looks
by the way all these code samples are
actually from the real demos we use a
ski dog for generating it so we'll
publish the slides shortly after and
talk and then you can have a look it's
pretty cool because we don't need to
change in two places it will basically
be updated automatically so here we
again use j unit we will deploy some
archive which for the sake of the
readable slide i just removed then we
will have the repository which is a JP
repository and we gonna verify if our
nicely written criteria API works we're
going to look for the strongest beer in
the world and as it's a Java code it's a
bit outdated because actually this view
is not the strongest one anymore but we
have a node.js application with the
lightest one so you will see the answer
at the end and an addition here is
Stanga little annotation using data set
is anyone here familiar with DB unit
okay a bunch of people unit tools maybe
okay so basically this is a little layer
on top of DB unit which lets you see
your database using data sets that's a
double unit concept which is basically
some sort of a mapping of your
underlying database
content you can use XML you can use CSV
I think and exhale that's by default
coming from DB unit on top of this we
offer yamu which is at least for me a
bit more readable than XML and we also
offer JSON so what this annotation does
it will it basically underneath us all
the DB unit boilerplate code because you
need to write a bit of things to let it
running easily this is convention over
configuration here is that first of all
when we start such a test we will tear
down the whole database it will be wiped
out because we want to start our test
from the non-state then it will use this
file to seat the data to sit the
database then the whole test will be
wrapped in the transaction in this case
because we run it in the application
server and we use JP underneath and then
at the end the transaction will be
committed obviously you can customize it
depends on your needs and the reefs also
another feature which lets you use the
same concept of data sets to verify the
content of the DB at the end because in
some cases it doesn't really make sense
to fetch the data and do some
tremendously big assertions you can just
provide this the data set with the
desired content and then it will be
verified underneath by alkaline and
persistent extension so in terms of what
is required is a cube docker dependency
and the persistent dependency and the
chameleon which you mentioned before but
that's pretty much it then we need a bit
of a configuration so first of all we
need to define how our image should look
like we can use this format here but we
can also use docker compose and just
refer to the file and then we configure
the whitefly target with the username
and password and that's pretty much all
what we need when it comes to the
configuration and again if you recall
the test code there is no notion of the
target
environment which is very convenient
especially if you migrate to the new
server for example you can actually
deploy your application or parts of your
application and just change the profile
and let's say deploy against the
websphere should work all right demo
time as it's not my preferred ide I
might struggle a bit but i'll do my best
ok so that's this one in idea you have
bookmarks so you can actually find your
test your content for the demo way
easier ok I think this is the one right
so control n was it drops yeah I already
forgot the shortcuts but i think it was
control alright so yeah the deployment
is a bit bigger than the previous one
what we have here is b 6 ml and
persistent xml definition and then you
can see that we have a bunch of tests
which we will now run this if you don't
if you are curious about these
assertions this is a surge a very
convenient to and api for verifying your
test your tests it's at least for me way
easier to use in comparison to hamcrest
because Congress is based on this oniony
so yeah I I would prefer to hit control
space and just find all the relevant
methods whereas in hum crest you need to
remember it by heart ok let's try to run
it how is it out shift XD yes alright
cool so actually we have somewhere the
docker running so as is it here or
should I change something I a here sorry
yeah we have a bit of an inception here
because we have a docker machine on the
proper Linux environment I mean boo to
dokur but as you can see we have already
jboss I mean Wi-Fi running and by now I
hope
we'll have our tests green and that's
true so so far so good no demo God's
around ok any questions so far with
regards to the to this part or shall we
yeah I on the bottom I'll on top yeah
this is this is finger up API which is a
some sort of dsl to create
programmatically the archive so
basically what it does is it will create
the archive of a jar type this is just a
file name if you leave it unspecified
this will be some hash some random
string and then we just build we just
add classes and packages recursively
there are several different options to
do it this is a simple one and I think
it's very good for micro services
because it lets you think about how you
structure your application so that you
don't just suck in the whole ear file
deploy everything which is irrelevant
for your test and then quite a few
seconds until to deployed so this is a
string ram a p.i this is the project
which was actually created for our
kuleana together with our quillian the
whole idea is to keep the build because
you can just run this test straight from
ID you don't need to wait for the whole
build process right question
yes that's how it works yes there is a
way of doing it once but it's not a very
heavy weight operation so I personally
prefer to heaven each test isolate even
though it's not the unit test it's more
like an integration test but still I
want to know where am I when I started
my test rather than when i run them for
example yeah in java 7 where you don't
have a guarantee on the order of j unit
tests the method executions you don't
really know what happens right yeah so
you can use several different options
for that so yeah by default you can use
for example hibernate scaffolding at
some point is good for prototyping I
guess we also do support planned sequel
so if you have plain sequel scripts then
you can also use that then basically the
create schema schema operations will be
run at the very beginning of the tests
and then all the methods will rely on it
another question
I am so the question is are the
dependencies also included in this given
example it's a bit of a it's a lazier
poor man's approach where I just know
that I need Arthur J included so I just
sucking recursively the whole package
but we have shrink-wrap maven resolver
which lets you get the dependencies you
need and also transitive dependencies
obviously then you need to assume that
it's going to be a bit slower because
then how the internet is downloaded by
maven but other than that it's pretty
pretty fast all right yeah so that was
the demo and now we have few words about
the orchestration because the test I've
run was using the embedded database so
basically we're using the one which is
shipped with white like example DB or
something yeah maybe you can answer it
the best right so the example that was
running there so the the example started
up a docker container that had a wild
fly instance in it and then the dr
killing chameleon NT are actually doing
or Killian wildfly integration I
connected to that server and did a
remote deployment essentially and then
you know the IP addresses and so on
right that is the basically this is the
first example is a bit awkward because
dr. is all about immutable containers
right and what we do here we have Wi-Fi
which is open and then we mutate the
state so we deploy new application but
for the last part of the talk for the
last demo will show you how to do it the
proper way and actually you can also do
it with white flies you just can deploy
the whole staff together if you're
standalone XML and the application
itself and then treat it as an image so
the orchestration part and example that
we had was saying it just uses the
internal internal database and probably
no system that is sensible is by itself
it needs to have other other partners as
well so we're going to look at
technically this same test but we're
going to move the database out to its
own mysql container and start in this
one's so it's to the or it's one
container depending depending on the
other and are killing cube supports to
to autostart X number of of containers
if you specify them by name or less the
option to to discover the linking itself
so it knows when you start to start to
walk like that these links to a MySQL
that should have been started and
separated that's essentially what the
demos go look over so the the the Q
configuration has now changed somewhat
so we're starting off with a still the
same type of wildfire image which is
actually being built built in the same
way but then we are creating a waffle or
creating a separate container as well to
link 1 given wildfire image to a
specific my SQL instance and then the
mysql instance is just the normal
standard
dinner almost the standard darker darker
darker mysql image the reason why we do
that extra step assist set of linking is
so we can add multiple different mysql
versions for instance so you can start
with 5 or you can just change the
property and then test 4 or 6 or
whatever and it's actually very
important for case of our current
president extension where before i had
to install all the things on my linux or
use some vm and then i could test
against post dressed and for example my
sequel but then I let's say I got a
report on the older version of my sequel
so either a new vm or deleting this
thing to run against the described
environment and now with the docker
approach I can just change easily one
line of configuration and I will have
another version of the DB and it's way
faster because like for example I was
testing against oracle DB and the whole
vm it starts up in like 30 seconds so
it's quite quite a huge time gain and as
we mentioned before as well those so you
might know the doctor compulsive formats
you will see that it kind of looks the
same as this the reason why we're
currently not defaulting to the doc
recompose format is essentially just
that we created this for the composer
existed so but you could define the tape
at the format and just refer to the
darker composer file essentially and it
will be the same same same type of said
okay so let's look at that run
yes so from the test perspect
perspective this is essentially exactly
the same as the other one just as we
have swapped out the underlaying on the
link database here we here so again this
is just run us g only test and we should
now be able to see that first thing it
starts of course the mysql database then
it starts to Wi-Fi image has been built
to severely for this little task and see
here we go green bars and then I tears
the whole thing down again the purse
well I'm intially there you go is that
um people understood that innocence yeah
in this example is essentially being
built the same way as the other one so
it's connecting to to a container that's
there and deploying it and then take it
down again so it's using the wild why
just happen to be running in a docker
container but as a normal app server
essentially right great great and well
it uses the management API of the server
so it did the output of that what do you
mean
right i mean an hour Killian core will
take that deployment method and then a
actually executing executing it and
exporting it as his hip stream
essentially which is up in horrible in
this example which in previous versions
of Aleph I you could deploy them but
that's been technically removed from
yeah eight nine and so on but in this
case we are building them as having them
as part as part of the dockerfile
essentially we're copying the driver all
over to the wall forester we're starting
up and then doing the manuals set up
essentially
oh no this part is just two single
wildfire version being a complete one is
here there you have it a Wallflower that
links to etcetera yeah i mean you right
i mean you could refer that to an
external highness well and just use the
doctor could post that format for
instance no that's the next example we
have a similar stuff similar stuff right
so yeah sure is eclipsed running inside
of the end or is it running right so
right so eclipse the question is where
is everything actually running
essentially eclipse is just on my local
machine there's nothing special about
that and just running a local job rbm
essentially then there's a doctor
machine identity that is in this example
I'm sure we show that or not but I can
see the top right we're referring to a
specific machine how cubed leno to go
out and ask poop what is the IP address
of that that machine the way the doctor
machine works so doc machine is then the
death machine we have here is running on
a local put to dr. machine but could
have been a digital ocean thing or a
Google App Engine all of the different
providers right I mean cube doesn't care
and dr. machine doesn't care and then it
starts up a couple of docker containers
inside of that pota da crib machine and
then that would be the mysql and the
wirefly and then
parts of it will deploy the application
over to the 151 and then run inside of
that little thing is like then back up
the tree until simple yeah when I run my
bill which yes great so now the last
part of a cube ecosystem is for the
moment because we will tell you what's
what we are working on currently is a
some kind of a funny name and we
actually have a sort of a competition
for the battery one so it's a container
less container because container is kind
of an abused word and it means
everything nowadays effectively what it
means that we deploy to the docker
container which does not have any
application server container for example
so if any of you have some better name
don't be shy we are open for suggestions
because it was confusing for me when I
started working with it ok so the
container list container is basically
any application that is deployed to the
docker container and we can use all of
these nice shiny technologies and we
have simple node.js example to show you
how it works so again a bit of a XML
horror we have a dependency which you
need I will just flip it over and then
we have an expert various application
which is up to date when it comes to the
strongest beer in the world it's 60
comma five percent snake venom very
expensive and probably not available
anymore because it was very limited
batch yeah I've never tried why I would
love to yeah and then basically this
simple rest resource in quotes it's
exposed on the given port and then what
we do in our test class is we in this
case we do
black box testing so we deploy we only
deployed archive which I will explain
later what it release and then we
exercise our application from the
outside if you are curious again about
what this is this is a rest assured
library for testing caressed resources
it's actually not only for testing it
can be also used as a regular rest
client fairly simple to use has a lot of
interesting features and yeah I think
that's the library I like to use the
most when it comes to testing rest
resources in my java projects so we're
going to deploy this simple tar archive
and then thanks to our query and our
principal to have tests portable or
unaware on the environment as far as the
code is concerned we have a way of
dynamically injecting the URL so it can
the same test can be run based on the
configuration against different
environments and you don't need to hard
code any like localhost switchboard and
so on everything is provided for you we
have actually a small jireh issue to fix
this one so that you don't need to pass
the file into the file asset but just
the string so if anyone wants to have a
low-hanging fruit pull requests we can
talk about it afterwards all right so
the doc we have a docker template so
it's docker file except of this one
little variable here so we extend from
the node container from the note image
we set the directory said it is the work
dear then we add the file which will be
created during the test execution and
then we run npm install so kind of like
maven it will download all the internet
again and then we start our application
then from the configuration perspective
it's pretty much the same as you have
seen in the previous examples and
probably no one of you will remember
it's all on the github so we can have a
look the only thing is we specify here
contain
ice container and we link to the
arbitrary docker file location which is
the docker file will be generated during
the test run so talking is cheap
especially about the code so let's see
it in action I guess the very last demo
we have it's so hard to switch to
eclipse after using samajh ID I tell you
that but it's quite simple control I am
right yeah okay do I need to clean up
something here or is it this one yeah
okay all right so I'll shift XD okay so
this will build our deployment package
if we look at what's going on we have
our docker container with note in our
application already up and running and
by now sorry for flipping the slides we
should have a green bar yeah so it's
quite simple obviously these are all toy
example so it's good for presentations
but at least it gives you direction or a
hint what you can do with with our
testing platform which equally nice yeah
so that's I think all as it goes with
messing with the Democrats so this time
we didn't fail and then you can take
over and explain what's coming soon
there's a couple of other things that
were kind of working on and some of them
are coming in X version and somewhere in
and something later ones but the first
thing is a concept were recording
container objects some of you might be
familiar with the selenium pedro objects
they can ID of encapsulated certain
things within those types of objects the
same ID goes for this type of container
objects where you can essentially define
the docker image and it's
configuration and its dependencies so
you would have a cube descriptor where
you define the cube configuration and
then you can inject other linked
containers that potentially have other
configurations and so on and then so you
can easily get access to for instance
this T the host in the port that this
thing is running on and the idea would
that then be that so if you are probably
if you are creating some form of service
you can provide a jar with this in it
for someone else to easily then use your
whole container which might be a I know
that with the with a database container
and some cues and so on so kind of
centralize all that type of
configuration in the one API to kind of
help out with that part and from the
user part even though just added your
job to the test classpath and you can
say cube in injected service and all of
that we started for you and then you can
access the services as you as you please
so cube started as as the darker
integration essentially for our Killian
while that was going on a lot of others
starting to use or other said the other
are using docker for la cadera not type
of good talking machines but other
deployments of docker containers so Cuba
is becoming the centralized API around
how r Killian work with any form of dr.
rice environments so in the last alpha
version we got service somewhat support
for appreciate three and cook Thank You
Bernie this will add four core OS and
measles and so on so you can also run up
those type of platforms and it's
essentially what we had for you so if
you're in the next steps if you want to
continue to look on this stuff and the
domain website is
is our cleaner organ discussed what r
kelly and todd org is essentially the
forum so if you want to join in the in
the conversation or health or I have
some questions so that's it for us don't
forget to vote you can actually press
several times I mean the only the green
guy who's that yeah I sure do we have
some combined to your handle and now we
don't point I mean you mean you want to
support me with beating my mom's records
that's one yeah I think she has only
bought so I'm fine with death and i hope
you want to watch this video okay well i
was here yes question of presentation
not yet but it will be today the only
thing is we need to remove or i have to
remove the images because the Dow's are
licensed one which for which i paid and
if i put it on github then it's for
everyone so yeah i think within like I
don't know one hour which guitar that's
a good question I think you can go to
mine and then should be sliced
presentations so another question
it was supposed to write I know I know I
was supposed to be released before
javaone but you know stuff happens and
we didn't put the legal slides so that
everything we say is a lie right so we
can give some we can give some estimate
or can we do we have this much no but
yeah essentially there I think the most
of the implementation is done there is a
discussion on discuss I think yeah so it
should be soon who's that and chemistry
can you take it offline a little huge
sir I mean I'm happy to discuss okay and
the other question 1 i'm a huge
well I mean yeah there's when do we know
it's up and running so the default
weight strategy that we have is to run
the SS command on the docker container
so essentially try to wait until the
darker container itself has opened those
ports and when that's done then we
assume that will be well it's kind of to
one continuous um java ee containers
right so this is a integration with
arquillian that is not a container so
it's a continuous container right
exactly or a bird is very docker
container like missing it's a bit
confusing for us as well anyone else
questions yeah
as whatever support you have for from
your IDE we have it integrated so if you
have just j unit of you as you have seen
on the demo you just run as j unit and
if you have testing g you just bring
another integration jar is a test run or
adapter basically which wire our query
on with with testing g and the same for
spoke except that we don't have support
for the latest version of spoke yet but
it's almost there cucumber ya can bury
was written by a magic community member
yeah and now maintained by tommy tribe
essentially yeah you can reach meeting
by Tom's right now ok yeah this import
well yeah gorgeous yeah their web
weblogic has official support for it
where that's being bundled with their
yes for a 12 something-something version
that yeah i've been using it with
westview 80 and 85 in work quickly
that's his gospel it starts it works I
think the liberty profile is pretty fast
yeah but if you use it as a on the big
guy then from my own experience with F
dot five dot something I don't remember
it was a year ago or two years ago that
was like roughly 20 seconds so 25 but
what we did we basically use the remote
adapter so we started wats and then all
the test shoot was executed against the
running websphere and then it's pretty
good thank you thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>