<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building a Distributed Application for the Cloud with Akka Clustering and Java 8 | Coder Coacher - Coaching Coders</title><meta content="Building a Distributed Application for the Cloud with Akka Clustering and Java 8 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building a Distributed Application for the Cloud with Akka Clustering and Java 8</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yPutaNumjNw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">synergist I have two people helping with
you
what was your name I'm sorry how do you
see you all right it's do you want to
introduce yourself really quickly just
you introduce yourself really quickly so
he's going to be helping out and then we
have Scott Lewis do I need to do so
yourself Scott yeah he does some great
consulting work so if you ever need help
with Scala NACA he's awesome yeah so I
worked for typesafe I've been working
for type suit for almost two years now
as a trainer consultant instructor just
wide variety of roles I just tell you a
little about myself
live from Park City Utah I've been doing
consulting for almost 15 years now and I
really enjoy working at typesafe have
been had an opportunity to travel all
over the world so then you know do you
align like South America a lot in Europe
yeah so if you're you know from a
foreign country you know like Argentina
or Poland or some of my favorite places
to visit so you're from you know a
different country come talk to me I'd
love to hear about it alright so let me
know if you guys have any problems as
with the set up those regrowing along we
want to make this as interactive as
possible - so you guys can get a feel
for how the software works he didn't
bring a laptop maybe look at your
neighbor and kind of help him do some
coding along the way
so with this racy you should be able to
pull up activator if you have the laptop
and there's the tutorial steps that
we'll be walking through and then I'm
going to be you know kind of talking
about the background a lot of the
explanation for this stuff as we go
through this so the idea is you should
be able to go through these steps right
and it basically gives you you know a
lot of the code so like you know it'll
say you know insert a new route file you
should be able to click on the the
conference and add a new routes file you
know click on tweets and update the
tweet so the ideas you can should be
able to follow along with most of the
code so you go through this and my
challenge is going to be that as I if I
walk around I gonna trip off the the
stairs with this wire in my hand so
that's gonna be my challenge all right
let's pull up the slides and kind of
talk about the background
all right so you should have activator
you should be able to pull up the
advance if you search for fit advanced
you'll find that advanced tweet map
right and then there's the every select
gift worked better there's this long
delay of doing things through a download
right you know so once it's off there's
the tutorial and then you know hopefully
you can start coding at that point all
right so to give you a background on
what we're going to be talking about so
it's a lot about clustering and there's
a reason for clustering clustering is
not just about going faster there's a
lot more to why we want to do clustering
it's all about it's kind of a
fundamental building block of building a
reactive application is building these
distributed systems and how we build
these distributed systems and make them
reactive so to start off let's talk
about why we want to build a reactive
application so what the reason is is the
users today expect a very different kind
of end user experience the kind of
applications that people are used to
with you know Facebook Instagram Twitter
you know any kind of you know live data
they expect are dated to be in sync
you know you upload your photo to
Instagram you tweet you expect all your
friends to see that instantly all right
so you're expecting everything to be in
sync and you expected this real-time
collaboration you know so when I tweet
to my friend I write you know I'm
sitting next to Mike he's expecting to
be able to see that instantly I bit you
know and able to tweet with them you
know Sharon's Instagram photos with them
you know and being able to do this you
know on a mobile application you know to
us it sounds normal but this is really a
drastic change in how we build an
architect application today all right
any other really important pieces to not
have to wait so people we have a very
low tolerance very low patience today so
when we build these applications we want
a very very low latency we want to be
able to respond instantly to the user
and be able to help them out so the to
build this kind of reactive applications
it takes a fundamentally different kind
of architecture so the way we build
these distributed applications need to
be to be completely rethought so we from
the ground up so the way they're built
can you know meet these you know and
user requirements and so that's right
we've come to title you know called the
reactive
we put up a website called the reactive
manifesto which kind of talked about
these four the four key traits the 14
tenets of a reactive application you
know we got a lot of flack for putting
up the reactive manifesto typesafe did
but it's really you know a lot of people
just thought it was marketing buzz it
doesn't have a lot of meaning but really
this there is a lot of fundamental
concepts and principles behind this
architecture and so the reactive
manifesto is actually put out by a
number of companies there's a you know a
lot of other people that are doing
reactive applications and so tight the
typesafe is just one platform that you
can build reactive applications on but
we feel like the modern architecture
going forward needs a encompass these
four principles to really effectively
you know meet these new kind of user
applications so I'll talk about these we
recently updated the reactive manifesto
this slides actually a little bit out of
date so the first thing is scalable we
now call it elastic what that means is
we want to be able to react to the the
end-user load so is the load of changes
we want to be able to scale up and down
and change the you know how well we can
react to this load and we want to be
able to you know add new servers and
take new servers take servers out very
dynamically so that the our
infrastructure you know costs match our
user load great examples like gilt
groupe they're one of our key case
studies right the gilt groupe has a
flash sale every every day around noon
they have a flash sale and they scale up
this massive load you know and they have
this huge amount of users that come in
for their flash sales once a day and so
they have to you know scale all their
servers up but then they want to take
those all back down so they don't have
the cost so that's being you know being
scalable you're reacting to load the
second part on the bottom event-driven
we're now seeing it's message driven the
idea is that we want our applications to
not only be you know static and you know
respond to user events we want to be
able to respond to outside events so you
know if you get new Twitter feeds new
photos you know you want to be able to
push data from the server on up so this
is a very fundamentally different way of
looking at your architecture because you
know traditional architectures are you
know
response from the user so instead we
want to figure out how we can push your
live data up to the user and how we can
build that you know message pushed into
the fundamental parts of architecture
the other key piece is resilient
so being resilient it means that
basically making a you know failure a
first-class citizen architecture you
know instead of building the art the
application you know and then we realize
you know when we go out to the you know
we make a web service call or we try to
you know parse the user JSON or
something like that
it's a try-catch block and you know log
exception we don't know what to do with
this crap something to happen you know
hopefully the easier didn't notice we
don't want to bail that you really want
to deal with our failures that way we
want to make them first-class citizens
so that we can you know properly respond
to heal our application and part of that
resilience is you I talked about you
know meaning the you end user you know
expects an incident response very low
latency so if we have a highly resilient
application it can be restore itself and
failures and heal itself bring yourself
back up and the the last part is being
responsive we want to be very responsive
the end user and you know responding to
you know so their needs and making the
application very much driven by the user
as well so you know building an
application with these type of
principles is a really hard thing to do
so some of the key tenets of building a
reactive architecture the first one is
right we never ever want a block right
so you have a single tree that everyone
has to use that's a blocking so we want
to avoid the we want to avoid that type
of scenario we want to you know remove
the single tree scenario and figure out
ways to distribute our load so that you
you know whenever there's a thread
processing something that's doing
something in our application so we never
want a thread blocking on i/o on
database calls you know when that user
request comes in on a thread if it has
to go and do some other processing in
the background we don't want to block on
that thread so this is one of the key
parts of being able to scale our
application is we never block a thread
and the primary way we want to do this
is by going to async we want to figure
out how to make our entire application
from end to end
fully asynchronous all right so what are
the building blocks of reactive so I
mean if you know this is about Java Java
8 but I will put out their skull as well
you know we we silly you know both of
these languages are very good platforms
for building
reactive applications on they both have
their advantages very good languages but
the key part of both of these languages
is lambdas right Java 8 lambdas and
Scala C has you know it's had lambda
since the beginning this idea functions
and the reason why Java the reason why
lambdas are so fundamentally important
is because the reactive application is
about being asynchronous event-driven
which means that we want to build small
units of work we want to make you know
small code blocks that can be you know
running executed on you know separate
threads we want to make callbacks and
the traditional way we did this was
using inner classes all right so you do
like an inner class and you you're you
try to you know two interfaces and some
other tricks then you end up with a
really messy code using landis makes a
really clean syntax for making
asynchronous event-driven code so it
really makes it easier so as we go
through all these code samples you
notice that there's a lot of use of Java
8 lambdas a lot of use of callbacks all
right so to build this application we're
going to use two main frameworks or
toolkits the first is play here here's
used play send you in here use play
company use play I was going to ask you
how many of you are doing Java 8 at your
judge job like on a day to day basis
buddy well so are you guys most of your
in Java 7 or 6 7 8 7 how many of you
guys have used Java 8 lambdas about half
of you ok well hopefully this will give
you a chance to get familiar with Java 8
lambdas get a feel for playing with
lambdas and what they can do and it's a
very different way of building an
application instead of the very you know
imperative you know so you can just kind
of driven programming you know lambdas
make it
change the way you're building your
application so let's talk about play
what play is so play is it's an open
source framework it's you know all open
source development typesafe is just the
company behind it that provides the
commercial support but we you know we do
all the development out in the open
indeed you know we really encourage you
know open source development
contributions and it's a we call it a
high velocity web framework high
velocity in two sense one is that we
want to make it feel productive like
you're using like a cake or Ruby on
Rails kind of framework and that type of
productivity but we also want to make it
you know a high velocity in terms of
being able to scale they handle large
loads so we are seeing play use of
places like LinkedIn you know large
companies that are using it for massive
loads as well and the key principles
behind play is that it's a fully
asynchronous and not blocking threading
model so that means that every request
that comes in does not actually block
it's it's a completely asynchronous so
that request comes in it doesn't block
the calling thread and it has what's
called the just hit refresh workflow so
if you're used to a traditional you know
Tomcat container model where you build a
war file and you deploy it out to your
Tomcat or you have to you know you know
refresh you know restart Tomcat anything
like that play is completely different
so play has what play comes with its own
container and it's built on um Neddie
so it basically as it's on HTTP server
built in and it's completely contained
of free so when you're doing development
you're just running play and you hit
refresh it's going to just do I write
update the code and you'll see the
changes instantly without even having to
do any deployment at compile time and
it's fully typesafe so everything about
play is typesafe the the views the route
to everything inside of its type safe
restful by default all the endpoints and
play return are can by default our
restful endpoints we makes it really
easy to do it like a JSON single page
app and it has built-in WebSocket
support we're gonna get into the
WebSocket support which is really nice
so that's you so there's if you've done
any kind of other web frameworks play
will feel very familiar excuse me
so basically played there's like three
key parts to play one is the routes file
this is when a request comes in we want
to say where are we you're in the route
that requests right so when we get a
route when we get a request into like
/foo we want to call the controller foo
method so we're mapping a request to
control our methods and telling the
server how to handle those requests and
the second key part is the controllers
that handle the requests right so when
you get this request in we want to
return a response right so a request for
slashed it's going to go to index and
index is going to render you know just
your new application is ready and then
the third part is views so play has
typesafe templates that are fully
compiled so you can write these are
server-side compiled templates so you
can build your application in play used
in either server-side templates or as a
single page app this the sample
application we're going to be building
today uses a little bit of both it uses
the server-side templates to kind of
bootstrap the process but then it's
mostly a angularjs or client-side
application it's a single page app so
all right so let's start building out
this application start looking at some
of the code so if we pull up here
right so the first part of this was to
add a new routes file all right so the
first part is you add the routes file
Yetta a route to tweet so we want to say
when you get a request into tweets we
want to run a search and then we want to
run tweet stud and then on our tweet
side job we want to add a reactor
request handler so this is basically
saying when we get that requested for
tweets we're going to run the search let
me pull the code up in a IntelliJ store
where you can see it better
there's that presentation
okay ah perfect yeah
all right so our tweets what we have is
we have the right we have the when we
get a request into slash tweets we want
to call the tweets controller search and
passing the query string if we look at
the tweets and you notice it does a
fetch tweets on that query string and
the fetch tweets what it does is it does
a uses play web service to go out and
make a web service call out to a Twitter
to get the tweets so you notice we are
not actually calling Twitter what we're
using is a Twitter proxy because of
Twitter API keys it's too difficult to
call Twitter directly so we're proxying
all the requests to Twitter so I'll walk
through this code I'm just curious how's
it going for everyone is everyone able
to get activator installed no no luck
there's any builder start can you help
him anyone else having problems or yeah
it should you having upon downline in J
Union
all right is it working for everyone
else through downloading still did do
how many people got it set up and
running so far okay we're doing pretty
good then yes you start going through
the tutorial please so I walk you
through the tutorial and if you have
questions please ask me and I'll keep
explaining stuff so let's talk a little
bit about this code what's going on here
so the first thing is promise what a
promise is is basically it's a promise
of a future value so what we're saying
is we want to like this web service it's
going to execute on a background thread
but we don't want to block why that web
service calls so that was the thing I
said I said fundamentally we never want
to block we always want to you know make
everything asynchronous so play web
service when you make this web service
call what we're saying is it's going to
return us a promise of a response so
we're not going to wait around for that
web service to complete we're gonna fire
off that web service call and then we're
going to make put a call back on that
web service call to handle that response
and so what we have is we have here
using Java eight lambdas we have the
response promise and then we're going to
filter that response right so if the
statuses each fuel to HDTV says okay we
want to continue processing and then we
want to map that response so what we say
so map is a really common paradigm with
lambdas and what we're basically saying
with math is we want to basically do a
map or transformation of that value so
you want to take the value that comes
back and we want to transform it into
something else we want to map it into a
like a new domain or new value so you
know for example if you have you know
like you can have a map X and you review
at X plus 2 so are you Titan you know if
I pass in one and give me three if I
pass in five you give me seven so it's
just giving me new values here I'm
transforming the status responses into
JSON and transforming them to be able to
send backup
so then if we look at our search
right the search runs this fetch tweets
you notice our searches controller it
returns a promise of a result so we're
telling plays that we promise to return
to the result we're not going to block
while we're processing our result that's
going to let play free up the request
thread so they can go and reprocess
other requests and we can go in our
background and we can do processing in
the background so what we're going to do
here is we say we promise to return your
results we're going to and what that
promises is the fetch tweets and what
we're going to do is when that fetch
tweets completes we're going to call a
map so you can think of that map like a
call back on that fetch tweets so when
the fetch sweets completes in the future
we want to take that result which is a
JSON and transfer it transform it into
an okay JSON node result in other words
we wanted to send that result back to
the the client with just an HTTP 200 ok
result so we should be able to return
let's see we should be running right now
thank you very things working yeah right
so I do the query it goes out it queries
you know here in this example it's type
safe and it fetches tweets about type
safe so everyone should if yeah if you
have any problems getting to this point
you know raise your hand we can help out
or you should be able to do everybody at
this point is be able to you know run
this query and see the type safe yeah
you can I don't know we can start using
Java line yes so the it's a Twitter
proxy and you'll notice that it about
every one out of eight request fails the
idea is we want to build a service that
failed quite often so we can do you know
simulate dealing with failures in our
application and kind of build failure
into the core of the application so if
we run this again we should get the
results back all right so I said that
failure is a key part of this so you
notice in our response promise we have a
callback to do a recovery right so
instead of just doing like a try-catch
block and through you know logging an
error like oh we couldn't call you know
the twitter proxy didn't work
what we have is instead
we have a way of dealing with this
failure and returning in a sensible
response back so the client can probably
do a nice you know error message with
that and it's a something sensible they
can deal with all right any questions so
far
yeah that's that's a yeah that ties in
perfectly to my next slide actually
right so the traditional way of doing it
was you had a client they're calling to
the server to be blocking and the server
then blocks to make back-end service
calls right but what we want to do is we
want to fundamentally change how this
works and so instead of the traditional
blocking request response model which
ties up a thread right so for every
request we've got to have this thread
sitting there waiting for the response
instead what we want to do is we want to
make a completely non blocking I think
what you're asking is when it does that
not blocking what happens to the HTTP
right connection and it actually sits
there and just waits because it it's
just a you know it's just a very short I
mean it's an extremely you know now in
millisecond wait time but it does keep
that that request open until the request
comes back and then it sends it back up
is that is that what you mean yeah cool
yeah so we want to make everything not
blocking for the client is server and
the server out to any kind of back-end
services we want to make everything
non-blocking and by doing this we're
freeing up our our threads and we're
gonna be able to scale up a lot a lot
more so
all right so what we wanted so what we
have I already talked about this a
little bit react to requests right to
change requests right pacing and I'm
blocking what it means my to change
request is right the the request from
the client to the server is not blocking
and this the call from the server out to
a web service or anything else is not
blocking so we're changing together
these two not blocking requests to get a
response back to the end-user all right
so we did this part alright next is
WebSockets yes they're the same thing
it's just naming convention so anyone to
confuse things right so play kind of use
play so the quarter play is built on
Scala and Scala has futures and for some
reason they need things promises so
there's a little bit of a mismatch in
terms of syntax but they're pretty much
the same thing like I can do like it if
I get back to Scala future there's some
calls inside to play that return a
future unfortunately so with those all
you have to do like a you can do like a
promise dot wrap you know wrap your
future and at play promise so but
they're the same things they're both
they're both the exact same content the
concept of you know creating a small
code execution block that I go and put
up put off in my worker pull of threads
they get executed and returned and you
know execute it sometime in the future
all right WebSockets so WebSockets
are anyone using WebSockets in your
application today a couple of people
what prototype you okay WebSockets are
it's a really cool technology it's still
the browser's are slowly getting to
adopt it and and now like iPhone you can
have it's a socket rocket you can do
WebSockets which makes it do this you
rate your client can be very reactive
using a WebSocket you know you know the
push data down to your client is a very
powerful concept the idea with the
WebSocket is we open up you do a normal
you know so
webpage and inside the webpage once the
webpage loads it then executes some
JavaScript to set up a WebSocket
connection that WebSocket connection is
a bi-directional full duplex
communication channel in other words I'm
going to send I can send a request down
that channel and I don't wait for a
response necessarily because I channels
open and then when the server is done it
can send the response back up that
channel so basically creating a
one-to-one you know direct connection to
my server so using WebSockets with play
play has built-in support for WebSockets
makes it really easy to use WebSockets
so to the next part of the exercises we
want to add WebSockets so what we wanted
kind of the end goal is we want to make
our tweets appear and real planet and
pushed up to the server sorry up to the
client so as new tweets come in we want
to see them being pushed up in real time
in route so the first step to doing this
is getting we want to update our code to
use WebSockets so let's go through that
code alright so the first thing with
play a WebSocket connection is just
through a normal routes file so all you
have to do is we have to add a route for
the WebSocket which I've already done so
that's just going to say when I get a
request on the /ws like any other
request it's going to go to a controller
like normal the difference is what
happens inside our controller let's see
I've already done this whole pulled up
in IntelliJ
a little bit ahead sorry we'll look at
the code here
all right so in play when we create this
WebSocket connection right instead of
returning a promise of a response now we
returning a WebSocket so what we're
going to do is we're going to wire up
the way we want to do on the end and on
the out so here when we get a new
message in write this is when the client
pushes something down the WebSocket to
our server
we're expecting JSON so we're going to
just take that as a JSON query and we're
going to execute a new fetch tweets on
it so we're going to do a search on that
JSON right and it's going to be the
exact same thing as before it's going to
return us a promise so we don't want to
block so here we have a non redeem so in
other words when that promise is
fulfilled we want to add a callback
handler so what that's going to do again
is it's going to be a completely non
blocking it's just having a callback
when you complete at that point we push
the response back up so we're not tying
up the thread but here on the on
response it's going to have this JSON
when you get that JSON we what we're
doing is we're just taking that jason
we're writing it back out to the out the
client and pushing that data back out
the other part so the application
already has the angularjs stuff set up
I'll just show you it's under assets
JavaScript index aijs you'll notice in
here right it makes it it's really easy
with the jcrane angular to set up
WebSockets
all we're saying is you know create a
WebSocket to that you know that host
that port and that you know and we're
going to /ws switches our route and
we're setting up a function that
basically when the client you know hits
the the query it's going to do a WS send
which is going to send that JSON down to
the server and then an on-message is the
callback on the client side when you
know it gets a new tweet back it parses
it into display so this is where I end
up the WebSockets from you know the
client to the server and that server
back up to the client let's see here
yeah so fine I'm a little bit ahead
sorry see if you go do a network if you
look into like a Firebug or chrome
developer tools you can look at the web
socket and you can see the requests in
the response coming back and forth so if
I do a pound Java one if there's a bug
with it where it doesn't refresh unless
you tap in and out but you'll see the
right here is the query sent down from
the client down to the server and here's
the the data as it comes back as it's
being pushed back up to the server so
was there any questions about web
sockets or any so that much working for
you guys I see some people as shaking
their heads but are you doing okay so
that's that's setting up WebSockets now
we've got this bi-directional two-way
communication between the client server
which is really interesting because it
means that the client is fully acing
non-blocking servers fully acing not
blocking and they're talking to each
other into this fully asynchronous
fashion it's a very different type of
architecture than your traditional you
know request response and make sure you
know the type applications you can build
is very different so the next thing we
want to get into is akka actors let's
see here
has anyone done anything with akka here
a couple of aqua users cool
so akka is our toolkit we call it
toolkit for concurrency there's a lot of
ways of looking at what akka is it's
it's kind of the building block for
building concurrent distributed
applications and it's going to be it's a
really powerful concept for ability for
distributed computing so right so it's
really a key building block for reactive
applications for a couple of reasons one
it's actor based I'm going to talking
about what actors are I'm it's highly
concurrent it's fully asynchronous fully
distributable and so that means it
scales both up and out scaling up
meaning leveraging all the cores in your
laptop your server any kind of machine
you're on scaling out so you know
horizontally scaling and this is the
scaling up and out is really critical
you know as the all these you know the
chips today you know you've got a 16 you
know cores on your chip you've got a lot
of you know thread and processing power
available on a single chip which makes
it really hard to take advantage of so
if you build a very traditional
application with blocking threads and
your idea you know leverage all of the
the cores of your CPU you're not going
to be able to scale so that's the really
the idea behind aqus being able to
really leverage the all the cores in
your CPU and then you know you know
multiple cores multiple CPUs on a server
and then multiple servers in the data
center you know so we're just scaling
and really kind of maximizing our
processing power alright so let's talk
about an actor so this is kind of the
fundamental building block of occas this
concept of actors actress is actually
invented by Carl Hewitt back in the 70s
it's a very old concept that we've
brought back and put onto the JVM or
lengh also implements actors actors are
very much like it's a traditional Java
object right they have behavior you know
processing and they have stay
which is their storage right so the
behavior is you know any kind of you
know business logic anything you need to
do and we go any kind of state you know
like in traditional object you know any
kind of you know like if we want to map
like a user or stock what makes an actor
fundamentally different though is this
this third piece is communication so
what's very different about an actor is
you never interact with your actors
directly
you never instantiate that actor
directly and call the methods on it
acha always manages that actor for you
and you only interact with that actor
via messages so the idea is that I I
basically tell Anka this is my actor I
want you to create an instance of it and
basically hand me a pointer or reference
to it alright and then I'm going to
interact with that reference and anyone
else who wants to interact with my actor
has to interact with that reference so
all my actors my system are just going
to communicate via messages this is
really and this really changes the way
that the the way you build application
it's a very fundamentally different
model because it's fully asynchronous
model but what this does is it allows
all could imagine the the concurrency
the threading forests and allows us to
scale at much higher levels and the
other thing that's really powerful about
this concept is it changes from using a
traditional you know traditionally if I
want to a sheriff state between you know
multiple threads you'd have to do kind
of some kind of you know shared mutable
state you're not to you know do some
kind of synchronization block or mutex
something like that with an actor you
don't even think about any kind of the
you know the threading the immutable
state anything like that and the reason
is is an actor processes one message at
a time right it gets a message in a
mailbox and it processes it and so what
it happens inside the actors it feels
very much of like a synchronous right it
feels very synchronous but it's being
executed async and us underneath the
covers because the threading is being
dealt with for us the other really
important part of akka actress is that
one actor is no actor they come in
systems so the idea with actress is they
get created in hierarchy so you have a
parent actor and it creates child actors
and those child actors can create more
actors it's like a file system hierarchy
and and this is important because
parents can match to supervise their
child
actors send them messages and children
actors can send messages between
themselves so what you end up with is a
very much of this walled fortress you
know I can only throw messages you know
over the walled gates and inside of that
wild gate I have this illusion of being
synchronous but unbuckles going to
manage for me my concurrency and it's
going to imagine you if I have several
you know million actors it's going to
figure out how to manage and scale all
those actors for me so the yeah the
anatomy and I'm an actor right this
basic concept is you have an actor an
actor has an actor ref right the actor
ref is what we send the message to the
message gets put onto the mailbox and
our actors going to pick up that message
off the mailbox and process it and the
dispatcher is what's all commands is
under the Neath the covers is the
dispatcher for the thread pool that
basically tells that actor when it can
run so basically you know it says
alright it's your turn to go and pick up
a message off the mailbox and you know
run it alright and then it goes to the
next actor says it's your turn
so that dispatchers kind of coordinating
you know which actors are running win
and it's going to keep coordinating the
thread part you know the thread pulls
for you and everything like that so you
don't think about thread processing or
anything like that so an actress system
I've mentioned this right so you have a
the route of your actor system the
writing underneath adds to user user
creating a pair of B child C alright so
the next part of these exercises we want
to create an actor and then update the
websocket code use the sock actor now I
said that acha actors are right the
fundamental processing with an arc
actors message which fits really nicely
with the WebSocket right so what we want
basically is you can imagine the client
is sending a message down to the server
that's the server just sends the message
into our actor the actor does the
processing and then it sends a message
back up to the client so this is a
really the Aqua actors room model
matches really nicely to a WebSocket
model because they're both fully
asynchronous so let's go to the code
all right so this is this is what an
actor looks like it's a normal Java
class the only thing that's different
about it is that we extend abstract
actor so other than that it's a you know
it's a lot the same as a traditional
Java class we use a props Factory and
props is what the properties for this
actor and this is what akka is going to
use to create an instance of our actor
so we're basically telling akka how we
want this actor to be created and so in
this case we are what we're doing is we
have a a ref an actor F to an out got
myself tangled up here yeah the out is
basically the out channel for this
particular actor so what's going to
happen is with play we're going to
create one user actor per request or per
socket connection per client so each
client will have a dedicated actor with
an N in and out the end is basically
just the message that comes directly
into our user actor and we want to send
the message back up we just send a
message to the out reference all right
so the other thing I said was really
different about actors is they have
message processing so instead of a
traditional just methods and method
calls what you're going to do is you're
going to match the messages that come
into that actor so in this case we have
two messages that are going to come in
one is the JSON node which is basically
just JSON from the client we're going to
basically take JSON from the client and
execute it this is a security hazard
obviously we're not that tucking the
user input for you know any kind of you
know security breaches you probably want
to do something that is scrubbing on
your user input but and the other thing
we might do is they match and update so
the idea I said is we want to simulate a
you know it kind of made it very much of
an event-driven real-time kind of system
well how we're going to do that is we're
going to create a timer that forces
updates out to the right so what it's
going to do is it's going to do this
scheduler and every five seconds it's
basically a tick timer it's going to say
update yourself meaning and go out and
fetch new tweets so every five seconds
we're going to be giving new tweets are
gonna be pushed out to the from the
server up to the client so this is
simulating a free word like connected to
the Twitter you know firehose getting
new messages pushed down to us
constantly and you know because we can't
really do that because you know the API
key and you know Twitter API limitations
where we're gonna do is we're just going
to simulate that with the timer every
five seconds we're going to say update
and go ahead and grab new tweets right
and so here in our match block so you
notice we see we're saying that update
and we're saying that to herself so
every five seconds we send a message to
our self saying update and we're not in
that update all it's saying is right if
we have a query from the client in other
words there's something that this
particular client wants to search we
want to run our fetch tweets and push
them back up and the last part to this
actor is here in tweets and our
WebSocket connection before we were
manually wiring up the end in the out
channel and deciding what to do with
everything now all's we have to do with
plays we just say play create us a
WebSocket with an actor we'd say we want
to use the user acted up props right I
said before props is basically the
properties of how akka is going to
create that actor for us and so it's
going to take that WebSocket and it's
going to wire it in with the actor and
so now that actor basically has it you
know when it gets a message it's going
to send it directly to our user actor
and never in our user actually wants to
send a message back up the client it
just sends it to out so we'll go back to
user actor I'll show you how it sends
messages back up right I the out is a
actor ref it's basically a mapping to
the out channel of the WebSocket else we
have to do a send it a message so the
other part with actors is how you actors
send messages to each other and that's
what the simple tell so I'm saying out
tell we're just basically saying out the
out actor ref tell it this message so in
other words fire off this asynchronous
you know mess
send the message sorry I said is the the
tweets we've gotten back to JSON I've
gotten back and here's this message
every five minutes cuz just coming from
myself at this particular instance so
yeah so in this particular case with the
user actor actor ref is creative for us
but I'll show you some examples of how
you recreate the actor ref manually by
ourselves in this case play is creating
the out actor ref forests and handing it
to us and basically wearing up for us
but sometimes you want to wire up your
own actors and and you can basically
create it you manually create an actor
ref your self and get it that point I'll
show you that code I'll be sure to show
that to you okay how's the how's the
tutorial coming for you guys so you guys
everyone able to get WebSockets and
actors working any questions so far
no everything downloaded and running
that's amazing last time I held a
workshop we had I had about 40
participants and the network's is
completely bond and no one could write
anything it's a disaster so I'm feeling
much better about this this is good to
see everyone working
all right so we created the akka act we
updated the WebSocket and the next part
was to update the twitter search at
geocoding all tweets don't have
geocoding sometimes they're missing
their geocoding people turnoff geocoding
for privacy purposes so we just randomly
pick a location and put it in there
because we wanted to play this on a
tweet map and the next part was to
update the tweet map so let's go to talk
it let's go look at that see I think I
already added the right yes so if I
don't have the location I randomly pick
a coordinate throw it on the map just to
simulate if we had real locations if we
look at our our controller our the Java
stride the angular controller in index
ijs I've updated so it pulls out that
the markers it pulls out the the
latitude and longitude and what we're
going to use what it uses is a leaflet
let me write right it uses leaflet which
is an open-source JavaScript library
that makes it really easy for mapping
and there's actually a an angular
directive for leaflet so it makes it
really easy for you to bind your your
data to it like a leaflet map and
display it so all we have to do here is
we're just saying markers is equal to
markers so that's basically we're just
going to hand the map a list of an array
of markers and that's this list of
markers right here all right so when we
get those tweets back we basically parse
the JSON we pull the allowed to in
longitude all those tweets and make a
list of markers and so when we run the
application it's refreshing
yeah Mayans
so you notice a lot of people are in the
Antarctic tweeting about Java 1 I have
no idea why people are green up there
everybody
yeah so
we're seeing this fully reactive
application right we're seeing tweets
being pushed up to us in real-time and
that's because we had this ticks the the
tick wheel in the background you know
executing tweets every five seconds
executing a Twitter store 35 seconds
pushing those results back out or the
client the clients displaying those and
refreshing those in the browser so now
we've got I mean this is what I consider
a fully reactive application because
it's you know you've got this live data
feed that's being updated in real time
right and the server is very much of a
reactive server because we are
event-driven we've got failure built in
and we're pushing these updates up so
how many people have this map working so
far
a couple people sorry can we is there
anyone that needs some help
terney any questions there's something
Scott can you help this yeah go ahead
you need help right yeah there's two
people here there's one person up here
in the front too
this guy right there cool thank you
sit work you're from you guys doing okay
still what's happened to yours really
can you ping Henrik on skype and just
tell them those errors her bill they
help you so what's the top
what is the actual root it doesn't go
all the way up oh man that's click on
your start again let's see if we can
watch it
you know I do this cardigan a pile let's
be sure it's compiling okay
see respond and Skype there you know no
he's not sure enough what was the
Hendrick
let me verify the username for a tenner
Oh
it's search etienne RI k RI k dot E and
G STR om it's still not showing up
do you want me to have a pink you and
said but you got it cool
right
all right any other anyone else need
help
any other questions yeah can you help
out you need to help yeah yeah there's
both these guys yeah I guess all right
why they work on those issues all you
keep talking we'll keep walking through
this and that and if you don't get it
done during this workshop I can guys
stay around after and help out so you
know what I'm going to lose power here
shortly
all right we'll keep going through the
tutorial through the slides and keep
talking about this all right this is
everyone feel like they understand what
actors are any questions about awk
actors or yeah yes where is the out
actor okay yes he's awaiting his
question is is where is the out actor
and I didn't explain that very well so
what happens is in tweets at Java when
we do this WebSocket with actor the with
actor underneath the covers what it's
actually doing is play is creating it
out actor ref for us and that's mapping
and it basically takes like out actor
ref and mounts it to the WebSocket out
Channel and so when it creates the user
actor it's going to hand us that out
actor ref so it creates it underneath
the covers for us and hands us that out
actor with so played the play web frame
where it's actually creating it out for
us
and that's when we do that out tell
that's where the odd is coming from so
any other questions about actors yes
how do you monitor the actors you're not
allowed to ask about monitoring yeah
that's my question I can't answer we're
working on that we had us so we built a
a monitoring solution we found it had a
dramatic impact on production
performance so we pulled it out and
we're working we've we're starting to
work on a new implementation so there's
some partners like kamon has built a
active monitoring system as well as New
Relic estimate monitoring but in terms
of like getting a graph of your actors
that's a really hard problem
so yes yeah
like how many like yeah like like if you
have a pool of actors like how many are
in that pool and that kind of thing yeah
yes
yeah I'm monitoring yeah so we had the
types of console but it was it had too
much of an overhead for production
purposes so we're trying to come up with
a new solution for that so we're with
New Relic you can get a sense of you can
get a sense of just like the overall the
health of the system and threads and
thread pools and I mean it's it really
is I mean because they are just Java
objects you can get a sense of you know
how many instances of that particular
class are being instantiated right so I
could use I mean any kind of like your
kid or anything like that and say like
with user actor I could actually say see
how many instances of that user actor
class are being instantiated and so I
can do that I mean so you can I mean you
ready they are just normal Java objects
and so I can look at things like that to
try to get a sense of like how many of
those objects are being created or how
many like what is my thread pool is so
it is it's a hard problem right
yeah it's so awesome basically it does
like a min and a max based on you the
number of course you have it kind of
matches the threats the number of course
and that's particular CPU but then you
can do custom configuration you see you
say you know I want to you know double
the number of threads that I have
because I know that they're gonna be
blocking you can basically configure
your thread pull yourself but it
basically just looks at the cores and
sit does like a you know well you know
I'm going to do it you know
approximately you know a percentage
based on the number of course all right
all right so we update Twitter search to
add the geocoding right we added the
tweet map so you can see the tweets
coming up in the map hopefully so let's
talk about the architectural pitfalls so
now we've built this application we've
got a the client mapping into the web
socket right the sorry the client has
the mapping to the website and that
website maps to the user actor there's
some problems with the way we build
things one of the primary problems is
you know we talked about being scalable
fully asynchronous the way we currently
built it is if you'll notice in our user
actor the user actor runs this fetch
tweets right well tweets are fetch
tweets is just a if I go where is it
right it's just a static method in the
tweets controller so now that my if you
can think of fetch treats is like a
service we want to build right having it
in the tweets controller
I can't scale that fed street service
independently right so fetch treats ends
up being a bottleneck to our system
right so you know you can imagine that
you know fetch tweets takes a lot more
time than it does to mapping you know
client connections so I want to you know
update my fetch tweets so that I have
more fetch street services independent
from that particular client from you
know the number of you know play
framework instances I have so I want to
scale things independently so I want to
do is I want to make fetch tweets a
separate service and I want to the other
thing we want to do is we want to make
it so we can eventually you know add
supervision and monitoring for it so the
next step is we want to pull fetch
streets out into a separate service so
we can scale it independently so so this
is kind of the let me
this is the end goal of kind of the
architecture we want to get to so the
first thing we're going to do is we're
going to pull tweed service out into a
separate actor right and so that it can
be run independent from the play server
the first step is we're just going to
create a tweed service inside the play
server it'll be part of the play server
and start it up with the play server and
then after we get that done and working
we want to pull that out and put it have
it run through a router which is a
cluster router and add clustering to it
so kind of the final step is we make
this entire application clustered so
alright so the next part is this of
right let's let's do this next part here
really quickly let's see here
I've got it Street service right so the
FET street service we just want to make
a new actor called tweet service Java so
if we go to a new file treats or such
Java okay
they'll drop this code in here and then
we can talk about it a little bit where
we're doing this a lot of these are just
the methods that we pulled out of the
net controller let me just grab
everything we're going to need and then
we'll go talk about it and then I'll
explain this Realty we're going to need
to explain this file right
so what we want to do is right so now
we've created this tweet service right
it's again it's just an actor it has
properties to create it right and it's
receipt block what it does is it's going
to receive a message called low tweets
so you can imagine the user actor it
gets in a message to load tweets it's
just kind of send that message on down
to the tweet service to the load tweets
but what this does is it makes the
loading of the tweets completely
asynchronous and executing on a
different thread being able to scale
this tweet service independently so now
the tweet service can do the load wheats
and what it does is when it gets a the
promise of the response back on redeem
right we're just kidding when we get
that JSON note back we're getting the
user sender who sent us those tweets and
we're just tying them all right we've
gotten more tweets for you and sending
those back up so one of the one really
important thing here that I want to
point out as you'll notice that there I
do a capture I you do actor with user
centered equals sender so I'm capturing
who sent me those tweets and storing it
in a variable and then I use that
variable when I send those back up the
reason is is you can if you think about
this the fetching the tweets is a
separate thread it's something that's
being executed on a future right and so
when that future completes that redeem
completes that's going to be a separate
thread that's going to be executing that
completion block so that for that reason
we've got to capture the sender because
the sender could have changed my time
that that promise completes so we need
to destroy that sender so that we have
the original sender and not the center
at the time without its execute we
wanted the sender who actually send it
now the sender not the sender who might
be on that thread in the particular
point in the future so we're sending
that Center data back out and the second
part of this is here in we want to do a
play plugin so this tweet service the
initial version of this we're just going
to make it a play plug-in what a play
plugin is is just a
a global class that's created on place
startup and executed I play startup so
it's something that's start it with play
so in other words we're sitting when
play starts we want to start this akka
actors the 1200 is just the order that
the plugin gets executed
I forget plays plugins are like below a
thousand so you know if you want to
override you know a particular play
plug-in you could do something before
and then after a thousand you can put
your own stuff in right so the our
plug-in just is a play plugin what we're
going to do is just send comment this
one chunk of code here it looks like I
forget it looks like we need to import
so if you're doing if you're following
along be sure you import a back-end
back-end tweet service or else you'll
get a compiler it looks like I forgot
that import in the instructions right so
all this is going to do in our plugin on
starts or in other words when play
starts we're going to create this actor
so there was a question earlier about
where do these actor refs come from I've
got myself a little bit tangled up here
right so then we do the assistant actor
of I guess backing up online so we have
a akka dot system
what's happening is that play is
creating an actor system for us right so
we're basically getting the the play
actor system if you create you can write
if you were to start up a standalone
node we create the actor system manually
but here we're just getting the active
system for play and then we're saying on
that system dot actor of in other words
take the I we're asking the actor system
to create us an actor and return us the
reference to it here we're just saying
insisted that actor have tweet service
dot props and we're giving a name treat
service client if you leave the name out
it'll just randomly generate a unique
name and what it hands back is not the
actual object for the reference the
actor references and that tweet service
clients is a reference to that
particular actor and it hands it back to
us that client so we can now use that
anywhere we in kind of in a global scope
anywhere we need a tweet service client
we just call this we just get a this
actor ref and we can send messages to it
so this is now creating a global kind of
tweet service inside of our place server
so this is kind of the first step to
breaking things out is creating this
tweet street service client what else
three what's our next step here right we
need to update the user actor right the
next part is we need to update the user
actor so currently the user actor is
calling directly into the the tweets
controller and we want to change it to
make a reference to the tweet service
instead so let's go to the user right
now did I mess myself up yeah we'll go
so end user actor we're going to add the
reference to the tweet service right and
then what we want to do is we want to
add we want to change the props so the
properties for how this user actor is
created we want to change them so we're
not we're passing both the out Channel
and we're going to pass a reference to
the tweet service client so we basically
want to pass in to this user actor when
it's created a reference to that tweet
service client right and then also
inside of our actor we need to update it
we need to update the constructor in the
receive blocks we use that so let me
copy this and then I'll explain it a
little bit more
right so what we've changed here is now
when we do the we were expecting you I
added a new method to match the tweet
service next tweet so these are the
messages that are kind of be coming back
from the tweet service in other words
when the tweet service responds it that
it has a new message it's going to send
us this next tweet message and we're
going to look at that message and pull
out via the JSON and send that back up
to the client right we also need to
inside the change at run fetch tweets so
now the fetch tweets before we were just
reading the fetch tweets and we're
adding a callback that was setting it
back to the client now what we're doing
in our run fetch tweets is we're going
to take that handle the tweet service
client and we're going to send it a
message to fetch streets for us so every
time we get that tick update you know
every five seconds we're going to fire
off a call to that tweet service client
and say hey go get me more tweets with
this given query all right and the final
step before I end this all together is
we need to change our tweet side Java
how we create that WebSocket so we need
to add a import for the actors drop that
in there and change that one block so
now when we create that actor what we
need to do is we need to change it too
so we grab the reference let me show you
that code because that's pretty critical
right so now we're saying website with
actor and the properties are again the
out channel from play framework but the
second part is the actress thought treat
service client in other words we're
eager to pull that actor out of the play
plugin right and we're gonna pull that
tweet service client reference out of
the play plug-in then we create it and
hand it off to our user actor so now
everybody user actually it gets created
it's now wired to a tweet service and
they can send it a message to get tweets
back so it's wiring things together from
end to end and I think that's all we
need to do yep all right so now if we
run it
we'll see nothing different on the
client side the client should work just
as it did before and I should be able to
run that yeah cool so everything is
running before nothing on the client
side really changes what's changing is
on the back end it's changing how
everything is going to be able to be
scaled and changed all right
update use your actor what's alright
we've got two more steps to go and this
is where we add clustering this is where
the fun stuff starts is we're gonna get
into the clustering all right
how is everyone able to do get the tweet
service to work or is that working for
everyone you need anyone need help are
you having a problem oh you can come sit
up here you want to sit up on the stand
and in front of very much
you sit up here you have to answer
questions though but we're gonna put you
on the spot see how much you remember
from the presentation so all right well
you guys work on tweet service I'm going
to talk a little bit about aqua cluster
and we'll get into that what aqua
clustering is so what's really
interesting is that scaling up it's
getting out is essentially the same
thing in other words leveraging all the
cores on our particular server on our
laptop is exactly the same is scaling
out in other words leveraging all of the
servers in a datacenter and so this is
what's so beautiful about the actor
model is it basically allows us to both
scale up and out so currently we are
scaling up right we've made the active
service so you know a separate service
it's being run you know independently so
you know it's going to scale up to
deleverage all the course in our CPU all
right it will be IL bound which is going
to you know kind of limit what you can
do but now what we want to do is we want
to scale that out I'm going to be able
to take advantage of multiple servers
right so you have a data center with
clusters inside those clusters you have
machines inside those machines you have
JVM JVM head nodes right those nuts have
threads CPU CPU sockets CPU cores CPU
cores have cache so you think of the
stack that we're building on today it's
this really large stack and it's you
know if you were to try to you know
write your own thread pool your own
concurrency library to leverage all of
this stack by yourself you can imagine
the amount of work that it would take so
what this is what akka gives us is it
helps us to scale up and leverage all of
that stack that's underneath us the
other thing we need to really think
about is how distributing computing is
the new norm right everything is
distributed I mean even on your mobile
phone you look at you know even the most
basic mobile phone now has multiple
cores right cloud services you know
Amazon AWS you know any kind of paths
says anything like that they're all
built about distribute computing no
sequel databases they're all about
distributing computing
react you know Cassandra these are all
about distributing basically distributed
computing is everywhere today and this
is kind of the the fundamental building
blocks of most services today so what is
the essence of distributed computing and
this is this is helpful to think about
what kind of problems are we trying to
solve with distributed computing so
there's two fundamental things that well
write so distribute computers value work
having two things one is information
travels at the speed of light we are
going to have a latency on our network
there's going to be delays things are
going to go slower than expect it right
you are going to have to deal with this
fact that there is a you know delay
between your sending receiving things
you have a network connection and you
know unless you're running you know
servers connected with over InfiniBand
there's going to be you know a somewhat
of a delay the other thing is
independent things fail independently so
as we add more and more nodes to our
server things get more and more complex
right so you know I mean running your
application on your laptop or deploying
out to a single you know Amazon AWS
instance that's pretty easy right now if
we have you know we want to add 10 more
instances well that gets a little bit
harder how to make those instances talk
to each other what happens if an
instance dies how do we start it how do
we bring it back online you know and
then you can imagine as I keep scaling
up you know I have a thousand servers
how do i spread my workload across those
thousand servers how do I make them you
know talk to each other you know in one
or two fails what am I going to do how
do I just you know they make that
failure you know or part of my system
that it doesn't even bother the
application completely resilient it
keeps ticking and so this is kind of the
the fundamental problems that akka
clustering is trying to solve alright so
again we have the nodes right these are
our cluster nodes and you can think of
it this way that we basically have these
clustered nodes and on top of this we
want to build it just a single layered
application like our middleware right
and so we want to make this all seamless
and build like a single application that
you know it operates the same whether
it's you know single server multiple
servers or multiple data centers
and one of the fundamental reasons for
this who's sort of an oblong so you're
unheard of am dolls law a couple people
and those law basically said they've
been percent the amount of speed up that
our application can get is directly tied
to the amount of parallelism and we get
alright so the more we can parallel lies
that the more we can spread that work
out the more we can speed up the
application so if you have right if you
only have a 50% parallel application
you're only going to get a small
percentage of speed-up right if weird
95% parallel we're able to want you know
spread things out we're gonna get a much
better speed up as the number of CPUs
grow right so the right so this is you
know what we talked about on Bell's law
will hunt you down you build a
traditional synchronous application
today on Dells law will hunt you down
meaning your application will not scale
you end up with enormous costs you know
there is a company recently in the news
that right they were trying to scale by
you know using synchronous processes and
they were all a sudden finding that
you're hosting bills you know forty
fifty thousand dollars because they had
to you know for every ten clients have
spin up a new server so you run into
these kind of problems when you don't
scale properly right the Iron Fist will
come to haunt you if you if you don't
scale properly you end up with these
Norton way you there's a lot of problems
when you don't scale properly because
you end up with a lot of costs and a lot
of overhead alright the other core thing
to akka
actors is location transparency so you
notice that when we created that actor
we got back an actor ref we didn't get
back a pointer right we didn't get back
an actual object we got back this
reference and what's really unique about
this reference is it does not matter
where that reference lives it can be my
local JVM it could be another JVM it
could be a JVM off in a different server
on a different data center somewhere
else I don't care where that actor lives
I just want to send a message to know
like it's going to take care of pinyin
to where it belongs so that means that's
what's location transparency is the
location does not matter I just want to
think about where how I create those
actors and send a messages and then awk
is going to basically make the location
transparent to thee the whoever sent me
those messages so the fundamental
building block of our kayak clustering
is remote actors
right so we want to send messages
completely decouples actors so whether
it's local or remote doesn't matter we
talked a lot about how you know we don't
try to make a remote transparent we make
it obvious and we optimize for local in
other words when you send an actor a
message it might be remote and right but
the thing is is that it's going to
optimize that call if it's local so it's
a more effective right so it doesn't do
like a you know an HTTP connection to
itself akka clustering so it's not a
traditional master server cluster master
server clustering has a lot of problems
they don't scale you end up with a lot
of network ball in that because you have
to coordinate between the master and the
the sorry the master and the clients
what-what in tzedakah question uses is a
gossip based what gossip based means is
that there's no single server in that
network cluster that's the master in
other words every single node is
basically an equal and one is just going
to act as a leader that's the oldest and
it's going to detect you know who's up
and who's down but that role of being a
leader can be fall to anyone in my
cluster it's gossip based because what
happens is I'm going to gossip that
cluster state to everyone else in my
cluster ring so I'm ready to basically
you know like gossiping with a friend
you know you just that's how you know if
you want news to travel fast you gossip
it to a friend and the friends spread it
between their network the exact same
thing what I want to gossip is the
network state who's in my cluster what
is the state of those individual nodes
and whether they're up or down another
really hard problem with distributed
computing is to telling whether a
particular server has died or it's just
slow am I having a network latency
problem is there just you know it's a
CPU overloaded so I can't tell me you
know send me back in a heartbeat so the
akka clustering deals with this with a a
failure detector basically a backup
failure detected you know it looks for
heartbeats so and what we're going to
build for this sample is we're going to
use cluster or where routers so with
akka where you can do is you can create
a router weather and you can think of a
routers just I want to create a pool of
actors you know I want to say
ten actors and I want to use that as my
pool it for scaling so you know for like
my tweet service I want to have ten
actors handling my tweet service so I'm
going to create a you know a router pool
of ten actors and I'm going to basically
balance and I load between them well
what's really neat with rocket
clustering is I can now say well I want
to create twenty actors I want to
basically scale between all my nodes in
my cluster so I want to create a NACA
actor on each of my notes or maybe I
want to take ten actors on each of my
nodes and when I get a request I'm just
going to go between each of my nodes and
you know spread that workload out so I
can use round-robin kind of spread their
workload between my cluster nodes I can
use consistent hashing like I have it as
example I use a lot like a stock if I
want to like track a stock I can have on
that stock symbol and then I can you
know yeah I know exactly where that the
actors running because it's based on
that stock you can do adaptive load
balancing routers so it's going to look
at the cluster metrics the CPU the
memory the load and balance out where
those that workload is going and spread
it between the cluster nodes so it's
spreading it out equally alright so the
next part is clustering let's let's get
into clustering this is where the
exercises get a little bit tougher but
hopefully we'll get it all to work all
right so I've already done a lot of the
work so hopefully this will be pretty
smooth the first part is play has a
config file playing aki uses config it's
called application comm an application
got coffee we want to configure OCH had
to use clustering so let me drop this in
here and then i'll explain it
let me just update my stuff here yeah
all right so the first part of this
cluster part one is just to turn on
clustering that's right after we
remember what I'm doing here and let me
show you that application often we can
talk about it so like I say said the
aqua question is built on remoting
remoting is simply like you can think of
it kind of like like an HTTP server for
actors in other words I want those
actors I want my actress to be able to
send receive messages over my network so
I want my akka system to basically
listen on a port and that port is going
to be able to receive messages from
remote servers so I can send receive you
know my actor messages over my network
the other thing is I can do is I can
using remote and I can say you know
create an actor on this particular
server so you could actually hard-code
it with remote e and say you know I want
to create a server you know there's a
server running on this particular host
this particular port going create an
actor on it so that's ocarina mowing
that's kind of the fundamental building
block for aqua clustering my actor
provider the default is the default
active writer is a local actor ref
provider so that's creates a locally
what this active writer is instead is
the cluster actor referee writer in
other words I want to create my actors
in a cluster and making it cluster where
and the last part of the config with
clustering is my scene nodes so like I
said akka doesn't have a master there's
not a master node that I'm going to join
into so instead what's going to happen
is I have some C nodes and I'm going to
go to them and say hey do you guys know
what's going on with the cluster what's
up and they say oh yeah here here's the
information and pass it on to me you
know it's basically going to gossip well
here's what we know so far and and then
we know we'll get back to with more
information and what's interesting about
the cenotes is it doesn't matter which c
node I joined so I could have a thousand
nodes and I could randomly pick IP
addresses so if I always using something
like docker or something like that and I
had those in a like a way to look at my
IP addresses I could randomly pick any
IP address to join into my cluster
so those are my seed notes rolls each
each server has a particular role each
question oh it has a role and so I can
have roles that it like I can have some
of my cluster dedicated to front and
center back in processing on the auto
day on unreachable laughter that's how
long it takes to detect that a
particular server note is down so so
every note said a heartbeat and that's
how often I'm seeing the down messages
and so after I've added this you've got
to restart play so if I go to right if
you're using activator and I going to
run I stop it and then just restart or I
could have hit the restart button right
I restart it you notice when I restarted
I'm not seeing anything yet I've got a
play doesn't actually start akka act
until I hit the webpage for the first
time all right so after I've started it
you'll see here it's trying to join it's
getting dead message letters trying to
join and then it says joining and then I
want to create two nodes right it
clusters no fun with just one node so if
everything goes well I've added a you
should be other area from the command
line do an activator RB run back in this
is going to run our back-end node let me
just show you that code really quickly
right this is just a Java main program
right so just like you'd run a Java main
from the command line this is just going
to run this mean and what's the only
thing that's it's going to do is it's
going to create an actor system and so
let's see started system where's then so
this is going to manually create a naka
actor system forest right you typically
have one actor system per day the answer
for this particular main we're going to
run a naka actor system and then right
and then it's just gonna do a little
command loop so you can answer can
answer shut it down and we want this
actor system will eventually add
creating some actors into it
so if we go to our if we do an activator
RB we should hopefully see it come
online and join the cluster so all right
so it's running right so there we see
cluster node
right so there we saw you right you know
welcome from two fifty five one two five
five one is our play server
so we've now clustered these two notes
together so in our logs over here lead
right we get a message right cluster
node two five five one leaders moving
node and then two five six oh two up so
what's happened is two five five one is
our play server that's the the akka
system inside of the play right now port
two five five one it's become the leader
just because it's the oldest it's
doesn't have you know and so if it dies
it will move to someone else and then it
what it does is when somebody else tries
to join we're ready to see it it just
marks it as up and says welcome to the
cluster so now we've got our two nodes
running and we've got a cluster up and
running that's that's probably gonna be
the hardest part is just to get the
cluster up and running but that's all
there is to it anyone have any problems
running the cluster doing that's much
you guys falling along some wider i've
got completely lost you guys are you
guys still falling along with the
exercises are all right what's the
purpose the leader when everyone joy
right so I should put it in my slides
the the cluster a cluster node has a
like a ring of states that goes through
so it starts with joining it gets once
it goes from the seat of joining it goes
to up from the state of outfits like it
moves to like going offline from going
offline to down so it's basically a ring
of states it's goes through so this is
the ring of state for the particular
node can go through and so what the
leader does is it decides when I go from
joining to up and when I go from up to
down so the leader basically controls
the state of that particular node and
marks it as being up and the idea is if
this gets into eventual consistency a
little bit but basically you think about
it I have you know five hundred nodes
and I don't want anyone to be
necessarily master or single point of
failure I wanted to be able to just mark
houses up and so the way I do that is I
can just change the state for Manoa from
you know joining two up and then just
gossip that information hey we've seen
this other note is being up and I can
send it out to my everyone I know about
does that help explain yeah
is there another question or is that
yeah I'm it's the end and it's you and
your config file you can do a seed nodes
yes so you have to put in some seed
nodes so like with Amazon AWS you can
get a like there's you can use the AWS
API so I could use like a like I can use
the Amazon AWS API to like update and
get like a list of like IP addresses and
then when I do the cluster up I can
manually set those notes from AWS like
your hard cardamon config I could put
them in like environment variable update
right config file when right the cluster
starts up so yeah go ahead yeah exactly
yeah
no the cenote is just like the entry
points of how I join that cluster but
they don't have to be right I only have
to have like two or three seed nodes and
the only reason you have additional you
can actually join it just one seed node
but additional see nodes are just for
redundancy purposes in case I can't find
the first one I can go to the second one
yeah yeah yeah it's like a bootstrap
yeah exactly
well that's why you need multiple seed
nodes because when that leader dies the
role just leader goes to the next oldest
node in the cluster ring and then so the
next oldest is now the leader right it's
just like a family like the oldest
person the family simply the the leader
of your family or that you know that
person passes on or you get the next
person that takes charge that family and
yeah yeah God are you running you're
feeling brave to help with some
clustering question yeah I don't like
your questions
right right yeah yeah talk to me after
I'll talk to you after about that that's
a hard question but yeah we can go into
that I have about 20 minutes so I asked
your question I tell you don't want to
answer him sorry I just realized I have
about 20 minutes so I want to just show
you guys the cluster running and then I
need left hanging left over we can
answer some questions or I can talk to
you guys afterwards so I just wanted to
finish up so the one thing with right so
play play automatically does right the
Refresh work load the question because
this is just a static java application I
have to shut it down and restarting time
I make changes so I want to start check
out my servers because I'm going to make
some changes to my clustering so I'll
just go and stop all everything just to
be sure we get everything stops and
restart properly so what we want to do
is we want to add a cluster router to
our config file so in the configuration
what were you going to say is right
we're going to do an after deployment
we're going to create a tweet service
router and the router is going to use a
the tweet service right and so what we
need to do I always do this handsome
save and acha actors we need to create
let's see here
let me add this code that I'll explain
it right so the idea is that what we
want to do is we want to create a
clustered router in our config file and
then in our actors plugin instead of
creating an instance of an actor what we
want to do is we want to make our
instance a router so it's going to route
inside of our cluster so that's the only
change we need to make this clustered so
I think this is pretty amazing
we went from a tweet service right
inside of our place over with about 10
lines of code
we've made this a cluster treat service
that's running inside of our cluster the
way we made this treat service cluster
Bowl so if we go to main cluster manager
we need to create an instance of that
tweet service I forgot that line of code
let me grab that or is that
so in the this main cluster manager this
is our standalone node that we're
running we create an instance of our
tweet service all right so basically in
this back-end node and you know that we
create it's going to create an instance
of the tweet service and then what our
router is going to do we're out T's path
is equal to user slash street service so
what it's going to do is it's going to
look at any node that joins the cluster
right so there's cluster events when
that node comes up it says hey do you
have a tweet service running you oh you
do I'm going to add you to my route pull
of routers that I can use I'm a group of
routers and I'll send you messages right
so the tweet service router just
basically uses that rowdies we put in
there a role so it knows that you know
what cluster node silica and we turn to
allow local Rowdies off so we don't want
any of the nodes on the place server so
then in right in our actor ref right
into play plug-in the tweet service
client instead of creating it directly
all we're doing is we're creating an
instance of the router so we're seeing
you know get the router the tweet
service router and create that instead
so now if we go we're going to run on
two nodes so we'll have a three node
cluster if it all works well thank you
for your running back into so the way
what I did say right get everything to
run see here where's my Intel Jane
right and IntelliJ what I've done is I
started to build SBT I've added this run
main that runs our main processes and it
basically starts up these nodes on
different ports so I want to run two
backends one two three four five six
zero one and two five six one if
everything is working connection refused
what my placer was not up yet guys start
my Play server I started to stopped it
so I need restarted so the placer will
come online it's loading the project I'm
solving okay so the place we're sort of
now and i refresh it's going to start
the akka actor system we're took joining
the cluster so if we watch inside of
here right cluster leaders maybe nodes
to up so everyone's joining
alright cluster node welcome from so now
I've got two nodes in my cluster so now
when I do a up
let's see you pound Java one with any
luck
ah there it goes cool alright so what
we'll see is if we watch the logs for
these two nodes I have their little
debug let me pull this up a little bit
right every time it gets a tweet it
right takes that tweet and it writes it
back out right so and if we look at it
right right next week so you notice that
both of these nodes are serving up the
requests so what's happening is we have
this user actor on the client side
that's sending messages to the tweet
router the tweet routers routing it
between two different cluster nodes it's
just going back and forth between you
know node 1 and 2 and balance it between
the two and so here we see these nodes
going back and forth getting the load so
what's really interesting about this is
right on the client side it's you know
we're getting these refreshes
everything's updating you can imagine on
the backend you know your server dies so
a normal process right if I killed the
server like that just cut it off right
everything or blow up and stop working
well what's really interesting is right
it's going to give me an error that I
couldn't talk to that particular server
but it's going to keep running the
processing the router it's basically
that that particular act has been pulled
out of the router pool and everything is
just going to this one node and on the
client everything is still working the
router dice you could actually add
supervisory so that's a big thing I
thought I act errs is to add a parent
that supervises so you could have a
parent supervising the router and
watching that route and be sure that the
router doesn't if it dies to restart it
or you might want to put in special
processing like you know you have
special error cases so even more amazing
is right now that the particularly node
is died I can just start it back up so I
you know you can imagine the scenario is
I have you know a couple notes my
cluster I'm noticing my loads or my CPUs
are showing to max out rememory starting
to max out so I want to add in another
node and have it started taking some
workload off so now I'm adding another
note into my cluster right it joins it
takes a little bit for the detection to
happen and so it's going to join the
node it's going to be added to that
router pool back into the router pool
and we'll see it slowly hopefully giving
some messages
oh there it goes so now we got it this
node back in so now we hit we're back to
having two nodes and bouncing between
the two nodes so that's that's the high
level with clustering I just wanted to
wrap up with a couple of summary about
the clustering and then we can talk
about some questions so we've talked
about cluster Rati akka clustering has a
lot of other features to it cluster
membership so your individual actors can
listen for cluster events so I can
listen for new notes to join I can
listen for up-down messages and you can
do a live interesting thing by listening
to the the gospel vents and finding out
you know what nodes are coming up and
down like a new publish/subscribe so I
can listen to a particular topic and I
can publisher to subscribe to it that
way I can like broadcast messages across
a cluster cluster leader cluster
singleton this is a singleton pattern so
you say I will have to have one instance
of a particular node running in my
cluster so like you asked what happens
if the router dies I can make my router
a singleton which means that it's going
to guarantee at least one instance of
that cluster that actor will run
somewhere in my cluster so I can say you
know make my router a singleton and you
know run on any of these ten nodes I
don't care which one just be sure if you
know one of the nodes dies for my
singleton running move it to a different
node and start it back up again
cluster sharding yeah the other another
really cool feature that we're just
getting into now is acha persistence
lack of persistence basically allows you
to persist the state changes in your
actor so right you when that it actually
gets an event I can you know validate
the event is it you know a good event
it's not you know like a null pointer I
can you know like like the JSON I can
validate I have decent JSON once I
validate it I persist it and say I
wanted to save this event what's really
powerful about persistence is well one
other thing I just explained persistence
it has a pluggable journal in other
words I can plug in like a Cassandra
Kafka any kind of journal in the backend
and save those messages yeah
what's really powerful about persistence
is with persistence do we have what's
called shardene so now that we've three
able to
that actor state so we can take this
actor state and we can save it to a
database we can snapshot and say okay
now after several thousand messages we
want this to be the state it's at you
know another thousand messages we on to
this state
now with this persistency States I can
take this actor and I can say I want to
distribute you know my tweet service
across you know one hundred nodes and I
want to cache the results so someone's
you know doing the exact same to Twitter
search on different nodes right sorry if
someone sends a Twitter search to me and
then I see someone else said that exact
same Twitter it's five seconds later I
want to cache results and just send it
back the same thing so now that my
Twitter service has a cache on it the
problem is I don't want to lose that
cache of that actor dies without cache
our Dean what it's going to do is it
actually can take that actor and you can
move it between nodes and that's also
going to allow me to take that state and
kind of take that actor state and kind
of rebalance it between my nodes so
we're starting what I'm doing is I'm
basically kind of using it's like a
router it's the individual instances
where those routers are stateful and I
can bounce it move the state of those
actors between nodes all right so just
to summarize kind of these are the key
principles is to read applications when
you work here with akka actors akka
clustering just keep these things in
mind into doing green I'll get this out
right so minimize contention we want to
minimize contention of resources ock
actors makes this really nice rate
because it gives us this illusion of
being synchronous although it's acing us
on the background it's only processing
one message at a time so we never have
to deal with contention right maximize
the locality of reference I really
didn't get into that you shared nothing
designs so like the Play server the Play
server does not have state I went to see
a play up buy any more instances I can
just sort with another server right and
I can add that into my cluster because
all of my play servers there's no state
it's not a stateful web framework by any
means right and very much within read
driven foundation so I can respond to
events and then location transparency
all right so I don't care where my
actors are running where my services are
running so this really allows me to have
this kind of a micro service kind of
framework can easily scale out the
independent services and not really care
about the location yes scale up and out
with ease Louis last minute okay that
was all he had for this and I can answer
some questions I think we have about ten
minutes
yeah we have about eight minutes and
then if you want help with the workshop
material I can help you work with it and
you know if you have any problems I can
help you walk through some stuff or
explain stuff um and I'd like the USB
sticks back if possible he's gonna
collect the force in the back really
appreciate your help by the way thank
you so much he volunteered last minute
to help I think in my Twitter and said I
need some help so is very nice yes
question all right well I can I can work
with you guys after it was that you were
you able yeah right that's it wholesale
well the interesting thing with akka
actors is that right you probably
wouldn't want to write you could
probably use them I mean I've never
actually thought about this but with an
akka actor what you could do is these
actors can um be sent messages from any
part of the system so right spring
alright so incited like your spring
controllers the spring can you can make
an actor reference that's a spring
controller like wired into your spring
controllers and you can basically just
send messages from your spring
controller into your actor and you scale
it that way so really you can just use
the actors right where you probably
won't get the full model but you can use
the aqua clustering you cannot use the
you know the asynchronous nature of
actors to do asynchronous processing
from your spring controllers so that's
an interesting question I haven't really
yeah that's that is a hard thing right
how do you migrate to a completely new
type of architecture slowly yeah so yeah
yeah dried yes so aqua clustering
internals uses protobuf the messages by
default with my class are just using
Java serialization but you can customize
it to use anything you want so there's
cairo protobuf because Java
serialization is really bad and slow so
you need to customize it yourself so
yeah what was your question
you know they're just kind of different
models for reactive I don't really know
him that well to be honest with you Ivan
sodium so I don't know really what the
difference is is I think they're just
different ways of building a reactor
applications so well there's the whole
lot of reactive streams initiative and
the idea the reactive streams is to be
able to send streams of messages between
different systems and I think that's one
of the ways that we're going to be able
to do communication is the idea of
sending your messages between a singers
boundaries between different types of
systems and so like Netflix and rx Java
and everyone's on board with this
reactor streams and I think the ideas to
how this is like a way of communicating
between these different reactive systems
so yeah yeah that was his question about
monitoring which we really don't have a
good solution for that today of like
keeping like you want to know like yeah
like how full your mailbox is and like
how much man yeah we don't have a great
solution that's something we're working
on so come on yeah come on have you used
come on yeah come on is it's a newer
it's just it's they just started about a
month ago it's an open source project
for akka actor monitoring we're hoping
they'll be able to pick up where we left
off what we're doing underneath the
covers is we're basically going to be
exposing this through like JMX
and we're going to tie into third-party
monitoring tools like kamon and cake
solutions has a monitoring tool that it
will be all the ID monitoring for all
these kind of things yeah yeah yeah yeah
yeah oh I'm sorry
it joins a seed node and then it sends a
gossip message to basically gossips to
the other nodes in the cluster that my
state has changed here here's my state
so doing just a c-note and and it's the
c-note bootstraps and Marx is up and
then you just gossip you basically
passing that state between the nodes
gossip protocol that the gossip protocol
does is you have a list of all the nodes
in your clustering and you randomly pick
like five or ten nodes to Gaza to and so
everyone you can imagine Bowser
clustering and I'm just randomly picking
five nodes my ring and saying that
here's the state here five nodes here's
the state here so what is your question
yes yes you can create you on like
router algorithms and over the balancing
algorithm plug it all in yes yeah yeah
go ahead
actually what time a greeny wrap-up I
can talk to you guys afterwards outside
we need to wrap up thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>