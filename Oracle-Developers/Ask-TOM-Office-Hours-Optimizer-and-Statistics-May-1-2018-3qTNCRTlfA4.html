<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Ask TOM Office Hours: Optimizer and Statistics May 1 2018 | Coder Coacher - Coaching Coders</title><meta content="Ask TOM Office Hours: Optimizer and Statistics May 1 2018 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Ask TOM Office Hours: Optimizer and Statistics May 1 2018</b></h2><h5 class="post__date">2018-05-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3qTNCRTlfA4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so hi everyone my name is Nigel Bayliss
I'm the optimizer product manager you
can follow me on VL d B which stands for
very large database Bayliss which is
really some of my background I had in
very large databases I've been the
optimizer product manager for two or
three years something like that started
really out with 12 - so during the
development to 12 - is where I became
part of the product management team for
the optimizer so I maintain the the
optimizer blog and generally speaking I
try to answer questions you know that
kind of in the gray area during the
optimizing the database what have you
fir I think for the sake of this session
I'll probably if the question sort of
outside the scope of the optimizer my
just partner and cur and then we'll move
on but I'll you know I'll do what I can
if it's outside scope the optimizer so
um and you know this is about POCs the
motivation behind this was that i heard
from the real world performance group
you may come across in oracle that a
number of POC is going on around the
world and occasionally people are
running into issues with optimizer
settings and certainly you know when you
hit say two LC for the first time
there's quite a lot of differences say
between 12 seen in there and GU indeed
18 see and kind of take people a little
bit by surprise and it can cause issues
in POC is where you've got limited time
everything's got core work first time so
i thought i'd do a session sort of clear
up those types of things so these are my
suggestions if you like so these are the
sort of broad concepts and the keep it
simple stupid situation where so just
say you aware of my background before I
worked in product management I used to
work in the solution solution center for
the Oracle when we did a lot of
proof-of-concept so kind of lived
through this for a period of something
like seven years or so and I'm trying to
put some of what I learned from doing
those that job into this session to
cover the sort of things that we got
into and the things that I found worked
and the things I found didn't work so
the things I'm going to cover here are
how to kind of start with a good
baseline
keep it simple basically then how you
can go about prioritizing stability and
consistency because one thing you don't
want in a POC is if you for example have
a particular workload that you're
running through the system you don't
want the performance of that to keep
changing in a way that feels
unpredictable you need to kind of get a
grip of things and be able to
consistently rerun things and measure
the effect of change in fact so that's
the other thing how do you kind of
control change you're the optimizer and
I'll show you what the optimizer does in
terms of adaption
because in 12 from 12c onwards we kind
of had the ability for the optimizer
sort to adapt over time so I want to
just cover that how that works
and what you can do to gain control of
it and understand what's happening and
in the final thing is to keep moving
this is a kind of important thing which
is to avoid getting kind of bogged down
with things and I certainly see this
quite a lot and I'm still in touch with
a lot of POCs that happen around the
world and you can see sometimes you know
there's a tendency sometimes to get
stuck and fixated on particular problems
and that's again something hopefully I
can help you to avoid by I'll go through
this session
so the big changes with an 12c release
one were the adaptive features we
introduced for the optimizer and that
split into two branches which is
adaptive plans and adaptive statistics
so on the left hand branch we have
adaptive plans and this is something
that happens at runtime and it's
actually quite easy to understand it's
not something that really is anything
that's particularly different from what
you've probably seen in the past in
terms of you know how to get to grips
with it and understand it
the adapter statistics is where the
optimizer learns or adapts over a period
of time so this is something that's
quite new and if you're not used to it
you know it can be confusing in the
context of a POC where you're trying to
get consistent runs one after another so
we take a look now this is quite an
overwhelming diagram but what it tries
to encapsulate really is that the data
dictionary is a repository where we
persist information about what the
optimizer has seen or measured and what
have you over time so I think the key
key phrase those over time so what that
means is that we actually are persisting
metadata and adapting statistics over
time so that means to you particularly
proof of concept is that if you run
through something once this process is
happening so if you run through the
process again you may see differences
and that's really the whole purpose of
this adaption is to make change and to
improve things over time so you've got
essentially metadata that's persisted to
the data dictionary inform sequel plan
directives and also we're gathering how
columns are used in predicates as well
so that's something else we collect over
time and in fact there are a number of
feedback loops in operations so secret
plan directives as we create them we're
learning about cardinality missed
estimates that we see when queries
execute and that can initiate dynamic
statistics so in other words we can
execute
where is to to gather data on the schema
that you have any applications and that
changes over time and also in 12c we in
enhanced cardinality feedback as it
wasn't 11g that's rename statistics
feedback in 12c but also we added
cardinality measurements for joins as
well as single table cardinality there's
quite a change here what the net effect
of this was that 12c is more dynamic in
its plans you'll see plans change more
frequently and again that's not
necessarily what you want to see in a
proof of concept it can kind of mess
with your stats so to speak but luckily
you know it's easy to understand once
you get to grip with grips with it which
is really what this session is about ok
so basically remember that the optimizer
adapts over time so the sequel execution
plans that you have made change over
time so run one may be different to run
two may be different to run three so you
have this sort of effect of adaption so
you might not see this kind of
consistent performance between
individual runs and then there's other
things that you should know I'm the
adaptive statistics from it does have an
overhead so you have dynamic statistics
so these are physically queries that we
execute in order to sample data in the
schema so if you have a lot of hard
parses then you're going to start to see
that overhead so it's something that I
think was seen quite often in some proof
of concepts because there are a lot of
systems out there that hard pass
frequently so of course as you I'm sure
you're all aware those frequent hard
passing from an application standpoint
is not best practice but you know
reality does get in the way do see
reality really you know the reality is
that you have applications that are hard
pass frequently and so you may see that
overhead so you the this the net effect
is that you have more dynamic sampling
crews that are executing in than they
did
in Oracle database 11g and sometimes on
some systems that may manifest itself in
longer past times and some latch
contention you may see some a steal at
contention which being fixed actually in
12 series 2 but it was certainly
something that was seen in release 1 so
how do you deal with all of that
and how do you know if you like get to
grips with what's happening luckily it's
very easy so when you execute queries
when you execute your proof-of-concept
workload you're gonna generate metadata
so in this context what I mean by
metadata is we actually gather column
uses information and we gather these
structures called sequel plan directives
which sense you'd remember predicates
that are used in queries that give
cardinality Mis estimates there's a
knight actually quite a cool mechanism
of really keeping track of where
cardinality miss estimates are happening
and then keeping track of that and
making use of that information to
improve other queries in fact different
queries potentially but this metadata
when it is created affects then the
creation of histograms and it affects
the creation of column group statistics
so in other words you can generate
additional statistics to support the
queries that you're executing over time
but these changes of course can affect
your run so one of the key things with
proof of concepts that then can become
an issue is if I have run one why
doesn't the performance mass run two run
three you know that's the sort of thing
you generally aim for and want to
prioritize in the proof of concept and
you can see this happening so if you
want to see actually physically look at
this metadata in the database you can
see sequel plan directives in DBA sequel
and directives and you can report on
column usage so you can see what columns
are being used in queries so that you
can see for example that particular like
a primary key column is being accessed
in equality predicates and so on so this
this is all useful information the
optimizer gathers over a period of time
the effect of that metadata is
potentially
to create new histograms and also new
extensions column groups against tables
all of this data is visible so it's the
sort of thing you can see easily but how
do you control it how do you kind of get
to grips with all of this to make sure
that your your runs are consistent and
you're in control of the proof of
concept so first and foremost they are
gathered or created when you gather
statistics so if you have sequel plan
directives you can create column groups
when statistics are gathered similarly
histograms can be created if you're
gathering statistics with a default
which is four columns size auto and
we've got this column usage metadata so
this is default behavior so you may get
a new histogram and it's no longer
default behavior in 12:1 you may get
your column groups
so what settings should use to gain
control over your workload for a proof
of concept so as I mentioned in 12c
release one we introduced optimizer
adaptive features and there are two
branches to that adaptive plans yep
sorry Chris yeah so Stefan is just
asking about histograms or how do you
handle unstable histograms
implementation with Oracle a 4-12 one in
pocs yes what's your recommendation were
not using NDB indistinct values
algorithm for histograms missing popular
has been has been something you've seen
in the past and there being one or two
bugs associated with that as well so I
think the missing popular is something
that we are have kind of dealt with so
the in 12c release to and onwards i
think you're going to see fewer
instances of the missing popular I guess
there are edge cases where that's
possible still some I think something
that's something be we've been working
to fix in fact the whole idea missing
popular if you mean in the concept of
proof of concepts then what I'm going to
propose actually is that you can again
control over statistics gathering
because it is something of course that
changes the environment so what I'm
going to do is actually cover how to
manage statistics in a proof of concept
actually so you can avoid those kind of
changes that affect potentially the
performance and of a proof of concept
but in the in a sort of production sense
it's difficult to have an absolute
answer to that because it's so dependent
really on how you gather statistics how
you how you kind of manage tables in
general how your data changes over time
how it might affect your particular
queries the type of queries you have
it's kind of difficult to come up with a
a one-off answer to that other than the
missing popular issue I am aware of we
have seen that but that's something
that's been quite aggressively addressed
I would say of late to avoid that issue
because I know there were things like
penultimate popular values missing and I
have saw as case relatively recently
about popular values that are missing
and again that was a bug that some we're
fixing so I my assumption is that those
kind of issues are going to fade away
pretty rapidly but I know what you mean
and though exactly what you mean okay
saying release two we changed the way
adaptive features were controls and
we'll split them into two and they are
now controlled by two parameters
adaptive plans and adaptive statistics
and now we made this the default so in
fact this is great news for proof of
concept goes because the right hand side
is these by default turned off and this
is quite a significant effect on the
ability for you to run runs consistently
one after another so we'll take a close
look at what that's done but the great
advantage with this now is that when you
run a workload in a proof of concept and
you use the default features then you
can expect very consistent performance
across runs and I think this is the
thing actually I want to really
emphasize in this session that one of
the key things that we are aiming at now
is that you use the defaults and the
defaults gives the best results for the
most workloads so basically what you're
going to do what the advice is in this
deck is really to always try new default
settings where as possible and if you
like start with that so that's part of
the keep it simple baseline we keep it
simple baseline it's going to be about
using default
so
so I almost laugh when I see this
picture I must admit because of Cour
it's quite a busy one but the idea
behind it is really just to show what
the defaults look like so what that
means what the defaults actually mean is
that when you gather statistics for all
columns Auto you will see new histograms
ask them the recommended best practice
and the sort of thing you would
typically use in production system an is
something you would typically I would
say used in a proof of concept as well
in terms of what the defaults do on
their right hand side of this diagram
basically you will create sequel plan
directives but they're not going to be
used so what that means is that this
sort of loop of adaption here isn't by
default enabled so it means you collect
information about cardinality miss
estimates over time but that information
is not acted upon so you keep the
information but we don't feed it back to
change sequel execution plans so in
other words you're going to get much
more consistent results as you run one
and run two and so on the other thing to
know is that single table cardinality
only is used in statistics feedback this
is kind of a technical difference but
what the effect of that is is again to
make this little loop here where we kind
of learn between executions it makes
that loop more stable so in other words
you're less likely to get new sequel
execution plans when a query is
repeatedly executed so it keeps this
kind of loop more consistent and in fact
it makes it behave in a way that's very
similar to the way 11g behaved so if you
are for example testing on a 12 C or 18
C data beta you previously were on 11g
you can expect to see more consistency
when you run on 12c you're gonna see
basically were close behave in a very
similar way as they did on 11g it kind
of gives you that sort of it lessens the
step if you like
so the default adaptive feature settings
that we have now in 12c from 12c release
to onwards prioritize consistent
performance okay which is again good
news for proof of concept the idea is
you get consistent performance between
runs
so what are the recommendations for 12c
release one so in fact I I suppose I was
a little bit surprised to learn that
there are quite a number of proof of
concepts that are still running on 12c
release one so I wanted to cover that
here because 12c release one is perhaps
the one with the most information as you
can see again another pretty busy slide
so from 12c release 2 onwards the
pictures actually incredibly
straightforward I hope you agree so I'll
get to that in a minute so if you're on
12c release one and you're running a
proof of concept the key step really is
to install the latest proactive bundle
patch and what I mean by the latest it's
really in fact greater than equal opto
by 2017 which is where we made these
changes so I think we're on that we've
got April out now but as an example
January 2018 this is the patch number
apply that patch and then there's a note
on how you have to enable the changes so
what does this do essentially what it
gives you is the control in 12c release
one that you have available to you in
12c release two so in other words it
brings the behavior of the optimizer in
terms of adaption from 12c release 2 and
applies that to 12c release 1 so if you
apply this bundle patch the changes are
not enabled by default so you have to
essentially switch them on and there's a
procedure to do that and that's
documented in this note here so very
very clear recommendation is if you're
running a proof of concept on 12c
release 1 apply the proactive bundle
patch enable the new adaptive settings
and then
set them to the default values
essentially so that's the key again um
basically recommending these default
values and this gives you your stable
initial baseline okay and to do that
these are the parameters you set you set
adaptive plans to true which is the
default adaptive statistics to false and
also you set global preferences the auto
stat extensions to off so that's the
switch that decouples the step between
secret plan directives and column groups
I'll give you a little diagram about in
a minute
if you're using 12c release two you use
the defaults so that means you don't in
fact need to put any optimizer
parameters in the parameter file in your
SP file your P file you just let them
take the default values which are
adaptive plans are true adapt estas to
false and again this should really be
the default but it doesn't hurt to
executed to set the global preferences
for auto stat extensions off a teensy is
exactly the same so again a teensy the
the the recommendation strong
recommendation just fuse the defaults so
that gives you something that looks like
this what you will see a sequel plan
directors will be created but they are
not used so they don't affect lat
so you will see a kind of consistent
sequel execution plan statistics
feedback works in a very similar way to
the way it works in 11g so you can
expect against all your plan behavior to
be very similar in 12 C and 18 C as it
was in 11g and again we're not going to
be generating any column group
statistics so we gather sickled plan
directive they just are gathered and for
later use if you want them by their cat
and then histograms are created just as
we always have by default from column
usage statistics information adaptive
statistics if you do want to try these
in a proof of concept this is the sort
of thing that you may want to run a test
for they tend to be better in DSS or bi
style workloads for ad-hoc queries
longer running queries where additional
overhead required to come up run
dynamics something queries dynamic
statistics queries it's worth taking
that time the optimize are taking time
to get better plans but advice really
start with the defaults if you want to
test it then run a specific test in the
proof-of-concept and measure the
distance if you difference if you want
but yeah sometimes it improves these
kind of workloads it's particularly good
at these but again you need to test you
need to just find out whether it's
something that works to you though
remembering that multiple runs might be
required because adaption takes over
time but the good news again is that
sequel plan directives are created even
if adaptive statistics is set to false
so it does mean you kind of gathering
that information when you run your
workloads that is what's going on all
the time okay
and once you've run a test you can set
adaptive stats to false to restore the
behavior you had beforehand but remember
that if you've gathered statistics in
the interim you may have new collin
group statistics or new histograms so
just bear that in mind
okay other recommendations obviously I
think this goes without saying to
gathers just stats for your application
schemas just as you would in an upgrade
it's good to get a solid baseline make
sure your statistics are all gathered
beforehand gather dictionary and fix
objects statistics as well you need to
do that as per the kind of directions
that are in the documentation Docs
pretty good on this actually very clear
about I should gather fixed objects
that's and issue stats so gather that
once your scheme is established system
stats if you don't gather system
statistics already then delete them and
restart the database that's make sure
you're not inheriting any values safe
from your previous system or a different
system if I know there are people out
there some customers out there that have
their own preferred settings and maybe
gather them or set them but the current
recommendation actually used to use the
defaults the defaults give generally the
best results so if you are gathering
them setting them using statistics in a
certain way it's a good this is a good
opportunity to kind of reset that and
think about whether you should in fact
follow the current best practice which
is again to use the defaults so my
advice is use the default system stats
if you want to include a specific test
you mean obviously go ahead and evaluate
that so I would you know if you if you
are kind of convinced or very happy with
your settings then maybe that's
something you want to test and if you do
find significant differences between
them they take some time to find out why
so I think this is one thing that is
again something I want to emphasize with
the proof of concept that I've seen many
where a workload is run through and
there's maybe one query that is an issue
one query as a regression and it's the
kind of the work
as a whole is seen as a fail or or an
issue so it's I think very important if
you are comparing performance the
performance of different changes is to
make sure that the proof-of-concept
includes time to figure out why or what
is the difference so this is where
things like a double WR and a DDM are
fantastic for you know getting a look at
what is the actual difference between
this run versus that run and be very
wary of making a change like this and
then making the basic assumption there
it's good in this case and bad in this
case I just really strongly recommend
that you you use the tools or gives you
like a WR IDM to figure out what are we
seeing here are we seeing an individual
query because generally speaking you're
not gonna see kind of like a magic
happen you're not gonna have sort of a
magic setting of course that makes
everything execute fabulously or execute
terribly it's never really a black and
white it's off the shaded gray so my
advice is use the defaults if you want
to test the difference with say you have
prefer a preferred procedure and you see
a difference take the time or make the
time in the proof of concept to figure
out why with the aim to try and use
defaults if you can defaults give you an
easier system to manage ultimately so I
think a proof of concept is a great way
to establish a system that is going to
be easy to manage in the long run that's
my sort of feeling about it so keep it
simple really there are a few little
gotchas you've got to look out for that
with different things that are changed
in 12c so one thing that a lot of DB ace
probably missed is that sequel plan
management evolution is now fully
automated in 12c and 18c so it's
switched on what that means is that if
you are using sequel plan management in
your proof of concept database you may
have sequel and base
that you kind of carefully nurtured and
you have sitting there and you use those
and they're used to control your work
you know your overall workload and they
adjust certain plans and so on but bear
in mind that if you're going to use 12 C
by default we can be gathering new plans
and they can evolve now that's not
inherently a problem but of course what
it does mean is that it can be a source
of change to your secret execution plans
that can be puzzling you know you've run
a take a run overnight secret plan
management runs evolve some plans and
changes some of you the workload
execution plan and then the following
day you get a sort of different profile
in performance so this is something you
may want to control you know you may
want to control when and how that
actually happens so one neat little way
of doing that is actually to allow
sequin plan management evolution to run
but tell it not to accept new plans by
default so this is how you can do that
because you may choose to disable tuning
advisor altogether so again you know in
a proof of concept is one of those
highly controlled environments where you
don't really want things to start
without your knowledge or without you
manually initiating them so again
something you may want to consider so to
be aware of that this is something
that's going to be going on in a
database next Auto stats first thing is
that you probably doing unusual things
on a proof of concept database things
that you've not necessarily done on that
database before no no that means that
you may get stale stats more often than
you had them before you may get changes
in column usage new histograms all of
these things can happen because you're
doing something that's different on a
proof of concept database in which case
you may want to control very carefully
statistics are gathered I think you
probably do I mean it's something again
you want to kind of gain gain gain
control of so recommendations for that
are but to set global prefs Auto stats
target to Oracle in that way our cool is
going to maintain the Oracle schemas
because if you don't do that and you're
running a lot of workloads through there
is a risk that the amount of data that
you have in the data dictionary he's
going to change shape quite
significantly and then you can have all
sorts of odd effects like you know this
queries like a WR or something like that
that can take longer than they should
because statistics are no longer up to
date so key thing really is to make sure
you do gather statistics on the data
dictionary but you may want to you could
disable auto stats collection entirely
but I think this is a this is not a good
option I think this option at the top is
the best and then at least you're going
to maintain data dictionary stat so I
would choose this option at the top you
can manually gather stats of course like
this and also you can initiate auto
stats yourself manually so in other
words you can simulate the effect of
running the auto stats job bear in mind
of course that if you're running these
kind of jobs they may take longer in a
proof-of-concept environment because
you're doing things that are unusual so
just bear that in mind that you can get
a different profile of gather stats on a
POC database it may take long but the
normal because kind of doing a lot of
unusual stuff on a proof of concept
temporary tables another thing to bear
in mind and that is pre 12c statistics
on global temporary tables with a shared
across sessions by default that's
basically how they work then in 12c we
added the behavior to allow statistics
to be private to a session now that's
that's a good change but if your
workload doesn't know that that's
happening then it can cause issues
sometimes so I have seen cases where
this is court people hours what it means
is that if you for example have a work
flow you'll say a batch job that you're
testing in the proof of concept that
gather statistics on the global
temporary table and then you fire up a
whole bunch of separate jobs that
they're dependent on those statistics in
12c by default they won't see them
because by default they will be session
private so that's something you may need
to think about and set the global press
the global tempt a Buhl's that's shared
so if your workload doesn't take this
into account you can see differences in
performance on global temporary tables
so basically it's a red flag so if you
are running a workload and a lot of that
workload is kind of being handed down
through a series of jobs that are
executing on a global template able look
out for that that could well be the
issue that you're running into
so so really we getting stats so of
course you may need to gather stats at
some point you might get new histograms
because of course what you might want to
do of course is over time we are
essentially adapting histograms to match
the were load so we will create
histograms in order to improve the
estimates or the cost estimates the
queries are going to have so it's
against something you may want to change
take advantage of of course you're
likely to want to take advantage of it
but I suggest you want to do when you
know it's going to happen
so I'd say you know at some point you're
gonna read out the stats and then you're
gonna take stock we run a workload
through again with new statistics kind
of a typical kind of test you may have
so bear in mind you know if you see
things like planned changes regressions
and you suspect it may be induced by
stats then you can restore that in other
words so you can gather and then peel
them back in time so it's a very nice
trick in a proof of concept to be able
to do that and I think it's something
that you probably don't necessarily do
on a day to day basis so it's kind of
easy forgotten you kind of get into this
state where you've made a bunch of
changes some of them may be involving
new statistics and now lots of things
will change how you do kind of Rican
gained control of that and understand
how is it because I change X because I
change sistex remember that you can
restore them to a point in time there's
a really nice cool feature for use in in
benchmarks and pre-hook concepts also
you don't have to publish stats so again
it's a nice little trick to be able to
say gather stats don't publish them test
them so you have a parameter saying use
the pending stats I've gathered find out
what effect it has on your workload and
then if it's a good affair everything's
good and you kind of happy that you
understand you can then publish them so
these are nice ways really of just
gaining control of of managing
statistics in a proof of concept it's
all about managing change
things so that then you always know what
you've changed and you can be confident
as well that if you're unsure whether it
changes has had a negative effect you
can undo those changes as well okay
we've had a couple of questions come in
Nigel yeah this one so we're saying on
twelve one yeah if you're using the
method of all column size one says know
about these stats we don't see any
virtual columns does it stop collecting
adaptive plans as well what does it I
guess it's just okay so if you're using
for all columns size one let's take a
look if we look at this okay hopefully
this diagram I can be relied on to be
understood a little bit but what that
break if you put for all columns size
one it cuts this step here so
essentially it prevents column usage
information from being used to create
histograms so essentially of course
you've disabled histogram creation as it
happens but it kind of cuts that link in
terms of this right hand side it does
not affect that so this right hand side
actually behaves in exactly the same way
so if for example you have Auto stat
extension setter on you can still
generate those even if for all columns
size one is set so for all column size
one is basically a histogram control
effects this side okay this side only
it doesn't affect this sort of overall
adaptive features yeah it kind of saying
that is a little bit sloppy actually cuz
because it does affect cardinality
Esther so histograms have an effect on
cardinality the whole purpose of
histograms is to improve your
cardinality estimates so in fact what
that does do is that it can have a
beneficial effect here on the optimize
the optimizer start seeing its estimates
improve and if the estimates improve
then the sequel plan directives are not
required so what can actually happen is
that the usage of sequel plan directors
is reduced and really that's the idea
behind this is that the we augment
statistics down here in order to make
sequel plan directives less relevant
less needed and that's in fact what the
optimizer does because as it sees these
things being created it may then alter
the status of the secret plan directives
and essentially stop them from modifying
the plans that's kind of what that's how
they sort of whole loop works so it has
a kind of a global effect so to speak so
overall things kind of settle down
that's basically how it works we gather
information here we gather information
here and then over time as you gather
statistics the whole thing feeds back
and the system reaches more of an
equilibrium and it's kind of interesting
because you know it's the problem has
been sometimes is that you you're not
aware that this equilibrium is coming
and you know you're in a position where
you're kind of running a workload
especially in a proof-of-concept you run
it run it run it run it and you're going
why is it different why is it different
it's bad it's not you know and you kind
of in a sort of I sometimes see this
sort of panic mode set in where it's not
really your not really understanding
what's happening and a lot of this is
about understanding and you know if you
are prepared to put the time in and
understand that this is a sort of a
process of adaption over time you can
see great benefit with it and but it's
difficult for me to say that
unequivocally that you will and also in
a proof of concept you don't always have
the time so this is almost really why I
picked this topic with proof of concept
because a proof of concept is really a
fairly easy system right you want kind
of consistent results that are pretty
good you want them fast minimum effort
and you want things to be consistent
so that's what this is about in a
production environment it's more
complicated and you know over time these
kind of features can add benefit but you
know it's more you you've got to think
more carefully about how you do it and
it's more difficult for me to say dou X
dou Y because it depends really on how
you manage your system how you prefer to
look after it what how you gather
statistics even that affects this this
as well of course it affects what
histogram to create so you know
production system is more complicated if
you want to kind of manage everything
having said all of that these features
are designed for you to just switch on
and leave and and I think what we found
is that the defaults that we have chosen
are designed to do that
so if you use the defaults you're in
good shape and most workloads will just
work absolutely fine with the defaults
so that's that's the recommendation
the the risk I do have a flavor of this
diagram that talks about parallel so in
the parallel concept in context when we
hit 12c release one parallel queries
would quite frequently execute these
dynamic statistics queries only in fact
some of them took longer than they
should have to run there was a there was
a period actually where they weren't
they they took a long time to execute I
don't think it was that they weren't
timing out quickly enough so there was a
phase where they started to had quite an
overhead to parallel execution so this
was something that was seen and was
addressed but in fact in 12c release two
we did change the behavior so what does
that mean it means that in twelve one
parallel execution did generate a lot of
dynamic statistics queries in 12c
release two it's fewer if you use the
default settings you will get dynamic
statistics queries but you'll get fewer
and they tend to be more targeted more
faster running so what that means for
you then it's a fused parallel execution
and you use the defaults it will behave
in a way that you're familiar with and
similar to the way it behaved in 11g so
again it's the kind of keep it simple
don't try and overthink parallel
execution use the default now you don't
I would say you don't as a general rule
have to micromanage the optimizer
dynamics that setting leave that default
to let the optimizer decide when it
needs to run the dynamic statistics
queries it will run them in 12c release
to an 18 C but it's less aggressively
let's say one way of putting it I guess
is that you will see fewer of those
queries being executed but they will
they will be executed but less so
so again user D for optimizer dynamic
sampling set to two I mean obviously
there are cases where you find
in altering that but again you know keep
it simple start simple and then if you
make change understand why you're doing
it and make sure you measure the benefit
that's the see my second give them
okay more general recommendations right
okay think holistically this is actually
for my painful experience and then
seeing others I kind of suffering in the
same way that I did which is consider
the overall picture right it's so easy
to get caught up in neither one bad
query and so try and avoid
micromanagement you know that's the
thing that he's really trying to avoid
it at all costs are basically you've
always tried to live by this that if I'm
over managing something then there's got
to be a better way and the other thing
that's nice if you haven't used them
look at things like test case builder
and sequel T which is the support to all
those links later on use these to
capture if you've got a plan that isn't
great capture it you know keep it and
then you it's something that's great
because often you know improve of
concepts I I can't tell you how many
times I've heard we had this terrible
query kind of made things miserable for
us but now the system's gone we had a
week to do this and now it's gone think
about using test case field or sequel T
to capture that at least so at least
later on you can take a look and make a
judgment about whether because you know
I think most of us on this call know you
can do you know Oracle's very good at
getting us out of trouble it's just the
question if you know figuring that out
but use things like sequel tuning
advisor it's all there for you to try in
a proof of concept oh I love this bit
use a service level agreement to guide
what is important and what is not and I
love that because as a consultant I used
to say I used to do this a lot which was
if I would go to a customer they said at
a performance problem and I would say
what does the service level agreement
say about this you know it's you know a
performance problem is not a problem
unless it affects the business it's my
way of thinking really and I know this
is kind of a slight this is I'm this is
a slight joke on my part I gotta admit
because an SLA exists like the joke so
but
it's part of thinking holistically does
this really matter that is the key you
know if you're if you've got a bad query
in the workload but the workload is 10%
faster than it used to be that for me is
job done but you know everybody's
different but just try and kind of step
back a little bit it's definitely my
advice but these tools are great look at
this as a way of catching things that
have happened later on yep think
allistic optimizers are not perfect
shock horror they use estimates let's
say what I do sometimes T is sort of
need to kind of chase to bug something
and get fixated on chasing a bug I I you
know I did this for seven years on
exadata and we never raised a single bug
we never chased a single both we'll just
work around things and in a proof of
concept that's really what we I think
that's the best advice I can give you
know you can usually find a way remember
things like C tuning advisor use it you
know use things like plan stability
features and what I mean by that is you
can use things like secret poem
management you can use sequel patch you
can use these features to control plans
if you really need to okay I'm gonna
give you more I think I'll do a later
session on this in fact also we used to
do this used to be a part of as which is
sometimes you know you see applications
that are flooded with with hints and you
might want to try seeing how it behaves
without that and he used to be a party
piece of advice actually to turn hints
off and run workloads through it can be
quite enlightening sometimes no it
really it really is a good day if you're
you know if I were a DBA and I was an
application that was hinted to pieces
like in a total hint storm take a look
at what would happen if you killed the
hints so yeah I think this is really a
summary
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>