<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Decompose That WAR! Architecting for Adaptability, Scalability, and Deployability | Coder Coacher - Coaching Coders</title><meta content="Decompose That WAR! Architecting for Adaptability, Scalability, and Deployability - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Decompose That WAR! Architecting for Adaptability, Scalability, and Deployability</b></h2><h5 class="post__date">2015-06-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AUsFNri5hFk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well thanks for picking the session I
know there's sort of lots of choices and
it's probably been a really long day
so welcome so over the sort of the next
hour I'm gonna really talk about sort of
the downsides of building these large
monolithic applications you know I'm not
not entirely sure what large is
precisely but just really big and even
though there's war file in the title
it's not really limited to just that but
the idea of just having a big monolithic
single kind of deployment unit of your
application what are the downsides of
doing that
and then talk about the benefits of
taking that monolithic application and
breaking it up into a set of services
benefits like improve deployability
improve scalability and also you know a
mashie makes it easier to adopt new
technologies when I was at JavaOne last
year talked with some people who were
still working on a struts sort of struts
and EJB to application something from
the deep distance path but if you build
a large application it so I'm gonna show
you end up being locked into those
technology choices that you made at the
start of the project and it's very hard
to adopt newer and more modern
technologies it's just out of interest
anyone using struts and EJB to here you
know it's sort of hard hard to get away
from it so you know before we get into
that a little bit about me so I grew up
in England and then moved to the Bay
Area 23 years ago which sort of accounts
why I think many of you have accents I I
got my start programming unless back in
the late 80s Lisp of course being one of
those very early functional and then
object-oriented languages eventually
ended up programming in Java wrote the
book pojos in action which was all about
how to use frameworks like spring and
hibernate which back in 2005 were these
pretty radical technologies though you
know today we we take them pretty much
for granted and then back in 2007 I
started playing around
with this obscure little thing called
Amazon's elastic compute cloud I think I
don't even know if the term cloud
computing had been widely sort of an
adopted certainly it was sort of not
hyped and that evolved into an
open-source project which ultimately
evolved into my startup Cloud Foundry
which was then acquired by SpringSource
shortly before spring sauce was acquired
by VMware and though I should say that
this is really not drawn to scale Cloud
Foundry was much more of a plankton than
a sort of multi cell organism though
though interestingly I actually for the
I'm actually now on on vacation so
there's been four years and I thought it
was time to move on and figure out the
next big project to work on so that
that's me when I'm not at JavaOne
anyway so that that's the agenda so I'm
gonna sort of talk about the downsides
of the model of this sort of monolithic
application how you know the breadth the
idea of breaking it up into a set of
services and then sort of talk about
various design issues like well how if
we break a system up into services how
do those services communicate and then
I'm going to introduce the idea of an
API gateway which sits between your
front-end application and all of those
back-end services that you've now
introduced and then sort of talked a
little bit about well if I've got this
ginormous application how do I go how do
I break it up into a set of services
there's some really challenging issues
there so let's get started so imagine
that you're building an online store
sort of yeah amazon.com type thing you
know you'd probably come up with an
architecture that looked like this so
you'd have the storefront UI the
presentation layer you'd have a variety
of back-end services product info
service that's storing you know product
descriptions a recommendation service a
service that was tracking reviews so
it's so on and then you probably used
you know various technologies like you
know years ago I gave a talk at JavaOne
with Kyoto man and we had JSF on the
front end and though today I probably
use spring MVC and then on the back end
I'd you know use technologies like
spring or hibernate or JPA or you know
there's a whole bunch of option so you
actually build some kind of modular
architecture but then what would you go
and do you'd go and package it up inside
a war file so you take all those modular
services build this one war file out of
it or perhaps some other kind of
deployment unit and then you know run it
on Tomcat in some kind of data bases
right so we've sort of gone from a
modular architecture to a sort of
monolithic deployment architecture and
then there's various reasons for that
number one I mean it's pretty simple to
develop applications like this our tools
are all oriented towards building web
applications it's simple to test and
it's simple to deploy you just copy it
onto a tomcat server and it and it gets
deployed and it's also easy to scale you
just run multiple Tomcats with a load
balancer in front and you've got some
kind of scalability at that point the
problem you get into is that there
really are various drawbacks of this
architecture number one today users
expect this rich dynamic interactive
user experience it's no longer good
enough to just serve up HTML to a
browser you know that that's just very
old-school it doesn't provide the best
user user experience and so what people
are doing today is actually building
applications that run in the browser
where the model-view-controller pattern
actually exists there or or in many
cases they're building native apps that
are running on on smartphones and the
server is really just so exposing
restful endpoints and pushing events to
to to the applications so sort of the
whole architecture changes at that point
so that's just sort of one basic problem
with sort of our traditional java web
application just serving up HTML and
then there's just problems to do with
having a large monolithic application so
number one it actually intimidates
developers so I'm sure we've all had the
experience of joining a project where
they built this massive system and
you've you join and it's like well where
do I get started how do I build the
system and that's the direct consequence
of just the complexity of a big
monolithic system it also ends up being
an obstacle to frequent deployments so
you make a little say you're working on
the UI and you want to push that change
into production will you actually have
to take package it up into a war file
redeploy the entire thing even though
you just kind of want to touch one part
of the application and that can have all
kinds of consequences it could interrupt
long-running quartz jobs I've had that
problem in my application they weren't
designed to be sort of interrupted and
then and in general you can all have all
kinds of unintended consequences when
you deploy or when you deploy a large
complex application so it's sort of
there's an element of risk and that not
only that is because in this
architecture you've put all of your eggs
into one basket there's just this one
thing that you have to deploy you really
really have to get it right and so that
leads to a fear of change which ends up
with like extremely long QA cycles I'm
sure many of us are experienced the
situation where we commit our changes
and then it's like weeks before the QA
folks have actually gone through and
exhaustively tested the entire
application in all so that they can then
push it into production so that really
slows down the frequency at which you
can deploy changes if you're working on
the UI it makes it very difficult to
iterate rapidly you want to you know you
want to run a B test and based on that
tweak enhance the UI and you really need
short feedback cycles and so it doesn't
really work if it takes weeks to get
changes from dev into into prod another
problem you have is that this is a
really interesting cuz the funny thing
is the horse does not look - look look
as if it's overloaded in any way and and
it's out in front but it's kind of a
cute picture so another problem you have
is you have a very large application
that's going to overload your IDE slower
the
you know the larger the application the
slower your IDE is the less productive
you are and likewise it's going to
overload the container the larger the
application the longer the container is
going to start up which means that the
longer the sort of dev test cycle
becomes so in other words the the larger
the application the less productive you
are a larger application is also an
obstacle to scaling development in a
large system we really want to take
engineering and break it up into teams
that work on specific functional areas
so we've got the UI team the product
info team reviews team and so on you
know that's sort of a nice way of
organising development the problem is if
we then all if everybody then has to
package the changes up into a single war
file that means there's a tremendous
amount of coordination has to be has to
happen between these teams you can
imagine a scenario where the UI team
says we're ready to push our changes and
then we're the back-end team says well
I'm sorry the chip the backend is broken
and so you have to wait and that that's
sort of a not a very good situation it
really prevents diff teams developing
and deploying independently of one
another and then another major problem
you have with this architecture is that
it really sort of enforces you to have a
long term commitment to the technology
choices you began at the start of the
project so you know for example a few
people here are still using struts than
EJB to and if you got a big system it's
really difficult to get away from those
technologies those choices and as you
know new things new and better things
come along periodically and you really
want to adopt them it will make your app
better and it will also make make it
more attractive for developers to come
join your team you don't want to be
stuck using old legacy technologies the
trouble is of course a rewriting an
entire application is a very risky very
expensive business and it's sort of
rarely done so there's a whole host of
problems with having a monolithic
so what can we do about it well a few
years ago I read this really interesting
book the art of scalability which was
written by some folks at PayPal and eBay
who you know and it's all about just
scaling sort of scaling the engineering
organization scaling the system and sort
of both sort of business concerns as
well as technical concerns and one
really interesting concept that they
introduced in this book is the scale
cube which is a three-dimensional model
of scalability so the idea is were along
the x axis you you have horizontal
duplication where you run multiple
copies of your app behind a load
balancer so that's sort of the standard
way of scaling your system then you also
have z-axis scaling or data partitioning
where the price say the primary key of a
row determines which server that row
resides on so that sort of standard
database sharding mechanism another
dimension to scaling and then the third
dimension is actually y-axis scaling or
functional decomposition where you
divide things up by functionality and
really most of this talk is about
functional decomposition and so when you
apply that idea to this monolithic
system you go from an architecture like
this back to an R back to a runtime
architecture like that like this one
where each module of your application or
each set of modules becomes their own
standalone service and so they're
collaborating and in some way and we're
looking to you know different kind of
communication mechanisms later so that's
sort of you know in a way that the big
idea in this talk is break up your
system by applying y-axis decomposition
into a set of services and then those
services can you can then apply x axis
and z axis decomposition to each of
those services to scale them
appropriately so you run multiple copy
run multiple copies of each service and
there may be some services like the
product info service would be shard
as well have z-axis partitioning and
there's various strategies for doing
this you could partition by verb so
you'd have a service that was
responsible for doing you know
performing a particular set of related
action so in an e-commerce system you
could have a shipping service that was
responsible for dealing with the
shipping of waters it's a verb or you
could have you could partition by noun
and have say the inventory service or
product info service that was dealing
with products the end the product
entities so that that's sort of a noun
based way of breaking up your system and
then there's some other kind of ideas
out there from say object-oriented
design so the single responsibility
principle is a good one and that's an
Uncle Bob our design principle that says
a class should only have one reason for
change so only should have one
responsibility so you could imagine
applying that principle to service
design as well services should have bit
should have a single responsibility
another analogy to adopt is sort of from
UNIX where you know UNIX is comprised of
all of these little utilities cat grep
find and so on each one performs a
little focused task but then you can
combine them in shell scripts and and so
on to build up more things so it's all
about small services you know it's sort
of to some extent how you break up your
system is somewhat of an art you know
there's sort of no sort of black and
white guidelines here you know you you
want to have make sure that you have
enough services because if you have too
few really that means you've just got a
few monoliths and so you you you haven't
solved the problems that you you were
trying to address and then arguably if
you have too many you could end up with
what some people call the Nano service
anti-pattern where you just have too
many services and it's sort of too hard
to understand the system there's which
is an interesting one I mean there's
definitely a runtime overhead with each
service because typically each service
is
at least its own JVM and in many cases
it's actually its own virtual machine so
there's there's overhead there and then
there's also a potential risk of
excessive nap Network hops where in
order to service a request you have to
cool a whole bunch of services
sequentially you don't want to do that
but you can interestingly you could cool
a whole bunch of services in parallel
sort of a scatter gather way of handling
a request and it doesn't really matter
how many services there are you still
get a good response time and then
there's sort of you know the more
individual pieces you have the more
harder it is to understand though in
reality if you the different this the
service is sort of reflect the logical
architecture of the system so you
haven't really no you haven't
necessarily introduced any extra
complexity by breaking it up at a
deployment time but anyway somewhat of
an art but just to sort of give you an
example of like how it's sort of how
extreme you could go here's a little
micro service that I wrote so it was in
a demo app and it's actually it responds
to incoming SMS messages that are
delivered via Twilio comm and it just
tells you the idea with this app is that
the user text the keyword registered to
a particular phone number and then the
app responds with a URL and that's
pretty much the entire app so this is
written using scelera that sort of as a
scallop web bit web DSL domain-specific
language that lets you write these
little micro apps and kind of
interesting you know it's sort of yeah I
wrote that deployed it left it running
even though the rest of the system was
changing and that sort of like captures
some of the philosophy behind this
approach little small services and it
turns out that if you look around most
large systems are actually work this way
so if you could look at Netflix you have
a really really good tech blog having
their various design issues you know
that's their system
have a lot of services running on top of
ec2 distributed around the around the
globe
likewise Amazon have a service-oriented
architecture like this as well and then
eBay or the same and what's interesting
is if you go look at the sort of the arc
it's the evolution of their architecture
I'm definitely Amazon and I think eBay
and also make possibly Netflix they
actually started off in life with a
monolithic system and then it got to the
point where this was not working for
them and then they refactored their
system into a set of services so it
seems to be sort of a common kind of
path that companies go through so
there's definitely drawbacks with this
approach it you know deployment and and
operations and sort of well actually
even development as well ends up being a
lot more complex
you know you've know inside your ID if
you want to test your application inside
your IDE it's not a matter of just
deploying one war you might have thirty
other services that you kind of have to
launch as well so there's some
challenges there and also at runtime if
a fault occurs actually identifying
where that fought the root cause of that
fault can be sort of at least time
consuming because maybe it was in
service a but maybe that was because
service a was cooling B and the problem
was there and then maybe it was problems
in service C and and and so on and if
each one of those services is managed by
a different team you've sort of got the
trouble ticket that's just like running
down the the the list the dependency
hierarchy until you get to the to the
root cause of the problem as interesting
Steve yeah he wrote some big rant about
Google but along the way he described
his experiences at Amazon and touched on
some of these issues and then another
problem you run into is just multiple if
you you know in addition to partitioning
the code the set the retinas or the
services you also tend to partition the
databases as well so
service has its own copy of has its own
database which means that well if there
were use cases which would normally sort
of which end up spanning multiple
database which now span multiple
databases you've now got some
interesting transaction management
issues and you really don't want to use
XA or anything like that and so that
implies a lot of careful design and
adopting approaches like eventual
consistency and so on and then at
development time implementing features
that span multiple services which in
turn communing multiple teams requires a
lot of thought coordination between the
teams and also the aiight actually
rolling out a new feature can also be
quite a little more challenging as well
and then another big issue as well when
do you use this approach in the
beginning where you have a simple system
and it's not dealing with a lot of load
maybe you really might not need this
problem this approach and if you did it
would slow you down and add
unnecessarily unnecessary complexity and
then later on gonna touch more on this
later and when you do need this approach
actually refactoring your system into a
set of services can be quite challenging
because of all of the intertangled
dependencies so there's some sort of
real-world kind of difficult problems to
solve
but despite that you know there are a
lot of benefits and I think the fact
that companies like Netflix and Amazon
and eBay and practically any large scale
system is architected along these lines
sort of illustrates that the that it
really is beneficial so number one you
know you have smaller simpler
applications and they're easier to
understand you know you're not
confronted with this massive monolith
you can look at an individual service
and it's good to get started as a
developer and it's easy it's a lot
easier to develop each service in
isolation
it also means reduce startup time which
interestingly on cloud platforms like
Google App Engine is a really important
issue
they time your time out your app if it
doesn't start up quick enough it also
solves the usual kind of jar file
classpath hell problem because I think
it reduces the size of the class path
and the number of dependencies and hence
minute reduces the risk of conflicts
which is good so in it you know you
could sort of say well we don't need our
SGI anymore I mean that's sort of
technology that's falling out of favor
anyway for a bunch of other reasons but
this approach actually really just sort
of makes for the most part OSGi
irrelevant and it also lets you scale
development you can break up your
development team and to function in two
teams that have focused on specific
functional areas and they can develop
and deploy and scale each service
independently with minimal coordination
between the teams it also improves fault
isolation as well if there's a bug you
make a change and introduce a bug into a
particular service only that services at
is going to be impacted by that change
it's not going to take down the entire
system which also sort of has the
consequence that well you can push you
can actually develop and deploy at a
much faster rate whereas before because
all of your eggs were in one basket you
had to be really really careful about
pushing changes into production whereas
in with this kind of architecture well
if you just kind of like you're not
going to break the entire system you
might sort of break one small part of it
but you're not and then you can quickly
roll back but you're not going to take
down your entire online trading platform
so that that's quite good
and then it also eliminates this long
term commitment to the technology
choices that you be that you chose that
the beginning of the project because as
I'm going to show you could actually use
different languages and different
technologies for different services and
not only that if these services are
small well you could just try we try
rewriting them using some fancy new
technology you had at JavaOne right
because the investment is fairly minimal
so that sort of moves us into this world
of these modular polyglot as in multiple
languages Multi framework applications
you've end up using a divide a diverse
set of technologies languages frameworks
inside your application and you can
think of you know your system now is
having two different levels of
architecture so you've got the system
level architecture that's this sort of
the traditional static slow changing
architecture that's dictated by people
who just use PowerPoint and that's yeah
well actually I mean I do architecture
too so I'm sort of criticised by like
keynote so so yeah so that's where
you're saying well these are the
services we're going to have and these
are the communication mechanisms that
are going to use and that's your sort of
traditional slow changing system
architecture but then each service has
its own architecture and you can make
your you know even individual teams
could make their own technology choices
provided that they implement the
required interface expose the right REST
API or interact with the message bus in
in in the appropriate way and it let you
know the teams that that level can pick
the best tool for the job and this level
is it's rapidly evolving because as I
mentioned if you wanted to try a new
technology you're free to do that you
don't have to rewrite a million lines of
code you could just write the few
thousand or a few hundred lines of code
that comprise that one service so this
this is really important it really lets
you easily try out other technologies
because there's a lot of options out
there today
you know I am fan of spring and haven't
touched DJ B's and years and so on but
you know I hear there's new versions of
EJB out there for example might be worth
looking at or there's other languages
closure there's other framework
like play and this if you want to build
a synchronous REST API is this spray and
and so on and you know there's even
server-side JavaScript that can be quite
useful as well so this this architecture
lets you try out these new technologies
and more importantly it sort of actually
lets you fail in a safe way because
you've just tried it out in the context
of a small service if it didn't go so
well you didn't like the end result we
you actually haven't invested much time
you haven't really risked much in trying
out this technology and you could just
throw it away and go back to some other
technologies so it really encourages
that experimentation and there was a
talk at Java zone last year about the
Guardian and how they went about
breaking up the monolith and they talked
about experiences like this where they
tried for awhile building some of their
services I think it was in Django didn't
like it so they went back to Java web
technologies and you know no harm done
so so it's sort of it frees you up to
experiment ok so so that's the big idea
break break up your system into these
services so that sort of now introduces
a you know a problem that we need to
solve how do these services communicate
there's a lot of options out there right
there's synchronous protocols like HTTP
there's also asynchronous protocols like
AMQP or JMS and then then in terms of
the messages that get exchanged there's
various formats JSON XML of sort of text
formats there's also binary formats like
protocol buffers thrift and so on and
yes you know many people are preferring
message oriented systems exchanging
Jason messages but for instance binary
formats can be a lot more efficient
because you don't have the overhead of
pausing the text so yeah so if we look
at you know applying a message based
system approach to this architecture or
I end up with something like this where
the service is a tight together using a
message broker and that sort of has an
interesting consequence of say you know
so when the storefront accepts an order
it actually you know sends a message to
the order service fire the message
broker and what's interesting at that
point well if the order service is down
that's okay in the sense that the
message broker will simply buffer up
that message and when the order service
comes back up and is it is ready to
process that order it will it will
deliver it so with the the UI can
continue to function even though the
back end is down obviously when it's
actually cooling into things like the
product info service or the
recommendation service you know that and
those services don't actually reply then
the the messaging doesn't kind of help
quite as much but there's sort of
various pros and cons to messaging the
pros so it decouples the client from the
from the server message broker is really
buffering up up the messages and can
smooth out spikes and traffic let the
consumer catch up or if the consumer is
down just save those messages until the
consumer comes back up and then it also
supports a variety of communication
patterns so you can use you can do
point-to-point messaging or you can do
publish and subscribe and some various
variations of that and then you know
they obviously some various cons we've
now got this message broker yet another
moving part in our system and
implementing a request reply style
communication which is very natural with
HTTP actually involves a bit more work
in a messaging system so some various
trade-offs there though the father
you've got this decoupling and the
buffering it tends to sort of push push
you in the direction of using a message
oriented approach and then it's various
technologies that will help like I'm a
big fan of spring integration so that
provides the building blocks of this
sort of pipes and filters architecture
that's described in that in the book and
enterprise integration
patterns and you can declaratively
define a set of pipes and filters that
process and transform and route messages
as they as as they flow through the
system and it what's really interesting
is that it can let you sort of change
the plumbing of your arc of your system
dynamically without actually impacting
the the application level components so
this means that you could have a
producer and consumer here it's an order
service and a shipping service that a
development time for user development
are actually co-located with in the same
JVM so the order service talks to a
gateway over it in memory channel that
then is connected to a service activator
that invokes this shipping service but
then a production time you you
reconfigure the plumbing and you put a
message broker in between those two
components so they're actually running
in different JVMs on different machines
and they're communicating via a message
broker but they don't actually notice
nothing has changed so you've got this
nice configure ability of your system
plus it's done declaratively which is
even better and then you know the other
option of course is synchronous rest and
you could say you know a storefront just
uses rest to talk to the back-end
services and in the case of say the
product info service recommendations and
reviews probably that would make sense
because it's expecting data to come back
whereas if it invoked if it uses rest to
actually do send the order to the order
service there's the requirement there
that the order service is up and if if
the order service is down then the
storefront will fail and the customer
will be unhappy so sort of not not so
good so you know pros and cons again
simple and familiar request reply is
easy firewall friendly is is good thing
if the part of the UI is actually living
in the browser and instead of within
your firewall and it doesn't need this
extra component extra message
but the downsides are is that it only
supports request reply you can't do
pub/sub directly with with it with HTTP
this the server has to be up and able to
respond as I mentioned earlier and then
a real basic problem is the actual
client needs to know the URL of the
service which in the distributed system
where servers are kind of constantly
going up and down and you as as you say
auto-scale that that's not an easy
question to answer whereas if they're
just talking to a message broker that's
one fixed intermediary that's a lot
easier once again you know technologies
like spring make make this kind of thing
pretty straightforward so you know I
like using spring MVC that lets you
define pattern routing patterns and also
the ability to extract parameters out of
URLs it makes it easy to take an object
and turn it into a XML and JSON and it
also makes it easy to do the inverse
take an incoming request JSON XML and
then turn it into an object so all of
the marshaling is happens quite
straightforwardly and there's you know
within the spring family there's other
sort of spring related or rest related
add-ons that deal with things like the
Haiti US hypertext is the engine of
application state which is sort of the
pure restful approach and so on so
there's a lot of different but there's
many other technologies for
accomplishing the same thing a lot of
options out there so that that's the
communication side of it so I now I want
to talk about this concept of a api
gateway for sort of front end server so
if you think about our system we've now
got on the front end various sort of
clients some of them are html5 and
JavaScript base other ones can be native
apps on iOS or Android and then on the
back end we've got a collection of
services some of them are exposed
restful api some of them X
both some kind of message oriented API
so the question we have is well how does
how does the front end talk to the back
end now in theory you know the browser
could actually access all of these
restful services directly somewhat of a
problem can be accessing a service
that's expecting to talk to a message
broker directly so there's sort of some
real kind of technical challenges there
but in practice it turns out to be
really really useful to put a front end
server between the two or an API gateway
and so you know so we now have an
architecture that looks like this and
the API gateway really sort of
accomplishes a number of things number
one it serves as a single entry point
into the system so the browser
applicable the front end applications
just know to talk to that gateway they
can't access the individual services
that are sitting behind that gateway and
then that gateway also offers up client
specific api's well that sort of ends up
being quite quite important for a number
of reasons so you could imagine that
you've got one kind of client is your
desktop browser app and that and the
date of the it needs and the you know
it's connected briar the Internet and
sort of a high-speed network and it's
got a ray rich user sort of UI it needs
one set of data from the back end and it
can also afford to make many fine-grain
requests and so the style of API that's
best suited to it is sort of has one
particular style but then if you look at
a mobile client either a mobile web app
or native mobile device they're
connected over some not-so-good wireless
network and they're and also the the the
UI tends to be sort of less rich and so
they actually need to make fewer course
you know coarser grained requests to the
backend and probably get back
upset of the data and so that's the job
of the API gateway it exposes one client
one set of api's to desktop clients and
different api's to two mobile clients
and then when a request comes in say
from a mobile client it would actually
fan out multiple back-end services get
all of the data from them package it up
into a single response and then send it
back to the mobile client over the
mobile network so it really sort of
improves the user experience cuts down
on the number of round trips and so on
so it plays a pretty important role in
the architecture of just providing a
client specific interface and it and it
also when talking with asynchronous
services actually does protocol
translation Pro you know translates
between the HTTP world and the AMQP
based messaging world so pretty
important role great example of that is
what happens at Netflix where they have
an API gateway it's real interesting
architecture so check out tech blog
Netflix com but basically they're
supporting a very lot you know today
like you can watch netflix on your
computer you can it's baked into my
television set Apple TV my blu-ray
player has it as well so they actually
support I think it's like 800 different
devices and they actually in their API
gateway they expose different api's for
different devices so eight API is that
are tailored and optimized for that
particular client device which is really
really interesting it's sort of it
avoids the problem of trying to come up
with a one-size-fits fix this solves all
problems fits all kind of approach so
you know in terms of implementing this
gateway lots of options you know you
could use Java EE web technologies
spring
there's also lower-level more scalable
options like using neti and Java niño
and then of course there's jar non JVM
approach options as well no js' is used
by
many people to implement API gateways
and it's low level it's very compact
very scalable very efficient runtime
downside is you have to program in
JavaScript and in terms of your various
design issues sort of want to cut touch
on a couple of them so the first is the
need for parallelism so you can imagine
a request comes in to the API gateway
saying give me the details of this
product and then the API gateway has to
go get information from your product
info has to get recommendations it has
to get reviews and aggregated all of
that data send it back as a single
response so one way of doing that is to
cool each one of those back-end services
in turn but that would result in really
really bad response time you know this
be the sum of the response times of all
of those back-end services much better
approach is to actually to cool those
back all of those back-end services in
parallel which means that the overall
response time is really just the maximum
response time of coming of each of those
back-end services but then in order to
do that we need some kind of concurrency
mechanism some way of firing off a whole
bunch of requests in parallel and then
waiting for all of the responses to come
back so that we can then aggregate them
together and you know that this various
API is obviously in in Java we could
like spawn off threads and so on and and
there's concurrency primitives like
countdown latches and so on if we really
really tried hard enough as a way of
synchronizing kind of all of the respect
of all of the responses but there's sort
of much better way of doing it and won't
one particular concurrency abstraction
that I found useful
our futures so your futures are
obviously part of the JDK but it's sort
of there they have a very rich history I
think dating
back to 1976 so the idea is is that a
future is this object that will
eventually contain the outcome of a
concurrent operation so outcome as in
the operation succeeded in here's the
value or the operation failed and here's
the throw a ball that represents that
error so the idea is see for cough some
kind of concurrent asynchronous
operation you get a future and you the
the value you want will ultimately
appear in in that future and so in Java
you can do that with the executor
service and you know it's there and it
it kind of works but what's really
interesting is is that the Java futures
have a blocking API if you want to get
the value out you have to ask the future
do you have the value you do you have an
outcome yet and it will block and if you
don't want to block you could just sort
of poll but it's sort of not not a very
usable mechanism least in comparison
with futures and other languages or a
better implementations of futures so the
first thing that you can do to improve
futures is how is implement a callback
mechanism so the idea here is is that
you register a callback and then the
future will tell you I have succeeded I
hope I have I now have a value or I now
have a throwable and that's an example
from scarlet futures where if it
succeeded it prints the number otherwise
it prints the exception and there's also
guava listenable futures java 8 has
completed all futures that implement a
callback mechanism and then scala takes
it one step further with this notion of
composable futures so they're their
futures have a very rich interface so
here oh yes of futures take a map
operation and the argument to a map is a
function in this case it's a it's a
function that will takes a value and
doubles it and so f to dot map that that
little expression gives you back another
future whose value will
be the first futures value multiplied by
two so that actually lets you implement
a kind of chaining mechanism where you
can just go future map this map door and
it just applies functions successively
to each of those futures as those
futures complete and then there's also a
zip function that come that gives you
another future containing the tuple of
the values from the it from the input
futures so FZ ends up being one comma
two so that lets us combine values and
then you can do interesting things like
take a a list of futures and transform
it into a future containing a list of
values so there's all these mechanisms
for transforming and combining futures
and that lets you write some really
interesting concurrent codes so you know
here's the code that's calling the
product info service the recommendation
service the review service getting back
futures and then it's using scholars for
comprehension along with zip to actually
get all of those values and create a new
future that contains the product details
object with with all of the various
values and that's all happening
completely asynchronously so there's you
can kind of think there's a lot of
coordination going on but using scala
you can actually represent it very
concisely which is really really nice
all of the details are completely hidden
from you lots of details but I encourage
you to go check out Scala Scala futures
as well as JDK 8 completable futures so
that that's sort of the concurrency side
of things and we can solve that using
futures another really interesting
problem is how do you handle partial
failures so now we've got a distributed
system which means that some parts of
the system can be up whereas other parts
of the system can be down so in
particular maybe the recommendation
service is down what do you do and how
do you how do you handle the
recommendation service being down once
again Netflix is a company
that sort of thought long and hard about
it and more importantly actually
published some articles about it for for
the rest of us to read and so that you
know they're a company that is
processing a billion API calls a day an
each API cool it actually fans out on
average to six service cool so that's
like six billion calls a day and you
know everybody knows how important it is
for kids to be able to watch cartoons on
a Saturday morning so reliable
reliability is really essential it's
like my kids have no idea how much brain
power has gone into making Netflix this
sort of awesome service that it is and
they've written about this on their tech
blog made to encourage everybody to go
read up on that so in the problem
they're really trying to solve is this
so you think about Tomcat has a finite
number of execution threads right you
know a request comes in gets assign to a
thread which cools some service locally
and then that service calls are a remote
service which ends up being down and you
know so or incredibly slow so that if
you do it naively that executes thread
is just tied up waiting indefinitely for
service B to respond another request
comes in it ends up getting tied up and
so on and before you know it all of the
execute threads within your Tomcat
server end up being just blocked waiting
for this in this case the recommendation
service to respond and this will happen
across your cluster and your so your
website is dead so they actually use a
nut a combination of strategies to solve
this problem number one is they always
use timeouts so you never block
indefinitely waiting for some remote
service to respond eventually you will
timeout they also invoke remote services
through a bounded thread pool so you end
up submitting a callable into a thread
pool of a finite size and that sort of
prevents your server or the api gateway
from mounting a denial of service attack
on some
I can service but it also means that if
that back-end service is slow the thread
pool will fill up the requests too that
are going into that thread pool end up
being queued eventually that queue as
good as also which is also bounded will
hit the max will hit its maximum and
then whenever an execute thread tries to
submit a request it's going to get a was
the execution rejected exception so it's
going to know instantly that that remote
service is unavailable so you get pretty
immediate feedback and then they also
use the circuit breaker pattern and the
idea here is if you see us so n
consecutive failures when calling a
back-end service the circuit breaker
opens and any subsequent requests for
within a timeout period of rejected
instantly so use just oh it's not
working so that's not even wait for it
to kind of like not respond you just
fell instantly and then after a timeout
period the circuit breaker let's a few
requests through it lets through a trial
request if it succeeds the circuit
breaker closes everything goes back to
normal and if it doesn't you go through
the timeout again and then the other
thing final thing they do is when there
is a failure they strive to return
default data or cache data so for
example if it was calling the
recommendation service let's just
in this case return an empty list of
recommendations we still want to display
the product page we just have to live
without any recommendations that's okay
and then only if they really really have
to do they return an error to the caller
which might with you know which would be
the set-top box which maybe would just
retry the request get load balance to a
different part of their system and that
cut kids cartoons will be displayed and
then they've got some open source
project that encapsulates most of these
patterns called hysterics which is on
github courage everyone to look at that
so so that's their approach to dealing
with sort of reliability reliability
issues and it's sort of very worthwhile
to actually emulate what they're doing
so in the final part of the talk I just
want to kind of wave my hands a little
around the problem of actually
refactoring a large monolithic
application which is like you know
intimidating developers it's slow to
deploy and/or update frequently and all
of those problems and sort of like well
you know what do you do if you are in
this situation how do you kind of get
from it into a to a service-oriented
architecture and so I you know I
arbitrarily picked sort of 10 million is
sort of a big number of lines of code
but you know I think you get this this
problem appears a lot sooner
there's an argument to be made that you
know 30,000 lines of code is the most
amount of code a developer can keep
straight in their head right and you
could say well if you get above that
maybe you really need to start breaking
your system up though I think you know
you should really consider having much
smaller services than that so I think
you know it's number one if you are in a
whole really the best thing to do is
stop digging right and so what that
means in this case is what if you are
implementing new functionality don't
just keep adding it into this monolithic
system actually start implementing it as
this new chunk of functionality as a
nice pristine small separate service and
then you use what you get cool you know
from domain driven design this anti
corruption layer that's the glue code
that keeps your service pristine while
integrating it into this messy monolith
and it's doing things like replicating
data between the service and the
monolith just to keep the two in sync
because you know obviously the problem
you run into is that they're really
dependencies you know the service is
gonna have to know about users and other
entities and it's going to change some
of them and those changes need to be
reflected back in the main system and so
on so there's all you know obviously
lots that lots of challenges a nice
simple diagram and but implementing in
practice is going to be a little bit
challenging but it ends up yeah it's
much better to do that rather than just
continuing to make your monolith larger
and larger because that's just gonna
make things even worse and then the
other thing you can do is just start
extracting services out of your monolith
breaking it up begin the process of
splitting it apart so you you can
identify a module within your war file
and just decide for what reasons I've
mentioned discuss in a minute we're
going to take that and break it out as a
separate service and then once again
implement this anti-corruption layer
this at this chunk of glue code to
integrate the two so the question then
is well what deal what should you
extract and so once one thing is that
you should always keep in mind well
what's our ideal architecture if we had
started from scratch how should we have
partitioned our application up into a
set of services and sort of use that as
the goal that we want to reef
incremental ii refactor towards so
partitioning by verb noun small focused
services so that's kind of the
overriding kind of guideline here and
then in terms of what modules of our app
should we start with it's kind of like
well that's you could say let's start
with the Troublesome ones the cert the
components that are constantly updating
that are forcing you to like always have
to go through QA cycles on the entire
application you know UI is are often a
good one there
great start break those up and separate
them out so that they can be developed
and deployed independently of the rest
of the system I once worked on an
application where seemed like a good
idea at the time but we ended up having
this component that was stateless that
actually meant that we could only ever
run one Tomcat server and that was kind
of like oops
meant that we couldn't write you know
have replica Tomcats running for
reliability meant sort of sleepless
nights or least anxiety anyway I mean
the service was pretty reliable but it
was like that was a prime candidate to
take that stateless component break it
up into a separate service so that the
rest of the application really was
stateless and then we could just cluster
it in the normal normal approach and
then other you know other possible
candidates are ones way those real
conflicting requirements of me in terms
of resource utilization so maybe you've
got a component that has this massive
in-memory database and then other
components that need a lot of CPU and
end up having to be clustered you know
large number of replicas which means
then replicating this large in-memory
database across all of your servers now
if you split split apart those two
services then they can be scaled
independently of one another so there's
sort of very various strategies there I
mean it's kind of so I'm sort of hand
waving and the actual specifics really
do depend on the exact nature of your
application and it's likely to be
painful you start splitting things apart
you end up with hundreds of compilation
errors that sort of need to be dealt
with and that's because the problem you
get into is one of just tangled
dependencies you have a domain model
that lots of rich relationships between
all the different components but when
you put those classes in separate
services those those those relationships
really imply every sort of a room a
remote procedure call which is somewhat
impractical in a distributed application
and so you have the strategy is we're
like well the challenge is how do you
kind of break those relationships so
what one interesting concepts is
actually of the bounded context which is
from domain driven design and really the
idea is is that what maybe you don't
really have one uniform domain model one
sort of universal domain model for all
different parts of your application
you don't just have one user object
that's the same everywhere but different
parts of your application actually have
somewhat different views of your
applicative say your user objects so
user management that's dealing with like
their avatar and all kinds of
information about that user has a
complex view of a user whereas other
parts of the system where the user is
really just a security concept they own
something they just have the ID and an
access control list and a name so very
simplified strengths so streamlined
model of the user so just the idea that
different so what that translates to
here is that different services can have
a different domain object with kind of
the same name but they're actually quite
different in purpose and you can use
messaging to synchronize to keep the
copies in sync so it's going to talk
about this really briefly because I've
only got two minutes left so here's a
simple domain model so you have orders
you know with line items and they have
totals and so on and then you have and
they belong to an or belong to a
customer and a customer has a credit
limit so the idea is that the order
totals of the outstanding orders can't
actually exceed the credit limit and
then the customers available credit is
their credit limit - that the total of
the outstanding orders so that's nice if
they were those two things were located
within the same service but then if we
go split it split it apart into into an
order management service and customer
management service we've now got this
somewhat troublesome relationship
between the two you know we have to
break that somehow and so the idea is
number one let's just replicate the
credit limit from customer management
where it gets updated via the customer
management UI
send a message to the order service to
say the credit limit for this customer
is now this so it so within order
management we've got a simplified
representation of a customer that's just
an ID and
credit limit whatever the order
management service users needs to know
so that that's sort of one thing we can
do there and that enables it to verify
that the customers credit limit has not
been exceeded and likewise the order
management system when it places an
order which changes the total of all of
the outstanding orders can then just
send a message to the customer
management system saying there's a new
open order total and that can cause it
to then update the open order credit
total which then enables it to display
the correct available credit so
basically these two systems end up
exchanging messages to keep their
different representations of the data in
sync and what this lets them you know
once again be developed and deployed and
scaled independently of one another
we're just sort of and they're loosely
coupled via messaging so you know key
idea you know refactoring is not easy
but I think living with a monolith is
far worse you know ultimately kills you
in the end so sort of in summary so
monolithic applications are you know
they're simple at some level to deploy
but once they get really big there's
this huge challenges and you want to
apply the scale cube and apply
functional decomposition to break up
your monolithic application into a set
of services that can be deployed and
scaled independently so you end up with
an architecture like this where you've
got back-end services an API gateway in
the middle and then various client
front-end clients over here and
communicating with the back-end services
via the front-end gateway so that's my
talk I hope you found it useful please
follow me on Twitter send me email if
you want to talk more check out my
website blog plain old objects comm and
I know we're out of time but I'll be
around for questions so thank you hope
you found it useful</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>