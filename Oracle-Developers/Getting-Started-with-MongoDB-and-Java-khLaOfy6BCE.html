<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Getting Started with MongoDB and Java | Coder Coacher - Coaching Coders</title><meta content="Getting Started with MongoDB and Java - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Getting Started with MongoDB and Java</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/khLaOfy6BCE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well we're really packed can everyone
hear me I like to move around and I'm
not sure how far back this mic will
actually pick up my voice
well welcome I'm very excited to see
this is really really packed let's do a
quick poll how many of you have used
Mongo okay
how many of you oh so how many of you
thought about using it but you're here
so clearly it's crushed your radars like
maybe I should figure out what this is
okay well as you know this is going to
be Mongo for Java developers it'll do
we'll do a brief overview of kind of
what Mongo is before we look at code
code I just have a few slides I don't
like doing slides a whole lot and we're
going to jump into the IB IDE where
it'll be a little more freeform so I
hopefully could dig down into whatever
questions may come up it'll also
probably a little bit more rambling
because that's just how I think but
hopefully it'll be a little bit more
interesting than having to stare it's
code on slides not my favorite so but I
am Justin Lee I work for MongoDB as as a
job engineer I've worked on a number of
different pieces up until recently I
worked on the Java driver directly which
we'll look at and I'll sum one of the
maintainer x' for morphia the object
document mapper if you if you're not
familiar with morphine which we'll take
a look at you can think of it as kind of
hibernate but for Mongo and I used to
say that without any hesitation but I
have to qualify now because there is
actually hibernate that works with Mongo
called hibernate OB OGM and so it kind
of muddies that analogy for me because
there was like what about there's
anyways hibernate and eclipse like both
work on work with Mongo to varying
degrees and I was so anyways so I work
on morphia the Mongo Hadoop project
which we're not going to cover here it's
terribly interesting but lets you use
Mongo underneath Hadoop instead of HDFS
if that's what you want that's very very
cool so that's a brief history of my
involvement with it I did use Mongo
before I started with the company I
liked it enough that I went to work for
the company doing different things so
yes I'm here representing the company
and
but yes my biases aren't totally
financial so now we do have Java drivers
obviously but we have a number of
different drivers I don't know I'm going
to resize this one if it doesn't freak
out one of one of our new hires drew
this we have drivers in almost any
language you could possibly hope to use
so we have Ruby with Python we have PHP
Scala data sight Python C sharp
we even have drivers in rust we have a
go driver there's an R Lang and Haskell
most of those are supported by the
company some of them are community
supported but we have I think we support
12 drivers directly but there are across
various languages 30 different drivers
to choose from when working with Mongo
so you can take your choice there but
we're going to cover Java today because
we're a Java developers so briefly for
those of you who have not had a chance
to really dig in with what exactly Mongo
is it means humongous for those of you
who don't speak English humongous is big
enormous I always like to think that any
blazing saddle fans I always think that
when I think Mongo Mongo just pawn and
game of life yeah exactly
it would have been terribly entertaining
but this turns out to be slightly more
prosaic that's okay whatever so it's a
scalable high-performance open-source no
sequel database buzzword quota net you
know it's like well what is it this is
what is scalable a little bit nebulous
high-performance reasonably when you say
a performance people no it means we use
the word no sequel mainly because it's
been kind of forced on us we don't
really like the name no sequel in
general simply because there's like 80
different projects that fall underneath
them no sequel umbrella and they all do
things radically differently you know
it's not like saying we're a relational
database where you have make certain
assumptions
you know you can use sequel on it and it
just kind of works but we don't use
sequel and we're nothing like most of
the other things inside no sequel but
there you have it so the kernel itself
is written in C++ we have a number of
tools that around it those are actually
increasingly written in go these days
which is kind of fun so it is document
oriented which we'll look at briefly
hopefully that means something to you
but we'll cover it it is also fully
indexable I was at a panel the other day
and people are like well what about this
and that you can you can define all
sorts of indexes on it we support you
know your standard I want to index this
numeric value or this string we also
support geo indexes full-text indexing
and searching and so it's it's rather
robust we have various features for
replication and high availability we're
not going to cover that entirely because
that that's a whole other conversation
that's very interesting but not terribly
relevant to the talk today and we also
support MapReduce if you're familiar
with that particular schema we do
support it natively for for what that's
worth it's a little limited by the
nature of the JavaScript engine but you
can certainly do it inside the database
and it works reasonably well but we also
support a more flexible and more
performant aggregation framework which
is designed a little bit better with our
with the JavaScript and our storage
engine format in mind and we also
support grid FS which is actually kind
of interesting it expose exposes your
can expose MongoDB as a file store so
you can stick you know blobs of whether
you want to store PDF files or images or
whatever some people like to do this I I
don't personally like sticking such
things in the database but there are
certain use cases where it makes sense
and Mongo supports that we have actually
have fuse drivers for any Linux people
in the crowd where you can literally use
it like a file system so alright but the
important part document-oriented what
does that mean so for everyone's used a
relational database right you're used to
tables and columns and and everything
well a relation in a document oriented
database rather than has
tables with rows and cells and whatnot
you're actually taking a document in
this case JSON ish document you're
storing that as one atomic unit so
rather than having to split up your data
into columns and stuffing in two
different various cells you're actually
taking the whole document and you're
putting it in and when you fetch data
out you're pulling it out as one whole
document so you can actually embed
documents people use the word sub
document and that's helpful from what
sort of looking for from a certain
perspective sub document makes sense
it's technically not a sub document it's
just it's a document that happens to be
in there but where that is super useful
is if you've ever tried to add data to a
relational store and it means you have
to add all these extra columns it's very
painful because you can't just change
that one row that you need maybe this
particular user needs three addresses
instead of two you can't just add that
extra address for that one user you have
to ultimately alter the whole table so
if you have you know forty million
records suddenly now you have to go add
forty million you know whatever columns
on on these rows with Mongo is like oh
this guy needs sixteen addresses so you
just put in sixteen addresses it's no
big deal some users may have zero and
that's okay if we Mongo has what we're
now calling a dynamic schema which means
that you don't have to predefined like
you would in a relational world you have
to say here's my table and it is once
you define your table it's pretty fixed
until you have to go in with your DDL
statements and stop your application
because you have to rearrange how your
data is laid out with Mongo you can just
use throw whatever you want in there
because it'll it dynamically manages
that we used used to use the word schema
less which is technically true but when
you say schema less people tend to stop
considering constraints to their
applications like we're just going to
throw stuff in there and not think about
it but you can still end up with a mess
in your data you didn't have to go back
and restructure because you need to be
able to index it appropriately and you
have to be able to query it and if
you're not if you if you don't if you're
not thoughtful about how you're putting
your doctor
and into your database you can run into
some problems I used to work at a
company and we had painted ourselves in
a corner because we just we're just
going to stick this raw string in the
database and then at some point we
needed to like do queries against what
was in that raw string but because it
was just a raw string and on a
structured document we couldn't but then
we couldn't change it because we had
hundreds of millions of these things in
the database and and changing that over
it just takes time right and we can't
afford the application downtime so we
just had to work around it because when
when that schema was chosen they didn't
think the implications through and this
through it in their Mongo took it
because why not but it did cause us
problems so all that to say we use the
word dynamic now and meaning that it's
flexible and can react to different
things instead of schema list but you
definitely want to think about what
you're doing and so I mentioned that we
store them in JSON style JSON ish
documents it's actually stored in what's
called beasts on and beasts on is binary
JSON essentially which sounds a little
strange but it has certain advantages I
don't have a bullet point on this yes so
it actually adds certain metadata to it
so rather like if you're parsing this
raw JSON you have to pass parse the
field name and then pass the value
because it's all text and you don't know
anything about it right so you have to
parse the entire thing to get the
structure before you can figure out I
just want this one particular element
over here we had to parse the whole
document to figure out where it was so
what beasts on does is it encodes
encodes header values and string lengths
and things like this so that if if you
know where you want to go you can look
at the first guy and say oh this is not
the key I'm looking for but I know how
long the value is all right so I'm just
going to skip those bytes I'm not going
to bother parsing when find out what's
in there especially if you have a like a
sub sub document it could be like 800
bytes that you no longer have to parse
anymore you just skip it and go into the
next one so beasts on allows just do
certain things like that and then
optimizes reads and fetches and indexing
and the like so it when you're working
in your and your code yeah you can just
treat it as JSON but once it hits the
wire protocol and often to the database
it's technically not JSON it's piece on
you won't necessarily run into anything
like that like it won't impact your
coding necessarily but it's helpful to
understand
to a certain degree what's going on so
this is what a document looks like and
like I said it is just well even this is
JSON II because if you'll notice the
first the the first element there is the
underscore ID which all Mongo documents
have if you don't give your document an
underscore ID will make one for you and
the default ID type is an object ID as
you'll see which is not valid JSON
because JSON expects a string there a
numeric value you know it's a very
restricted subtype this is the type that
we've actually added to biess on so an
object ID is we'll call it globally
unique and I'm sure they're security
people and cryptologists or like I can
break that and it's probably true but
for all practical purposes unless you're
doing cryptography you're never going to
have a collision with object IDs because
the way that it's calculated so they are
globally unique and they're faster to
generate than say a UUID would be
anyways the ID can be any type you want
it to be can be string can be number it
can actually be a document if you want
it to be that but by default it is an
object ID and it's generally recommended
to use object B object ID because it has
certain properties and make certain
things easier but certainly if you have
if you're especially if you're like
referencing external data that you
already have maybe it's a skew off a
product catalog or a user email off of
Facebook or Twitter or whatever might
happen to be you can use a string and it
works perfectly fine you can index it
you can query it technically you could
even have same documents in the same
collection they have a different ID type
Mongo doesn't care the queries we start
getting weird because you'd start the
query for a certain type and some
documents would imagine some others
wouldn't but it works it's functional
and Mongo
it's dynamic it's you know do what
everyone so just real quick there at the
bottom how many people are familiar with
JSON don't need to dig in too much this
this should look reasonably familiar
right you have addresses here which is
an array of documents but that's what
the documents look like on this bit
above here I don't know if you see my
mouse pointer
see if I can highlight this that's
actually what a shell query looks like
and we'll look at more of those in a
minute and the actual query is this is
this is DB which is you're telling Mongo
I want to work it this is a database
operation I'm going to do and that's
important when you start talking about
replica sets and sharding because
there's also an RS dot and it has a
whole subset of stuff and there's an SH
dot for all your sharding but this this
just says I'm going to do something with
this particular database and so users is
the collection name instead of tables we
have collections but if you look at our
documentation and you're especially an
indexing stuff we have things like if
you don't have an index you're going to
do it like a full table scan which it
should be say full collection scan but
we all come from a relational world too
and sometimes the old terminology creeps
in but they're called collections
technically so find is an operation
defined on a collection you can pass in
a document here for a query which we'll
look at in this case we're not so we're
going to pull back everything and dot
pretty is a helper if you don't if you
don't put this on the end and that's
fine but you just get back your JSON
document all in one line and sometimes
that's fine but if you want to read it
it can be it can be a little problematic
so you can put dot pretty on it and it
will it'll pretty file your JSON for you
and that makes it easier to read ok so
just real quickly replication and hi
events high-availability we are on some
spectrum eventually consistent I think
sometimes we use the term strongly
consistent but it depends on how you
architect your application we use
various level which is called a write
concern is the technical term for it so
depending on what your write concern is
you can be super strongly consistent or
if you're you're ok with it
you can be a little less paranoid about
it there are varying levels the default
now is when all the drivers should do
this now as I think last year sometime
when you write up to the server the
driver will wait for response
and acknowledgement for that and what
that means is that the server received
your your document and it is put it into
a queue to be stored that is that's an
acknowledged right there are varying
levels you can say I want to wait till
the server rides it to the journal
because all of our rights are journaled
and then they're written to the disk and
so you can say I want to wait for it to
be journaled so that's a little bit
slower you can wait for the F sync which
is a little bit slower and if your
replication you can say I want to wait
till it makes it to one replica set
which is even slower because now it has
to do that same thing with another
replica set and you can do depending on
your right concern level you can say I
want to I want to wait till it goes to
six replicas sets you know like I want
to be really sure this data is never
going to disappear and if you do that it
takes even longer but then of course you
can be sure like not all six computers
are going to probably burst into flame
simultaneously and your data is not
going to be lost
so depending on how much that you want
you have varying levels of safety on
your data so we support we support all
this through two mechanisms replica sets
and sharding replica sets are basically
full copies of all your data it goes to
everything goes to your primary server
and then gets replicated to your
secondaries and in the case if your
primary error goes down it'll all your
drivers will just fail over to there's
an election and some other secondary
will say I'm the primary now and then
all rights will go to that guy there's a
very small window in there where if you
have written to the primary and it goes
down before it gets replicated there
might be some roll backs on the rights
that made it to the primary that weren't
replicated some people are more
concerned about that than others and
others are surprised when they find out
like wait what happened to my data I
thought this couldn't happen it's a very
very small window and it does happen but
very rarely anyways so is everyone
familiar with sharding with the basic
idea it's basically a way to segment
your data so it lives on separate
servers and this serves a number of
purposes it splits up the rights across
servers so if you're doing a lot of
really write heavy data they can
actually spread that out
your cluster so it speeds up riots and
it reduces load on certain servers but
then it can also spread out your reads
as well and that can be handy in a
number of ways you can do like taga
where sharding there's certain things
you can do for data center we're
starting so you know what machine you're
on and then we have services that will
route those queries to the right server
so you can spread the load across a
cluster and then each sharding is a
little bit more complicated but then
each shard can be its own replica set
member so you can have that one shard
with its own sub set of replicas sets in
addition to all your other replicas says
so it can become quite complex if you
want it to be and it just kinda depends
how you want your data laid out so
enough with that I'm sorry what more or
less I think there's probably some
subtleties the question was is charting
the same as partitioning and I want to
say for the most part it is I'm sure
there's some nuances that might be
different depending on who you ask about
which what means what I'm but
essentially it's the same you can do geo
eric starting - so if you have data
centers across the world all your data
in Australia can stay there right have
to come all the way back to New York
where I live because you don't want your
Australia users to wait for your request
to come all the way across the world and
then back and it's just dumb right so
you could do geo aware sharding and then
everything stays you know in Australia
or Asia or wherever you might happen to
have your data so so we're going to look
at a number three different ways of
doing things with Java and so the first
one of course is the Java driver it's
you know obviously it's the first thing
that you're going to use as a as a Mongo
and Java developer a lot of our
customers use the Java driver directly
and they don't have any interest in
using any of the higher-level stuff that
we'll look at perfectly acceptable in
fact it's I guess it's so good most be
this is what I've seen most people use
but we're looking at two different
options because we're Java developers
and we like our types right the Java
driver you're essentially using a Java
util map and if you like using you know
gets inputs that's
fine um I like my types personally so
we're gonna look at two options one is
called jongo which is not written by a
MongoDB but I think it's actually quite
nice for a number of reasons which we'll
see
and then we'll use morphia which is what
I work on and add various times and this
one is supported by MongoDB so we're
going to take a look at oh look this is
how before we get into all the details
this is the step I've forgotten in times
past it's like I can't tell you this is
how you use it but not how to get it
maven users yeah alright so that should
look familiar it's just integer in your
palm so this is the Django dependency
and they're up to
1.1 now and then the morphe dependency
so just the one line in your palm or if
you're using Gradle you can put in your
build-out Gradle as well so with that
out of the way we're going to look at a
number of different queries ok so these
are what the queries will look like in
the shell syntax
well we'll walk through each one and so
you don't have to memorize this we'll
see each one or we'll look at this three
different queries and we're gonna look
at it in the java driver and john go and
in morphia and and this will comprise
most of what the slides are then we'll
go off into code but I wanted to do
these on the slides because it's easier
to see comparatively what they look like
next which are then draw then happen to
flip back and forth inside of an IDE so
alright so the first one we're going to
look into a collection called product
orders and we're going to find all the
orders who have a property called
fulfilled that is set to true and in
this case I'm going to do a limit of two
I didn't have to but I thought we'll
throw an out there because it kind of
complicates a little bit just to kind of
see how things start to compound without
getting terribly complicated with it so
this is what the Java driver code looks
like is that too small for anybody for
everybody I can make it bigger I'm just
a little afraid that I don't know if the
rendering will look weird with it bigger
but we'll make it work
how's that readable such a small screen
okay
so a DB cursor is what you get back from
from Mongo with a typical query so in
this case we have a DB I cut out some of
the boilerplate because it just confuses
things so DB is a reference to the
database to your to your Mongo we're
going to call get collection with
product orders and then we're going to
issue method called find now this is
where the Java driver gets verbose and
this is a little bit Guaymas I'm
surprised that someone to use the driver
driver directly because it can be rather
cumbersome if you've over large query so
up top you can see we just have a JSON
document fulfilled true to do that in
the Java driver you'd say new basic DB
object with you give it the key filled
and the property value of true the
driver will convert the basic types
often to JSON dates strings numbers if
you need something more complex you're
going to have to convert those to DB
objects yourself and that can that can
be hard or not depending on how
complicated your structure is but it's
not terribly bad and then we're going to
issue the limit of two and then what you
see at the bottom and the while
statement this is this how you just
iterate through I want to take all those
things that come back out of my query
add it to a list called orders but I
want to wrap it into a Java type called
product orders and this constructor
literally just walks through the DB
object and the calls get and sets it to
Java properties yes
right to disk
no no the question is if you have a
query and you return back a million rows
our million documents is it going to
just all go in memory or can you spool
it to disk what actually happens is the
default batch size on a query is 20 so
you're going to tell you're going to
talk to the Mongo server and say this is
my query and it's going to set up the
cursor and it's only going to send you
back the first 20 documents you can set
the batch size if you want depending on
what your needs are but the default is
20 and then when you get when you get to
the end of that it will transparently
ask for the next batch there's a command
called get more and it will pull back
the next 20 so the server actually
stores the cursor information and then
it only feeds you
one batch at a time so you're never
going to pull all those into memory at
least on the client side the server will
try to keep stuff in the working set but
the server does kind of some magical
things to make sure that you're not
going to create are things but you're
not going to you're not going to
necessarily kill your server if you pull
back a billion documents in one query
the server will pull what I can into
memory and if it can't pull them all
into memory then with each get more it
will go fetch those out of disk so that
you're not you're not going to blow up
your server yes
okay the question is about some of the
missing boilerplate and how you get the
connections I'm gonna answer it real
quick and then we can look at it we can
look at some code I'm here in a minute
and that it'll be easier um but the the
short answer is the driver actually
maintains a pool internally and so it's
recommended in your application that you
really only create it's called a Mongo
client typically only need the one
because it creates a pool I think the
default size is 10 and it'll grow up to
either 20 or 50 I think before it maxes
out but that's the max pool size and
once you no longer need a middle it'll
it'll kill those connections back down
to the the 10 so it'll manage that for
your connection pool and that's tunable
if you need a bunch of them we've we've
had some some support issues where
people every time a web request come in
they create a new manga client and they
do all their thing and suddenly they
have 6,000 connections to their database
and like what's going on it's because
they're creating all these connections
so the short answer is and I'll show you
the code here in a minute remind me in
case I forget the the Mongo client will
manage your pool your connections for
you so you just need that one and it'll
create as many as needs did you yes that
is an excellent question
um and I generally I think we've heard
it as the the shell query syntax which
is of course that that is correct yeah
it is unique to Mongo now you can
actually use this same query syntax with
db2 because IBM went and implemented the
wire protocol to talk to db2 which is
strange but apparently there was a
business need for that and so if you
want to use IBM if you use db2 with our
query syntax apparently it's possible
but yeah there there is no common query
language across no sequel databases
which is one reason we're not a big fan
of the name so that makes sense
you
like multiple queries in one request by
multiple sign
okay and the question was can we can you
do multiple queries to return back
multiple to result sets and that is not
supported a single query with multiple
rows and sets no that is not supported
in the query language and yes yes and no
you can it when you call closed on on a
cursor for example it actually just
releases that connection back to the
pool so it's actually good practice to
call closed when you're done with the DB
cursor one once you've exhausted the
batch set it'll actually auto closed for
you because it knows oh I'm done and
it'll release it back and the next time
you do next time you try to iterate
through it'll just open a new connection
or we execute things but it's important
to call closed because if you don't it
like if you just do this if has next go
grab the first one and go back to do
whatever you're doing you're going to
leave that cursor hanging and then at
that point you can run into cursor
exhaustion because it's by default the
server will kill inactive connections
when they've been idle for ten minutes
but if you're in a very busy server ten
minutes is a really long time and
they'll just hang out until the server
decides oh you're done with that I guess
and I'll kill it so you definitely want
to call closed when you're done with
your cursor and because otherwise you'll
kill things anything else before we move
on
we do not currently support transactions
the most of most applications built on
Mongo don't really need them some people
really think they do and it turns out
that they kind of don't now that's not
to say that every application will fall
on that but what I will say is that when
you're writing documents document rights
are atomic so for a given document when
you start writing that document no one
else will see those changes until you're
done writing so you're not going to see
you're on a partial reads you're not
going to have partial rights that
corrupt a document so the document
rights are atomic but if you're updating
multiple documents at a time you're
going to get multiple atomic updates so
if you're doing like a bulk update you
might see you might get you might read
data in in the middle of that bulk
update but for each individual document
that update is going to complete or not
before anyone can see it so we don't
currently support transactions whether
or not we might in the future is kind of
up for debate it gets weird and very
very complicated transactions do once
you're in like a sharded situation and
distributed transactions even in a
relational world start to break down
very quickly because xa is complicated
so yes
well Mongo doesn't actually require you
to define anything up front the the
first time that you write to a
collection called product orders or fizz
bang it just creates a collection for
you and like in a relational or get to
go in and say create me a table and then
I'm going to do an insert with Mongo you
can say go take this document and write
it to this collection if it already
exists it will add that document to that
collection so you have to be aware of
what's going on because it will just
silently say oh I don't see that so I'm
going to create it but no well since
since it silently creates it for you
Mongo really can't tell did you really
mean the new collection or not because I
found one so I'm just going to go ahead
and write it because I'm pretty sure
that's what you want
so yeah you definitely want to make sure
that you're especially when you're
removing things that you mean the
collection you mean because Mongo will
just take it yes not currently um
there's a number of efforts outside of
Mongo to create like a JSON schema soar
like an XML schema there hasn't been
like a clear consensus on what that
should look like but I know that the
kernel engineers are looking at
especially once you get your application
built and you're you're reasonably
stable you want to be able to say like I
want to make sure that this document
always has this particular shape there
isn't currently support for that but
it's definitely on the radar somewhere
down the line but if you use yeah if you
start gonna get to that here in a minute
if you use something like morphia or
Django where you're your schema is
defined by your java objects then at
that point it becomes really hard to
write a document that's not of that
shape if you're using morphia because
you can't just like randomly add stuff
to a java class right you have to
actually go through the whole compile
cycle and and things like that so it's a
little bit more rigid at that point and
that's that's actually why I prefer
using such tools so
yes
we we do support upstarts for sure if
you generate your own ID then you have
to make sure that your ID generator
generates unique ones and it depends if
you're using object ID you're not likely
to have a collision because you can say
new object ID a million times in ten
different threads and they're all going
to come up unique if you're using a
string based ID generator for whatever
reason whether it be email address or
whatnot you're going to that point your
application has to confirm that the ID
is unique and that's one reason why why
we prefer or encourage you just to
insert your document and let the driver
and Mongo create you an ID for you
because IDs typically or meaningless if
you if you if you can get away with it
your ID shouldn't have any semantic
meaning for your application it's really
just a way for the system to get a
handle to a specific thing yes
it it depends on the operation that
you're doing but yeah if you're doing if
you're doing like an up cert and you
have two documents that have an ID
collision it'll actually just update the
first document that it finds and clobber
your data because it just as far as it
knows like oh this that's the ID you
really meant it doesn't know that you
had a collision on your IDs um so okay
let's let's scoot along before you run
too much out of time so this is what
jungle would look like it's a little bit
more succinctly like about jongo is if
you look at the find method there the
first bit looks the same you still you
have a reference to jungle which its own
kind of God object so to speak you get a
collection you give it a string name and
then your fine method you'll see that
this query here looks an awful like the
one at the top of the screen right and
that's actually what I really like about
Django is that you can work in the shell
and you can kind of perfect your query
and figure out I need to tweak this and
change that without the whole compile
you know recycle test them that you have
in Java and then when you're on the
shell you just cut and paste into your
java code and it just works right and
this is awesome and it's really really
nice inside Django on the downside it is
what is called string lis typed if
you've heard the term you still have
these strings that are just kind of
hanging out there that aren't
necessarily validated against your
object model some people are perfectly
comfortable with that and this works
great I know that some of the jungle
devs and they all love it and and I live
in X to be honest it's why I still talk
about it even though it's technically a
competitor to morphia but it's nice you
know because you can just cut and paste
from the shell and it's it's a little
bit less magic and API to have to learn
but this is the exact same query in
Django and as you can see here it
actually does this for us the very last
thing you see in Django you want to find
all these you want do your limit of two
and return it as a product order and
this method returns a list of product
order instances that have been
automatically populated with data from
Mongo inside your java objects django
actually uses jackson the j the json api
if you're familiar with that so if you
like jackson and you're familiar with it
annotating your java objects you've
probably already done
in Django just plays with that morphia
looks very very similar but we have a
slightly bit more of type safety kind of
I like to call it type safe-ish even
though the original developer calls it
type safe but we still have these field
objects that take a string and so this
will compile if instead of actually when
I was running these slides I had a typo
and I had fulfilled with two L's F ull
fil led and it compiled and none of my
queries were working like what is going
on and then I finally figured out oh I
had a typo so it will compile but what
more if it will do for you actually is
that when it sees that you're querying
against a field called F ull fil led it
knows what your Java object looks like
and you'll get a validation error at
runtime
it'll be it won't it won't kill the
operation it'll just say this is this
doesn't match what my mapping is but
it'll still go execute the query
so you'll at least see the the error in
the logs but it won't necessarily crash
your application for you so a bit more
typesafe api on top of it and I like
morphia quite a bit and it's one of the
things I went to MongoDB to work on yes
does it have generics port yes when you
see this as list at the bottom if you
were to save this to a variable and will
and will see the code in a minute that
this actually returns a list product
order so you're not getting back just a
raw list it'll actually type it to
whatever comes in and that's and this
done through when you create the query
here with product order class it tells
it this is the class that I want to
deserialize my data into
and I'm sure I can hear you
what well when your sharding you don't
talk to the individual there's a there's
a MongoDB process which is the actual
database in a sharding situation you
talk to a Mongo s and the Mongo s will
look at your query and it will do its
best to figure out this query should go
to this chart and this shard depending
on what your query looks like sometimes
Mongo s can tell what it is if it can't
tell how how this query lays on top of
your data it'll just spread it out to
all the shards and say go run this query
and give me back what you've got and
then it'll merge those and send them
back so from a developer standpoint and
your codes not going to change in a
sharted situation that makes sense
what's that
no it's the mungo s process the driver
will just talk to the one process and
then that process that Mongo s will
we'll talk to them how are we doing
alright I'm going to add these other
slides they're little bit variations on
the themes I want to kind of run through
these so we can look at some some more
code and so the driver starts to get a
lot more verbose depending on what your
query is in this case we're doing like a
filter on all of the totals are greater
than or equal five thousand and we're
doing a sort so as you can see the Java
code the Java driver starts to get a
little bit more verbose it's not bad but
you know it's it can be a lot to look at
John go on the other hand just boom it's
just this little snippet looking mostly
like what you see above one thing I did
want to point out as you can see here
there is this pound sign
that's a parameterised placeholder so
you can build your query and if you want
to parameterize on sometimes you want
orders more than a million or orders
more than 10,000 and you just pass those
in as parameters sort of like the string
format function and junga will then go
in and positionally place those
parameters inside your query but as you
can see this this is basically it's a
one-liner really one logical line even
though it spans and it's pretty
straightforward
morphia is shorter than the Java driver
a little bit longer than than John go
this this line here there's two ways you
can do this you can do a this is the
method called filter we give a string
and then an operator and it it this is
actually kind of nice because it's a lot
more succinctly support inside that
filter string some of those might or may
not make sense but it's all it's all
document I'm mostly listening it just so
you can see what's there but if you
really like your API and you like to be
able to read your Java code and see what
it is you can there's a method called
greater than or equal
I want your personal preferences so
we're going to sort we call it order in
the API of course give it the field and
then again we're going to return as list
so both dongho and Morphy are slightly
more compact and then the Java driver
but your taste so very okay one last
complicated one and this one gets a
little bit more involved we're going to
do an or so it's going to involve
multiple nested documents so we're going
to create there's two filters we have
here where the size is less than or
equal to 3 and the fulfilled is false so
we have to create those two documents so
here's the we're going to fulfilled
we're going to have the size less than
or equal to 3 and that's the operator
you need to have and it's one thing I
don't like about the Java driver using
that is you have to figure out like
there's $1.00 LTE and there's dollar and
ni N and all these doll interpreters I
mean it's not bad if you know them just
plug away most people do but it is a lot
more up front and then we have to create
this you know a whole new wrapper object
to then or altogether the same query in
Django I just bang it all out not so bad
and then the same query again in morphia
and so we are at 6 444 okay updates they
look pretty similar and I'm sorry I
really want to blaze through this but I
would like to at least look at some code
so we can see kind of what morphia would
look like you can do this is this is
doing an update if you were to do an up
sort you see these true/false here one
thing you should know I want to comment
on update by default the update command
both in the Java driver and in the shell
will update the first document it finds
and then stop because that was
considered the safe choice if you do if
you fat-finger your update suddenly
you've updated you know all 800 million
documents in your in your collection and
now is like
now what do I do but most people like in
a seat in the seagull world you'd say
update bla bla bla and everything in
your table has suddenly changed and it's
just normal you try to do the same in
Mongo and like why isn't my data changed
well it's because you have to pass in a
true to say update everything and then
there's also a true if you want to do an
up cert has you know it has everyone
heard the term up cert it's up sort is
very nice it's it's it's a mash-up of
update or insert and it's basically
saying if you can find it I want you to
update this document to look like this
if you can't find it I want you to
insert the document and what gets
inserted is your query object so it
tries to go find a document with the
size of three and if they can find those
documents it will update them and will
set the total to 400 if it can't find
one of those it will just create a
document set the size property of three
and then it'll update the total to 400
and it's it's actually quite useful in
certain scenarios but you'll end up with
the one document instead but that that
is it's called an absurd so this is this
is what it looks like in Django and Jung
goes a little bit nicer you don't have
these random boolean's like what what's
the order in the Java driver is it the
multi first and then is the absurd or is
it the absurd you know it's a it's a
boolean it's like I don't know what's
going on Django was nice enough to
actually give explicit methods say
absurd
or multi and you can kind of you can
look at the code and know what's going
on and then this is this is where
Morpheus starts to fall behind the curve
a little bit it's a bit more verbose now
if you want to do in more fee on the
other hand it will by default do if you
do an update it'll update all of them
more if you had went the other way
around say I know you really wanted to
go update all of them so I'm just going
to do that for you but if you really did
just want to update the one the first
one you find that method is called
a fake burst so there is no boolean for
for multi or non non multi single and
it's just it's you call a different
method by default it'll update
everything but then you have a
true/false for up certain and the same
rules apply so
this is slightly more complicated and
we're going to blaze best because we are
its 447 so let's look at some code real
quick you wanted to see how you get the
driver let me see the question is where
would that be base test okay in order to
get a reference to your database if if
you're on localhost that's actually all
it takes
new Mongo client is that big enough I
couldn't get it to I couldn't get it to
increase the size for me
can everyone read that that's as simple
as it that's that's all it takes a
connection to a database the default is
localhost and the default port is twenty
seven one seven it can be a little bit
more complicated Mongo client actually
takes a number of different things there
is this Mongo client URI can specify all
sorts of interesting things right
concern there's a thing called a read
preference so if you want to read from a
second here you can do that it's a bit
it's a bit much to wait into here but
you can configure all sorts of
interesting things and this lists the
seeds here if you have if you're in a
replicated set what you can do is give
it you say three of your replication
servers and the driver will connect to
all three and I'll say all right which
one of you is the primary who should I
be talking to and it'll find your
primary for you and then if your primary
should happen to die it has discovered
now where your cluster looks like
because maybe you have eight machines in
your cluster but you only give a three
but it talks to those three and those
three can tell it this is what the
entire cluster looks like in that guy
over there is our primary so you seed it
with an initial list and then the driver
once it connects can go find out where's
your primary and once an election
happens you can go find out where your
new primary is so that's that so in
order to create your your morphia stuff
you have a Mongo client and you just
tell that I want to create a datastore
and then you give it which database you
want to talk to this is this most of
this the demo slides
have all been vetted through unit tests
because I want to make sure that they're
not I'm not giving you broken code since
this is a test I just go in and I drop
the database because I want to rerun it
so you can drop a database through Mongo
if you want you can map a package in
this case we're going to do it's a
morphia demo so we're going to give it
the package and more if you will go out
and find out or what are all my entities
and it will map those for you and and do
certain things and then you can you can
index things all right I'm going to go a
bit faster so I can have some other
questions all right
and so this covers most of the
interesting stuff with morphe anyways
and I know it's a bit of a firehose but
hopefully this will cover most of it so
I would personally I would love it if
everyone always used at entity because
it may it would make the morphe code
simpler I could delete a whole bunch of
code because I can just assume that
there's an entity and if not you didn't
mean for more for you to use it you
don't have to use at entity morphia will
figure it out but it's nice from like a
self-documenting perspective to say this
is to use that entity so when you're
looking at it you can know but what's
nice about it is if you don't use that
or if you just use the raw annotation it
will create a collection in this case
called github user it uses the simple
class name as the collection name but in
this case we want to use something
different so we're going to tell it this
is an entity and it belongs in the users
collection by default morphe will store
the class type in your document it will
create a new field called class type and
it stores the fully qualified name of
your class and this is useful if you
have multiple classes maybe like
subclasses stored in your collection
more if you knows how to pull it back
out
most most best practices prefer you to
do like one type per collection or table
because it's a simpler model to work
with but if you know that you're not
ever going to store a github user inside
the users collection you can tell it no
class name stored equal true and then it
just won't it won't add that field for
you you can define indexes you don't
have to do it this way you can manually
define your indexes inside the shell and
that's fine or you can use this inside
your code
like you would in JPA if you're familiar
with JPA you can say here's my indexes
and you're going to create yes yes
and will this I don't know if it's in I
think it's a parameter on this there is
a an option hopefully everyone can read
that the colors are probably great on
the screen and there is an option called
background by default that the indexes
are created in the foreground so when
you saw that create indexes command if
you don't use this it will block while
it goes and creates those indexes
because it's waiting for very for
verification those are done or you can
say yeah just do in the background when
you get done it's good enough and then
ensure indexes will send off the call to
the server hey go create these indexes
I'm going to go on about my day and then
it just comes back so if if you're
indexing existing data you're going on
it you want to decide do I want to wait
for the index to show up or can I just
tell the server create it and then the
application can load up nice it's a no
op it'll look at and say but that's also
true that's important to note though
that if you change that index if you add
a field to it or maybe you want to
change the order or whatever it just
looks at the name it says oh I have it
indexed by that name so I'm going to go
on and now you're in what you thought
you had an index is no longer the case
because it's an old value for your index
and Mongo will just say I have one by
that name so it'll go on so if you
change if you change the shape of your
index you're going to want to drop the
old index and you get the new one I'll
like reverse generate from your schema
for example from a document or whatever
at the moment no in part because there's
no there's no consistent JSON schema
around hibernate can look at a table and
say here's the structure I'm go create
'add in theory you could write code that
would go in and look at a collection and
say I think your object looks like this
but because from mongos perspective it's
dynamic you can have drastically
different documents in one collection
you'd have to choose to say I want to
scan the first
thousand documents and do your best
guess to make sure it all fits but you
can't guarantee that every document in
your collection then is going to fit
inside the job object yes spring data is
I I'm glad you asked that I meant to
mention it spring Gate is an option it
fills the same sort of role as morphia
it does a little bit more it starts to
encroach in another project called Mongo
Hadoop it's spring data's a bit of a
larger thing than just a straight object
mapper but we have we have customers
using spring data and they love it there
was a question yes yes
well like I said Mongo will just take
whatever your um when you first connect
I don't think I have a shell open
terminal that's what it's called when
you connect if you just connect a Mongo
I uses the default I figure what the
deal is but in this case let's connect
to a connection a database called Java
one and and now it's like oh there's a
database we just created database Java
one sort of um it's technically not
there yet but if you do show collections
now it's actually written something back
to the server now the server knows that
there's a database called Java one it's
kind of a weird artifact I think was
maybe an unintentional artifact but if
you connect from two different shells
and you say connect to it the server
won't necessarily know anything because
there's no metadata shown but now if you
do show DBS you'll see a whole bunch of
stuff some of those are internal but
down here my mouse down here you can see
there is our Java one collection and
it's currently empty so if you wanted to
create a collection you could say DB dot
session dot insert : hi and there you
can see the right result we inserted one
back and if you do now DB dot session
dot find you can see we created a whole
new document and we never created the
collection we just said go right to it
and Mongo said all right I'll just I'll
create the collection I'll do the but if
we were to do another one now we have
two documents because it already existed
so just added the document and we can do
something completely different
this is going to the jelly add the Java
one collection and now you can see we
have the third document has a completely
different shape because among what just
took it and added it so you don't you
don't have to create a new collection
you could well you it's part of the
command if you see here we have this the
insert command see if I can find what
that happening well you're you're
inserting into the session collection in
the database Java one because yeah in
fact down here as you can see I create
another one called session two because I
just changed the name of that comes
after DB but you can switch databases by
sort of like in in my sequel or wherever
you say use you can use let's see
non-existing so now we're in a different
database that didn't exist until just
now but we switch to it and some
long-ago just seamlessly switches over
under the session is over in the end the
other database so if i do show
collections now you can see I have no
collections in this database because I
switched yeah it was it was a first word
that came to mind and even as ice'
typing as i this might not be the best
choice but you can name your collection
whatever you feel like
it's just kind of whatever works yes
yeah yeah yeah yeah I actually it's five
it's five now
alright just real quick when you're when
you're modeling your Java object you'll
you're going to need an @ ID it can be
whatever type it is but you have to have
that otherwise morphia will complains
like I don't know what my ID field is
in this case we're using a name we're
modeling in this particular demo the
github object model sort of and since
github already has unique user names
we're going to use that as the ID inside
this particular application and those
are of course strings by default every
property on a Java object gets mapped
more than I rights where there has data
or not is a different story but it will
map every property you have it and it'll
use the field name by default or you can
tell it you can use the app property
annotation to change the name to
whatever you want one of the concerns
with Mongo is that it stores them in
documents so for every document it's
always key value key value key value so
you're repeating those keys a lot which
is one of the reasons we want JSON
schema so we can compress some of this
but it is a lot of repeated data so if
you have a very large collection not a
lot of people will they'll abbreviate
the field names in the documents too to
use less space in your document and so
that's an option too this is at
reference we actually support database
mint references outside whether it's a
different collection or just different
documents same direction you can think
of them as foreign keys without the
referential integrity we don't enforce
it and that can be good or bad but you
can point say this particular piece here
actually is this document over there
that document may or may not be there
and you won't know until you load it
morphia has a nice feature that if you
want to it will actually load that other
document for you like like an eager
fetch in hibernate or sometimes you
don't really want it just now or maybe
ever in this particular workflow and you
can say lazy equal true and it basically
puts in a proxied reference and that if
you ever try to reference that if you're
trying to load up the repositories in
this case at that point then it'll go
load those other documents and hydrate
them into Java objects but it only do
that once you ask it to
and in in the user name here in this
case it's a primary key on this
collection no it's it actually uses the
app yeah actually yeah because there's
the ID on this one DB refs are um
they're interesting and when you look at
them in the collection okay it is it is
five and I think I think we're done
right the ground at I'm sorry there were
a lot of really great questions and so I
didn't get quite as far into it as I
hope it would but I'm happy to answer
any questions you might have come on up
and I will ask them we're not going to
kicked out of the room are we Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>