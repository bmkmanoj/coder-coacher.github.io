<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>12 Factors for Cloud Success | Coder Coacher - Coaching Coders</title><meta content="12 Factors for Cloud Success - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>12 Factors for Cloud Success</b></h2><h5 class="post__date">2017-10-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/x8gMeg_HZUU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody good afternoon it's a
great pleasure for us to have you all
here especially after the Java keynote
thank you very much for taking your time
coming from Moscow nor everywhere
everywhere else to the session and as
you can guess today we're going to talk
about 12 factor applications so this
this talk is titled 12 factors to cloud
success and it's a great pleasure
especially for me to be here with my
great friend and partner Rafael
Benavides he'll be one of the speakers
of the session ruff I was a director of
developer experience at Red Hat he is
also in an Apache committer he has like
many different certifications from
different companies in different areas
and I also like to reduce Rafael because
he is by far one of the best engineers
that I've ever worked at so far that's
why I'm so proud to be here with you to
him with hidden today to be present to
you this subject welcome everyone it's
also a pleasure to be here sharing the
stage with Edson Edson is an amazing
professional as you can see he's a Java
champion and also a Microsoft an MVP I
know that's a little bit weird but
that's why he is so exceptional and it's
a pleasure to join this stage with him I
forgot to mention I'm a Brazilian
Japanese - yeah we're Brazilians before
starting the session I like to invite
everyone to visit and join developers at
Red Hat calm which is a portal that you
can find resources for developers ok
including his book that talks about
databases and how to break monolith
database to microservices catalyst and
I'm talking about the book this week
we're gonna have a book signing at the
Red Hat booth the Expo or Riley centers
some 200 books and some of them will be
available for signing
if you check by the booth you can see
the schedule ok let me start this
session by telling you a story that
happened is basically to me when I was
in Brazil I was I lived in Brasilia the
capital ok
and I was there one on one day in the
zoo with my niece she's like 4
years old and one day during a duel ride
she asked me she saw different animals
and she came to me with a question well
I realized that every animal has a
different skill the birds can fly these
necks have their poison the monkeys can
climb did the tree very fast and she
asked me what is the human superpowers
because she's crazy about superheroes
and I started to wonder what I could
save for that little girl 4 years old
and the best answer that I came to her
is that thinking is what is our best
superpower because thinking has taken us
to places that we never been before and
well and because of thinking we became
problem solvers of course until we
decided to work in IDE in the IT
industry ok that's a joke but what
happens when we have a problem
first with ones that we densify a
problem we start to analyze the cause
and effect of that problem and what's
the proper solution for that problem
right
and once that we identify different
solutions we and we come with the best
solution until that moment and then we
start to have a continuous improvement
right it's that what we call a feedback
loop right yeah exactly and a feedback
loop is a very important thing in all of
the human activities because basically
that's how we know if we're doing the
right thing right and software it
couldn't be different and I like to
emphasize the point of it's very
important for us in fact I think that in
the next like 20 or 30 years all of the
major evolutions and evolutions
evolutions and revolutions in the
software development field we're
targeting the the feedback loop process
because we as humans we have a very
limited capacity for what I say to hold
some contexts in
well human memory right so what is
context context is your ability to hold
the entire demap problem domain space in
your brain just for you to for you to
formulate hypotheses and try to
establish simple correlation if I do
this how do you achieve that
if I don't do these I don't get that so
if we have a large problem or if we take
a long time to try to establish this
correlation between what I did and what
is the result of that the quality of the
software that we deploy to production
suffers so we're talking about all of
these DevOps and micro-services stuff in
fact we're just targeting we need to
shorten the feedback loop because we
need a smaller amount of time between
what we're doing and the context
consequences of what we're having in
production if we can shorten the time if
we can reduce the context context in our
memories if can we reduce that time
between this to establish this
correlation we can improve a lot the
quality of the software that we live in
to production and some of the techniques
that we're going to present you today
can help you to shorten this kind of
feedback loop okay
let me ask you a question now that we
find the perfect solution in our case
what do you think that we should do with
that solution the best answer is share
because when we share we have more
people joining this feedback loop that
adds and said we have feedback for
different people and that make us
stronger and that what that was
what a heroic was did with the the what
hero
iroko did Hiroko is a cloud provider
company and they realized that all of
their coast customers had more or less
the same problems and they call it
started to collect those the problems
and N and suggest a solution for those
problems and they joined they the
solutions and
the kind of methodology to improve the
cloud applications sorry and they
decided to call that 12 factor app
because that's a collection of best
practices and principles that we will do
a journey through all of them together
all of us now together will see those
factors and not only talk what are them
but we wouldn't understand
why it's so important to two cloud
applications to know what kind of
problem they solve let me try to add add
something to that here okay at that
point was a separate company now it's
part of Salesforce and Heroku created it
was the like the first large platforms
as a service as a service service
offering that we had so Heroku had a
very opinionated approach but that work
it very well that's why many different
developers from with different
backgrounds and languages we're
targeting Heroku as the default platform
but is it was very opinionated
Hiroko needed a way to share some best
practices so people could use their
platform so they shared this document
that 12 factor app but one of the
thoughts I think of the Heroku approach
is that at that moment they decided that
their solution would be proprietary so
they were using containers already but
he didn't share their source code they
didn't share the knowledge of the others
and that's why today we are sharing the
12 factor app concepts but we are not
using the Heroku solution in most of the
case because it's not open source and I
can't emphasize enough the power of the
open source yesterday I gave a solution
of why open source is the best possible
technology or alternative for you to be
deploying your applications on the cloud
and and today we are going to show you
how you can apply all of these 12
factors in your applications using the
default the de facto standard for
deploying applications in the cloud in a
container environment which is
kubernetes so all of the examples that
Rafa is going to show to you are going
to be applied on top of the Cuban
this platform yeah isn't just to mention
there's a website called twelve factor
dotnet there you you find the collection
of those factors and each factor has a
title and a brief description of each
one of them for example code base one
code base track the new revision control
menu deploys that seems a little bit
tricky so we will explain what this what
that means of course the site the site
explains itself but we will explore that
in an open source context okay so what
we will see now the first factor is
called of as I showed to you the code
base one code base tracked in revision
control many deploys but what does it
mean
of course it means that we should use
version control but use it in a right
way for example we have a rip version
control for a repository that will
create a package for that application
and that single application will be
deployed in different stages and
production and development on staging
whatever environment you have if you
have another app another application
that should go in another repository
okay so I want to mention what are the
things that you should not do for
example there are some companies that
are working in a fast release cycle they
are working in a development environment
where they fail fast were they
experimenting futures and they try to
place that in a in a in a repository
that's deployed only on development
environment and there is a another
version of the same application that's
running on production and that receives
receives this bug fixes or security
fixes and that's hosted in another
repository of course that will cause a
problem because
he has some in a moment in time you need
to have the new futures and also the bug
fixes and the security fixes so in that
case you should the application should
be at the same repository but of course
in different branches but only at the
same repository I would like to add to
that before joining Red Hat I used to be
an independent consultant and I was
singing some different companies that I
visit the threats that you have a
repository where you have no your
development branch and it was not
unusual but for my surprise that some
companies had a press well we had this
development when then we're just cherry
picking the files that we want to be the
point of production and we're copying to
another repository there's going to
generate they're too fat that is going
to production if you think that this
kind of thing is where I was expecting
it to be but it's not that unusual but
now these days we have a modern version
of trying to copy the files that we want
to develop it to deploy into production
from the development branch and it's
called cherry picking because many
different companies everybody just
commits on the same repository
everybody's developing different
features on the same master branch one
went but when the product manager or the
product owner decides to deploy that
coat that's artifact generate the
artifact to go to production they just
decide well which commit that do we want
to deploy into production then we just
if they're very advanced until I get to
be doing the cherry picking and just
applying that it into the production
branch which is a very very very bad
press we always advocate that you should
be having an astable branch to be just a
single source of code base for - for you
to be deploying in any kind of
environment from death to QA to
production of course another thing that
you should avoid is to have the master
repo where you place every application
that's an you should not do that and to
demo to do this journey through the the
12 factors we'll use an application
that's deployed here in these lights you
see the link so after I can give you the
link to the slides
and in this is a single repository
hosted at github with a single
application java application that's
available here
okay so let's continue to our second
factor which called dependencies the
subtitle is explicitly declare and
easily dependencies but what does it
mean it means that you should not commit
we are all Java developers right
of course many the modern language have
their own dependency mechanism but we
should not in this case of Java
applications avoid to store jar files
inside github of course if you are
storing jar files binary files inside
github you are doing something wrong you
should use maven for that case for
example that application that I'm using
here as an example it has a poem XML
file where all the palaces are declared
ok it's a vertex application and we will
see all those dependencies declared and
no binary files is stored
ok yeah the reason for not committing
your binary artifacts in your source
code repository is that your version
control operation is going to take a
long time and if you remember the time
when we had like hibernates doing in our
class path with lots of different
dependencies and you only have just like
Commons login and you don't even know
which version was that when you wanted
to upgrade the version of your add facts
you didn't know which version was
compatible with the other one so you
need to explicit declare which are the
dependency versions for your to easier
to maintain that in an easier way when
you didn't when the moment comes to do
then and library upgrade ok now to make
sense we'll take a detour to the factor
5 and then we will return to the factor
3 and 4 later ok because the factor
number 5 says about beauty release and
run it says that we should strictly
separate build really sand run stages
and there's a reason for that
the 12 factor app use is to accept
separation between build release and
stage and because each one of them has a
different purpose for example when we
are building a software what we will
release as a Java developer we will
release war files or if jar files with
our using pet jars okay and who will
produce that it will be a continuous
integration tool like Jenkins for
example and we want to use a continuous
integration mechanism or a continuous
integration tools because we want to
avoid that kind of phrase it works in my
machine ok we need to collect that that
data that that codebase the piece of
software from from the version control
ok
they then the next stage of the build is
to release and since we are talking a
lot of containers now nowaday instead of
releasing your war file or your jar file
we will release an image and there's a
thing very specific here every will
release should always have a unity
release ID and if you stop to think
about it every container has your your
hash to identify that container so that
hash can be used as an identifier okay
and what because why we are using
containers because it makes easy for
deployments it makes easy for updates
and rollbacks and finally since we have
containers we need a platform to run
container instances to run our
containers to run instance of our
containers and we need a platform to run
those containers because it gives us
speed management and orchestration I
would like to add to that why is that
white the requirements for you to split
in these three different stages
because our application is not running
composed about is not only about source
code your application to be running
properly you need a specific version of
your source code you need a specific
version of your environment and some of
the configuration that you need in your
environment can change at runtime for
example if you have your source code but
to be running effective that maybe you
need another operating system dependency
you need to be running a specific
version of the kernel or you need some
specific files that to be available some
other like if using you know JJ and I
you need a specific DLL to be providing
your environments so first you have your
source code you generate your source
your binary artifact from your source
code then you need to package everything
in a single in what we call now a
container which is a virtual appliance
you contain in your software source code
the report binary artifact and the
dependencies of that and then some of
these environment configurations from
your application needs to be determined
at run time for example your database
URL service might change from time to
time or if you want to switch providers
these kind of things must be provided at
runtime and not at you time okay so
that's why we need to split is separate
the the whole software development the
release process in these three different
stages so as you can see I just made a
first step the same the first stage of
the of this cycle we just did a maven
build what's the next step
releases release an image note here that
I have a docker file that specifies how
my container will be created so I have a
script here that we release this the
software as an image in this case I'm
using here openshift
which is a a platform that runs
containers it's its base it on Cuba
needs so if you see here on the about of
Red Hat openshift you see that's running
on top of Cuba needies which there are
castration platform for containers so
when
I'm doing Oh see new beaut I'm building
a software you can even see the log here
and this log of course is a the log of a
darker of a darker Butte and once that
the image image is available inside
internal registry you can see here that
this registry was released this image
was released a few seconds ago there is
a hash here that it went identified that
that release the software will be
deployed and we have will have an
instance for that container running and
why is Rafael showing OpenShift
overshift is an open source solution
it's a platform as a service that runs
on top of kubernetes in fact OpenShift
is a docker container running on top of
kubernetes and the thing is that
kubernetes is a very low level
abstraction you're dealing directly with
your containers but we are software
developers we need the other tools to be
productive in a container environments
so maybe we need some two to generate
our content our containers we need a CI
CD - maybe we need a container registry
maybe we need an interface to provide
this blog aggregation and other kinds of
features that's why we're showing
OpenShift
running on top of kubernetes that will
provide all of these tools that are
required for a successful software
deployment pipeline so we don't need to
do everything by hand okay and the last
stage was run the application which in
this case is already running as you can
see any parameter that I use here it
will say hello Java one from the name of
the container okay so let's continue our
journey through the 12 factors by the
way of course I presented every stage
here's separated but of course if you
think in a real world all of them will
be part of a single continuous CI CD
pipeline continuous integration and
continuous delivery pipeline okay they
can be different states of this
my pipeline automated it doesn't need to
be manual as I did here okay now let's
go back to the factor number three which
says about the configuration and the
config factor says that we should you
should store config in the environment
but what does it mean it means if you
need to repackage your application to
change something you are doing something
wrong it's like hard code values you
know you will not store database URLs
you not tower passwords match numbers
inside your if you have needed to do a
redeploy every time you change it that
database password no okay so in this
case how I will show that of course you
can explore your configuration in
different formats you can store in
property files you can store in config
files or even in environment
configuration in this case I'm adding a
new new environment variable and because
this is a orchestration Conner container
orchestration you see that this new
environment variable will was added at
the environment variable it's called
greeting and it has a different value
and want my application the text that
that new configuration from coming from
that environment variable it will cause
a redeployment and it changed the
behavior of my application note I didn't
need to read package to do that cycle of
build release and run on in my
application again I just changed the
configuration and it worked okay so
let's continue to the factor number four
which called back in service but what
does it mean back in service treat back
in services attached attach the
attached' resources so suppose and today
that you are using an instance of a
database in
installed on premise and then you
decided to move to the clouds to the
Oracle cloud for example you should be
able to do that by by attaching it
treating that resource as a attachable
resource if you are consuming something
for from the network for a product for
example if you are consuming something
from Twitter from Salesforce you should
always treat that as a tangible resource
and one way H demo debt is that as you
can see my application doesn't have any
database here and what I will do is to
deploy a database this is the factor
number four I would okay okay yeah you
don't assume your services are running
on localhost don't assume they mark and
they can be accessible through the file
system don't assume that you know the IP
of the service all of this kind of
certain must be located in some way
usually you use DNS resolution to be
locating your services which means that
your service today can be running
locally on premise on your local network
but tomorrow can be eternally accessible
through the cloud for example don't make
any assumptions about the localization
of your what the location of your
services okay it seems that I'm having a
network issue here I will not be able to
show that let me just try to debug that
very quickly to avoid yeah Wi-Fi has
been flaky and since we're deploying and
we need to sometimes download some
artifacts from the Internet
it can fail yeah so let me see
back in the planes had database let's
hope that the okay it's the point now
and now that I'm I will have database
deployed remember about the factor
number three about the configuration I
need to say to my application how to
access that that database so here inside
my application I added more
configuration I added the database the
name of the database the name of the
host the password the username of course
in this case I start in in an
environment variable so I'm not really
concerned about the security but I'm
just showing the how those factors can
interact with each other so if I can if
I come here to the endpoint DB it will
give me an error because the database is
not populated but let's populate that
populate database and if i refresh i
have connection al so you saw that I
just attached it I treated my my my
resource as a petrol resource okay now
what about the factor number six we saw
the factor number five during the build
and religion stage it talks about the
process that you should execute the app
as one or more stateless process and of
course this is a little bit
controversial because every application
has a state right you need to store this
they stayed somewhere but those states
for example the database values that
should be stored forever or for a
certain amount of time it should go
outside your application outside of your
container it should go in your back in
service okay even if it
a cache mechanism or database because
one big mantra of containers is that
containers are ephemeral they will die
and they can be replaced right you
haven't your application has to - well
we can consider even three different
kinds of states you have persistent
state usually which you are used to
storing up like a relational database
you can have like a Hemmer state which
is the state that you should be storing
in like a key value store like memcache
or Reddy's or infinite span and usually
the type that well information that you
store in an ephemeral database it should
be like HTTP sessions on anything else
and you can have what I could call like
a transitional or transactional let's
transfer over that state which is the
state that you pass along your requests
it just gets processed transformed by
your service and returned after that so
we're talking about state we're talking
about the ephemeral and persistent state
you should never store this kind of
information in process you should you
should always rely on a service because
you need to have the assumption that in
some in to any given point of time your
container or your running application
can just fail so we don't want to be
like we we need to be fault tolerant so
if this container fail fails we don't
want our system to fail you that's why
our data needs to be stored somewhere
else and in the on those cases on the
bag the service okay so what about port
binding this is very useful for people
who work in on the operation sides
because for example we all know that
Tomcat or most of the application
servers world fly application servers
what uses the port 8080 and sometimes we
want them to use the port 80 or in this
case my sequel runs on port 3306 but
suppose that for any reason in the error
because of the operation guys can I get
can say oh the poor 2006 I already have
database running I need to install a
second instance running on the port 5000
so you your application should never
rely on the port and we've container
that runs that happens automatically
because when you do for example docker
- P you can specify the port the mapping
port or if you do a - capital P it will
assign a random port to you okay
so never rely on the port number in the
reason for that is the since we were run
in a container world we want to improve
resource consolidation we want more
instances of any kind of service running
under that same hardware which means
that I can't bind to different
applications running on port 8080 so the
the translation between like the
official port 80 from the outside to the
internal container running in the
specific port should be provided by
infrastructure you should not be
assuming that your application will be
run in an exact port because this port
or in all of the translations required
to be it's ready for it to be running
properly will be provided by
infrastructure for example we have here
3 306 is the service port target into 3
306 what I will do now is change the
port in binding to the port 5000 as they
as you could see on the slides and so I
have now the port 5000 and the port 3
306 to be even more clear I will edit
the a Cuban Aires Cuban II this file
just to delete this portrait 306 so you
can see that I have the port 5000
targeting to the port 3 306 ok and my
application has now using the is it's
now using the the configuration factor
it has now the ports specified here and
if i refresh the application it's still
connected to the database I'm not
relying on the port 3 306 anymore I
chanted the port I
to my application where what's the
proper port and it's continued working
yes some options for distributed cache
like for the famous state should include
the most popular ones are probably
memcache and Reddy's but there yet how
do you say they just do key value store
there are very simple solutions well we
work for Red Hat we should be dead for
can't even finish span not just because
of that but we finished panel has more
features than this this the comparison
yes
but that's a long answer okay we can
talk later ok
concurrency is one of my favorites
because it says that you should scale
out the process model and the process is
the process itself that for example
suppose that you have increased on your
sales if you don't want to scale your
whole application just because you had
an increase on the sales so I like to
say that the this congruence factor is
the best advocate for micro services
because it you should split your
application on in modules in a way that
if you have increase of usage on that
specific module you can scale out an app
just that specific model ok for example
I have here just one replica that lets
container running ok and she scale that
I can simply say ok it's K or true 3
replicas oops now that's scaled to 3
replicas
once that it's available like that's for
example let me get API hello Java one
and do here curl while true do crawl on
sleep one second stop okay so you can
see now that I have three replicas
running I just scaled easy my my number
of replicas because I'm using containers
it's easy to come here and I have just
two replicas running or have three or
four replicas running okay yeah this
principle also state that you should
never assume that you only have one
instance of your application running at
a given moment so if you're relying on
Chrome based tests for example that
you're running you should assume that
well maybe I have like five different
instance running at the same time being
triggered by the same chrome trigger so
you probably have problems if you want
like something like a cron job you
should rely on external cron job for you
to be to be providing the triggers right
you never should rely on having just a
single instance running at a given
moment because usually that will not be
true okay what about the factor nine the
factor nine I like to explain it says
max Mac and maximize robustness with
fast startup and graceful shutdown the
best way that I'd like to explain is the
theory of pets verse cattle have you
heard about that theory yeah for those
who haven't heard is the that for many
many years we treated our servers just
like pets we give them names if they
were sick we took them to the vet and
literally one day I were arrived at my
work and I saw this isn't mean crying
because the server has died
and they serve I had the name it's
called plate plate oh it was the name of
the philosopher so here's what the
seasoning was really emotionally
attached to that server and if that
server died he almost died with him with
it there's no way he could get back the
sack to save configuration' right yeah
but with we should treat our servers as
Carol's because that should be easily
replaceable so if you lose a server if
you lose an instance you should have you
should minimize your startup time it
should start be started or stopped at a
tenth moment without any concern so for
example we have here three replicas
running right so what I will do is to
kill two of these processes okay and
note that the container itself it will
detect that the container died and we
have just one instance running but
remember it will be replaced at fast by
another instance automatically as you
can see here now that I have at the
second and the third web receiving
requests the request will be added here
as a part of my of my pool of servers so
it's like a kettle
I don't I it's not emotionally attached
I can kill it again
I destroyed to process I can run it
again and new servers new replicas will
be created no problem with the
application it's and it's because also
it's stateless right and I didn't lose
any data
okay what about a factor number ten they
haven't prepared priority keep
developing stage and production as
similar as possible of course we all
know that's a bad idea to get your war
file from your machine and give to the
seasoned minutes and say deployed I like
to say that the best thing that you
should do is use a continuous deployment
pipeline as I said you should place your
code in a version control and the
developer will place that in a version
control and something a tool a
continuous integration to a continuous
ICD two will get the source code built
and that package will you build that
image that will be deployed in on
different stages that will be deployed
on test environment let's say the same
package that will be deployed on stage
and finally if you approve that will be
deployed to production deployed to
production since we're talking about
containers basically we're just using
the direct band after consume one of the
great greatest benefit of container
which is virtual appliances we're
packaging software as software artifacts
we've environments and this principle
states that we should have the dev and
QA and production environment as close
as possible so if we're building your
container image which means we're
building other environments and an
artifact just once and we're just moving
the container between these productions
or testing environments we can guarantee
we can assure that we always have the
same environment of our application in
any different kind of cluster that we're
running that yeah and so just to demo
that you can see here that everything
that I did I did in my development
environment and I have here a - QA which
is the quality assurance environment of
course I have here my image which has
its own ID which is to be 30 te5 let's
see the pipeline for that part for a for
this deployment inside the open shift
environment I have the pipeline where
may they check the gear check out it
beaut it deployed on the development
they've run the automated tests of
course because I don't want to deploy
things we thought without in tests I
deployed that to my QA environment and
now I need to approve and send that
production once that I send that
production the pipeline will continue
and you will see that my application
will be deployed on a new project that
that was just created and if we go there
to the production environment we will
see that the product the projects is
being deployed and note here that it
this is the same image tchoo tchoo de 33
'if I've it was created five seconds ago
which means that the the same image was
promoted from one environment to another
create continued image once run it
anywhere ok and finally let's talk about
logs logs tell us that we should treat
our logs as event event streams ok the
12 factor app never considered itself
about routing is storage and containers
does that pretty well if you run a
docker container you see that the Lord
will be lost with your container so if
you need to do something with your log
you should have something external that
will consume that log stream and that
can be used for log analyzers with tools
like the ALK stack like search log stash
in Cabana for example just to demo that
you can see that I can tail the logs and
see the output of my application here
it's just a string
we're just restating that your content
your application should be stateless
because if you're writing your logs in a
file in your file system your
application is not stateless
anymore you're starting something inside
the container you should always again
use an external service for that yeah
and you can even see the log on the
terminal and finally and just in time
the last factor is called admin process
what does it mean it means that you
should run an admin and management task
as one off process because you you have
in a container the main process itself
so if you log in in a terminal of the of
the the the container you see that the
process number one is the process that
the container is running itself plus I
have here the new process that I started
it's a shell and the process that I just
asked it up with PS but the main process
number one is that the it's the main
process we should avoid as much as
possible to mess with that process
because that could cause the death of
that container if that process died so
if you need to do any kind of maintains
you should do in a one-off process in a
in a parallel process that you've woken
in a container and and avoid handling or
messing with the main process so we want
to conclude saying that these twelve
factors is not a specific Java in fact
it's technology and language agnostic
methodology okay but pretty satisfied
with containers as you could see and the
whole time we use containers it's pretty
satisfied with micro services and with
CI CD pipelines okay so yes we can
fulfill 12:12 factor this 12 principles
by using many different technologies and
applications but we truly believe that
the modern way of the plant that of
developing these 12 tighter applications
are using containers and CIC depop lines
and everything
and mostly lacking most likely using a
defector container extraction platform
like kubernetes okay that application
that I used with a java application you
can find here and you of course you find
these lights available at the java one
website so thank you so much for your
attention if you want to get in touch
with us this is our twitter handle and
we really appreciate for your presence
here thank you very much thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>