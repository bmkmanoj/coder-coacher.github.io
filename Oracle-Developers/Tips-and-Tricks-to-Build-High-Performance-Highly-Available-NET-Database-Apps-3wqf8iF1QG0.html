<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Tips and Tricks to Build High Performance, Highly Available  NET Database Apps | Coder Coacher - Coaching Coders</title><meta content="Tips and Tricks to Build High Performance, Highly Available  NET Database Apps - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Tips and Tricks to Build High Performance, Highly Available  NET Database Apps</b></h2><h5 class="post__date">2018-04-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3wqf8iF1QG0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so welcome you guys have learned a lot
about the cloud server less computing a
lot of different things today it's time
for a little more advanced session so if
you're a.net developer interested in
database and want to learn about how to
really improve performance and really
improve availability of your
applications not the database itself
although that helps but your
applications including the end and
availability well this is the session
for you so my name is Alex key i'm
oracle product manager for dotnet and
i'll be talking about oracle databases
in general sorry i'll be talking about
databases in general but a lot of the
tips I provide are going to be some
specific to Oracle databases and I'll
point out things that are generic and
things that are specific to Oracle
databases so why don't we begin I'm
gonna do a few demos and I'm gonna talk
a little bit about our demo environment
we're gonna use the cloud the clouds
getting very big in the development
world because it's very easy to set up
you can create a set of databases rent
them and use them as you need them or if
you just need some machines and
infrastructure you can do that as well
so I'm gonna be doing my demos against
Oracle's database cloud services so that
it's you know it's very easy for me to
use in fact the performance aspect can
get very interesting because I'm
actually connected to a u.s. data center
so I'm connecting all the way around the
world so something like a database
round-trip is very expensive for me
hopefully you guys will choose something
more local but in my in my demo
environment it'll be a little longer but
that's the data center I have because
I'm based out of the US and then we'll
talk about some of the considerations
your users you develop to increase your
application performance and also improve
your availability so let's talk about
the cloud environment what I'll be using
is Oracle's database cloud service which
is actually a DB CS which is actually
perfect for large past environments so
if you needed database service have it
easily set up you don't want to deal
with the operating system with setting
up the hardware with acquiring the
hardware itself DB CS is perfect for you
and if you're using dotnet and you want
to connect to it you
can use our Oracle data provider for
dotnet it's best to use the 12:2
versions although you can use twelve one
the latest twelve one version but ODP
done at 12 two is best on top of that
you can also use the tooling for Visual
Studio Oracle developer tools for Visual
Studio and connect because that just
uses Oh deep Internet under the covers
anyway any of the modern visual Studios
2017 2015 or 2013 are supported as well
as managed unmanaged ODP dotnet and if
you need some instructions for how to
set up your dotnet connection to
database cloud services we have this web
page for you to connect from on-premises
to that I'm not going to talk about how
that that's more of a getting started
type of session but I'm gonna talk about
just assume you already know and just
talk about the performance aspects of it
so let's talk about performance and I
kind of broke up this talk talking going
from say connections to commands to
getting results to using different data
types and providing tips as we go along
there so it's kind of you know as you
start your your application you're gonna
connect next thing you're gonna do is
issue some commands to the database and
then be able to manipulate data from
there so what is the one of the what is
the first aspect that you want to keep
in mind in general when you're working
with databases is that connections are
expensive creating them are expensive
they're in on their own you know
individually one by one they're not that
expensive but when you consider that
when your users come online and if
you're say working at a business and
people come in to work at 9:00 a.m. and
they're all trying to connect to the
database all at the same time well
that's when it gets expensive that's
when we usually get the concept of a
connection storm in which you have many
many users coming in trying to connect
and so what you want to do to alleviate
some of the pressure from a connection
storm is to pre create some of those
connections so that when those users
come in you can dispense the connection
that's already connected to the database
from a existing pool and that's what is
known as connection pooling and pretty
much every data provider supports that
all the way back to the OD
Vesey days they had a very simple kind
of connection pool and so everybody
supports connection pool for being able
to scale not only scale but also be able
to have very performant reaction to
connection requests and the nice thing
is that often times you'll have a way to
monitor the pool and net with windows
perfmon you can do that or you can also
do to programmatically with with in.net
as well right api is to monitor your
connections the OD p.net pool
specifically we have a couple things we
do recommend you to use so in most in
most pools you'll have a minimum pool
size and a maximum pool size something
like Oh dpi Nets min pool size and max
pool size and I'm often asked what what
should we set it to when we're when
we're designing our application and what
I generally recommend people use for the
min pool size is not the actual minimum
number of connections you expect your
users to use but rather what you expect
the average or steady state to be of
your load so if you expect on average
you know you have you know 100 users max
that you're going to support and about
you know 50 to 60 users that that are
going to be there most of the time well
then maybe it's somewhere around 50 to
60 is where you should set your min pool
size maybe even a little higher and the
reason why is that if the connection
ever goes connect number of people
connecting ever go down to like you know
five or six and all of a sudden you know
60 people try to come in you're going to
have that connection storm problem again
and the only thing you're sacrificing if
you have a little larger connection pool
at the beginning is that you're using up
more memory but you know if the machines
sitting there idly anyway you might as
well use that memory in preparation for
possible large number of people coming
in so that's what I would recommend for
min pool size for max pool size that
will depend on how what you're what
people are doing when they're on
connected to the machine so if they're
doing heavy loads a lot of processing a
lot of computation on your middle tier
you might not be able to support as high
of a max pool size it's just based on
how well your machine can handle the
load so if so basically it's something
you
to kind of you know figure out and work
around and seal okay my system can
handle 100 users maximum at a time if
101 users 100 and first user comes on I
get significant performance degradation
across the board so I don't want to let
that happen so I'll cap my max pool size
to 100 and you can always be a little
bit lower it's just that you just have
that you know you start getting more and
more users which is a good problem with
half you'll probably just buy another
cloud machine or you can add your own
hardware if it's on-premise but of
course the cloud makes it easy to scale
so you might just add another cloud
machine in the middle tier one thing to
note about OD p98 is the those min and
Max values are always obeyed those
anything in the connection pool and
there's some more connection parameters
but those are the kind of - two key ones
that most people need to ensure high
performance in their application and
then when we talk a little bit about the
performance counters and let me show you
how they work so I'll do a quick demo of
that performance counters are kind of
interesting because they allow you to
monitor in real time what your
connection pool is doing so you'll want
to see like okay I have this pool how
many connections are being used you know
as are they are they being used and
being dispensed and being returned
quickly or are they being used and
people holding on to them for a long
time so let me show you how to do that
so here I've got Windows perfmon up it's
just a standard part of Windows and I'm
gonna run this application here and this
application let me show you the program
itself you scroll up here and they kind
of scrunched everything on my screen so
I've got things pushed over a little bit
so let me let me fix so that it's easier
to read let me fix the font yeah it'd be
a little bit smaller hopefully you can
still read then didn't like that so it
kept it the same okay why don't we just
move on so I've got this program here
and here you can see we've got our
pooling parameters and
use the pointer here it doesn't show up
very well so we got a min pool size of
20 and a max pool size of 100 so this is
how you set your your your pooling
parameters and then I'm just going to
connect here and then we're just going
to go in an infinite loop just to show
you how the performance counters work so
you can look at those and we're just
going to open and close the connection
and do some work in between and then
have it sleep for about 0.1 seconds and
another interesting thing you'll see is
that I'm using a bind parameter which
I'll talk about shortly and bind
parameters can be very very useful in
terms of improving your improving the
way you're being able to parse your
statements and be able to use soft
parses instead of hard parses but I'll
talk about that a little bit later
so once you've you've got your your
application done you'll want to indicate
hey I need to turn on I need to be able
to turn on monitoring for my my counters
so you go to your config file and since
I'm using a client-server app we'll use
the app config and you indicate under
the settings area of the the dotnet
config file for Cody P net what exact
performance counters you want to use so
here we have set that we're setting it
at 12 which indicates you want to take a
look at soft connects and soft
disconnects and then also we indicate
which pool to monitor and so this is the
same pool that you saw previously except
without the password obviously and we
just give it a pool name and this allows
it to be more easily readable for human
beings rather than having to like figure
out okay which pool am I looking at
because you could be monitoring multiple
pools and it's easier to put like a
string that you will easily identify for
that pool so they basically we're done
we're all set up let's run this and
you're not gonna see anything on the
screen because I don't have anything
being generated but let's take a look at
the performance counters and let's add
the performance counters here so I hit
the little plus sign and then we're
going to go to ODP net
and we scroll up here the manage driver
that I'm using and we can see here that
we've got the instance showing in the
middle tier running and we can go by the
the node level the app domain level or
the or the connection screen here and as
my Oracle DB that you saw that I created
before so we're gonna it doesn't matter
which one we choose because it's just
one database anyway there's no rack
cluster so there's no individual nodes
to monitor it's all the same app domain
anyway and you can see we have about
twelve different statistics we can
measure but we've only enabled two of
them these last two here so soft Connect
soft disconnects I'm gonna add those and
we say okay and now we should see those
statistics being generated and you can
see that we've got about three connects
and disconnects per second and it's a
little hard to see the green but it's
kind of being hidden by the red part so
if I if I I unlocked the red sock the
connects per second you can see the
green and if I put it back on you can
see the red there and is it a little bit
easier to read if you use the report
graph and you can see that there's about
three connections being connected per
second and three being disconnected per
second so that's how you kind of use
performance monitoring to be able to
take a look at your profiling of your
connections because that's what often
people do one thing I do want to show
you is the database I'm connecting to
just to show you what what it is in the
background and get you a little bit from
the middle with the Oracle cloud this is
the database we're connecting to and yes
it's in the United States you can see
it's in Ashburn which is in the state of
Virginia and the east coast of the
United States but it's a database that's
12 to version Enterprise Edition and I'm
connecting to it using first using the
public IP and then I can then go to look
at what the port I need to use 1521 and
then the host domain and that's
basically all I need I just need to
identify which pluggable database to use
in this case I have a PDB one that I've
and then I put that in and then you can
see in my connection string here I'm
starting out to connect a string in my
connect descriptor I've included that
information that the host information
the port and also the that subnet the
domain I'm sorry that we have here
including the PDB name so that's all I
needed to do to connect to the the cloud
another thing you can do is if you want
you can set up a middle tier net
infrastructure-as-a-service if you want
and I have one here so you can I'm going
to just connect to it with remote
desktop and you can manage it just like
any other middle tier machine that you
would use except now it's just in the
cloud so if we just log in here this is
a Windows 2012 r2 machine and then we
have is manager up so I just wanted to
show you it's in the same data center as
if in my database but this is
infrastructure as opposed to the
database which was which was a database
as a service okay so that was
connections and may you yes no you can't
because as soon as you so the question
was can you change the well so yes and
no you can do it but you're going to get
a bad side effect so if you change any
of the settings the mid max almost
anything except for a couple things like
proxy in the case of OD Peter net for
different reasons you can change the
proxy and not not have anything be
affected so if you as soon as you change
something that indicates the ODP dinette
and and you generally to most other data
providers to that you're using you want
to use a new connection pool so OD peed
on that actually what it does is it
looks at all the values and as soon as
you change a value that that's
indicative that you want a new
connection pool so if you same in pool
five instead of in pool 10 it'll say
okay new connection pool this one anyone
calling min pool five is now
in this new connection pool and you have
a separate connection pool form in pool
10 so you can dynamically change it but
you have the site effective you actually
are creating new connection pools which
is not what you want you actually just
want to change the current connection
pool which you can't do and and
basically all providers don't let you do
that so it'll so if it hits the max and
people are still requesting it'll
timeout so you usually each provider
will provide a connection timeout value
whether it's a minute or 10 seconds or
30 or you can usually you can set it and
what people said is default is up to
each each vendor but when you hit that
max when the time hits where it hits the
limit you'll get a timeout the end user
will see a timeout and then they can try
again and so if you're hitting that
problem just add another node add
another add another middle tier of
course then your database might be
overextended then you just add more more
more database nodes to at some point you
know that's a good problem to have in
the sense that hey a lot of people want
to use it so you know if it's something
revenue generating then that's good then
you can have something to support buying
more machines and what that so I
apologize if I'm if I'm going a little
fast I do have a lot of cover because
performance actually is probably where
they have a two to three hour talk I'm
trying to spit as much as I can in about
30 minutes so I can also cover H a some
other interesting things about the Oh
deep internet connection pool one thing
we introduced several years ago was run
time connection load balancing so a lot
of people use real application clusters
or something like global data services
or Data Guard and that allows you to
have connections to multiple database
server machines now one thing that
sometimes happens with that is that you
know if you bring a new machine up and
you want you want load to go to that
machine well unfortunately the
connection pool just has connections to
the existing nodes it'll create some
connections to the new nodes but you
know there will be a lot of connections
to
the other other nodes so at the Spence
time what we do is we figure out okay
which nodes are very heavily loaded and
which ones are not and what what ODP
done that we'll do is give a connection
when there's a request to one of those
less loaded nodes so that way you
balance out the the the load among each
each node among each database server
machine pretty quickly as long as you
have people connecting and disconnecting
can I gain Vista connected so this is a
runtime connection load balancing and
all you need to do on the.net ODP dotnet
layer is set load balancing to true your
connection string once you do that
you're done I'd like to say the rest of
it is your DBA handles they handle all
the the setting up of the fan the fast
application of Education which I'll talk
about a little more later when I talk
about a che but they do most of the work
which actually isn't that hard it's
mostly a configuration exercise but they
do have to configure it and plan for it
and have kind of a machine for
supporting clustering but the work for
the application developer is very
minimal just load balancing equals the
true yes on premise or even in the cloud
you can you can do this yeah it's very
actually is very commonly used right now
on-premise just because we first created
about probably seven eight years ago
it's been a while since we've had this
feature database connections Oh so this
is actually this applies to more than
database connections but almost any
object within net which is that whenever
you create an object like an Oracle
connection or any connection an Oracle
command Oracle parameter you create it
and then at some point you should
explicitly destroy it by calling closed
or dispose and you might say well gee I
got a garbage collector why do I need to
explicitly close in the suppose the
whole point of this garbage collector is
memory management I don't need to worry
about it this is not see this is this is
a dotnet or this is Java why do I need
to do this well a very bad problem
happens when your your systems under
heavy load is that the garbage collector
can't get high enough priority to be
able to function be able to clean up the
the memory needs to in a fast enough way
that it can do to to make progress in
giving you memory back so what happens
is memory starts to accumulate among
more and more connections and soar or
whatever objects that exist and they're
just Eiling waiting to be cleaned up
because they haven't been explicitly
disposed of and then you soon hit a
problem of running out of memory so one
of the things that you know people who
often call in support say oh you've got
a memory leak and we first asked them
did you make sure to close and dispose
all your objects connections commands
etc not just OD pete on that but also
your your net objects and just match
them up when you do a trace then make
sure all the the opens match with the
closes and a lot of times they figure
out oh we didn't and then they add that
you know few closes and disposes and it
clears up the problem magically so
that's that's something to watch out for
bind variables as we move into from
connections to commands bind variables
are very important and the reason why
you you know if you have a statement
where you're doing like select star from
employees where department ID equals 50
equals 100 equals 150 whatever each of
those statements if you change just a
literal without using a bind variable
that's considered a unique statement in
the database whether it's Oracle or any
other database and that means it has to
do a hard parse on that statement it
means it has to get you know the the
memory objects for that statement and
return it to the client so it becomes
very it can become very cumbersome for
for the database to do that all so wait
if you use bind variables and it sees
that you've bound a variable to where
the department ID is because it is that
the same statement in terms of figuring
out what metadata to use and figuring
out whether to use a hard part to do a
hard parse or a soft parse the soft
parts will save you much more than a
hard part so if you're executing the
same statement over and over again just
changing that last value or changing
just values which you could be using
bind bind parameters in and replacing
them from literals then then you'll save
your database a lot of grief and be able
to maximize your performance now one of
the things with using bind parameters
is that well it's theoretically you'll
always have that par stored in your in
the database memory there are times when
you're executing so many statements
those those parses fall out of memory
and you know you the the database looks
for it's like it's not there I've got a
real hard parse this so ODP Nanette has
introduced statement caching and
statement caching allows you to store
that in a statement cache that part's in
a statement cache and ensure that your
most recently used statements for for
you as an end-user regardless of
wherever the database is doing we get
retained in the statement cache so that
they can be reused over and over again
and of course it works best bind
variables and what we figure out also is
we self tune this cache for you so if
we're seeing you're executing 50
statements on a regular basis we'll keep
that statement cache set at 50 for you
if it's only 15 or 10 we'll keep it at
10 or 15 depending on how we see which
statements are executing often and you
don't need any code changes for this on
the client side it's all obviously with
bind variables you've got to change your
code behind parameters but with the
statement cache you don't need to change
any code to use it in terms of data
retrieval
now that you've executed your statement
you want to be able to optimize how you
return your data to the client side the
key thing you want to remember is
reducing number of round trips so
creating connections is expensive round
trips are pretty expensive too you want
to minimize how many round trips back to
the database you're trying to create
data so if you are if your end user
needs to read 50 rows of data you want
to try to retrieve all 50 rows at a time
if they're trying to use it in that one
and that one instance and then they
review it then look at the next 50 rows
and then you try to retrieve the next 50
now the reason why you want to do this
obviously is that if you set your if you
if you set your data buffer size too big
to retrieve you're going to be wasting a
lot of memory on the client side
especially if it's spread over many many
statements if it's too small you're
going to be doing more round trips so
finding the just right size is very
important
and the way you do this with ODP dinette
is which with our effect size property
off the the data reader so when you
execute a command whether it's a sequel
statement or whatever you'll get
populated this row size property and it
will tell you exactly how big the row is
from your select statement that you've
made and then based on that you can say
well my end user needs 50 rows so I will
set effect size equal to the row size
times 50 and that will retrieve 50 rows
per round-trip and that's something you
can obviously with row size you figure
out at design at run time it gets
figured out and then you can dynamically
set how many rows you want returned or
have the end users ask how many rows
they won't return if it's 50 if it's 100
they can send it and then you can make
that equal the fetched size so that does
require some coding to do a little bit
but it makes it really optimal in terms
of how to make sure that you return the
right amount per round-trip so let's
show you a demonstration of that so here
we have we're gonna execute this
statement select star from employees and
then we're going to time it so we're
going to time this part this for loop
and if you your smart diet you can see
that I only run it one time and that's
because I've I tried doing this from
from here combined with the Wi-Fi with
having to go to US data center it takes
about 9 to 10 seconds to execute just
once so so this is the slow method which
is we're gonna we're gonna find out the
row size so you can see after the
command is executed
I'll have row sized populated so I can
use it and I'm going to multiply it by 1
and then we're gonna set that defect
size and that's going to indicate I'm
gonna retrieve one row per round trip
which is amazingly slow because it's a
hundred seven rows so I'm gonna do 100
senators round trips and we're just
going to read the data just pretending
like we're processing it but we're not
going to bother outputting it to the
screen or anything so we're going to
time to see how that takes that should
be slow and then we're going to time to
see how long
takes two to execute the same thing
except this time we're going to multiply
it by 107 which happens to be the exact
number of rows that are being are being
are in the table that we're selecting
from and that means we're going to
retrieve all the data in one roundtrip
or you know if it's too big is to be as
few round trips as possible so let's
execute it and see what we got so when
I've done this before it's been about
nine to ten seconds so it'll it might
take a while but this provides a very
optimal way for you to say you know if
I've got data and I want to have just
the right amount of round trips coming
back and using fresh size on both sides
will be perfect for that so I know it's
a little small hard to read but it says
nine point five eight seven seconds for
effect size of one row and then when you
set a thread size of bushes at 107 is
0.14 for nine seconds so about half a
little under half a second about two
thousand percent performance improvement
so pretty good you should use fetch size
when you can of course you can leave the
default on which depending on the
version you use is you know can be big
or small we've increased it as time has
gone on but you can leave it at the
default but it's best if you if you if
you choose if you know exactly how much
your end user is going to retrieve at
once to use that no it won't because
we're still going back to the database
to retrieve it are you talking about the
parse or true well yeah you could you
could be in the yeah yeah although in
this case because I'm going around the
world to get it it's gonna be a round
trip so next time I can I can reverse it
but you let me just say you're gonna
still see benefits for this yeah maybe
it won't be exactly 2,000 percent and
there's always a lot of other things
that get in a way you know things like
is there anything else happening on the
machine at the same time things like
that network congestion and whatnot but
it's it's a rough estimate it's a demo
so data types
one of the interesting data types we
have is the Oracle ref cursor and it
works actually very similarly to a data
reader but you know it's very Oracle
centric so you can use it in order to do
things like take after you do a select
you actually don't actually get the data
when you have a ref purser yet what it
allows you to do is defer the results
that retrieval until the time you
actually need it so that you have some
fine-grained control over processing
when to process the data you can do
things such as let me just skip the
first ten rows I'll just start reading
from row 11 because maybe my end users
want to just read from the eleventh row
on rather than starting from tenth or
let me send this ref cursor back into
the database as an input ref cursor into
a stored procedure for further
processing you can do that as well and
the nice thing is you didn't have to
pull any data down in order to to use it
like that
so ref cursors are very flexible if
you're familiar with dotnet constructs
is just like a data reader as I said so
it's it's very useful in terms of
deferring that result set retrieval and
then controlling how you want to bring
it down to the client and lobs are work
very similarly to lobs are any large
object things like documents like Word
documents Adobe Acrobat videos sound
files pictures you know things that are
in binary or text format that are very
very large and by default our our Oracle
Labs work just like the rough cursor
which is it's a deferred results it fits
because we you can actually select you
know gigabytes and gigabytes of lobs but
you don't necessary fetch that you know
the instant you execute it because that
could really bog down your network
especially if many users are making the
same query so to prevent that we just
fetch you a lob locator which is just a
pointer to the lobs
and so because of that you can control
when to bring that lob down so you can
just fetch maybe one page of that
document or maybe the last 10 seconds of
the video if you want it's just like the
way the ref cursor works another nice
thing about this lob feature is that if
you do want to select all the law
data at once you can we have a property
called initial life exercise which says
forget about this lob locator just get
me the first X amount of bytes from each
of my lobs and we'll do that for you so
if you have a lot of small lobs it's not
going to take up a lot of network maybe
you just say give me the first 1k of all
your lobs
so you set initial not bed size the 1k
so that becomes very handy and if you
set in that initial head size to
negative 1 that just says just we
retreat me all the data from the lobs
instantly you know if you want that if
they're all very small then that works
perfectly a general tip is being able to
use stored procedures and functions I
mean a database is very useful but it's
not a dumb data store necessarily
there's a lot of intelligence you can
build into it and one of the things that
you can really save yourself on a round
trip is that not to do the round trip to
keep the data on the database side and
do some of the data processing there
where it makes sense for example if your
end user only needs you know 100 rows of
data but they're doing a select for
10,000 rows maybe you want to do that
select on the on the stored procedure
side do the processing figuring out
where the hundred rows that this end
user needs and just ship that over to
the client side rather than the 10,000
rows and having that do it it'll save
you the round-trip of pulling all that
data down when you don't really need to
use it and then also the the ref cursor
idea was talking to before is that have
the database work on data processing
tasks and then have the middle tier work
on probably more computational heavy
tasks with some data processing when
it's needed in terms of what else we
have
boy I'm running slow on time here not
gonna have much time for H a so we have
caching as well caching we have several
ways you can do caching and the
important distinction between this cache
and another cache is is that these
caches all provide updates to the N
cache so if your database server has
gotten an update that would change the
values in the in the cache
the database server will tell the cache
hey your out-of-date you have dirty data
and then some will do it automatically
will update the data for you
automatically on the client-side and
some will require that you initiate the
change and provide your own logic so if
you want an easy-to-use updatable cache
client result cache that's perfect for
that a much more configurable cache as
the continuous query notification cast
cqn and that won't update the data
automatically for you because it is
customizable but if you want
customizable use client result cache I'm
sorry if you want easy-to-use user
client result cache if you want
customizable use cqn and then if you
want a very very fast cache you have a
lot of contention in the database but
you need a cache but the data keeps
changing you probably want to use times
10 in-memory database and that's
available for you and dotnet I just want
to remind you database round trips cost
a lot of money a lot of rupees and you
want to save yourself these caches are
nice because they only initiate a change
to the client side when a change on the
server side happens you don't want to
you know just ping ping the database and
say did I did a change they change you
just you want to get an update have the
server do it for you and that's what
those do so I'm gonna run pretty quickly
through the HEA slides here so those
were the performance aspects and let me
just say one thing I have my slides up
there actually 60 with some slides I'm
not going through 60 slides here but
those slides cover you know more
comprehensively than what I've talked
and what I can talk about in 45 minutes
so that you guys can get more idea of
things to do for performance things for
do for a che so this just gives you kind
of a flavoring of things there I've also
put up my sample code onto github as
well so that if you go to the github
site I'll show you at the end you'll be
able to get it if you want to try it out
so let me talk very quickly about h.a so
the nice thing about database h.a is
that you know you've got rack you've got
data guard a lot of great technologies
to provide for your high availability
but as an application developer you're
going to be like well you have some
interesting new problems which is
you know if a database goes down you've
got bad connections in your pool now so
with that how do you how do you fix that
problem and or close the technology
called fast application notification fan
and what fan does is it has something
called CRS that is watching all your all
your nodes on your cluster or your data
Guard instances or your or your global
data services and will tell you whenever
a node or a server goes down or a
service member goes down and tell a dpi
net and what ODP tonight can do is then
clean up the bad connections to that one
note or to that one machine that way
your end-users will never get a bad
connection also be able to clean those
up that are immediately bad connections
so that your end user can continue
working if they happen to be holding on
to one of those bad connections so in a
plan maintenance scenario what you can
do is that fan will alert
ODP Dannette that node has gone down or
Machinist going down so what will a deep
internet do it'll stop allocating new
connections to that node next it will I
enforce any idle connections in the pool
- that bad node it'll force it to close
and then lastly it'll wait for this is
for plan plan maintenance I'm sorry
so it'll then drain it after that so
that anyone who's completing work will
get it drained and then won't be able to
well well as soon as all the connections
are drained from the pool to that to
that one no that's plan to go down then
maintenance can be taken on that so at
the end of the day your end users will
see little or no disruption because of
the ability to do plan maintenance so
I'm being told to wrap up so I'm going
to go I'm gonna skip a little ahead this
plant this pool draining also works with
Data Guard switchovers - so that's
available as well as we have a way to
ensure that during the switchover you
have this service relocation connection
timeout which ensures that your
end-users will pause and won't see an
as the switchover happens which could
happen in past releases but in 12 -
database talk to it it doesn't happen
with the service the relocation
connection timeout with unplanned
outages you also have the similar
feature with with fast connection fell
over but this time we immediately kill
your connections and then you can also
use transparent application failover
which provides a way to restore your
connection restore your session state
now in 12 - and then also replay initial
transaction statement now if you go
beyond that in order you want to replay
the entire ensure your transaction
whether it's been complete or not
complete which is kind of the holy grail
of restoring your session which is not
just being able to restore your state
but also figure out whether your
transaction completed or not we offer
application continuity which is
something new that ODP Nanette's
supports in 12 - so if you want to use
it you just set application to
continuity - true and you use the 12 -
versions and I know I went very fast
over the AJ features but I'm happy to
talk to you later about it again these
slides are available to you on our I
didn't put up the github site but
actually I have a longer one our H a
session to talk about all these and much
more detail on my on the youtube site
for our team so you can go to that
website and then our github site is it
will be available off the OT n page so
that you can get the code for the
performance demos but thank you very
much and I'll take questions and answers
after after we wrap up here thank you
actually it's quite popular so and the
enterprises I see most often use Java
and.net and and because enterprises are
using most enterprises are using Oracle
database so they happen to be using net
- and it's it's kind of actually
interesting because you have I don't
know if you're a regular application
developer but what I often seen is like
you know DBAs and and developers there
kind of like two religions and and we
all know what two religions they don't
get along you know it's kind of like
well we're just doing databases and we
believe what we're doing is the best but
all the performance problems they're all
developers are causing it and of course
the developers always say oh those DBAs
they don't know what they're doing and
we know what's best and but the problems
always the database so you know they you
know a lot of times the the developers
choose the technology and database
vendors choosing the DBA choose another
because it works best for them they
think it'll be the best solution and you
know with dotnet it we just were in
charge of making sure it works well so
we do see a lot of people use it because
you have a lot of people who are just
that net developers who love it and they
just say just give me give me something
that works and I can use the features
that DBA tells me to that's all they
care about no problem okay you can ask
Microsoft but I don't think Microsoft
would agree with that I think they're
trying to evolve dotnet well cloud is
getting cloud is getting popular yes
that that's correct I think I think
everyone you know is looking at cloud
saying like you know it's becoming
important I don't think there's anyone
in the industry who says oh this cloud
thing is it's not it's not going to
happen and in fact we offer our we offer
our cloud solutions on on dotnet so we
we have an application container which
you can run that net core on we have D
BCS which you can connect that net to
which you saw in my my demonstrations
you can also have a dotnet running on
your infrastructure as a service so
actually I did a demo of that if you
attended my header events
last week but you probably did it
because it was in Hyderabad but but I
did a demo of that and unfortunately
they didn't record that one but I think
we'll probably do a YouTube video of
that so take a look on our YouTube site
maybe in the next month it will probably
upload it by then okay okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>