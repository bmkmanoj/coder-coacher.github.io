<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>DevOps in Action: Show and Tell Session on Handling Production Grade Container | Coder Coacher - Coaching Coders</title><meta content="DevOps in Action: Show and Tell Session on Handling Production Grade Container - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>DevOps in Action: Show and Tell Session on Handling Production Grade Container</b></h2><h5 class="post__date">2017-08-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZjD694O2GTI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey great so uh welcome everybody this
session is about DevOps in action show
and tell how we handle production great
containers there are actually two
buffers in there like DevOps and
containers how many of you are familiar
with docker containers just to get an
idea using it okay how many of you are
like having applied a DevOps practice
and you're in your company already
DevOps culture okay so this is what this
is about today I'm going to talk about
like DevOps how Devils has being done in
a modern world as well as how to handle
containers and I give you a bunch of
tips and tricks how to work with
containers there my name is Marshall I
work on the Oracle micro services cloud
so I'm basically responsible for
building out a micro services platform
that's what I've done the last four
years I build out two micro services
platforms one proprietary the other one
based on kubernetes and PC owner DCs
that's pretty much what I'm doing at
Oracle another charter there is building
out some services that support micro
services and that's what we use as a
showcase today so the service we touch
on is a real service we're using into
Oracle internally and I'll talk you
through how we do DevOps with that
service cool all right
so agenda objectives so I'd really let
you know what you can expect in that
session and what you should be taking
away from it and I'll talk about what is
DevOps because I didn't see a lot of
hands and I think it's really important
that you understand the difference
between like traditional death of our
development and operations how how it's
done in the past or how it's done most
of the time and enterprises and how it's
meant to be like in a more agile world
so I'll go into that then I briefly
touch on the service use case what's the
service so that you get an idea what the
components are and what you're dealing
with when we release updates that has to
do with their just service design goals
and principles I briefly touched on the
platform architecture and I'll talk you
through our entire CITV pipeline as well
as the lessons learned
sounds good all right objectives I've
already mentioned it we're going to give
you an insight in
our production grades are cloud services
how to do this again that's not a
service that's built for demo purpose
that's real service that we're using
internally also some insights into
production grade CITV pipeline why am I
saying that because I don't know how
many of you have read books about DevOps
continuous delivery continuous
deployment right so the new thing is you
check something in and you deploy it
into production and I'll tell you we're
not doing that we're not going all the
way and I'll tell you why and I think
that's useful lessons on you takeaways
or you get some insights into depth of
practices how we run our stuff
internally as well as how we build out
more or less a pattern for other Oracle
services internally all right so what is
DevOps ah that picture sounds familiar
to you or like how many of you are
developers how many of you are on the
operation side you guys talk a lot with
each other right
so what happened in the past even when I
was like writing code it was always like
that blame culture right oh I built my
software it doesn't work and then you oh
that's that's on your machine because
there should be a DLL or something on
that machine it's missing right and vice
versa like the ops person says no no no
you should package that stuff so that
box is meant to address that it's really
a combination of development and
operations team and they work on a
unified goal and the goal is really the
highest quality code and infrastructure
and service shorter span of time and
that's really important because now the
way you look at infrastructure in the
future is also different than the way
you used to it right it's not just oh
I'll take a server off the shelf it's
really like I need to make updates to my
infrastructure and it should be seamless
so now at that point your developers
your infrastructure your operations team
need to work together as one um so I
have added a table I've taken out of a
book that I wrote so that's traditional
and modern devil so in a traditional way
quality of code check-ins I mean most of
the people do some unit testing but it's
really not you really don't know what's
the quality of that code especially
if you deal with dependencies right you
may know your codes working well for
your scenario but what's really the
quality modern DevOps there's a huge
emphasis on unit tests when you check in
CI to continuous integration so that the
code is actually really validated at its
same as sound rated you're not shipping
anything that might harm it the
environment creation and I touched on
that it's also very different right in
the past you went out there and said hey
I did some analysis I need three servers
right you enter your hardware department
and said or there are three boxes hey
and then you basically put them
somewhere you connected them together
obviously in the cloud you already have
the servers but you still most of the
times you need to spin up an environment
that environment creation is fully
automated so there's this notion of
configuration or infrastructure is code
which basically means you describe your
infrastructure as part all in a
declarative way and say that's the
infrastructure that should host my
application and then you basically spin
it up in an automated way right so
that's another difference deployment
frequency of applications I've been
dealing with customers who deploy like
once every six months or every every
year right so it's it's long release
long deployment cycles for an update to
roll out in a devops world if you
actually deploy whenever needed
included several times a day there is a
there's companies like the big ones
Twitter and Netflix right it did deploy
like they put out like a hundred
thousand today right and that's only
possible because it's everything's
automated so the application deployment
process in a typical like enterprise
fashion you're planning meetings right
hey oh I have a new update let's sit
together let's see how we work it out
and push it out there then you have a
bunch of things where you drop your code
and any push it out in a water and death
of slow it's really a push button to
blunt and and the development team is
responsible for pushing out the code
into production monitoring wreck
there's a so the question was am I
talking about deployment into a deaf
caste environment or production it
actually goes for both because if you
think about you have continuous delivery
and I'll talk about that which basically
means you have a drop and you may put it
into a pre staging environment or a test
environment that's what we do I'll talk
about that that being said in a modern
modern cloud applications there is also
the notion of deploying to production
and the way you can do this is you can
run versions of services side-by-side
it's a micro services architecture we've
basically put it out but it's more
complex you can technically do both and
I'll talk about why we don't go into all
the way into continuous deployment okay
there are things that's cool so oh sorry
I missed one important part here the
other thing is the monitoring piece
monitoring doesn't necessarily mean you
only monitor your application right if
it's healthy you also monitor in a
DevOps way in a modern way you monitor
the usage of your application have you
invested in the right features great is
that feature is even being used or
people dropping out and things like that
that's really what a lot of people think
about when you think about health and
performance monitoring or monitoring in
general right and so DevOps and
relationships it's in the modern DevOps
way it's really a culture of trust right
it's a give-and-take there and the the
different differentiation is varied
everything's blended in so if you look
at the death of cycle on the left upper
left it starts with a planning backlog
you typically have a backlog for minimal
Viable Product and you say okay that's
what we want to put out there as a MVP
Minimum Viable Product then it goes into
development and there's a development
cycle you can also think about it like
as an as an inner development cycle
because not cycler developer writes the
code for the component are built it and
test it rate it stuff like the first
inner loop testing if you will right
then once the developer says hey gray
that thing works well it pushes it out
into the
Lerman and that can be again can be
continuous delivery or continuous
deployment then once it's in production
you actually start monitoring and learn
how that thing is being used and based
on the outcome you may even update your
you brought up that log again because
you may not use features or you may add
other features wait and then the cycle
begins again I think what that picture
actually shows very well is how
development and operations actually is
everything it works together okay
all right ready mention a couple of
times continuous integration delivery
and deployment does everybody know what
that means difference between delivery
and deployment cool so continuous
integration means you write your code
you check your code in rate and then a
build step is being executed in a bunch
of tests that's continuous integration
then you have continuous celebrity
delivery that means your code is
production ready by running immigration
load tests and so on and so forth so
you're running a bunch of tests on it
but that thing is actually being dropped
somewhere usually and that's what we're
doing right and enders of thing
continuous deployment and that's way
literally run all your tests if your
tests on that component have been
successful you push it out into
production that obviously requires a lot
of work on the architecture in the
production how it works if you deal with
different versions you need to route
traffic and things like that and there
are other reasons why continuous
deployment didn't work for us and I'll
talk about that but think about it now
if you read about it continues and
delivery and deployment are two
different things when people talk about
it rate deployment really means I put it
in production deliveries what people
usually refer to I checked in my code I
did continuous integration now I build
it I run a bunch of tests and I have my
life service or defect and then I
deployed all right so that was a really
brief primer on depth of service use
case now I'm going to talk about the
service that we build and then I'll talk
you through how we actually do their
folks women make sense cool all right
service use case is the backbone for
other internal distributed services you
guys probably who went to the keynote
okay you liked it all right as you
probably notice we're building out a
bunch of services in your group cloud
right
and that requires on our hand we also
need to have supporting services
internally that can be used by other
services that service I'm talking about
is one of those services because a lot
of our services are distributed systems
distributed systems need leader election
they need some service registry
discovery configuration management so
that's the use case that we were asked
to build out potentially we're making
that service available to customers
because that's very useful features that
is especially need a micro services
world but we haven't decided yet when we
put it out publicly on the service
design goals how did we look at that
obviously because it's a cloud service
that supports other cloud services it
needs to be hyper scale right it really
needs to be scalable because we want our
cloud to be successful if they're
millions of people on our cloud over
here that service gets hammered and
needs to be scalable right it needs to
be highly available because other
services depend on it if our service
goes down other services go down so in
that sense because it's a distributed
system something will fail it has to be
resilient
okay so resiliency was another design
goal and then multi-tenancy was a design
goal for us internally because it's an
internal service we obviously want to
make the most out of the hardware
resource and utilization that we're
using so we said okay we going to build
a market out as a multi-tenant service
so run multi multiple tenants on one
machine and then we had to optimize for
a child delivery and that's where we
basically get back to the DevOps because
if another service team needs a new
feature we need to be able to ship that
thing right away we cannot wait six
months or three months to update a
feature and some features are chosen one
component so those are the service
design goals the principles we applied
is designed to optimize for time to
market yeah
yes so the question was affection
elaborate on multi-tenant and if you
read like two slides I'll show you so
design principles are we obviously how
many of you have heard about
microservices it's absurd password in
obsession okay so we went with a
micro-services approach because our goal
was really designed time-to-market
micro-services is as much as a desktop
thing then it is an architectural thing
because it's all about like speedy
delivery of components right so we chose
my micro serves architectural approach
each service in our overall application
is delivered by independent development
teams everything's automated up to a
certain degree and I'll talk to you how
far we go with automation and just
already get an idea we have nine
separate services which are delivered by
five different geographically
distributed teams so if you can think
about like if you put everything
together in a common pipeline that's
going to talk so governance because we
have all those components we had to have
governance in place which goes into
deserts as well so we had or we have
standards for unit testing coding
standards and code reviews and all the
comments think about that's the first
thing when I talked about code quality
so that's one thing that every service
team has to follow and then obviously we
also have common architecture reviews
and common patterns like application
packaging versioning and log format
particularly important because you think
about you have nine different services
you have five different teams if you
give them the choice whatever they want
to use you end up in anarchy right if
you don't have a common log format
everybody blocks out some certain random
message you will never be able to
monitor those services and basically put
them together every service has to be
deployable in testable and can be
promoted and it has to be built to
operations so that's part of the death
of spiel here we have a custom dashboard
you eyes that give us a view into where
each component is in a deployment cycle
if it's failed or not what the
upgrade issues were what's the latest
version as well as are very
sophisticated diagnostics and monitoring
so those were the service principles and
if you're familiar with micro services
you'll see a lot of those principles
apply to micro services architectural
point of view are obviously we run on a
limit order bare metal cloud services
I'll use a managed container service
right now we're using mazes marathon um
but we'll move to another war castrator
nothing to do with mazes marathon it's
just like right now our team operates
mazes marathon and we'll get a managed
container service then we move it over
and we can hand over the operations
piece of it um yes so the question was
it could be different and I'll talk
about the components so um then we have
we use nginx for load balancing for
those of you are familiar with in
genetics very popular open source all
voluntary technologies designed for
operations we're using docker as our
deployment unit docker containers we
using the elastic stack but we also use
elastic stack with kick Donna and graph
owner which is a different dashboard
thing gives us more insight and for time
based series are logging the using
Prometheus on the Java side using checks
RS Jersey chris lee nettie and coherence
so that's the Charla portion and for
CIPD we're using Jenkins CI as well as
Hudson our internal tool so this is how
the architecture looks like and I don't
want to waste a lot of time on that one
because it should just give you an idea
on the right hand side again it's an
internal service on the right hand side
we have an operator so some support guy
or operator can come in and say I want
to create a new activity cluster entity
is actually the service we're creating
so I can create a new activity cluster
and then it basically spins up are the
components like Etsy D gateways and
oracle coherence
back end so that's on the on server side
if you will right and then the way we
implemented multi-tenancy that that
round in a service network in a service
vcn that's ours right and then we have
on the left hand side different tenants
different teams can come in and say hey
I want to use Ltd what does that mean
they basically want to have an
application they want to write some
configuration into that store right
which is then stored in coherence or
they want to use a CD for leader called
leader election and the way we implement
multi-tenancy here in that case we
separated through networking we have
client site or tenant load balancers
which you can think about being
wormholes into the service vzn so it's
that type of multi-tenancy it's
separated on the arm it's actually
separated on the networking level no
long storage flow so now to your
question the platform components we have
obviously load balancer nginx based it's
been used for the control plane like the
one have you come in as well as for the
tenant load balancer and the tenant load
balancer as I mentioned is basically our
bridge from the tenant our VPNs
into the service we see on it's the
wormhole as we call it then we have
management API is because the console to
create a new cluster or for @nn to use
or spin of a new at CD store is
obviously done through a dashboard for a
UI or CLI so we have management API then
we have the sed service itself and
that's more like a logical construct
because if you are familiar with EDD you
probably know it's not using coherence
on the recovers but we basically replace
on the SPD store with our own coherence
technology for data persistency data
reliability and things like that so it
still looks and feels like a 2d because
you can use EDD client API is as a
tenant but under the covers we basically
did a different way of implementing it
the orchestrator on top of means was
marathon we have another component that
helps us spin up an environment
and it's basically can think about as a
management layer between the api's and
mesas Marathon Majors marathon it's or
marathon itself as an Orchestrator but
there is now you may wonder if you're
really familiar with the field why did
you guys do this because mesas Marathon
accident if you paid attention like REI
TD service is basically a distributed
system a distributed data store and it
has a bunch of components think about
the load balancers think about the HPD
gateways think about the clusters right
so we needed to make sure when we spin
over or we create a new cluster that
it's done in a certain order we cannot
just say oh you know what we push out a
bunch of new services and they're going
to be scheduled and and and started
right in a random order so we needed to
make sure that an order is basically
validated there the other thing is from
a DevOps perspective we also wanted to
make sure that we can spin up the
environment in order the system in
different environments so think about
that right or test you don't need a big
cluster right as we need in production
you don't need like I don't know hundred
50 cores 25 gigs right so what the other
thing that the orchestrator does it
supports deployment profiles so it
basically says hey I want to create an
ADD CD service in a virtual machine on a
single box that's what the orchestrator
does and then it basically adjust the
memory settings and it's just the cpu
settings and so on and so forth that's
why we did this then obviously because
we have our Orchestrator we need a
platform manifest which is just like a
file it says okay those are the
components those nine components in that
version and we give it to the install
and say install it so that's at a high
level on the architecture it makes sense
or okay cool
oh so the question was the changing the
orchestrator I will be moving to
removing to kubernetes um the CIC D
requirements obviously the way we
started in that was also fairly new when
we started out that @cd service because
Oracle revolta don't like the
traditional software development right
internally so we said okay what are the
requirements for our DevOps slow right
so the first one was the code must
always be production ready and if not
why not write think about it you
check-in you do a CI CD you don't run
your first test we need to know why that
if it fails and widefield the other
thing is think about the speed I was
talking about
it's like be ready to deliver the code
or production like code within four
hours so the team asks for some changes
and we adventure the pipeline we would
need to be able to push out a new update
to the service which means to either one
of those components within four hours
right so there's this time-to-market
thing then the other thing obviously
because we have data like customers
already have data a customers shouldn't
see a disruption like our tenants if we
migrate for example to a new version of
a CD right now we own a TV version too
entity has a new version at CD version
three if we might create the cluster
obviously customers should you see
disruption or if we change a component
like if we update a load balance and
things like that so it had to be
basically on continuous deployment no
downtime deployments that was that was
obvious the other thing is as you'll see
we have a very sophisticated testing
pipeline right but there's always the
chance that something goes wrong right
in production because there might be
something we didn't catch and that's
something you cannot really a hundred
percent avoid but in that case the other
requirement was we needed to be able to
roll back right away so if something
doesn't go through roll back that's so
actually the functionality of many
orchestrators now if you look at Google
it is and things like that or even
marathon they do that but again we had
to do this
because we needed to make sure which
component in which order had to be
rolled back it's another reason for the
orchestrator bill all right how did we
address the requirement so there was
nothing there we basically started out
building no service while ago so how did
we start so first of all it requires
some investment way we've all made us
smarter we read books and we hired a
bunch of people and then we basically
bootstrap the team that to create a si
si ICD infrastructure and that was
actually developers rate which was good
because you get them involved think
about you want to have them really
involved in the process babe and then
some of the team are they will still
stay back and run it because if you have
a fairly sophisticated system there you
have to operate it at home we
bootstrapped a team to create the
end-to-end tests because yes we test the
component individually but someone and a
bunch of people basically need to sit
together and say yeah you know what
that's how we need to test them as a
whole because we have like all those
individual services and what's actually
a test that guarantees of everything
works together that was the team ought
to create the end-to-end test so that
took a while to basically come up with
our end-to-end tests then we bootstrap
the team to create performance tests
because performance is crucial for us so
the same thing we basically created a
team that came up and created a
performance test framework and as you
can see was all a joined effort when we
started us out it was all a joint effort
and then now part of the team are still
staying back and working on it but while
they're doing their other stuff but the
actual performance tests are run now by
each individual team so by doing by
having that approach how did we address
the requirements we actually were able
to come up with an infrastructure in the
process that's now been leveraged by
other teams so for example we're
building out a Redis service aid and a
travel service and easily leveraged what
we've built there and customize it so
it's a one-time effort and then you've
benefit from it
and you can translate that directly to
to your enterprise and to your
applications and so we continuously
continued we continue to evolve our
investments there by for example or
trying to have a better automation and
things like that but so that's basically
how we address the requirements so how
does the CI CD pipeline look like so we
have a testing strategy that we came up
with the first one is we have micro
service level tests so that's basically
tests on each component right so each
team includes the unit test components
tests and minimal acceptance test which
is a test against a api's to test
against the integration and so on and so
forth and those tasks are being run as
part of the individual bills prior to
see ICD stage then we have the platform
level test and again that doesn't mean
it's not agile as just they were just
built by a platform team and again as I
mentioned before we needed to have a
team and say what actually what's the
tasks matrix to guarantee that that
service all of its component function
properly that they work nicely together
that we can upgrade in that they don't
fall apart after a time so a team came
together and we built that platform
level test right which happens which is
basically a stage that happens after
each team has tested their services as
part of that is obviously minimal
acceptance test which is again pinging
api's can I can I actually call in it to
be a API often upgrade can I call this
up greatest service feature test
longevity test so we actually then want
to be at a point we run tests for like a
night against that whole application and
see if we run into leaks or something
right and the last one or did obviously
performance test in the last almost
Jepson testing how many of you have
heard about Jeff's and testing oh okay
so one checks in testing is something we
had to do because it's a distributed
system
it's a distributed data store and what
that test actually does is you're on
test and it ensures like let's say one
node falls away and you write to the
store that you always have consistent
data on the back end as well as for the
user right so think about it like a
distributed test for distributed data
and things like that
to make sure you don't have any stale or
a bad data in there and we started out
doing the checks and testing manually
but now we're going to make it part of
our on CIT pipeline so the question was
is the micro service or is the testing
done by developers and testers it's
mainly gone by developers yes that's all
automated so the platform team like the
test you see here they're being defined
by what's called a platform test team
but they're automated right so there is
no manual involvement there is no person
who does those tests yes yes so that's
that
I'm sorry say it again yeah so those
tests also we have dashboards and stuff
like that we will actually want it or
everything so think about it as soon as
you check in the code right as soon as
the developer checks on the code
everything is automated everything is
reported and you see if your component
go through if your tests go through or
not it is yes oh yeah that's that's also
I mean we gonna ensure that our
developers are doing unit tests because
of part of the governance right as I
mentioned before it's very important if
you build an application that consists
of multiple services delivered by
multiple queues you need to agree on
certain standards right you need to
apply governance
yes
so whoop yes we'll catch it I'll show
you I'll show you pipeline if that's
what on properly we'll catch it we have
we have plenty of tests there that's not
the pipeline by the way that's just a
high level stages right so the first
level of integration is what we call
pre-integration
it's localhost installation with the
latest published platform manifest and
think about the platform and manifest
what I talked before
it's basically a document a chase and
file that describes all the components
that make up in their versions that make
up the application right now ok
localhost may be little misleading
because it can be on a virtual machine
it can be on your death machine right so
it's not necessarily your death machine
on locals but it can be like in a cloud
thing so then are we installed a new
version on off that component or on top
of it so that team would basically
install let's say at CD or nginx version
2 let's say on top of it then we run
functional acceptance test in 10 minute
interval Jones and the reason why we're
doing that is because we have a bunch of
we have a fairly sophisticated test
suite we're doing a lot of tests way if
we run through all those tests
sequentially takes forever to get back
to developers and say you know what you
were successful what's the worst thing
you can do developers you can make them
wait like a day until they know if their
stuff was successful or not
so we basically split up all those tests
and we spin them spinning up in parallel
think about it as parallel test
controllers right each having a subset
of those tests and running them in
parallel and by dad we're cutting down
the overall testing time to ten minutes
then we run the upgrade acceptance test
and see if it's good and then we
basically are promoted into integration
this is um basically it's a prod like
environment it's not your local
environment mayor anymore and we deploy
a platform instance from scratch meaning
everything not just that component
and we deployed the entire application
yet city architecture that you've seen
we deploy everything right and then we
do the upgrade and see if it works right
if that's worked that's like the the CI
of our platform component into the
application right because now we've seen
we have the entire application and the
new version of it hasn't created any
problems and that's basically our CIS
that gave then we're going to put it
into our pre stage it's a product
environment with the current manifest
again upgrade and run another set of
tests in ten minutes
chunks and then we go into staging and
that's very actually run a test like
longevity test performance test
functionality acceptance test so then
this is where we stop this is once
everything its effects successful here
that's where we stop with the whole
automation everything up to there is
fully automated and here at that point
we stop and the reason is not because we
don't like continuous deployment we
could do it because we run on on
marathon and we're gonna run on kerbin
it is fully supports like multiple
versions the reason is because we are
not able as of now to to read or
interpret like all of our test results
we running fairly sophisticated
performance tests we get a lot of data
right and so there is currently we
haven't figured out and that's why we I
said before if you remember that we're
still trying to improve that process
there's still a lot of data from tests
coming in that require manual like
interference where people look at it and
say yes that looks good that looks like
what we've had before and that's a
production candidate actually that's
something we really want to put in
production and then obviously there's
other aspects to it because we're an
internal service we need to make sure
that you basically are we have a
business requirement that the other
partner teams know that we have two new
new platform but this is how far the
automation goes from a detailed service
release pipeline that's how it looks
like those are on the left-hand side
activity data played and controlled Lane
those are basically doing
your services so every team goes for the
build unit test integration test and
they publish the image we have the
platform test we update the manifest and
then you see all those tests on the like
literally going almost to the bottom and
that's the pipeline that I described in
four steps right now that's everything
that's happening there and then we
basically grab the new black phone
manifest and put it into a release
pipeline for production which is a
different one again so as you can see
it's a very I think the takeaway of that
pipeline is it's almost like an
enterprise pipeline because a lot of
enterprises do lots of testing right
after test apartment and so on so we
still do that that's not going away
because we need that rate we need to
make sure that what we put out there has
a certain quality that I think the
biggest difference here is that up to
this production release start point
everything is fully automated and I
think that's the biggest difference
there is no manual interference that go
through everything's automated so the
lessons learned are make projects filled
easy and build metrics visible rate
that's what I said before manual are one
button will deploy builds are triggered
by code check-ins very automated posters
validation fails reported and key here
is a lot of people underestimated you
need to have the dashboards right you
need to have you need to provide your
developers with the tools to go there
and figure out why that thing failed and
not oh it just it it just did fail and I
don't know what to do right so a very
high visibility into failures is key and
it helps us a lot to speed up because
think about you check something in I
mean there is always as a developer you
always check something in it may not be
caught it goes out there and then you
don't know why so that's very important
so the next couple of things is talking
about what we learned on the container
side again we are using how many of you
are Java developers probably all of you
so as I mentioned before we use we made
it really clear if
you want to have a fully automated death
of pipeline release pipeline we need to
have one unit of deployment right I
cannot have a tu ship like jar file of
war file the other team shifts the
container wouldn't work in our
production violent anyways because we
use containers but we wanted to have a
common deployment unit right our
deployment unit happens to be a
container that also means for us
everything that is built is going to be
packaged as a docker container is going
to be published as a talker container
right that also means for those of you
are familiar with containers I think
that's not new and that most of you are
you should run only one instance of your
application in a container there is some
literature out there that says run a
bunch of instances doesn't make sense
because you really control your
application through the container right
so you give your container runtime
metrics and things like that and that's
how you control it so think about that
then the other are lessons learned here
is use proper container image versioning
so up there there's an example our
version it's a CD engine eggs and then
we have two versions semantic versioning
behind there avoid using the latest tag
how many of you know what that means
like in docker watch so here's the thing
if you build a docker container and even
if you don't tag it and you upload it
into a docker repository it gets
attacked latest great so now people
think that this is the latest version no
it's not it only means it's the latest
not tak version so it might be your
oldest image right so that's why imply
versioning or apply versioning to your
docker images always do that the other
thing is use small base images also
something that's very often overlooked
because a lot of people follow
instructions on the web and they use
Ubuntu Linux Ray they have huge
container images with a lot of code in
there so the image size is pretty big
what does that mean if you're in a
distributed systems world and you want
to scale out quickly meaning spin or
more instances of that container and now
the container gets spun up on a new host
that doesn't have to
image pulled it takes a while to pull
down that image from a registry across
the network and start it up so your
service you scale out may be delayed so
you small base images we use our Oracle
Linux 7.1 and then you can use the base
images for multiple purposes I mentioned
we have the nginx we have a load
balancer for the tenant as well as for
the operator the tenant one actually
supports HTTP to the operator one
doesn't and the way we enabled HTTP to
on nginx is we added an additional
software component to it and once we
launched it we basically pausing on
slack and say enable HTTP to their CI CV
pipeline automation takes time so full
automation even longer so don't
underestimate how long it takes for you
to build out such a pipeline there's a
lot of testing involves queues it's
literally writing code right automating
everything but it's record in the end
because your deployment cycles go down
everything goes down everything is
automated so will benefit greatly for it
but you have to you really have to plan
for it it's not something that you just
click together define requirements and
provide tools but allow flexibility so
as I mentioned we have provided
governance for each of the teams but we
also give them flexibility for example
with regards to maven versus Gradle
right so use whatever you want as long
as you adhere to our governance the code
review process depends on the team
culture we still have ongoing
discussions with the teams this is the
right level and you're you're really
noisy here and that's the wrong tool
that's something you have to deal with
but I mean you'll get there eventually
and then start using deployment deploy
other components and for other it was
like a docker container was the natural
choice that we package it as a docker
container as early as possible in the
pipeline so that it's been tested in the
final stage then the other thing we
learned is isolated sandbox for
development if we debugging and testing
this is really
orchestrators actually really nice
because developer can go in there it
takes a manifest Hey
I need to debug my my my component
failed right now I want to debug it what
they can do is it just use the
orchestrator and install and say hey I
want to have a deaf environment spins up
the environment and they can debug it
exactly with the components so it's
actually pretty cool then also very
important there is a testing pyramid we
put a lot of efforts into testing close
to the developers meaning
unit test integration test if you seen
our integration tests happen really
really early great and the reason being
is it's time end-to-end tests of a very
complex architecture take a long long
time
so think about it as a pyramid as I said
right we have a lot of testing close to
developer down there and we try to get
less and less testing that time
consuming testing the closer we get to
production
paralized testing where possible again
we came up with that or we had to do
that because a lot of developers were
complaining initially that our cycles
are too long it took too long for them
to get feedback on the component was
successfully promoted and so on so these
basically are splitted up in chunks as I
mentioned before test upgrades early in
the CI CD pipeline as I've shown you in
our pipeline we literally like the
second step is upgrade the component
because upgrade is always the tricky
part
so we retested very early on and that
actually hurts us avoiding a lot running
into a lot of upgrades issues later on
words might be harder to identify where
it is address intermittent failures and
end-to-end testing right away so
everything if there is a failure we're
going to get right at it and look at it
then developers focused dashboard as I
mentioned is really important don't
underestimate the like usefulness of a
visual representation of the status the
health of your components where it is in
the pipeline so we've done that on so
just to give you a little bit insight
into this using Jenkins and Hudson that
we basically take the build steps on
everything right into a database and
then we have another custom
for the top of it that we built it's a
very simple web page that says okay that
component was upgraded to the next step
failed or succeeded if it failed or
succeeded you can click on it and you
see the manifest right away and you see
okay why did it fail and what what were
the other components involved and then
more specific to our situation was
really that external black hole manifest
used by Orchestrator was a good choice
for us and to your point and that's
again more bourgeois we wish we had
abstracted container management
interfaces early on because now we go
into a different Orchestrator that means
we need to do some work there because a
lot of our work is right now try to
mazes marathon
so to summarize DevOps is a shared
responsibility I hope I made it really
clear how we work jointly together in
our team to come up with a good DevOps
pipeline it took us a while to get there
to be honest it's not something that
you're going to gonna do tomorrow and we
still have ongoing discussions but the
good thing is there is no throwing over
the wall right no to you is just on and
throw the component over and say hey you
might have team you my ops team just do
it right it's a shared responsibility
it's like that you build it you run it
that's really what we live and that's
basically a prerequisite for micro
service cloud scale deployments then
tools technologies of choice required
government I think I made that pretty
clear
see ICT pipeline and automation are key
like ever said everything in that
pipeline is fully automated up until the
point where we say contrary put it in
production right and the reason being I
also addressed that is really we cannot
read certain results we're trying we
trying to get there more on that topic I
actually started like a five-part blog
series about micro services container is
it's very independent from technology
and it goes like into DevOps patterns
and stuff like that so with that I think
I'm right on time ah thank you guys for
coming any questions
so the question was should a database
component are included in the CICU
pipeline yes should be no because we
don't have a database that's why there
is no date of it so the data for us is
stored in a coherence cloth and it
stores it just to disk so the direction
was what's the the rollback strategy if
something goes wrong so they're all bad
strategy is remember that manifests we
have we basically applied the manifest
they get the latest or diversion before
we always have we always have a full
history of our versions and so we have a
version of the manifest if you will
right and then it has the versions of
each component in there so let's say
nginx v2 didn't go through we'll catch
it the orchestrator relax you roll back
or actually that case mesas Marathon
will roll back right and then the
application is still functioning and we
go back to the latest manifest all right
so hope you enjoyed it and it was useful
somewhat ok</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>