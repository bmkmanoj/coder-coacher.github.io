<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Don’t Be Pwned: A Very Short Course on Secure Programming in Java | Coder Coacher - Coaching Coders</title><meta content="Don’t Be Pwned: A Very Short Course on Secure Programming in Java - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Don’t Be Pwned: A Very Short Course on Secure Programming in Java</b></h2><h5 class="post__date">2015-06-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/nnFFxY96EOI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so there's a this three of us here today
I'm Robert Secord I'm the manager of the
secure coding team at cert this is a
Dean Sutherland and we have a third
David Swoboda is in the back there he
gave a couple security talks yesterday
that pretty well attended and received
and and we have a we've had two books on
secure coding rules and guidelines so
these are three fifths of the authors
the one of our authors Dhruva hinders in
the pune india and the other guy dr.
fred long is at the university of
Aberystwyth and wales
so we're we've got pretty good coverage
continent wise so so these are the two
books that we've completed over the past
few years but the story behind this I
can't help but tell stories so we we did
a C standard first and when I moved into
you I used to be a job I was a Java
program for about ten years I moved back
in to see when I went into software
security because I thought well that's
where all the action is in security you
know C is just lousy with
vulnerabilities so eventually we got
around to doing a Java coding standard
and I thought well this will this will
be a pamphlet job is basically secure
language you know and then like a
thousand pages later we thought oh oh my
gosh you know this is too much for one
book so we which kind of drew the line
and published the the cert Oracle's to
care clinic Stanford Java back in 2011
and we just now completed the the
remainder of the rules that we want to
publish in this Java coding guidelines
book so so most of these were most these
rules were developed to address real
exploits of compromised Java programs in
the field some of these are more
anticipatory we do have several examples
that describe core vulnerabilities that
have been exploited and techniques for
avoiding those problems so here again is
a list of authors I think I've already
kind of run through this we also got a
lot of help we started this of course it
was originally called the you know this
the the cert Sun Microsystems speaking
standard for Java which kind of tells
you how far back the effort
went and so we actually began this
effort with Francis Howe originally at
Sun Microsystems and Tom is hot and
who's a security expert he's uh works
out of the UK but he's he's a very
bright but kind of shy I guess so you
don't see him out in public very much
so I'm gonna start by talking a bit
about secure coding and scale then I'm
gonna do the first rule that I'm going
to hand things over to Dean because
Dean's more of the Java expert than I am
I'm more of the C guy I a couple years
ago I submitted a proposal to talk about
integers in C language at a Nick C
conference in South Africa so he's so I
said I was gonna talk for a full day so
six hours so the guy called me up me
says how are you gonna talk about
integers for six hours and I said well
I'll talk fast skip the boring parts so
they found that amusing but of course
didn't accept it because there aren't
that many masochistic people who attend
that conference so anyhow we we've had
the secure knish ative at cert since
2003 and the the initial thing we did
was kind of looked at all the
vulnerabilities that come out in the 15
years cert have been handling
vulnerabilities and kind of wrote up the
the search secure culling C C++ that
guys involved with standardization and
got us to write the search C secure
coding standard and then we sort of
branched off into C++ Java Perl and some
other languages so this is a bit of an
old slide because we got the old slide
deck somehow but there's been quite a
lot of adoption and most particularly
look at software adoption by developers
and acquires Cisco a few years ago
adopted the C secure coding standard
last year Oracle adopted all assert
secure coding standards so these are now
being used internally throughout Oracle
and what they've done is they've they've
blended our standards with their own and
in most cases that's worked out pretty
in a limited number of cases there were
some conflicts because you know they're
probably wrong not that I've got a you
know ego or anything so and we've also
had quite an uptick in adoption by
analyzer vendors so a lot of them a lot
of them like to claim conformance to our
coding standards some of them actually
do in most cases what you'll see is you
know these coding guidelines and coding
standards are written for developers so
they're not necessarily all analyzable
right so a lot of times these things
need to be analyzed using a heuristic
type analysis which will generate true
and false positives and the final thing
here is that search stood up something
called scale where we'll take source
code from vendors and some money and we
will analyze that code for conformance
against one of one of the secure coding
standards presumably for you guys the
jaw of a standard and then at the end of
the process we have a conformance test
at seal that you can then use to market
that product if it successfully passes
conformance testing so this is the
search source analysis lab and the the
process we you know so this is not an
easy thing to achieve particularly since
the standards haven't been around that
long so a lot of code that we would
analyze today wasn't developed
specifically to conform with the
standard so we sort of built an
iteration into the process so vendors
will give us their source code will
analyze it will give them the findings
and then will give them up to six months
to address the findings they can
resubmit will verify that the problems
have been solved and then we'll give
them a certificate published out in a
registry okay
so so the issue we're trying to address
is is is kind of this investment that
you have to make in security right so
part of the problem is say you're
looking at two products right and one is
available today it's functional its
high-performing and but it's insecure
whatever that means and no one will ever
tell you it's insecure everyone says oh
it's secure um but but that's of course
just the meaningless phrase entirely and
then there's a second product which is
not quite out yet
is going to have less functionality is
going to be a little bit slower but it's
secure well that you know there's no
there's no choice for the consumer there
that's a no-brainer they're gonna buy
the fast functional product that's
available today and so there's a there's
a problem selling security when security
doesn't mean anything at all and and so
what we're trying to do here is to give
some meaning to this word security by
saying well here's this pretty
substantial book which consists of
collections of rules
which you need to conform with in order
to have secure code and then we can sort
of independently assess conformance to
that set of coding standards so what you
have is you know so after all that's
done there's no guarantees that systems
secure but you have established a pretty
significant benchmark in terms of the
the quality of and the security of the
code and then this this seal is a way to
sort of demonstrate that and there there
are there are many people who are
surprised that you know I got this past
the sei chief operating officer and CMU
council and they agreed to let us use
the certain name to to market other
people's products because you know so so
it suggests a high level trust on their
part in us and the processes we're
following okay so so used to the secure
coding standards again sets this
prescriptive set of rules against which
source code can be evaluated the basic
process is that we'll evaluate the code
for can for
with each rule and we'll have one of
three findings so so the the first
finding is provably non-conforming so
that's a very easy finding for us to
find all we have to do is find a
violation of that rule in your code base
and then you know overall you're not
going to pass but we're going to
continue to go through and evaluate you
could against all the rules the other
possibility is provably conforming which
is that we've determined that the code
adheres to the rule in all possible
cases and we almost never say that so
that it's mostly there to differentiate
between from the middle one which is
conforming and conforming just says that
we weren't unable to identify any
violations of the rule in the code and
mostly people will pass by just having
you know their code be conforming to all
the rules so it it's not a positive
assertion about security but basically
it's still a it's still a rather high
bar to to pass ok so I'm you can get on
talk about an actual rule which is IDs
o7j do not pass untrusted on sanitized
data at runtime exact method so Java
programs can invoke contain or depend
upon the JVM which of course you need to
trust even though maybe sometimes you
shouldn't locally develop code with it
which is both trusted and untrusted
third party code Java runtimes and JDK
libraries that again need to be trusted
to some extent you know other libraries
both commercial open source and
dynamically loaded code which could be a
legitimate system or user provided
plugins or it could be malicious
attackers so the the malicious classes
are clearly untrusted but how do you
distinguish those from the code that you
know you should trust and you should be
able to run so there's this concept and
security of trust boundaries and and and
and so you'll you'll frequently have
different components we could pause well
someone gets that but if it's for me let
me know so so so each component may
operate in one or more trusted domains
and that is determined by only the
architecture of your system the security
policies you're trying to enforce the
functionality each of those components
needs to perform and the resources they
require and in general what you want to
do is you know you you want to you know
keep your your users so users I used to
develop commercial software and so I had
this theory that all users are evil
anyone here develop commercial say so
you know what I'm talking about right so
so anyway then I moved into secure and I
found out that theory was correct users
are evil elite at least some percentage
of them so so whenever you you kind of
hear the word user you know you really
have to substitute that with an attacker
and think about things like well how is
an attacker going to use my interface
and so so you know part of what you want
to do with these components is you want
to have a different component
communicating with the attacker from the
components that are you know dealing
with very privileged and secure
resources so for example you might have
a system where a component can access
the file system is going to lack any
network access you might have another
component that has general network
access but not access to the file system
and the secure network or a component
that can access the secured net network
but not the file system in general
network so so there varies forms a very
common form of attacker these injection
attacks and you have sequel injection
command injection all sorts of command
injection also some different kinds of
injection attacks and mostly what these
involve are taking unsanitized
user input and passing it to a complex
subsystem that has more functionality
than you're aware of well now that you
know since we're at the Oracle show I
mean a good example that's an Oracle
database I mean those things have a lot
of functionality
everyone understands everything that
those things can do so in this case
we're showing an example of command
injection so we have someone who's taken
we have some code that's taking a system
property derp and concatenated into a
string to pass to you RT exec and mostly
that looks mostly harmless right where
we're going to let them take the
directory of a particular user specified
directory but this code does in fact
violate this rule IDs o7j do not pass
untrusted unsanitized data to the
runtime exact method so the issue here
is imagine this programs running with
root privileges and the attacker
provides this string for derp so what's
happened here is first you have a bogus
argument which just makes the LS command
happy so now it's got something to give
you the directory for followed by a
semicolon which is a new new command
delimited delimiter we have a printf
that just allows use of a /n for new
lines then we have a line here to
authenticate to anonymous FTP site we
have a line which will upload the
password file and then at the end of
commands to FTP and a little flag here
to not not prompt the user for any input
during this transaction and so so that
that violation of that rule in this case
is being used by an attacker to steal
your password file and you you would
sort of hope that you know FTP evil net
would get shut down one of these days
but you know the government sort of not
as efficient as it used to be so this is
one example and any of course there's
out there you know once you have this
kind of problem there's old just all
sorts of fun things that an attacker can
do and I don't even know what all of
them are but the ones I know about are
sufficient for me not to allow this to
happen but you can also for example call
this one time two down low
a Trojan to your system and then call it
a second time to execute that Trojan so
there's there's a significant risk here
okay so so the solution is and I was
hinting at this before it was really
this concept of distrustful
decomposition work insecurity just
really ruined you for everything else I
mean you just
it becomes suspicious of you know
everything and everyone you interact
with in your life and you know
unfortunately too many times it's it's a
it's valid so so components have a
limited trust in each other it's
basically a form of compartmentalized
security but this also means that you
have to you have to manage the
interactions between these components
with care I mean as the David was
talking about in this lecture yesterday
you can have this sort of confused
deputy problem right where you can have
a component with privileged access start
performing operations for an
unprivileged client because it's become
becomes confused about who's making the
request so so one consequence of that is
you need to sanitize inputs between
components with different trust levels
so what that means is first canonicalize
it that means get it into a standard
form so that you can you don't have to
look for every variation in every
different form of something sanitize it
remove any sort of dangerous characters
and then when you're when you're done
with all this finally validate that the
stringent Eanes only the things that you
want to have in that string and nothing
else you also want to sanitize outputs
so the difference between inputs and
outputs sensation is input is a little
bit more general you want to limit
inputs to valid inputs but output
sanitization you actually sort of know
what the you know what your where you're
sending that
so you have a pretty good idea what the
scary characters and character sequences
might be okay so so once you have this
componentization you want to have
privilege separation and privilege
minimization so each component should
possess the minimum privileges required
for it to function
the thing I used to deal with the policy
file was and this isn't completely valid
but sort of works is I'll have no
security policies and then I'll run my
code until it crashes and say okay I
need that security policy and all you
have that and that's a way to you get a
minimum set if you're testing all your
path and you want to make sure that you
know there's not some policy you need to
enable on an untested path in the code
so that's one method I mean you know the
others to be careful as you're writing
the code and keep track of the policies
you mean okay so the consequence of this
is that component cannot perform other
privileged operations and that limits
the impact of errors and successful
attacks so privilege minimization
privileges have disabled most the time
they're enabled only when you need them
and only for as long as you need them
and then they're then they're disabled
so that reduces the amount of privileged
code and sort of temporarily limits the
time the sort of the the windows in
which attacks can be successful so so
how much do you how do you establish
these trust boundaries you know it it's
or depends on a lot of things but for
example if you trust your network lesson
you trust your program you've probably
found a trust boundary and you know we
have a we have a really large group at
cert that deals with insider threats you
know so you know you have to think about
who's running even locally on your
network and what sort of you know sense
of data is being passed where maybe
someone with a
machine on that network and sniff your
your network traffic you need to ask the
same for your file system who has access
to that where's that data come from how
much does that data trusted various
kinds of users that have access to the
system input data from various sources
is this an input source that is
originating you know within my trusted
computing boundary or is it originated
outside you know we had a we had a
vulnerability in a JPEG handling files a
couple years ago and people you know so
here's here's what happens here's the
faulty sort of thinking process right
you write some code to generate a JPEG
file and then you you finish that and
you have a JPEG file now you write some
code to read that in and as you write
that code what's going on in your brain
is you're thinking okay I I just wrote
the code to generate so I know that this
value is in this field and this value is
in that field and I know exactly what's
there and I can trust that data so the
problem is that doesn't translate into
real deployment because you know people
in the real world have hex file hex file
editors you know and they can they can
edit that JPEG file and break your
assumptions about what the values are so
you have to think about you know where
is this data you know where is it coming
from is it leaving the your your trusted
computing Basin and potentially getting
compromised
okay and with that I'll turn things over
to Dean so part of the reason we were
talking about trust boundaries there in
in brief is that we want to be able to
sort of hand wave about okay now you
know where your trust boundaries are now
all of these kinds of things are rules
you need to follow anytime you cross a
trust boundary even within your own code
so we're going to move on to another
example of sanitizing data here we have
a little picture a notional picture if
you will of a a trust boundary the outer
black box the blue blue box just inside
that represents one
component you can imagine you might have
many components inside the same trust
domain okay and if that was the case
passing things between those components
there's no issue with trust boundaries
right however if you lift the lid and
look inside a little more I've drawn
some boxes in there that show the the
kind of processing you need to think
about doing in terms of anything that
comes in or out across the cross trust
boundary we mentioned all the you know
canonicalized normalized sanitized and
validate and by the way yes those have
to happen in that order because if you
do it out of order you open up
vulnerabilities there are some examples
of that in the book that we will not
talk about today there's the core of
your actual work which we're just
showing this one blob because it's not
really relevant to this discussion and
output sanitization which as Robert said
on the one hand you know the sort of
scary characters and things but the
piece of output sanitization that lots
of developers forget is that you want to
be sure that you don't let outside the
trust boundary data that shouldn't go
outside the trust boundary imagine if
you will for a moment that you're
working on a program that involves
national security and there's a log file
that's generated but the operators who
can read the log file aren't cleared to
see any of that data so if you let any
of that super secure high high security
data show up in the log file you know
they're gonna take you out behind the
building and shoot you or something okay
so that would be bad so that's an
example of a kind of output sanitization
that a lot of developers forget about um
maybe you're not doing stuff with
national security but it's still likely
that that your company or your open
source project for that matter might
care quite a bit if you leak the wrong
kind of stuff outside a trust boundary
that's one of the ways that the bad guys
get the information they need to attack
your system so for validation and
sanitization you have to make sure that
your data is both appropriate and non
malicious so as it said as I said
earlier canonical is a
normalization sanitation and validation
in that order although if it's
appropriate you can leave out a step
that's just not needed so I presume you
all know about regular expressions I'm
going to skip over this very quickly we
have a class that lets you provide a
regular expression it will compile it
and use it to match characters in a
character sequence very useful stuff so
here we have a little problem
description this is this version is made
up although it is actually extracted
from a real vulnerability in in essence
if you will so there's a system log file
that has messages output by lots of
system processes some of those are
things that ordinary users would like to
see and legitimately should be allowed
to see and others of those messages are
things that ordinary users should never
be allowed to see so just to make this
example easy to talk about we've made
sure that the log file has each line is
flagged either private or public to
indicate whether this is something that
a user should see or not we want to
allow our users to search the log file
from interesting messages that they're
allowed to see but prevent ordinary
users from seeing the private ones so
here's an insecure solution for this
we're going to periodically load the log
file into memory the user is going to
provide some search text that's just
going to get slapped down in the regular
expression and there we go it's going to
be stuffed in that regular expression
which will be used to search the log
file and there's the things they can
look at of course if an attacker can
provide that search text he can have
great fun because he can insert this
closed paren open parens sequence into
the regular expression which turns the
overall regular expression into
something that says well actually we'll
just match anything and display it okay
obviously this would be bad in our
little scenario so here's a CVE from
2005 the the eeping program which
executes that
command used a reg aft reg X to check
that the user was supplying input that
was a valid IP address and unfortunately
that reg X was written incorrectly so
that the user could hand a carefully
crafted input string to e ping and
execute an arbitrary command on the host
now I'm sure you all know that arbitrary
command execution is a bad thing so this
is an example of something that you
really don't want to allow to happen so
one thing you could do will we'll see
some examples of how to do some of this
in a couple of slides one secure
solution would be to filter out all
characters that are not alphanumeric
from the string except for space and
single quote and at that point there's
nothing that the attacker can feed in
that will change the meaning of the Reg
Act other than changing the search
string or another approach you could use
is you could filter the log file so that
all the private messages are gone before
any reg X has ever allowed to run then
there's nothing private for the bad guy
to look at and that's okay of course
that filtering thing has the feature
that if you do it every time the log
file is loaded into memory either you
have to be clever about lazy loading the
log file and there's an added delay for
the user or you have to load the log
file preemptively and strip it of the
private stuff which has an overhead even
if the user doesn't look at the log file
at all so you know there are performance
issues too with that particular solution
so if you had followed rule IDs oaj you
would have sanitized the data and you
would not have had this exploit so
here's one example of how to do it what
we're going to do here is we're going to
whitelist the characters were willing to
permit and reject everything else so
here what we're doing is we're saying if
it's a letter or digit it's okay if it's
a space that's okay if it's a single
quote it's okay otherwise it just gets
dropped from the string as
run around this loop and then we collect
construct our egg X and off we go and
we'll be okay so this is the just don't
let them put the bad characters in
approach so I gave that little example
of logging sensitive information outside
a trust boundary well of course we have
a rule for that and we have an exploit
for that too the lime control Java
client jlc in early versions leaks
passwords into the log file in the clear
okay you can imagine that attackers
thought this was just the greatest thing
ever
and indeed the sensitive information
could in fact become available to
untrusted parties like the attackers and
some people did until that particular
application was patched so again we have
it we have a rule for that so it turns
out you might say well why do I ever log
sensitive data and the answer is well
sometimes you need to you need logging
for debugging you need it for incidents
response or collecting forensic data of
various kinds on the other hand if you
are going to log sensitive data you now
have the problem that you have another
file with sensitive stuff in it and that
raises privacy concerns legal
limitations it raises the level of
insider threat possibility it's a
trade-off so the other thing that that
especially Americans may find surprising
is how much stuff is considered
sensitive information okay I'm not
surprised that a password is sensitive
on email a credit card number that's
obviously sensitive social security
number sure IP addresses yes there are
many many circumstances where an IP
address is sensitive information um if
you have to deal with EU privacy laws
any personally identifiable information
whatsoever is considered sensitive okay
there are lots of different countries
with different laws about what what
personal data you can collect
you'd better make sure that your logs
contain only data that is in fact
permitted by law to be in a log that
will be seen by the people who can't
possibly see that log file so here's a
piece of vulnerable code okay it's a
straightforward thing it's just going to
take a a string and say we want to log
the remote IP address so we're going to
look up the the IP address and if it's
an unknown host we'll you know report
that if it's a security exception of
some kind we'll report that but we're
also going to stick out this debugging
log that says hey I I did this host
address and and and didn't get something
that I expected and that's sticking the
IP address of the remote client into the
log so there we have a potential issue
okay what you want to do with something
like that is not stuff it raw into the
log but instead feed it through
something that can do output
sanitization where that output
sanitization is appropriate for the
trust level of the log file that it's
going to go into so you see you will
have seen elsewhere in this code this my
exception reporter we have a an example
piece of code in the the big fat rules
book called my exception reporter that
is an example of how to take an
arbitrary exception and sanitize it in
an output sense to include only
information that's allowed to go to the
place where it's going so this is an
example of insisting that the output go
through the sanitizing routine before it
arrives in the log file you'll note I
haven't shown you the sanitizing routine
partly that's because the code that goes
in it is pretty boring and partly more
importantly that's because the
appropriate sanitization for any given
product and log file and so on is going
to be varying all over the map depending
on the trust levels
okay I'm the trust levels the problem
who's allowed to see it all that stuff
the key item here is not what goes in my
exception reporter but the idea that you
force that log output to go through the
sanitization process so here's an
example this is from the rule I hate
this example but it could be enough in
very simple cases if you use the
java.util logging class it supports
multiple logging levels you could use
that capability to not send to the
console things that are potentially
things that are potentially sensitive
but allow them to go into a log file
which is perhaps somewhat better
protected than the console itself is and
you could manage that by which level you
report the error at okay this is the
world's worst example of output
sanitization but there are in fact many
cases where that would be enough if
you're doing anything more than the very
least bit sensitive please do something
better than that okay if you do that you
have to make sure that an attacker can't
modify the logging level filters right
because if they can you're wide open
again so this next guy is going to be
the meze meatiest example in this talk
don't use reflection to increase the
accessibility of classes methods or
filters we're going to use the January
2013 zero day as our example for this
rule given the length of this
presentation I'm gonna have to go
through this bit at lightning speed I'm
sorry about that
but to give you an idea David gave a
full hour on the August 0 day and I'm
going to try to handle this one in about
10 or 15 minutes so what did the
attackers do they had a three-step
exploit their first step was to get Hann
for classes out of the Sun org Mozilla
intern and internal package that they're
not supposed to be able to get handles
for the applet security manager is
configured to forbid access to those
things but they managed to do it anyway
the second thing they will do is they
will use those internal packages to
create a trusted class loader of course
once you have a trusted class loader
that's another thing that you shouldn't
be able to do except from trusted code
the security manager is configured to in
fact to reject all attempts to create
class loaders trusted or not unless
those attempts originated from untrim a
trusted framework that's why they wanted
to get these internal classes in the
first place and then of course the
Prophet right once you've got a trusted
class loader you can load anything and
it could be as malicious as you like and
off they go
what they actually did was they set the
security manager to null at which point
there's no more security at all and they
can do anything we're not going to
discuss step 3 in any detail because
that is in fact common to every
interesting Java exploit set the
security manager null or otherwise just
get out of the sandbox the interesting
parts are the first two steps how do I
get there when I'm not supposed to be
able to okay so we want to get class
handles for these internal classes if
you just use reflection the security
manager rejects your attempt this is
good we want it to reject your attempt
right unless you're an attacker so they
can't just use ordinary reflection what
they did is they called this Java Bean
thing and mbean instantiate er find
class routine to do the work for them it
should have been blocked by the security
manager but it wasn't we'll see why in a
bit here we go we are inside this this
is inside M being instantiate er here's
the fine class method it just delegates
off to load class you run into load
class and you chug down through here and
you discover that load class calls class
for name without making any security
manager
if its own okay it's depending on class
for name which is the ordinary
reflection interface to do the security
checks unfortunately do I have that on
this slide yes here we go M being
instantiate er ah one more thing I need
to say here class 4 name is one of the
class one of the interfaces that
produces that performs a reduced
security check it only looks at its
immediate caller to decide whether or
not it should do what it's doing it
doesn't look all the way up the call
stack so what we have here is a case
where class four name is being called
from trusted code but the attacker
should never have been able to invoke
that trusted code in the first place so
because it was intended to be a hidden
part of the javabeans implementation
that appears to be okay it didn't need
to do a check unfortunately JMX beam
server exposed it through a public
interface awesome yeah okay so now the
attacker is able to load any
pre-existing library class including the
ones that are supposed to be privately
hidden inside the Sun dot star hierarchy
I should note here it's not at all clear
which piece of code is wrong okay it
could be that the the beam instantiate
er was absolutely correct that it was
supposed to be hidden and gmx being
server was broken or it could be that
JMX beam server was correctly exposing
this thing and M being instantiate
shouldn't have thought that it could
only be called from trusted code we
don't actually know those of us on the
outside of the the library groups don't
actually know which of those two is the
bug right but it's obvious that the
combination of the two is busted so we
need another step we need to build a
trusted class loader well ordinarily if
you're building a class loader you would
just call some methods from generated
class loader but if you try to do that
the security manager will shut you down
it'll say no you can't do that so you
could use ordinary reflection to try to
do that and indeed once again the
security manager will still shut you
down so they're going to do a
very odd thing here they're going to use
java.lang invoke method handles in a
3-step process they'll use the thing we
already saw to get handles to JavaScript
internal context in JavaScript internal
generated class loader we'll see that on
the next slide then they're going to use
perfectly ordinary method handles things
to get a method handle for the find
constructor method they'll use that to
get a method handle for the internal
context and then they'll build an
internal context object and then they'll
use that to load the class loader
because and that works because the
context is considered trusted so this is
a really bizarre thing they're using
reflection to invoke reflection methods
to build trusted stuff on their behalf
two layers in two layers of reflection
going on to make this all work ouch so
here's the code and the beginning of the
code and what we see is we're getting a
method handle and we're we're getting
making a method handle and then we're
going to tell it we want to handle for
find constructor and we go look it up
and right so that code I actually need
to look at my notes here this is
frightening um so this first assignment
is getting us ready to use the public
lookup there's nothing wrong with that
you could you could legitimately do that
most anywhere this batch of boxed code
is using public lookup to get a method
handle for the find constructor method
you still haven't done anything that the
security manager ought to shut down this
is a security problem however when you
actually invoke the constructor that's a
problem because you shouldn't be allowed
to run that constructor the security
manager should shut you down why on
earth are we using reflection to invoke
invoke method handles to do more
reflection well it turns out the
implementation of the refraction of
their implementation of the reflection
libraries has to prevent untrusted
callers
invoking sensitive methods but it has to
allow trusted callers to do it and in
order to make the implementation
manageable they frequently delegate
responsibility back and forth between
various parts of the reflection
reflection libraries that's not wrong by
the way that's an important and useful
implementation technique the problem is
however that that means that you have to
figure out who is the effective caller
for the purposes of the security check
is the effective caller trusted or is
the effective caller possibly not
trusted and you have to do your security
manager check on that effective caller
it turns out that finding the effective
caller is not so easy as it might seem
every reflection method is supposed to
know how many stack frames above itself
the effective caller should be and that
how many stack frames calculation is
supposed to ignore frames that belong to
the delegation within the library okay
because that's what lets the delegation
actually work and then of course you
want to permit the operation only when
everything is properly secured so in the
version of Java that was vulnerable the
invoked framework was brand new in
vocables as compared invoke yeah but
that framework was new so the
implementers of the invoke framework
forgot to add the methods in the invoke
framework to the group of methods that
are ignored because of delegation okay
and as a result that means that other
other reflection methods would walk up
their call stack ignoring things and
then they would see something they
weren't told to ignore and go oh that's
trusted code I should let this happen
and there's your vulnerability okay and
so in effect the library has had at that
point conveniently violated rule seco
five on your behalf without your having
to actually do anything and that in turn
let
let this vulnerability happen so they're
in Wow ten minutes was the January 0
date so here's another one that's nearly
as mind-bending the rule is very simple
never load trusted classes after
untrusted code has loaded any classes
you have to load all your trusted
classes before you let untrusted code
blow to anything
well why might you be allowing untrusted
code to load classes at all well it
turns out that there are value that's a
valuable feature of many things consider
for example Tomcat Tomcat as an
application server trusts itself but it
necessarily doesn't trust the
applications that run on top of it or at
least it shouldn't so internally it has
a flag that tells it should I use the
trusted class loader or the untrusted
class loader and if you're using the
webapp class loader that says all of
this stuff is untrusted and that's used
to load whatever classes are requested
by the applications running on top of
Tomcat that's great ok on demand class
loading however it gives you all kinds
of fascinating problems lots of JVMs
deliberately defer class loading until
the class is actually requested by some
executing code this is important it
gives you a smaller average footprint it
avoids wasting time loading unneeded
classes but what happens when we mix
trusted and untrusted class loaders
along with this deferred class loading
so here we are in Tomcat this is before
version 6.0 20 and they have some code
here that says if we're in start-up mode
create a web digester this is a web
digester is an XML thingy that looks at
web logs and God knows what all but
never mind it loads an XML parser so
you're going to call at some point
create web digest
and a couple of levels down in there
what's actually going to happen is
you're going to be in the class digester
factory and you're going to call this
new digester method which is going to
create one and decide which class loader
to use and return it um load it and
return it I should say okay so the
result produced from here ends up as
being the web digester we saw before so
digesters use the context class loader
flag to decide which class loader to use
should I use the context one or the
untrusted one okay that's great
none of this is wrong what you're seeing
here there's nothing wrong with this
code it's all in green for a reason so
when you want to process a web dot XML
file the code is just going to get a sax
parser and off it goes so all of this is
fine everything I've shown you is in
green where the heck is the exploit
remember we're talking about Tomcat
suppose there's multiple applications
running on this Tomcat server and
suppose some earlier application before
the one we're looking at right now asked
to load a malicious sax parser factory
ok it turns out that the method on the
previous slide would end up getting the
malicious factory instead of the trusted
one even though it expected to get the
trusted one and the consequence of that
is that once you've got that malicious
partial parser factory you can make it
read or modify web.xml or lots of other
pieces of arbitrary web applications
that aren't your own application there
are other things that are expecting to
be walled off from the malicious
application but they're not ok more
generally this kind of vulnerability
would allow an attacker to provide
trojan versions of sort of arbitrary
tests arbitrary trusted classes and of
course your very safe and secure code is
going to get
very unhappy when it tries to invoke a
trusted thing that turns out not to be
so the solution turns out to be very
straightforward if you load all the
trusted classes first before any
untrusted thing is ever allowed to be
loaded then the bad guy can't replace
your trusted thing with an untrusted
thing so what they actually did is they
simply change their creation of the web
digester so that it doesn't use the
context class loader it only uses the
trusted class loader and you always get
a trusted parser that's great okay now
Tomcat is some hundreds of thousands of
lines of code the Tomcat developers in
their changelogs found a bunch of other
places where there were similar
vulnerabilities to this and patched them
to so now how many of you are confident
that they found them all okay
well I'm not terribly confident that
they found them all either okay but wait
there's even more fun
suppose you're using OSGi modules or
some other deployment technique that
makes really fancy you use of complex
class loader trees yes still have to
follow this rule because if any
untrusted code can ever be loaded before
some trusted piece is loaded you could
be vulnerable to this same problem okay
so if you're off in OSGi land or any of
those other kinds of scenarios where you
have complex class loading going on you
want to look very very very carefully at
the order that classes get loaded in to
make sure that you don't have this kind
of vulnerability I'm afraid I don't have
any good advice about how it is that you
navigate your way through all of that
and make sure you got it right this kind
this is the kind of thing that makes my
head explode so I haven't got a great
solution for you but this is a great big
vulnerability if you're not careful
about it okay
now we're going to talk about something
that you probably thought you would
never see in a security lecture we're
gonna talk about floating-point so we
have this rule here that says do not use
denormalized numbers well obviously
we're gonna have to tell you what a
denormalized number is I'll go through
it quickly we have I Triple E float in
Java so here's an example of problems
with denormalized numbers what does this
thing print we have we create 1/3 we
multiply it by a very small number we
divide it by the very small number and
we print our output at each stage now if
you're a normal ordinary grade school
math kind of person you expect to see
you know one-third some tiny number
one-third what you actually get what you
actually get is about 1/3 a tiny number
and 0.4 wait where did a point four come
from well the way the way I Triple E
floating of your that's the fractional
part of your floating-point number
normal values have an implicit leading
one-point fraction okay so this value
here I've written out the fraction in
binary would be a normal float value
trust me there's 23 bits there you don't
have to count them but when values are
very very close to zero you don't have
enough precision left in that fraction
to have the leading 1 bit okay there's
just not enough so you wind up with
leading zeros in the mantissa and that
is that kind of number is said to be
denormalized because as the mantissa
shrinks those leading zeros are no
longer effectively bits of precision
they're now behaving as part of the
exponent not as part of the fraction and
so as you get denormalized numbers you
are absolutely guaranteed to lose lose
precision and the more denormalized they
are the more precision you lose so yes
it is possible to have a denormalized
number that has one bit of precision
okay and you can imagine what that will
do to your floating-point calculation so
now here's a nice generic piece of java
code we're just going to call parse
double-a library routine on this string
okay
so what happens when you call this any
takers from the audience before Java
update one six update 24 or 1.5 update
28 or whatever what actually happens is
a denial of service whatever thread you
call this in goes away and never comes
back okay so now you're beginning to see
why I'm talking about floating-point in
a security lecture what actually
happened is that input value caused an
infinite loop in parse double okay and
the reason it caused an infinite loop in
parse double is that the library
implementers forgot about denormalized
numbers when they wrote the library that
parsed doubles okay and so their
iteration inside this the parse double
never converged and they just sat there
computing away forever now guy Steele
who is an Oracle fellow and was a son
fellow at the time this did this
happened wrote a paper in the 70s about
how to correctly parse and print
floating-point numbers and you know you
can get that paper for free from the ACM
digital library there is no excuse for
making this mistake okay but never mind
the point is I'm know I'm being a little
harsh on the on the son developers but
really this is emblematic of a bigger
problem with floating-point that yeah
they fixed it it now gets the correct
value everything's hunky-dory but in
your code where you work with
floating-point numbers even if you don't
have substantial accuracy requirements
you'd better go detect floating-point
numbers that are denormalized on input
because you don't want those
ever being involved with your
computations because you will get the
wrong answer okay and depending on your
particular algorithms and your
particular application a wrong answer
could be as simple as somebody comes and
you know beats you up for breaking their
spreadsheet or it could be as bad as the
airplane crashes or you know your system
locks up because of an infinite loop
like that we don't know for sure so it
turns out it's absolutely trivial to
detect denormalize numbers this is not
necessarily the most efficient way to do
it but it absolutely will work you know
they give you constants that tell you
the smallest normal number and you can
do the obvious range check and say is
this denormalized or not easy as can be
so there are a whole bunch of risks with
floating-point generally but denormalize
numbers in particular if you lose
precision you can get the wrong answer
the print representations can be very
different from what you expect to get
leading zeros where you didn't expect
them you can also break you numeric
algorithms non convergence give can give
you an infinite loop you can get wildly
incorrect answers or total garbage all
kinds of fun things there is however an
exception to this rule in the in our
coding standard which is denormalized
numbers are acceptable when suitable
numerical analysis shows that all
relevant accuracy and behavioral
requirements are preserved now what does
suitable numeric analysis means mean in
this context fundamentally what it means
is someone who is a professional
numerical analyst has looked at your
algorithms and has figured out it's okay
it won't matter now I've had a couple of
classes on numerical analysis which
means I know just enough about this
topic to know that I am NOT a
professional numerical analysts and
unless you do that all the time you
aren't either okay so the easy way to
follow this rule is just keep the
denormalized numbers out of your out of
your inputs entirely okay there's a lot
more detail in the standard so
the the Java designers paid a ton of
attention to security
there's tons of standard libraries they
paid a lot of attention to security as
well there's all kinds of facilities to
help you with security and that's great
but none of that is enough unless you
follow a reasonable standard development
practices to avoid putting holes in your
code and lots more information available
thank you very much and I'll happily
take questions even though we're a bit
over</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>