<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning in Action | Coder Coacher - Coaching Coders</title><meta content="Machine Learning in Action - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning in Action</b></h2><h5 class="post__date">2018-04-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1U1XViHjzLU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome everybody this is the last
session today so I was thinking 15
seconds is not too much to start too
early we're talking about machine
learning in action today very briefly
about myself so my name is Helle the
last name is healthier but nobody can
ever pronounce it it's very funny at the
airport when they announce my name is
pronounced like SK aho and I'm surprised
who is that it's me healthcare ho but my
name is chelsea aho but everybody calls
me Helly from finland because it's much
easier to pronounce and everybody knows
I come from Finland I have graduated
from University of Helsinki with a
master's degree in computer science and
currently working on my doctoral studies
I'm doing research and lectures at the
University my areas are databases of
course big data multimodal databases and
missiles and tools for utilizing semi
structured data for decision making that
means it sounds very fancy but it means
how do you get value from your data
that's a value and that work I do at the
University of Helsinki which is one of
the best universities universities in
the world so welcome to visit us I've
been working with Oracle products since
93 honestly I've been working with them
since I think 89 but I was at the
University so I've been paid for working
with Oracle since 93 on ITI plane since
1990 I've been working with other tools
as well
data and databases is very close to my
heart and that's why I find machine
learning very very interesting I'm the
CEO for miracle Finland which is a small
consulting company in Finland Oracle ace
director ambassador for amia Oracle user
groups and listed as one of the top
hundred influences on IT in Finland for
three years in a row which surprises me
the most probably but anyway that's what
I am public speaker author I want the
DVD Award in 2015 ever since it's not
being given to anybody so that was
probably very traumatic to Oracle or
something I don't know anyway that was
the last the first and last device ever
so the two books I have written the
first one is about database designing
and the second one I wrote together with
four other ace directors are open and
aprenden Tierney Martin with Lake and
Alex Norton very international book very
different countries different continents
and so on and
different backgrounds for all the
authors in the end of the presentation I
will give some chapters from that book
if you're interested to read more about
those topics I talked about you will
find from this book as I said I'm an
Oracle ace director so if you're
interested about the ACE program here's
some information about it there's three
different levels in the program and
anybody is able to nominate the person
as an ace any of the levels so up to the
topic finally what is machine learning
machine learning is an important part of
artificial intelligence machine learning
teaches computers to learn from
experience
just like we learn from experience but
they learn from algorithms so they learn
from data the algorithms and they make
predictions
it's about mathematics it's about
statistics it's about a lot of different
things it's a field of study that gives
computers the ability to learn without
being explicitly programmed said mr.
Arthur Samuel in 1959 so this is not a
new topic this is even older than me
think about it
1959 a systematic study of algorithms
and systems that improve their knowledge
or performance with experience so if
that was 1959 why do we talk about it
now why machine learning today because
of improved technology the technology we
have now is something beyond what he had
in 1959 he was not able to do things we
are able to do today so we have the
technology to do these things the price
of storage solutions has gone down many
things has happened with the technology
itself but there's another reason to the
environment where we live now it needs
machine learning and so two reasons we
are finally able to use it and we really
need it that's why we are talking about
today
so it's artificial intelligence one of
the reasons but the other reason is Big
Data what is this big data
so the name is horrible because it
implies that there's the size of data
after this size we have big data and
it's not true of course it's it's about
the size as well but it's about many
other factors as well so the data is big
when the traditional processing with
traditional tools is not possible due to
amount or complexity of the data you
cannot open the attachment of your email
or you cannot edit the photo or
something that you can normally do but
now you can't it might be that we are
talking about big data in general when
we talk about big data we usually have
three weeks we have the volume the size
the scale of the data velocity which
means the speed of change and the
analysis of streaming data and thirdly
variety which means that we have
different formats of data sources
different forms of data we have
structured we have semi structured and
we have completely unstructured data so
these three these kind of make it Big
Data but I don't want to make it too
easy for you there's other ways as well
that might make it big data veracity
means the uncertainty of the data so the
data can be worthless or harmful it can
be a virus because we have so many data
sources it's not just our invoicing
system it comes from somewhere outside
how do we know it's reliable data
viability which means which means that
we need to validate hypotheses before
taking further actions like when Haley
arrives to Boston it's raining like in H
which is true I write here and it was
raining really hard but it's still not a
fact that whenever I arrive here it's
raining I can't say it for sure because
I haven't been here before so how would
I know it's raining always but the
computer would say yes whenever she
arrives it's raining but person knows
it's not a fact so this is not a true
fact also the value so some data is
valuable some is less valuable and what
makes it even more tricky
that today's valuable data tomorrow can
be completely useless or a data that is
very very useless today we have nothing
to do with cat videos it's very
important tomorrow because we need to
find all those customers who are posting
cat videos because they are a target
group so the value of data can change
variability refers to date house meaning
is constantly changing like a word in a
sentence if you put not in front of the
word it changes or if you have the same
word in different sentence it might meet
different things so depending where the
data is its meaning can be something
completely different so we kind of have
to understand also the context when
talking about the data and last but not
least visualization visualization is one
of the most important things I think
because if we have a lot of data it's
very hard for human eyes to see the data
plenty of rows or whatever however we
have the data but if we put in a
visualized way we have a picture of the
data it's much easier to understand and
interpret so visualization is one of the
biggest things I think in big data to be
really able to understand and use your
data so all these V's makes it quite
difficult to handle big data different
kind of challenges more and more dates
are the volume different data models
different data formats the variety
loading in progress while data
exploration is already going on velocity
not all data is reliable veracity we do
not know what we are looking for the
value the viability the variability and
it must support also non-technical users
like journalists investors politicians
so we need to have a soul is a ssin for
those people they are not technical
people but the problem is that all this
must be done efficiently and fast and
actually as must as much as possible by
machines because they can do it fast and
cheaply and that's how the machine
learning comes into picture so when
should I use machine learning when you
have data
and that's a serious thing not a joke
because you cannot use machine learning
without having data that's number one
I once tried to build a demo with just
small and crappy data I didn't work so
it is a fact you need to have good data
plenty of good dates are to be able to
really use machine learning so it is
part of this data you use for finding
the right model and part of the data you
use to prove that the model really works
so you don't use all your data to build
the model just part of it
the rules and equations are complex like
image recognition and they are
constantly changing like fraud detection
these are the possible use cases for
machine learning very very easily set
there are of course different other
plenty of different other options as
well so the nature of data changes and
the program must adapt to that
today's spam might be tomorrow's ham and
the computer must be ready for that
it cannot be explicitly programmed like
predicting shopping trends I've been
trying to do that manually following my
younger son who's very good with
shopping trends
I can't Forge whenever he tells me some
brand is very very fashionable and I try
to go and buy something with that brand
it's already gone a new brand is already
in which is much more fashionable than
the previous one I just can't keep track
I wouldn't even learning for that to be
able to buy something for my son that is
exactly the correct in machine learning
the important thing is a task a task is
a problem that we are trying to solve
with machine learning and it's really
important to define the task well what
am I trying to achieve with machine
learning it's not just computational
subject so if you're afraid that this is
not yours because you hate math or
you're not good in statistics or
something else don't be afraid because
there's a lot of different things in
machine learning that are needed and one
of them is understanding the world how
the world works what's interesting in
the world
and I don't think computers can do that
the computer would say it's raining when
Haley comes to Boston but you will know
it's not true you will know that there's
nothing to do with me coming here and
having such a kind of weather so we need
also human beings to be able to define
the tasks what are we trying to achieve
but it's all about algorithms so this is
usually the scary part people say I
don't like algorithms I don't understand
them but this is nothing scary really an
algorithm is the experience for the
computer to learn with it solves the
learning problem and it produces the
model humans learn with experience but
the computers with algorithms the
problem is that it's not easy to find
the right algorithm for your task it
will take some some trial and error and
before you find the right one depending
how you work but usually it is not easy
to find it in the first try but which
algorithm to take the selection of an
algorithm depends on for instance the
size and type of the data the insight
you want to get from that data and how
those insights will be used but it's
always a trade-off between different
things it might be a trade-off with
between a predictive accuracy on new
data or speed of training memory usage
or transparency which means black box
versus clear box how the decision was
made how did the algorithm decide to do
such thing or interpretability
the ability for human to understand the
model so it's a trade-off between
different things and depending what is
important to you that might define which
algorithm would work the best for you
and which model so a model is the output
of machine learning the task is
addressed by a model there are different
models there are predictive models
descriptive models and prescriptive
models predictive model is a model that
says that the forecasts might happen in
the future tomorrow it might be raining
because this script did tell us what
happened
yesterday it was raining and
prescriptive model is the most complex
one it's a predictive model plus
actionable data and a feedback system to
track the outcome features or dimensions
are very important in machine learning a
feature is an individual measurable
property or characteristic of a
phenomenon being absurd said Krystal
bishop in 2006 in his book pattern
recognition and machine learning and
deriving features or feature engineering
or feature extraction this is what I
really like in the machine learning they
have several terms for the same thing
which is very confusing for the reader
that's why I put all the words here so
these all mean the same thing so
deriving features is one of the most
important parts of machine learning
it turns data into information that the
machine can understand and that's why
it's really important and the model is
as good as its features if the features
are rubbish the model doesn't work in
short machine learning is use the right
features with right algorithms to build
the right model that achieve the task
you are trying to build or trying to
solve
that's what machine learning is about
there are two types of methods or
techniques in machine learning
the first one is unsupervised learning
the second one is supervised learning
depending who you ask this list might be
longer but these are the main catagories
unsupervised learning means finding
hidden patterns or intrinsic structures
in input data so we don't know what the
input data is we're just trying to find
something logical from that data while a
supervised supervised learning is where
we train the model on known input and
output data and predict future outputs
unsupervised learning is from unlabeled
input
it's typically used when you don't have
a specific goal you are not sure what
information the data contains or you
want to reduce those features of your
data for pre-processing for supervised
learning data for unsupervised learning
would look like maybe something like
this a lot of data No Labels no headings
I have no idea what it is I can see this
LAX
I might think LAX somewhere here oh it's
not showing it
lax might mean the airport in Los
Angeles but it might be also Swedish
language meaning salmon the fish that's
Luxan in Swedish so I can see that this
is something to do with LAX but what is
lax I don't know so it doesn't have any
header Eddie any any names for my data
it's just data and I'm asking the
computer find me something from here
something that might be interesting for
me and then it's my job to tell the
computer if it's something that is
interesting or not clustering is the
most common method for unsupervised
learning and it's used for exploration
exploratory data analysis to find those
hidden patterns or groupings in the data
there's two ways of doing clustering
hard clustering or soft clustering hard
clustering means that each data point
belongs to only one cluster Wireless
soft clustering allows these data points
to be in several clusters hard
clustering
has different algorithms I just
mentioned here some if you want to
Google more about them
this k-means caimito it's hierarchical
clustering Wireless of clustering which
has data points in probably more than
one cluster might be fuzzy C means
Gaussian mixture model this about 100
150 or 300 1000 different algorithms so
these are just some examples you so that
you see what they are called
they might sound familiar from the
school x supervised learning
it's learning from known labeled data we
are training a model unknown input and
output data to predict the future
outputs this might be data for
supervised learning so we have the
headings there and actually telling me
that Alexei was an airport airport in
Los Angeles in supervised learning we
first trained the model we load the data
we pre process it we learn using the
method and the algorithm and we create a
model we repeat this as many times as
needed to finally get the model that
works the best for us when we are happy
with the model we can start predicting
we use the model we just built with new
data we pre process the new data we use
the model and we get predictions if we
are happy what happened here we are able
to integrate actually this model to our
application and we are ready to use it
in production just in short the chatbots
I'm sure you were attending the keynote
this morning about chatbots it's one
tiny small example about machine
learning I see if I can oops where am I
too many things open here okay I will go
here no go away
so Chuck bot is a simple example
okay I'm completely blank now always fun
with computers so chat bot is using very
simple algorithm it's using linguistic
learning as you learned in the mall was
everybody attending in the chat pod
session this morning most of you good so
we have intents which actually means
kind of functionalities that I'll check
what hat do you know what is a chat bot
chat pod is the thing that you can use
with your phone you can order a pizza
using a facebook Messenger that's what I
did the first thing I did with with a
chat board was ordering a pizza
I can tell you now that I didn't get the
pizza I wanted I get something
completely different and then I gave
them a lot of feedback but the feedback
system didn't work so I tweeted them
that your feedback system doesn't work
and you can't actually give me what I
ordered
but every anyway so it was very fun
ordering pizza with your phone and with
the chat bot so the check but idea is
that you are kind of talking with a
person but actually it's not a person
it's a robot it's a program so you're
chatting with a bit of program and it's
asking you the right questions you are
answering and it's asking you more so
it's it's really a discussion so it
starts with those intents which are the
functionalities in this one we have
balances we have transactions so kind of
money kind of things here these are oops
these are intense
they have entities like in this
particular chat for tests like account
type and so on
and you can define different values for
this like account I can have savings
checking credit card and so on and then
we also have the orchestration the the
program logic which is kind of handling
everything but how it works is that in
my intense I have my computer's very
slow so bear with me I have different
utterances that will help it to decide
what I'm trying to ask so I will show it
how it works so if I ask the computer
balance oops so I want to know the
balance of my account it's thinking and
thinking and wondering what on earth is
she trying to ask me I have no idea and
say sorry I don't understand that
question why does it understand this is
very clear to me I just want to know my
balance I don't want to type like a lot
of things because I'm in a test mode I
can go here and ask it why are you not
knowing what I'm asking if I ask you
balance what do you think oh now it
knows it no it's
I can't know it because balance has 50
15.4 like who that you are actually
asking for balance but you could also
thinking about sending money and that's
14.1 and because they are so close to
each other I'm not sure which one you
mean
oh dear so how I can solve it these
utterances are kind of hints to the
computer when I'm asking this kind of
things I mean that
so in balance when I balances when I ask
balance I really mean balances I will
train my model I will reset the whole
thing let's ask again if I say balance
what do you think I'm asking for 100%
sure you are asking for balances and not
any transactions because I just told
whenever I type balance
I mean balances so now the computer
knows it and it's not just if I if I
test it and I say here balance it will
ask me which of your accounts now I know
you're asking for balance so this is how
I can train my chatbot to learn better
to understand better what I'm trying to
ask so it's a very simple example of
what could be machine learning jackpots
can do anything this morning we saw how
the speaker just sold his car using a
chatbot so I don't have a car to sell it
but I could sell it with chatbot no I
wouldn't actually sell it with chat
board I don't think so so supervised
learning so that was just a tiny little
example you don't get bored with my
talking that's why I want it have a demo
here it was about supervised learning I
knew what I have and that's why it was
not unsupervised but back to supervised
learning
there are actually four predictive
models there are two main methods or
techniques for supervised learning and
they call classification or regression
classification models are trained to
classify data into categories so in that
case when I ask for balance
I'm asking for balances the categories
balances they predict discrete responses
like email is genuine or spam tumor is
small medium large tumor is cancerous is
spinning person is credit first person
is not credit worthy so it's putting
things in categories two or more
categories applications for that might
be medical imaging speech recognition
credit scoring credit scoring is very
typical example of this so can the data
be tagged a categorize can it be
separated into specific groups or
classes if you say yes it might be that
classification is the solution there are
plenty of algorithms for classification
typical ones are decision trees backed
and boosted decision trees okay nearest
neighbor night vision or neural network
regression is predicting continuous
responses not just one yes/no categories
like that but just continues responses
like changes in temperature or
fluctuation in electricity demand
forecasting stock prices handwriting
recognition acoustic signal processing
failure prediction in Hardware
electricity for a load forecasting that
kind of examples that would be
regression regression algorithms could
be linear regression non linear
regression or gosun process regression
model but whatever you do with machine
learning any of those we already spoke
about or something else remember it's
always approximation it's not a fact it
gives you an approximate answer based on
the data it has and based on the
algorithms it's using so it's not a fact
some of these answers are better some
even useful but some are completely
rubbish when Haley arrives to Boston
it's raining that's completely rubbish I
so actually in Los Angeles it happened
the same when I arrived to Los Angeles
it was raining and it never rains in Los
Angeles they told me to come back any
any day so at least I have one place I'm
welcome if I bring the rain with me
always
so we are searching for patterns and
trends that's what we are doing most of
the time usually we want to have very
accurate predictions the higher the
number it is the better is the
approximation but there are several
models you choose the best but it's
still not a fact it's an it's an
approximation it's a guess something
might be happening like this but I'm not
sure if it's true or not so it's not a
correct answer so if this machine
learning says that because of your genes
and your background you might have a
cancer it does not mean that I do have a
cancer it just said this is the
possibility and instead of starting
crying I should go and see a doctor so
it's not really a fact real life use
cases for machine learning spam filters
very classical example I'm sure you all
have spam filters in your email that's
it LOC filters or alarms data analytics
image recognition speech recognition
medical diagnosis robotics fraud
protection all these kind of things done
by machine learning online shopping you
go to Amazon you search something you
could recognize recommendations
how would Amazon know what you are
looking for voice-to-text smart personal
assistants like give me the recipe for
bread you talk to your phone seriously
and ask for recipe for bread and it
gives you a recipe for bread that's
weird
find the nearest grocery and it finds
the nearest grocery that is weird you
have Siri Google assistant Alexa echo
Cortana many different technologies that
will do that already today and then we
have Facebook when I was preparing this
session Facebook was not as famous and
popular as it is today we all know about
Facebook now that time I was just
curious because I noticed what Facebook
can do and I wanted to learn more how do
they do it there are three article
here that I used as a background search
for this how Facebook is working so I
don't work for Facebook and I have no
inside knowledge of Facebook so
everything I say here is based on these
articles Facebook's mission is give
people the power to build community and
bring the world closer together well I
think they did it pretty well we are
very close now to Facebook it connects
more than 2 billion people and that was
December 2017 but this could have not
done without machine learning so it's
it's an obvious thing that they are
using machine learning the massive
amount of data required by machine
learning services presents challenges to
Facebook's data centers plural form
several techniques are used to
efficiently feed data to the model
including decoupling of data feed and
training data compute colocation and
networking optimization disaster
recovery planning is essential and
that's something I enjoyed a lot when I
was reading these articles because even
though they are doing all the modern and
cool things they still remember the
basics we have for computer science we
still need to have disaster recovery
planning they realize that what they do
is time and an energy consuming resource
consuming and if they lose it they have
to do it again so they need to have a
plan for disaster recovery they are
actively evaluating and prototyping new
hardware solutions a while remaining
cognizant of game-changing algorithm
innovations so they're doing both
hardware and software to stay in the
game they use machine learning for
products such as a newsfeed ranking ad
search Sigma Loomis face a language
translation and speech recognition just
some examples newsfeed machine learning
is used for ranking and personalizing
newsfeed stories so those stories I see
in my newsfeed are completely different
than what you see even though we had
exactly the same friends and everything
is the same they know I'm interested
about different things than you are so
we will see different things in our news
newsfeed
it's also filtering out offensive
content which I didn't recognize at all
but I interesting they do it they also
highlighting trending topics and ranking
search result much much more so the
thing they deal with all that data is a
lot they have general models that they
train and they use those models with my
data to get this particular news feed
for me the ads is the same thing so they
get the money by clicks so online
advertising allows advertisers to only
bid and pay for measurable user
responses so not everything but just
those that are measured that it was
really clicked and because of that it
has to be a very good system to predict
those clicks because they want to have
as much money as possible and those
people who are having these ads they
want to have as good audience as
possible again they have a general model
which is adjusted to my data define
which ads would be interesting to me and
which will I click so predicting the
clicks it has to be robust and adaptive
and capable of learning from massive
volumes of data there's so much data
that has to be used to be sure that I
will click that ad and not show it to me
without really being interesting to me
so based on the experience the most
important thing is to have the right
features remember the features it's
really valuable to have the right
features and the right model this is how
they do it I don't go to details here
but they actually use two algorithms
combined to really achieve the best
result as fast as possible as accurate
as possible and it didn't work with only
one algorithm they actually needed to
the search it's not just one search it's
a series of distinct and specialized sub
searches that are collected together in
a classifier layer and then found those
things that are in
in offline stage they train the model an
online stage they run the model and find
the right searches then Sigma is a
general classification and anomaly
detection framework that they use it
includes hundreds of distinct models
running in production every day and each
model is trained to detect anomalies
classify content
Lumos that is interesting it extract
extracts high-level attributes and
embeddings from an image and its content
and it can translate that to text and
this text can be used to another model
or algorithm as an input so
understanding images and they content
using this Lumos is quite interesting
phasor is the one that is the the last
thing that we heard about facebook about
face recognition so phasor is Facebook's
face detection and recognition framework
given an image it finds all the faces in
that image it runs to use a specific
facial recognition algorithm to
determine determine the likelihood of
that face belong to one of your top and
friends and it finds that tells you this
might be your friend Alan and it says
that it only uses to those of your
friends who has said that they enable
face recognition not to all your friends
only those who enabled face recognition
so this is allowing Facebook to help you
to find your friends from pictures and
making it faster to recognize who's in a
picture language translation is my one
of my favorites
it makes internationalization of
Facebook content so instead of showing
me what people write in English they
show it to me in Finnish which makes it
very very funny because Finnish language
is not easy so I have a lot of funny
moments when I'm reading when Facebook
is translating Finnish it's very fun and
I'm really looking forward to this
because this will improve
for sure but now they have support for
more than 45 languages as the source who
is the target and with all these
combinations it actually means that they
support more than 2000 translational
directions that's a lot and because it
sounds very stupid to have so many
programs translating from A to B B to C
C to a and so on they are actually
considering to have multi-language
language models to kind of make it more
straightforward speech recognition also
I'm looking forward to see the finished
version of speech recognition which is
not there yet
it converts all your streams into text
and again this text can be used by
another algorithm as an input it
provides automatic caption of videos
quite interesting but at the moment
mostly in English so you heard what they
do with machine learning and you would
expect them have about hundred
algorithms they are using no they
actually using five algorithms yeah so
machine learning is not tricks about
algorithms it's about finding the
features finding the model being as
simple as possible that's what they've
been doing simple a couple of algorithms
they are using algorithms they
understand very well so how do they do
this they have a Facebook learner
platform FB learn a platform which has
elements like FB learn a feature store
if the flow and FB learn a predictor
they have data features training they
have the model inference and predictions
the feature store is the starting point
for machine learning modeling tasks it
is kind of catalog of several feature
generators so features that might be
interesting in facebook world it helps
to find those interesting features you
don't have to see all the which features
in the world it will help you to kind of
narrow down your search then we have the
flow which has workflows operators and
channels
and the flow has tooling for experiment
management so they can experiment
different kind of things to find the one
that is the best
it consists of three core components on
authorship and execution environment and
experimentation management user
interface and numerous predefined
pipelines for training the predictor is
Facebook internal inference engine that
uses this model strained in FP learner
flow to provide predictions in real life
and real time remember they always have
the general model and it's used with my
data to give the prediction for me
that's how it works
they also have frameworks for deep
learning they have two distinct but
somewhat sanitized frameworks they have
pi toge which is optimized for research
so they can quickly try different things
and they have cafe tree which is
optimized for production so when they
finally find the best model this cafe 2
is fast and efficient in production so
pi toge is flexible easy to debug and
dynamic neural networks it is not
optimized for production and it's not
optimized for mobile mobile deployment
it's for research mainly well as cafe is
in-house production framework for
training and deploying large scale
machine learning models but it's not
good for researching it it has good
performance cross-platform support and
cover its four fundamental machine
learning algorithms but the problem is
if their research with one and then they
want to have to implement it to another
one for production how to do it they use
the thing called open neural networks in
exchange oh and NX it's a tool and a
format to represent deep learning models
in a standard way to enable transforming
from one to another so they don't have
to build it two times they can use this
to transform it it's an open
specification there's a group working on
this on annex X and Facebook is one of
those members so it provides an ability
to automate automate ik capture and
translate statics parts of the model and
additional tool chain facilitates
transfer of dynamic craft parts from
Python by either mapping them to control
flow primitives in kappachu already
implementing them in C++ as custom
operators so it does a lot of things
automatically without telling the
programmer to do the same work twice the
success factors for Facebook I could
really say now success because we
already know how much they do with the
data is predicated on the availability
of extensive high quality data so the
data is the key thing with machine
learning complex pre-processing logic is
applied to ensure that data is cleaned
so the data must be good quality and
normalized to allow efficient transfer
and easy learning enough data good
quality data the ability to rapidly
process and read this data to the
training machines is important for
ensuring that we have fast and efficient
offline training and these impose very
high resource requirements especially on
storage Network and CPU they are
actively evaluating and prototyping
hardware solutions as well as algorithms
and knowing what to measure is very
important so how do you know what to
measure well how does the model perform
and data which of the models is best
which of learning algorithms give the
best model for the data and so on and so
on and so on and you need to have
measures to know if you are achieving
whatever you want to do you have there
are so many things you can measure so
depending what is important to you have
to define what to measure can be number
of positive number of negatives class
ratio accuracy error rate ROC curve
whatever but it all depends on how we
define the performance for the answer we
can improve the models to increase the
accuracy accuracy and predictive model
and so on and so on we can improve many
many things
usually improving means feature
engineering so we reduce the features we
have too many features and we need to
remove some of the features or it might
be hyper parameter tuning these are the
common things to do in facebook they
said we noticed that the largest
improvements in accuracy often came from
quick experiments feature engineering
and model tuning rather than applying
fundamentally different algorithms you
saw five algorithms so that's really a
fact so a quick demo with sequel
developer so this is the demo where we
have the example input data with known
input data we want to verify the data
what kind of data we have what is
interesting then we train the model we
test the model we use new input data and
we do predictions I don't have much time
so I will just do it very quickly so
okay it's not changing here what
happened okay I changed but the computer
doesn't let's try
yes please here we go so this is sequel
developer sequel developer has a thing
called data miner which can be used for
machine learning this is a tool that I
don't need to know about math I don't
need to know about many things I only
need to know about my date and kind of
know how the tool works by the way this
tool is for free you can just download
and start using the only exception is
data miner
I will go to details a bit later so I
have my data here I have just a very
typical Oracle example table which has
customers and I have here buy insurance
which says I either have insurance and I
don't have insurance and my job is now
to find those customers who doesn't have
insurance yet but would actually quite
likely buy one so I don't want to call
all my customers I just want to call
those customers that are likely going to
buy an insurance I need to find those so
I tell my tool here is this is my sauce
table and I want to have all the
attributes here and I tell my tool here
that my insurance is the fact I want to
crop by yes and no so it has a known
input unknown output it already knows
who of those customers bought insurance
and it's trying to find me the reason
why they bought it and based on that
find me those customers that would
likely buy it as well so here I can
explore many things I can view the data
or I can view the statistics it will
tell me that H so here is it has this
person has insurance the person doesn't
have insurance so no insurance is read
so I can see if H is a factor or if Bank
funds is a factor or if credit-card
limit is a factor for buying an
insurance
so I can understand my data better then
I can just build the model here the good
thing here is I don't have to know
anything about the models I just tell
the tool if I if I'm interested about
classification or regression that's my
only thing that I have to know and after
that it will use those models that it
has built in in at all you can see here
it's been using these three models and
found let me say compare test results so
I just go very quickly here so it's been
it's been using all those models and
comparing them for me how these models
are different and then I can based on
the facts here I can choose which model
I want to use so I have decided I want
to use this one decision tree so I found
this is the best one then I have
collected here new data these are the
customers who doesn't have insurance yet
I want to use my algorithm or my model
here define those customers from those
who doesn't have it yet
who be buying an insurance what would be
a target group for me to go in and call
and here I will see customers that the
prediction is no this customer will
definitely not buy and I'm pretty sure
80% sure the customer will not buy
insurance so if you want to call the
customer go ahead but waste of time but
instead if you go and call this customer
this is the customer number here it's
70% sure he or she will buy own
insurance so maybe you should call this
customer or maybe you should call this
customer who's also about 70% sure that
will buy a insurance so all this can be
done without very deep mathematical and
statistical achieve this tool to build
my model very very quick quick example
so oops the wrong one okay so the tool
we just saw is equal developer and it
has this add-on called data miner so
sequel developer is free tool while as
this add-on is payable option if you
have on premises you have to have a
separate license for it but if you're in
a cloud database service either
high-performance package or extreme
performance package includes it then you
are free to use it
there's the installation instruction
here if you want to start using it and
there's also a tutorial here in our book
chapter 10 is talking about this
particular thing there's also another
book written by Brendan Tierney lies
talking about data miner then this
Oracle or Enterprise so if you prefer
using our that would be one option if
you don't like the tool I'm showing
maybe try or if that's something you
already know if interested our chapter
11 we'll talk about that and there's
also another book about it if you want
to use predictive queries in Oracle
database now in eighteen see it's even
more than that go ahead and do that you
can also build those using the data
miner I just show you you can build
those predictive queries and just use
them or you can write them using sequel
chapter twelve or you can use any of
those programming languages that you
already know so my advice is take
something you already know and add
something new so if you're super guru
with C++ start with C++ there's plenty
of libraries that you can use for
machine learning go ahead and if you're
already familiar with sequel and that's
the one that you know the best start
with sequel or if Julia scalar Ruby
octave a MATLAB SAS is something you
already use go ahead and use that I put
a link here showing which of these
programming languages would be the best
to learn so it depends on depends who
you ask but anyway don't
everything from scratch use the
knowledge you already have and add
something new there but whatever you do
do it now because the future is here
artificial intelligence machine learning
is here and it is the future so it is a
skill you really need there are so many
interesting areas here to learn and I'm
sure you are an IT because you love to
learn new things and this is a great
area for learning new things so pick
your area and start learning it is time
for machine learning now because we are
technically able to use Allen because we
need machine learning for big data
remember all of these giving lot of
difficulties that can be kind of handled
with machine learning it can be used
everywhere with spam filters robotics
chat BOTS image recognition whatever and
it's everywhere so in Facebook they do
everything using machine learning it's
about approximating so remember it's not
a fact however well you do it it's still
approximation it's not a fact there was
unsupervised learning and supervised
learning
I'm supervised learning was the one with
LAX I didn't know what's about while a
supervised learning was telling me it's
Airport improving models is very
important one of the way stories feature
engineering another one is hyper
parameter tuning what to measure how to
measure are very important because
otherwise you don't know how you're
performing and there is so much to learn
about machine learning so I just
encourage you to start because it's very
exciting any questions I'm happy to
answer and if you have questions later
you can reach me by email or in Twitter
or you can read my blog at the moment my
blog is mainly about database designing
but we'll see it might change one day
this is so exciting thank you so much
for attending and sorry for being a
little bit over time but this is too
interesting to finish in 45 minutes
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>