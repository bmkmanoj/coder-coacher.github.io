<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Ask TOM Office Hours: SmartDB April 17 2018 - Code Classification | Coder Coacher - Coaching Coders</title><meta content="Ask TOM Office Hours: SmartDB April 17 2018 - Code Classification - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Ask TOM Office Hours: SmartDB April 17 2018 - Code Classification</b></h2><h5 class="post__date">2018-04-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/PMPW024NIDE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome everybody to what if I haven't
lost count his session number three in
this series where Tony and I are talking
about and we hope fielding your
questions about this general business of
smart DB that starts so so one point
that I wanted to make in this third
episode is for one point one topic that
I wanted to touch is the topic of code
classification inside the database and
I'm gonna talk about that at a high
level certainly not going to explain how
intervals are going to be done in secret
or peer sequel what we were discussing
about just a minute ago at a high level
now before I do that I always spend two
slides for any potential newcomers on
what we mean by smart DB this is my
really two slides short definition of it
smart DB is how you use or fail to use
the database do you use the database
just as a persistence layer or as a
full-fledged processing engine and smart
DB is of course about the letter the
using the database as a processing
engine we talked about transactional
business applications within the smart
DB arena and these business applications
that do transactions conceptually have
at a very high level three layers of
software or of code or whatever you want
to call it they have at the bottom that
the table store the data store that has
all the tables in the middle this thing
called business logic and I'll be
talking about that the next 15 20
minutes and then at the top we'll have
we have the various user interfaces of
which I'm depicting the two most common
the user interfaces and the graphical
user interfaces displayed in web
browsers nowadays and the software
interface just nowadays usually done
through restful restful calls restful
services endpoints now the two distinct
approaches that we see at the left the
database is a persistence layer you see
the business logic blob outside the disk
labeled DBMS
and at the right you see the DBMS disk
spanning that blob also indicating that
within the smart DB paradigm we envision
that business logic should be
implemented inside the database it has
many advantages that we talked about the
last two episodes and will probably
touch upon a few more in future episodes
now so using the database as a
processing engine is called a smart DB
approach of course the user interfaces
and the endpoints will always live
outside in the database now what I would
like to talk about is because this is
only this is always a point that that is
being asked when I talk about this more
DB paradigm is how do you prevent what I
have here one big pile of Gil sequel
spaghetti code inside the database and
my answer to that question is basically
the same as how do you prevent one big
pile of Java or JavaScript spaghetti
code outside the database you adopt a
sound code classification there in the
know PL sequel approach in the do
everything outside the database approach
we have model view control frame works
that help us do with that or other types
of mmv mvvm types of approaches in the
new JavaScript world and I would like to
talk about how can you adopt a code
classification inside the database and
again at a high level so I'm gonna start
with this picture again and before I can
talk about dissecting this business
logic thing into small areas I want to
make a few points about the the table
design the database design itself
because from that already originates a
code class I talked about the table
datastore here is in in the sense that
it should hold a proper apologies it
should hold a proper relational database
design and by proper I mean twofold I
mean two things of course it must fit
the business requirements but it must
also be sound and it in sound I mean it
must follow relational database
principles
now the first is up to you up to the
information on our analysis to make sure
that there's a good fit there the second
is about education you cannot design a
proper relational database on design
unless you know some of the underlying
theory that that this relational
database design is all based upon so
let's talk about it in the second
meaning when you have a proper database
design and I will discuss a couple of
guidelines in a minute here you ensure
that you won't have all kinds of various
issues that that you normally see in
applications that are not based on a
proper relational database design and
I've put I've listed a couple of issues
down here I'm not going to read them up
out loud you can you can read them
yourself and you can look at the
recording later on but but and creating
a proper relational database design
prevents these kinds of issues in the
end it will ensure that your whole
application is easier to me to maintain
but also will have a better performance
now let's go to some of the guidelines
that that I have learned them during my
career and that I employ successfully
whenever I design a database so I'm
gonna provide you with some of the
guidelines from my point of view the
first guideline is and I hope that most
of the people on the call won't think
this is a really crazy one is you should
always ensure that you use the third
normal form or the boyce-codd normal
form if applicable now you may ask what
what is he talking about here especially
if he says boyce-codd normal form or
third normal form I'm not going to
explain what that is that's out there on
the internet just google for it and you
can educate yourself but the reason why
I asked why I say this using these forms
normal forms is because then you avoid
structural redundancies and structural
redundancies are really bad because
redundancies need to be maintained and
give rise to additional code in your
application code base so if you use
third
normal form you won't have structural
redundancies in your database design and
you won't have to build additional code
to maintain these redundancies also now
what I also always say right after the
first one is don't design incidental
redundancies either this is some this is
what I sometimes call premature
optimization inside the database design
for instance you may think about should
I add a total value column of all the
order lines at the order level because I
have a lot of screens that always want
to do a sum over all the prices of the
order lines within a given order and it
needs to be displayed at the order level
and for me you should always start out
not doing that here again you might end
up with a situation where you will spend
more CPU cycles maintaining the
incidental redundancy during inserts of
order lines or changes of order lines
then you do in not having this
redundancy but always having to compute
the sum of all the order lines often
it's it's totally not necessary and and
introducing an incidental redundancy
will just end have you end up having an
application that spends more CPU cycles
that are rather than less due to the
maintenance that that you need to do
there the third guideline that I always
have is use a surrogate when whenever
you use a surrogate or synthetic key on
a table map for instance this is a very
common practice where we use a sequence
based meaningless primary key on a table
this table should always have a second
business key because if you don't have a
second business key then you might end
up in this table with two rows that are
exactly the same on all the columns
except for the synthetic key and I
invite you to start thinking about
whether that's the situation that you
really would like to have whether that's
something
that that you desire to ever happen in
in this table very likely that's not the
case so there was there there was most
likely always the concatenation of a
couple of other problems that also
constitute a key in the sense of the
database relational database theory
number four put different things in
different tables and this is all about
avoiding that you have a column inside a
table whose contents mean something
different over different rows so
depending for instance on another column
this column might have I don't know the
manager's name or depending on another
column value this column might have the
department name or might have whatever
kinds of kind of data in it columns
should have always a single meaning
inside a single table if you have a
column that has different meanings again
depending on a different column in that
table your you are not having a proper
relational database design you should
probably have introduced two tables that
that has the column each in the
different two tables with the single
meaning that you had in the in the first
design the other thing is put special
things in separate tables and this is
about what sometimes refer to as
subtypes so when when you have a table
with a whole bunch of columns that are
all mandatory but you also have let's
say three columns that are optional but
they are optional only for certain rows
in that table again depending on the
value of another column these three rows
must hold a value and that's typically
an indication that you have designed a
subtype inside a super-tight table also
for me that's a bad database design
subtypes should always spin off the
super-tight table with a one to one or
one to zero one relationship to be more
precise and only have those columns that
were optional in the original table but
now our mandatory in the new table and
the
we'll only have a row in that new table
when they apply for a certain row in the
super type table now
the first thing that I should have
started with number zero is you should
always choose your table and column
names wisely because they are the first
stepping stones in understanding your
database design yeah I I've been
involved in a couple of projects years
ago where tables had and columns had
totally meaningless names and that's a
that's a tough spot to be in
and let me put it that way now never
allow columns this is the last one
never allow nulls in columns that are
involved in what I call data integrity
constraints and I'm going to clarify
that a little bit more and that will
help me end up in a first code class
which I want to talk about when I say
the word data integrity constraints I
mean it in the broader sense of the
relational model of data not just the
constraints that we can currently do
declaratively in the sequel products
like oracle is that we have a we can do
check primary key unique key foreign key
but the sequel standard includes this
concept called a sequel assertion that
has the that offers you the opportunity
to specify or to declare any constraint
that you might have inside your database
design they are basically check
constraints that allow sub queries of
course we don't have sequel assertions
yet but I want to convey the concept of
a sequel assertion here so this this
this is a an example sequel assertion
select count star from amp where job is
president must be smaller than or equal
to one yeah we only allow no or just one
president in the employee table and your
typical OLTP database design will have
mold will have many of these constraints
that you can assert as a sequel surgeon
that you can declare as a sequel
assertion and you so so and the last
guideline is and all about whenever you
are able to assert a constraint in this
way
in your database design all the columns
referenced by these assertions must
always be mandatory for instance if I
have this assertion my rule is going to
say job cannot be nullable job must be
not know the reason why I'm doing that
is because you will you will end up
building code to maintain these at these
these sequel assertions and nulls are
always a dangerous dangerous thing to to
program they they always give rise to
books inside procedural code or inside
sequel statements etc so by ensuring
that all the sequel assertions all the
columns referenced by the sequel
assertions are always mandatory you you
end up in a situation where you can
easily with less effort built
maintaining code for these things now a
couple of you on this call already know
about this but out there in the Oracle
developer community site I haven't a
database idea if in case you haven't
voted yet we're thinking inside Oracle
of providing support for sequel searches
in the future release if you vote for it
the likelihood of us actually doing this
increases question for you Tony if I may
can hear me yes yes about that
recommendation never to involve knows
what was what has been over the years
over the many years your human
experience there did you find that oh my
god I've for reasons extending from the
business analysis ended up with a
nullabor column in such a constraint and
now I'm going to have to strain to get
rid of it or did you find that the mere
idea of expressing your constraints
coherently and refining them into sequel
assertions speak led to that result
naturally the the last one the last one
right so yes that kind of as I suspected
so this is not the piece of
recommendation that needs a lot of
effort to follow and you could almost
paraphrase it too
courses level really really think very
clearly you have about all the rules
that you're deducing from the business
world yes yes yeah yeah so so at a high
level it's it's not rocket science you
again third normal form
no incidental redundancies put separate
things in separate tables which is all
about subtyping and don't have columns
that have multiple meanings and then the
last one if you have sequel assertions
that involve other columns that are not
already involved in primary Keys check
losses or for peace make sure those are
also always not null now the point that
to make is a non-government coming to my
first code classification since your
databases I will have many of these
constraints you are going to have to
write code to enforce them an
enforcement is required to during
transactional API so whenever you change
the data you're going to have to think
about what are the insertions involved
in this transaction
what validation code should I write to
check if the transaction currently at
hand is allowed or not all code that you
write in this sense to me is what's
called data logic code this is what we
call within the smart DB paradigm data
logic code and that's a separate code
class there are different approaches how
to do data logic code in the throughout
the years we've seen people using table
triggers or having table api's and embed
validation code inside these table api's
or have all the validation code out in
different rule packages and have calls
to these rule packages from the table
api's or from other modules and there
are also various tricks around which
involve function based indexes or
materialized few tricks to to implement
certain subclasses of these sequel
assertions i'm not going to talk about
that that's for me that's at the moment
not interesting but the point that i
want to make is this blob I can now
split up in three areas
I have transactional business logic and
whenever and I'm going from the from
upwards down downwards to the table
whenever have I have transactional
business logic data logic code
the class that I just defined is also
involved and I have query only business
logic
I have query use cases that just produce
data to be displayed on a page or to be
given back to a rascal and those
obviously don't involve data logic
because they don't change data so the
the the the guidelines that we use
whenever we go smart to be is we are
trying to specify whether effort we can
declaratively it at the table levels the
primary keys unique keys foreign keys
check losses within constraints within
within rows and we want to treat this
thing called data logic logic separately
and your challenge here is to end up
with some way of dealing with this and
I've had a few ways of do out to deal
with this at the previous slide so make
sure that you don't repeat yourself
there's a big danger that you start
repeating yourself when you write data
logic codes because different
transactions might require the same
sequel assertions to be validated the
same constraints to be validated make
sure you do the validation code at a
single place in your PLC be code base
and if you do that then the
transactional basis logic what remains
as transactional business logic will be
a clean procedural code that does the
insert updates deletes may be with
embedded queries in it and that only has
error handling error handling in the
sense of whenever a data logic module
that you reference inside this business
logic module gives you the signal back
or raises an exception that something is
wrong you just have to handle that error
over here the query only business logic
that will just be procedural code PL
sequel with embedded have very likely
set based sequel statements and then at
the top we have our du jour technology
oracle jet apex those kinds of things
and in the middle we have the rest
enablement of the API layer and the API
layer is just the disclosing the modules
in the database that are actually the
top-level modules to be called from the
arcs
world now of course you will have
insight your transactional business
logic or in your query only business
logic you might have things that that
you code at more than once yeah and and
and coding more than once is always a
bad thing so you have to apply common
sense dry across this whole thing here
so whenever you see you can push
something down inside a shared view or
push some procedural logic down into a
function or a procedure please do so and
make sure that that logic is only
visible or programmed at one place and
and the the point the big point or my
personal experience has been whenever
you ensure that these yellow boxes are
separately visible inside your code base
either because you have them in a
separate schema or you have some naming
convention for these modules or whatever
whenever you make sure that those are
separately visible you will see that the
the real meat of your application that
these two these two things that you will
have to program will not end up being
spaghetti it will end up being
straightforward highly maintainable
procedural code with embedded SQL yeah
so again what I just said how do how do
we make this visible well we materialize
the code classification a thing that
brain already talked about a couple of
our session or the session before that
where we introduce preferably multiple
schemas to all these code glasses we
have we have of course we have to
connect schema at the boat at the top
that that actually doesn't have any
objects because it's used by the
connection pool to connect into the
database then we have the API schema
those are the empty empties packaged
procedures jackets on top of the actual
meat that are being granted to the
connect schema so that they are callable
from outside and then we have the code
schema that holds all the business logic
and the data logic I say and the data
logic here but let me make an another
remark about that in the next slide
and in and then we have a separate
storage schema that holds all the tables
and the declarative constraints and
again why would we want to do that it's
very simple separation of concerns as
soon as you start separating concerns
you start creating overview you have
different things in different schemas
and it helps you making everything more
maintainable also security wise we can
apply these privileges principle to
schema which which can be done in much
more detail than I'm talking here
because I'm only talking about it at a
very high level here visualizing this
the storage schema the business logic
schema the API objects and then the
connect schema where the connection pool
connects into now and you might say the
business logic schema only has the
business logic and we put today's the
logic schema in the table schema maybe
you choose to create yet another schema
in between here that has the data logic
schema to me actually if you ask me
honestly those are minor issues the big
point for me is make sure data and logic
code is separately visible and
separately maintainable you will have
constraints that change over time
wouldn't it be nice that you can go
straight to the package that has all the
code related to this at most one
president for instance or two this these
rows that have a begin and a start date
cannot overlap in this table type of
constraints so if you have that you
create a maintainable situation of your
code base and I have one last picture
here where I talked about how you might
think about also making sure that from a
maintenance point of view whenever you
have something in a page out there in
your application for the users that you
can very quickly find the code in the
database typically a page in your
application is part of of multiple flows
you can you can have a page and
depending on how you arrived at that
page different data is to be displayed
at this page the page can have multiple
buttons that going outwards signal
hardly call it
need to execute different types of
transactions so all code for a page for
me could be consolidated in a single
package a single package that has all
the render api's use cases stored
procedures package procedures and all
the package procedures for the process
api's and that the package name somehow
if you create a naming convention that
helps you match this package to a
certain page out there or that helps you
match this package to a certain rest
call or set of rest services that you
offer for a different application out
there that helps you to very quickly
drill down into your code base whenever
something is wrong with page X or
whenever something needs to change needs
to be changed on a certain rest endpoint
so naming conventions inside the
database in terms of your store PL
sequel modules is very important also
and of course we have the API the
coatless package on top of that now
again I talked about this issue
resolution and impact analysis helps a
lot whenever you make sure you have
thought about things like this and with
that that's that's the high level code
classification architecture that I
wanted to present in this third office
hour can I make just a little point you
often make it more explicitly but it's
nice to have a change of voices here go
back yes on that slide there
you mentioned impact analysis I think
it's some fair and indeed proper almost
and almost mandatory for tone and me to
talk in terms of always the latest
current technology I suppose that's 18
if we're going to be careful but for my
present purposes it's quite sufficient
to talk about Oracle database
twelve-point out that this feature
called PL scope lets you discover far
more about the objects that you or the
phenomena you reference in the world of
the data items the tables in their
columns than it used to do and this is
gold dust you can discover
by ordinary using use of sequel and by
packaging this up in your own bespoke
reports what code references what tables
for what purpose and at the next level
of granularity what code references what
columns in what tables and when I say
for what purpose I mean insert or update
or delete or or select and with that
information so readily available you can
so easily trace backwards come to you if
you if for some reason you've discovered
you need to increase the width of a
column because you'd miss analyze the
business world and now you realized the
present column is too narrow it's one
thing to change it but the other is to
discover the various places in your code
that needs to accommodate it now a lot
of the accommodation in the database
code can be self-healing I suppose in
many cases if you've used the style of
anchored declarations but beyond doubt
these things are going to emerge of
course into the user interface and this
use of peer scope as mentioned together
with the conventions that the tone has
been recognizing here gives you a
mechanized way of discovering in a
heartbeat which UI screens need to be
adjusted in response to this change and
surely that's a far better way of going
about things and simply thinking about
it or simply waiting until the bugs are
reported when screen n among a large
number of them happened not to get a
rewrite in in connection with this and
just a hammer a point that ability to
embrace all the relevant metadata that
determines this whole back-end data
related part of your application in one
simple mechanism where the data is
really really really available for the
mechanism to use or that's unique to the
smart database paradigm
yeah so now the questions I'm just gonna
read one out and not respond to it now
it comes from a friend hothead and
Barcelona and he is drawing attention to
the fact without saying if it's good or
bad that some applications and maybe
those who've drunk the kool-aid of the
in memory and are combining OLTP use
cases with various sorts of what you
might call data warehousing use cases in
the same database back-end and therefore
to some extent at least in the same code
base and he's wondering if we have
anything to say on that whatever we
might say on that I think that tone and
I would like to think about that and
defer answering that to a later time
well I can make a commit I can make a
short comment here because because this
this too is a question that that I've
seen earlier we had we had we make a
very specific statement about api's into
the database are all JSON in JSON out of
package stored procedures and this this
is based upon the fact that our context
are all tp'ed transactional business
applications now if you have inside the
OTP business applications you're using
the in-memory option to also cater for
analytics or bi type of query in from
third-party tools then for sure you must
have an opening into the database that
allows straight sequel queries because
that's what these tools do these these
tools use third party but we have them
ourselves also they they generate sequel
statements from within from from from
some metadata specification layers that
are configured in these tools and you
would have to allow sequel statements to
be submitted straight into the database
from these tools
surebut make make sure you do that via
separate a separate schema by a separate
schema that then only has access to
those tables that you want to be F that
you want to be X F FX s via these
third-party tools and strictly only read
access to yes yes
so don't reuse the don't reuse the the
connect schema used by the by the
connection pool in the Java tier for
that I have a separate schema configure
a separate screamer for these tools
any other questions Brinn I'm reading it
now there's comments but I haven't yet
seen another question your your friend
and mine Piet de Visser is talking about
using views in pursuit of exposing a
relation for outside of the database
generated query to use I guess in one
sense you already had that on a slide
earlier on I believe you said if you
find it useful to encapsulate some
frequently occurring query pattern well
by all means have at it and this is I
think beat only another example of that
same thinking so really be the deeper
question here is very much one of
taxonomy one of definition one of how we
use our terms and the question is often
put I always associate this with them
Philip salvus for work in Switzerland
does the smart DB paradigm allow the use
of views as part of the definition of
the API so the outside of the database
entities can get their queries at least
done that way and my answer would be as
a simple almost naive matter of deficit
definition no the smart NE
any term to use are most useful when
they have a crisp terse definition and I
would like to say that the smart DB
paradigm is definable it's definable at
two levels one is very very very
operationally and that's just that the
one or several connect schemas that are
exposed to give access to the database
within this paradigm are constructed by
the well-known mechanisms of what they
contain namely nothing and what
privileges are granted to them namely
only execute on other things that they
are constructed to allow only access
through a PL sequel API now that implies
a subtly different question which lies
behind what Pete just typed and that's
if a database is exposed to some clients
using this smart DB paradigm does that
mean that no other exposure at all is
allowed and it would seem to me that the
answer is no it doesn't mean that and
this bi case is an example where the
single corpus of data in the tables
that's ultimately the persisted reality
of the database might have another use
and provided especially now provided
that that use is query only then have at
it
by doing what toan said and exposing
things as views for outside of the
database sequel you do run various risks
namely that it's no longer one Authority
who's responsible for writing the sequel
and who stands for both its correctness
in the sense of giving with the results
that you're planing this statement of
what results you want to see Express and
in the sense of its performance
characteristics but if you're willing to
separate your concerns and share that
responsibility how about it but I think
we proved that we have to stick to tone
but you can comment if you disagree with
this way of putting it is that you can't
let go of the authority that makes
change
to the data that must be under the comes
of the control of a strips party B
paradigm as defined yes yes
so that would accommodate the huge class
of apex devotees out there who want to
talk about smart TV and who like a lot
of the ideas that you heard from tone
just now we would have to say to them
that your apex client as if we think of
it in that formally separated way has
two subsystems a query only subsystem
and data changing subsystem and our
recommendation would be that you use the
smart database paradigm absolutely
strictly non-negotiable no violations of
it in slightest iota for the data
changing subsystem and then take your
own decisions about how you satisfy the
query only requirements and if you think
beer is useful here how about it but
don't complicate our whole discussion
space by calling that a variant on the
smart DB paradigm rather it is what it
is can you live with that Pete out there
let me see a type tensor from you yes
speeds can live with it victory and we
have a question all the questions are
coming from that hotbed of intellectual
activity the Netherlands and now we've
gotten from Rob thunder burg and and he
says I you reckon can read it without
having pre-screened it are you
recommending to implement the table
triggers ah I'm going to answer this on
separate schemas and I'm simply going to
say there's a tension here you might
think that putting triggers who ought to
be very specific now you've got trigger
on T who is supposed to be created on
table T and certain concerns code
classification concerns might prompt you
to think that you should put on T in one
schema and T the table in a different
schema
well you'll find that if you want to do
that you can't unless you start giving
the owner of auntie some any privileges
and I would say that as in many cases in
life there's a tension here you can't
both have that cake and eat it and I
would say that if you want a stronger
principle even than the natural Bandhan
wanting to win the natural benefits that
using schemas for code classification
bring you and even stronger principle is
don't let a single any privilege into
your regime and the reason is sad but
true
it's that studies are shown and I'm not
going to get to go into the detail that
well-nigh any single any privileged no
matter what it is let's the devious
exploiter do a terribly tortuous and
mischievious series of escalations and
get to be DBA and more and the other sad
fact is that you simply cannot trust a
large number of people to know about
that thing
a simple regime is where you can get the
people who know how to log on to the
database with any user who's got a
single any privilege or more you can get
them all in one room and see him and
interrogate them you've got a hope
otherwise if you've just federated it
out and out and out and out you're just
out of luck and for that reason I would
say that you have to sacrifice the code
classification imperative there to avoid
using Enya's yeah Rob Rob also touches
on another very sensitive topic he has
transactional business logic between
parentheses when he talks about traders
we discussed I think we mentioned this
in an earlier session let's go go back a
little bit so so I I talked about using
I mentioned using triggers to implement
data logic
yes you can do that but it's very
difficult make sure you think about it
really good and and and make sure that
you have have a couple of people in your
development team who can do this for you
implementing data logic multirow
multi-table
crossing constraints using row level and
statement level table triggers the
essence of these triggers is that they
will only query data they will query
data to see what has changed and is this
allowed or not and they will then
optionally give a raise application
error to make sure that transactions
that violate the constraint don't
proceed now you can also have triggers
that have in them transactional business
logic that have in them embedded insert
update delete statements this is
considered to be bad practice it's a
sensitive topic I think the majority of
the of the PL sequel and sequel
community out there is in agreement with
me is that you should not do this
because whenever you do that you are
cascading logic whenever you insert into
a table something else fires namely the
transactional business logic that you
have in your table triggers they then
execute DML against other tables that
again may have transactional business
logic triggers that cascade even further
and before you know it you'll end up
with we
cascade of coat going off on a single
insert statement that you cannot that
there's very hard to deburr core to
maintain etc so for me I would never do
that and and I I agree with you brain
that if you use stable triggers to do
data logic yes you will have to put them
in the table schema because otherwise
you'd have to grant to create any
trigger privileged to another schema and
we don't we from from a security point
of view we we are very hesitant in in
allowing that and there's another
question waiting from yet another
acquaintance he's hi Simon here and but
before we get to that I'm just gonna
remind everyone in case you've forgotten
for even a microsecond that I have two
jobs here at Oracle not only am i PL
sequel product manager but I'm product
manager addition based redefinition and
he can't hear the word addition based
redefinition and know anything about it
before you immediately recite those
three things addition wait for it
auditioning view and it's coming now
what's the next one the next one of the
triumphant it is none other than the
cross addition trigger and I'm not going
to teach he BR now but I will just say
that cross addition triggers have the
special property in the world of EBR
that they're not a integral part of the
application when you come to do an e BR
exercise you work out what use cases
you're about to do need synchronization
and for those you design and implement
the cross addition triggers they sit
there for as long as you're doing the
patching and once you're over you whip
them away at the earliest opportunity
and the subtext there is that you need a
certain intellectual stamina and certain
background to be able to do EBR
successfully and there there is no
better alternative than the use of the
triggers and I don't want anyone to
think that has EB our product manager I
would disapprove of the use of cross
addition triggers of contrary it's the
only way of that use case being best but
that's a very very very special case
yes so now we've got got another sort of
verging on the academic question should
I read it out tone you can see it there
- um it says this is from nice and it
shouldn't views be an integral part of
the relational model so that some
entities as you would have them in the
pre physical world where you're just
drawing boxes and arrows and
understanding the business world so that
some entities are deployed as tables and
others as views which of course sit on
top of other tables or indeed other
views that's the question
yeah and the answer is of course yes I
mean but but to me this is going back to
the slide where I said apply common
sense dry if you have multiple use cases
and I'm gonna I'm going to use an
example in the empery Department
database if you have multiple use cases
where you always query empery data in
conjunction with the department name for
instance or put otherwise you are always
joining to dep know in order to get that
department name at the record level
where you have all the employee data
also then yes create a view that that
has that entity that extended employee
entity that retrieves the department
name already as a shared view at the
bottom on top of the table design to be
used by query business logic data logic
orbit or true business logic modules but
but of course it can be complex or also
if you have you have if you have an
entity that involves joining two tables
or maybe have a group by and some
aggregate aggregation going on by all
means create a view for that and make
sure that you have that definition that
entity definition which you apparently
want to have want to be able to use from
different spots defined in a single way
namely inside the view text yes and
that that whole discussion lets me just
refer to a twitter exchange that
suddenly sparked up into about 87 turns
or more in the course of a couple of
short hours maybe 10 days ago where many
let's say almost I would call them anti
smart TV merchants
people who believe that certain things
have to be done programmatically and the
only languages that allow those
programmatic things that need to be done
exists outside of the date database all
sorts of strange things were said for
example it was asserted that using the
Smart TV paradigm to the extent they
knew what they were saying prevents any
kind of reuse the use of sequel
fragments or things like that well
you've got you can't express what tone
just said you know in a tweet unless you
find a phonetic way of going booth but I
hope that at least everyone on this this
call having heard what tone explained
there is ready in person if not in
typing to counter such such peculiar
claims about the advantages of having
code outside of the database and
spraying atomic sequels into the
database bring and one thing I think is
guaranteed you'll meet people who who
tried to bend your ear to that story
telling and I do all the time I think
yeah and there probably are situations
or cases where you can create a better
modular solution outside the database
but these these are the rare cases and
by far in the majority of the cases you
are able to prevent duplication of code
inside your PLC code base either either
through views either through separate
shared functions or shared procedures or
maybe pipeline stable functions or there
are there are so many features inside
the database that help you deal with
with various issues where you may want
to prevent the duplicating code in the
database
yes I did type D and and and the yeah
well the point that I wanted to make but
I set it at the beginning is there mice
there might still be cases where you
cannot be 100% pure in this sense in the
dry sense don't repeat yourself sense
yeah okay so to me that's not an issue
to just discard smart to be all all all
all the way because there are some some
use cases that might not be done in a
pure sense from the dry world yes and it
boils down to almost sorry what the
discussion boils down down to is similar
to almost any discussion you have in any
exercise of software design and there
are pros and cons associated with any
design and you often come up with
competing designs and it's never the
case that one of them is absolutely
conferee and clearly therefore the
blindingly obvious alternative it's
always a balance that one is
overwhelmingly better because it has far
far far more pros than cons well we just
saw an example that with that would be
tension between the urge to distributes
code in different schemers to
materialize a classification ocean in a
very very tangible way on the one hand
and the disadvantage of needing any
triggers on the other and if you were
convinced really really really really
convinced that some programming
techniques that were uniquely available
outside of the database were a strong
Pro you'd still have to list up all the
cons that you took with you if you went
for that and if you're a matones talk
where he did the let's say code word
flame graph talk then you're giving up a
hell of a lot in performance and this is
where tone and I disagree slightly in
the moral space I get uncomfortable when
people lead with performance arguments I
much prefer leaving with correctness
documents and moppet but I'm happy that
one leads with one and another leads
with the other and and together we we
perhaps and get a message across but the
the the imperative must be for
correctness I
correctness has to come from I have said
many times the authority to fulfill your
responsibilities and that authority has
to be in some way materialized
concretize dinner in a whole scheme and
this is what the hard shell does it
gives her a war a barrier behind which
the authority is wielded and the minute
you do any code outside of the database
caveat with the reading use case that we
mentioned earlier but the minute you do
any code outside of the database that
issues data changing sequels straight
draw into the database well your
exercise would be now do it when this
call is over list up all the risks
you've exposed yourself to list up all
the Bears things that have suddenly gone
away from you in your armory and list up
all the human beings who have to be
involved in the tree of marketing of any
security breach that's discovered after
the fact so we are 53 minutes past the
hour and I'm waiting to see if any other
questions come in get typing out there
let me just have a quick review of the
number of attendees she has had a follow
up typing shouldn't I have you then be
exposed just as tables to the JavaScript
world I fail to understand the just like
tables to the JavaScript world because
we don't expose tables to the JavaScript
world so just like tables we don't
expose these views to the JavaScript
world we have Jason in Jason out api's
that bring back data from these tables
to the UI to the JavaScript world
I'd say that's the answer thing you
exposed them in the same way yes yes
exactly
oh if you worry where there are many
ways we could put this we may as well
use another minute to put it yet another
way it's a sad fact that Oracle database
and as far as I've come across no other
database uses a word which is the
super-tight word for table and view but
you know when you've typed the sequence
select statement to pick an example you
don't specify whether it's a table or
view in the from clause you just say
from my guy and these days with this
syntax simplifications that we have in
the latest 12 that guy could turn out to
be a PL sequel table function as well
all with the same notation if the
function had no parameters well for want
of a better word let's just call it a
relation so the question is should
relations be exposed out of the database
outside of the database for various
forms of sequel consumption and we
hammered that one to death earlier on we
said in the strict OLTP use case never
ever ever in this case where there's
some very ad hoc queering going to be
allowed and the only practical way to
allow it is by having hand types equal
or generated sequel coming in from
outside
well expose those relations and who
cares if their tables and views in the
first analysis expose those relations
through a dedicated connect schema of
course when you realize that the aim is
to allow them you select you soon
realize that if the relations you're
exposing were tables in that connect
schema well you wouldn't be preventing
insert unless you did some horrible
complicated malarkey that you didn't
want to do the simplest way to do is to
have the tables hidden and to expose
even if it's just a select star with no
restriction they exposed the table
through a view layer whose purpose is
not sequel reuse in any sense its
purpose is entirely as a stepping-stone
to allow the right privileges to be
granted
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>