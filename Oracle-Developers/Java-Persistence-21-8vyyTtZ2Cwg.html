<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Java Persistence 2.1 | Coder Coacher - Coaching Coders</title><meta content="Java Persistence 2.1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Java Persistence 2.1</b></h2><h5 class="post__date">2015-06-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8vyyTtZ2Cwg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everybody I'm Linda D'Amico I'm the
specification lead for the Java
persistence API we'll start this talk
sorry I'm gonna lose my voice at least
once during this talk we'll start this
talk with a standard Oracle disclaimer
this basically tells you that you
shouldn't trust anything I say as a
basis for making financial decisions so
what I want to do in this talk usually
I've given a talk on JPA at the last in
Oracle Java ones and what I usually do
is an overview of all the new features
and well that gets kind of superficial
once you've released an API that has a
lot of new features so what I'd like to
do instead is a very quick summary of
the new features in JP a21 and then I
want to spend the bulk of this talk
drilling down on a few of these in
particular the new features that we've
added in the last year since the public
draft of the JPA spec so we're gonna
drill down and look at some gotchas in a
few areas and then hopefully if there's
time at the end or you can catch me
afterwards I'd like to talk about where
we're going with the next Rev of JP a
mostly I'd like to get input from you
all as to where you think we should be
going what new features you would like
to see this API has largely been driven
by input from the community in terms of
how we prioritize what we add to JPA
ok so let's get going with a quick
summary of what's new or the new
features in the JPA 2 1 release when we
started this work we started in the
query area there was a fair amount of
infilling we needed to do we also wanted
to make sure that JP QL and the criteria
API were well aligned we had some
features in and JP QL that weren't in
the criteria API we had some
functionality in the criteria API that
wasn't a JP QL we wanted to make the two
more parallel I think we've achieved
that so what did we do
we added support for down casting and
what this is is when you have
relationships that are polymorphic and
particularly relationships and you want
to access subclass state because you
know you that what you're really
accessing is a subclass of the the
nominal type is that you need a
convenient way to do that so down
casting we stole the sequel treat as
syntax allows you to get it
subclass specific state in the criteria
API we had a little method that let you
escape to invoke vendor functions at the
JPA level or our database functions we
didn't have that in jpq else so we added
that ability to J pql so you can now if
you have a function in the database that
you need to invoke as part of your query
or if you have your vendor supports
something that we don't in a proprietary
way then you can do that we had outer
joins but our outer joins were a little
bit naive insofar as they didn't support
on conditions so we added support for
the use of on conditions in outer joints
both in the criteria API and in jpq l j
PQ l I think since the first release has
had support for bulk update and delete
operations but we didn't have those in
the criteria API so that was something
that we added to the criteria API to a
line on that we improved the result
mapping for native queries you can now
use constructor results for native query
results which we didn't have before
and we added support for dynamically to
find native named queries so you can
define a query dynamically attach a name
to it and register it with the entity
manager factory and then later in your
application you can pull that query back
and reuse it with different parameter
values or whatever so that's a way to
dynamically create a query you can treat
as a name query later on and one of the
things
one of the more major additions which
I'm going to talk about later is we
added support for stored procedure and
in the API okay so to switch over to the
runtime API is in the o.r mapping area
we've for quite a while had requests for
CDI injection into entity listeners that
was another feature that we added it's
the responsibility of the persistence
provider rather than the container to
ensure that this works works
appropriately so the persistence
provider is utilizing the CDI SP is to
make this work we had had previously
unwrapped methods that allowed you to
unwrap an enemy manager and drop down to
the persistence provider object that was
implementing that interface we added
that capability for the entity manager
Factory and for the cache API so if
there's something vendor specific that
you need to get at you now have a
standard way to do that we add a support
for converters and what these are
they're fairly simple - they're their
support for simple type mappings so that
you can convert between the database
representation and your entity level
representation and and back they work
for basic attributes it's not a terribly
sophisticated capability but it goes a
long way to helping smooth that
transition we also added support for
what we call unsynchronized persistence
context and I guess those of you who are
hibernate users are probably familiar
with a basic notion here with the
hibernate I think it's called flush mode
manual it lets you control when the
persistence unsynchronized persistence
context let you control when the
persistence context is responding to the
JTA transaction in progress so if it's
not synchronized with the transaction
and that transaction commits the
persistence context is not flush to the
database you have to join the
persistence context to the transaction
with a join transaction method
to have it respond to the J the JTA
transaction synchronization
notifications so what this gives you is
that it gives you a way to have
long-running conversations without
forcing a commit on an intermediate
phase so think your shopping cart where
you don't want to commit that shopping
cart to the database until the end and
the and the user says yes I want to
execute this transaction and and do the
purchase okay and any graphs I'm going
to talk about shortly this is another
significant feature that we added in the
last year schema generation I spoke
about schema generation in last year's
Java one we realized after that that we
could have done a better job in aligning
the the properties that control schema
generation the the did not seem as
intuitive in terms of what you submit it
when to make it happen so we did
somewhat of a shuffle there and I'll be
talking about the results of that
also the meted new metadata that we
introduced for schema generation for
indexes and foreign key constraints
indexes I think we made a minor tweak
foreign key constraint a metadata we
changed for the better in my opinion
okay so let's get going and drill down
on some of these controlling fetch so
before we launch into entity graphs
let's let's recap what we've done until
now in JP a in terms of the ability to
control fetch this is important
obviously because it can have a
significant impact on performance if you
fetch too much that you're not really
going to use then you've wasted all that
database access time if you fetch too
little at a time and you're going to
have to go back to your database for
more and again that's not good okay so
how do we control fetch up to now we
have actually
it's a fetched type eager and the
semantics are that if you have an
attribute of fetch type eager when
you're fetching the corresponding entity
the persistence provider has to fetch
that attribute that's a requirement on
the persistence provider if you
specified an attribute as fetch type
lazy on the other hand then that's
advice to the persistence provider that
you don't want that fetched now the
persistence provider in any case is
permit it to fetch that the persistence
provider can fetch more but not less and
we had the mechanism at the query level
of join fetch where again if you use a
joint fetch in your query the
persistence provider has to fetch that
related data but of course they may
fetch more okay so any graphs and any
graphs are a general-purpose mechanism
for defining an extent of entity state
through relationships and through
attributes so the obvious use case for
this is controlling what gets fetched
from the database and when it gets
fetched this has the indirect impact of
course in determining what's available
when an entity is detached from the
persistence context such as when you
might ship it over the wire to a client
ok so what's an entity graph you can
think of an entity graph as having a
root which is the entity on for which
this graph is defined every entity graph
is rooted on a particular entity type
and then the nodes of the graph
correspond to attributes of that entity
some of these attributes may in turn be
relationship valued in that case you can
recursively define a sub graph for those
managed types and I'll show you an
example shortly before we go any further
we need the notion of default fetched
graph which I'm going to abbreviate as
DF G in the examples so this is the
transitive closure of attributes that
are fetched tight
Iger namely and by default the
attributes that are fetched type eager
basic attributes embeddable z'
and the two one relationship attributes
so we have two notions of fetch graph
one that we call a fetch graph and the
other that we call a load graph these
differ somewhat in the extent of the
data that you bring back when you
specify that you want to use a graph as
a fetch graph or a load graph and the
way this works is you pass this graph to
the find or the query operation in
question and that determines the profile
of what gets brought back we had also
proposed and discussed that we use this
mechanism for what we called copy graphs
and merge graphs so when you want to
submit data to a client as an entity or
connected set of entities often you want
to control exactly how much gets exposed
to that client you may not want to
expose some of the data so the obvious
mechanism today to do this is through
the dao pattern but we wanted to do
something more convenient which would
allow you to declaratively or
dynamically specify what you want it in
terms of a copy graph and then knowing
that you had that copy graph you could
have a corresponding merge graph so when
you get back data from the client that
you want to merge back into the
persistence context you can use the
complimentary merge graph to merge what
you consider to be the appropriate
amount of that graph back into the
persistence context we proposed this it
was fairly late in the game and
unfortunately we couldn't reach
consensus and time in the expert groups
so we withdrew this feature we withdrew
the proposal for this feature but I
think it's something that I'd like to
consider in a future rebbe of the spec
okay so again a bit more detail here so
when you pass an entity graph as a fetch
graph
what gets fetched for all of these the
primary key inversion attributes are
always fetched when you fetch an entity
obviously you need this to keep track of
the entity and its relationship to the
data that's in the database but the
other attributes aren't necessarily
fetched unless you specify and again the
rule applies that the persistence
provider is permitted to fetch more but
is not permitted to fetch less okay so
if you specify an attribute in an
attribute node and you don't specify a
subgraph for that attribute then the
default fetch graph for the attributes
fetched if you do specify the attribute
in a sub graph then that attribute which
is going to be a managed type right it's
going to be it's going to be a
relationship type or it's going to be an
embeddable type a type where or it's
going to be an entity type or an
embeddable type where it makes sense to
actually specify a sub graph for the
attribute if you specify a sub graph for
the attribute then the attribute will be
fetched according to the sub graph so in
other words the sub graph plays a role
in giving you a more fine grained
control over exactly what gets fetched
rather than a default fetch graph when
you use an entity graph as a load graph
the situation somewhat different again
the primary key inversion are always
fetched if you specify the the attribute
in an attribute node then you fetch the
default fetch graph of that attribute if
you also specify the attribute in a sub
graph node then any attributes that you
specify by the sub graph are also
fetched so it's a way to augment the
fetch for the thing that's specified in
the sub graph okay all right so I want
to get to some examples what you need a
little bit more first so how do you
define these you can define these either
in metadata
through the named and any graph
annotation and you would apply this
annotation to the entity type that's
going to be
the root of your graph like everything
else you can do this in XML or you can
define the entity graph dynamically with
the create entity graph API and then
depending on how you want to use it you
specify it either with a fetch graph
property or the load graph property to
your entity manager or query operation
okay so let's deep dive through some
examples I'm gonna whip through this
stuff but and I'll show you graphically
what it looks like but let's first go
through the classes so customer has an
ID some properties like a name phone
address and it's got a couple of
collections orders and credit cards
address is an embeddable with the usual
stuff order has an order number the date
the orders place the address you're
going to ship it to get making use of
that address embeddable and it's got a
collection of line items usual pattern
for orders line item has a quantity
that's associated with it and it's got a
relationship to a product product has an
ID a name and a collection of suppliers
that would presumably supply that
product and credit cards got an ID info
about balance and limit and a
relationship to a bank so graphically it
looks something like this and you'll see
why I could never have a career in art
so the the errors are pointing to our
corresponding either to relationships or
a reference to an embeddable that's used
in that class okay so if we look at the
default fetch graph for customer what
does it look like it looks like the
stuff in red an ID name phone these were
all basic attributes address was an
embeddable and then we're taking the
transitive closure there so for address
all of these were basic attributes of
address orders and credit
cards by default as too many
relationships are lazy so they're not
included in the default fetch graph okay
so let's define a fetch graph now for
customer details and we'll do this
dynamically we want the name address
phone and credit cards to be fetched as
part of this entity graph so the way we
do this we start off with an entity
manager we're just injecting the entity
manager and then we create an entity
graph that's rooted in the class that's
going to be the root of this graph
namely customer and then then we're
adding the attribute note so this makes
use of varargs for convenience so we're
just simply adding these attribute nodes
now and then I'm scrolling away this
named entity graph which I have created
dynamically I'm registering it with the
entity manager Factory so later in my
application I instead of having to pass
this thing around I can just simply pull
it back and I'm registering it with the
name customer details with the entity
manager Factory the entity manager
factory also has a method not just to
retrieve this entity graph which would
be retrieved as immutable but a way to
retrieve a mutable entity graph based on
this entity graph that you can you can
then modify and perhaps refine for other
purposes in your application so and then
we're going to create a query just
simply fetching customers passing this
entity graph as a fetch graph to the
query operation so what happens what
happens is we get back this so I
specified those four attributes
including address and I didn't refine
address in a sub graph so address was
gonna bring back the default fetch graph
for address and I specified credit cards
in my sub graph so I'm going to get back
as well
the default fetch graph or rather I
didn't specify credit cards in my sub
graph I specified credit cards as an
attribute node so I'm going to get back
the default fetch graph of credit cards
so how would we do this with annotations
same example where we want the name name
address phone and credit cards okay so
here were naming the entity graph I
named it customer details you wouldn't
want to do this if you had already
defined a customer details named entity
graph dynamically it went to choose a
different name and I add the attribute
nodes now with annotations I'm using the
named attribute node annotation for each
of these attribute nodes so this has the
same semantics as before and I can use
this in the named query annotation that
I'm defining here and attaching to
customer as well so I named this query
details same query and I'm registering
this fetch graph by name as a query hint
for this named query so when I execute
the query
I'll get back the same data that I got
back before okay so I want to look at a
different example now so going back to
our graph in the next example I want to
pull back information about products
that the customer has ordered so to get
to product I have a fair amount of this
graph that needs to be traversed okay so
customer has the relationship to order
ordered a line item line item to product
okay so now I want to define an entity
graph for customer product orders I
start the same way I created an any
graph that's rooted on customer and now
I'm gonna add the named attribute node
that's about all that I really care
about with regard to the customer
information other than the customer ID
and I'm going to add a subgraph for
orders because I need to traverse two
orders and from orders and so on so I
need to get down to the attributes of
orders now as a convenience when you use
the add sub graph method you don't need
to call as we saw you don't need to add
an attribute node for that sub graph
with ad attribute nodes the ad sub graph
has the effect of adding an attribute
node for the orders and then from orders
from the sub graph from orders we're
going to add another sub graph for items
and then from items all we really are we
want to bring back is really the product
information so with this entity graph
I'm again passing it to a query with a a
fetch graph hint the hint is really a
requirement we kind of miss named that
that method this is what we get back we
get back the ID and name of customer and
orders and as we're traversing from
somewhere here I have a laser pointer as
we're traversing from order to line item
notice that I added the sub graph for
the sub graph for the line item I didn't
add any of this other information it's
not getting back we're not bringing it
back unless the provider chooses to and
then from line item we have the item ID
always and then product and then as you
go down to product we're fetching the
default fetch group of product okay what
does this look like in annotations it
looks somewhat different in annotations
and the reason it looks different in
annotations is that you can't take an
annotation type use that annotation type
and another annotation and then and then
recurse that way you have to basically
flatten out the structure so let's look
at how this works we're creating the
same graph customer product orders we're
adding the attribute node for name and
this time we're adding an attribute
node for orders with the subgraph for
orders now what's going on here so
orders disorders is the name of the node
this orders here this Dame is doing the
binding between the attribute node and
the subgraph named orders I could have
called this foo which might have been
clearer so this name here is just
basically doing binding within the
structure so the name subgraph for
orders we're bringing back the attribute
nodes for item and that's the only
attribute node we're specifying we're
bringing back and again to traverse we
need to specify we need to specify the
subgraph for items and link it using
this sub graph sub graph reference and
then finally within items we're just
bringing back the default fetch group
for a product so it was I thought I had
a picture there but I don't so this
brings back the same the same example of
the customer product orders graph ok one
final twist before we leave this topic
which is how do you deal yeah only a sub
graph yeah we we discussed that we
discussed that and decided that at least
certainly in this release that was too
complex and probably not a good practice
let me continue because we're going to
be really tight on time on this talk and
I want to make sure I get through things
and then you can ask me whatever you
want in the next half hour okay so to
look at an example for inheritance so
here we have a customer our customer
again same customer and we have a
preferred customer with some additional
state so if we specify an entity graph
on customer and our queries bringing
back preferred customers which it will
how do we specify what information of
those preferred customers we want to
bring back so the way to control this
is with another element of the entity
graph called sub class sub graphs which
lets you specify for those sub classes
the state that you're going to bring
back so this looks pretty much like
everything else the name of the sub
graph in case we have to in this case
we're actually not using this name the
type of the the sub type that we're
processing with this sub graph and then
the attribute nodes or perhaps even sub
graph information for the state of that
sub class so that starts getting a
little bit complex and annotations I
think the annotations are good to use if
you want to define all this statically
but I think the in my opinion the
dynamic AP is are somewhat more
intuitive and easier to use but again
we're kind of constrained with we're
pushing the envelope kind of in terms of
what you can really do here with
annotations in a user-friendly way okay
so this previous sub graph that I
specified with just level what would get
fetched what would get fetched is the
let me go back to my example make sure I
got it right yeah I did specify credit
cards so what gets fetched is all the
stuff in red including the default fetch
graph of of credit cards and then the
attribute that we specified in this sub
class sub graph namely the level okay I
want to switch topics stored procedures
was another area that that we address
this bits worthy in my opinion of a deep
dive this is an invocation not a
definition facility like like invoking
native queries they're not defining
you're not registering information in
the database that you're going to invoke
later on you're pulling back what's
already been stored there so this is
complicated by the lack of
standardization across
databases sequel isn't totally wonderful
in its standardization but compared to
stored procedures which are all over the
map with the various databases it looks
really good so what we did here we
modelled the JPA api's after what JDBC
supplies part of this was a necessity
part of it was JDBC is very flexible and
we wanted to capture that flexibility so
there are two aspects one of which is
the registration of information that the
persistence provider needs to know to
execute the stored procedure and bring
back the data in a suitable format and
then the other aspect is of course just
executing that stored procedure so the
registering of information again can be
either static through metadata with a
name stored procedure query annotation
and the associated metadata that goes
with that information about the
parameters whether they're in parameters
out parameters it out parameters and so
on and then the result set mapping if
you're bringing back a result set from
the stored procedure and again depending
on your database some databases support
that other databases don't dynamically
you would create the stored procedure
query with a create stored procedure
query method and then you have to
register information about the
parameters okay
so results stored procedure query
results again this depends on what the
database supports probably the most
common is passing results back from in
an out parameter so that's more limited
than having a result set an update count
like if you're doing a stored procedure
that's doing an update or a delete in
the database and result sets or with
some databases will support a
combination of all of these okay so
let's look at some examples
the sequel here corresponds to MySQL I
tested these out on MySQL so that's
that's what
that's what you get here so I'm creating
a procedure very simple I'm assuming I
have an employee table and my stored
procedure is getting the employee name
for a given employee ID and in this case
I have two parameters for the stored
procedure I've got an integer parameter
which I'm gonna pass it the employee ID
and I've got an out parameter which is
good to give me the the varchar'
corresponding to the employee name so to
do this dynamically I'm creating a
stored procedure query which I am naming
and sorry
a misspoke on that I'm creating a stored
procedure query that corresponds to the
name of this procedure and I'm
registering the the parameters the in
the in parameter which is the integer
corresponding to the ID and the out
parameter which I'm going to be
retrieving is a string corresponding to
corresponding to the name and then I
execute the stored procedure passing it
the parameter value that gets bound to
the ID
I'm calling the execute method and after
the stored procedure executes I can call
get output parameter value to get the
output of from the out parameter
okay returning an update count is
somewhat simpler so here are my
procedure is update salary and I'm gonna
give every employee a nice race so if
you're returning an update count this
will return the number of rows that were
updated so I just simply create that
stored procedure query it has no
parameters so there's nothing to
register there and I can call execute
update on it and get back an update
count from the execute update method
this is an example of returning a row
set get MPD's I'm selecting returning
results that
I'm selecting the M PI D and I'm
ordering ordering it in descending order
in my stored procedure and I just simply
create the stored procedure query I have
to with the results that I need to tell
it the class that I am expecting this is
going to correspond to the JDBC result
which is going to be the the row set and
I call get result list and I can process
it from there
so to do this with the named stored
procedure query annotation would look
something like this
there are two names going on here one is
the name that I'm going to use to access
this name stored procedure query the
other is the procedure name for the
thing that it corresponds to in the
database and then I need to specify with
a stored procedure parameter annotation
the information that I had supplied
dynamically before namely what are these
parameters are they in out and out and
what are the types of the parameters
okay that's the first query so that
corresponds to how we would do the first
query that I showed you with passing
results back from the parameters the
second one there's a lot less to
register I just need to register the
name that I'm going to use to invoke
this and then the procedure name the
stored procedure name as it is in the
database and there's no reason these
shouldn't be these shouldn't use the
same name they can use the same name and
then the third example in this one I
have get IDs as the name I'm going to
use for the named thing the stored
procedure in the database was get M PI
DS and then I'm specifying the result
class that I am expecting so a couple
awards about stored procedure execution
show so I showed you the the execute
method and the execute update method
execute is like the Swiss Army knife of
stored procedure executions depending on
what it returns it's telling you what
it's looking at
so if it returns true it means that the
thing that's there for you to retrieve
is a result set so you can retrieve it
in the obvious way with a get result
list or get single result and then you
call has more results to see if there's
anything else you should be retrieving
if execute returns false then then it
means that the result is either an
update count or the result is being
passed back through and out or out
parameters in this case you could call
get update count expecting that it might
be an update count get up the account
will return a negative one if there is
no update count in that case you're
assuming if you know that the result
could be passed back through the in out
parameters and to advance to the next
result with this paradigm you called has
more results and has more results will
return true or false
with the semantics that I just explained
for execute so it advances you to the
next thing that's there for portability
you should retrieve the results from the
in and out parameters last that's always
the best practice in the simplest case
which I showed earlier is where you just
have in and out parameters that one's
really easy and that is what I think
that the the bulk of bulk of databases
would be supporting this case there's a
limitation to our api's namely that you
may be getting back from a fairly
complex stored procedure you may be
getting back multiple result sets you
know you execute and then you advance
through has more results of them there's
another result set waiting for you
when you specify the shape of the thing
that you're expecting you either specify
result classes for those or results that
mappings but we don't provide the
ability to mix and match result classes
and result set mappings in this case
okay oops about to detach my mic schema
generation so this is the last major
topic I want to cover
we added metadata to support schema
generation the metadata that we had in
the o'er mapping metadata is was pretty
comprehensive but we were lacking
metadata for indexes and for foreign key
constraints so those were added in this
release index gives you the ability to
specify additional indexes beyond your
primary key index I know last year's
Java when somebody came up to me and
said well what if I you know what if I
want to name a primary key index and
what if I wanted to say something about
the column order in a compound primary
key index we can use this annotation for
that as well if you want to so notice
that the target of this is empty in the
annotation definition which means that
we're using it embedded in other
elements and the elements that we're
using it in the the annotation elements
that we're embedding it in are the table
oriented elements you know we had the
option of should this have been at
entity level but that gets you into
trouble
for example in the case where your
entity may really be spread across
different tables you may have secondary
tables for that entity so that really
didn't make sense indexes is a table at
the sequel level is a table specific is
a table specific item so here's an
example of the use of index using it in
the table annotation so here we're
creating an index for information in
orders and the columns that we're
including in this index or the foreign
key namely the which will be the
customer ID and the date of the order so
we may want this index for performance
purposes remember there's always
performance trade-off because you have
to worry about updating the index as you
create new orders and all of that so but
we're
adding this with the assumption that
this is important for performance the
other metadata that we added was foreign
key if you were at last year's Java one
this is different from what I presented
there we revamped this because we
thought there was a better way to do
what we had before this is another
annotation that again has it has an
empty target this is used within those
annotations that have joined columns or
that would logically specify foreign
keys so namely the join column family of
annotations as well as the table column
the table family column of annotate the
table family set of annotations and also
Association override which allows you to
control what you might have inherited so
the way this works you can assign a name
to your foreign key constraint by
default the the value of the constraint
mode is constraint and the reason we
chose this default is that if all you
want to say is at foreign key then that
makes it convenient for you if you don't
specify the foreign key definition then
what that would mean is that it would be
the persistence providers interpretation
of what it meant to supply a constraint
okay but it's still a shorthand so
here's how you might use it this is how
this was the simplest table annotation
that they used this foreign key foreign
key element now what I want to point out
here in collection table is collection
table has adjoining columns element
that's to specify the join back to the
parent table and join column as I said
before also contains a foreign key
metadata element so why am i adding
foreign key here as well so there are
two
if you have a non compound foreign key
to specify a foreign key constraint
within join column or at table level
obviously you only want to do that once
you don't want to specify two of them
your persistence provider may reject
your application if you do so but the
reason we needed to add this here is
again due to a limitation of annotations
if we had a compound compound foreign
key referencing a compound primary key
of the parent table we otherwise have no
way to specify the foreign key
constraint within that join column
annotation what will we do we pick one
of them we pick the other one of them
that didn't make any sense so we added
this at table level as well so if you
have a compound foreign key then you
would need to specify the constraint
using this ok so here's an example this
is using a simple fairly simple case I
have a collection table
I have items and I have a collection
table which is capturing pictures of
those items there's a name of the
picture and then there's the image
itself so here I'm saying I don't want
any I don't want a foreign key
constraint don't give me a foreign key
constraint okay that's pretty simple I
don't need to specify anything else here
here's an example of where I might want
to supply a foreign key definition in
this case same table I'm saying ok so I
want a foreign key constraint and
specifically the foreign key constraint
that I want is to do a delete cascade so
if the item is delete it then I'm going
to do a delete cascade on on the child
in general treat this with care
rightmost persistence providers are
pretty careful about how they handle
foreign key constraints and how they
interact with the rest of the
application so don't take too heavy a
hand here
okay so changes to schema generation we
want at this facility to be extremely
flexible all the way from the simple
case that you're just starting with the
set of entities and you want to persist
those entities in the database you don't
want to have to create the database
schema you just want to generate from
the object relational metadata to the
more and that's that's your typical
prototyping scenario you're just playing
around writing sample applications in a
production scenario you would most
likely have very carefully tuned the
structure of the data and you once
you've done that you want to preserve
you want to preserve that database
layout in terms of sequel DDL scripts
and you may also have sequel load
scripts so that you don't bear the cost
of you know starting with entities and
populating your database from the entity
level that would be very laborious so so
you can generate the database artifacts
on the basis of sequel DDL scripts you
can use schema generation to generate
directly into the database or you may
want to use it to just generate the
sequel DDL scripts tune those scripts
and then use those scripts to generate
into the database so that or you can do
both so the process is really very
flexible it's controlled by metadata and
set of runtime properties so these are
the properties you specify the action
that you want on the database so do you
want to create stuff in the database do
you want to drop tables in the database
if you don't specify database action in
a property somewhere nothing happens if
you do then you can generate into the
database from either metadata or scripts
or a combination of the two if you
specify the scripts then it will default
to scripts otherwise it defaults to the
metadata if you don't specify create
source
likewise for drop source
and why would you want a combination of
the two well maybe what's generated with
metadata is good enough but you want to
do a little bit of tuning with regard to
your script or you may just want to add
the the sequel load script if you're
using scripts then you need to specify
where those scripts are if you're doing
schema generation dynamically through
the entity manager factory api's you can
use a Java a reader here or you can
specify a string that corresponds to a
file URL if you're specifying this
information in your persistence XML file
then obviously you would just be
specifying the string that corresponds
to that file URL okay if you're
generating scripts things look pretty
much the same so you specify which
scripts you want to generate again this
will default to none if you specify you
want to generate scripts you have to
specify the target locations or nothing
gets generated so again you specify the
targets in the same way as we specified
before you'll use a Java I arrive if
you're doing this dynamically otherwise
a string that corresponds to a file URL
if you're doing schema generation into
scripts and you're not connected to a
database then the provider needs to know
what the target is so it can do the
appropriate sequel dialect that it that
it has to do for that database so in
that case we give you the ability to
specify the information the corresponds
to the what you would get back from JDBC
namely the product name for the database
and the version information for that
database so here's a simple example this
is in the persistence dot XML in this
case this is what you might specify if
you wanted to generate into scripts I've
specified the data base action as none
that's the default so that's a little
bit redundant here
I want to generate both drop and create
scripts and for the targets I've
specified targets on my local file
system if you want to generate from
scripts that need need to specify the
database action for this to take effect
you specify that you are generating from
scripts rather than the metadata that's
necessary piece two and then you need to
specify the source of those scripts in
this case these scripts are bundled in
the root of my persistence unit with a
names create sequel drops equal and load
sequel okay so that pretty much brings
this up to date we release this API back
in May if you'd like to see the various
discussions and the working documents
and all of that information everything
was done in a transparent manner using
the java.net java.net so we have a JP a
project on Java net you can see the
expert group archives there's a user's
list that's there for discussion and
feedback there's a juror that you can
use to report spec related bugs or API
related bugs for implementation bugs
you'd go to your persistence provider
site to report in to report bugs that
are related to the implementation and
feature request so if you have some
great new feature that you'd like to see
us add in a future release if you want
to discuss it with other people I
recommend that you use the mailing list
but at the same time log it into the
JIRA so that we can track it and then
it'll get some discussion there as well
if you do so please the more information
you can provide the better we've
actually seen some fairly concrete
proposals the reference implementations
eclipse link again another open source
project and of course that's included in
GlassFish so what's our roadmap the next
release of JPA will align with Java EE 8
if you're interested in Java EE 8 and
you want to talk to Java EE spec leads
were hosting a
spec lead off this afternoon right next
door at 4:30 and we're gathering feature
requests so feature requests again
either to the users list or to on the
JIRA or to me and I think I have like
5-10 minutes to hear what you guys think
in terms of where should we go let's get
rid of anybody got any requests yeah
sorry yeah let me see if I can get a
feedback discussion you can come talk to
me at the end I think there's some time
yeah yeah so this is a big question in
my mind because no sequel comes up and I
always say well which of the no sequels
should we address how do we do this what
should we do
do we want something that's as simple as
you know at entity and you can use
whatever piece of the query language
might happen to be supported or do we
really want to do something that's more
targeted at what a particular no sequel
database or flavor of database if we
want to say address key value stores or
document or how should we do this so I'd
like to hear from you all what do you
think know more seriously I mean this is
we would like feedback on this because
this this does come up no sequel
databases are getting much more
prevalent right should we start now
should we wait for more of a shakeout in
the industry
should we have like four flavors of API
should we have least common denominator
approach how how will we prioritize with
with regard to other features that we
might add because obviously our time as
an expert group is constrained our
implementation time is constrained where
does this rank in the prior
yeah well I can give you a density and
some you know minimalist query language
but that's not going to help you very
much yeah well maybe it'll help a little
bit for a certain subset but again I
mean part of the reason you're you drop
your presumably using a no sequel
database is because you have you know
either widely varying schemas or there's
some performance issue and to really get
the full performance out of that no
sequel database do you want a program at
the JPA level especially if JPA is very
vanilla or do you really want a program
with lower-level api's to that
particular database so we're looking for
information for input I should say
anybody else have a favorite feature
that's not no sequel or want to tell me
what they think we should do with no
sequel yeah
just to specify nodes oh wow you really
want that you want to use we can use the
metamodel API we could use the metamodel
api do you think a to use this okay okay
well that's something to think about
yeah thank you can you log that as a
request yeah with an example hopefully
yeah thank you yeah use that well we
have a treat as for jpq well we have a
treat as syntax which kind of mimics
what you do in sequel so you can you
know if you have products and you really
want to access the book specific
information from product then you say
the product range variable treatise book
like you would in sequel and the
criteria API there's a treat method yeah
I think that was in last year's slides
which are still there yeah yeah I'd have
to think about that yeah that just
didn't come up didn't come up first we
wanted it to look sequel ish in JP QL
and we could steal what was already
defined and in criteria API just looks
like criteria API yeah
yeah well what JDBC is bringing back as
its bringing back that row yeah I know
but we're actually getting back the
other the additional data well we're
getting back we're getting back
something that the runtime thinks is an
employee because that's all it can think
of it as it's not just thinking of it as
like one field I'm not yeah I'd like to
get you a better explanation but I'm not
sure I understand the underlying JDBC
mechanisms myself but I should blog this
I should get the details and blog it
yeah but I ran this on MySQL and that's
what you have to do anybody else okay
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>