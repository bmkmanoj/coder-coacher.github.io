<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Parallel Streams Workshop | Coder Coacher - Coaching Coders</title><meta content="Parallel Streams Workshop - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Parallel Streams Workshop</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/hSIhx_5CFj0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Stuart marks I work in a JDK
core libraries group at Oracle and this
is parallel streams workshop so I'm
calling this a workshop because I'm
gonna be showing a lot of examples and
NetBeans and showing you little programs
and running them so you can see the
results of running things in parallel I
observed this is the third session in a
row in this room on parallel streams so
we're doing them one after the other and
it's like why didn't they run them in
parallel it would have been much more
efficient all right so I'm gonna start
off with a very very brief recap of
streams and I'm hoping that you are
familiar with lambda and streams from
the other talks like my talk yesterday
or they're amid several other talks I'm
not gonna go into streams and lambda in
detail I'm gonna start from base level
understanding and go from there but I
wanted to reiterate a few fundamentals
here which is that stream is not a
collection it doesn't store its values
it doesn't store well I'd like to talk
about values not objects because objects
tends to imply a mutation there's a lot
of mutation going on in Java over its
history and so we kind of need to to
wean ourselves off of that so stream is
an abstraction that represents zero or
zero or more values that's what I like
to to think about streams so it's not a
collection oh it's not necessarily a
sequence sometimes people describe
stream as a sequence of values and you
know it's sort of is but it implies that
streams are ordered they often are but
they often are not and so I am going to
be spending a fair amount of time on
ordering in this talk today all right
pipe lines just to set up some
background here Stream pipeline consists
of a stream source zero or more
intermediate operations and a terminal
operation so you can see a very get that
out of the way very simple example of a
stream pipeline here so we have some
collection of some type turn it into a
stream run it through a filter and map
operation and then we collect it
somewhere presumably into another
collection somewhere although not
necessarily now I'm gonna talk about
what happens when you make a stream
parallel so there are a few more there a
few more calls on a variety of streams
so
like to turn a collection into a stream
you can call the stream method on it or
you can call the parallel stream method
that gets you a stream in parallel mode
there are also methods on the stream
interface called parallel and sequential
and so it allows you to switch modes if
necessary so there are a lot of there
are a lot of stream sources that start
off sequential so if you want to turn
them parallel then you can turn them
parallel you can and there no-ops if the
stream is already in that mode there is
a sequential call if you have a parallel
stream you can turn it back into
sequential I don't think I've ever
actually used that well one key point
here is that if you look at this code
fragment it seems like okay we'll start
off with a sequential stream filter
something turn it into a parallel stream
do a map in parallel and then turn it
back into a sequential stream and do the
collection sequentially that's not the
case actually it was the case during an
earlier evolution of the design but that
that was removed so really what happens
is that the way these method calls work
is that they chain up a data structure
that represents the stream and only when
the stream gets its terminal operation
does anything actually happen and in
that case the the parallel or sequential
mode in effect last is the one that wins
so in this case this is a completely
sequential stream so you cannot switch
parallel sequential modes in the middle
alright so you know we all love
parallelism we all have multi-core
machines so we just say well this is
great we just put in a parallel call and
it makes everything go faster right well
not right there are a lot of things to
consider when you think about parallel
streams and an overall goal is that if
you write a piece of code it should give
the same result in parallel or
sequential or or should it should give
the correct result and that's usually
the same result for a lot of problems
there's one result and you run it
sequentially if you if you if you run
something in parallel you get a
different answer
that ought to make you think a little
bit maybe it's the right answer but you
know if there's if there's one solution
to a problem and you run in parallel you
get a different solution that's quite
likely the wrong answer so so you have
to think about that more than you did in
sequential mode parallelism almost
inherently has non determinism in it
right so you spin off a bunch of threads
and they're doing work independently of
each other
so they do things at different times
they do things in different orders and
so there's some non determinism there
that's based on how the OS schedules the
threads what what garbage collection of
memory allocation is going on the GE VM
and a whole bunch of things and so it's
very easy to have race conditions data
races and so forth in your parallel
programs and if you're not careful non
determinism can lead to incorrect
results but as we'll see non determinism
might be okay now I am gonna spend a
fair amount of time on this notion of
encounter order if you look at the
streams documentation especially Java
util stream in the package doc there's
this whole section on a counter order
and quite frankly it's not explained
very well so I'm gonna spend some time
talking about that and in particular
encounter order is no I won't get ahead
of it there are a couple different
concepts here encounter order versus
processing order or just I'll dive into
the details in in a few moments there is
a lot of potential issues with stateful
operations in streams since your
potential since you have the potential
to run streams in parallel if you have a
stateful operation you need to think
about thread safety it's very easy to
forget that or it's yeah you need to
think about thread safety you also need
to think about order dependence right so
it's very easy to come up with something
that makes perfect sense and works
perfectly in sequential mode and you
turn it into parallel mode and you get
the totally wrong answer I have a bunch
of examples of that I want to spend some
time talking about accumulation and
reduction accumulation is something that
we're very used to basically you start
off with some result value that's
initialized and you just you know add
the
into it or combined so forth and in
sequential mode that's perfectly natural
it's something that we all we all grew
up with when we were or when we were
learning programming and we we kind of
need to get out of that mode that's
really a parallelism anti-pattern and so
I'm going to present reduction as an
alternative to accumulation
now reduction is not a cure-all for the
issues of accumulation you have to think
very hard about some subtle issues with
reduction in particular there's this
notion of identity and associativity of
operations and if you get those wrong
you will get the wrong results from
reduction so if you're careful you can
get good results out of reduction but
you have to be careful let's see like I
said earlier non determinism is inherent
in parallelism and depending on your
problem you can use non determinism to
your advantage to get results faster but
you have to be prepared to to deal with
it and finally there is I'm gonna finish
up with some some kind of empirical
thoughts about when to use parallel mode
when it speeds things up there's
overhead to it so it doesn't always
speed things up all right quick diagram
here sequential stream source couple
intermediate operate source couple
intermediate operations and then a
terminal operation if we run them in
parallel what happens is the source
workload gets split up and the
intermediate operations and potentially
the terminal operation or parts of the
terminal operation run in parallel but
in the end they're merged into some
result all right so let me talk about
ordering all right we have a fairly
simple stream here it starts off with a
range of integers and we're gonna filter
that for integers that are multiple of 5
and then convert that into a string
using map to object and collect the
results into a list so we have a list of
strings that's our output and so the top
half we run it in sequential mode at the
bottom half we run it in parallel mode
now what was I saying about non
determinism right in parallel mode this
rain this this range of integers will
get split up and all the threads will do
this
in parallel but somehow at the end the
result comes out in the right order
every time and in fact this this is this
is guaranteed by the API actually
confuse some people yesterday if you
were in my talk I did this with a for
each and things came out in a different
order and so you have to think hard
about ordering here and and the ordering
of whether the source has an inherent
order list has an order to it and this
is what we call encounter order so if
you have a list you have an element you
know element 0 comes before element 1
and it's not a list if that's not true
but but if you have a set the members of
a set or do not have any ordering
relationship to each other alright so
something's going on here where I'll
show this in a minute but take it on
faith on this slide when the threads are
running in parallel they are working on
these integers in some arbitrary order
yet when the thing gets reassembled the
result comes out in the right order so
how does this happen
so let me explain some things about
ordering here so let's say the the
orange the orange circles at the top
consider that to be our input list and
we want to do some processing over this
list in just just say we're going to do
a sequential algorithm now in this
diagram left and right are the position
in the list so so element 0 is way over
there are an element n or element n
minus 1 is at this end so left to right
is the positional the position in the
list or kind of a spatial ordering so I
like to think of this kind of ordering
it's called encounter order in the in
the documentation which is not a
particularly descriptive term that's the
term that's used so that's why I'm
telling you but I like to think of it as
spatial order because those elements are
to the left of those elements so we have
a left-to-right ordering so think about
that in terms of left to right now time
is proceeding downwards so we have one
thread who's operating on these and it's
going to step through these items
from left where I mean it's kind of
natural only to do it left right some
night sometimes you do it right to left
but let's say that this thread is gonna
do these operations in left right order
so it picks up the leftmost item does
something then and then in time order it
picks up the next one going right words
and then so you see there are two things
going on here we are progressing from
left to right and we are progressing
forwards in time and it's like so what
right this this is the way everything
works you go left or right button that's
going forward in time now the reason
this is significant is in parallel these
orders can be different and they are
different in general so we have a notion
of left-to-right order and that's our
spatial order or encounter order but
then there's the time order because
different threads are processing things
at different times and that is almost
certainly going to be in a different
time order than the left-to-right
spatial order and so you can see that
the the the threads potentially process
these things you know in some arbitrary
random and non-deterministic order if if
we were to I mean this isn't an actual
diagram but if it were and we ran the
thing again we'd get those operations
floating up and down in in different
you're in different times but the
streams framework is set up so that the
spatial order or the encounter order if
it's significant to the source that's
preserved through the pipeline through
most of the operations there's some
operations that will destroy the order
but but the simple ones like filter and
map they preserve encounter order from
the source through to the destination
but the processing order or the temporal
order can be arbitrary in a
multi-threaded system all right now I
want to show you how that actually
happens so I'm going to switch over to
NetBeans here so this is our this is a
code I showed on the slide and let me
just run this all right so that's that's
what we have here right we have you know
it's the same code and we get the the
multiples multiples of 5 divided by 5 we
get 0 through 9 great now what happens
we'll be running in parallel
so I'm gonna add a parallel call here
and run it again all right so we can run
this an arbitrary number of times and we
get zero through nine every time and
that's that's an effect of the streeams
framework preserving encounter order
through the pipeline but sort of hand
waving here well yeah things are
happening inside in a different order
how is that happening so I'm gonna try
to show you show you what order things
are what order things are happening in
so in order to do that I'm going to
create a let's see I'm going to create
an intermediate list here which I'm
going to pecan and then I'm gonna add a
peak operation here and so I'm gonna
take each string that's coming out of
the map I'm gonna add it to that list
oops and that should work so what
happens if I do this well same thing oh
I didn't print it out that's why
all right so let's try this again all
right so what we did was here let me
scroll this up a little what we did was
we put a peak operation in the middle of
the stream and that's adding into a list
the things that it goes by and notice
they're in a completely different order
and actually there's an element missing
here why is that well let's try it again
and see what happens okay we oh we got
all the elements this time but they're
in a different order again all right so
what ah
very okay that's what I was expecting so
we got a big ol exception stacktrace
array index out of bounds 1 all right so
I think a few of you have picked up on
this a little bit I did that on purpose
so I deliberately added a non
thread-safe data structure and
manipulated it from it within a parallel
stream which is exactly what I said that
you're not supposed to do and that's
what happens you saw well okay so so
there's ordering mixed in here but but
this is sort of a digression from that
we're manipulating a non thread-safe
data structure so we got missing
elements sometimes he seen nulls in the
middle of it and we got an exception
because one thread was reallocating
we're resizing the ArrayList while
another thread was trying to put
something into it okay right so let's
see so what what do we want to do here
so let's add this make make a
synchronize wrapper around it and run it
again
all right so that works and that should
work I can run it several times here so
we're always getting the right number of
elements and this is very very simple
thing here I put a synchronized wrapper
around the ArrayList and now multiple
threads in the Piku are in the peek
operation adding to this list but it's
synchronized now since I put a
synchronized wrapper so it's safe so
that the data structure is protecting
itself against corruption or throwing
unexpected exceptions okay but this is
okay so now back to ordering right so
the result here is that the order in
which things get processed by all the
different thread
is is arbitrary and completely different
so here it goes three 209 if I run it
again its to 409 you know and it's it's
almost unpredictable yet when we look at
the final output it comes back in the
same order and the reason is that the
the reassembly of the results is based
on position not on the order in which
the threads execute whoops that's not
you know want to see my calendar okay
okay all right so now we have ordering
behind us let's talk about accumulation
versus reduction so by accumulation I
mean this is a typical thing here and
this is you know you always have all
these toy examples for you know for
showing for showing programs but here
let's take a really simple task of
adding up all the numbers between 1 and
a million and you should be able to do
this if you're in your head if you're
Carl Gauss but that's the right result
there there's a famous story about the
mathematician it was able to do this do
this kind of arithmetic in his head when
he was a school child anyway so the
typical way to do this in you know
conventional pre Java 8 sequential code
is to have a for loop right to count
from 1 to million and repeatedly add
that number into an accumulation
variable which I'm calling quite
naturally some and then print it out at
the end ok pretty simple all right
actually I'll go right back to NetBeans
here
alright and here ok so I just called it
limit but otherwise this is the same we
get the same result every time all right
so now let's convert it to let's convert
it to a lambda oh well actually sorry
before I do that let's say we want to
run this in parallel right that's the
whole point of this you here for
parallelism so we could you know write
some fork/join code and submit this to
executor thread pool right but but the
you know one of the point I mean I'm not
gonna do that in front of you should
wage this way too complicated
right but the point of the parallel
stream stuff is like all you have to do
is add parallel right ok and and
everything should go faster but but it
doesn't work that way as you'll see but
first in order before we can make the
parallel call we have to convert this to
be a stream instead ok so let's start
off with our sum variable and so
actually so we want a long range no long
stream dot range from 1 to limit
probably want that to be range closed
okay and then we say for each and then
we're gonna take our well I'm still
using I even though it's a long I don't
like using an owl because it looks too
much like a one so we take i and then we
add it to some alright and then get rid
of our for loop oops
and the red squiggles don't go away well
why is that all right so I'm I'm I did
that on purpose again so what were what
this code is trying to do is modify a
captured local variable and so if you've
ever programmed with anonymous inner
classes whenever you use a local
variable form within an anonymous class
then you had to go back and make that
variable final and what that does is
tells you you can't modify it you can't
modify it either in the outer context or
even from the within the anonymous inner
class so the restriction with lambda
well in Java 8 yeah in Java 8 the
restriction with lambda is essentially
the same if you capture a local variable
you cannot modify it we've relaxed it a
little bit so you don't have to you
don't have to put final in it you can
capture its value but you cannot modify
it and in fact that relaxation applies
to anonymous inner classes as well in
that you don't have to put final if you
capture such a variable however the
restriction against mutating it is still
in place so so we have to think about
what were what we're what we're gonna do
here so we have a local variable but we
want to accumulate into it so let's
let's try harder so some people when
confronted with this problem think oh I
know I'm going to create a single
element array now they have two problems
so so what we can do though is we can
say take a long or create a long array
and make that be
okay so create a single element array
and put that in there and instead sum
into the array it's the first element of
the array and then why doesn't that
won't work oh thank you
ah okay very good all right so what
we're doing now is we're doing the same
accumulation except into zeroth element
of that array does anybody think this
will work okay you should be way ahead
of me well it does well it does because
you know we're running it sequential
mode so so what we've done is we've just
changed our accumulator variable all
right now but the point of this exercise
of converting into a stream is to run it
in parallel all right okay well I think
if you run this several times I'm not
gonna sit here and rerun until I get the
right answer right it's getting it's
getting a different wrong answer every
time all right so so clearly I means the
same thing again right all right so it's
it's it's the same thing but it's a
little bit subtle right this is it I see
this workaround all the time
oh those you know those Java guys they
have this restriction against mutating
local variables so we'll just we'll just
create an array but in doing so you buy
into a bag of hurt because a local
variable has a bunch of really
interesting properties that were that
we're so close to them that we're not
used to it right a local variable is
inherently thread safe because a single
local variable is visible only from a
single thread and if you know if a
different thread calls calls this method
or whatever it gets a different local
variable and since it's inherently
thread
you know confined to a thread the JIT
compiler can do all kinds of wonderful
things like say you know there's
actually no memory associated with it
because it can hoist it into a register
and do all kinds of register operations
and stuff and so we've just totally
broken that we've said okay we're gonna
throw away this notion of a local
variable create an array on the heap and
what's more we're gonna put it on the
heap and we're not going to put any
synchronization around it or anything or
even volatile
we're gonna have to do memory accesses
to get to it so it's threat unsafe and
it's it's creating memory traffic for us
so so this you know this is usually a
bad idea it's it's it's totally wrong
thing to do if you want to do parallel
programming so it's like all right so we
can't you can't make a synchronized
array and you can't make a volatile
array because none of those none of
those concurrency are constructs apply
to arrays so it would be nice if we had
an object that could contain contain our
long accumulator value because then once
it's an object then it has a monitor
lock on it and we can synchronize on it
we come and and so forth
and it turns out there is one in the
library already it's called atomic long
and the java.util concurrent package
this has been around for quite a while
it's been several releases this is not
new so you could well actually I'll just
show it here right so there's there's
wrappers for primitives in these this is
atomic int and atomic long and atomic
double probably so let's just change
this to atomic long I believe I have
this imported already so get that all
right so now we're running our long
range we're gonna run it in parallel and
we have to change this here so since the
atomic long is an object where you're
going have to call a method on it called
some dot and atom get and we're gonna
add I to it and then we're gonna print
out we're gonna print out the result
alright okay so now we have a parallel
stream that's accumulating into an
atomic long and we got the rate result
and in fact we are gonna get the right
result every time yay we're done wrong
there's still half an hour left in the
presentation alright so what's what's
the problem with this why is this keep
there we go alright so what's the
problem with this so I'm you're not
gonna put a million elves on the slide I
only have eight but if we accumulate
into an accumulation variable what
happens is they're all banging on the
same memory location and remember what
I'm saying about memory traffic before
that's gonna generate tons of memory
traffic all right so if you have a
sequential loop that's adding numbers in
registers that is very very very fast
and what atomic long means is that it's
doing atomic transactions it's doing an
ADD and get so it basically has to do a
read modify and then it has to do an
atomic write back in so it generates
memory traffic which is very slow
hundreds of cycles to go all the way out
to memory and you're doing it for
multiple threads so this is really slow
alright so actually somewhere later I
have some been ok actually after the
reduction examples I have some
benchmarks of this you can see how slow
it actually is all right so I'm gonna
present reduction as an alternative to
accumulation and so we're gonna take the
same range of only eight integers here
and the idea of reduction is instead of
taking things one at a time we're
thinking of the whole whole workload all
at once and it's kind of a group
operation on the whole thing so if you
want to add up a bunch of numbers you
just write them out it's like well what
is what is reducing over addition mean
just put a plus sign between each of
them and if you look at this there's no
reason that you have to add one and two
first and then three and then four and
then five and then six right so that's
our that's just the way our sequential
mode of thinking has taught us to do
things because it's there's how else are
you gonna do it but if you if you have
parallelism then you need to think about
things in a different
so is there a way to do this all at once
and indeed there is if you if you take
this range of numbers and then start
subdividing it down now you can do
pairwise addition in parallel so this is
only for pairwise additions that we can
do but we can do all of these in
parallel and so you can think oh if if
we if we have millions of elements and
we can we can split up the workload this
way we can do a bunch of stuff in
parallel and then as intermediate
results accumulate we can merge those in
parallel as well until we get down to
the bottom so what this does is it
allows us to get out of this and break
out of the sequential mode of thinking
which which accumulation is you know is
fully bound us into alright so now let
me go back to NetBeans here alright so
how would we do a reduction here so we
let's get let's get rid of this go back
to go back to here so what I'm gonna do
is just have the result of this be the
result of reducing it okay so now we
have a parallel stream of a range of
Long's and we do is the make the reduced
call and we're gonna start off with an
identity element which I will explain
later
and now we give it a reduction function
alright so what's a function for
addition I said do pairwise addition so
we can do take a right a right a lambda
that takes two arguments and adds them
together and so that's our sum so we
don't need this is not a object anymore
so we can get rid of that and we get the
right result now this is this is so
common in operation adding up a bunch of
numbers in fact there's there's a
special case there's a special case
method on here called sum which does the
obvious thing so I'll run that as well
and we got our right answer
does this go back to slide motor okay
all right so here the benchmark results
so I just stepped you through a bunch of
things right so we started off with a
straight sequential loop that just did a
for loop accumulating to a variable and
that's sequential and so this is this is
the results from a benchmark harness
called jmh that it's become very popular
it's it's quite a good benchmark for
some it spread good harness for creating
small benchmarks you have to learn to
read the results a little bit of course
they're a bunch of different ways to to
format the results but I like to I like
to have jmh proves its results in units
of operations per second and so higher
numbers mean it's faster so sometimes
people like to measure time and I find
that kaneen it's nice it's like oh okay
this took 500 nanoseconds and that's
that's easy to understand but then the
problem is if you make a change and it
takes 300 nanoseconds now you say things
like oh the performance went down to 300
well wait did the performance go up or
down right so the numbers are going down
when it's getting faster and that's
actually very confusing so what I like
actually like to do is do the reciprocal
of time which is workload per unit time
and so the score column is the one to
look at here and so we see that the and
the these are units of I actually
changed the limit to a hundred million
just so that we can get reasonable
workloads here and this is on my
five-year-old laptop which has two cores
so so this the actual numbers are
meaningless what's what's important here
is the relative numbers and so we're
establishing a baseline of integer
addition you know a large inner addition
integer addition workload and that is
you know it's getting this score of
eleven point six or so that's sequential
mode only but look at the numbers for
atomic even in well in sequential mode
that is what is that one fifteenth the
speed of the of the sequential loop and
that's just one thread
having to do memory creating memory
traffic
now if you run the atomic loops in
parallel you think okay well that'll
we'll gain something back from running
in a parallel but the threads are now
contending with each other over the same
memory location so we're so threads are
generating all this memory traffic but
they're contending with each other so
the way that Atomics work is there
there's no well it depends on the
processor but the typical way it works
is there's this notion of compare and
set where you optimistically store
something in and if the if the result is
not what you expected then you have to
back off and retry so that so it's not
really an atomic operation the sense of
it freezes everything let me do my thing
and then then unfree so it's not like a
synchronized block the atomic operations
are usually non-blocking but there their
assumption is that contention is
relatively low so they proceed
optimistically and retry if it fails and
so this is why a Tom you know the idea
of okay so I showed the pitfalls of
accumulation on unthread say things and
this shows why using it the atomic
variables is not a solution to this
because it just gets so much slower now
if you benchmark the reduction code the
even the even in sequential mode using
reduce or some you get comparable
performance and don't read too much into
these numbers there there are some their
arses the this is the error here you
know 0.179 and that's over is
interestingly the the error and this one
is higher you know maybe something was
going on in my machine but the
sequential loop the sequential reduction
and the sequential some call are all
more or less the same so the you know
once you have a large enough workload
the over there is additional overhead
for setting up a stream but what these
numbers are telling me is that it's it's
darkness it's pretty darn efficient for
large enough workloads now if you look
at the parallel reduction and the
parallel sum call you get you know 80 90
percent speed-up which is what you
expect on a two core machines so we're
we're making pretty good use of the two
cores
using the simple parallelism
all right now reduction is great it's
really good I threw that little identity
value in there and I wanted to talk
about that because there are some things
that can go wrong with it so the the
identity is the starting value okay so
if you partition down the reduction the
identity value is actually the starting
value for each partition after the
workload has been split up and it also
serves another purpose which is if if
you have zero values if you have an
empty stream then the identity actually
becomes the result now a key point here
is that you have to use the right
identity value and so for addition you
can take you can take some number and
you can add zero to it any number of
times and the number stays the same and
so we were doing a we were doing a
hands-on lab where somebody actually
used an identity value of one and he
kept getting the wrong answer
right so you so the first lesson is you
have to choose the right identity value
for the operation that you're that you
are performing now consider
multiplication what's the identity value
for multiplication it's 1 right so he
got confused there you know using the
wrong one right so I and I people make
the opposite mistake I saw somebody to
use 0 is the identity value for for
multiplication and it's like you know I
do this reduction and I get 0 all the
time why is that so so that's why you
have to choose the right identity value
the second thing is it must really be an
identity value so in Java we have
primitives which you know you can't
modify it's not like in Fortran you
could you can actually modify the global
constant 0 few old timers in the
audience but in Java we have objects and
lots of objects are mutable and so if
you use an object as of value you don't
want to mutate it because it might get
used in multiple places and and then
then very strange things happen so so
you want to treat it as a value all
right so let's go back to the reduction
implementation here and talk about the
partitioning right so so
so the previous diagram was something of
a simplification right so here if you
partition it down
notice that okay so this is the same
thing you split it up and then you do
the the pairwise addition in parallel
but notice that the identity value has
been thrown in at the at the bottom most
partition everywhere and there's no
obviously you know if you set things up
correctly then this does not change the
result because as we said it's the
identity value you can add 0 as many
times as you want and in fact if you if
you run this in a real system it will
get partitioned in different numbers of
time you know it'll get partitioned in
different ways in different numbers of
times so the number of zeros you're
adding in might differ from run to run
but that's ok because it's an identity
value all right so let's talk about this
here
all right let's demonstrate this ok so
here I have a simple string a simple
stream that takes starts off with a list
of strings which is some generic words
and just to make things a little more
visible I'm gonna wrap a pair of
parentheses around it
and then this is a simple reduction
operation now notice ok so the so here
you have to think about this a little
bit so the identity value for addition
it you know arithmetic integer addition
is 0
what's the identity value oh i what i'm
doing is i'm concatenating ok so this
plus actually since these are strings
this plus means string concatenation so
what is the identity value for string
concatenation it's the empty string so
you can concatenate the empty string is
many times as you like and the string
value does not change so let's let's see
the result of this ok so so this is it's
the sequence of words each wrapped by
parentheses pretty simple now what
happens if ok let's run it for
completeness we'll run it in parallel
actually I could say parallel stream
there but same thing alright so we get
the same result in parallel around a few
times get the same rate
every time now let me drop back into
sequential mode and put the wrong and
identity and see what happens so I'm
just gonna throw something else in there
just so you can see it so what happened
is we have sequential mode that started
off with the identity value which is
actually you know this this base string
and then it just kept concatenating
things to it so that's that's not too
that's that's not too surprising but
look at what happens if we run this in
parallel so you can see that the
identity value gets reused in a bunch of
times
and in fact this this split all the way
down so that every concatenation every
individual string got concatenate it
with the the identity that's so called
identity value so since it got since got
put there every time so you in in other
workloads or different sizes you might
you know the exes might or might not be
present in all places so this is not a
guaranteed result this is this is one
potential incorrect result what's that
why do you need the identity okay well
so for parallel for okay yeah so the
question was why do you need an identity
value right so so it goes back to that
slide I had which where it said that the
identity value got inserted when just
the way the the the the partitioning
gets done is if partitions it down to a
certain level and then it does is you
know you know under the covers it does
sequential accumulation but it has to
start off with something so the the zero
for integer addition is remember back in
the for loop we said long sum equals
zero that's the same identity there so
you have to initialize the the local
accumulator with something but what
you're doing is you're partitioning it
down into a bunch of different threads
and each of them needs to start off with
that identity value and then do their
their local accumulation and then in
parallel across the threads and then the
results are merged and then as I said
the identity is also used in case the
stream is empty if there's no identity
value you can you can get away without
that but then there's this thing called
optional which I don't cover here but
you have to basically optional tells you
that
no results so if you if you do a
reduction on an empty stream you get an
empty optional so question over here
oh okay difference what's the difference
between parallel and parallel stream
essentially nothing it's a shorthand on
a collection you can just say parallel
stream here it's a little shorthand I'm
just doing dot stream parallel just
because it makes it tiny bit easier to
add it but otherwise they're the same
all right so let's you have a parallel
stream with the wrong identity we want
to do here I know I'll just paste in the
code sort of having you watch me type in
okay so now I'm gonna take a leap of
your imagination here if you if you look
at this string concatenation is actually
fairly expensive because it's creating
new string objects all the time and some
people some people are concerned about
this and you know sometimes you you
write to be concerned about it so what
they what they'll say well if you're
doing lots of string manipulation in
mute mute that needs a lot of mutation
then the thing to do is to use string
builder and so here I've replaced that
code with okay so this sort of the same
thing we take us we take our string and
then what I do here is change this so
that this is a stream of string builders
so we take our so these are strings and
so we take a string and then we convert
it into a string builder at the same
time as we wrap the parentheses around
it and then we do our reduction operator
okay so our identity here is new string
builder with nothing in it so that's an
empty string builder and that works
because we get our you know we get our
words come you know wrapped in
parentheses concatenating correctly
mm-hmm
no I don't I don't want to I don't want
to go too far off the track here because
I have a bunch of other material to get
through we can talk about it afterwards
though sorry um yeah I'm gonna I got to
figure out where to post them cuz you
know I was working on them up until
yesterday so I haven't posted them yet
question was are the code samples gonna
be available so yes I'll try to make
them available all right so what I did
there is I change this into a parallel
stream and something really weird
happened and I actually don't know what
these what these squares are I think
they're I think there's zero there's
zero chars so so we're running a
parallel stream here but remember here's
our old friend mutation come back to
come back to haunt us where you started
off with a new string builder as the
identity but it's not really an identity
because you know what this does this
mutates it and so what we're doing is
we're taking the same object and we're
mutating it but we're reusing in a bunch
of different places and they're all
mutating it so basically and and
stringbuilder is not thread safe so you
know we're lucky we didn't get an
exception this time but instead we got
garbage characters in our output and you
know really really weird output so so
okay well it turns out there's a
counterpart to string builder which is
thread safe which is called string
buffer so let's change to use that all
right well we we got rid of all those
weird characters but with it still blew
up so what what's being illustrated here
is even though we're mutating it in a
thread safe fashion now mutating your
identity is a bad idea
because so instead of concatenating
concatenating things in a nice neat way
it's mutating its identity value which
is occurring multiple times in that
reduction tree and so it's you know sub
sub strings of intermediate results are
getting replicated a whole bunch of
times so this illustrates what happens
if you if you mutate your identity
object during a reduction no actually
this is identity no I'm okay so the
question was is identity the hashcode no
and so this this actually has nothing to
do with an object's hash code and
identity hash code I'm using identity in
a mathematical sense here right so if we
go back to addition the addition
operation has an identity value of zero
the multiplication operation has an
identity value of one and the string
concatenation operation has an identity
value of empty string so you can do you
can you you can do addition of 0 as many
times as you want you can concatenate
the empty strings many times as you want
without changing the result and so the
the the notion of reduction relies on
you having the proper identity value for
whatever operation you're doing all
right I better get back to the slides
here ok so now there's another this is
sort of elementary school arithmetic
here we have talked about the identity
value now we need to talk about
associativity and so we all learn at
least at least I learned in in in grade
school that addition you can group
addition in different ways and it does
not change the result and that means
it's associative woohoo
and they never told us why that was
important and so many years later many
years later we learn why it's important
because reduction relies on the
operation to be associative because
things get grouped differently right so
in in the accumulation example we added
things left to right in the reduction
example we group things in some
arbitrary way and combine them in some
arbitrary way and so if you don't have
an associative operation you're going to
get the wrong result so carefully chosen
in well actually I'll show you there's
what happens if if your operation is not
associative the key point here is that
the function you use in reduction must
be associative so here's the example of
that so here is string concatenation and
so we have a B and C if you concatenate
a and B first then C you get a result
if you concatenate B and C first
than a no notice we're not we're not
shuffling the order of them
that's commutativity that's something
different but instead this is
associative or associativity refers to
the grouping so we if we if we group
these differently we get the same result
and so it turns out well this is not a
proof of that this is an example you
have to you know if you really want to
prove that it's associated if you have
to do this for all about all input and
output values and they're probably ways
to do that but it turns out that string
concatenation is associative now here's
an example of a different string
concatenation operation where I actually
use one of the operands before hand
after and the result if you group them
differently the result is different so
this operation kind of a double string
concatenation is not associative all
right so let's go back to our code here
and see what happens when we when we do
this all right so here's our string
concatenation so basically this starts
off with just the letters a through J
and we concatenate them and so you get a
simple string a through J great now we
can run it in parallel and we get a
through J again right so that works
because this particular operation is
associative now I'm gonna change it to
this kind of you know double
concatenation and I'll run it in
sequential mode because that show that
actually gives the expected result so
what that does is here let me bring that
function up what what this does is it
takes the first operand and then it puts
the the second operand on either side of
it and so each time that gets added
you're sort of bracketing it so you
start in the middle a and then B then C
then so it expands outwards so so the
result is we get you know the alphabet
in reverse order in the middle and then
it goes back and forward order so this
is kind of what we expect from this but
if you run this in parallel
well so what happened is that you got
intermediate results that were combined
in a different way and so this function
is not associative so you get the wrong
result I mean it's basically a graphic
graphic depiction of what happens if you
choose the wrong the wrong kind of
function with which to use reduction all
right so I think I went over this before
this is just a summary use the right to
identity value make sure it's immutable
or if it's not strictly immutable make
sure you don't mutate it and you have to
use an associative reduction function
all right all right so I want to talk
about non determinism here there are two
streams operations fine first and find
any and you know we were talking about
this the other day and it occurred to me
that it's like what does first mean
remember back at the beginning of the
talk I said well there's encounter order
or spatial order and temporal order well
it turns out fine first means spatial
order now so if you send a bunch of
threads to do something fine first does
not mean it returns the first result
returned by one of the threads right
that's temporal order we're not
concerned with temporal or fine first
actually means first in spatial order or
in counter order now in parallel the
parallel threads can find a matching
element very quickly but they don't know
if it's the first one in spatial order
now there's another operation called
find ami which says to find any matching
element regardless of where it occurs
spatially so I have some diagrams that
that show how this works so the the the
gray bar here represents a workload and
the workload has one matching element
represented by the orange dot so if we
run fine first in sequential mode now
because everybody pay attention I have
some nice builds on I'm very proud of
all right so the thread runs and it
starts at the left and proceeds to the
right finds it great pretty pretty
straight
for what happens if we run fine first in
parallel that is we have two threads
I'll just assume we have two threads
all right so both threads start running
now turns out that the thread on the
right found a matching element but it
can't report it can't finish here
because there's this gap between where
the two threads have have not yet
searched and so if there's a solution
there then that would be the first one
not the one that the the right-hand
thread has found so the right-hand
thread has to wait for the left-hand
thread to complete and said ah since
that left hand thread didn't find one we
know that that one that one that got
found is is the result of fine first now
find any is is different yet again so
here I'm gonna run two threads and at
this point the right-hand thread found
it it's like okay great so we found a
solution this the semantics of find in
ER you know we need to find any solution
no matter where it is so it can report
as a result immediately and then
essentially it's a little more
complicated into this but essentially
that other threads can say okay you know
give up you can terminate early because
we found a solution already all right so
we can see this in the benchmark results
for a workload that is representative of
what was on the previous slide you can
see fine first sequentially takes a
certain amount of time or it runs at a
certain speed fine first in parallel is
faster because it it it does the same
amount of work but it does it in
parallel now find any in parallel is yet
again faster because it does less work
because it doesn't have to have the
restriction of finding the first in the
sense of leftmost solution so as soon as
it finds any solution it can return all
right all right so here's a different
example where there are two solutions in
the solution space so fine first
sequentially starts from the left and
I terminates when it finds it fine first
with two threads okay so it kind of
doesn't matter which one found it
earlier but the right suppose the
right-hand one found it earlier so it it
it found its solution earlier but it has
to wait and indeed the left-hand thread
found its left the the leftmost solution
and so that's the one that's returned
and the the potential result from the
right-hand thread was discarded now if
we run find any with two threads than
depending on the the threads are racing
now so let me let me do that again
the left hand thread found its solution
first so that's the one that we earlier
the left hand one found its solution
earlier so that one's returned but in
this one the right hand thread found its
solution earlier so that one is returned
instead so find any might return
different results every time if there
are multiple results in the search space
all right so I'm gonna skip over this
demo since I'm running it was basically
some code that showed that but I think
you can believe if you search a space
with find any run at a bunch of times if
there are multiple solutions you might
get different solutions when running
parallel all right a few wrap-up
conceptual things here where are the
threads we've been talking about threads
a lot no we're not creating any threads
they're not we're not even doing any
thread pools or executives or anything
like that so the threads are actually
behind behind the parallel call there's
some infrastructure which uses what's
called the common fork/join pool and
fork/join pool Fork joint for joint
pools were introduced in Java seven and
you had to manipulate them manually and
so by default when you run a parallel
stream it does its work in the common
fork/join pool which is essentially a
JVM global fork/join pool now the the
reason you might want to do this is you
can imagine a whole bunch of different
code all over the place if every piece
of code created its own thread pool as
people want to do then you might have a
bunch of different
things parallel going on in parallel all
those thread pools would would be sized
according to whatever that programmer
thought was the right number of threads
and basically you wouldn't have any
control over over the you know the
amount of CPU that that that the
workload would take so consider for
instance running multiple threads in a
parallel stream inside of an application
server you would want the application
server administrator to be able to
configure the size of the fork/join pool
so that's why it's a global centralized
resource that should be administered
centrally instead of appearing in the
API and having the programmer say oh
okay I want this to run with four
threads or you know n processors or
whatever so we do there the problem is
like I have that example of a Java EE
container that would need to use some
policy api's for sizing things and those
don't exist yet so we do have some more
work to do but but the obvious thing of
putting the number of threads or putting
a fork/join pool argument into the
parallel call is probably not the right
thing to do all right when to go
parallel there's a bit of hand waving
here but there's a bunch of trade-offs
Doug Lee I have a I have a link to this
on the next Lara subsequent slide Doug
Lee has written a nice essay about this
with help from some of the so that other
concurrent Java folks first thing to
realize is that when you run something
in parallel there is a start up overhead
and so you know on today's systems with
modern JVM etc it's 100 microsystem 100
microseconds so if your workload is
shorter than 100 microseconds
just forget doing it in parallel because
you know if you run sequentially it's
gonna be done before even the parallel
threads actually get their tasks now
there's this n times Q thing and it's
it's quite empirical but the idea is
there's a trade-off here depending on
the number of elements in your workload
and how expensive each is the process so
and Q is the sort of weird thing you can
argue about what units it has or should
have but it's sort of you know as a rule
of thumb you say let's take a really
cheap operation like integer addition
at ten thousand is about where the
crossover point is so if you have an
array that's shorter than ten thousand
it's not worth processing them in
parallel but if it's longer than you can
get a parallel speed-up now there's some
more complicated mathematical operations
that that use floating point and square
roots and stuff I have a couple examples
here
empirically I've measured the crossover
point and you know 3d Cartesian distance
the queue is about seven right so that
means that you know ten thousand divided
by seven which is 115 hundred or so so
that means we get a parallel start
getting parallel speed-up if we have
more than fifteen hundred elements but
this is all very empirical and the thing
is measure your workload and see if you
can get it if you get a parallel
speed-up you might or you might not
measuring performance I could spend a
half an hour talking about this jmh is a
great benchmark harness I recommend
using it don't write your own because if
you write your own you're probably going
to make some mistakes and the JIT
compiler is going to out with you and
you're not going to get valid
measurements okay so I'm really out of
time here so the API makes it really
easy to write parallel streams but
there's a lot that you have to think
about you have to think about avoiding
accumulation thinking about reduction
you have to get the right identity value
you have to make sure your reduction
function is associative and the slogan
is measure don't guess so be careful
when you're measuring this stuff and you
might get a speed-up and you might not
and the only way to find out is to
measure you can't say oh well this blah
blah blah blah blah parallel makes it
faster
you really have to measure so let me put
up a page of links and I think I'm
pretty much out of time but I will be
around the conference and you can ask me
questions if you see me wandering around
the halls thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>