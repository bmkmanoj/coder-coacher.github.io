<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>JSR 236: Introduction to Concurrency Utilities for Java EE 1.0 | Coder Coacher - Coaching Coders</title><meta content="JSR 236: Introduction to Concurrency Utilities for Java EE 1.0 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>JSR 236: Introduction to Concurrency Utilities for Java EE 1.0</b></h2><h5 class="post__date">2015-06-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-aYTcsMOP3g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so welcome today we're going to
give introductions to Java concurrency
utilities my name is Anthony lie I am
the spec list for chairs out 236 and
this is Fred I want you give
introduction I work for IBM and
WebSphere architect for the number of
complainants one of which is KS or 236
and 20 patients since the time we are
first going to give an overview to the
introductions of what the goals are for
this concurrency utilities for Java EE
and and then we will go through all the
managed objects on the is going to
provide and then we will talk about some
features that that is specifications
provides before we go into summary and
funnels of resources so first of all I'm
going to talk about cause it was distant
and fixed way
technical difficulties
just a position
Thank You straining okay so here are the
cause of the concurrency utilities for
Java EE is to provide a simple and
flexible standard API for application
commitment providers to design
applications using concurrency design
principles and to provide simple
migration paths from a Java SE
concurrency utilities to the Java EE
platform by providing consistency
between the two platforms and also allow
application component providers to
easily add concurrency to existing Java
EE applications and also we want to
support simple and advanced concurrency
patterns without sacrificing we still
values abilities so let's go through a
brief history of this jsr as you can see
this a long history okay it started when
just our 236 and Jess are 237 were filed
in 2000 2003 case up to 36 was
originally called the common j timers
API for application servers and J's our
237th was originated having difficultly
work manager API for application servers
and then in 2006 when the Java SE
concurrency utilities which you suggest
are 160 days come out and this common
J's API were replaced and be written to
be more in line with the Java SE
concurrent package and then in 2008 the
two years our merchants do dress up to
36 but then arm nothing really happened
since then and here we restarted the
Jess our last year and then we make some
progress and finally made it to released
and it becomes part of the Java EE 7
platform
so here the some high-level main
features as this utilities from a
concurrency GUI provides it provides a
simple centralized API for using
concurrency from application components
so the Java EE applications can use Java
as to be like API token currencies and
the api's are mainly extensions of the
concurrent package in the java SE and it
provides a lower-level asynchronous
processing capabilities in Java EE
applications in a safe reliable
consistent manner and it provides our
management and monitoring capabilities
for the lifecycle of asynchronous
requests so more specifically on the
spec provides four types of managed
objects which implements the following
interfaces they are managed executor
service managed schedule executor
service manager Factory and contact
service
so all these interfaces are defined in
the new Java X Enterprise concurrent
package we also and the spec also
defines behaviors such as how container
contest publications will behave and how
transaction management would work in
those a synchronous tasks we also
provide a mechanism and API basically
for receiving lifecycles events
notifications for the synchronous tasks
so we're going on to move on to talk
about all of the managed objects so
alleged objects they are provided by the
Java EE server and they implement one of
the four interfaces that we just
mentioned and applications components
can reference these mesh objects they're
provided by Java you need containers the
way they do it is in the code they can
do it and you look up or they can get
reference of these mesh objects through
resource ingestion using the resource
annotation and these objects are
configurable meaning that there can be
multiple instances of these objects can
be configured in ways that are provided
by each Java EE server probably through
some interfaces or command line or even
XML files and we in the spec doesn't
mandate what kind of configuration
properties are required for each of
these managed objects so each each
vendor the travel offender can provide
the hallways of consecrating these
objects but the spec you meant maintains
that there's pre-configured default
objects that should be provided to all
applications and one of these different
object will be created for each of these
four types of many objects and they are
they they all have to be received from
the standard ANTM names for example if
you want to get the default measure P
for manage that for actually an object
you will go to this our Java
: come slash rethought manage my factory
change the name to look it up or if you
have a using resource ingestion if your
resource annotation doesn't provide a
lookup name
then the default instance will be
provided to your applications so I'm
going to turn it over to Fred we're
going to walk us through the four types
of mesh objects
so thanks to everyone for coming a lot
of people in here for the last day after
lunch that's a good thing and as Anthony
mentioned this has seems to have been
the longest running expect in jeaious or
history but anyway so let's look at the
types of managed objects that are
provided by GS or 236 first one we're
going to talk about is the managed
straight factory and the ministery
factory is a way for applications to get
a container managed thread in a magnet
in a way that is safe and will be
managed by the container the threats of
that thread factory will be
contextualized we'll talk about
contextualization and what it means to a
thread or to a task threads from the
factory can be used with 4 async
processing and servlets in async methods
in Egypt bees or just general logic that
you have within your application so the
one of the things that Anthony mentioned
with the history of the KSR 236 was it
originally we were using the common j AP
I don't know if you guys are familiar
with that but at some point when the
Java SE implementation picked up
concurrency utils we changed the api's
so that they basically if you're used to
using the standard SE api's these should
look very familiar to you with a few
caveats which we'll try to point out as
we go along and because of that
typically what you'll find is word
managed in front of the same entity that
exists in the SE packages so in this
case the bandits thread factory or I'll
say MTF going forwards because
eventually these names become really
long hard to say
so the ministered factory simply extends
the third factory that's in the SE
concurrent package has the same API as a
single method that can be used to get a
new thread passing it or runable the
context of the application that's
running that creates this thread Factory
is going to be captured at the time that
the thread factory is created and all
threads produced by that factory you're
going to have that context we'll
continue to talk about context more and
more but just in brief if you think
about how the containers the web
container the EJB container within an
application server worked when your
application is running you have
resources that are made available to you
by the container things like the jinda
namespace security context the class
loading context those are all things
that your application can make use of
that are set up and managed by the
container
similarly this threads coming from this
manage thread factory will have that
context applied to them so that your
task will have a context that is similar
to that the same as the context of the
application of your application that's
submitting that task threads that
they're returned by that method will
implement the manageable thread
interface this allows you to query and
see is the thread being shut down as the
thread factory being shut down perhaps
the either the
application itself is going away because
it was uninstalled or whatever reason or
the application server itself is being
shut down
in which case is shut down which it
shouldn't return true so turn looking a
little bit more into shutdown so the
threads up from the factory will be
interrupted when the MTF shuts down and
the runnable which we saw was passed to
the new thread called
your runnable shouldn't look and say
well is this I got interrupted why did I
get erupted in am I being shut down and
if so then you should clean up and be
prepared to exit looking at an example
of how you could use a managed thread
factory you see that we make use of the
at resource annotation that Anthony
mentioned he also mentioned that there
were default instances of the for
managed object types specified in the
spec so the server the application
server this is possible for creating at
least a default instance of each of them
and has created a default manage thread
Factory and that will be injected by the
app resource annotation in this class
and then we make use of that thread
manage thread factory to create a new
thread pool executors and once again if
we're familiar with the sae concurrency
packages a the same a managed thread
factory can be passed to anything that
will accept a thread factory assuming
that someone hasn't done a poor job of
implementing the any of the executors
and another example so here's an example
with an asynchronous servlet erasing
servlet again we inject the manage
thread Factory into the servlet via that
resource and as I mentioned because the
resource is injected within the servlet
it's going to have threads created from
that thread factory are going to have
the context the application context that
was present at the in the servlet at
that time so any whatever work you do on
those threads will have be able to see
that application context in this case
pretty simple and are do get we create a
async context which is a construct for
doing a synchronous servlets and we pass
that as a runnable to our new thread and
a call on the manage thread factory and
get a thread back in started running any
questions about the MTA it's the next
managed object that we wanted to talk
about was the managed executive service
or mes it's used for running tasks
asynchrony asynchronously on threads
that are provided by the application
server this thread those tasks will need
to implement either run the ball or
callable tasks will just just like the
manage thread Factory the tasks will get
the context of the application per
forget it to them and we use the same
api's in the managed executor service as
we do in as you'll find in the SI
version of the executor service which
means that we simply extend from the
executor service interface and provide
methods or execute submit invoke all
invoke any no there's no additional
api's that
manners executor service so if you're
familiar with the concurrent concurrency
package in SC you'll know that execute
can be used to submit a task for walk at
some point in the future it doesn't you
don't tell the executor when to do it
you just simply say please do this and
you get no result back from it you
simply go off and do whatever you need
to do submit is a little more complex a
little more has a little more capability
it submits work and returns a future
object that allows you to do a couple of
things one you can look and say has this
task completed execution yet what's the
status of it and use it to actually
access the results of the your task
which is when you when you finally
execute when you finally use the future
to get the results well if the task
hasn't executed it will wait until the
task does complete execution just like
in Java SE one thing that is different
from that I told you we would point out
differences between the SA versions in
the EE versions you may not call any of
the lifecycle methods one and mes doing
so will result in the illegal state
exception because the server is
providing these mes is to you and it's
managing the lifecycle of them not the
application
so let's look at some examples of how
you might use a mes in this case again
default instance is created by the
application servers required by the spec
and we inject it using that resource
annotation we then later submit that to
the managed submit a task which we have
written as the sum method we say that we
have a callable and of course the call
method implemented on that for our task
then we submit that callable to the
managed executor we get a result back
via the future I talked about and then
at some point in time later we call get
on that result and get the value or wait
for the value to be wait for the task to
complete and return the value a similar
example to the manage stripe Factory for
using a mes with the async servlet we
inject the default instance of the
managed executor service via that
resource annotation we created a basic
context for the start want to do
asynchronous processing we implement
that as a runnable and then we pass that
runnable to the manage executor service
speed of this subnet in this example we
probably could have used the execute
method because if you look we're not
making any use of the future that was
returned and that's a good sign that you
don't really care about the results you
simply want to execute something
there any questions about the managers
executive service up to this point so
this is a diagram to try to help explain
what it looks like on the server side
these are all ap is that your
application makes you so but what does
it look like for a application server
vendor to implement this on the right
hand side we have three EE applications
app a B and C which are all wanting to
submit asynchronous tasks for execution
by the server those tasks are the blue
squares on the right-hand side and those
submissions are queued up by the
executor on the server and in order to
service thank you the server will
typically and this is implementation
detail and varies from vendor to vendor
but would typically have a thread pool
underneath with a set of worker threads
that run from the minimum amount of
threads configured in the pool to the
maximum and as workers become available
that they would be taken out of the
thread pool and work items in the queue
would be run on those threads with the
context of the application which
submitted it so you can see in the
legend that the you have bare worker
threads which are the greyish cubes and
then you have contextualized tasks which
have a blue and white square inside of
them
and then surrounding all them is the
actual application which submitted that
task so you can see that in the third
poll there is one to three tasks being
executed by application a1 by FB
and three biopsy and there are three
queued up the diagram doesn't indicate
what application submitted those however
so there any questions about what what
might what happens behind the scene on
the application server side so the
question was why do you leave the queue
and what was the the rush of it so if
you didn't have a queue and you don't
have to that it is really up to how the
vendor wants to implement the spec
doesn't specify that if you don't have
the queue then you don't have any easy
way or also easy you don't have a
convenient way to as multiple apps are
trying to submit work it becomes single
threaded to actually submit it to the
thread pad because a work you're having
to wait for a sub thread pool to return
a useable thread which could be any
length of time you could be waiting for
one to become available or simply just
the actor that returning an available
one your everything has to wait while
that task is being submitted by using a
queue you can submit multiple you know
there's yes
from an MDB I'd have to think about that
for a minute
you know I'll go on and I'll come back
to that if not during the session after
the session I'll talk to you about it
any other questions so the next manager
object once again has a managed schedule
of executor service it is familiar to
anybody that she's the SAE concurrency
package and that it's the scheduled
executor service from that just made for
use in the EE managed environment it's
used for scheduling tasks to run after a
given delay periodically or which is
different from the SAE version at some
custom schedule it was recognized by the
S or to 36 expert group that one of the
things that would be nice was to be have
a little more flexibility in scheduling
that he didn't have an se begin the
tasks that are submitted we're going to
be contextualized you by the container
with the application context and anybody
that's used to using se should recognize
the methods on mes with the exception of
a couple additions we'll talk about so
the API of it is extended directly from
the scheduled executor service so it has
the schedule scheduled at fixed rate and
schedule would fix the way methods just
like the SE version
the similar to the management executive
service applications cannot call
lifecycle methods one the manage
scheduled executor service doing so was
all in a exception and again there's a
custom API added to the managed version
of the scheduled executor service to
support custom scheduling and it uses a
interface called the trigger which we'll
see in a minute so here's the API that
we get from the scheduled executive
service the SAE version you'll see that
the scheduled method can be called with
either a callable
or a runnable that that's your task that
you implement and that's the task which
we're going to contextualise with the
application context when the task ones
and you can optionally pass a delay for
how long to before the task is executed
then the api's for the schedule at fixed
rate schedule a fix the way work similar
to the SE versions scheduled at fixed
rate is periodic and that you can
specify an optional initial delay and
then every 10 milliseconds execute this
task schedule with fixed rate is
slightly different flavor of that and
somewhat less deterministic because it
says wait for any specified initial
delay execute my task wait for a
specified amount execute my task so your
the execution time of your task is taken
into account in that periodic scheduling
and of course that can cause it be
somewhat less periodic both are more
useful for different
you know things different use cases the
additional API that we added for custom
scheduling the schedule method which
again takes a callable or wrongful and
this object called a trigger which we'll
look at so triggers are implemented
either by applications by you the
developer an application or by vendors
application server vendors or anyone
else they can be simple safer inspire
this task a single time maybe fire this
task at an absolute time or day or they
can be as complicated as you want in
terms of calendar watching and we'll see
how that calendar logic get what the
interface used by the service is to
allow you to specify that calendar logic
as we saw on the previous slide that
trigger your further is submitted along
with your task and scheduling time so
what is what's the API prepared to look
like two methods skip run get next one
time and these are used by the manage
scheduled executor service to ask
basically should I run this task now
it's here's the current time should I
run this task skip run is a simple
boolean test you know is perhaps perhaps
the trigger calculates that it's too
late you've already passed the point
where I needed to this task to execute
so bother doing it in which case it will
return false
similarly get next one Thomas where your
trigger logic calculates based on the
current time wind should and possibly
the last execution info which contains
results
other information about the task perhaps
change when it should actually be
scheduled to run again there's a simple
example of a trigger this one is meant
to fire at a single point in time it's a
one-shot we see that it has a
constructor that takes the time when it
should be executed and then implements
the get next one time and skip run
method to get next run time simply looks
at the current time is represented by
the tasks scheduled time passed in and
says have we already passed the time I
was supposed to fire out and if so it
returns null which tells the service
don't bother we already missed it
otherwise it returns in this case just
excuse me the time to farm which was
configured in the constructor skip run
has the same logic in this particular
case because of the simplicity of the
turn as the same logic to simply return
a boolean that indicates whether the
time with which the term was initialized
has now passed and therefore we
shouldn't execute any questions on
triggers or the scheduled managed
executive service yes
springboard
so you you could you could use almost
any caching solution and you're right
one of the things that utilities like
quartz and other ones do so there's a
couple of things
persistent scheduling caching and things
like that for the first release of this
API we specifically left that out
because we didn't we tried to get
feedback through the expert group on
what people were looking for and we
couldn't get a really good sense of what
we needed to put in so we we left that
out so I haven't given it any thought
but I would assume that part of that
would depend on the complexity of your
triggers and of the schedule as to what
would be an appropriate caching
mechanism but I have I haven't given it
a whole lot of false yes
no no one of the other things that we
initially had inspect but then it took
out for the same reason trying trying to
couldn't get a good answer of how to do
clustering or district distribution of
scheduling so we took it out our plan is
to add it back in but we also kind of
want to look at how would this work in a
cloud environment because now that you
know we had a fetid clusters everybody's
all application servers have implemented
clustering in their own way clouds
coming along clustering is getting a
little more standardized so we wanted to
look at that and I suspect that in the
next release of the spec we'll be
talking about persistence of scheduling
distribute district distribution of
scheduling and things like that
it is the complicated part to implement
Venus
implementations
I would expect that we would probably
provide some guidance inspect you know
how you implement it would be flexible
but some sort of guidance on a minimum
level of what you had to provide yes sir
I'm sorry say that again what's the
difference so that's a good question so
a lot of once again that's what happens
when you're a very old spec things come
along and bypass you part of what we are
probably going to have to do in we were
talking about this yesterday and the ae8
meeting is try to resolve happen how you
know what can we Dec 8 timers can we use
can we use timer implementations and
timer and annotations use this and we
haven't worked that out yet
similarly if anybody is paying attention
or as a JCA person the work manager of
JC a we're going to have to figure out
how how and if this work manager for
those you don't know is they waited to
do asynchronous work in the JC a
connector architecture and we're going
to have to figure out how these to tie
together if they tie together it may be
an implementation detail for an
application server vendor to simply
implement as work manager on top of this
or to 36
so the answer is we need to need to
figure that out
any other questions so contact service
we've really talked about a contact
service a lot already because all of the
MTF the mana start Factory the managed
executor service the managed scheduled
executor service all make use of the
context service in order to provide that
contextualization of the tasks so that
when when they get executed at some
point in time in the future they have
the same context of the application that
submitted them originally when you
create it just as an overview to this
topic when you create a contextual proxy
using the context service the
application context gets captured at
that point in time well step back for a
minute and some contextual proxy what
what does that mean so hopefully you've
had a chance at some point in time and
you're coding wife to look at the
dynamic proxy mechanism in the reflect
package was added in 502 thing we use we
use that in the context service you'll
see the API to basically create these
proxy objects the context service is
really a separate entity and since it's
required for use by all the others as a
application writer you may never use
this because if you're just wanting to
run asynchronous worker or schedule
tasks you may never need to use this
because you're you're gonna get that
contextualization done for you buddy
so typically you would only be used in
advanced cases one of which we go by one
of which the second one task was their
task listener of notifications Anthony
will talk about task listeners in a bit
one of the performance things that
performance recognitions that we made
was we decided not to contextualise the
callback methods of tasks Elizabeth
because typically you're not interested
in trying to look at the application
context you simply want to know is this
task starting stopping what the state of
it is it can be contextualized if you
want it by using the context service but
you get they you can imagine that every
time you have to take a thread if we
went back to the diagram every time that
you have to take a bearer thread and
contextualize it for the application let
the tasks run and then guess what you
got to pull that context back off of it
because it's going to get put back in
the thread pool and if you were putting
a security context on it you wouldn't
want the thread to be next task to start
running with that security context so
there is some overhead to this
contextualization so in areas where we
could avoid where we didn't think that
make good sense as a default to use it
or to apply that contextualization we
don't but you can always apply it
yourself in the task list and there's
one case where it's not trigger was one
that I mentioned also
so there it there is the ability to
customize the proxy objects that are
returned by the context service through
execution properties this is a generic
mechanism that there is only a couple of
execution properties specified by the
spec because there was not a really good
consensus on what everybody wanted so
some of the some of the execution
properties were given a vendor specific
but the ones that we did specify are
things like identity name so that you
can name a task in a standardized way so
anybody looking at a test is how to find
out its name
things like long-running hint that the
executor service might look at and this
is going to take a really long time
maybe I want to use a different cue a
different thread pull to pull this to
execute this task and the transaction
property which Anthony is going to talk
about in a few minutes which controls
how transactions are handled on those
tasks there's an API for getting the
execution properties off of a context
off of a proxy instance get execution
properties
and this is a look at the API so you can
see there's a number of methods all
create contextual proxy and similar to
the dynamic proxy means and reflect we
take a instance of what needs to be
proxied and you provide a list of or
depending on the eight which of the API
methods a interface that you want proxy
or a list of interfaces that you want
proxy and the final to allow you to
specify one or more execution properties
which again control the configuration of
that proxy doctor so there any questions
about the context service once again you
may never need it it's going to be used
behind the scenes by the application
server to contextualise
the either the threads from the
management factory or the tasks of the
various executor services
so an example here is creating a
contextual property we give it my a
pimple which you know this is what we
want to be contextualized or what we're
going to be proxy excuse me
and therefore contextualized and the
class which has the methods in this case
we have an interface that we only want
those methods in the interface to be
proxy so if my my a pimple has a bunch
of other perhaps implements a whole
bunch of other api's you can specify
that you only want certain ones to be
proxy and that's important because once
again there's takes a real amount of
time in order to contextualize the
methods that its proxy and basically if
you think about what the proxy is doing
is you're saying I have this Java object
capucho that I want you to contextualize
maybe my set of methods so that as I am
setting fields in my POJO I need to be
aware of context and maybe I don't ever
need to be aware of it in any of my
other methods in which case you would
provide an interface compasso for the
center's and pass that in and you could
recognize a pretty significant
performance increase over trying to
contextualize your entire
second example works somewhere a there's
very little difference we have a object
message processor that we want to be
proxy and we use the same API create a
contextual proxy for so at this point
I'm going to turn it back over to
Anthony and let him talk about a few
remaining pieces
so we are going to go through some of
the selected features in the concurrency
released in Java EE if I talk about a
lot about the context publications so
what it is in the spec we define the
following types of context that our
application server every needs to be
propagated for this gel 236 managed
objects once we define our class
building jdn namespace and security
identity and this type of context our
contractor falls in the sense that each
manage objects you could configure them
to propagate combination of these types
of contexts or maybe you can obtain none
of them or you can propagate all of them
on combination temp so it's all contact
at all and also it's extensible in the
spec we identify these three as the
context areas that may need to be
required to be propagated for proper
functioning of the simplest task but
each vendor could have the other types
of context that they want allow to allow
users to be propagated to the
synchronous trust so and and if we have
identified additional of this type of
context we could standardize them in a
future edition of the spec as well again
these are contest applications is
supported in all types of all types of
our mesh objects that Fred mentioned so
what is the copper 20 there are contexts
propagation happened so in the case of
you submitting a task to the managed
service or manager schedule executed
service at the time you call a submit
method the Epicurean server would
capture the context at the method call
so whatever the application component
has a be the task is running it captured
those context and then when the task is
started on usually a thread from that
pool which is different from the thread
you submit the test room we'll apply the
context in the death threat so the task
will appear to be running in under the
same applications so it means that the
task we have access to
the classes that are loaded for the
applications that the task will be able
to do to same jndi look up as if he is
running in the same application and is
running under the same security identity
as the locking user when the task was
originally submitted and for manufactory
the contest was captured when the new
threat methods call to return the
managed threat and then the contest will
be applied to the new threat just before
the run method is caught on the run the
buttons passed into the new third
network and for contextual proxy objects
similar things happen the context will
be fractured when the contextual proxy
objects created using the create
conceptual proxy api and then the
context will be applied when the
proxemic that is involved on whatever
threat idiot is worth running on that
invoked across the object except the
exception was possible when the hashcode
equals two strings which are the objects
that defined
I mean methods defined the object class
was caught and we don't apply the
context over there okay transaction
management so usually um when we talk
about context provocation we do not
include transistor in that so that for
example you submit a task from one fret
the transactional context is not
propagated to the threat that runs the
task so the however in in the task
itself you can do transaction
demarcation by using the JTA use the
transaction objects and you have to be
keying your own transaction and then you
have to remember to rollback or commit
the transaction at the end of the chest
so this applies to both in our magic
secret service mesh schedule secure
service and manage their factories for
context contact service
things will be a little bit different
because the proxy object methods are
could be run on si continue managed
transaction beam which
it has decent transactions so what do
you do we provide two options the one
option is you can leverage the same
transaction on the application component
so any work you have done any resource
we want you want to retrieve the status
JDBC connections in your proxy measure
it would be also enlisted in the same
transaction as the operation component
such as the continuum managed
transaction bin that you're running on
and everything would be committed a row
back together
another option would be you want to do
transition demarcation separately on the
proxy method and from the efficient
opponent area calling from
so in that case whatever transaction on
that Epogen components such as the
content of an image transaction beam
will be suspended when the proximity
info and then in your proxy method with
your own transaction demarcation using
research and session and then you can be
the Rope actor changes before your
return from that method and once you
return the origin of transaction will be
which is resumed on the thread so that
what we go on as a separation session so
all this can be configured using
executing properties it's fair mention
when you create a proxy object okay toss
defend applications so one of the
features that our case up to the state's
provider if you allow notifications to
be call when you keep track of the
progress of asynchronous tasks so the
assistant through the manage tasks this
in the interface and the defense would
be when the charge is submitted or we've
got notification when the task is
supported in the convenience cancel
forward through the future API
object a reduced submitted task or is
not about I mean it's not able to start
for some reason for example perhaps an
application this submitted chess has
ended and we don't want to start a trust
or there's some server configuration of
a threat to usage that limits Leary so
saying that okay we offer the musician
English so you don't want to stop the
task so at that time you get the task
afforded notifications you also can
notification when the touch is just
about to start and also get notified
when the tasks are completed running
meaning that either if something is
successfully always failed with some
exceptions thrown from the task so this
question okay
renew them there's no priority on the
task also you're hoping about part of
the task itself we need something to
mention to your service the way it works
is usually each application server they
can configure different vendors executed
surface say some of them you can
configure with a higher priority work or
some of them you can configure with a
lower priority work or maybe a
long-running task for example if you
have a higher priority task we want to
submit to the monistic single service
that are configured to run higher
priority task so this usually is
defended with that take care of how the
comforter which meant single service
with all different priorities okay so
the defender vacations will be used for
locking task progress or for doing some
remedial actions such as if the task is
to retrieve some data from a remote
surface and the time hour and fail and
then listener could try to resubmit to
trust if you try to reach any more
service again or it could the stay is
send email to administrators say you
know kayla has failed
okay so many trust listen is usually
implemented by application components
you have some ways to associate a chance
with this managed our listeners and
we're going to give some example radar
and as Fred mentions this business call
under unspecified
context so if you want to make a
confessed row you can use up the contact
surface to create proxy for that - cos
mystery
so as we mentioned is we do this for
performance reasons so these are the
api's in the managed transitioners
matters so in all of them we possibly in
future objects so we can check the
status of the task execution so the
weather is completed or canceled
and you can also use the future objects
to cancel the classic the listener met
that want to do that do so the second
object we pass until all the methods is
then executed so this is for use if you
want to resubmit to chest similarly we
have a deposit back the original task
object so you can use it too recently to
test for tasks of water in pasta we also
pass in additional exception so increase
the cast is completed with an exception
and the reason of the failure will be
known from checking the exception object
or if the task has been canceled and we
get a result
exception in the exception arguments so
obvious these are two ways to a register
ministrant listener and associate with
the task the first way is the task
itself can implement an interface for
manage tasks which returned the TAS
listener we also provide some utility
method to associate a task to task
listener this will be useful if let's
say your task is from third party vendor
that you cannot change the
implementation and we want to end your
listeners to listen to the progress of
tasks so we just talk about manage tasks
so what it is on this and interface step
la casa bits for mes or MSDS quick
optional increments so I think we
provide I think the key informations to
the application server we associate a
mesh touch listener for life cycle event
of patients and they can provide
additional
securing properties to tell the
application server we'll have more about
this task so it contains only two api's
one for getting the execute properties
another one is getting listener so I
think Fred already mentioned about these
extra properties so I'm not going to
repeat them here one more thing is all
this these are the standards exhibition
properties that we define inspect so far
and you can find a constant for all of
them in the
I manage tasks interface so they are
defined there and then again in the
future if they have enough feedback we
could add more securing properties that
can help the application server to
populate if you do the tasks any
questions so far
prior to this he's talking about this
only fifth that choice is already
suspended not suspended is specific to
this year specifically context from
surface so if you submit a chest to
manage traffic to manage executive
service um it doesn't apply to it so far
so in indexes is always I use a
transaction for transaction demarcation
if you have even using the concept of
processing methods yes
extrication properties to specify that
or if you say Singh is a we use let's
say magic your surface is a bit new task
then we always have this long
transaction we can propagate transaction
from the ejp to the task in that way in
synchronous now
right Scaroni we don't do that yeah I
think we are very close on time so the
just last one is magic servitors it
contains some utility methods for
helping like the weather that if I
checked in where the current thread is
marked for shut down when you're
interrupted and it's interrupted or for
associating a task with a managed start
listener or execution properties hey so
um so it's in summary this specification
is for arm basically to provide some
low-level mechanisms for people who are
more familiar Java s eat so they can
bring along the same programming models
to the Java EE environments so we've got
a lot of questions about how that's it
aligned is like using new JT how does it
align with arms the timer service and JP
and things like that
yeah I don't have very good question
about that we just profile off the way
of series we provide alternate way to do
things but we this one allow cause to be
more aligned with other Java EE
technologies and so any of any if you
have any feedback - it is very welcome
that we can address those issues in the
next revision of this path we kind of
like we want to throw this out so we can
feedback from the community saying okay
we should proceed from here so here's
some memory resources so the first link
is a jsow our website for the purchase
of 236 you can download the speck from
the person link a second one is the
browsable Javadoc for all the Java EE
api's including positive
areas and the third one is the java.net
project workspace for our concurrency in
this pack so from cackling we have issue
tracker Kira all all the corrections a
clarification of the spec would be
listed on the etcetera issue and if
you're any suggestions or on our
features that you want to see in the
next revision aspect
you're very welcome to follow Kira
issues so we look into it in then when
we are looking in the advanced way and I
think the last email is for any comments
or suggestions or you cut any errors
feel free to send email to get the last
email reduce our mailing list in the
spec we don't want to go forward to
feedback from the user communities so
that's it you have any questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>