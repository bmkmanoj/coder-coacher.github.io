<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CON3629   Servlet 4 0   HTTP:2 and Reactive Programming in Java EE 8 | Coder Coacher - Coaching Coders</title><meta content="CON3629   Servlet 4 0   HTTP:2 and Reactive Programming in Java EE 8 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CON3629   Servlet 4 0   HTTP:2 and Reactive Programming in Java EE 8</b></h2><h5 class="post__date">2015-12-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3uHhx-TMV8o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay good afternoon can everyone hear me
okay my name is Edie burns this is my
colleague Shing watch an everyone having
a good show so far
Java 115 20 years of Java it's pretty
exciting so we're here today to talk to
you about Servat 4.0 http/2 and reactive
programming and java ee 8 mm-hmm this is
a part of Java EE 8 as I just said and
therefore it's a four word general
product direction so everything we're
saying here is not intended to be used
to base your investment decisions on so
just keep that in mind if you're
enjoying the content that you're getting
at Java one especially on the streaming
people as well out there hello to the
streamers
there's plenty more training and
technology you can learn about on this
website education oracle.com
so here's how we plan to spend your time
investment of the next 60 minutes and I
know there are lots of other great talks
that you can attend so I really
appreciate that you've chosen this one
and we take that very seriously so we
really want to make sure that you get
the most out of this we'll be talking
about establishing the motivation for
why we need HTTP 2 in the first place
will give an overview of the big
features in the protocol itself then
we'll have some aside on servlet and
reactive programming a little insight
into what we've been thinking about on
the expert group a look at how servlet
might expose those new features that are
in HTTP 2 then we'll have another aside
on Java sc9 support for HTTP 2 and
conclude with a summary and current
status so let's start out this section
of the talk will allow us to explain why
you need it right
if HTTP 1.1 was good enough for the last
15 years why do we need this HTTP 2
thing in the first place certainly if
it's good enough why do we need to
change it and Shing Y is gonna tell us
why
now let's take a look on what happened
in a web page right now the web page is
more complicated than before
if you try to grab a web page you will
notice that they will have stylish free
JavaScript and you will have many images
and icons now let's take a look on how
the browser load the resources first the
browser we try to load the index.html
and they will find that they have about
30 resources they need to low so one way
to do it is you try to say you lost out
at number one and you wait for the
respawn and then you come back you load
the establishment number two but in HTTP
1.1 we allow to be doing a better job
what they do is HTTP pipelining so they
will send all the requests for the star
1 star 2 and JavaScript 1 JavaScript 2
that is one by one to the server and the
server are required to respond in the
same order so they are expecting the
result of the star 1 and star 2 now
let's say the first two star should
return quickly to the kind and then they
are waiting for the next JavaScript but
the JavaScript somehow it takes some
time to load back to those kind and in
this case all other resources like
script number 2 and all the jpg file
will not be low it is due to the head of
line blocking because we need to
preserve the order of the requests now
since we have the head of line blocking
then we try to solve the problem in
different way let's take a look on how
the peoples of this ok one way to solve
this is ok instead of using one
connection we have two connection or
even many connection so for example your
connection number one they try to load
the JavaScript condition number two you
load gbt and the condition number three
you try to load the stylesheet
now if you try to
do this this okay sort of but then it
suffered two problems the first one is
we all know that the TCB soccer is
expensive so it is not an effective use
of the TCP socket and secondly is
because for a given browser they have a
maximum number condition per host so you
cannot just say you have a hose you want
to happen
join the connection then these are
allowed so given the restriction we have
then we try to find some way to solve
this I have a line blocking problem and
then we have a different way to do this
and all of them are workaround now the
first common workaround is Falcon
communication and the image despite what
I mean is like this instead of having to
starship you make it in the one pick
stylesheet instead of say Knight reverse
script I would give you a big JavaScript
contain all the function that you need
and the image Spy is is like this
suppose you have a page you have ten
different icons instead of I give you
ten jpg file well I'll give you t is a
huge JPEG file and then you would use
the JavaScript and say okay I'm going to
straight this particular corner of the
of the G file then it will become my
icons now another way try to work around
this problem is called domain shutting
now as I mentioned before there's a
restriction on the maximum number or
connection for a given browser to a host
why don't we just separate the resources
to different machine so you can say I
put some JavaScript on machine 1 and
then I put the suction machine to and
then when we try to low it then we turn
to be bounded by the number of
connections that we have and the last
technique that we try to over try to
resolve this issue yes we try to
actually and Bend the resources inside
the web page now you can do this in the
Java
script you can embed the stylesheet in
the web page but actually you can also
embed the image inside the web page the
way that they do it is they will try to
do a basic set for encoding of the
primary and then they will set the
inside web page and then when the
browser's are low it they will extract
that part and then they do a base64
decoding and then they will display the
image now if you try to do this you
expect you will spend a lot of time
doing this encoding and decoding and
also you expect you have a hard time
doing the caching and sharing across the
pages now let's take a look on the HTTP
- all right so stream I and I have
established the some of the reasons why
we need it the rationale for HTTP - from
the very beginning is increase the
perceived performance of the web
browsing experience that's the main goal
that the HTTP 2 working group was
chartered with and that was their guide
throughout their entire working group
period so let's take a look at before we
understand how they solve these problems
let's do a little bit of network
programming review first the good news
HTTP 2 is really just a new transport
layer underneath the existing HTTP 1.1
so it's the same request response model
there's no new methods no new headers it
doesn't change any kind of semantics as
an application layer protocol basically
what they're doing is standing on the
shoulders of all the work that has been
done before and I'm really pleased
because it's very common in our industry
and it still happens today where a new
technology comes out and they say well
let's just reinvent everything because
now we're gonna get it right and they
tried to avoid doing that by studying
the past and learning from the mistakes
and one great way to do it is to go look
back at your old CS networking textbook
and what they did is took some of the
ideas that Farrar from the seven layer
OSI protocol stack and
sort of X take the semantics and
concepts of that and put that into HTTP
- in the following way so we're all
familiar with this the physical Data
Link Network transport session
presentation application these are all
different responsibilities in the OSI
Network protocol stack and a few of us
have to worry about this level of detail
anymore but inside the HTTP 2
specification which is entirely defined
at the application layer they have a
concept of a connection now this wasn't
really formally defined as much an HTTP
1.1 before it was basically a connection
exists and everything goes through the
connection and if you need to do new
transaction you open up a new connection
and that's all we say about connections
in the HTTP spec HCB - formalizes that a
lot more so that connection concept if
you're familiar with the OSI protocol
stack is introduced when you get to
level 4 transport
that's when connection lifecycle open
close is defined the next concept that
was taken from the foundations was the
concept of using frames this is in the
network layer of the OSI stack but it is
still in the HTTP 2 specification and
we'll have a lot more on that later in
the talk another concept was introducing
streams which is a session level concept
but now we have it in HTTP 2 and on top
of all of these things sits basically
HTTP 1.1 so you don't need to pay
attention to anything that's happening
under here unless you're at the protocol
layer yourself there are some
interesting potential synergies to use
that funny word that we're exploring in
the servlet expert group particularly as
it applies to the relationship between
the so called back pressure which really
to me just seems flow control and which
is an application layer concept and the
framing and flow control mechanisms that
they have in the HTTP specification so
that's an idea that we're playing with
so in one dodo and HTTP 1.1 oh and 1.1
sockets are seen as a throwaway resource
the specification says very little about
how they are to be used there's nothing
anywhere that says browsers may only
open eight sockets to a given host
that's just kind of a I don't know an
industry industry standard that has
evolved over the years you know the
original NCSA mosaic only opened one
socket and when Internet Explorer came
along they updated it to four people
were really upset oh my goodness is
gonna be the end of the Internet now
every browsers are opening for sockets
at the same time so that just got worse
and worse and worse and worse so in
contrast with HTTP two sockets are seen
as a scarce resource and the
specification says a whole lot about how
they are to be used ideally if you're a
browser talking to an HTTP 2 server
you only need to open one socket to that
server everything that you used to do
with n sockets is now done in one so
it's all collapsing down to one thing
another angle to look at this is the
adoption angle when HTTP to one I'm
sorry when HT one came out it was
designed to be easy to implement with
the contemporary development practices
of 1991 so it was a text-based protocol
there was no flow control at the
protocol layer it was very easy to write
a parser it had a very simple socket
life cycle it was important when that
was it was important that it had that
simplicity because when you're
bootstrapping in technology you want it
to be as easy as possible for people to
start using it so writing an HTTP server
back then wasn't that hard surprisingly
and if you were fortunate enough to be
starting out your career in 1994 and you
wrote a web server you know you could
really do pretty great things because
very few people had done it back then
and you might have ended up going and
being in that scape and done quite well
so anyhow if we had started with http/2
at the very beginning with this state
machine and header compression and by
reframing all of these complex things
which again because they're based on old
ideas it's not like we couldn't have
come up with that in 1991 there was a
conscious choice to keep it simple so
another thing to consider is one HTTP
Wanda okay mount open-source wasn't
nearly the powerhouse of innovation and
sort of off the shelf availability that
it is now so if you wanted something
more than likely you had to write it
yourself whereas nowadays if there's a
feature you need you can probably find
some library out there that does some of
it and either use it wholesale or take
the code and fork it and copy it so lot
has changed since then
economically and technologically one
thing that's fun to point out is it's a
binary based protocol now so there's no
more tell netting to host 80 and typing
some text and getting the file back so
you can pour out a 40 and sadness for
that the age of that is over with HTTP 2
these are the big-ticket features
request response Multi multiplexing
binary framing stream prioritization
server push header compression and how
do we get into this h2 thing in the
first place and there is a really great
resource that I'd like to point out this
guy ilya grigorik he's a performance
developer a difficut at google and he
has a freely available book that's also
a very good book high performance
browser networking so anything you want
to learn about h2 I think it's a great
place to start so execute that search
query in your favorite search engine
okay thanks for add give us a motivation
an overview of the http/2 now let's try
to take a look on some more details now
the first important thing about the
http/2 years they have the request and
respond more time practicing even they
have a one single connection they can do
the multiplexing and the communication
is bi-directional so it's not just same
one way you had a way for a finish and
then you respond later
now before I continues I would like to
define four different concept the first
one is the connection a connection is
just a TCP socket and a stream will be
just a channel of communication between
the connection and the message which
requests respond and control message
which I'm going to talk more about later
now the stream I mean the frame is the
smallest units in the communication so
for given requests in the past
you just have one HTTP request but now
you will see that actually we are going
to break down into smaller frames that's
how we can transmit across without the
head of line blocking now let's take a
look on how this four concept related in
fact this four concept is defined in
there also I energy that it has just
mentioned previously now for keeping
connection you can have multiple stream
and for given stream you can have
multiple message and for given message
you can have multiple frame so you can
see they have this hierarchy
therefore this four different concept
and the fundamental unit of the
communication is framed here
now once you break down the
communication into frame then you can
see that you can the other thing are in
the with each other then you will not
have the hair on line broking issue now
let's take a look say
shrim number seven here now if you look
at stream number seven you see that the
header is sent first and then before I
send the data which corresponding to the
HTTP the request body I'm actually the
server is try to sending the stream
number to the corresponding body of the
HTTP response so you see that they don't
need to wait for the request come
completely then the server can already
try to do something else that's why they
don't have the head of line blocking
here now T is not a new idea is this
idea is in fact in 1960 but with the
HTTP to this new idea this ideas become
new again now as you can see the basic
unit of the communication is framed so
let's try to take a closer look on how
the frame look lies now the frame itself
has a header and the header consists of
some information first
it contains the length of the payload
and it contain a type which I'm going to
talk more about and then they have some
configuration tracks and then they have
a research bit and then you have a
stream identifier the stream identifier
corresponding to two four seven nine in
the previous diagram so each each stream
has a particular ID now there are many
different type of frames and in this
particular presentation we will only
look at some of them so I will try to
conclude this with you now the data
frame corresponding to the HTTP request
for T so but in this case you may have
multiple of them for example if you have
huge body you may chop it up into theta
1 theta 2 and theta 3 and the head does
corresponding to the HTTP headers and
the parity is something that I'm going
to talk more about and the RIT rst
stream is basically about the error so
you notify the other side okay there is
an error in the network layer and push
respond I'm going to talk more about
this in the later part of the
presentation now having looked at how
the frame lock lies we would like to see
how the HTTP required is mapped to a
frames now on the left hand side you
have an HTTP request and then it's
mapped into a headers header frames now
in this header frame you had to
configuration frames here the first one
is answering a path i means you set it
to true now if you set it to true it
means that T is the last frame for this
request and if you set an N header it
means that you will not have another
frame tails for a header all the
information is in here and then you'll
notice that they will just map all the
new information I'd method scheme path
from the head line into here now notice
that I have a semicolon in the method
scheme path and authority this semicolon
is called pseudo header it corresponding
to the information in the first line
here and also some special header
defined in the HTTP 2 specification now
have a look at how the head requests
localize we will try to take a look on
how the respondent life now in this case
and the left hand side the respond will
be a normal HTTP will respond with a
body hello world and then you split this
into two frame header frame and then a
data frame and the first one you see I
put the end stream to be - because it is
not the last place
frame in the stream and then I put a
pass here and stirring in the data frame
because D is the last one now as you can
see the header frames have a lot of
Heather's information can we do
something about this okay in fact we can
do something about this
it's called each pack is about a higher
compression now if you look at the
diagram here the request number one and
request number two you will notice that
there are a lot of similarity in fact
all the header are the same except the
path so why don't we send them over and
over again can we do something better on
this and the way that they will try to
do in the H pack is instead of sending
the data over and over again both the
kind and server is going to keep a table
of the headers so you try to keep a
table of the header and then when you
send it across that's when the second
time you send a header across you just
reference the Hatta number in the table
and then the client side will know okay
you're actually using this now T is one
of the feature in the HT t db2 and
another feature that I promised to talk
about is the priority now in HTTP two we
define a priority
the priority can be the information can
be either put in the header frames or a
new particular frame corporality now I
want to emphasize that the priority is
not a integer it is something more in
fact is represented by a graph here if
you say a resources P assume IDP depends
on a you put in a graph like this so we
have actually multiple scream can depend
on a stream in this KP and C is
depending on a furthermore you notice
that I put a weight on the stream here
four and twelve and here is how it work
okay suppose you pass a stream
a and somehow the system gets stopped in
a so you will try to spend the time and
try to pass it a string B and C now in
this case C will take three time of the
resources that a BTech so that is the
weight here and of course this is only a
suggestion to the server the server can
read the information and process it and
then they will say okay I cannot honor
the request this is only recommendation
now the next important thing about HTTP
2 is server push the server push
eliminate the need of doing the resource
inlining now what they do is they try to
P populate the browser cache so that the
browser will save the time to send a
request to the server when they say I
want the style sheet or the style sheet
is already in a cache now together with
the SS e the server side event actually
you can push aperture resources to the
to the browser side now here is how it
work first the server will push the
resources to the browser and then they
will send an SSD to the to the browser
and with the name of the resources as a
data in a in the inner SSE event and
then the browser will use JavaScript to
look at the given and say okay I want
this resources but then you look at the
cache is already there because I push it
to them earlier so this is a one
interesting UK use case about the server
push and in fact I expect this will be
useful in the framework like JSF now
another interesting thing about HTTP 2
is now most of the website right now is
in HTTP 1 how can they talk in HTTP 2
now there two way the first way is you
are using HTTP 2 HD
and that way is the clear tax so in that
case you can use the upgrade mechanism
in HTTP 1.1 you just send upgrade header
upgrade to a protocol called h2 si si
mean clear tax then the server will do
the corresponding thing and they upgrade
to h2 see now but what happened when it
is secured in the secure it turns out we
can have a LPN which is a TRS extension
is still in the handshake you send a
particular extension to the to the
server side and the server side will
figure out ok he is the h2 then they
will continue the communication in h2
now I will let and to continue to talk
about what other people look at HTTP
okay so everybody's a critic and
especially in working groups so one of
the prominent members of the HTTP 2
working it was Paul Henning Kemp and
towards the end of it right when they
were getting to the working grant last
working group last call he posted this
rant which is very much worth the read
and also cross posted it to a cmq
magazine and in a single post he managed
to mention Taylor Swift Ronald Reagan
and Samuel Beckett in a post about HTTP
2 so it's pretty cool
his criticism and several others in the
working group were mentioning that
head-of-line blocking is still a problem
it's just been shuffled around so it's
still can happen in the headers frame so
if you're the type that thinks that
human nature is that protocols are going
to be exploited to the maximum advantage
of the stakeholders then you might think
well gee someone looks at how this thing
is and realizes I would like to front
load my stuff well you can just stuff it
into the headers and then you can
guarantee it'll get there first
maybe that'll happen maybe that won't
another thing is h2 see there's no H to
see and Firefox or Chrome so that is if
you want to talk h2 and your browser
happens to be Firefox or Chrome and I
think Safari also there there's no clear
text right so everything is TLS encoded
TLS everywhere h2 equals TLS
pretty much and this was done a nod of
compliance to this IETF RFC 725 8 which
is pervasive monitoring as an attack I
like to call at the Ed Snowden RFC
because it came out after he did his
thing and it's basically says if you're
in the fortunate position of having to
develop an IETF spec fortunate or
unfortunate I guess when you're doing so
you should take steps to make sure that
pervasive monitoring can't be done
defeated at the protocol level because
the government doesn't control that
another criticism which is a bit
far-fetched but potentially true the
increased carbon footprints from all the
H pack encoding and decoding that now
has to be done so we're just trading off
cpu for network resources whereas before
we just send the same headers over and
over and over again now we're saying
well we're going to send Delta's back
and forth but you have to do a little
bit of encoding to do that so instead of
network traffic you get CPU usage with
any new technology especially one like
h2 which has so much new stuff in it
underneath again not at the semantic
layer at the implementation layer it
does open up a potential for new dos
attack vectors that no one has imagined
before so that should be interesting
another criticism people might get
confused and say hey h2s server push
it's bi-directional is that related to
WebSocket no in fact it's completely
orthogonal to that WebSocket is an
application layer protocol with a nice
JavaScript front-end that you can use
you know from your web application
whereas H to the server push feature is
really lower-level
the one way to leverage it potentially
from the application layer is the
approach the Xingu I mentioned which is
you know using a combination of servers
that an event to push stuff you push it
and then you tell the browser hey go
fetch it but the browser already has it
right
if you don't take my word for it you can
go and look at the speck yourself but
you'll quickly realize it's not one
speck it's actually two it's gotten that
complex so h2 is the protocol is in 1
RFC and H pack is another one and in
order to understand them like most
things in the ITF world you have to read
a whole bunch of stuff so 7 5 4 0 is the
h2 protocol 7 5 4 1 is H pack these
depend on RFC 7 2 3 0 which is H an HTTP
1 1 messaging RFC 4 6 4 8 base64
encoding RFC 7 3 2 3
TCP extensions for high performance and
on and on you have to keep breeding if
you want to say you understand all there
is to know about HTTP 2 or you can just
use a nice layer on top the servlet API
to make it a little easier for you so
now I'm really excited to get to this
part of the talk I wanted to get here as
quickly as we could
the server for and reactive programming
which Sheila is going to explain for us
thank you sad now another thing that if
you try to look at recently is about
reactive programming
this seems draw a lot of attention on
what how the people try to do this so in
this presentation we will also try to
take a look on this and how server is
fit into this programming model now
let's take a look what the reactive
programming means a programming is
reactive if they satisfy for property
responsive resilient elastic MSE
children now responsive mean it will
respond to the user need in a timely
manner and the resilient mean stay
responsive in the face of failure so
this will be more like a high of a
mobility and the elastic means stay
responsive when is under heavy load and
the message often we mean the system is
defining it in a loosely coupled manner
so that they will interact each other in
a synchronized fashion now in servlet we
will only concentrate on the responsive
and message refer
now let's take a look on what we have
recently for the Java SE 9 you will look
at the source of open JDK you'll notice
that the Java SE ni is still under
development and recently they have
checked in something about the reactive
programming which I'm not trying to go
through with you now they have defined a
class called fro and the Castro has
false there the interface processor Papa
sure subscriber and subscription a
processor is just a subscriber and map
opera at the same time and the publisher
only have one method is called subscribe
in the subscriber will be able to
listens event lie on complete on error
or on next or next mean when the data
come then they were passing the data and
then they will also have unsubscribed
which they allow the publisher to pass
them a subscription and a subscription
can also can do the cancel and a request
now for those who familiar with the open
source project called reactive stream
you may notice that this four interface
is actually coming from there so it's
nothing new in here now in the JDK what
April Y actually is in here the
submission proposal I'm going to explain
a little bit more why it is so nice to
have a phone a class like this because
if you want to do the reactive
programming you actually you have to a
lot of grunt work need to be done it's
not as life or interface is enough now
before I move on I will try to show you
how this four interface interact each
other in one example I'm going to try a
simple one I have an actor and the actor
will say I go to the publisher and I
subscribe we've given subscriber here
now once I do this this publisher will
create a subscription object and the
subscription object will contain any
information that they need later and
then the publisher is going to pass back
this information to the subscriber so
they were called unsubscribe then they
will have the information and then the
subscriber will have to call the request
end it means that I want any items now
once they call the requests in on the
subscription and later when the data is
available then the subscription or the
publisher itself is going to call the
subscriber or next and later in this
case they will do it through an executor
the reason is you don't want it to be
broking because if you the subscription
directly causes subscriber or next and
what happened when the subscriber or
next is actually taking a lot of time to
processing the item then the part we
will proc so in that case they will use
executor just submit the job and then
use a different threat to call the
subscriber and then they would try and
the executor will call them on next on
the subscriber later in a different
frame now notice that in this example is
really simple because I assume that the
subscriber can handle the data from
publisher as fast as they want now
imagine the case you have the publisher
published the item really fast and the
subscriber cannot handle it what
happened then what people supposed to do
is they have an a buffer for the
subscriber then in that case whatever
the item cannot be handled they will put
it inside the buffer but still you have
to figure out what to do when the buffer
is full
what do you want to do it turns out
there are two case okay and that's why
we need a submission parser now if you
look at the the code which I'm going to
talk more about on the submission
pupusas I think basically they try to
handle two cases one case is when the
buffer is full you want the people who
call the subscribe to be frog you don't
want any other thing to get in until the
threat is on the subscriber pick up an
object they release a slot then you push
it in this is number one the second case
is okay if the buffer is already full
you try to put more I despair I just
drop the request now if you do this you
will expect there will be some handling
error handling method in here now let's
try to take a look on the submission per
person and the submission purpose are as
you expect there will be an executor as
in the previous diagram and you should
be able to allow to convict the maximum
buffer size and then you will have a
handle on object and the handler object
is used like this suppose the submission
purpose are go to court on next method
on a subscriber and the subscriber is
trying to process data what happened
when there is an error you want to
handle the error right in this case the
handler will be called and in to handle
this to handle this exception you may
for example put a lot in there or you
try to do some adjustment later okay
now these so far these for this
submission per person now
there are many interesting method for
the submission popular the first one is
submit method and this one is the method
that I just mentioned about yes when the
buffer is full if I try to submit they
will just broke and wait and wave
the particular is going to bro
and then you will wait and there is
ready then you will put a thing in the
into the queue now but the submit effort
is cell it's not blocking they return
immediately know that okay you can
oppose as this the other one is the
offer method the over method is it's
doing something like this if you try to
submit you try to give the object into
the queue and if the queue is full they
just returned immediately because they
know they cannot do it but before they
return they will call handle a call on
drop and this on drop will give you a
chance to say whether you want to submit
the object again one more time
so there's a pride by practically here
and you can see from the diagram here
when they went over failed and they work
all the tests they were called the test
method in the on drop and then they will
determine whether they will submit it
again now this is what happened in the
gdk9 let's go back to the servlet now in
the servlet actually we already have
something about the reality programming
in Java EE 6 in EE 6 web service written
all at that time we have defined the
synchronized API so you can call the
start acing and then do you get an
easing object async on test object this
allows you to configure the listener or
dispatch or do you call the country and
then the listener is allowed to listen
to 40 value n which is complete error
start acing and timeout now with this
API together with SSE the surface I
event you can actually
- the Eve event children of the reactive
programming that is good right because
you handle one condition
now the other thing that we have even
breed reactive programming is responsive
now in server 3.1 actually we already
have them responsive in there it is the
non parking i/o and we solve the non
broking i/o using the listener approach
in the server input stream
you will set a great listener there in
our stream and you have a right listener
there and read listener we have the
event life when the data is available
the listener will be invoked when all
the data is read the listeners will also
be invoked in case of error
you always also be invoked and similarly
for the right listener
now there is a discussion on the expert
group whether we want to have the
reactive programming in the fro concho
as mentioned by ad in HTTP 2 you can
have a back pressure push back and let
it they will push by a frame and let
them let you know that okay there's a
problem and you may need to slow down
don't push so much data on the stream or
in this case right now in the expert
group there are basically three proposal
the first one is called pou delivery and
this one is similar to the non broking
i/o so yes once you have you notice that
there is a bad pressure you will note
you have a callback to be notified and
then you will try to do some IO
explicitly inside the callback this the
approach number one approach number two
is going push delivery the push delivery
instead of you letter Compaq try to read
the data they already read those data
for you and pass it to you this small
look like the WebSocket approach and you
can either explicitly say ok you want to
start from control now and stop it now
or you do in a poll pace in that case it
means okay I want to read something once
you inform that I want to read something
then I will give you a we give you the
carpet light in both the carpet later
now T is so far about it's only a
discussion and expert group and we will
still continue the discussion now after
this now let's take a look on how we
supposed to do this the surf lab with
the HTV to
now as I've mentioned before the servlet
is the right abstraction for those RFC
you don't want to go to programming the
frames because this is more difficult it
would be nice you have a more high level
API to hide the network layer so that
the in a servlet API you can do the push
server push and you can do the error al
p.m. without doing the low-level stuff
now one of the challenge that we have in
the servlet API is in HTTP 1.1 you have
one request and one respond now in HTTP
to this assumption is no longer true you
can have one request and then the server
made this I say that I'm going to push
several resources and then finally you
return the original page so it means
that you look like you have one request
and you have multiple respond at the
same time and this is a challenge that
we had in server api is we try to have
try to have as a model for this and you
don't want to just hack this into the
ABI and make it difficult to use later
now let's try to see how we resolve this
now in server folder oh you have many
feature as I mentioned before you have
multiplexing by Mary frame shrimp our
authorization server push header
compression and also upgrade so in surf
report all we only concentrate in two
namely the server push and also the
upgrade and the upgrade we already
talked about it in server 3.1 so today
we will concentrate on server push
now let me emphasize that the server
push is not a replacement of the
WebSocket and they just allow you to
peep operate the browser cache and we
will expect of framework like JSF is
going to use this and we will solve this
problem using the Builder API and insert
photo we will also talk about some easy
to use enhancement now let's take a look
on on the push builder now the push
builder is associated to HTTP server
requests and you can see that we have
the API to do the configuration of the
header like add a header you can do a
neat a class modify and you can also
modify the query string section ID now
once you config
all the headers you need you can call
API push in here let's take a look on
how this supposed to work now you have a
browser the browser will try together
index dot HTML and the server will
notice that ah I need the style sheet
and I need a Java Script so what we will
do is we try to get a push builder from
the HTTP request and then you try to say
I want to set the path to be the style
sheet and then you do a push and then
for the second one I was set a path of
the Java Script I will do the push again
now in this case then the style sheet
will return and the JavaScript will
return and then the original index dot
HTML is returned so it's easy right you
just get the push builder and then you
conflict the header and
you set the path and then you push now
there are two things I want to emphasize
in this diagram first of all is the push
builder can be reused you notice that I
use a push builder to push to different
resources so the starship and the
JavaScript the second thing that I want
to emphasize in this diagram is the
index dot HTML is returning to the
server after the push resource the
reason is like this if the index dot
HTML is returned P for the route
resources the browser will immediately
try to analyze say that ok I need these
two resources do I have it in the cache
no then what do you do you will start to
be crazy right so in this case if the
browser cache will not be popular so
that's why the push requests need to
return first and then the index.html and
ad is going to talk more on the yep
we go back to this one other point that
you mentioned one of the frame types was
rst stream so that's how the client
declines a push promise frame so the
server tries to push a resource and the
browser already has it in its cache
rather than letting the server send some
bytes it will send a rst stream frame
saying hey I already got it don't push
it to me so they figured that one out
this is the stock phases servlet and in
my opinion the most important use case
for server push is the framework case
server pushed is entirely dependent on
the server having a priori knowledge of
resources the client will ask for before
the client asks for them and the
server's are well positioned for that
and server-side web frameworks are in an
especially good position so JSF is able
to use server push very very very very
easily
it turns out that any time JSF is gonna
render a resource script stylesheet such
it will call this method encode resource
URL and that's our entry point where we
can simply initiate the push right there
so that's how web frameworks such as JSF
will be able to leverage this thing with
a single modification I talked about
some ease-of-use features really these
are coming from the community JCP org
has been open and transparent for a long
time now and we're trying to make sure
we take good advantage of that so both
of these new features actually all of
them came from the users list in one way
or another we added some default methods
for a lot of things so if you're
providing a HTTP session activation
listener and you only want to do one
thing you just have to override that one
method there's the defaults it's kind of
low hanging fruit easy to get we also
added a generic filter and HTTP filter
classes and we added a default context
path element in the web that XML so
simple things but important for an
incremental API such as servlet you know
we're not going to be reinventing
anything and doing a brand new API
servlet is very stable it's among the
oldest of the Java EE specifications so
we treat it very very carefully but at
the same time we want to add new
features where we can a quick view
there's a talk tomorrow by Michael
McMann who's the guy who actually is
leading the team that's developing this
but if you want to get a quick overview
of it here it's done in JEP 110 the
ideas have a easy-to-use API we're not
going to be reinventing Commons
httpclient so the idea with the java SE
9 support is you have this HTTP client
builder and
you ask that thing to give you an HTTP
client and then that thing is reused to
produce multiple requests so you get a
request builder from that thing and then
you ask the request builder to issue the
individual requests with different
methods attached to them it's really
just a handful of classes should fit
into your brain pretty easily you have
this concept of a body processor so
that's a way of passing behavior to the
request handling mechanism to say hey
this is how I want my bodies to be
handled it's got two modes blocking mode
and non blocking mode and the non
blocking mode is really simple you can
just use the executor service and
completable future it has full support
for server push so this is what it looks
like you say request create and this
does the Builder thing under the covers
for you put some headers on there set
the method to get and then do the
response then you can ask the response
for its status code so this is the
simplest case here's a slightly more
complex example which is also blocking
mmm the same thing we're gonna ask the
request to be created get the response
give the status code here's another one
get the status code again you can see
here we're passing a body processor so
as file gives you a body processor that
will write the response body to this
text file here for example and now that
you've got the body of a processor you
can see how the post goes so we're
issuing a post request there
this one is a little bit more advanced
with the async case and I'm just gonna
skip over it because in the interest of
time but you can see it's making use of
completable future it's making use of
lambdas and the streams API as well and
completable future being done there so
this example fetches a list of your eyes
asynchronously and stores them in the
file and all this has done
asynchronously and then the weight
operations happen here so everything
happens up and this part is completely
non blocking nothing blocking happens
until you actually do this call right
here okay they also have support for a
LPN and server push and each pack is
being supported as well of course where
are we right now with servlet 4 so the
idea is circle 4 brings HT 2 to Java EE
if you're using sort of a 4 you're
guaranteed to have 100% compliant
implementation of HTTP 2 it exposes the
key features of the API most notably
server foot server push the HTTP 2
specification itself was done so that's
all done in May of 2015 as far as where
we are with the servlet spec we
published early direct review to JCB org
last week so right now on the early
draft stage of the specification so you
can take it out give comments send mail
to users at servlet spec java.net with
your feedback on that you can also get
involved by checking out our adopted ASR
page following our status on the
aquarium blog and looking at the Java EE
referenceable mutation in GlassFish org
so
I think that's it you want to say a
closing remark err okay
okay we have three minutes so we could
take one question maybe only one person
is we're in some contention here okay
all right go ahead
mm-hmm
question was what is the relationship
between server push and services
well services don't have that mosaic
like quality usually where you have one
resource that's a composed of a
composite of lots of other things as far
as I've seen with services it's pretty
much they're each doing their own things
individually in isolation so if you can
imagine a service that does have that
property you could imagine reusing the
concept but
okay
I see
mm-hmm
no we were not thinking of exposing that
but that's a great idea send it to the
users list and try to explain it a
little more in detail on something we
consider because the other important
consumer of servlet I mean it's not just
web frameworks that are using servlet as
your question brings out people use
servlet when implementing proxies and
server-to-server communication as well
so there might be some interaction there
as well okay one thing that I would like
to clarify is in the server push
they cannot push aperture e-resources
back if you look at the RFC there's some
limitation I think they only can push
those cacheable resources back to the
kind so it is something that you may I'd
like to take a look on the RFC okay all
right thanks for your time please fill
out the session surveys and here's the
session tomorrow if you want to take a
look back</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>