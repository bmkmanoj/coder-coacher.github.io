<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>ARM: Over 10 Billion Served—“Want 64-Bit Support with That?” | Coder Coacher - Coaching Coders</title><meta content="ARM: Over 10 Billion Served—“Want 64-Bit Support with That?” - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>ARM: Over 10 Billion Served—“Want 64-Bit Support with That?”</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/uw_ieULgZkM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so my name is david holmes i'm i'm
working at oracle i'm a consulting
engineer in the Java Sea embedded group
I'll be working on there as he embedded
product and be co-presenting today with
Zack Shelby who's director of technical
marketing in the Internet of Things
business unit at arm and today we're
going to be taking you through a bit of
a look at the arm Java ecosystem that
has been been growing for many years and
is expanding quite rapidly at the moment
in particular with the arm v8 offering
that that's that's now coming out the
ability safe harbor statement we're
going to talk about many things no
matter what we say you can't rely on it
it could change but we'll try not to so
the basic agenda for this afternoon was
have a bit of an overview of the arm
ecosystem and a development environment
and Zack will take us through that and
the arm v8 overview and then I'll come
back in and fill you in on the java SE
and java SE embedded in particular how
they relate to arm and talk a little bit
about the arm v8 java port that is
underway and we'll finish up with a bit
of question time so with that I will
hand over to Zack for the arm overview
and sorry do apologize we have to keep
switching presentations hi everyone so
we have to start by complementing our
audience you are all surprisingly well
dressed for a bunch of Java developers
which worries me do you guys actually
code anymore no I'm just kidding so my
name is Zack Shelby and I come from from
arm and I'm an IOT guy but we're
actually going to be talking about
servers that's really interesting then
we're gonna talk about servers and IOT
at the same time and you'll find out why
pretty soon it really has to do with a
common architecture for hardware um that
we're seeing deployed across really
interesting applications so from really
small embedded low-power coin cells
sensor chips to mobile all the way up to
the cloud so server infrastructure and
that's the ARM architecture and
a lot of people don't know everything
that arm does not you're going to learn
a lot more but in particular you're
going to learn that so we can talk about
what we're doing with Java that's what
we really care about here is what's
happening with Java on all different
kinds of arm arm platforms and we ship a
lot of chips with our partners arm does
not directly make chips so we're not a
chip company we don't produce silicone
we designed the the chip design so the
architecture that goes inside the chips
and our partners should have a lot of
ship all kinds of chips based on arm 10
billion chips last year went to market
50 billion in total so far so huge
numbers of devices with a common
hardware architecture and I'll just pick
out a couple interesting things here so
on in particular we do things that at
two very extreme ends of the spectrum a
lot of you know mobile really well and
all the different types of ARM
processors that going mobile but we do a
lot in microcontrollers so we have over
200 licenses for cortex-m and huge range
of microcontroller applications at the
same time we're starting to do a lot
more in servers so the ARM architecture
is now going into 64-bit server designs
and already now we've licensed 50 of
those licenses so there's actually
designs in progress and available right
now for servers so we're gonna talk
about both of those what does it mean to
do Java on 64-bit ARM servers what's
happening what's the latest in software
and we're also going to talk about the
Internet of Things so what's happening
with Java ME on the smallest of these
microcontrollers arm is also very much
about ecosystem so we we only provide an
architecture but it's much more than
that its architecture its silicon
partners its software tools software
solutions on top of that and we do that
with over a thousand
partners today and as you'll see when we
talk about servers it's a lot about
cloud and open source and Linux so we're
engaged with kind of the whole ecosystem
around around computing so just like
with mobile we're seeing a big pickup
now in the use of arms 64-bit with our
new what we call an arm v8 architecture
in server infrastructure and this is
really exciting because it means we can
do a lot of things with more specialized
system-on-a-chip solutions for servers
so not one size fits all but lots of
specialized chips for really
purpose-built on computing machinery so
for example video versus web loads it
can be very different we'll talk about
that in more detail in a moment the
great thing is that we already have 27
silicon companies developing solutions
for arm-based servers 27 it's not 127 so
we expect to see a lot of um a lot of
variation of the types of solutions that
are going to market so what is this arm
v8 and what's different from the past um
so what what you've typically seen in
the past for example in mobile you
mostly seen arm v7 so this was optimized
for low power mobile applications so
maximizing the amount of computing that
we get per watt so this is the typical
problem with more and more cores we have
GPU compute we have things like big
little a lot of things that have
happened in mobile the newest generation
of the ARM architecture arm v8 is pretty
cool because it includes both 32-bit and
64-bit computing at the same time and
backwards compatible so now a lot of the
newest generations of chips that you see
hitting mobile are already armed v8
and in some cases 64bit the other cool
thing with this is that we're starting
to include crypto acceleration in chips
with partners which is super important
especially for server loads so some
really interesting things happening with
this but I think the most the key thing
here is that you know common
architecture across 32-bit and 64-bit
and that's about efficiency so it's
about efficiency for software we do a
lot in the aah 32 architecture with
compilers with thread face safe software
ever you know supporting crypto
acceleration extensions in 64-bit
software it's interesting because we've
really looked at how do we make this
friendly for Java so Java on 64-bit is
super important for the server world and
we'll talk more about that in detail so
where does this stuff actually get used
and what does it mean to have a server
solution for four armed 64-bit well
really depends on the number of cores
and of course the type of application
let's talk about Korres first so we have
an evolution happening right now we're
seeing 8 to 16 core chips hit the market
now followed by a little bit bigger and
then even bigger and these are on socks
right so we talked about 16 cores to 48
plus cores we're talking on a single
chip and because these are actually a
low-power design to compared to what you
see in servers today that's a lot less
cooling a lot less cost a lot less power
consumed so it's an interesting mix so
right away we're doing things like
storage data so big data type of
applications scale-out web tier stuff
that's what's happening right now and
later when we start to get bigger socks
we start to get into
data analytics telco stuff so things
that require heavier lifting so we have
it we have a whole roadmap of hardware
hitting the market and this takes more
than just hardware it takes the entire
software ecosystem so we're working with
everybody from supporting firmware to
all the leading operating systems up to
the actual middleware and applications
so making sure there's ports of native
applications for arm 64-bit but also
making sure that everything fits
together in the Java ecosystem around
this
and web scale is one of the things we
spent a lot of time on so the the really
exciting thing about web scale is that's
a lot of open source software involved
which means it's been really easy to get
these um these partner projects to go
and pour to get excited about new
architecture this coming support it and
so we've seen a huge interest in this
space form for the the 64-bit server
offering and the cool thing is that
actually the bottlenecks are mostly
having to do with um I oh and memory
it's not about raw computing performance
so if you look at the graphs it's it's
mostly that and the other thing is that
that varies a lot between type of
application right so doing something
around video versus um typical web
serving might require a very different
sock design right so it's not a one one
chip that's all and the cool thing about
the way we we do hardware with partners
is that they can really optimize for the
particular load they're going after both
in the sock and also in the in the
server hardware design but it's a common
architecture so when we do any of the
software support it's the same software
regardless of the type of socket is um
it's the same Java that runs on all of
these servers
now let's talk about the other extreme
end of the Java spectrum and that's
embedded all right so we just talked
about mobile which all of you probably
know pretty well up to servers in the
cloud down to really small and this is a
great example of small so on the right
is a cortex-m 0 plus and it literally
fits in your finger like that um that's
a little bit too small for what we want
to hit here with Java ME you which is
we're going to talk about on embedded
but it's close we actually see cortex m3
and cortex m4 cores going to this type
of size as well so very small very
low-power very cheap embedded socks
which now can run Java as well and we're
not talking about small numbers out of
the 10 billion chips that went to market
based on ARM architecture last year over
3 billion of those where cortex-m so
very small microcontrollers so the
beauty about Java is that if we can
actually make that a common development
platform for Java me8 which is exciting
because it's the same as java SE in many
ways that's a huge developer ecosystem
that we can tap into so it means a lot
of new people developing for embedded
i'm using java and why is that cool why
don't we need lots of new developers
developing for embedded well it's
because i OT is going to be really
disruptive and it's going to be
disruptive because we need new solutions
for society and because um we have a lot
of startups that can provide them and
when there's startups there's new
innovation and new things and you know
the Raspberry Pi electric in arduino to
name a few great examples of where
there's lots of innovation happening we
see um Java ME adding to that really
nicely if we can make it available to
everyone and just the fact that most of
the solutions are going to be coming
from startups in the future really tells
it all so a lot of those developers
younger developers coming in they know
job out of school already it's
comfortable for them applying that to an
embedded device is pretty easy
this is something we've been working on
together with Oracle is how can we make
this happen right how can we provide a
native platform that works across all
these different microcontrollers from
armed partners along with the same Java
ME platform from Oracle and we have
something that we call em bed + Java ME
and we actually announced last year at
javaone and our men that is a platform
for making embedded development easy
across platforms so that includes
hardware design guidelines software so
actual SDK for the native abstractions
operating system features etc because
always under Java you need some native
right it's not something that runs on
bare metal and that does that and it's
about component sensor drivers etc so
all the underlying stuff you need for a
hardware platform it also includes a
pretty large ecosystem of hardware
providers so some of our silicon
providers providing all kinds of Deb
boards that are compatible with the
software SDK as well as tool chains so
we support most major tool chains with
the with the software and the cool thing
of that it means that Java ME built on
top of em bed can actually very rapidly
go to all kinds of microcontroller
targets in the past this has been really
hard because we actually had to go
import Java ME to each new target one by
one that's so it's a pretty painful slow
process and with just a huge diversity
and embedded of socks you'd never be
able to cover that range of devices with
em bed we can because we actually have
the driver how portability across these
and we share a common architecture
between the chips and so something that
terrence bar who leads Java ME for
oracle announced this morning is that on
Java any 8.1 now available actually
include
support for this for a free scale based
cortex m3 platform the K 64 and you can
actually download that as a developer
preview right now which i think is
really cool so you can get the tools it
goes and builds on this to run on the
Emmy 8.1 release so check that out if
you've been scared of Java ME in the
past actually I think you'll find Java
ME 8 to be a really nice solution so
it's it's much much closer to java java
SE eight then with that I hand it back
and David exact so that's a good
overview of the particularly the
hardware ecosystem and where these
devices are scaling you know how far
down and how far up they they scale and
this talk is not about Amy what we're
focusing on here on the software side of
things in Java is jab SE embedded and
java SE on the arm v8 ship so there's
often a bit of confusion about Olivia
how these things are positioned you know
where does any fit where does he fit and
pretty much it's a it's a boundary
that's always shifting depending on the
capabilities of the hardware so if we
look at the history of Java on arm then
you know it did start way back in 2001
and that was a Java ME implementation
CDC and cldc on the ARM chips because
they were very small systems you
couldn't fit hot spot those days on any
of these systems it just wasn't it
wasn't feasible at all so for a long
time there you know the arm support for
java was pretty much it just in the emmy
world but as always the hardware is
evolving the capabilities become greater
you suddenly be able to you can get a
lot more processing power you can get a
lot more storage you get a lot more
capability for the same amount of dollar
and suddenly we're starting to see or we
were starting to see embedded devices
that no longer look like embedded device
they look like normal computers only a
bit smaller a little bit more resource
constrained and 2007 we had the first
java SE embedded implementation on arm
in 142 and you know things a little bit
slow but over time sse embedded has
expanded into a range of nut of
platforms and it's always been playing
catch-up with se but we decided to put
an end to that about 2009 we try to
catch up and by 6 225 we were releasing
SE embedded in parallel with SE
releasing at the same time we finally
got the two trains in sync and we were
releasing them together and we've
continued that through with AC embedded
7 which was the first time we released
across all of the platforms in sync for
a Java major release so that was a big
milestone and just after that in 2012
the market are they you know the
marketplace shifted again that arm chips
were no longer just to be considered
these embedded Emmy related or Jesse
embedded related devices but arm was now
a contender in mainstream server like
computing environments yeah this chip
had grown up so we had a project there
to produce not just an SE embedded
implementation on arm but a full java SE
implementation on armed with jdk 7 and
from there things have just gone to
strength from strength to strength so if
we look at this year it's actually been
a very big year because we have now
released earlier this year java SE and
SE embedded 8 back in march and after
all those years of SE embedded lagging
behind SE we finally decided to get one
up on them so we actually released an
eight you 6 update for SE embedded and
jdk on arm back in i think it actually
shipped in august this year so we've got
a little bit of a leap frog there on the
SE guys they haven't come up with a 220
yet that's still coming down the
pipeline looking ahead what we have
available now that you can see as a demo
it's a preview available is java SE on
arm on the arm VA chip
okay fully-featured java SE product
running on arm v8 again that's where we
are at the moment so the platform has
been growing and what java SE 8 the
major things about java SE 8 was all
about evolving the platform and it was a
major milestone for the SE platform we
are evolving the language by introducing
lambdas and default methods so that we
have an updated much more modern much
more future proof programming model for
the developer using Java this has really
set the scene now for job of 10 11 12 as
I say that keynote Java for the next 20
years along with that there was a lot of
library evolution in particular the
introduction of default methods allowed
us to evolve the collections so that we
could introduce the new streams api's
and introduced a complete framework for
parallel processing something much
higher level than the primitives that we
provided previously you go back you
could start with threads and
synchronization and monitors and on top
of that we have Java util concurrent to
provide a nice tool kit for really low
level systems programmers and then on
top of that we then got the fork joint
framework and finally we have an
abstraction through streams that provide
transparent parallel processing where
you can express the solution in a very
obvious and clear way you know that
functional style of programming with a
functional program is I don't they
finally got it ok so the libraries have
evolved language evolved hotspots a
little bit slow at evolving here it's
it's big it's clunky it's old it carries
a lot of baggage but we do try to evolve
it where we can we got rid of the perm
gen which had been weighing it down a
little bit over the years we tacked on
some new bits on the side the jsr 290 to
invoke dynamic method handle support
there were more improvements in in that
particularly motivated by lambdas you
know the jsr 292 mechanisms really
provide the way to implement landers
as a full feature component of the vm
not just this some kind of syntactic
shortcut that the compiler just turns
into a bunch of inner classes behind the
scenes that would never a flow so we had
to provide a much more performant
implementation through the jsr 292
mechanisms and we introduced things like
native memory tracking to try and get a
better idea of how your program is using
native memory how the vm is using native
memory so we can manage it for some
reason whenever we give people a vm to
run they always manage to run out of all
the resources they're trying to manage
and so they're always trying to figure
out what's going wrong and what they can
do to to deal with that one of the
things we also introduced in se8 and we
it was important for us to introduce
this under the SE banner was the concept
of the minimal vm the ability to say
well it's ok to produce a vm that
doesn't have all the bells and whistles
there are a whole bunch of things if you
read the specifications that are
optional components of the Java platform
or optional services provided by the M
but we always provided them we always
provided the entire the entire kit but
the minimal vm was a way of saying well
we now want to be able to target smaller
environments we know that i see embedded
is targeting smaller environments and we
want to be able to do that in a
well-defined way not just some ad hoc
mechanism for trying to throw out things
that you might not need and related to
that we had configuration evolution with
the introduction of the compact profiles
we need it away mmm excuse me under my
voice is not going to last year we need
a way to support the embedded product
and the embedded product says I don't
have all the capabilities I don't have
all the footprint available as the SE
platforms typically do I need to be able
to have a stripped-down java runtime
that has just enough for what my
application needs and none of the stuff
that I don't need so I'm not wasting
resources on things that aren't needed
but again we wanted to do that in a very
well-defined and specified manner so
three compact profiles were introduced
to give you three tailored runtime
environments and these were all
described in the Java enhancement
proposal 161
but the basic idea was provide the
significantly smaller based java runtime
that could then be used on embedded
devices and partnered with a a custom UI
stack particularly a javafx stack on
these devices to go along with this we
provided a new tool that the developer
or the deployer could use so they could
select what they want they saw I'll have
compact one with a minimal vm throw in
javafx and some debugging support I
would you like char sets with that odd
no thanks but I might have a locale ok
there are all sorts of optional
components that can be thrown in to get
you from the minimal type of system
through to a full-featured a JRE
environment that you're used to seeing
NSE and one of the motivations for doing
this as Oracle has talked about from
probably last three years now was this
notion of getting this Emmy SE
convergence happening but there would be
a mechanism for transitioning from the
higher end Emmy platforms cdc foundation
profiles plus extensions into an SE
platform and that is what we have now so
looking at this visually the compact
profile simply divide all of the class
libraries into three groups so you can
then layer things together you start you
have your vm and you have a choice of
VMS and client vm server vm minimal vm
you pick the compact profile that has
the set of classes that are needed to
buy your application and you have some
optional components in contrast the
normal view of a full jari is a bunch of
functionally or later things bunch of
core classes an extra library for this
and the AWT or desktops that for that
but now we have a more structured
approach and if you look at what's in
the profiles not that I expect you to be
able to read any of this you know
compact one is pretty much every every
day class that you use it's everything
in java dot lang it's everything in java
don't util it's everything the new Java
dot time java dot security plus a bunch
of other things that sometimes get
dragged along some of the things in java
x dot security it's got all of java.net
occasionally some specialized sub
packages don't get included
for you know some less commonly used
networking protocol for example but most
of the foundation classes are in compact
one and if you've been following the JDK
nine jigsaw effort compact one is pretty
much what they're calling the base
module and that's what all of your for
your core classes are and then compact
two builds on that by providing some
additional capabilities in particular
the ability to go outside the single
process world we reintroduce the RFI
support and along with that for a lot of
the network communications XML support
as well so a lot of devices a lot of
even stand alone and jvms are
communicating within a network and they
need to use protocols that are using XML
as a data transfer format by the time we
get to compact 3 we're adding back
things like mm java.lang management
support java.lang instrument support the
sort of more advanced things that you do
on a JVM that you still may need to do
an embedded environment so we can add
those back in a compact 3 and of course
you need the functionality you have to
pay a little bit extra in terms of the
static footprint and then finally we
just have the full java runtime stack
the JRE the one that to everyone's used
to know your jdk is a JRE plus a bunch
of tools like Java C Java p et cetera so
you can build up as your application
grows you say well we put some more
functionality in we're going to switch
from compact one to compact two or the
more likely scenario is we're upgrading
our hardware we can now support compact
to which means we can now support this
additional functionality so you can grow
your application in that way once you
have the hardware capabilities to
support it there were some SE embedded
specific things that we needed to get
into aid things some of these features
have been languishing a little bit so we
finally got Java flight recorder support
into se8 for the embedded platforms no
Mission Control you've got to manually
or you've got to use other mechanisms
for processing the event logs etc and it
still does require a full jo
because Misha the Java flight recorder
itself relies on some of those ap is
that otherwise would be stripped out in
the compact profiles but it's a good
step that we have flight recorder
support in there the minimal vm was a
key thing that we wanted to introduce in
se8 embedded because we did need a way
to strip down the JVM we wanted to get
down to something about three and a half
meg or even smaller for live JVM on
these platforms so pretty much this is
the bare-bones vm it's a client-based vm
it only supports in serial GC because
we're assuming you're ready going to
have a really small heap so there's
other GCS and not going to do you any
good whatsoever we don't have any of the
fancy management aspects or the
debugging aspects is no JVM TI there's
no need in method track and native
memory tracking we don't have class data
sharing the profilers can flat profile
is gone not that anybody really misses
it GFI on the management EP is this is a
bare-bones being vm for a barebone
system if you've got a really
constrained environment that you want to
deploy on then this is where the minimal
vm can be used as the smallest
configuration of this java SE platform
you know this is where you make the
little hop from the emmy side to the SE
side we try to make it instead of being
a massive leap as it has been in the
past there's now a small step to get
from Emmy to se there's all the general
performance improvements going on
particularly from a PPC we did a bit of
code cache management changes there to
get the prepared performance happening
and in particular for arm we were
looking at leveraging more capabilities
of the arm hardware and particularly the
advanced SIMD capabilities the neon I'm
not sure whether to call it a chipset or
a whatever it happens to be but those
neon capabilities are now being
leveraged in the server jit compiler so
that we get higher performance out of
java SE embedded on arm systems so that
was se8 from and we've been trying to
play catch-up here and keep up to date
you might be able to imagine that while
all of the SE guys are busy making all
these new features we've been talking
about lambdas and default methods and
all this other stuff for years and
they're busily hacking away on their x86
and spark systems are some better guys
again what we got to try and keep up
with that yeah every time they do
something for x86 we've got to go and do
it on PPC we've got to go and do it on
arm we've got to do it got to do it
wherever we have to do maybe it's a more
constrained x86 environment so it's
always been a bit of a rush to play
catch-up so there were a few things that
didn't quite make it out the door for
MSC eight embedded that we would have
liked to have put out for a c8 embedded
so we decided then to get a leg up on
the SE group and we put out SE embedded
at you six so this was the first release
poster a decade completely independent
of the mainline se release which has
only come out with a 220 which I think
has just been released but of course
it's important that we maintain
up-to-date with the security releases
with the critical patch updates so it
was based on the eight you five CPU
release and what we put into that some
key features there are two things we're
always doing with embedded these two
girls never go away make it smaller make
it faster okay and as you probably aware
those two girls are often in direct
conflict with each other but we have got
some additional changes for reducing
static footprint for constrained devices
we also want to improve performance on
our higher-end devices we had some other
arm specific enhancements coming through
what I mentioned and there are a few
platform specific things you know FX
would now support the imx6 platform for
example so we did two things to help
reduce static footprint with eight you
six and the first thing was that our arm
v7 builds switch to using the thumb to
instruction set so the thumb to
instruction set allows for a much more
condensed representation of the things
you want to execute on the hardware so
we end up with a smaller binary size
that filled us through to having reduce
static footprint which can also take a
small amount of pressure off the amount
of that dynamic memory that's needed but
we don't lose any functionality we're
still fully compatible
all with non thumb to binaries native
code that the application may be built
with so we managed to shrink the vm a
bit but we haven't lost any
functionality or we're not requiring
anybody to change their apps to use
thumb to as well it's completely in the
operative and the second thing we did
was to try and squeeze even more or
compact even more than minimal vm by
taking advantage of something that's in
the canoe GCC toolchain are called link
time optimization and as you might guess
from the name the idea is of at link
time the linker can have a good look at
all of the things you're using all of
the object files and you can throw out
the stuff that you don't need and so the
actual resulting live JVM then becomes
even bit smaller and we've saved a bit
more footprint there are a few caveats
with that some things you have to change
the way you do with them the link time
optimization it doesn't always guess
correctly which bit of code is used in
which bit of code isn't used but overall
that helped us to get some footprint
improvements on the performance side we
wanted to get TF compilation up and
running for the server vm across the
embedded range in particular on arm if
you're not familiar with Ted compilation
hopefully you familiar the fact that
there is always historically being the
client compiler c1 and the cervical
policy to see one does limited
optimizations has really fast startup
but its maximum running speed is far
less than the server compiler the server
compiler takes far longer to actually
ramp up and actually deal with all the
hot spots in the code which is where the
name came from but ultimately it
produces far superior optimized code so
the idea has been floating around for
many years was to provide a way to sort
of transition between these two so the
idea is that we combine all of this into
one binary it looks like you've got a
server vm but actually built into it is
the client jet as well and when you
first start up initially c1 compilations
will occur as they normally do in
relation to the interpretive code and so
you get that benefit of the fast startup
time by using C 1 and C 1 then inserts
the profiling hooks that are used to
control
when the situ compilation takes a
perfect okay so then you can move over
the longer term as your application is
running to get higher optimization level
and so get optimum performance for long
running applications so the idea is to
try and get that balance between startup
and long-term performance not every
application is amenable to tier
compilation not every application will
get a speed up from it so by default
tier compilation is not enabled so you
have to enable it using the dash a dash
X X colon + tiered compilation just to
turn it on a benchmark result I never
paid too much Koreans to these things
you can always find something you can
run to demonstrate the point you're
trying to make but looking at this as an
example de Campo benchmark on a first
iteration shows an average of eleven
percent improvement now if that
translate to something meaningful in
your application go for it you stared
compilation if the Linpack thirty-three
percent improvement in time and one
hundred percent improvement in mega
flops per second if that kind of
computing profile matches your
application then th compilation is going
to work for you but as anything with all
of these are performance improvements
any kind of optimization it's totally
dependent on what you're doing depends
on your application and the platforms
that you're running on but it's another
tool that's in the toolbox the other
thing we wanted to play catch-up on with
SE embedded was enabling g1 now I just
misspoke we didn't play catch-up on
embedded for this because g1 if you're
familiar with it is what we call the
garbage first collector it's completely
different design garbage collectors
compared to the other collectors that
have been in hot spot for many years
with zero collector the parallel
collector concurrent mark sweep
collector they all have a particular
style the way they approach are finding
the live objects moving them around and
then you've reclaimed the dead space
garbage first as the name suggests
actually tries to track the dead objects
so that you actually get rid of the
garbage first and that's a GC that's
been being developed over
of years it's been an SE for a number of
years now it's still evolving and if you
really want to know the details of that
please do consult the SE documentation
but the key thing about g1 is it was
developed and tuned for big heaps really
big heaps and that's you know completely
opposite of what we expect to find in
the java SE embedded world so in java SE
embedded g1 is explicitly deactivated
you can't turn it on it just doesn't
make any sense there we don't provide it
there we don't support it there but as
soon as we provided a JD JD ke on arm a
full se implementation it made sense to
provide all of the AC capabilities
because we're now not talking about an
embedded environment we're now talking
about a server like environment iris
Serena I must apologize i keep saying
server like these these chips are
server-based chips and came we just tend
to forget that they've grown up from
where they are where they've been so we
ported this in eight you six so that JDK
on arm would now have the g1 garbage
collector available and for non
technical reasons it's a technology
preview so it's not officially supported
but it is out there in the JDK unarmed
product as of 86 the final bit of
optimization and improvement that we did
with se embedded specifically was to
allow some customization of the class
data sharing feature now familiar if
you're familiar with class data sharing
what's EDS allows is the ability to dump
an archive of all the classes that were
loaded on the boot class path and then
you can use that archive the next time
you start the vm so that it doesn't have
to go through an open RT dodge our find
all of the class files defined within it
pars all the classes and set up all of
the internal data structures of the vm
so the idea is that if you do this and
you share that archive across multiple
VMs this is running on the same machine
then you get a reduced dynamic footprint
for that machine which is great but you
also get a reduced startup time because
you avoid all of that overhead of
opening class files and
them and dealing with all that kind of
thing so CD s provides benefits for
startup it also provides benefits for
dynamic memory if you're using more than
one vm on a system but the problem with
CD s was that you know we had made a
decision as to which classes should go
in an archive we ran a bunch bunch of
benchmarks in SE land looked at the
classes that they loaded manipulated
that list and said right this is the
content of an archive and that's it you
can't really play with it you'd have to
hack around all sorts of things to be
able to deal with that but in the
embedded space set of classes that were
chosen completely wrong I'm pretty sure
that nobody really wants a WT and swing
in there okay so we needed a way to
customize that and so we customized it
we provide three new flags dump loaded
class list basically says to the vm hey
when you finish running the application
dump all of the classes that were loaded
from the boot class path into this file
so now you've got a complete list of all
the classes that your application was
using and now when you dump an archive
using xshare dump you can say hey use
this class list file as the set of
classes to be dumped out so now you've
got an archive that's tailored for your
application and you can also use the
shared archive file flag to change the
name of the archive you can now have a
per-application archive each one
customized for the different
applications that you want to run in
your environment so it just gives you a
lot more flexibility there to again just
squeeze that extra bit of performance
whether it's startup time or the dynamic
memory if you haven't be in a sharing
environment
so where are we now I'm v8 the ser v8
port is collaboration the started
learning is a little over a year ago now
Henrik store put out a press release
July last year now by working closely
with arm to enhance the JVM adding
support for 64-bit ARM technology and
optimizing other aspects of the java SE
product for the ARM architecture
enterprise and embedded customers can
reap the benefits of high performance
energy-efficient platforms based on arm
technology in other words everything
you've expected in the standard SE world
whether you've been using x86 chips or
spark chips or whatever happens to be in
your classic server environment world
all of that is supported on our and
particularly the arm VA chip okay the
goal here is to provide a full-featured
java SE implementation on the arm v8 for
these server enterprise systems
optimized for the arm v8 and so we've
been working very closely with armaan
this are they've been providing a lot of
assistance with development resources
and we've also been working very closely
with key arm v8 64-bit partners such as
applied micro now who've been using this
they're the x-gene ship that will be
running on in the demo so what's the
state of the port at the moment okay we
have a full jdk bill it's headless at
the moment it's based on the hard float
ABI and it's java SE 8 based at this
time it's a little bit too hard to play
catch up while you're porting to a new
environment and try to keep up with 86
so it's based on SE eight it's
functionally complete c1 support see to
support tier compilation g1 flight
recorder JDM TI serviceability
everything everything you expect to find
in a full java SE platform
it's passing one hundred percent of the
j ck which is always a good thing and in
terms of the other functional and
regression tests you know we're getting
up to 98 a half percent in the
regretting the functional testing
ninety-five percent in the functional
testing so still a little bit of work to
be gone it be done there you know this
is not a release product yet this is
only at a preview stage and the initial
performance work is happening on this
and the application stress testing such
as using Hadoop all of these things are
being applied to it at the moment we've
just made this available as an early
access release within a managed private
beta program okay I'm afraid you can't
download this at the moment but if you
work for certain companies you may be
able to sign up for the program the key
arm v8 licensees and partners are
participating such as AMD implied micro
arm of course and many others so this
beta program is now active and we're
getting a lot of use out of the system
so that we can get more feedback on the
port and of do tuning etc so if you want
to see a demonstration of this it is
being demoed down at the arms haul up
around across wherever we are the arm
stand in the exhibition hall at stand
5112 and there you'll see I'm VA EA the
jeddak Arvad a running on the applied
micros x-gene system over ubuntu the
unfit port is kind of unique i'm pretty
sure i mean i haven't been a rounded
oracle or sun since you know the
beginning but i'm pretty sure that most
of the time when we do Newports we do it
two platforms that have been been there
for ages but they just weren't ones that
were being targeted by Java you know we
started on x86 and spark and we've crept
down into arm PPC or the original arm v5
v6 I'm b7 as it goes on I think this is
the very first time that when a brand
new architecture and you're on the 8th
is radically different to the previous
arm architectures it really is
completely
you and for the first time we have a
port happening of Java to brand new
hardware okay we have a chance to be on
the bleeding edge and of course if
you're on the bleeding edge sometimes
you get cut but overall the porting
experience has been terrific experience
collaboration with arm and and partners
and licensees such as applied micro MD
has really been a great experience the
port progress has gone very very well
it's been done very quickly we're very
happy with where we are with testing and
performance at the moment and now I
can't share any performance results with
you I'm afraid and we were all so
pleasantly surprised at how well we
could leverage the work that had
previously been done on the 32-bit arm
port within the vm there's a lot of a
lot of stuff there that doesn't have to
change her v8 and obviously there's a
lot of opportunity for optimizing for v8
and the port work actually exposed a few
bugs in the existing arm 32 bit code
that we had which was a good thing as
well they're not so good it's pretty
typical when you're working on the
bleeding edge you review new hardware
not just the chips the boards that
software chain the toolchain everything
okay they're teething problems with
getting licenses sorted and agreements
and all this kind of thing and sometimes
you just can't physically get the
hardware that you need in the time frame
that you like to do it but you know that
that's par for the course when you are
on the bleeding edge of technology like
that so overall yeah this porting
experience has been really good now some
of you probably how many people have
heard at the OpenJDK a arch 64 project
oh good I know how to talk about it okay
there has been there is an effort in the
OpenJDK community to create an open port
for our v8 a 64-bit port from VA of the
openjdk and there's a link there to that
project and that project is in the
process now of getting integrated into
jdk 9 they want to bring their code into
JDK night and that port it's great the
community has done this they've seen a
whole they said hey you have new
architecture Java doesn't run there
let's go and make it happen which is
fantastic but Oracle as a large
corporation with a massive investment in
the Java platform also has its own ideas
and goals of how to deal with Java on a
new architecture so if you want to read
more about that then I can only refer
you to Henrik stalls blog where it does
discuss you know some of this rationale
why they we have to seem to have these
two competing ports farm I think I
didn't bit of competition is good here
actually you know if they do something
fantastic we've got to beat it if we do
something fantastic they've got to try
and beat us and that's only going to
make the platform better whether you
choose to go with the open
implementation or you want a fully
supported product that you can purchase
so future plans and considerations where
are we what's going to happen well the
plan is to release sometime in 2015 we
want to get out onto the SE release
train so one of the SE update 8 Update
releases that comes out in 2015 that's
where we want SE on our v8 to appear so
definitely going to be our except for
that safe harbor statement course
definitely going to be out next year and
then of course on nine now a couple of
years ago 9 was going to be coming at
the end of 2015 it's now shifted out the
2016 or beginning because se8 slipped by
a few months as well but will you'll see
our v8 support coming out next year 48
you and then nine so that basically
everything that's being done on the SE
development for se9 se10 whatever
happens to be armies to our v8 is just
going to be one of the standard
platforms you won't even think twice
about it
of course what as this work is going on
we're looking at performance
optimization opportunities targeted
benchmarking profiling tuning there are
all sorts of interesting hardware
aspects to the arm v8 systems
cryptography support even more advances
to the neon s mi deve support so we want
to have a look at the type of high
performance computing aspects what we
can take advantage of there and
something it's a bit closer to my heart
is the memory ordering optimizations
yeah I deal a lot with threading
concurrency synchronization memory
models memory barriers atomic operations
and there are new instruction store
release load acquire which might give us
an opportunity of producing a more
streamlined way of supporting the Java
memory model on the arm v8 ship we tend
to over fairly well the memory model
support in hot spot basically evolved
from total store ordered systems spark
and x86 when memory ordering was always
a secondary consideration and we forever
been trying to track down all of the
areas where there are ordering issues
when you run on a non totally stored
system such as arm and PPC so it's very
good that we've got an opportunity there
to actually try and optimize that code
for the new architectures that are
coming out and of course we always want
to look at expand the platform testing
so there are as I said there are a lot
of licensees for the arm vein
architecture and they're all working to
produce different types of hardware so
for example one of the things we'll be
looking at is KTMs new 48 core Thunder X
system I think I want one of those yeah
it just sounds like the kind of thing
you want to go out and buy I want a
thunder x absolutely and of course if
arm continue to evolve the architecture
they continue provide new capabilities
in the architecture then we will be
doing the best we can to track those as
closely as we can as quickly as we get
hardware coming out that support it so
that's what we're trying to do and with
that I'll open it up to questions and
thank you all very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>