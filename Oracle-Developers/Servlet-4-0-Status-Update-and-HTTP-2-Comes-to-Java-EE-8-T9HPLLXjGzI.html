<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Servlet 4 0  Status Update and HTTP 2 Comes to Java EE 8 | Coder Coacher - Coaching Coders</title><meta content="Servlet 4 0  Status Update and HTTP 2 Comes to Java EE 8 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Servlet 4 0  Status Update and HTTP 2 Comes to Java EE 8</b></h2><h5 class="post__date">2016-09-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/T9HPLLXjGzI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay good afternoon how's everyone doing
having a good show all right I'd like to
thank you all for coming my name's ed
burns and I'm talking to you today about
sir look four point oh status update and
HTTP two point O comes to Java here's
our safe harbor statement it's a great
honor to be here today for many reasons
but I have always been a big fan of
believer in and participant in JCP and
JCP is a total community process it
really is and the way that they give the
spec leads latitude to lead the jrs as
transparently as they want to is
something I really appreciate so servlet
is an even older technology than jsf
which is the other thing that I work on
and we could put a lot more names on
here that have worked on servlet over
the years but this is just a current
expert group and you know it's been it's
always been a true community effort in
that it certainly applies to serve it as
well here's our agenda I think we'll
have enough time for questions to start
off with the big picture how servlet
fits into the bigger picture then a bit
of a deep dive you might even think of
it as an aside on the core HTTP protocol
itself in particular the HTTP to
protocol that is then we'll talk a
little bit about servlet reactive
programming taking a quick look at
what's coming in java SE 9 regarding
flows and publishing subscribing and the
reactive api there a look at how that is
currently exposed in a somewhat reactive
fashion in several a 3.1 and a little
bit of discussion about how we could
take that forward even better in server
four-point-oh then the heart of the talk
the new and planned improvements insert
a four-point-oh most notably server push
another aside java sd9 support for HTTP
two there's a session going on now that
i would like to be in myself but it's
the session from michael mcmahon about
the HTV to client
and it's the full deep dive on that I'm
just going to touch the top of it and
then summary in questions does it sound
good alright so here's the slide you've
probably seen a number of times so far
many of the other talks you have seen
probably included this slide at least
the ones from Oracle and the ones that
you may have seen talked about how
important HTTP two is through java ee 9
and java ee 8 and servlet is where that
happens so plan of record right now is
that servlet is going to be the thing
that exposes HTTP to to the rest of the
api's but yeah well we'll cover that so
let's talk a bit about the dependencies
here I'll spend a good bit of the
session talking about a core HTTP two
but as it turns out most of hcp two is
about reducing the perception of latency
and thus is kind of transparent to all
the other upper layers of the stack so
all these other layers of the stack are
going to be getting it for free
basically just by depending on servlet
now JSF and jax-rs over here will depend
on servlet mainly to leverage the push
builder API which I'll cover but that's
the largest surface area of any new
feature that's HTTP to specific that's
actually in the core servlet
specification servlet will depend on
JSON be to enable the simple marshaling
and on marshalling of pojos to and from
json which i'm very excited about
servlet and security will depend on each
other this is a two-way dependency here
to coordinate authentication and
authorization servlet will likely depend
on configuration to enable
externalization of the configuration in
a war file and servant will also very
likely depend on the new health check
facility to enable an easy
implementation of a standardized health
checking which is a very important thing
in a micro service
environment one where you have
containers as a service and these
containers come up and they come into
service and they need to know hey are
you on not just are you on but are you
on and can you contact your downstream
service because when you build
microservice based architectures you're
going to quickly run into the
relationships between the different
services and how to make sure that they
are able to be managed and that's not
something that is like totally clear cut
so it is actually very good to
standardize this health check thing you
might think it's pretty simple it's just
a can you respond with 200 okay some
people think that's a good enough health
check but actually you need some more
when you have a network of services so
it requires some deep thinking that an
expert group is very good at doing so
that's the big picture so HTTP to
perception is reality especially with
web browsers so hdb to this is right
from the RFC there enables the more
efficient use of network resources and a
reduced perception of latency by
introducing header field compression and
allowing multiple concurrent exchanges
on the same connection that's basically
the heart of it and I you know the RFC
is actually pretty readable if you want
to take a look at its RFC 7540 and but
they do a great job of summarizing it
right there on the front page the good
news first HTTP two is really just a new
transport layer underneath the existing
HTTP 11 it's the same request response
model they're not adding any new message
methods to the set of methods there's no
new verbs there's no new headers more
importantly there's no new usage pattern
of how you're supposed to use it it's
still request response based they're
still using URLs in the same way so when
they designed it they really did not
reinvent the wheel they are indeed
standing on the shoulders of what's come
before so going back even further we can
take a look at the classic Stephens
textbook here for where they got
inspiration I believe
for designing bless you hdb too so this
is the familiar old seven-layer OSI
protocol stack and you know going all
the way from the physical electrical
ones and zeros up to the application
layer which in fact hdb is an
application layer protocol but it has
concepts that are kind of like the lower
levels of the OSI stack you've got a
connection concept which really and the
OSI stack comes from the transport layer
you've got a frames concept which comes
from the network layer really you've got
a session concept which is you know I'm
sorry you got a streams concept with
kind of which kind of comes from the
session layer and on top of all of this
they've now stuck HTTP 11 so they've
basically done a lift and shift on top
of some new concepts there I'd like to
look at HTTP two from a few different
angles now to help you get a better
understanding of what the why it's
useful and you know how to use it first
the socket angle so in HTTP 10 sockets
are kind of seen as the throw away
resource you just you know open up as
many sockets as you like well actually
browsers kind of have some rules on this
where they limit the number of sockets
that are open and this is one of the
workarounds that people had to do to get
better throughput one thing they don't
say very clearly in the RFC is that
we're trying to give all of the web
developers up there out there that have
had many years to develop very clever
work around such as the domain charting
and image sprites and lots of parallel
sockets being open all these browser
hacks basically that people had to do
multi hosting so you can get around
various browser rules make it so they
don't have to do those work arounds
anymore and this is how they did it so
the first thing your sockets are a
throwaway resource the specification
says very little about how they're used
and browsers are free to open many
sockets to the same circuit so
server on the other hand an HTP two
sockets are seen as a scarce resource
and the specifications has a whole lot
about how they're supposed to be used in
fact when you have a connection between
a client and a server in HTTP to their
supposed to be only one socket that's
open at a time and so they are able to
really come LS all of these different
former sockets down to one and this
really will save a lot of network
resources on the server side and that's
kind of really important for achieving
better density and all of our other
talks that we've talked about a
multi-tenancy and packing more stuff
onto the server side makes it a little
bit easier when your clients are talking
HTTP to another angle is the adoption
angle who here has been working on htb
since 1991 or so 91 all right good deal
so that was very few people can say that
and when it was first came out it was
pretty simple do so do you remember who
that ncsa Oct you do you remember the
server who who'd ncsa oh yes yes yes so
I had a very good fortune to be an
undergrad at U of I and was working on
ncsa and actually had who who's sitting
under my desk so I remember what it was
like anyhow it was designed to be easy
to implement if it was you know it's a
text based protocol doesn't have any
flow control at the protocol layer easy
to write a parser very simple socket
life cycle open clothes right if you
look at HTTP too it's much more
complicated to implement there is a
state machine even though it's still a
stateless protocol there is a state
machine now it has a flow control layer
it has this whole header compression
thing which I'll talk about and it also
has binary framing so I just like to
think about the fact that the spec was
designed to be easy to implement and
really at the time it wasn't a given
that HTTP would win there was other
protocols out there there was
ways there was gopher anyone remember
gopher so right so all of those other
ones were much harder to implement so
simplicity wins out but it also leads to
hell these turned us hacks that people
had to do over the years so kudos to
them for actually getting HTTP to
finally done because it is very good so
these are the big-ticket features in the
protocol itself request-response
multiplexing binary framing stream
prioritisation server push header
compression and you know how do you get
there upgrade let's look at each one in
turn briefly this request response
multiplexing thing lets the protocol do
more things with a single TCP connection
that's what I was talking about when I
had that graph and all the stuff is
coming together it is a fully
bi-directional protocol and that's
enabled by defining some terms right so
you've got a connection which is
basically a TCP socket you have a stream
which is a channel within that
connection a message which is a logical
message such as a request or response or
also some of the flow control and other
kinds of meta information is done using
messages and frames because as an OSI
analogy and other analogy there that
they also have the same terms connection
stream message and free and they have
the same meaning there as well so this
is the first evidence we see of reactive
being in the Corps HTTP protocol itself
this flow control you know that they
have they came up with this term back
pressure but really it's basically just
flow control I challenge someone to tell
me a difference between back pressure
and flow control during the Q&amp;amp;A or maybe
after we're done but they seem like the
same concept to me I don't know why they
had to invent a new term so this is a
graphical depiction of what I just said
you know you've got your connection and
you got a number of streams in the
connection you have a number of messages
within each stream and each message is
composed of a number of frames
this is what the frames kind of are
looking like pictorially the frames have
a number each frame has a number odd
numbered frames are originated in the
client even numbered frames are
originated in the server this is how you
don't ever get them you know confused so
here we can see we have stream 2 is
coming down with the data well actually
you know first we've got the headers
from stream 2 then we've got the data
from stream 2 and we've got another
stream for coming down and at the same
time over the same connection we have
stream 7 with its headers and data and
stream 9 headers and presumably they'll
be data following over there as well so
it's another ayah new idea from 1960s
that we're having now brand new for us
today this is what a frame looks like
another thing that's nice about the
frames that was a problem with HTTP 11
is the head of line blocking problem
where the spec itself said that the
requests had to be returned in the order
that they were I'm sorry the responses
have to be returned in the order that
they were requested so you get this head
of line blocking problem and using this
binary framing you no longer have the
head of line blocking problem one
particular frame type that I'd like to
call to your attention here is the
window update frame this is the one
that's used to do the flow control and
another one is the push promise frame
this is the one that the server says
when okay you know I know you didn't ask
for this thing but I'm going to give it
to you anyway so that's the push promise
field let's compare the protocol people
like to look at the old-fashioned you
know get / index.html so there since
it's a binary protocol you know you can
only represent it sort of in a pseudo
fashion these things here with two
colons are actually pseudo headers and a
pseudo header is a special header field
that is defined for things that normally
would be in the request line or
our headers that have to always be there
so you know that there's a pseudo header
for the method and a pseudo header for
the scheme and a pseudo header for the
path and regular headers of course are
still just prefixed or suffix with the
colon pseudo headers have to be prefixed
and suffix with the colon also they
headers themselves must be in all
lowercase or the it's considered an
invalid request but the spec says the
strings must be compared in a
case-insensitive fashion so that's the
kind of little subtle bit of the spec
that is very important to be there to
have good interoperability hard-fought
lessons that the people at the RFC and I
ATF have come up with so continue in
this example here this is the response
so here we have a status and these
pluses and minuses I'll cover that when
i get to header compression that's part
of header compression which is just up
now H pack is the single biggest part of
the HTTP specification which by the way
is actually two there's RFC 7540 which
is the core protocol and RFC 754 one
which is a full separate specification
just for header compression and it's the
single biggest thing that enables the
HTTP working group to refute the claim
that HTTP two is just another rubber
stamping of Google's speedy protocol as
speedy does not have any header
compression they just say use Z live on
your header bit actually on the full
full header end body so what happened
with H pack the designers realized that
a lot of bandwidth is being wasted by
sending the same header again and again
and again you know why sent host if it's
the same as last time so what they
really did was come up with a scheme
where you express a delta from what the
previous request was so that's what the
pluses and minuses was so have the
server and this is where the state
machine comes in because you now have a
table on the client and a table on the
server that's connection specific that
has to keep what the state of these
header tables is so it can compute the
Dell
is by simply sending references and it
actually does achieve significant
compression which saves resources saves
CPU saves data center costs it's a good
thing all around but again imagine if
this was an HTTP 10 no one would bother
to implement it next feature stream
prioritization so browsers I'm sorry
servers know that what priority they
would like the browsers to render the
resources in and web developers know
this too they have all of their
different tricks that they can use to
make sure the browsers render things the
fastest way possible and the spec being
led by Google you know they're like well
let's make this as part of the protocol
so the priority concept is actually not
just a single number it is the stream ID
a weight and an exclusive bit and also
the priority is only a suggestion even
though the frames you might have image
image packets you know that relate to an
image that the browser sending that are
given a high priority the browser can
choose to ignore that if they want to so
here we have a simple example here three
different streams a B and C and a is
higher priority than both B and C so if
you have let's say you're blocked in
some way in processing a but you have
the packets for B and C handy you should
prioritize them at a ratio of 4 to 12
where you give more weight to see than
you do to be at a ratio of 4 to 12
that's how the protocols defines it this
exclusive bit here effectively says
there's only one of these that's got the
exclusive bit set so treat that as if
it's just a single child of a so you
give a higher priority basically that's
it level up one now the big feature that
people are excited about the most
user-facing 12 server push so the
workaround that server push works around
excuse me is resource in lining so
resource in lining is a way to for web
developers to sort of front load the
data in the HTML itself using a data
call in URL and with server push you
don't need that so what happens is when
the browser makes a request to the
server the server says ah well I know
that when you request this web page
usually you're also going to request
these 40 images and these 10 scripts or
whatever because you know one
implementation strategy is to keep a
little cash of that information and
compared the timestamps on the headers
and just discern a correlation which is
similar to what jetty does actually
jetty is way ahead of everyone else in
terms of implementing this there and you
know their their main guy Greg Wilkins a
super-sharp and I'm very blessed to have
him on the expert group so an in fact
the push builder API was really designed
by him and then we talked about it and
discussed it and adapted it to give
fairness to all the expert group members
as well anyhow another strategy
regarding server push is one that web
frameworks can take advantage of and
I'll cover that later anyhow with server
push it basically says the server knows
what you're going to ask before you ask
for it let me just start giving it to
you okay how do we upgrade so you know
how is the content negotiation and a
handshake happened and there's two
different ways to do it the first way is
kind of respect punts and they say let's
let a LPN deal with this so a LPN is the
application layer protocol negotiation
and it is kind of the next version of
TLS you can think of it that way and it
has a handshake phase where you have to
specify what kind of protocol you want
and there the HTTP to specification said
well let's just use this handshake phase
to determine if it's safe to do HTTP to
if you're not secure though h2c it's
what they use for that h2 clear text
you still use port 80 and then you use a
one-on-one switching protocols message
negotiate HTTP to one of the things that
I'm not addressing but it's something
that is going to be people are dealing
with in the adoption phase of HTTP two
is how to deal with intermediaries and
proxies and when to terminate the HTTP
two connection or to keep it active all
the way from the client of the browser
do you stop it you know it's kind of
similar to a decision of what you deal
with when you're when you terminate TLS
do you terminal eight TLS right when you
get into the data center or do you you
know have it go all the way to the end
point that's a architectural decision
you'll have to face so the server API is
well positioned to enable all of these
HTTP to optimizations simply by you know
requiring the implementations to perform
htb to just gives the gives an awful lot
even without the bush build or API so
it's also great for developers because
just as with H the servlet protocol
initially was kind of based on CGI and
one remember CGI so you know you didn't
have to I was rejoicing when didn't have
to learn CGI he had servlet and it made
it much easier and so the same thing we
can plug in a whole new protocol layer
underneath but the API stays the same
and you're able to reap the benefits
that's why I abstractions endure one of
the challenges that we faced with server
for is you know adapting the one request
one response thing and you know it
doesn't exactly destroy the assumption
of update of the slides but it makes it
a little more challenging to you know
keep that one request form response
model when we have this multi-channel
thing so that's the features i just
showed and these are the ones we're
actually proposing to expose so flow
control server push and of course
upgrade now a LPN is a bit of a
challenge because a LPN itself is
defined in Java nine
and we're here with java ee 8 so you
know we're having to face that
implementation challenge and that's
something that we're discussing the
expert group how to do that there's some
proposals that are saying hey can we
release a patch release of JDK 8 that
has a back part of the a LPN modules if
some people would like that love to see
if we can get that working it's it's one
of the tough spots our current plan of
record is to leave a LPN as an
implementation detail and you know but
we'll some people aren't happy with that
I'm working on it you know we'll see
what we can come up with it's something
we have to have so that's why I was
pointing out at the beginning of my talk
all of the HTTP to that you've seen on
all the slides here means servlet which
means we got to get this a LPN problem
figured out okay so your HTTP Q is
required and we have this server push
thing the idea is push the resource to a
client for a given URL and headers it's
definitely not a replacement for web
socket some people have come to me
instead of http too has binary framing
and full duplexing do I still need to do
web socket and the answer is well
they're different things websocket has a
w3c defined JavaScript API and there's
really no way to get to the HTTP to
framing thing from a browser based web
app it's just completely handled by the
protocol so I just want to get that out
there this is what the API looks like we
added a method called get push builder
to serve a request and the idea is you
just you know when you're publishing
your request here you can mutate the
push as much as you like by adding
adding headers and such and the path to
the resource and pushing it
here's a little sequence diagram of it
so the browser is making a request for a
resource and the server says hey well I
know that you're going to need style dot
CSS and script that j/s so we get the
push builder we set the path to these
things and we call push and then we
start sending the bytes of those things
before we send the bytes of the HTML I
mentioned using push from web frameworks
so web frameworks such as jsf and others
are in the business of knowing your
content you have to declare it it for
example in jsf you have to declare what
are the resources that a component needs
to render itself so jsf is in a very
good position to push those resources so
this is just the stock faces servlet and
you can just this is part of the face of
servlet service method and we can simply
here's the what's this one the execute
method when it is executing the portion
of the I'm sorry the render portion of
the life cycle it will come across the
need to render a reference to a resource
which goes over to this other class
external context and this encodes the
resource URL so when the component says
I need to render this script or image
it's going to call this method and this
is where we can easily just hook in the
call to push builder it's one line to
make jsf push builder aware
okay let's now talk more about reactive
programming so these are the four
concerns of the reactive manifesto
services should be responsive meaning it
needs to respond to user requests in a
timely matter that should be resilient
which can withstand outages with
graceful degradation elastic meaning
these system response is not too heavily
degraded when demand is high and
reasonably utilization is not too heavy
when demand is low it should be meses
driven which allows the parts of the
system to be loosely coupled and
interact with each other in an
asynchronous fashion servlet I was only
dealing with responsive and message
driven which makes sense these are other
concerns that really maybe some of the
other cloud-based jrs would have to deal
with so one other thing before we move
on I mentioned this in the earlier talk
with Pavel about jax-rs the more are
more I work with this and start to you
know work on implementing it and think
about it more it's it's really comes to
the point where you're pushing the
places where you would block further and
further out of your stack so and the
challenge is to make API is that allow
people to write code that does that
without becoming so ridiculously
difficult to understand with all the
callbacks and such so that's something
that when I think they did a pretty good
job of in the jax-rs spec and servlet
we're trying to do what we can there so
in java SE 9 to have this flow which is
really kind of based on the reactive
streams protocol that was done by the
same people that did the react to
manifesto so this is a class diagram
taken from the JEP 266 so you have this
flow processor and a flow processor can
either be a subscriber or a publisher a
publisher is a thing that publishes
items and its subscriber is a thing that
consumes items and subscribers can have
a subscription to them
okay this is what a class diagram or
usage diagram looks like the subscriber
says the publisher hey I'd like to
subscribe to this thing and this
publisher makes a new subscription and
sends back the unsubscribe method and
then request says okay here's one more
subscription to for you to submit and
the executor is able to then pass you
back on next here's a thing there's
another thing here's another thing it's
it's pushing you these stuff submission
publisher is a concrete implementation
of the publisher over here and it's got
these two different it's got some
parameters to the constructor you pass
it the executor which is you saw it was
doing a new subscription over here it
uses the executor to do that the max
buffer capacity how many items you can
keep before you have to start saying no
because reactivity really is more about
being able to say no without blocking
that's kind of what reactive is all
about ok so the submission publisher has
two different ways to interact with it
submit which publishes the given item to
the current subscriber by asynchronously
invoking its on next method and blocking
uninterruptedly so this was one you use
when you're okay with blocking and the
offer one is where you're publishing an
item to each subscriber asynchronously
invoking it's on next method and it says
the item may be dropped so you also pass
a handler which is a non drop so if you
try to get something and there's nothing
to be gotten then your handler will be
called back and the return code will
give you an what to do with that
so let's talk about what can we do
reactive wise in the existing server
three-point o API and then we'll also
cover 3.1 we added a sink in servo
through point O now I said with Pavel
earlier that a sink is not equivalent to
reactive it's something that is kind of
a necessary but not sufficient condition
for doing reactive the ability to be a
sink but non blocking is also important
as well and that's what we added and
served with 3.1 so in order to be able
to really proudly sport the we are
reactive banner we have to take a look
at these methods over here on data
available and on right possible remember
I said reactive is all about being able
to say no without blocking well this is
how it happens in server 30 the servlet
input stream and servlet outputs dream
have these on data available and on
right possible methods that let the
caller say hey if I'm going to call you
now will you block and you know you can
get the answer and then don't call so
rather than being a push model it's more
of a pull model but it does give you the
ability to do flow control which does
mean that you can be fully reactive even
with the server 3.1 API although it's a
lot harder than we'd like it to be one
idea that has been floated is using the
HTTP to protocol itself with the window
update frame that I mentioned earlier to
help implement this back pressure this
is where the back pressure can this is
the current manifestation of back
pressure in the server at 3.1 API so I'm
really going to be going with the expert
group and trying to talk about is there
something more we could do shy of you
know we can't introduce a compile-time
dependency on the java SE 9 flow AP is
or something more we can do than just
this to make it easier
there's also been quite a few
improvements just semester suggested by
the community so you know Oracle while
we are leading the spec as I mentioned
is a community effort and community is
doing a lot of the work as well it's
more pronounced on the jsf side which
I'll talk about on Thursday where the
community is doing like literally most
of the work which is really awesome
because they're the users they want to
get it in and they're doing the work to
get it in so I really applaud that but
the community is also suggesting a lot
of things and we've put them into the
spec so first off was the ability to
take advantage of java SE a default
methods so you can be a little less
verbose when you're declaring your
listeners now we added a default method
for filtering it and destroy we added
this generic filter and HTTP filter that
was requested concept of a default
context path we also added this get
cookie method which was requested some
of the people on the server load expert
group Arjun Tim's and about their shots
and the Omni faces guys totally
requested and designed this API for the
ability to discover what's the mapping
of the currently invoked servlet so we
added a new method called get mapping
and the mapping itself has some
properties to it what kind of match it
is what was the value and what pattern
it was and the mapping match is an enum
talking about the different kinds of
mapping so this would be useful for web
frameworks that need to discern if
you're doing different kinds of URL
mappings we did deprecated some methods
and classes right here you know when we
deprecate something it doesn't go away
it's going to stay there it just has a
deprecation on it
we specified what annotations are not
scanned when metadata complete is true
this was kind of vague so one of the
things that's will it's a challenge
working on technologies mature is
servlet is by the time you get to this
long you're left with just like the
really hard problems like one of the
things that came up and i don't think i
have slides for this was the default
request and response encoding the spec
currently says it's iso 8859-1 but who
here is still using iso 8859-1 anyone
who hears using utf-8 okay there you go
so you know we were considering changing
that but that's that's a low-level thing
right so we have to be very careful as
we going to break anyone if we now say
in the spec the default encoding is now
utf-8 unless you tell us otherwise one
proposal is let's change the default and
add some XML to the web dead XML lets
you set the default character encoding
there rather than calling the method
that does the same thing so I'm very
cautious right because we can't break
anything it's very fundamental that's
another thing that I really admire the
HGB to people they did tons of main it
since it was google they basically had
the entire worlds internet data to test
the stuff on so everything was very well
tested before it finally got in someone
run wanted to write a book about like
behind the scenes of the development of
HGB to it might be a very boring
documentary but I'm very interested in
seeing okay this one came up just a few
weeks ago now i'm there was a period in
time when the spec was not as active as
it is now in the last month or so so
this is something that was suggested by
Greg Wilkins the RFC 72 39 this is a
standardization of all the X dash
forwarded 4 and X dash proxied
headers so apparently this is something
that lots of people that are using
frameworks that sit on top of either tom
cat or jetty they have proprietary ways
of doing this but it's very important so
as let me see a show hands is anyone
interested in this being in the spec
awesome alright so this is something
we'll probably talk about the expert
group meeting tomorrow which i'm so
excited i can say that man you don't
know so servlet could provide an API to
make it easier for programs to access
the information without having to
manually parse the header so some
potential future areas for investigation
JSON be support this is going to be nice
we could imagine allowing incoming or
outgoing application JSON to be
automatically marshaled or unmarked
working with jsr 375 the security jsr to
provide oh off or open ID connect
integration packaging there is a lot of
interest and people have been doing this
for a long time now this concept of
executable jars that just run rather
than everything is a war file that gets
put into a container you know it's I
remember being really excited when I
first saw the concept of an executable
war and it's like well of course that
makes perfect sense now that idea is
mainstream and mature and we'll be
investigating how we can do that with
Java EE multi-tenancy this is important
for achieving you know really good scale
and good use of resources on your server
side it's about packing more ability to
process requests since your existing
hardware get more out of what you've
already bought so right now there is no
concept of a tenant in the servlet
specification so therefore application
scope data is tenant specific there's
only one tenant so maybe if we introduce
the concept of a tenant had an API for
discovering the tenant ID
I would be able to do that now of course
the challenge is having sufficient
isolation in both in terms of data
access but also in terms of things like
noisy neighbors if you have a
multi-tenant system you have to be able
to guarantee that 110 it's not going to
bother with the others anyone here
experienced with multi-tenancy I'd you
run into that kind of problem yeah so
some you know there was a talk at
javaone last year by this guy I think
Adrian trentman from guilt and he
divulged that when they do their micro
service based architecture it's not
multi-tenant at all it's singer single
service per server and that's certainly
a an effective strategy for them but
there's plenty of customers that have
you know won't be able to do that so
that's where we need to come up with
something that's a software
approximation of that which is really
kind of what multi-tenancy is the health
checking that was one of the boxes on
the bottom of the big slide with all the
boxes and maybe we could consider adding
a health pattern attribute on web
circuit I'm sorry web sore butt or web
filter this is still just very very
early in terms of discussion continuing
along and the theme of HTTP two comes to
Java because I wanted to cover all the
ways they should be two is coming to
Java is the support for se9 this is done
in Jeff 110 it supports both HTTP one
and two and i really am fond of the fact
if you look at the api it actually
builds on api classes that were seldom
used but we're added in java 1.2 it's
kind of exciting because it's been a
really long time I think probably Arthur
van't hoff was the last person to change
some of the files that are in this thing
httpurlconnection for example so you
have this HTTP client using a builder
API and you ask the builder ok give me a
new HTTP client then you ask that thing
for a thing to build a request
so the HTTP client is able to send
multiple requests so therefore you ask
the request builder give me a specific
request and once you get that you can
actually finally do methods on it get or
post like that okay so it's a handful of
classes they try to design it with a
smaller footprint as possible it uses
this concept of a body processor which
is really nice and there's default ones
so it lets you do it really takes great
advantage of completa bellucci and the
lambdas to let you write client requests
and really much better than Commons HTTP
client I have to say no offense to any
of the comment HTTP client fans out
there it has a blocking mode and a non
blocking mode and it has full support
for server push so summary and current
status we for GSR 369 on September of
2014 we get an early draft review just
before Java one last year so we're
expecting you know the schedule that
we've published and we were saying is
will have Java EE out in 2017 the exact
JCP milestones are still being defined
but it's going to look something like
this i'm pretty sure and now our survey
slide you've probably seen it i can't
say it enough take the survey please and
not just take the survey of a come up
and talk to me or talk to any of the
spec leads and tell us what you think
because that's that's why we're
listening we're trying to do this and do
the best we can to act on what you're
saying so we've got a few more talks
about this we've got two more full days
of the conference which is so great
let's see i'm talking about jsf on
thursday at the tail end these are some
other ones that look really kind of
interesting so you've probably seen them
before and that's it we have
15 minutes for questions so and you have
any questions we wrap in the front okay
the question was given what i said
earlier how relevant is the continuance
of web socket and the answer is it's
completely still relevant it addresses
an entirely different thing for example
let me go back to the one slide that I
had on this slide sorter so all of those
features in terms of flow control and
streaming and such here this one I made
sure to put this in italics let's the
protocol do more things with a single
TCP connection so in order to take
advantage of this and this is one of the
things if you looked at spring 5 which
was just shown to me earlier they have a
web reactive thing and they're talking
about the ability to use HTTP and a way
to do flow control you can only do that
if you own the implementation yourself
because the protocol itself doesn't
expose any way to get to that stuff so
of course servlet is going to require an
implementation of HTTP too so we could
do something similar and we might do
something similar but the actual
protocol design isn't doesn't surface
that to the users
mmm no one has asked for that I don't
think so the question was do you see
deprecating asynchronous servlets any
other questions no no I'll cover that
earlier there was the question was what
is the relationship between server push
and service and events is that a fair it
is so 11 tip you want one tip you can do
is if you'd like to really take
advantage of server push and your you're
building a web app which lots of people
do you could use you could use server
push to basically pre populate the
browser's cache with things that you
know that won't manually be asked for by
the web page but you could have
framework code in the JavaScript layer
that is actually going to fetch those
things so in other words and the typical
use case of server push is a web page
that has resource references in it and
the browser then would make subsequent
get requests for those things you could
also use it from a JavaScript framework
by having server push push the resources
down and then use an SS e to tell it ok
go ahead and do this thing which will
cause a request to resources that you
already know happened to be in the cache
because you already pushed them so it's
it's a it was a nifty sort of
illustration of using server push done
by the blog entry of the sky Ilya
gregorich who wrote a very excellent
book called high-performance browser
networking it's a free book published by
o'reilly but he has a full ebook of it
for free so it's a good thing to check
out if you want to know everything there
is to know about networking and browsers
they mean really good stuff but he has a
blog and one of his blog post is about
server push and service and events
Kevin questioned oh that's great news
there so our delay has actually worked
very well because I didn't repeat the
question about adoption of HTTP two
versus when server for comes out so HCB
to has been out a long time now and the
adoption is rolling along quite well so
it's very widely supported the problem
that most people are running into i
think is the proxies getting the proxies
up to speed because the minute you have
any of the intermediaries that doesn't
understand an HP to you kind of lose it
so it has to be has to be available
end-to-end or you don't get the benefits
any other questions
the question was why do you have to do
funny things with the boots to bootstrap
jetty to make a use HTTP two and that's
the LPN thing because there there's the
some TLS stuff in the core java SE that
has to get in the classpath the right
place and that's why it is it's a it's a
very interesting thing if you want to
see the details of it let me go back to
the page where is it oh you know what
there's some other sessions of interest
I wanted to share I always put the safe
harbor at the very end let me move this
up yeah these are you know in addition
to this slide which has all the sessions
but these are my personal favorites so
but I wanted to answer your question by
pointing to this list here if you go to
I'll just put another one right here
give me this guy java net projects
servlet spec this is where you can get a
link to the mailing lists bless you and
search the archive and you'll find out
the whole story of a LPN and why that is
Stewart Douglas has a really good
explanation of it any other questions
yes
the question was given that we've
mentioned ties between servlet and other
Java EE specifications will there be
problems or concerns raised by other
servlet implementations set a fair
characterization right okay so yeah
we're very experienced with that one one
of the things that came up recently was
jaspin which is a security API and there
was a lot of discussion on this
initiated by Arjun Tim's about making
just pick a required part of all servlet
containers not just serve the containers
that run in Java EE so that's an example
of where we said and we made a
concession sort of to the Tomcat people
to say hey you know we realize that
Tomcat is not a full Java EE thing and
in fact you know Tommy that goes way
back you know to before there was Java
you know just back to j2ee it created
the concept of the so-called servlet
container JSP and servlets oh it's kind
of funny to think about that as an early
manifestation of the micro profile
anyhow if we come into an impasse we
could always play that card and say well
you don't have to do it unless you're
part of the full Java EE that's what
we've done in the past any other
questions yes
mm-hmm oh it's blue sky right now that's
a very the question was what state is
health check in and it's brand new you
know the jsr hasn't been filed but again
I mean I think this is a great time to
do it because people understand what
health check means and it's got some
very subtle implications to it that
really make it worthwhile to think about
it and do a standard for it I think at
least for all of the Java EE side
anything else okay well thank you very
much for your time enjoy the rest of
your conference</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>