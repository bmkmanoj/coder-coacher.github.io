<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Everything You Wanted to Know About Writing Async, Concurrent HTTP Apps in Java | Coder Coacher - Coaching Coders</title><meta content="Everything You Wanted to Know About Writing Async, Concurrent HTTP Apps in Java - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Everything You Wanted to Know About Writing Async, Concurrent HTTP Apps in Java</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WJ2eZJNBtrQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay let's start the first presentation
of the day so I'm going to talk about
writing a concurrent downloader in Java
using the async Java API is mostly I'm
going to talk about things that are not
that simple to do I'm going to look at
things that why don't use things that we
suggested and things that we decided to
stay away from so it's going to be like
a journey in our decision making process
and and basically how we went about
doing I couldn't count downloader and
why we did it just above myself I'm the
city of Jeff frog my name is you have
and Jeff frog is a startup company
located in california in israel and will
like a java commando unit and mostly
around JVM not all only we have two
products auto factory which is a binary
repository manager and Binta which is a
download center as a service so that's
all product and we naturally deal with a
lot of binaries so we serve a lot of
memories we serve not only jars but we
serve plenty of other types of binaries
and we have a lot of libraries and
clients in github that are using our
binaries and that of people are using
but we didn't have any library that is
concurrent and we it started to really
bother us and clients were really coming
to us and say okay we need your
libraries to be concurrent because the
fact that you optimize a lot in the
transport is not enough you have to
allow us to do come count downloads and
and so on so the requirements will
support parallel downloads support
parallel downloads of parts of files
okay so if you should be able to
download the file concurrently and be
able to interrupt and resume a download
and get progress events in order to show
the progress bar and so on and also
employ check some caching which I'm not
going to talk about that much but it's
important if you download
products are basically like AG e to the
0 based on checksum and deduplication so
when you download something you want to
be smart about it if you have it already
in your cash and it said the same file
different Jackson just don't bother so
when you think about downloaders and
concurrent downloaders what comes to
mind is those small bars or type
extensions that are capable of doing
concurrent downloads and they're pretty
smart pieces of software actually and we
were looking for something out of the
box and we found we found a very nice
piece of software on sourceforge called
the JDM the java a download manager and
that we found out it's completely
useless for us because we really
couldn't embed it for a lot of reasons
first it's a challenge if you can go
online and try to find the sources you
will not be able to find not sell
license now the source is not the dogs
and it's also an application of the
library so we decided to keep out for us
as a startup company especially if we
use some third-party it's really
important for us to have something that
we can trust and that will not bite us
back on the legal grounds and then we
thought about writing it ourselves and
we started looking it's there you're the
URL connection of the jda of two JVM and
we said okay maybe we don't need any
external library but we knew enough form
using it that it's very wasteful it's
buffering everything it does into memory
and it's very minimal on the api's and
it's using blocking stream streams and
we didn't want to use any any blocking
streams we wanted something which is
completely a synchronous so we avoided
that and in order to not block we were
looking for something that is going to
be a sink of force and is going and to
do that I think we'd with callbacks I'll
show you in a moment and to do that what
we need is what we needed is something
called the reactor and it's a it's a
common pattern and for doing guys in
chaos
and of course the nao api's in order to
implement it so I spoke about the
reactor basically the reactor is a very
common pattern for implementing
lightweight concurrency its event ribbon
and it's using its doing reuse of fights
and a non-blocking i/o if we look at the
pattern so it looks a little bit
complicated but it's not really you have
an event dispatcher it's like you can
see there pseudo implementation here
it's like a loop that goes on it's using
a selector from the operating system to
select to do selection on events and
then you have just a single thread it's
like the i/o that the event read in the
AWT you have a single thread that is
dispatching event it senses for
availability of events and then it
dispatches them and then you have
handlers on every event and then you can
use some kind of a thread pool to post
those events but there is just a single
thread for for dispatching those events
let's see if you can guess who made this
slide so it's a very problematic
low-level kind of slide this is showing
a server-side hierarchy of of players in
the in the reactor so you have to type
of handlers you have an acceptor that
accepts the connections from remote
clients and you have all kind of
processors like we decode compute so
those are really low level comprar
sessle's that you dispatch the actual
request payload to so it's the one and
only Doug Lee it's a from one of his
first presentations when Java launched
any y OU AP ice and this is a nice view
of it so what happens so so this goes
down to the API level you have clients
use ok creating socket channels to
connect to the servers and then you have
they register every client registers for
the operator for for their actions that
he is interested in with the selector ok
so the selector is shared between
channels and there are keys there are
events coming back from the server and
there's going to be at redhill using the
selectors
creating give events and passing them
through the channels for processing so
this is what the minimal code for it
looks like so don't don't mind too much
the first part accept the fact that we
create a socket channel then we create a
select oh so it's like a single tone
factory for select on sale selector we
configure it to be non blocking you
cannot use channels and selections on a
blocking channel and then you register
with an operation and this small thing
that does attach handler basically lets
you put any any object that you want on
the selection key so the selection key
is central power to you register to to a
channel you put a selection key as part
of your registration and that's what
you're going to get back when you poll
for follow events so the polling looks
like that you have one thread okay so
it's the dispatch of Fred it's looping
again and again and again it's doing
select or select and it gives you back
the selection key after the selector
turns so the select is going to be
blocking if there was nothing to select
it's going to stay like that once you
get the selection ok this is your logic
for dispatching you get from every from
every event you get the selection key
you take the attachment which is a
handler which is your own code and then
you can delegate to another thread pool
to do the event processing so this is
this is the whole idea of the reactor
it's basically a simple multiplexer you
get a bunch of events and you have one
thread that is doing dispatching and
just thawing out lines of execution form
a single point so it's quite complex to
process those events because you need to
maintain some kind of states and you get
really small discrete events to the bike
level so if you want to do some more
complicated processing for example if
you have any HTTP you have chunk
transfers so you have chunks and you
have boundaries and you have to find out
where the boundaries how so you need to
maintain state in order to
do that you have to use some sort of
buffering and and you have to coordinate
all those a sink events basically told
boils down to maintaining state and the
good thing is that the Nile firebox or
we didn't know but now yo is one is the
guardians of the name for the guardians
of Buddha so they do the heavy lifting
for you so the like this narrow that are
smart and they can take a lot of the
burden of doing this complicated
processing from yourself so we starting
looking at niya libraries and most of
them are server-based so that was not
really an option for us we were talking
about things like Nettie grizzly I found
out that Nettie also has a client API
but it's not very stable just found out
yesterday apache mina the apache HTTP
component as in client and the ning HTTP
client so this is what we looked at so
for the servers we rolled them out we
started with mina it's a it's a dual
library client and server and it was an
evolution from Nettie and it's not very
well maintained if you look at the
github commits you see that it started
to to be neglected so we obtained from
it the server-side libraries we ruled
off or doubt so we were left with you
with the Apache HTTP component testing
clients and with the ning HTTP client so
Ning you probably you know especially if
you live in the States the company that
makes a software for creating your own
social applications communities and they
have a nice HTTP client this is the
github you see the date it's 2010 if you
click the link yes so that there is a
red me with the link for the new
location of the library and you click it
and this is what you get and then you do
a little bit of a search and you find it
ok so and and you can see that it's the
screenshot is not from too long ago it's
maintained some people are walking on it
and if we look at sample code you can
see the heavy lifting as it goes so what
they're doing is they're creating a new
s in client okay and then doing a propel
gate and the execution of a get request
and they all do it and you get back a
future with an HTTP response and you can
see the events they uncompleted and have
some nice of you so you can see the
uncompleted down for bail and you can
get the result once everything is
finished yeah so that's very cool and
another thing that we looked at is the
Apache HTTP s in components which is a
brand new implementation from the Apache
house and they have two main concepts
they have a request for yourself and
have a response consumer if you'll
remember I was talking about to the HTTP
URL connection from the JVM and that it
buffers ever think so really it's really
different they make sure they don't
buffer anything unnecessarily to memory
which is nice the same ning is doing the
same and you look at the code and it
looks very very similar so you can see
we create an async bite consumer which
is an instance of the consumer that I
was dating consumer I was talking about
before and you get really nice callbacks
on response on by Tori sibs you really
get you can see that you really get the
progress going Willis resources and
build result you don't really have to
compose an HTTP result you can compose
your own result if you if you have to
and you do a future get at the end so
you get both the progress and the final
response from there from the method so
there are almost the same right so in
terms of API they do the heavy lifting
and they look very much alike which
makes the selection pretty complicated
to make giving that they are both they
both have the pause and cons so what we
did even before we made a selection we
decided to build on
or below so that we can switch in
implementation if we want to and then we
implemented the onset of events which we
delegate from those libraries to so it's
a common practice nothing very fancy
about it and then we started to compare
so I had to head comparison maturity
ning is more more mature the HPS in
client is practically very very new it's
very easy to do download cancellation
inning we found bugs with the HTTPS in
client we filed a bug report and the
developer was very very fast to respond
and to find a walk around with us so it
involves throwing an exception but
that's already fixed so so it's it's
nice winning we found out that events
progress events or not granular enough
so you're going to get event if if
you're doing a chunk HTTP download
you're going to get event by the chunks
which is not good enough for us we
really wanted to get a events to the
bike level and documentation for both is
terrible so you have to look at a lot of
examples and figure out what the best
part is to go with this and it's not a
mass to have a server-side counterpart
but usually it it's a good sign of a
good design because those the reactor is
very very much similar on the client and
on the server side it's the same pattern
and it's really easy to implement the
server side and the client side together
with parallel classes so it's a good
sign of a solid design there is a blog
for my class Ian that is quite
controversial form about almost two
years ago that compares the the
performance of those two libraries and
the Apache comes out first but the if
you go to the comments you will see that
a lot of people claimed that the
comparison is not good enough what we
did is a at the end of the day we
selected the apache HTTP component and
like we said currently we're very happy
and like we said like i said
we are we kept ourselves the freedom to
do the switch by implementing your own
abstraction below and then we discovered
the whole new world of anyone knows
who's the workpiece ellipses take a wild
guess HTTP so if this is the HTTP 11
spec and when you start walking with
HTTP it seems like a very simple text
based protocol but you start finding out
that there are so many edge cases and so
many open questions and then you either
go to the spec itself and start reading
it and most of the time it's it's very
clear on helping you make the right
reaching the right understanding of what
really the spec is is it once wants to
say and if you if you have still read it
and you're confused so you can go to the
22 stack overflows and all those so
stack overflow is really full of great
information and great discussions about
HTTP and let me tell you some HTTP war
stories that we found out so okay so
let's start so those are really kind of
edge cases so first question if there is
a content length in an HTTP response but
there is also a way to send response
back compressed which is used a lot so
what's going to be the content length if
you're using if you're using downloads
of ranges and those energies are
compressed so is it going to be the
content length the real content length
of the range like you requested it is it
going to be the compressed content
length so it's it's a real tough
question so if you look at stack
overflow they don't really give so this
is one of the most common thread about
it and you see they have a rating here
of of 12 this response which says
it's smaller than you will request a
range of 0 to 1 to 10 23 to 1,023 and
the guy said okay must be smaller than
1024 or the comp west side so doesn't
help a bit okay so moving on what we
went and find out this is a github page
for the HTTP to our discussion and there
is a conclusion that there is a debate
here because it's a real it's not a
clear-cut so there is a debate between
the HTTP to spec makers and they reach a
conclusion that it has to be the actual
content length that is transferred on
the wire and the reason is that you want
to have download manager like what
reward display a bogus bow since this is
not yet implemented and multiple servers
may decide to do different servers may
decide to do their own stuff about it we
just bail out if we have a range request
that and we find out that the response
is compressed we just bail out and we're
trying to do a full we give up the
partial the pallets download which is go
and download the file in one in one part
another question what we found out that
a lot of times there is a redirection
for to see the ends okay so when you
request a chunk when you request to do a
partial download and you get a
redirection for seed before the CDN
every time it starts to download
everything from the beginning even
though you requested to download the
chunk and the reason for that which is
quite make sense if you think about it
is that when you get the redirect your
request headers our lost okay so if you
have a request header that says I want
two x two x two x two ought to bite why
you're going to lose it after the
redirection so you have to add it so
this is the code for for Apache I think
HTTP client to edge back those headers
after every direction so it's a it's a
very simple code you just keep track of
your video action headers and you the
range headers and you add them back and
you implement a new reader Xstrata g
so it's really nice that the framework
is flexible enough to do that since we
were we didn't check it with Ning we
don't know maybe it's supporting maybe
it's not but with the patchy you have
all kind of strategies that you can
register and you can override the
default behavior okay another question
how many simultaneous connections can
you open to a server form a single
client anyone knows this is actually in
the spec it's it's something that is
very little known but the spec really
says if you have her out and the route
is a composition of the scheme a port
and in the server and a hostname as a
client you're allowed to open ex-con
action to it and the number no one just
to ok this is the spec so this is why
you see a lot of websites doing using
different host names for images and for
other media types and Java scripts and
so on or see the ends for that matter
because the spec really tells you open
to connections bowser's initially
respected that they stopped a long time
ago so this is a table of what houses
count this is what wikipedia i think not
remember this is a spec this is a table
that shows what browser actually above
those actually do in terms of maximum
connections to the same out and i'm
leaving an open question here that i
will give an answer at the very end what
does HTTP two is doing in that respect
ok so it's it's quite interesting
another common misconception is URL
encoding this is really it it's
mind-blowing when you when you see the
first time because it's something that
you didn't think is complicated than it
is so my question is what's wrong with
the next snippet of code
now somebody has to good very good
another thing that is wrong with it yeah
those exception which sucks but on the
conceptual level wats what else is wrong
with it let's look at an example so take
this URL for example the query equals a
and B equal ich will see ok so if we
think the thing with encoding it's not a
symmetrical game you cannot take a
decoded URL and encode it back to the
same format because you have you when
you decode it you start getting back
characters which are not allowed and
need to be escaped so you have to know
when you encode the URL you cannot
encode it as a whole you have to know
the parts of the oil if you don't know
the parts you can you cannot just for a
string at your encoding code doesn't
matter if it's the URL encoded off of
the JDK or another piece of code that
you owed there is no way to go back so
in this case for example the query
itself is this value ok and if you go
and start to decode it you will break it
down into to query parameters a and B
right so there is no way to go back this
is really important you when you in
coordinate a URL you have to know what
the parts that you are encoding and like
the dancer from the audience was the
encoder is doing a form and coding so
it's something very similar to the query
encoding so in terms of the spec that
well there is a clear spec about the
characters that are allowed in the query
the characters that are allowed in the
path which are not the same by the way
and what's the JDK offers us which we
think it's going to offer us a good API
doesn't it it's useless basically in the
HTTP client you have two methods so you
have the UI builder and you have a lower
level method which is a collection of
static methods URL encode utils and you
have to say encode query encode
path and you cannot just say encode this
URL it doesn't work it doesn't make any
sense in a mathematical way another
thing is a socket closing and this bite
us really hard so when you close the
socket there is there is a some kind of
a protocol that goes on for socket
closing its DCP but it applies to http
as well if you look for clothes on those
go wait it's a state of the socket you
look it up in Stack Overflow you can see
that you have quite quite many results
and I'll tell you the reason why so
there are three ways that the server may
close the socket on you as the client it
may just cut down the input and output
socket completely so you cannot write to
it you will get a pair disconnected if
you if your time to write okay so it
closes both the in and out it can close
the out but let you keep writing until
you negotiate some kind of phase so this
is called the graceful cloves which is
used by most servers by the way and
there is another way to close the in and
and leave the out open what HTTP 11 is
doing is they implement the graceful
cloves Sophie it's like closing a stall
you let the buyers that are in go out
you don't lock them in the store okay
and you don't let anyone after closing
hours or close to closing hours you
don't let anyone in okay so you need to
communicate you you you call on the on
the speakers of the off the stove and
you your announced everyone the store
will be closed in a couple of minutes
please finish what you're doing in and
go out it's the same with HTTP so what
happens is as the client you're getting
a closed event the client sense is that
the server close the output you will get
in the end of end of bar fell and the
response from the server and that you
know that if you have something in your
bar fell to I to the server if you're
caching something there is something
that I don't
to go into which is called HTTP
pipelining and you may have outgoing
sockets in your buffer you will keep
writing them okay and you will you will
get a call back to the socket close to
the close socket closed event now if you
do if you're doing something stupid in
the socket closed like blocking or
something or waiting for condition that
may never happen which is what we did
you will see that you're starting to
lick a lot because the protocol expects
you to close nicely and finish off if
you don't do it you will be you it will
hang forever if you do a netstat you
will see those sock those clothes wait
states keep accumulating the server is
in is I don't remember the state on the
server but it gives up on you after some
configurable time so it closes the
circuit is as this client is co-op tie
don't care so just make sure never to
block on this close method and of course
you spy catch and this is something that
goes without saying you can see it here
in the HTTP client of knee okay another
thing is the writing pouts concurrently
so this can be quite challenging so we
have to we have actually two methods to
write concurrent files first one is we
can write multiple files ok and then
assemble them which is not very elegant
it's quite expensive on the eye or you
can use memory mapped files and so on
but it's still quite even looking on
your file system and seeing a lot of
partial files is kind of ugly we didn't
feel very comfortable with it in other
ways to I to the same file so you write
a file you you give it a dot part
extension and you write two different
regions of the file and that's what we
did so there is a in Java I oh it's an
old class the random access file which
we thought about using we started using
that by the way and it turns out a
it's unusable for this job even the
javadoc says that you need to use an
instance of c cable by channel if you
want to do concurrent access
non-sequential random access and not use
this class because it's a not using
random access file because it's it's not
that safe so what we are using is we're
using a file channel and file channel is
just an implementation of sick people by
channel and you can see the main method
that we care about we have a right that
takes a buffer and the position to write
into so that kind of solves the thing so
another thing that we light is we don't
only light the fire itself concurrently
but we also write a state okay so we
write a state of the downloads we have
some small civilization that we're using
it's not nothing fancy just print lines
to to a file with carriage returns at
the end and we're writing the the total
size of the file it's shower and checks
on the number of parts were using and
for every part we rewrite the state of
the part whether it's completely door
not what is the size because the size
may not be equal if it doesn't divide
equally and for that we find out we
needed to use a file locking so there
are two ways to do filho key there is
the vm level so to synchronize between
threads in the same vm and there is the
OS level so think about another and
concurrent downloader that somebody
opened configured by mistake may be
configured to the same location on the
file system in the vm level phyllo king
so yeah so why do you need lock so so
the main reason that we need lock is the
closing the closing sequence of writing
the concurrent state of the file and
writing the file itself involves a lot
of heavy lifting so we have to close all
the logs we have to close all the
channels rename the file to it so its
original name so we need to maintain
some sort of locking state in
vm that is doing the change to the file
and realize the progress info and so on
so for this clove state what we did and
this is nothing very special we have
just shelled lock we are using the red
light entering entrant read write lock
of the java.util package and we're doing
two we're taking two locks we're taking
a shower lock so I to Phi lock so it's a
read lock and we have a closed file lock
which is the which is to protect the
closed state and this is an exclusive
right look so when we close the file
we'd basically take the file the right
log and then whenever somebody tries to
write to the file we protect it with the
shell block so if you if somebody took
the right lock you cannot use the
Sherlock anymore this is a very common
pattern and that solves the interview
intervie em problem of locking now for
the OS level locking so I mentioned that
it it needs to protect from different
processes of the same download writing
to the same file so we need something
possibly that the vm gives us to help us
with that so this is the this is what
we're using we're using the file log API
for that we get from a file channel
remember that we're using a file channel
you can do a try lock on it which is a
non-blocking rock and if it's not so we
don't block if it's not we just throw in
overlapping file lock exception and try
lock is basically equal to getting an
exclusive lock on the file for for full
regions of so from the zero position of
the file to the end of it and force
means it's not a shelled look okay the
fact that we're even if we wanted to
write to here and use a shared lock it
doesn't work on windows because windows
falls there are not share blocks on
windows so even if you do a Sherlock you
you get an exclusive look and what we
found out is that we have a problem on
Windows and this is why we changed our
code
set of the default title we changed our
code to look like that and anyone knows
what's why we did it or what this trick
is for okay so what we're doing here is
we're locking it sounds strange but
we're locking is think that we have a 20
bite file okay what we're doing is we're
starting our lock not in position zero
but in the last position possible so in
the we're kind of seeking the the play
the position of the lock to an almost an
infinite position and we lock a single
bite okay so that low key and you can do
it you can do it it's an operating
system a construct it doesn't have
anything to do with Java people were
doing it before and this is one of the
stack overflow gems that we that we
found for example and it allows you to
lock to get a filesystem form the
operating system you get a lock that is
maintained by the operating system it's
not going to allow anyone to write to
this region but it will allow other
windows clients to read and write to the
file so we were in this in this instance
we needed other windows client just to
read the file see if it's dell and and
we couldn't because the lock was
exclusive so we had to lock in a
position where well nobody else can can
I to so other windows client can read
the file so it's a trick to devise your
own shell lock mechanism with Phi locks
okay so a little bit a view into the
future so HTTP a2 so what HTTP two
brings is a is it boils down to
standardizing the speedy API by Google
as a user you don't feel too much the
differences between HTTP 111 and HTTP
too by the way they write it like that
i'm not sure why it's not 20 it's HTTP /
2 and it's it's a it boils down to the
low-level details of transfer so they
added HTTP header compression which is
so when they did that GTP I think they
just didn't think that Heather's are
going to be used that much but today you
we know that we see a lot of requests
that the header pout is louder than the
body of the request because you overload
so many for so much information on the
headers so that's a natural evolution so
the headers can be compressed this is
very very a strong feature oil of HTTP
two and multiplexing or flaming
basically it takes away all the
serialization issues with HTTP and I'll
show you a slide in a second and when
you have framing thou there is internal
prioritization to take care of so it's
all low-level details of the HTTP spec
it also clears up some ambiguities such
as the content length for comp west
region and also not very much
interesting for us but it offers any
sort not rating writing written here for
that reason but it offers something very
very cool which is a server push so if
you think about it when you download the
page and the page has a JavaScript on it
for example your browser is the one
knowing it says okay I'm missing this
small JavaScript I need to go and open
another request to get it and this in
HTTP to the server can be smart enough
and say I'm returning you an HTML page
that includes a JavaScript I'm pushing
back the JavaScript without you're
requesting it
even because I know you're going to need
it and your client that supports HTTP
two needs to be smart about it so
firefox for example already does it i'm
not sure how many servers already
implemented but your client needs to be
smart about it because he's getting
something he didn't expect so in the
political negotiation you have to
declare what version of the HTTP you
support and I mentioned framing before
so this is what it looks like basically
it means that on a single HTTP
connection you can you can mix different
it's multiplexing basically you can mix
different frames and from different
requests and the server and the client
are going to be smart enough negotiating
about it and if you remember before I
was presenting the problem of how many
HTTP connections you can open / out so
now what my question now my question is
given this HTTP to spec what do you
think is the maximum number of
connection with HTTP two okay good good
choice so yeah it's one and it's if you
think about it it's like all of the
sudden with HTTP 11 there are tricks
like pipelining and so on but at the end
of the day it's like very very small
pipes and you open those small pipes and
it doesn't matter how fast your
connection is you're still pumping data
I see related or small pipes so and here
you get all of a sudden a big pipe that
you can stream all your data to and they
actually did they have a lab and they
did a lot of tests around it and they
came to the conclusion that client-side
and server-side managing multiple
connections on the server side it's
going to be a lot more efficient to do
things and by using just a big fat pipe
to to transfer everything so that's
that's something new just a couple of
links for you so the the presentation of
course is going to be available online
and so you have all the links and of
course we have the presentation itself
I'm actually a lot ahead of time so I
have some some time for questions and
I'm finished thanks guys</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>