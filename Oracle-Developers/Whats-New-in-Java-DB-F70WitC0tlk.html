<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What’s New in Java DB | Coder Coacher - Coaching Coders</title><meta content="What’s New in Java DB - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>What’s New in Java DB</b></h2><h5 class="post__date">2015-06-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/F70WitC0tlk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Raquel guess I hope you can
hear in the back I work on the Java DV
team for Oracle for those of you who
don't know about much about Java DB its
Oracle's branded redistribution of the
Apache Derby open source database how
many people here have used Java DB order
be great about half the people all right
for those of you who haven't used Derby
it is a one hundred percent Java
relational database it is a it comes
bundled in the DB directory of the JDK
it's loaded with SQL features it runs in
an embedded mode inside your application
in the same jvm as your application and
in that mode there is no process
switching there is no network handshake
between your application and your
database access it also runs in a
classic client server configuration
where your application and your database
live on different machines across a
network it is free under the apache
open-source license and all of the
functionality comes packed into a jar
ball which weighs less than 3 Meg
alright what I'm going to talk about
today is what's new in Java DB and by
that I mean what has appeared in the
latest two releases of Java DB 10 9 and
10 dot 10 in the previous rev of the JDK
jdk 7 Java DB 10 8 is bundled and in jdk
8 we're bundling javed be 10 10 so this
is the feature increment introduced over
the last two major releases of Java DB I
don't intend to talk about any Oracle
product plans everything that we do on
Java DB is done out in the open you can
track our work you can follow us on the
Apache Derby mailing lists on the open
jdk mailing lists than that we have no
secrets nevertheless I am advised to
hold up the following legal I guess and
under this I will proceed alright the
feature increment can be divided in the
following major buckets changes to the
Java API changes to sequel coverage that
is new SQL features enhancements to
security and some new tools which may
help you develop data rich applications
powered by Java DB the changes to the
API are divided into the following major
categories changes to support the small
device profile introduced by JDK 8
changes to support JDBC 42 which is the
version of JDBC supported by JDK 8 and a
small extra change to support a feature
of JDBC for that one about small device
profile as you may be aware the jigsaw
project was bumped from JDK 8 into JDK 9
and ind its place jdk 8 is going to be
providing a couple smaller sized jvms
for use on resource-constrained devices
these are called compact profile 1 2 and
3 the compact profile which java DB runs
on is compact profile to the reason that
we run there rather than on the smallest
compact profile is because profile 2 is
the profile that contains JDBC this
gives you a sense of what your static
footprint savings is if you use the
small device JVM as you can see compact
profile to weighs 13 Meg on this Linux
distribution compared to the full JRE
which weighs four times as much here
again is a picture of what is in the
various profiles and as I said before we
run
compact profile too and we run there
because that's the smallest profile that
supports jdbc we didn't have to do a lot
to support a compact profile to outside
of the the data sources and the all that
had to be done with the data sources was
to invent some new data sources because
the full contract for the data source as
described by the javadoc is that a data
source needs to be referenceable so that
it can be looked up with a jndi naming
service if you're running in a Java EE
environment so the difference between
the compact profile to data sources and
the full JRE data sources is just that
the compact profile to data sources
don't support jndi look up now the way
that the data sources work is that JDBC
defines three of them there is a vanilla
data source there's a connection pool
data source for use in app servers and
there is an X a data source for use when
you're doing distributed transaction
processing because Java DB has two
separate jdbc drivers and embedded
driver and a client driver there are
there for six data sources in Java DB or
there used to be now that we're
supporting an extra compact profile to
platform you have to multiply that by
two so now there are 12 data sources in
Java DB if you're running your
application embedded with your
application in the same jvm and you're
running this on a resource-constrained
device that uses compact profile to
these are the data sources you would use
if you're running your client
application on a resource-constrained
device that is running a compact profile
to these are the data sources you would
use otherwise you would use the other
six data sources which you would be
familiar with or might be familiar with
the job ID reversion that's bundled in
jdk 7 no changes there alright the next
piece of the Java API want to talk about
are the changes to support JDBC 42 JDBC
for tattoo as I said is the version of
JDBC which is supported by JDK 8 mostly
JDBC 42 is a lot of spec clarifications
and what we did was verify that in fact
we are in conformance with the Titan
spec the biggest set of changes in JDBC
for do have to do with supporting very
large data sizes data sets where your
row count is more than two billion where
it can't be described by an int where
you need along to describe your row
count there are also some changes to
database metadata and jdbc for to
introduce type enums these are database
types and the JDBC 42 introduces
standard type enums for the sequel
standard types and it also offers the
ability for vendors who want to
introduce their own custom vendor
specific data types to do so with these
enums Java DB only includes data types
that are defined by the SQL standard so
we don't need any of these special items
but it's important to be aware of them
as you write portable applications which
you expect to run on JV DB as well as on
other larger enterprise caliber
databases as far as the large update
counts is concerned these are the
classes which have new overloads
injected into them for operating on very
large data sets which have more than two
billion rows as far as the changes to
database metadata they are fairly minor
the data type of the histogram column in
the results that returned by get index
info has been changed from an int to a
long again this is is to support
large data sets a new method has been
introduced to report on what the maximum
size of a large object a character large
object or binary large object is this
method actually has no meaning for Java
DB and we return 0 finally there's
another method which was introduced to
report whether your data beta base
supports cursors on reference data types
java gb does not support reference data
types so we don't support cursors on
them all right the final bit of change
to our Java API it has to do with jdbc
escape sequence for limit offset syntax
so many days of databases including jovi
DB have a way of specifying that you
want to start your query results offset
by a certain number of rows and you only
want to retrieve a certain number of
rows after that it's useful for taking
your query and forking off partitions of
the query results to different threads
or two different operators the good news
is the sequel standard supports this
functionality the bad news is not all
databases use the sequel standard syntax
and for databases which need for
applications which need to be portable
across all those databases there is a
special JDBC escape syntax which will
work regardless of what the underlying
sequel dialect is so this is what the
sequel standard syntax looks like for
specifying limit and offset this is what
java DB supports the offset clause says
how many rows into the into the result
set you want to throw away before you
begin to throw return results to the
client and the fetch next clause says
how long of a block of rows you want to
actually return until you you designate
that the result set is thin
ok this is the sequel standard syntax
this is the same query using jdbc escape
syntax the words between the including
the curly braces the words between them
and the curly braces are the jdbc escape
syntax that's how you express the same
limit offset directives that are stated
in the sequel standard syntax alright so
that those are the changes to the java
api that you'll find in the version of
jdk of java DB that's bundled in jdk 8
now i want to talk about new SQL
features which are introduced by this
Reb of Java DB we've introduced two
features one is user-defined aggregates
and the second is support for routines
with variable length argument lists all
right and now we come to the
surprisingly trendy topic of data
aggregation what is a gregation
aggregation is a set of techniques for
extracting a small packet of actionable
signal from a large body of data noise
the sequel standard comes with some
simple aggregate operators that you may
be familiar with max min average count
there's 12 others that are actually in
the standard or about a dozen others and
the sequel standard also comes with
syntax for dividing your noise in two
partitions or windows or separate blocks
the sequel standard calls these groups
and the aggregate syntax allows you to
compute a separate piece of signal for
each of those partitions in your noise
the good news is there are a number of
enterprise caliber databases out there
which allow you to define your own
user-defined aggregates and plug those
into your database and use them in
exactly the same way that you use
ordinary aggregates
the bad news is those there is no sequel
standard syntax to harmonize how you
declare one of these aggregate operators
to the database so if you write a
user-defined aggregate and you want to
have a portable application you will end
up having to write a little bridge code
to translate the your your code that
runs on one database into aggregate code
that will run on another database but
the good news is the differences between
the way that you implement these
user-defined aggregates and different
databases are fairly minor that bridging
code is fairly small the actual queries
who write will look exactly the same and
the major difference that you're going
to face other than writing that bridging
code is that the way that you declare a
user-defined aggregate is a little
different so Java DB has implemented
user-provided gets at a point in history
after we have generics in Java and that
means that it is very simple to describe
what an aggregate operator is it is the
following a user trying to aggregate is
a class which implements the following
parameterised type there are two type
parameters that are important here V is
the data type of the noise that is fed
into the aggregator and r is the data
type of the signal that comes out of the
aggregator at the end in implementing a
user-defined aggregate you need to
provide implementations of the following
methods in initialization method there's
an accumulate method which is run for
every piece of noise there is a merge
method the merge method is run
if you are running a grouped query and
your number of partitions is so large
that we end up having to spill the
result the intermediate results to disk
in that case the merge operator is used
to blend together intermediate results
from the same group and finally there is
a terminate method which returns the
signal out of the aggregator at the end
alright and this is a piece that is not
portable this is how you declare a
user-defined aggregator to Java DB you
declare you what it is is a binding
between an aggregate name which you will
use in your queries and the class that
implements that aggregator in this case
the aggregate name is in most and the
name of the external class that
implements aggregator is most so at the
end of this slide deck I'm not going to
present these slides today but the end
of the slide deck if you downloaded
you'll find a bunch of sample code the
sample code demonstrates that I'm not
telling big lives here and in that
sample code you will find the code for
this most aggregator the most aggregator
does is basically a mode aggregator you
feed it the stream of values and what it
computes is the value that is seen most
often so the application that I'm
imagining this being used for the toy
application is some sort of video rental
application in which think about your
your cable provider and say an on-demand
movie application and here's a query
which uses a user-defined aggregate
you'll notice that the aggregate is used
exactly the same way that you would use
a standard max-min average account
aggregate there's a group by clause here
the group by clause divides the data up
into 24 partitions one for each hour of
the day and then the inmost aggregator
is is called
in the Select list of this inner query
and it produces a result something like
this so in this result we see that
during the dinner time hour between six
and seven in the evening the movie
Phobos attacks was downloaded more often
than any other movie all right there's
another use that you can use user
aggregates for and that is to implement
something called a pivot table a pivot
table is a feature that which is
implemented by some enterprise caliber
databases and the point of a pivot table
is to take a vertical data set and to
flip it 90 degrees to turn it into a
horizontal data set essentially it turns
your columns into rows so it takes a
data set like this and it presents it
like this and this is how you use a
user-defined aggregate to implement a
pivot table so the code in here is
something that you can probably press
into service to implement pivot tables
other kinds of pivot tables for other
kinds of data just follow this pattern
there we define a couple of user-defined
types we declare a couple user-defined
methods and then we declare an
aggregator the user-defined types that
we're declaring our a column type and
what a column is in this in this
instance is a binding of a column name
to a column value and then we decline do
we declare a row type and what a row
type is is a simply a bag of columns so
it's a collection of ordered pairs each
of which it consists of a column name in
a column value then there's a factory
method here make into column for
constructing the column objects there's
a get int column which is used to
unpacked column values out of a
aggregated row and finally there is the
aggregator itself the aggregator is fed
a stream of columns and it puts them
together
into a row so in the query I'm about to
show you the you're going to see the
grouped query the data is divided up in
again into 24 partitions one for each
hour in the day for each hour in the day
we construct a row out of the out of the
column information that comes from the
partition this is the beginning of the
query but I'm going to skip on to the
second slide because this is where the
aggregate is invoked and then we'll go
back to the first slide in a moment so
as you can see it's a group by query and
the aggregate occurs in select list as
always first we construct one of these
column objects out of the noise and then
we run the columns column objects
through the row building aggregate and
finally after we have done this inner
query we unpack the results using this
get in column method and we end up
turning this into this all right now I'm
going to leave you with something
tantalizing but I'm going to wave my
hands here because this is not an
experiment I run myself but these
musings come out of a paper written by
Michael Stonebraker co-authored with a
number of other researchers and he wrote
this paper to explore a claim which had
been made by some proponents of some new
SQL databases that using MapReduce
techniques on a massively distributed no
SQL database you can achieve orders of
magnitude better performance than you
can from issuing a similar query against
a relational database and Mike
Stonebraker thought that that was not
true
and he and these researchers ran some
experiments and they wrote this paper to
publish their results and the conclusion
they came to is that in fact it is not
true you can achieve the same
performance using a relational database
the trick is your relational database
has to support two features it has to
support user-defined aggregates and it
has to be a parallel database so Java DB
supports user-defined aggregates we're
not a parallel database however in order
to use this technique with Java DB you
would need to stick an enterprise
caliber parallel database on top of Java
DB but that's where you'd spend your
money the cheap part is using Java DB
planting a meat planting a lightweight
Java DB instance on every leaf node of
your massively distributed no SQL
database now there's you're going to use
two features of Java DB in this in this
solution one feature is the user-defined
aggregates that I've just described the
second is something called table
functions a table function allows you to
package up any kind of external data set
that can be represented as a result set
using the Java SQL results at interface
anything you can package up as a results
that can be declared to Java DB as
though it were a local table it's a
function that materializes the table so
what did what you do is you wrap the
external data from the no SQL database
in a table function and then you run
your user defined aggregate on the table
function and this is what gives you your
MapReduce scale out on the leaf nodes
there's a little bit of coding to be
done to connect the the parallel
database that sits at the top of this to
all of the nodes and I'm going to leave
that as an exercise to the reader but I
think this is a really fruitful approach
all right now that I've 10
lives do with that I'm going to talk
about the next SQL feature that is
introduced in the version of Java DB
that's bundled with jdk 8 and that is
their args routines so Java 5 introduced
the ability to declare methods with
variable length argument lists though
basically what you do is you you
annotate the last argument in your
argument list with the three dot
ellipsis token however there is no
support for binding sequel functions and
procedures to ver args methods and
sequel standard in order to do this we
had to introduce some syntax which was
an extension to the sequel standard
however it is a compatible extension to
the sequel standard and it we believe it
is impossible for the sequel standard to
be extended in a way that will make this
invalid in the future so this is what it
looks like first you declare a public
static method which is a ver args method
in Java so the last argument is
decorated with the three dot ellipsis
token and then you bind a function named
a sequel function name to that external
method using the create function syntax
so the little bits in red here are the
extra bits which were added to the
create function syntax in order to
support various methods as you see the
trailing argument is decorated with a
three dot ellipsis token and a special
parameter style of Derby is used here
this is what prevents any future
evolution of the sequel standard from
encroaching on the syntax and once you
declare a function like that you can
then use it anywhere you can use a
function in the SQL syntax and as you
can see every invocation of this
function has a different number of
arguments all right now I want to talk
about security enhancements which have
been added to the latest increment of
Java DB we've added two
security features one is the ability to
unencrypt databases and the other is the
ability is a new kind of authentication
scheme called native athan extent
occation and in this this scheme the
credentials are stored in the database
itself so unencrypted databases is sort
of a minority practice it's probably not
something that a lot of people want to
do but you can imagine that if an
application were developed outside the
firewall for use by a single person that
the application might want that database
to be encrypted it might feel that it's
vulnerable since it's outside the
firewall and then at some point maybe
the application gets moved inside the
firewall and you want to be able to run
your queries against the database
without incurring the performance drag
which comes from encryption and
decryption so this is a technique for
once you've moved your your database
into a secure place for turning off the
encryption all right this is how you
encrypt a database to begin with that's
done at creation time you add some extra
bits here in red on the connection Earl
you tell the database that you want to
turn on data encryption and then you
specify a boot password to be used to
unlock the database when you boot it and
this is how you unencrypted the database
later on so you boot the database
specifying the secret password that
unlocks it and then you specify decrypt
data base equals true and from then on
your database will be unencrypted and
you will no longer incur that encryption
decryption text all right now I want to
talk about native of chthonic
authentication which was introduced in
10 9 so there are several ways to
authenticate users when you are opening
a connection to a Java DB database one
way is you can plug in
ldap authentication if you have an LDAP
server another thing you can do is you
can write your own custom Authenticator
it's a very thin interface that you have
to implement and that can wrap whatever
your company's specific logic is and now
there is a third way which is to use the
built-in native authentication which
comes bundled with Java DB and which
allows you to store the credentials in
the database native authentication
replaces an older form of storing
credentials in the database called
built-in authentication the built-in
authentication was actually a testing
debug tool that somehow escaped into the
wild if any one here is using built-in
authentication in their production
databases we strongly urge you to
migrate to using native authentication
which we believe is much more secure so
negative indication allows you to do the
following thing it allows the database
owner to create users to list them it
allows the database owner to configure
how passwords are hashed when they are
stored in the database it allows the
database owner to remove users to resit
reset the credentials of compromised
accounts and it allows ordinary users to
change their own passwords turning on
native authentication is very simple all
you have to do is create credentials for
the database owner this is done with the
CCS create user procedure call the
database owner must be the very first
user that you create credentials for
once you create credentials to the
database user for the database owner you
cannot drop them and the first time that
you reboot after creating credentials
for the database owner that is what will
turn native authentication on so in
addition in a real application you would
create more users than just the database
owner and here you see a couple other
users being created by setting a
database property
it's kind of a mouthful derrida
authentication native password lifetime
nil aids you can configure how long
passwords are good for they start out
being good for a month you can configure
that up or down you can also set a
number of properties which configure how
passwords are hashed in the database you
can can you configure the algorithm used
you can configure the number of
iterations the number of times that the
password hashing is is run and you can
configure the length of the salt which
is used in order to frustrate rainbow
table attacks on your hashed passwords
if you turn any of these knobs we
recommend that you also set the Derby
database properties only property this
makes it impossible for anyone to
subvert your choices to override your
knob settings by using system properties
as i said the database owner can list
the users in the database the day the
users are stored in the sisters table
the only the database owner can select
from this table and there is an
invisible column in the table the
password column which even the database
owner cannot view the what's stored in
the in the password column is a hash
it's not the it's not the real password
of course the database owner can remove
users by calling CCS drop user the
database owner can reset the credentials
of a compromised account by calling CCS
reset password and ordinary users can
change their own passwords using sis
seus modify password the database owner
can grant execute permission on these
procedures that are initially restricted
only to the database owner so if you
were operating in a situation where you
have lots and lots of users and you need
to have a separate role which which
performs
password maintenance you can grant
authority to those roles all right I
think I'm doing well on time here
finally I want to talk about some tools
which we've added optional tools which
hopefully will help you write data rich
applications using Java DB we've
introduced two optional tools what is
called database metadata that is called
foreign views the database metadata tool
what it does is it declares a set of
functions corresponding to each of the
functions in the database metadata
interface for the functions in meta days
database metadata which return result
sets these functions return our table
functions so they return tabular data
sets and you can use these functions to
filter and join the results of database
metadata calls here's how you do this to
load the tool you call sis CS register
tool with the name of this tool which is
database metadata the second argument is
a boolean true means load the tool false
means unload the tool once you've loaded
the database metadata tool you can start
filtering and joining the results of
database metadata in this case we're
doing something fairly simple the get
columns method of the database metadata
interface returns the tabular data set
it turns result set and one of the
columns in that result set is called is
generated column we take advantage of
that you can see that in the query we
are invoking a corresponding table
function with the same name get columns
as the database metadata function since
it returns the result set we are
invoking it as a table function and then
we are filtering the result of the query
by asking a question in the where clause
about the is generated column that's
returned by get columns
when you're done doing your database
introspection you can unload the tool
you do that by calling CCS register tool
with the tool name and the second
argument you set to false that does the
unloading all right the final thing I
want to talk about is the foreign views
optional tool this tool what this tool
does is it creates a view in your Java
user table in a foreign database and
this can be very useful if you're doing
data migration if you're migrating data
out of some other database into Java DB
this can also be useful if you're doing
some kind of ongoing data integration
task for instance if you have a giant
legacy database and you need to write a
Greenfield Java TB application to
perform some sort of new analysis on
that data but you don't want to impose
an ongoing burden on the legacy database
during working hours you could do a
little data integration cycle in the
evening where you siphon the latest
increment of data out of the foreign
database you load it into java DB at
night and you run your queries against
it the next day this is what it looks
like you once again you load the tool by
calling sissy as register tool the name
of the tool is foreign views true means
load the tool sissy s register tool is a
ver args procedure and it and that means
that it has two optional trailing or an
arbitrary number of optional trailing
arguments in this case for the foreign
views tool the the two trailing
arguments are a database connection URL
and a scheme of prefix okay so in this
case this is a derby connection Earl not
terribly exciting but it could be a
connection Earl to any other database it
could be a db2 connection Earl and
Oracle connection or a postgres
connection or MySQL whatever it just has
to be a JDBC database
when you issue this command what happens
is the following jovi DB will open a
connection to the foreign database using
this connection Earl then ER VD b will
introspect the metadata of the foreign
database finding all of the user schemas
then Java DB will create shadow schemas
in the local Java DB database one for
each of the external schemas the shadow
schemas in the Java DB database will
have the same name as the foreign
schemas except that they will be
prefixed with this final schema prefix
here then Java DB will go in and for
every table in the foreign database it
will create a shadow set of table
functions and views which wrap those
table functions which make it appear as
though the foreign data is living inside
Java DB so this is how you would use it
after you've issued the call that loads
the tool now you want to create a local
table that has all of the data of the
customer table in your foreign database
so this query will do that the this
right here the CP dbo customer that is
the name of the view that was created on
the foreign data you create the table as
an empty select from that table that
creates a table in Java DB which has
exactly the same shape as this view and
then you siphon the data out of the
foreign out of the view on the foreign
database using a regular insert select
statement this insert select will run
with bulk insert performance because
because the table is empty and we're
selecting from this from a view backed
by table function so you can do that for
all the tables in your foreign de
tourism when you're done doing your data
migration or ongoing data integration
you can unload the foreign views by
calling the SIS CS register tool
you specify the foreign views tool named
false means unload the tool and you
specify the same trailing arguments that
you did when you loaded the tool to
begin with and that's what I had to talk
about folks for more information you can
go to the job EDB website or you can go
to the Apache Derby website you can ask
me questions in just a moment you can
also find me on the demo ground floor
between three and five Monday Tuesday
and Wednesday of this week and you can
also hunt me down in the Apache Derby
community I do all my work in the open
like a circus animal and you can come
and poke sticks at me there so and now
is the time for questions any questions
okay so the the question was what are
the heap implications of running java DB
on a regular Java app we have run Java
DB I believe in a very minimal
configuration where it only consumes
like eight Meg so that includes all the
class files that includes the generated
class files to the queries and that
includes the page cache other questions
well it looks like you have 15 more
minutes added to your lives</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>