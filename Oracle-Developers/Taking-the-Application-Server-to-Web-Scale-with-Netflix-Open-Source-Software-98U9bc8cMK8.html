<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Taking the Application Server to Web Scale with Netflix Open Source Software | Coder Coacher - Coaching Coders</title><meta content="Taking the Application Server to Web Scale with Netflix Open Source Software - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Taking the Application Server to Web Scale with Netflix Open Source Software</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/98U9bc8cMK8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is David curry for the next hour
we're going to talk about taking the
application server to web scale with
Netflix open source software as you'll
notice from the subtle branding on the
chart I'm from IBM and no IBM
presentation is complete without a word
from the lawyers actually 171 words I
counted them to save you doing it I'm
sure you all read very quickly though so
we'll move on the saw with a little bit
about myself as you might guess from
this picture I'm a runner anyone care to
guess who I am in the picture guy at the
front of course it's a bit of an it's a
bit of a cheat really though because
actually I organized the race and I
didn't tell everyone else where to go
they just had to follow me so that the
main reason for including the picture
though is the building in the background
that's his Lee house which is the IBM
location where I'm based sadly I don't
get to sit in the house there are some
nice or any office blocks just off to
the right I started there just over 16
years ago and before long I was working
on some product called websphere
application server we were doing j2ee
1.2 which i think went out in the 2000
which was very good it's good to GA
product after the year 2000 because that
meant that we got paid to do pagerduty
for a product which wasn't yet generally
available anyway I've done lots of other
things in the meantime but it so happens
about a year ago I came back to
WebSphere application server turns out
they've been doing things in my absence
and they've got up to version 8.5 I'm
responsible for all sorts of weird and
wonderful things so I'm currently the
architect for CDI in websphere
application server I'm also responsible
for various bits of cloud integration
for the application server so there's an
example the the bill pack that we have
for cloud foundry and IBM bluemix falls
under my responsibilities as to some of
the work that we're doing with Netflix
OSS
so I intend to cover three things in
this presentation firstly why is a guy
from IBM stood up here talking about
Netflix Oh assets you may be wondering
that then I'm going to give a brief
introduction to micro services and then
dive into some of the detail around some
of the netflix OSS projects and then i'm
going to close out by talking about some
of the work we've been doing with
netflix OSS and websphere application
server so to tell the story about IBM
and netflix OSS i need to introduce this
guy called Andrew spyker he was the
websphere performance architect and he
was responsible for running things like
the spec j enterprise spec and ensuring
that IBM stayed up the top of the table
I don't think we are at the moment so
we'll move on swiftly this was around
2012 and andrew is wanted to make sure
that we had a scenario which was more
representative of the saudi applications
that were expecting people to be doing
in the future so something that was
going to run in the cloud something that
would have both mobile and browser based
clients something that was going to
expose api's and and to that end he
created an application called acne
airlines of fictitious airline and the
architecture for that application looks
a bit like this I'm not going to go
through it in great detail but as I say
it's got browser and mobile based uses
IBM worklight for the the mobile based
pieces that comes in and they both use a
common API exposed for jax-rs running in
the application server and then on the
right-hand side of the picture it's
using WebSphere extreme scale which is a
distributed data cache for the the data
to you if you're interested in finding
out more and Ruiz got a nice blog post
which covers both the original
application and all of the stuff that
has been done with it subsequently
including some of the the netflix
integration that i'm going to talk about
in a moment so this was pushed out into
ibm's cloud at the time it's scaled up
very nicely running on around 50
applique
servers we managed to get something like
I think it's 50,000 transactions a
second that scales up to around 4.3
billion API calls per day and at the
time ProgrammableWeb but just Paul it
published this API billionaires club and
4.3 billion API calls a day would have
put acne air somewhere between Facebook
and Netflix so everyone was very happy
scales up nicely however and restart to
think about well actually what does it
mean to be a web-scale application what
about aspects like operational
visibility so we could draw some pretty
graphs but the pretty graphs were based
off collecting n Mon stats when it was
running and then post processing those
at the end of the run not something
you're going to be able to do with your
long-running web application so things
not looking quite so happy at that point
then we started think about some of the
other aspects what about DevOps how does
this architecture supporters deploying
new versions of the application what
about high availability and disaster
recovery what about elastic scaling
which showing the application running
our maximum scale but how do we scale it
down how do we scale it up whether that
be manual or automatic not so happy so
Andrew started to look around what else
was going on in the industry at the time
there were plenty of folks like Google
Twitter Facebook LinkedIn all writing
about what they were doing to create web
scale applications but Android like the
look of Netflix OSS the reason for that
well actually were probably three
reasons one like many of their peers
they had a tech blog where they were
writing about what they were doing
probably more importantly than that
though they were actually open sourcing
a bunch of the projects that they were
using not everything admittedly but
enough to give you a decent platform to
build upon the third reason which
hopefully given this conference
as if interest to you as well is that
those projects were written in Java
although Acme air was entirely written
in Java I was actually rewritten with a
node front end and we also had a bunch
of services written in C that we wanted
to to scale as well but we could use
Java as a sidecar on those processes and
still use the netflix technology so
Andrew and his team did a number of
things they started out by recoding at
mir to use the netflix libraries it's no
secret the netflix runs on awss AWS it
was about that time that IBM had just
purchased softlayer as an eyas so a
piece of work was done to port the
netflix OSS library still on top of
softlayer as well as AWS so porting acne
air and that work to put across to
software one Andrew a couple of glad
prizes from netflix and it wasn't just
about the work that was done it was also
about the way in which was done again it
was much in the way that Netflix would
have done it themselves Andrews blogging
about what was happening we were having
discussions with Netflix through google
groups we'd go along to the netflix
meetups and talk to other people who are
interested in netflix OSS about what we
were doing so why we were doing this it
wasn't just about you know some
performance test application that we had
a number of different things firstly we
wanted to prove that building web scale
applications wasn't just about AWS that
you could write portable web scale
applications across multiple is vendors
we wanted to understand better how our
own public cloud services could be made
more robust and we also wanted to build
out a platform that our customers could
use as well so work is ongoing at the
moment within IBM to create
a platform that we're using for our own
czars offerings API management is a sad
offering that went GA recently and
that's using netflix OSS as part of the
platform on which it runs so what does
netflix OSS provide before we go into
that i would like to talk a bit about
microservices architecture it seems to
be all over the agenda at javaone this
time who's been to a session already
that talked about microservices quite a
few the others I'll go through this
fairly quickly just to give you an idea
about the concepts so we start with
their idea of a monolithic application
that's what acne a used to be it was a
number of components a web front-end
data access layers all running within a
single process that process being the
application server if we wanted to scale
that up then we run multiple instances
of the application server in this case
we're running in the cloud so they're
running on on virtual instances but we
still end up with each of those sets of
components running a number of times in
different processes a number of issues
with that firstly as we'll see later on
in the presentation if one of those
components fails the chances are it's
going to take out the rest of the
process with it and if it fails in one
of those processes there's a reasonable
chance that it's going to fail in all
the other processes and sooner or later
you find that you have no processes left
to run your application the second issue
is the you can't scale those components
independently so if for example the
component that is talking to the
database tends to be the bottleneck I
can't just scale up that component i end
up with all the other components being
scaled at the same time and lastly we
come back to the DevOps piece if I want
to update one of those components I have
to update the entire application
so when a micro service architecture we
take the application we break it down
into a number of independent functions
typically organized around business
capabilities and we make each of those
functions into a micro service in the
Netflix case those micro services are
virtual server instances so they package
the micro service up as an ami which has
the application code it might have
things like a local cache a reverse
proxy or package together inside the
same virtual server instance each of
those virtual server instances also
exposes a number of management and
monitoring interfaces and that's the
piece that is common across the micro
services so the team's developing the
services are a Liberty to do what they
like within the server instance
providing they expose those common
management and monitoring interfaces so
in a typical customer facing application
you might have a single front-end
invocation which would come in and might
maybe spawn off 20 to 30 at different
micro services
this is the scaled view now
microservices isn't the panacea it
brings all sorts of other issues with it
one of those is the deployment process
now rather than just a single
application to deploy I've got multiple
services that I need to deploy there are
potentially latency issues if I'm making
those 20 to 30 calls off the back of
each unification coming at the front end
I need to ensure that ideally those are
happening in parallel and that the
latency is there is at a minimum one of
the other issues is well I need to be
able to find the instances of my
services and in netflix OSS that's done
through a project called Eureka so
Eureka is a runtime service registry in
Netflix's case they don't use Eureka
just to register rest services but they
also register other instances such as
memcache the instances Cassandra rings
they're all registered within Yuriko
when a service instance comes up it
registers itself with a typically a
cluster of Eureka servers that cluster
is there to provide high availability
and you might have Eureka clusters
across multiple availability zones and
regions they provide a client library
written in Java in order to perform that
registration but I think one of the
other things we liked about Netflix OSS
is that although it has a Java API the
rest interfaces are also documented so
you're not obliged to use Java to
perform that registration once the
service has come up then needs to
provide a heartbeat to let Eureka know
that it's still running as Eureka is
about running instances of the service
and then when our service consumer needs
to resolve its dependencies it can go to
that Eureka cluster query it to find the
location of its its dependencies and it
can specify as part of the query does it
need to
instances in its own availability zone
or as it prepared look more widely again
as part of that trying to keep down
latency so you Rico at how I find the
services ribbon is how i go about
invoking them at least in the case of
rest services so ribbon provides a java
api for driving rest services but the
key thing about ribbon is that it's a
eureka aware so that when i invoke the
rest service ribbon is going to go to
the eureka server and locate the
instances that it needs in order to
invoke the the back-end service at that
point it's going to retrieve all of the
instances and ribbon will also do
client-side load balancing across those
multiple instances it will also do
things like that load balancing
algorithms pluggable I'll also do things
like marking services are unavailable if
ribbon tries to invoke a service itself
and discovers that it's not there maybe
Eureka's out of date it hasn't yet
detected that that services has gone
down so with Yuriko we've got the
ability to find the services with ribbon
we've got the ability to invoke them so
one thing we should consider about is if
we've got all of these surface
interactions how are you going to
prevent failures in services propagating
back to the services that are invoking
them who here is red Michael no guards
release it not very many if not you
should it's getting older by tech years
I was published back in 2007 but I'd say
it's pretty much as relevant today as it
was back then one of the main talents of
the book was that failure is inevitable
failures can occur in lots of different
places if you're out in the cloud the
failure it might be down in your eyes
layer it could be you know I can't
provision a new instance it could be the
networking is unavailable
it could be in the software layer where
the software is not just your
application code it's the the OS that
it's running on it'll could also be in
and services that your service relies
upon whether their application services
or things like a user registry or even
DNS might not be available not only can
lots of different things fail but they
can fail in lots of different ways
probably that the simplest way is by
just disappearing more insidious though
is if it disappears intermittently or
even worse still it's there but it's
very slow well there it accepts your
requests and never respond means what we
need to do is not hope as this quote
says that the failure won't occur we
need to expect the failure will occur
and we need to ensure that when it does
occur it has the minimum possible
effects and in particular that failures
don't cascade through the application so
let's look at a concrete example at the
top we've got an application container a
user request comes in here it's invoking
three different dependencies f h &amp;amp; j one
of those dependencies fails but whatever
reason maybe it's trying to use some
database which is no longer available
before long we've got lots of user
requests stacked up all trying to access
that dependency maybe the threads are
hanging and at that point maybe we run
out of threads in the application server
so it's not just request which are
trying to use dependency H which can no
longer respond but other user requests
are failing as a result of the fact that
we no longer have spare threads in the
application server so what would we like
to do instead we'd like to fail fast so
in this picture we've introduced an
additional layer in the middle which is
effectively a proxy to each of the
services that we want to invoke and
underneath each of the dependence
there you'll see it's got a number of
threads and that's the number of threads
that we're prepared to tie up on the
client side to talk to that particular
service so now when we come in and try
and invoke dependency F we switch to
another thread at the client side we
make the call off dependency f if
everything's okay we respond and send
the response back to the original thread
if that thread doesn't respond and times
out where the timeout is specified by
the container the original thread is
free to respond even if that thread is
still tied up trying to talk to the
dependency more so if we've had five
threads which are now tied up the
container knows that it's run out of
threads in that pool and the next time a
request comes in and try to invoke that
dependency we're just going to return
immediately we're not going to bother
trying to invoke that dependency so
that's what I mean when I say to fail
fast not only here have we failed fast
but we've also ensured that we've
limited the number of threads that are
going to be tied up as a result of a
failure with that particular dependency
so that pattern is called a circuit
breaker pattern that was probably made
popular in that book release it but it
existed before that in netflix OSS the
implementation of the circuit breaker
pattern is is called hystrix history x
being that a genesis of Porcupine so
this is the prettily thing that my
service uses to protect itself from
other things other things failing
history actually has two modes of
operation I spoke about one just there
where I switched another thread you can
also stay on the same thread and use a
semaphore again it's still about trying
to ensure that i can return in a finite
amount of time to the original caller
when I districts in Java they use a sort
of command pattern where the command is
the thing that I want to run on the
other thread and as part of that command
I also specify
something which history calls the fail
back which is at that point at which I
time out which there are no threads left
available this is what I'm going to do
and that's probably the hardest thing
about writing code that uses historic
switch is deciding that what am I going
to do if a failure occurs what we're
trying to do here is not send an arrow
back we don't want to just propagate the
error because then we're back in the
situation we were before is there
something meaningful that I can do at
this point maybe I have some cache data
locally that I can use that okay it's
stale but maybe it's better than having
nothing speaking of caching so history x
has another number of other tricks up
its sleeve caching is one of those
another thing that it's capable of doing
is batching requests to pass through to
the back end as well one of the side
benefits of always using hysterics to
invoke those dependent services is that
now I've got a hook point where I can
monitor service availability from the
perspective of the clients so this is
not what my external monitoring tool
thinks is the availability of this
service it's all about what are the real
clients of that service think about its
availability so hystrix provide
something called an event stream where
it offers up statistics about the
services that it's trying to invoke then
there's another netflix project called
turbine which you can use to aggregate
those events streams from multiple
servers and then there is a dashboard
which is the the thing that you can see
here which displays the statistics and
we'll see a demo of that later on in the
presentation
so the last piece in the puzzle that i'm
going to talk about today at least is a
netflix project called our case so our
case is another animal it's a chameleon
this time so in the same way chameleons
can change color our case is about
configuration allowing configuration
that can change over time you may
remember earlier I said that those those
virtual server instances were baked
they're immutable images containing the
micro service which is all very well but
if I've got mutable images I need
something to tell them who they are at
runtime which environment they're in
where are they running and rks is the
mechanism to do that rks is built on top
of Apache Commons configuration so if
you want to provide additional
configuration sources it's very easy to
do that by simply implementing the
comments configuration provider
interfaces what rks builds on top of
that is a number of things one of them
is the ability to poll configuration
sources over time and that gives us the
the dynamic behavior that I were talking
about it also has the ability to give
you a hierarchy of configuration sources
so in this picture here for example at
the bottom of the stack maybe the
container in which it's running provides
a default set of properties maybe the
libraries that are part the application
also provide properties which should
take preference over those in the
container maybe have a property file in
the application and they should take
precedence again and then we get to the
ones that are more interesting at
runtime so maybe I have a database which
contains configuration properties which
I access at run time to retrieve the
properties maybe I have a URL which
specifies a properties file which I want
to pull in at runtime I can update that
properties file that would be detected
and those new properties will be made
available to the application and then at
the top of the stack we have at runtime
maybe I want to be able to as an
administrator poke the application and
say here is the new value for this
configuration property so there's an
example of top of the page here there's
an API so you can configure our own
application properties through our case
so in this example I've got a property
called my web app lock wait time it's
got a default value of a thousand that
I'm putting in the code and then when I
need the value of that property and this
is the key thing when I need the value I
call get on that dynamic long property
and it returns me the current value of
time to wait and when i call that get
again i might get back a different value
okay so that was a brief introduction to
just a few of the netflix OSS projects
there are over 40 projects up on the
netflix site at the moment some of them
are very much specific to using AWS some
of them are specific to some of the
other technologies that netflix use for
example Cassandra but I think these just
these few basic ones or something that
can really make a difference to to your
java applications so I'm then going to
switch to the the last part of the
presentation where I'm going to talk
about some stuff that we did with with
web server application server before I
started the presentation who'd heard of
WebSphere application server it's
probably the majority how many people
have heard of the websphere liberty
profile and the application server so a
smaller number ok so in Webster
application server we've now got two
profiles one we call the full profile
and that's the application server that I
started working on 15 years ago those of
you who've had the joy of using the full
profile may have come to heat it over
time it is growing larger and larger
I know we're in hundreds of megabytes
for the download certainly is a
developer it's not a pleasant experience
to use it so if you've used either
rational tooling with web certification
server in it it really is a hefty
beastin and we recognize that so a
couple of years ago we created the
second profile called the Liberty
profile and we basically ripped apart
the application server threw away all
the bits which we had accumulated over
time which nobody was really interested
in these days a whole load of stuff
which has been deprecated but you know
somebody's paying us a lot of money to
still keep it in the product and we took
those pieces and built them back up
again into what we felt was kind of a
minimal set of things which were useful
in particular the thing we started with
was the je 6 web profile as a kind of
base set of things that people needed to
write a je application so as a result of
that we ended up with a download which
was 50 megabytes in size it's memory
usage is around a 60 Meg footprint it
starts up in less than five seconds it
is able to pass its configuration
dynamically so as a developer you can go
in and make updates configuration or
they'll be picked up without even having
to go through that five second restart
time it's easy to get hold of you can go
to our wires dev dotnet site and
download it all you have to do is read
some more stuff from the lawyer and
click accept it's free for use for
development as is the tooling that comes
with it clips based tooling which allows
you to edit the server configuration in
a nice graphical way in the tooling you
don't have to use that the config
duration is designed to be very simple
it's a single XML file there's a lot of
configuration by convention so for a
very simple web app you end up with a
very simple server.xml to configure it
so I mentioned that we had support for
web profile that's in what we call that
the Liberty core edition that's the
piece shown in blue at the bottom of
here there's a few other things in there
other than web profile which we consider
to be kind of must-haves things that
that people might want each of the
blocks here is what we call a Liberty
feature it's actually an osgi subsystem
archive and the server is built up from
those Liberty features that means we can
have other editions which add additional
capability so our base edition adds
things like JMS support for example and
more than that it also means if you
don't want everything in the web profile
you can actually build yourself a
version of the server which has even
less in it than that 50 megabyte
download you tell it which features you
want run the minify commands and you get
a set of binary that you can pass around
which have just and it may be just one
servlets both nothing more in addition
to that as you'll see in a moment you
can actually add your own features into
into Liberty as well we've also done a
lot of work in the ecosystem space so
trying to integrate with things around
Liberty so for example providing and
tasks maven tasks ensuring that not only
do we support eclipse but IntelliJ as
well Jenkins support in addition to IBM
things like urbancode deploy as well so
it's as part of this ecosystem work that
we decided we'd like to do something
with Netflix OSS
and as a side effect of that all of the
netflix OSS projects bills using Gradle
so when we were going to do something
with netflix OSS we thought well we need
to use Gradle as well and as a result of
that we wrote a Gradle plug-in for the
Liberty profile as well all of those
things are available on github so if you
go either to where's dev donate or
directly to github you will find
projects up there with these things in
so here I'm going to show what you would
need to do to build the netflix OSS
feature hands off i'm not typing sorry
no live demos here so simply clone from
from get i need to give it a property to
tell out where I've got the Liberty
profile installed locally as some of the
the Gradle talks rely on having a
Liberty profile and then I'm not going
to do just a default build because it's
going to run off a whole bunch of tests
as well i'm just going to build the
essay that i want and those of you whose
Gradle will love this bit actually will
start doing something in a minute and at
the end of this i have any essay file
which is basically a jar file which has
a manifest which describes the feature
and inside that there are a bunch of
osgi bundles so we take each of the
netflix projects like rks turn it into
an osgi bundle and then package that ups
inside a Liberty feature some of you
will notice that one here called Eureka
lies sadly some of the dependencies that
are specified in Palm files and some of
the netflix dependencies which claim to
the osgi bundles but actually armed
there's all sorts of things there so
we've had to do a little bit of a hack
which says that we provide some things
which aren't actually in maven at all
anywhere but so many claims that they
depend on them not Eureka itself
but one of its dependencies so having
built a CSA how do i use it well I can
install it into my Liberty installation
using something we call the feature
manager I should say actually we now
have an online repository of features
and at some point we hope to get the
netflix feature into that one one
repository as you may guess that
involved lawyers again so it may take a
little bit of time but at that point you
won't have to go to and build the
feature itself the feature manage and go
off connect to the online repository and
just pull down the features as they
needed so having installed it how do I
then use it in an instance of the server
so this is a bit of a server.xml file at
the top you can see the feature manager
that's the thing that says which of
those features those bricks that you saw
in the picture earlier this particular
server is going to use and in the middle
there you'll see one that says use a
coal on WS netflix OSS so that's saying
please let me have access to those
libraries which are exposed by that
Liberty feature so we didn't just
packaged up the netflix OSS libraries we
wanted to give people also a bit of a
Liberty experience for netflix OSS so i
mentioned server.xml just then which is
the thing that configuration file for
the server we wanted to add that as
another source for ik its configuration
properties so again I've got me example
here that I had earlier my web app door
locked away timeout and now I can
specify a value for that in my
server.xml using the snippet of XML
that's shown just here
then for hysterics so actually I didn't
show it snippet of hysterics code
earlier here's the hysterics command you
can see the run method that's going to
be spun off on another thread and the
fall back which is the code that it's
going to use if that that fails the
netflix projects as i said earlier are
also configured through rks so in this
case i can specify a time out for
example for this particular hysterics
command you'll see in the xml where
there's an element called my command
which matches the name of the historic
scommn and glass above and i can specify
the time out that I want to use their we
did another piece of work for hysterics
certainly in WebSphere we really don't
like people spinning off other threads
if the server doesn't have control of
all of the threads that are in use when
you come to shut down the server it
means that we can't notify them that
it's it's time to go we also have a
bunch of metadata which passes around on
the thread and sew in its default mode
where history is spinning off another
thread you lose all that sort of
metadata that means for example you
can't get hold of the kernel subject if
you came in to the web container and we
authenticated the user there that
subject normally passes around with the
thread another example is local jndi
resources the or application may specify
once you switch thread in no longer
knows what application you're running in
and you don't have access to those jndi
resources thankfully hystrix has a
mechanism to plug in the pool the thread
pool so we've plugged in a mechanism
which uses the AP is that the
application server provides for creating
new threads scheduled executor service
and consequently you can now get access
to those those je resources on the
threat
that's true so at so the quiz these are
application properties why am I
specifying in that the server.xml so if
you remember the stack that I had
earlier which said you could have a
hierarchy maybe these are default values
for the for the server but i'm going to
override them in the application or as
I'll show in a minute maybe you're going
to use the dynamic nature of the
server.xml as a mechanism to what those
update the properties at runtime but
yeah that's a reasonable point so there
is a mechanism in history for example to
say here are the default values for
timeouts for all of the commands you
don't have to use this mechanism where
you specify a specific command name demo
time ok just a short demo I have five
Liberty servers I have the web app
running on the front end I have my one
micro service in this instance which is
that the customer service I've got
Eureka running I've got turbine doing
the aggregation of statistics from the
web app and the customer service and
they're being displayed in the history
of dashboard this is the Acme air
application I don't think it would win
any design awards it has to be said
maybe it's of its time so I've logged in
I've retrieved details of the customer
from the customer service in this case
it's not using WebSphere extreme scale
there are lots of different versions of
the Acme air application now this one
using MongoDB and this is the historic
dashboard concentrate on the two things
on the top left get customer front-end
get customer back end the front end is
the web app trying to call the customer
service and the back end is calling
MongoDB so here's my server XML
configuration for this application and
history has a property called force open
so I can turn that to true and that will
force the circuit breaker open at this
point so you can now see that updating
dynamically in the hysterics dashboard
if I then return to my application and
again try and retrieve my customer
information at this point it's going to
hit my fallback and the fallback says
are the only information I have is the
ID you specified I'm just going to pass
that back so here we're making use of
the fact that both our case is dynamic
and also the liberty server
configuration is dynamic as well so if i
change it back to false the circuit
should close again and if i go back to
the web application i can then
successfully retrieve the customer
service information the benefit of not
doing a live demo is that I know it's
going to work okay so that's bit
contrived where I'm forcing it open and
closed using the property so I'm now
going to show a slightly different
scenario so as I say it's using MongoDB
at the back end so I'm just going to
control C MongoDB at this point i should
say there's not just there's a Jamie to
load running on this as well which is
why you saw lots of things happening in
the dashboard so I've been killed that
off you see that history is detected but
it should open the circuit because it's
seen a bunch of requests which are
failing and once again if I try and
access the customer data at this point I
go through the fall back and I just get
the account ID
restart mongo DB and hysterics are every
so often is going to let through a
request to the back-end service to see
if it's now available again at that
point the circuit closes again it's
going to now going to let through all
the requests to the backend and I can
once again retrieve the customer data
okay so hopefully you have a better
understanding now not only about Netflix
OSS but also why IBM has been involved
in that ecosystem as well does anyone
have any questions ok so the question
was about you know it's there any
additional infrastructure you need to
run any of these projects so eureka for
example it's a war file so you need an
application server to run that on or a
cluster of them but nothing beyond that
likewise turbine historic dashboard
they're all packaged as as war files so
typically no
huh so the question was how does netflix
OSS compared to akka so i guess i'm not
going to answer that question instead
i'm going to say what we are trying to
provide is for people who are on a je
programming model how can they get the
benefits of netflix OSS without having
to change programming model so yeah I'm
not going to answer that question either
through ignorance i should say any more
questions yep that's correct yes
so so the features part of a manifest
for a feature is its dependencies so you
specify the ones you directly need in
the application and will work out what
it needs a downstream of that so for
example as a concept in osgi essays
called auto features so I have this
feature and I have that feature maybe
there's some integration I can have as a
result of having both of those and
another feature will pop into life as a
result of that so for example same CDI
I'm running CDI I'm running jax-rs okay
now i want some integration which
integrates GDI into jax-rs so in the
server.xml you saw that list of features
that isn't necessarily the set of
features you're going to get it's that
plus any dependencies that they have it
does yeah yeah and so I mentioned again
the online repository so again when you
use the feature manager to access the
online repository it's going to work out
what the dependencies are then used to
pull down so if I go off and say I
already have CDI in my application
installed locally I say now I want to
add jax-rs goes off to the repository
not only pulls down jax-rs but also the
auto feature that needs that for the two
to work together okay any other
questions
so the questions were for the components
that I mentioned are the minimum Java
versions and do I need a full
application server so i believe the
minimum java version is java 6 and no
you don't need a full application server
so out of the box the netflix OSS
component would run on jetty j ok so the
question was we're not all doing web
scale what is the point of which things
like hysterics actually become useful
versus the overhead I have of
administering those those extra projects
it it's difficult for me to say because
I'm not a consumer of the projects but
certainly in some of the SAS offerings
that we're working with we're not really
seeing that the overhead is actually
more dependent on the model but you
choose your micro services so in the
Netflix case you've got an ami for your
micro service you've also got an ami
that's running eureka instance you've
got an ami that's running your history
dashboard plus you want a cluster that
it's not very long before just to run
the simplest of applications you've got
a raft of a vey ma my stack tub which is
fine if your Netflix and you're putting
the workload through that there needs
that but not for my first web
application one of the things if you
look at Andrew spikers blog is there's a
version of this that we've done the runs
on docker so the services that micro
services at that point to reach running
inside docker containers as our Eureka
and the istick stash board etc they're
all running in docker containers so you
know it's got a fairly complicated
made an environment which is all running
just locally on his laptop but can then
take that and run that on softlayer as
well there was actually some other
interesting stuff in there so I didn't
talk about Asgard and the way in which
you can control scaling etc of the the
number of instances as part of that
docker work we did created called a
microscale ER so it was using docker to
do the scaling of the instances based on
the information that as God was
providing so and in the example here for
example you know all of those Liberty
servers were just running locally on my
laptop there's nothing that says you
even need to necessarily do
containerization of any sort or
virtualization of any sort around each
of the instances typically you would
like to do that because that's giving
you the isolation between the micro
services but you know maybe in your
simplest scenario you don't you don't
need that either so a long way of saying
I don't think you need to be that big to
to benefit
that's a good question so the question
was do we have a docker image for
liberty profile so there is a blog post
on developerworks which describes how to
create one right now we don't have
anywhere where we have publicly posted a
Liberty image that you could use in a
docker file to build the docker image we
did publish a statement earlier in the
year that said we would put a Liberty
image up on docker hub that has yet to
happen but it will come yes so the
current version is e 6 web profile
compliant if you look at the beta
version that's up on wa's devnet you'll
see that we're slowly starting to add je
7 capabilities and those go beyond je 7
web profile I don't think I'm allowed to
say where we're going to end up but you
can probably work that out any more
questions ok good thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>