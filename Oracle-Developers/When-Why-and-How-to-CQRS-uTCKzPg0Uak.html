<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>When, Why, and How to CQRS | Coder Coacher - Coaching Coders</title><meta content="When, Why, and How to CQRS - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>When, Why, and How to CQRS</b></h2><h5 class="post__date">2017-08-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/uTCKzPg0Uak" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm very happy to be here it's gonna be
a buzzword session today CQRS and before
i start i should tell you something from
the auricle organizers so if you like to
give some feedback on either the event
or my session then you can use that
using twitter by twitter using the
hashtag oracle code hashtag so if you
have any questions for from my session
of course for the session your you act
to ask here in the session or just give
feedback using Twitter all right when
why and how to CQRS
who of you has a slight idea what that
buzzword is about CQRS okay okay and
whoever you a few has played around with
that technology or even used it in
projects okay what more than I expected
right so high from my side my name is
Sebastian - nur I'm a Java consultant
and trainer based in Germany Munich and
yeah I'm a conference speaker regular
conference speaker on events like this
and I'm really happy to be here in
London again
my first time in London for this here at
least for some in England
yeah what's more for me I'm helping
shaping the future of Java EE so I'm
participating in the JCP for Java EE 8
into expert groups namely Jack's arrest
and JSONP and I'm also so-called Java
champion and the last ones Java one
double Rockstar speaker and yeah on that
topic of CQRS so why should we care and
what's all that about and so on and so
forth normally I'd like to do live
coding sessions if you've seen one of my
presentations before someone like Adam
bean has been doing this morning I
really like this kind of sessions but I
found out that for the topic of today
it's well makes sense to introduce a
couple of concepts first and because
this is quite what we saw quite unknown
to
to most developers for the enterprise
world so what's going to be a show and a
few concepts and few ideas first and
then I'll do a live a little bit of like
coding and life demoing so why should we
care
typically we build enterprise
applications in a craft based way right
create read update delete we have a
database mostly relational database
residing somewhere and what we basically
do we have the current state of our
system stored we have some domain
objects right and they contain some
properties and so on and so forth and we
always have the current state of the
system if we change the properties for
our customer objects then we change it
to the new state persist that and then
we have a new state in the system and we
don't have all the transitions normally
so one of the shortcomings of crud based
systems we are facing is that we don't
have to reproducibility and the whole
history how our system got there right
so imagine your system has been running
for two years and then you don't know
what happens in between you just can see
the current state so that can be a
problem if you want to reproduce things
later and in the same way if you're
storing just the current state and of
course you want to do that in a
consistent way then you have to deal
with competing transactions right you
can change things at the same time and
still the outcome should somewhat be
reasonably reasonable so you have to
deal with concurrency and all this all
these things and because of that because
what you're doing is that you're more or
less lock either the database on on row
level and so on and so forth or do
things like optimistic locking you can
scale infinitely right because that
system either your application server or
at least the database is somewhat than a
bottleneck at the end and you can scale
infinitely using a crop based approach
this may probably not be even a problem
for you if you're not Amazon or Netflix
and want to scale up for like forever
but at least it's in
you and now about two motivations and
two concepts that are related with
secure risk and I want to show them
first because I would say there are two
kind of different motivations that lead
to to the same outcome one is event
sourcing and the other is event driven
applications event sourcing first that
doesn't even have to be something with
scalability and event-driven approaches
and it's a concept that is quite old I
would say so probably a few of you have
have been using that concept regardless
of event driven applications before so
I've used that quite a lot actually in
the past and that solves the whole
problem of history and repressive
reproducibility because for events or
systems what you're doing everything
you're changing in your applications are
atomic events so all the use cases
create a new user or the something are
events that are stored as is in your
database and everything you're doing is
just append only so you just add up new
events the best example is money
transactions right you have a bank
account and you add 100 pounds and you
subtract 50 pounds and so on and so
forth you can't delete transactions in
your bank account right if you transfer
transferred money for accidents then
what you do is you do like adding up
transactions then that corrects the
amount right if you transfer a hundred
pounds too much then you subtract
hundred pounds again but you can't
delete an transaction it's just append
only like like in the git repository and
that's the way how events or systems
work right and to have the current state
of the system yeah well you start from
day zero and you add up all the events
right to get the current balance in your
money in your bank account you just add
all the transactions from day one and
that of course gives you the whole
history and the full context information
because you see everything that happens
to you
system and it also enables you to do
well what I would say future use cases
to do things later and that means as you
have to full context information at the
full history available you can always
well count on them that you use them for
things you didn't even think of first
for example if your application has been
running for two years and then your
manager comes and tells you oh by the
way what is the number of users that
signed up on a Monday for some reasons
because manager do these crazy things
right and then you said well this was
never a use case we don't know but in an
eventual system you all already have all
these kind of information because what
you're doing everything that comes into
the system is stored in an atomic way so
all the information that ever happened
is available so you can just count on
them later and reuse them later on and
now the second motivation that leads to
secure s systems its event-driven
architectures that is somewhat yeah
related to micro services or at least
distributed systems and it's somewhat
solves the problem of yeah
scalability of distributed systems
because what you don't want is
distributed transactions right if you
have some some system and you want to do
a use case that involves several systems
what you normally have to do in order to
be consistent is well lock everything
down to the duration of the transaction
to something like a distributed
transaction which is a really bad idea
and then you have a consistent
transaction spanning multiple systems
but as I said it doesn't scale and well
in some use cases it doesn't even work
so in general it's it's a bad idea
unless you're doing really exceptional
cases but you want to avoid distributing
transactions so how to realize then use
cases that are consistent over time
right because if you want to transfer
for some money from juices that involve
system a
system be holding user account a and B
well you want to be consistent and you
want to do this
so you do it basically by splitting up
your transactions into several ones that
are in themselves still consistent and
that communicate by events that means
you do something in in system a and then
you fire up events and then system B
well continues on that event kind of and
the communication is solely done by
these events and well just to give you a
short example imagine you're in a coffee
shop and you want to order um some
coffee
or you're in a restaurant and want to
order something to eat right so what you
do and this is the showcase what I will
show later on in my demo application we
have three systems involved here an
order system a beam system to store the
coffee beans that you need to order
coffee right and the barista who wants
to brew your coffee so what you're doing
you want to order a coffee right and
normally if if you're in a crop based
world and what you do is your order
coffee then that system asks our bean
system are these beans even available
and the whole time you use the request
is blocked and wait for the second
system to respond and then the second
system responds and then your first
system responds yes the beans are
available that it would somewhat be
attributed to a transaction and of
course it cannot scale because if your
second system is really slow then your
first system will always be slow as well
so what you do instead you communicate
by events and how this works is if you
order a coffee then an event is fired
order placed and now you split up these
well basically the use case of ordering
that coffee that means your user doesn't
get it the risk response if it worked
immediately rather than it only
responded order has been placed doesn't
mean your order will be ever executed or
if it's even possible but it's just
being placed
and that is an event the events are
immutable and happened in the past so
that is a fact
the order has been placed even though it
will never be possible but at least it
has been placed and now the beans system
listens to subscribes to these event
stream and gets the new order that has
been placed and now it validates the
beans and then it fires an event order
being validated or maybe order not
possible due to insufficient beans and
only now the order system listens to
that event that has been happened and
now your order is accepted and if you
user that submitted everything
asynchronously comes back now it will
read Oh am i already is actually
possible and starting from that the year
barista system that is only interested
in accepted orders because everything
else can be done anyway will start your
coffee brew and then this event will be
fired whereas your order will be updated
to and/or start it that will be
reflected in the status and so on and so
forth and then the beans will be fetched
the order will eventually be finished
from the barista system that events
happens when your order is updated and
delivered and so on and so forth so I
hope you get the story how how this
works the user however and sees this in
an eventual consistent way right because
it submitted the order and then let's
say it requests the status of the order
and 100 milliseconds before the order
has been validated but it still reads
the old status because the events are
well delivered asynchronously and it
doesn't get the new status yet normally
this is not a problem right because the
outcome in the long run is consistent
it's just eventually consistent that if
in between you ask for the status you
see an old state but it's the same for
all kind of enterprise systems if you go
to Twitter if you go to Facebook it's
the same story right or even bank
accounts it's also the same story if I
am deficit sum
money somewhere then I'd and I hit
refresh in my online banking I don't
immediately see it maybe sometimes days
afterwards depending on your bank and so
it's the same story and any questions on
this so for everything everything clear
and I hope you also get the idea that
this is somewhat related how how the
real world works because in the real
world you're also mostly eventually
consistent right you order a coffee and
they say yeah fine and you wait and walk
away and then they notice oh by the way
it's not even possible to to give you
the coffee because well the coffee
machine just broke down and you said
well you said it's accepted you would
right assume that in a consistent system
but actually it's eventually consistent
and you will have to deal with these
kind of errors later anyway and this is
how the real word normally is designed
so it makes sense to some of model these
in our applications as well right and
now if you have any questions as I said
any time feel free to ask and interrupt
me um CQRS stands for command query
responsibility segregation quite funny
long name that could be driven and as it
says it separates the responsibilities
to read and write it means you have one
system that only writes without
returning data and you have another
system that only returns data without
having any side-effects that sounds
quite simple but it has a lot of
implications actually and that means in
for example for code speaking you have a
void method and you have a getter on the
other side the void method well can't
return anything and together is not
supposed to have any side-effects and if
for example you invoke that void method
and it
well returns without any exceptions then
you can rely that this worked
successfully that at least the order in
our example has been placed and that's
if not then it has to throw an exception
and this is actually quite important
you have to rely on that because for
example for a coffee order it's fine
if you get your coffee of course it's
also fine if you can't get your coffee
if there are no beans available and you
eventually will be notified about that
however it's not fine if they forget
about your coffee order right so if you
at least submit and place the order and
you get the accepted response then
eventually you want to see some outcome
right it's the same in the restaurant if
the way that never comes back and tells
you about your order you will be annoyed
and yeah now about how to implement this
right and more fgf demo and slides just
to showcase this so what I said you have
two systems now write a command service
and the query service command service
only writes and the query service can
only return data and in an event-driven
approach you communicate by these events
so while your systems are basically
loosely coupled and communicating only
over these events that are done using a
so called events tour and each and every
service and that is quite important is
self-contained it's really independent
so what I what I draw it here as
databases are whatever internal
representations of your domain objects
it could be in memory it could be a real
database that is somewhat like in a
corrupt based system that means you have
for example a relational database by a
plain old JPA containing your current
state of your object and everything that
is done to update this representation is
by applying these events that come from
the event store that means the event
store is the single source of truth
fires all the events that happen to the
system for example order placed and you
your services all of the services update
their internal representation
accordingly
that means you somewhat hold a current
state of the system but only
play contained in each and every system
so that for example for the query
service you can return the data in a
fast way without applying all these
events each and every time and at the
same time you just communicate over
these events so you have the benefit
from both worlds basically if you accept
the fact of being eventually consistent
so what does it mean em so now for that
some use case for example you place the
order like in the example you place it
of course using the command service that
has some internal database for example
and then what happens the command
service it works to place the order and
it will fire in an event to the event
store this publish publishing of the
event happens in a reliable way so your
command service will only return hup-two
to accept it if the event has been fired
reliably this is important in order to
be fully consistent over time right
because if the event never never happens
at the event store then of course your
order will be forgotten
and then you're already asking placed
and the user can walk away with some ID
and come back later what happens then
the order place event is published to
all the services query and of course
command services were as well to update
their internal representations in their
database and now if you later if the
client comes back and ask for specific
order for its specific ID it will get
the current representation from the
query service that was applied from all
the events for example that order placed
event any questions to make sense and
also in the same way of course
- well process that further because at
the end of the day want to have a coffee
you also have an event handler on the
command sort of a site that will process
it further so it listens for order
placed events for example what we had in
the bean store example right and then it
does something based on that
but to be that's important only the
command service will actually fire and
click or events write the query service
is not allowed to do that and well now
you have a couple of advantages doing so
so first of all as I said to two
motivations event-driven architectures
to deal with micro services and with the
whole use cases over distributed systems
and the event source system motivations
leads to the CQRS architecture and this
now has the benefit that you can first
of all scale independently because as
you only communicating via these events
in the event store you can fire up as
much systems as you like what I showed
here there are several instances of them
and all of them have their own database
which makes several things easy if you
change something on the code side if you
model your databases for query and
command side differently so that they
are optimized for each and every system
if you deploy much more query service
than command services because for normal
enterprise applications what we do we at
the right side we read site highly
outnumbers the number of writes normally
right you read way more often than you
write something for each and every
request you probably have a get request
that requests a couple of other things
and then eventually you change something
so it doesn't make sense to be scalable
only on one side right not them with
both and with the crowd based approach
you can't do this because you you always
well synchronize over the database and
yeah of course if you doing event
sourcing only what you do you apply the
current state by applying all the events
after another so if you always do that
on each and every request that would not
be performant enough right if you have
hundreds events hundred of bank
transactions and in order to calculate
the current balance you would apply them
each and every time
that mode would now scale right so you
kind of have a cache on this side and
that is each and every service with each
and every representation and that solves
that problem and well to scale on the
events they come from the event source
system and of course a nice side effect
of this if your event store breaks down
that is basically the same for crud
based system as the database breaks down
so normally you can't do anything then
at least here you can read on your read
side still you can't write because the
events won't be published but you can
read as you have an internal cache and
eaten each and every instance which is
quite nice because then at least your
read site is still available so any
questions on this yes yes
it's the order of the events important
yes it is important and because if you
it depends on what you're doing but in
some cases it will be important if you
think of money transactions first you do
one deposit of money and the second
won't work because of insufficient
balance right and you want to make sure
which one works so what the event store
implementation does it make sure that
the order arrives in order in the order
it was published or in the order it was
well at least received for the event
store and then the system the event
handler that deals with processing the
event will make sure this is received in
the correct order and then well your
business use case accepts the first one
and denied the second one for example
yes that's important and that's part of
the events or to do this reliably yeah
yes very good point and the question was
if it makes sense to validate on the
command server site before sending the
event and it depends if it's possible
yes of course it makes sense because if
you already know that the event or that
your use case is not possible and then
of course you don't have to send the
event because you already can deny it
right and deny it right away so yes you
should do this the reason why you
normally can do this if you involve
several systems so if I have the order
system here and it doesn't have the
information from the beam system well it
can't do this but if it can do it for
example because the order is not valid
at all then yeah you can just reject it
right away and you don't have to file
that event that totally makes sense yes
very good question any other yes yes you
need to do events or thing or in order
to do CQRS but not vice versa you can do
events or Singh in an old well
monolithic and crud based way using a
relational database so you don't have to
be an event-driven
approach and you don't have to involve
several systems to do event sourcing
that's what we did a lot in the past so
we did a lot of event sourcing without
this new world alright any other
questions yeah
yeah so what exactly so what would I use
as a vendor and there's a very good
transition to my demo now yes I'm using
Apache Kafka you could argue that kefka
itself is not an event store as well
normally that event store already
includes something like the current
state that would be like a relational
database and but I I would argue about
casca actually persists your events so
they are available in a persistent way
and they are published in a reliable way
as written to disk so actually this is
what I'm showing to implement it that it
will be well persisted and that it will
communicate using in my case Catherine
what you can also use is event store
yeah like from get events or calm it's
the original event store from Gregory
areum which uses I think c-sharp
internally it also has a Java API but
actually in the Java world Casca is
pretty common and also the Oracle cloud
offers and capita servers and a lot of
players out there use Apache Kefka and
so am I so what I will show is a demo
running on the bare metal cloud and what
I will show is what I call the scalable
coffee shop example so this is what you
saw in the slides it has three systems
the barista the beans and the order
system and implemented in Java EE using
Apache Kafka and as this is normally as
I said I would love to do some live
coding for you but actually while the
whole C curette so even for the most
basic examples you need to write a lot
of stuff like all the events and the
integration unfortunately it is not
possible in that short amount of time
but I will quickly walk through the
things that at least you get the idea
and that's what I think the most
important stuff so what do they have I
will show the order system I have an
orders resource here playing all jax-rs
render a rest interface for now for the
simplicity I have both the command and
the query service and
system you can totally split that up so
other than the jax-rs
resource here that can't be totally
separated if you will implement the post
and to get here in two distinct systems
which is totally fine but first of all
we want to order a coffee right by some
Jason whatever that uses the command
service that makes use of a so called
event producer and it published well a
new order placed event right as a set
void method to place order and if
everything happens successfully here and
that publish well we'll also have to
publish that in a reliable synchronous
way then you can may be sure that the
order has been placed and tell the
client well to to accept it with that
location come back later our order was
accepted and in the same way if you ask
the order query service then it will use
the world coffee orders that is my
representation of the coffee orders to
return that and return the current state
and what it's does here it is a
singleton EJB the police don't be afraid
of ejbs and single teeny dairies in
general and as with bean manage
concurrency this is probably the fastest
way I would say to have hashmap and
singleton instance of a hash map in your
system and this stores an ash map the
current state of all the coffee orders
that is updated with events so what I'm
doing in my demo application I'm using
Java EE C CDI events that will be fired
as soon as a new event arrived arrives
in katka so what it's doing here my
communication internally in that
application is done by a CDI and the at
observed method well applied in new
status in our aggregate coffee orders
here and then this current state will be
read from for example the order query
service
and that's how it basically works so
also in the question of time I won't go
too much into detail how the integration
with Kafka works here but ever said it
basically it consumes for for Kafka
event streams and for specific consumer
groups and as soon as one event arises
that is published by a Jason so it's
yeah encoded by Jason then a CDI event
is fired that will be listened to in
this aggregate and this is all that's
done on the read side here well and on
the right side the event producer is
also quite simple it will use the Kafka
Java API to produce that event record
and send it and that's the important
thing
in a and synchronous way so you can
configure capita in several ways and
what it's important here that you want
to make sure that if you publish an
event that it will be published reliable
reliably and Kepler will persist it
internally in order to make sure that
this happens questions so far so another
thing regarding the persistence what I'm
showcasing here on purpose is just an
in-memory store that means I don't have
a database other than Kafka to store the
current state of the system so all that
happens is these events as soon as they
arrive will be applied well in memory to
my hash map normally and two things here
you would first of all connect the
database so what you could do here
manually is include JPA
and then as soon as new events arise you
well store the current state in the JPA
database and then you commit that the
event has been consumed to Kafka and
second then you can apply a concept
called snapshots that if you fire up
your application you can well
with you can return from your last state
and yeah then make sure that everything
is is not applied from day one because
what I'm doing here I tell Kafka that
for new consumer groups that is the
concept in katka to send us all events
it will always resend all the events
from day one so by doing this in memory
that means if I fire up a new instance
it will ask kefka to give us all the
events to make sure everything is up to
date in my in memory day and hash map
right so it will recalculate all the
events on startup and this of course
doesn't scale if you have millions of
events because then on application
startup time you have to wait half an
hour until everything is applied right
so this is for production while you wire
include something like snapshots and
typically use a relational database for
that and then you can play around with
when to apply to the database and when
to commit that the event has been
applied reliably because this has to be
done then reliably and then character
won't resubmit these events any
questions
it depends how you want to integrate
your third party system so normally then
I would say you have one system that
handles the events that some what do the
payment right and that integrates your
payment system in a synchronous way for
example but as you're doing this in
whole events in the event driven
approach then this is done
asynchronously as a whole right oh yes
that's a very good point and that means
yeah that's your process of it doesn't
even have to be a third party system
button anytime and that it's not done
twice so you want to make sure that and
this is done by kafka consumer groups
that there will be one consumer group in
all your instances that handle the well
processing of events only once that
means that you have three instances and
there will be a new order that will
order place and then being validated
what I had that this is done only once
and this is done by having one distinct
consumer group and only one system gets
it and then will commit on the
processing of my new event and then this
over and nobody else will processes
later and in the same way as you have a
distinct consumer group for that if you
replay everything then this consumer
group is already committed to the last
status and it won't be sent
well it won't rehan Dalal these events
so then only for the other consumer
groups these events are we send in one
example and this is actually a good
point because this is what I want to
show in my demo so what we have here we
have three as H instances for our and
applications of what I have of course I
use an Ducker
and I have three Ducker instances beans
orders and barista that well as I'm
using Java EE will fire up three
instances of whitefly and that all three
of them as a set are totally independent
they store the current state only in
memory and of course they will all
connect to Casca
so I have the cat-car instance running
and all these three all the free
containers and of course normally you
would use some kind of orchestration
framework for this right but here we can
create a new order by posting - oh yeah
it's the same ID as before by posting
rest interface right a new order to our
order system and what it does - or to
accept it it will accept or order but
you can already know that it will never
work because we don't have beans in our
system right so it will then validate
and we don't have any beans yet so that
means if you look at the it lock order
it will immediately be canceled so there
is you know a new order and all the
failed beans not available and then
immediately order cancelled so if we ask
now our system although it was accepted
in the first place and this is being
eventually consistent if we ask about
our order then you see that immediately
it will be canceled so our nice espresso
from Colombo Colombia is not possible
although it was accepted in the first
place right but immediately it was
cancelled and well now if we want to do
if you want to do something that
actually is possible then we want to
post new beans to the bean system and
actually didn't check about the IP but
it's oh yeah it's the same so we just
requested the system to well store 10
beans from Colombia so then now if you
post to this that new order will
actually be possible so now you see same
outcome - to accept it
we placed another order but this time we
know that it's possible so and if you
look at the lock well or the beans
validated order accepted and so on and
so forth
and oh all the brew has already been
started and what we have
so I simulate the barista using a timer
and it actually yeah we'll start the the
coffee brew and then after some time it
will actually finish and then it also
will serve the customer so yeah randomly
eventually we will see some outcomes
that are always possible and in the
meantime we can actually order a second
one as we still have ten beams available
so then we see another order started and
so on so forth and I just want to wait a
second until one at least finishes and I
can show the next thing oh yeah now you
see it's finished and then later on it
will be delivered but even before it
will be delivered oh now it was
delivered yep that's it now we want to
shut down the system or all of these
free systems because now what I want to
show is how to reapply these events and
if we well start up again the order
system the bean system and the barista
system then ever set for heat and for
now it will fire up using new caf-co
consumer groups that means all the
events will be reapplied so we still
have the latest state of the system the
event handler consumer group will not be
reapplied so we don't have well the
validation a second time otherwise we
don't have eight pins but six beans and
then four and zero beans although there
were only two orders right in our system
and in order to showcase this we can now
you know still sign up the order system
here or the wall will be deployed and
now you can see already we lock that all
the events are there again so now what I
did I asked the same order with the same
random UUID that is now in the inter
system still although it's a totally new
system I deleted everything the memory
my map is gone and it was reapplied and
as all the events have been redeliver I
still have my delivered coffee available
although it's a totally new instance the
same is true if I would fire up three
new instances all of them will get all
the events and then you can ask each and
every system for this old order although
it's happened in the past although it
happened on a totally different system
but it's all communicating via the event
store and then it reapplied and what you
would do differently in production is
that you then would have a database and
you could then use your snapshot state
in the database as two new day one and
then start up from that so you don't
have all the startup time you can just
start it up and apply it maybe the left
can be then commit on them and then you
have the current state of the system and
you're fully up and running using that
secure s approach so any questions on
this yes yes exactly but this doesn't
matter then because the single source of
truth is still you events tour so if
your database schema changes and you
can't do any database migrations then at
the last resort you can always throw
away your database to a new schema
reapply all the events once so we have a
new snapshot state for your database and
then continue from that which is a
really a benefit because that makes data
migrations quite easy if you want yes
yeah yes
yes so there are some well some attempts
for frameworks for example this
eventuate io from Chris Richardson that
uses spring and well the thing is that
for both spring and Java EE if you speak
in ddd domain-driven design language
then the concepts mostly sometimes don't
really fit in into the traditional
enterprise framework development model
because when we have some kind of
managed beams there like like an EGD or
CDI managed bean or a service and spring
then you have one instance or a couple
of instances but normally not one
instance per domain object that listens
to all the events that you have
traditionally in a DDD world this
aggregate is normally per coffee order
then and that listens to all the events
that correspond to that order and so on
so forth and if you do this in Java EE
or in spring then it doesn't really
match so these frameworks there are some
frameworks around that well use this and
somewhat modify for the approach however
what I would say that in order to do
micro services you should actually not
introduce something like a common data
model or try to avoid this redundancy
because then you are tightly coupled
again having that set so for example all
these events here are of course applied
several times because each and every
system has to know about this event for
example and then you say well we have
now application because these events are
there three times for example plus you
have some of course some code but all
the code you have to define is actually
well you have to define all the events
but they have to do have to be there
anyway right and I wouldn't say the code
is too much for for what you want to
achieve so probably the biggest
challenge is that this is quite
and quite unusual for enterprise
developers so it's a totally new concept
and you want to make sure that you don't
well over engineer in terms of that you
couple your systems together again right
because if you now go and see all the
events and introduce something like a
common data model this then introduces
other problems because this is exactly
how the approach of this micro service
world is that you want independent
systems that could even one could use
Python nodejs and the other could use
Java if they solely communicate using
these events that are persisted here by
adjacent for example and then of course
you have some duplication but you also
have to freedom to change everything and
you don't well you know you're not
dependent on each other which is a good
way any other questions
yes
yes yeah yeah
so the synchronization is done because
all of the bins services consume the
events using that single event handler
consumer grouping Kafka and then cascade
delivers only to one event at a time so
that is done using Kafka CAFTA make sure
there are the events or make sure that
this event is delivered only once to
that consumer group yes
and then no because you actually consume
the latest state and then you can also
choose which version you consume but
basically if you say consume for that
version and you commit to some version
then only one system will get it and
that will still be applied in order so
having that said yeah it's quite it uses
some some algorithms internally to do
that but it basically says that one
system will get both of these events as
soon as that system commits to them
right we're running out of time so we
can answer another question and if you
want to hear all that in a more well
with more time I actually recorded a
video course that is available for free
my website that well introduce this
whole concept with all the examples
using a little a little bit more time
and it also shows how to connect to
Kafka using my java ee example so that
is available on my block and also it
points to the github an example where
you see all the code so I don't have any
slides available so everything I just
showed with the fpr demo is shown in
that video codes as well and you can see
the example on github how to integrate
that with cafe using java ee and then
thanks a lot for your attention</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>