<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Event-Sourced Architectures with Akka | Coder Coacher - Coaching Coders</title><meta content="Event-Sourced Architectures with Akka - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Event-Sourced Architectures with Akka</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gvsRl6xZiiE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you for joining me in the session
this morning my name is Solomon I work
for luminous technologies which is a
software company in the Netherlands
although we also do international pro
producing states as well and we
specialize in the creation of modular
and scalable architectures and there's
one of the main reasons that our was
also drawn to haka and event sourcing a
tech concept so what you will see here
is our exploration of what paka and
defense sourcing entails and I'm pretty
sure it will be very different from what
you're used to in so to say regular
mainstream application development but
just because it's not something that you
see often doesn't mean that it's new so
event sourcing itself goes way way back
like over eight concepts in our computer
science it's just that in my opinion in
the last few years there have been more
and more toolkits libraries etc I think
coming available to do event sourcing in
your mainstream development as well and
akka and especially are capriciousness
which we're going to be talking about is
one of these toolkits so the event
sourcing has been used for example in
finance for trading systems etc etc and
even though I'm talking about event
source architectures here I don't mean
to imply that event sourcing will give
you a top level systems architecture
blueprints for your system actually
event sourcing is just a new way of
looking at how to produce the state
inside of your application so it will
provide an architecture for death and it
will fit in nicely with other top-level
architectures like in a service-oriented
architecture or the whole microservices
craze that's going on right now or
whatever you're doing at the top level
of your systems architecture you can't
fit in
eventsource positions as well if you do
that you will probably end up tuning and
then changing your top level
architecture as well but that will not
be the main focus of this talk we're
just going to look at how can you do
persistence with event sourcing so
the journey for today is the first loop
together what is event sorting and why
would you even want to use this right
what are the benefits and then we'll
move on to a very short introduction to
the extra model I presume that a lot of
you will be familiar with actors
if not we'll have a short introduction
to that as well but then we'll quickly
move on to how to actually do event
sourcing using our crackers and that's
using our cup resistance which is a
fairly new addition to the deck a
library echo toolkit and we will have
first some examples of that as well and
in the end of the presentation we're
going to shift gears a bit and shift
away from actual code and look at more
what are the design constraints that you
have to think about when you're building
an event source application in a source
system so what is this offense sourcing
thing all about you might ask so let's
let's do an example so say you are the
general manager of an asylum for the
chronic insane is here I have a measure
from the 19th century and you're tasked
with administering this this is high and
people pay your money and you write it
down and people you have to fail the
people give the pay the bills you write
down and somebody comes in and pays you
and amounts you write it down and the
next day you think alright hmm it wasn't
really the right amounts they have to
tell you much much much much much more
so what do you do you grab your pencil
you strike out whatever happens
yesterday and you say okay well I have
to I have to forget about that and have
to fix it somehow well that's not really
how accountants work is not really how
people think you're not going to erase
the past and act as if it never happens
what you're going to do is the next day
if this person comes in you're going to
try settle it with them
they say ok you still have some amount
you have to pay and then you know down
the amount the extra amount that you
received and everything is ok again so
really events or thing is all about
getting the facts straight
and effects never change right even
though this person paid too much or not
enough well that will never change
you can only correct it later and a
correction is an addition to this
measure
so the generalities of event sourcing
are really based also on these
accounting principles so glance through
bookkeeping keeping the books balanced
by adding transactions never mind
changing transactions I mean if your
accountant does that you might want to
double check with them
really this is the essence of events or
C so our applications mostly loop like
this right we have a three layer
architecture the right interaction with
the client we have some sort of surface
layer which is tasked with implementing
the business logic and also talking to
the database that we have there so if we
were to implement a system for this
asylum in the current day and age we
would probably come up with something
similar like this and what we actually
do in a service layer is when we have
some data that we need to change or
resist or whatever is that we're going
to fetch it from the data that database
we're going to somehow modify it and
probably we're going to fetch it using
an ORM right hibernate or JPA or
what-have-you and we're going to
actually modify the object that we got
back and in this object of sorry and
this object we're going to just save it
save it stories and even then we're
going to that's the ORM or whatever
library we have figure out what to do in
the database you know to update or to
the leaves or whatever and this is
really something that is grown out of
our desire to keep this service layer
stateless right because stateless a good
stateless means that I can't deploy many
many many instances of my service
without having to deal with any
synchronization between the service life
but what actually happens is that we
push all of our
concurrency concerns all of our shared
data into this database but actually
what's happening is that we're using
this database has a very fancy looking
state synchronization safety net service
a and well that works
I mean I've build a lot of applications
that work his way and those were fairly
successful but it only works up to a
certain level and with level on the
scalability levels so once you're going
to outgrow your relational database you
really have a problem and this is
essentially where event sourcing and
positions using events or senior kicks
in so we have all these new fancy data
stores right cloud providers offer
really really cool and very scalable
storage systems but they're very
different from the relational databases
that we're used at they are very
different characteristics and I don't
know about you but most of the times I'm
not really sure how I'm going to use
these data stores with these different
interfaces with these different
characteristics and event sourcing
really has a good story for never
raising such data stores as well so
let's go a bit deeper in this typical
architecture still so where we have the
objects and we modify objects etc so
there's the old-school way to say and in
this example we have for example a
concert which is an artist a date and
available tickets and a price and it
doesn't want to matter in relation to
ticket orders because of course users
can order tickets many users can order
tickets so what would in this case
happen if we are going to change the
price of this concept so we're start at
10 so in our typical architecture we
would retrieve the concert objects
hopefully we wouldn't get all the ticket
orders but that's really an OEM concern
and we just set the new price on this
cos identity and we save it and always
well well what if for example someone
cancels
take it order all no no big problem
either if you cancel this order it just
means that we have to fetch the ticket
order to find the right one and just
delete it
that's gone and the available takers of
course have to be changed as well but
didn't do it here so what actually is
happening here is something that we do
very very often and I want to say that
really is very very very wrong to do
this and I've been doing it myself as
well but what actually happens here is
that you're losing information the fact
that you do an update statements on some
call in your database means that you
will not be aware of the fact that it
used to have a different value energy
from Earth of course for delicious so if
I delete this ticket order I will have
no way of knowing that either
yeah and that the ticket order was
cancelled or that it just never existed
that nobody ordered these days and I can
hear you thinking okay you can solve
this problem right you can have things
like soft Elise with the flags and
toggle them and you can have sort of
audit tables in which you track all the
old values or update and that's true but
that sounds like a lot of work and what
if we do you can sorting and get all
this audit trail for free and get the
insight into information for free
because like I said event sourcing is
all about facts facts never change
effects are never deleted in a sense so
what would it look like if we model this
using events or see same situation we
want to have some sort of a notion of a
concert concert with data if and take a
notice well the first thing you see here
is that these events are all in the past
tense because there are about effects
right so the first event is the fact
that a concert was created and still has
the same data right so a price and
artists heard of tickets and then once
this concert is create created biggest
can of course be ordered by people and
in this case we have three separate
ticket orders events and
this is just a continuous stream of
events that represents this this whole
concert is the concept and the nice
thing about this is that you can
actually reconstruct the structural
model of the concert that we saw in the
previous slide and truly what to the
trivial way if we had this concert
objects we would just apply this concert
created event an updated state and if we
for every two tickets or this event we
just created a ticket border project
then we would have the same model back
again so actually this is more or less
equivalent to what we saw in the
previous slide only things change
when we apply new actions to his
concerts so for example if I wanted to
change the price of the concert I'm not
going to change the events that happen
because it happens it's a fact we cannot
we have to live with that
instead we had to use a new event for
example this event price changed with
the new price now you see the difference
because you can still derive this
structural model again where the concert
ends up with a price of hundred but we
can still see that in the beginning this
concert had a very different price of
ten in this case and the same again for
cancelling an order what we're going to
do is not just ignore the fact that this
ticket ordered event happens in the past
and throw it away now we're just going
to create a new order cancels event for
the particular user that wants to cancel
this order and this way each state
change in your system actually is
represented by an event and the event is
what hold on to store and the event is
going to be our canonical representation
of of the data and using these events we
can either build up a structural model
or a different kind of model whatever
suits our application but the gist of it
is that we're not not going to throw
information away never so what do we
gain by event source modeling instead of
this structural or
well events are immutable like I said
we're not going to change them and that
means that your event stream will only
ever grow and at months it might sound
like a bad thing but actually there are
lots of data stores that are really
happy to write very very much events for
you into an append-only storage because
that means you will have a sequential
access instead of random access when
you're doing updates and this is really
a very reduced case for many of these
highly scalable data source that exists
another very very cool thing about
having an event stream to represent your
data it's the fact that you can replay
the stream at any point in time so you
can reconstruct the current state or you
can also reconstruct historical state
right if you just replay a subset of
your event stream you will end up at a
better state in the past and this is
very powerful of course you don't have
to expose this to your users but you
could do it you could say okay I want to
see what this order look like or what
this concert look like at this point in
time and all you have to do is look at
what events were stored until that time
and replayed and there you have it in
your application so these events are
also in and of themselves and all its
real right because each piece of
information is stored in these events
it's never deleted if something changes
to just is a new event with containing a
new information where you can always
refer back to whatever was more stored
before there's a question okay there's a
question what if you have many many
events and if you want to go free step
back and then you would have to replay
all the events up to minus three so to
say and that's true but there are ways
around that and we'll see that there is
an optimization possible in the scenario
as well so the last point events as an
integrator
mechanism we'll get back to this a bit
later in the talk but you can imagine
that if you have clinical events
happening for each state change in your
system that is all but also a very good
way to update for example external
implications or to inform different
components of your application that
something has changed and you get it for
free by just doing event sourcing
instead of in-place updates on your data
now we saw these events culture created
tickets orders etc etc and you might be
wondering what are these events come
from right because there's not really
how we think we're doing application
design we think in actions users take
actions and then something happens so
the dual of an event is a command and
the command is actually a description to
the system do something order tickets or
create a concept in event sourcing we
work with clouds coming in and what a
command does is it describe the intent
of the user what actually happens in the
events or system is that it takes this
command and it actually turns it into
events and these events are the
representation of what happens to system
so here again events they're just facts
you have to deal with them it happens
you cannot change it with commands or an
imperative you say do something to the
system and then big difference is that
commands may be rejected
right if you have an order tickets come
out for a thousand tickets and you only
have for example a few left that you
might just say to the user okay I reject
your command the fact that you reject
you come up maybe an event you know
itself that you store but in essence
commands will always have to lead to
events in your system in commerce can be
responsible to the user so you can
either report success or failure or
maybe even give back some information on
what happens in the system
so using offense hours in this way gives
you a very nice way to model the right
part of your system but you might be
wondering what about the real part what
about query because we're so used to
having a normalized database where you
can have a dog sequel queries and that's
this a very nice model in a sense if you
do not know her from what you want to
know from the data so that in that sense
we're a bit lazy
I guess if we're using a relational
database but now you only have this
event stream right this is linear a log
of all events that happens so how do you
queries well one way of course would be
to there's a question the question is
okay have dependencies between events to
trace back what event cause what you
could of course do that but it's not
something that typically happens in
events or systems what typically happens
is that you have a sort of a consistency
boundary for example in a single entity
like a concert and you just serialized
all events and that's the order that
they're in and there's no different
dependencies between that's just what
you typically do in you can store system
so I was saying it you have a plain log
and if you have a query yeah the only
thing you can actually do is walk all
the events that are in the log which is
of course cost-prohibitive if the dog is
very big so fortunately there are
solutions to that as well and one of the
approaches is of employed in conjunction
with event sourcing is glomp query
responsibility segregation this is
actually very mouthful but come on we've
already seen that that those are just
instructions do this in a system the
chorus is actually what we're interested
in here and what CQRS actually says is
that we're so used
having a single model in our application
that we use for both writing and
updating data and querying data but why
it doesn't have to be this way
why not split these two concerns up into
two separate or even maybe more than two
set to compartments in your system one
which actually accepts the rights and
there's all the updating and one which
is really specialized in query and when
you think about it sometimes we already
do this in your systems right if you
have an us X search for example running
in conjunction with your database now
you're actually sort of doing CQRS
because you're saying okay sure it's
it's really something that the database
itself is badass
so we employed elasticsearch instead so
that's the general idea of CQRS and you
can do CQRS without defense sourcing so
this will be the state of affairs if you
are not doing any secret seek us
implementation so you would have a
command which travels to reserve layer
of this database and any queries also
come from the same database in the same
model they can have of your data and the
service length and I think we've all
felt the pain here if you have a
particular particularly a nasty report
to create then it might be very hard to
get this out of your database or it
might be very hard to get this out of
your model layer which is really more
based towards yeah real-time updates and
transaction processing so what they say
what see curious is okay split this up
there's a model that's really suited
towards updating and writing and it
might still be a database right this is
a relational database but it might also
be a a different data store it doesn't
really matter and then on the other hand
if you want to create queries data then
we have a much better way of
representing this data for example in a
graph database if you're interested in
the relations or in a key value store if
you're just interested in very
particular parts of your data and not
the whole entity Harvey so the big
question of course here is how you keep
is in sync
that's always the issue so if you have
this datastore for your command model
and if you have an relational database
there and you're doing updates and
deletes now you're still losing
information so if you want to build one
of these query models yeah how do you
know that you still have all the
information to build this query model so
people are doing this and there are ways
to do this and one of the easiest ways
of course when you're for example using
views for materialized views in the same
database etc so there are ways to do
this to a certain extent but it gets
better when you use events or CQRS so
what happens there is that the command
model is actually the model that we've
seen before where you send commands and
these commands are turns in into events
which are stored in the journal and
actually these events are can then be
emitted to the read side as well
what a query models update themselves
and in this way you're guarantees to
keep these data source and sink and of
course they're still concerned what if
we want to one is down or the other is
up and there are things to think about
here but since the model is sound you
have a canonical event stream that
represents everything that happens in
your system
every state change in your system is
captured so what about access right
because we're here for akka and
persistence using an event sourcing so
myself is a very mature and open source
toolkit has been around for a while it
has both Java and Scala API and pretty
important in this context is the fact
that it also has a clustering feature
which means that actors cannot just run
on your local machine but can be a
dispute around the coast as well and
since we're interested in doing event
sourcing for scale we need some way to
escape from just having a single machine
so a cursor is going to help us with
that actors themselves well there's
there's really not that much to it an
actor is an object so to say that has a
mailbox which receives messages so you
interact with an actor
sending messages to it instead of for
example calling methods on an object
this message sending is asynchronous the
mailbox is handled one message at a time
by the extra itself so any logic that
you implement any behavior to implement
inside of this EXA can be sure that
there is only one mesh has been being
handled at a time so you don't have to
think about looking or whatever you can
just update the internal state of the
actor as if there were no other systems
order threats or whatever interacting
with you so I think it's a nice
characterization of actors you're an
island of consistency in a sea of
concurrency and the nice thing about
exes that are very lightweight they're
not tied to a single thread for example
there are many execution strategies for
our practice maketh many many actors in
a single JVM I think they've been
marketed to several million millions of
ecstasy in a single JVM so really it's a
very lightweight model to do concurrency
now is an actor a good fit for offense
sourcing you might ask one thing that
really makes the bad fit out of the box
is the fact that this mailbox where you
receive the messages is actually non
durable so it's not stored on this by
default or anywhere else if your jetty
empresas then your your message sugar
are gone and the same holds for the
internal state of the actor so that's
does Reno go out of the box for default
akka accent on the other hand you might
think well this model if I squint my
eyes a bit sort of looks like what's
happening with the commands and state
that's changing right because an actor
British one command at a time and it's
handles this command at the base estate
so why don't we just store all the
incoming commands for an actor and if
the actor fields jvm fields or whatever
we can just replay all these commands
and the internal state will we build up
again and your
where you were where you started well
this there's some merit to this IV and
it's sort of works but it breaks down
because we already established that
commands and events are different right
so in every message that you sent to an
actor tisha as you command it says to do
something and it might be rejected it
might be a faulty command it might
perform side effects charge your credit
card or whatever now you don't want this
to happen when your system replays all
these commands right so we have to do
something more and a lot of issue there
is a what for example if you have a
failing command right and if it's
written to the journal before it's
handled to the ex oh yeah well we replay
time and time again and your ex will
feel every time so this model is
seemingly nice and attractive and simple
but it won't work but that is where echo
our positions in terms of its head I
have to say this is an experimental
module of but it will be part of the
upcoming to the for release if
everything goes according to plan
and again this position module also has
Scala and Java API and what it does is
it tries to add resistance to access
using the concepts of events or C so
what does this look like again we have
this actor but now it's a persistent
actor which is provided by our
consciousness and you can send commands
to this actor and actually what this
advocate then can do is it handles sis
commands first this report means it has
to validate the command where it's even
I fell apart if not well it can just
reject it and do nothing but if it is a
fellas come out it must have some
effects on the internal state of the
actor and it does this not by directly
updating States but by deriving events
from this command so for example a
create conscious commands would result
in a concept created events being
derived
inside of the action it stores these
events in the journal and once it's
stored it will actually apply this this
side effect of this events or bedding
state or maybe even charging credit
cards or whatever only then that happens
in the internal state of the exits so in
a persistent x-ray you always have to do
implements two ways of handling messages
one is the one I just described where
your handle commands the other handler
that you have to write is to handle just
playing events that were written to the
event block and what happens there is of
course that you get all the events from
the event lock and you should only obey
your state based on these events but you
shouldn't before the side effects that
were associated with the commands that
led to this event right because when you
reconstruct the state of a persistent
actor you do not want to charge the
credit card again for ticket order so
all these persistent actors are
identified by so-called the actor ID or
position ID that is used to create a
separate area for each Britishness actor
in the journal and this is why the event
stream for for a given persistent exer
ends up so let's look at some code what
we have here is some Scala code which
shows a very simple persistent accent
it's very simple because we have a
single integer as a state and we're
going to try and model a counter so we
need to come out now we need events
that's what was defined here by the case
objects so we want to say to the actor
increments and at least of course two
events incremented now to create a
position actor you only have to extend
the persistent exit clause innaka so
that's very simple it does need you to
override the persistence ID to create a
new unique ID for your persistent extra
in the journal in this case I'm just
going into the counter and I'll I have
this state this internal state of the
actor which starts at zero now like I
said you have to implement two kinds of
message handlers inside of an persistent
actor instead of just one for normal
actors in this case we have two
to receive a mouth first which obviously
receives in this case e increments the
command and what it does is it calls
deep resist method which is provided by
persistent actor and it resists methods
you will have to pass in an event or
events that you want to store what is
come on I also give a second argument to
this persist a callback version and in
this callback function that's where
you're actually going to do your side
effects and the rating of the state of
your actor so what we have here is a
persist my increment event by the way
since it is a callback might make sense
of course you that this is asynchronous
so the communication between the
persistent actor and the journal is
asynchronous as well and when the
journal is done processing your event it
will call this callback handler a can
update state and you can print line so
just to simulate an side effect even
though this callback from the journal is
asynchronous it doesn't mean that in the
meanwhile at different messages can be
handled by this persistent actor because
that would of course wreck this directly
internal state of your application so a
persistent actor guarantees that the
Associated callback for a persist call
is actually called before any other
messages are being picked up and the
other commands are being picked up so
this is sort of the online transaction
processing part of your a persistent
actor or what we have here is the
recovery part of your actor and what we
see here is that we do not handle a
command because those are historic but
we're going to handle an event our event
stream is pretty simple we only have
incremental events and each time we
receive this incremented event on
recovery we're going to increase our
counter by one so this actually allows
us to create an actor with internal
state that can be reconstructed from the
journal just by replaying these events
and of course the print line will not
happen on recovery because it's not that
it's not there now back to the question
of gentleman isn't this going to be
really really slow
if you have many events and the answer
is yes probably if the
a problem in your system you can employ
a mechanism called temp shots so here
again we have this counter active but
now I'm creating a snapshot in character
and the difference here is that are
handling an extra message in my receive
c'mon say if I receive a message take
snapshots I'm going to call be
persistent nectars method
snaps save snapshots and I'm going to
pass my state in and actually what
happens in the hood is that the position
sector will write out the state to do a
snapshot store so you can have both a
journal and a snapshot store associated
with your position vector and in your
receiver koper you will must receive
only events but you will also receive
the latest snapshots so recovery will
start with the latest save snapshot and
from that point on you will only get the
events that have been persisted after
this snapshot now you might be wondering
okay what kinds of things can i plug in
beneath these servers as actors this is
all done by our plugins so you can
really mix and match and pick and choose
whatever you want so for general and
snapshots you can use Cassandra you can
use Kafka there's a new plugin for the
dynamo to be mobile to be HBase metabee
and even playing JDBC back access are
possible though I'm not really sure why
you would want to do that because you
will run into same scalability issues
there of course as far as the
serialization goes by default the events
and the snapshots are actually last
using Java serialization which is not
recommended of course because of all
kinds of issues that you can have with
compatibility there so the advisory is
to choose a different plug-in to do
serialization and there's many options
you can do protocol buffers you can do
cryo Avro those are all schema based and
evolution ready mechanisms to
civilization so really yeah you can have
conviction match there and pick whatever
suits your domain
application now we've seen the right
side of our persistence so that's a
persistent actor handling commands
resisting events and eventually
restoring from events but this only DC
part of CQRS and we still have to fix
our queries right because this
persistent acts are still only creates a
sequential event stream and whatever
we're going to ask difficult questions
for this data so there's an Magnusson
for that as well in our composition is
called the persistent view and what you
can do is you can create a persistent
view that points to the journal ID of
position actor what happens is that this
persistent fuel will update itself with
all the events that are stored in the
journal for this actor and what you can
do in this view is of course create
domain-specific use data for your use
cases the point is that often you want
to do this for multiple event streams
you want to do some aggregation that's
currently not natively supported by
persistence views though support for
that will be in the next version so
currently you can only track a single
persistence actor ID which is sort of
limited but yeah it's for some use cases
it's enough and you know the other nice
thing is that these persistent views
since they create a very different model
of your data they can also have their
own snapshot store in order to create a
quick recovery scenario so what we have
here we have a map persistent Excel
radically journal and this persistent
few takes all the messages out of the
journal it this is by pulling the
journal is some journals also support
pushing so I'm currently hoping that
this will also be supported by our
compositions so the events can be pushed
to a view instead of pulling for it yeah
question
the simple question is can you have an
aggregated extra that becomes itself on
the whole process and let's show a real
question yeah okay yeah so the question
is if you have a persistent actor that
there's aggravates these things yeah
into the journal yeah yeah you could do
that but I think you still have some
ordering issues then right how does
aggregation so I think we should just
wait for a solution where positions you
can merge actually these journal logs
so the polling is configurable so you
can see how eventually consistent you
are between your view and your protector
but it also means that this view can
live without the actor being life which
is also very nice because rights are
less frequent than reads most sisters
know this a very nice quote database is
a cache of a subset of the lock which is
actually very true way to think about it
I'm not going to go too deep into it
because with lots of different things as
well I want to give an example of the
persistence view so here we have this
view and it has to has a have a
persistence ID to point back to the
right persistent actor but you also have
to specify a view ID because you have
your own snapshot store and we have to
somehow identify that as well and then
we have this internal state again and if
this view of court only receives events
of months and if I receive a persistence
incremental collapse I'm going to do
some very complicated complicated
calculation on the security state and
going to store it inside of the sector
and in addition to handling these events
if you of course has to respond to
queries so in this case I'm sending a
complex a query request and to the
sender I can just bring back my state
because it's already pre computed inside
of this view now I'm doing doing it
within memory state but you can also use
this persistence of you to update
an external data store right each time
you receive an event you can add or
remove a relation in the graph database
and when you get get a query you can
actually do a query on this graph
database and get the result back so this
is one way to get the synchrony
synchronization between the mob part the
query parts or your system I've created
an example for you guys at this URL the
bit the URL which actually shows a lot
of the concepts I'm not going to show
the code in detail here but you can look
at it at home and the last five will
also have a URL for this example so
you're welcome to check it out and see
how this looks like in practice now
we've talked about scaling right and so
far we've seen a single position vector
and a single few etc so but how does it
work if you want to create a scalable
system using these actors well acha has
a closer module like I said which allows
you to run access not just locally but
on Christian notes as well and since
producer actors are just actors they can
benefit from the same approach but
that's a twist because since a
persistent actor is actually creating
the canonical event stream for some
piece of a system we need to ensure that
this actor is there's only one of them
so we only need one persistent actor for
a persistence ID writing to the germ now
there is a solution and a catalyst that
Kristin module called cluster singleton
which actually can assure that a actor
is running only on single node but the
way it works really isn't what we want
because it just chooses the oldest node
in the cluster and runs each singleton
on the oldest node which is technically
correct but not a really scalable
solution for us so that's why for this
ruling persistent actors over cursor we
need something extra and in this case
there is an extension for akka
called cluster sharding which actually
gives you a flexible system for shifting
around these persistent actors around in
the in the actress
and what we see is that you have a
single coordinated there so that's the
single term in this case which actually
manages which charts live on which
region each of these short regions those
are actually instantiated on each node
in your cluster and these manage the
access to your persistent axis so what
happens is that if you create or want to
send a command to a persistent actor in
a cluster you're not actually going to
look up the persistent actor itself I
sent a message there no you're going to
send the message to the shark region and
the shark region tries to find out okay
where this is act to live and forwards
the command to the actor and reply back
to you as well now the very nice thing
about of course about the position Texas
is the fact that their state is in the
journal so you can easily rebalance the
cluster and ship will be persistent
action around because it's just stopping
the actor and starting to possess a
persistent actor at a different node and
just replaying the events and snapshots
and you get your state on a difference
different person of I think it's a very
refreshing way of looking at surveyed
distributing your state across the
cluster and the way this works is by
making sure that this close to shouting
extension knows about the ID of your
actor right because otherwise it's not
going to work so what you have to do to
use this cluster sharding to provide a
method that can actually from each
command that you have in your system
extract the ID and the command so in
this case we might have concert ID on
our commands from the extract extracted
and give the command back and there's
also of course the question of which
persistent actor belongs to which shark
in the cluster and they implemented this
by a consistent hashing algorithm so
what you actually do is that you have a
hash of your ID for the position vector
which actually determines where the
active lives so for which region the
charge region it will
fall into there's also something that
you can tune yourself by implementing
this chart resolve a method passing back
to the first extension so this is the
way that you start this cluster shouting
accession you have to provide an active
system just a plane close to the access
system you've called the start method
and you say okay I have this this sort
of type of vectors called concerts if
they provide the props which is a way of
telling a car how to create these
position actors because you're not going
to create yourself anymore actually
you're going to delegate that to the
closest shouting system and you have to
provide this ID extractor and this chart
resolver to assist and then when you're
going to talk to this actor you're not
actually going to talk directly to the
persistent actors anymore but you're
going to talk to this region so you're
saying to the closest shouting system
give me the chart region for the type of
concept position to access and then
you're going to send a message for
example buy tickets and this has to
contain the ID the extra concept that
you want to target another cliche
shouting will figure out using the
coordinator and all the other chart
regions where the position x-rays and it
will route to missus accordingly so
unfortunately it doesn't always go to
the coordinator it's those cash some of
the locations of the auto shard regions
once it has talked and once and that's
of course very nice because otherwise
you would have a single point of failure
in your cluster which you always said go
through so what about designing for
events or see because we've seen a bit
of directionality for why you would want
it and we've seen a way to implement it
using a cup resistance well what happens
if you're going to actually try twice at
home so that's where a lot of times in
the description surrounds you can
sourcing a CRS also domain-driven design
comes up now let me preface this with
saying I'm not a domain driven design
guru so this is just my understanding of
what I've seen but what you have in the
meandering design is the concept of an
aggregate which is actually a
combination of a single root entity and
several related entities that together
must always be fully consistent right
you can have many aggregates of course
in your system and one day I need to
communicate communicate with each other
they they do not have this strong
guarantee of full consistency and why
would you do this to yourself well the
only reason is of course again skill if
you do everything in a fully consistent
way you would need a single
transactional data source underneath and
that's just something that we wanted to
get away from with this architecture so
it just so happens that these aggregates
really met very well to our notion of a
persistent actor and okay took it so
Allstate inside of a persistent actor is
fully consistent you're always
guaranteed that you're handing one come
on all the time and you're always
guaranteed that the event stream is
orders in a way that you write to it and
etc etc so the really met really well so
even though our cup resistance is
definitely not a food domain driven
design and seekers toolkit it comes
really close and while following the
descriptions on the mailing list it will
become even better in this regard over
time because there's something they're
working towards themselves as well so
what about design of these aggregates
this might seem obvious but it's really
something that that that doesn't happen
very often when you start designing when
you start talking to the business people
and you should really focus on the state
changes in your system instead of trying
to find out what is all the state that
is there and how should we update it
it's really tempting to go and draw a
structural diagram so for your domain
and think that's all that there is to it
but actually we talked about the events
and things happening that's where you
get to the interesting points that's
what a business processes emerged that's
where actually yeah the most of your
system at a failure will be in as well
so if I the areas focus on state changes
and the events
system rather than just teasing out the
structural representations of the domain
because these will follow naturally if
you see whatever happens and what needs
to be record size matters as we've seen
if you have small persistent active
small areas with relatively little
little events then replay will be faster
and of course you can always employ
snapshots to also speed it up but in
general smaller is better but on the
other hand if you have small aggregates
and small position taxes it also means
that you have to have a journal that
supports as many of these journal
entries as you need in your system first
said that's trade up that you have to
make and the depends on what kind of
journal you're using underneath another
thing is that what cigarettes
it isn't always immediately the case
that read you're right consistency
applies yes come outside if it's
criticize and if you perform a come on
and you do a query directly after that
yeah you're not guaranteed to see the
effect of the kalam directly in the
query so if you need this there are ways
to do that you can infer of course
directly query your persistent AXA but
there's only one of that that's not
really scalable you can also employ
something like sequence numbers where
you say okay I want to do is query but I
want to be absolutely sure that I'm at
least at this sequence of events number
so but those are things you have to
think about when you're designing
systems like this so communication
between these aggregates or between
persistent actors they should never know
about their internal details of the
state so actually the domain driven
design of five years in these aggregates
here Haru density and you should only
know about visuals ft bytes ID and you
can ask it to do something for you but
you should never be able to update it
yourself the holes here as well it also
means no distributed transactions
because those
generally don't skill as well and that
means if you don't have distributed
transactions that you might have to
employ other mechanisms like
compensating actions right if something
hasn't acknowledged back to you you
might want to try it again and on the
other side if something has succeeded
but your acknowledgments was lost
somewhere in the way back to the
requester you might have to be able to
cope with an additional commands but
ashes they do the same thing so
duplicate removal on the left side is a
thing so that's really it sounds like a
lot of work and it might be but it's
also something that can be done at the
business level right we always tend to
select solutions where we have reliable
delivery and really are really are
reliable messaging you can ask yourself
how reliable it is right it's only
reliable when you have a business level
acknowledgement of that something
happens in your system and that's more
or less the model that you need to
follow when you do you can sourcing and
sakura-san domain driven design as well
although I must mention there there
isn't at least ones delivery
implementation in our competitions which
well this what it says what the name
implies and you can use it as well in
your system and then a caucus typically
bookkeeping for you for messages that
have make sense between persistent
actors it's like like a set system
integration is also something that you
can do using the events that are stores
parties and sourcing an example what
I've seen is that you have an
application that use a cup resistance
and use Kafka as as a journal and there
are multiple topics in there and these
topics are not just consumed by their
compositions application are also
consumed by an analytic system for
example spark streaming which can also
read events from car park use and you
can even combine topics inside of Kafka
and you might use that to the place for
example an external application and keep
it in sync with your
resistance application so all kinds of
possibilities there and I think it's a
really powerful way of looking at the
whole system design as well if you're
doing defense source resistance now if
you look at commands they should be
self-contained right they should contain
enough information for his persistent
actor to validate the commands and to
actually derive all of the events that
need to be done so it's sort of like
yeah this command should not have to go
out and fetch all kinds of different
information to do is thing it should be
the units of atomic change if you send
two commands in sequence to a persistent
actor they will be handled one after the
other but it might be that one succeeds
in the other fields so if you need to do
something atomically to the internal
state of persistent actor it should be
done using a single command and you have
to think about the granularity and the
intent of quartz right and that's
something that you don't have to really
think about in a structural model but in
this case you have to you can have
something like an update address come
off but you can also choose to have a
change treat change city command and
this really also depends on what your
user interfaces like course the user
interaction is like the first one is
more if you have sort of a crude screen
second one might be more if you have a
task-based interface in which people can
for example only update a street and
intention I mean their address is sort
of a crate action but you might want to
move to more meaningful commands like
okay this person wants to move and that
does mean indeed that I need to a very
address but it also means that I have to
send out some information etc etc etc
which is all captured by a meaningful
even commands the results in all kinds
of events inside of the actor if you
think about designing events well like I
said past tense it has to be an
irrefutable fact and if you have an
event for example in this case the
tickets both events after
my tickets come on let's receive you
really do not want to store the arrived
state inside of your events actually was
it's much better to do
Delta based events in this case you want
to store the fact that someone bought
the single tickets and not the store
detects that the nuclear capacity of
your culture is now under minus one
because you can do it yourself when you
replay the events and you build up your
state again if you look at events
themselves it might be a good idea to
always extend an event with some
metadata like the who when where etc and
if you do this you will get a lot more
value out of the events that are in your
journal because they're truly an order
to lock their versioning is not a very
interesting topic because of course when
you have this event stream you're bound
to change at some time right software
changes is just a fact of life and what
you can do is you can evolve your event
version one to version two and then just
start storing events in versions version
two but that would mean that your actor
actually has to implement both logic for
handling version 1 and version 2
commands right so this is the most pure
way of doing this
there's also another solution to this
problem you can also say ok even though
I have a new version of micro mal it's
backwards compatible with the last
version of class so I'm going to rewrite
the version 1 events to version 2 events
while preserving their meaning of course
otherwise yeah you're rewriting history
you know I mean preserved male voice the
whole concept of a event source so you
might do this at the joiner level and
you could also do this at the DC
realization level and with a occur
serialization plug-in and this way you
only have to implement the logic to
handle the new version of commands
inside of your actor another way which I
wouldn't recommend but you can do this
is to say okay I have a new version of
my events so at this point in time I'm
going to take a snapshot of my actor and
I were to throw away all the previous
I don't want to handle them anymore I'm
going to take the step shows as my
starting point and from then on I'm
going to store all the events well you
can do this but obviously it will not
allow you to go back in time anymore to
be 40 snapshots so the lesson here is
that even your events in a backwards
compatible way use tools like opera or
protocol buffers to evolve your events
because there's those allow you to
actually translate easily between
versions of events if they're compatible
and you can do this translation in the
sterilized sterilization program if you
want to do so you can also first
snapshots generally think it's not
really worth worth it and migrating
between snapshots is going to be pay so
in summary I think we've seen that the
event sourcing is unfamiliar at least it
was to me to us quite a while ago but
it's really a powerful concept and if
you think about it yeah there are lots
of applications that might benefit from
this this architectural pattern to reach
the skill that you desire it really
combines well with the main different
design and the cqs process so having a
model for your commands and having one
or more different models for your
queries really you can apply that even
if you're not doing event sourcing like
SF it's really a good at you going back
to the relational database again I mean
it's sort of strange that we have this
normalized database that we're using and
it's really optimized for writing and if
you want to do some queries it has to do
all kinds of expensive joins etc and we
have to Bent then the object array
object relational leopard tour will to
do all kinds of crazy it's really
strange why not just separate those
concerns and creating a different way of
models that are really suited to your
use cases but then again event sourcing
is report not a gold hammer
I wouldn't recommend using this for your
next simple crud application that is
used by ten users in your opinion and
your company really this is something
that you should be thinking about when
you need the non personal benefits of
different sourcing so this factor you
can go back in time factor you have an
audit blog for free the fact that you
can scale using an append-only an
immutable storage so the combination of
a cactus in that persistence really does
give a good fit for event sourcing but
then again you should be a bit wary
because our compositions really isn't
production ready at this point in time
but it will be in a couple of months if
I see the development that's going on in
there
so it's currently experimental but it
will be part of the final version of I
got to this for so with that I just
wanted to point out that's at 11:30 in
the room I have a little talk coming up
it's just about touch groups from the
developments very different with cool
topic as well if you want to look at the
code that it created for the session and
look at that URL and I want to thank you
and open the floor for questions this
question here okay the question is how
will you approach develop my REST API
and this I don't think the fact that
you're using rests that really have has
that much effect it's really just a
prompt to get in your commands into your
system so it really depends on what
happens beneath the rest layer whether
this makes sense or not a question
okay this question why you taking
snapshots are the old events
automatically removed and that's not the
case so you have to do that explicitly
if you want to do to redo all the events
yeah okay thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>