<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Is Your Code Parallel-Ready? | Coder Coacher - Coaching Coders</title><meta content="Is Your Code Parallel-Ready? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Is Your Code Parallel-Ready?</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/k0FMfIhMDck" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">afternoon alright so welcome to his talk
on the title says is your code parallel
ready thank you for coming to the talk
like to thank the organizers of Java 14
for allowing me to speak I know that you
have a choice when you go to when you
come to Java one about which talks on
lambdas you're going to go to some
sometimes people say hi there's so many
talks about lambdas but there's also an
idea around that it's big enough subject
lambdas and streams that different
people are going to put different points
of view and you may you'll learn
different things from the from the way
that the way that things are posed so my
my analogy for this is the idea of you
know the blind men in the room with the
elephant they're all report something
different so today I'm going to report
what I found by feeling the tail of the
elephant the idea of this talk is that
i'm going to i want to explain the idea
of parallel ready code i'm going to do
that in terms of my understanding of the
of it as a motivation for the designers
of the stream api I always believed that
you can't really work effectively with
an API unless you're in tune with the
ideas that the designers had when they
were thinking about it so you if you
don't understand me or what you're
working against the grain of the API and
that's not always very obvious the
Javadoc for example tends to be pretty
dry and it just states things in a
rather bold way and young at any sense
of what's going on behind the scenes at
all so I'm going to try i'm going to try
and communicate that as well as well as
i understand it i mean in particular the
idea of the idea of parallel ready code
which is kind of which is actually quite
important it's very important to the way
that the way that the designers were
thinking actually wasn't ever formulated
although i didn't i didn't in fact
formulated it was Brian gets who put the
idea forward it wasn't until I kind of
insisted that there should be a word for
what it what I'm going to talk about
today that the what
the word came into existence so the talk
is going to be at quite a high level I'm
not going to it's not going to be a very
thorough introduction to landers and
streams I am going to go into detail
about the collector API because you know
I'm just I'm just a kind of over
enthusiastic about that so if anybody
was at my talk yesterday that was some
overlap of them with the material then
is there anybody here who was at my talk
yesterday wow you guys are really
suckers for punishment I I knew somethin
you know San Francisco is the world
capital of kind of weird desires but I
didn't know I didn't know that anybody
wanted punishment like that I'm going to
finish off it I'm going to finish off
with some practical examples which I
hope won't have again to have too much
overlap with yesterday's talk so this is
me i will describe myself as a repeat
offender i made the mistake of writing a
book on java 5 i'm co-author of the book
on java generics and i'm now author of
something something good i can actually
wave it at you i believe today the rumor
was going around this book doesn't exist
but not actually is so i got i got this
book this week this is what this is my
book on java 8 i'm kind of down on
oracle on sun and then oracle because
they left 10 years between right between
the release of the major upgrade of java
that was java 5 and the upgrade that was
java java 8 and with my poor memory
10 years was quite long enough for me to
remember the excruciatingly long enough
meat for me to forget the excruciating
experience of writing a book so that i
made the mistake of doing it a second
time so I'm really hoping they're going
to get themselves organized and bring
out the next major upgrade but I still
remember how horrible it is so so the
what I'm going to talk about today I'm
going to actually trace I'm going to try
to reconstruct as i said the ideas of
the design team in an hour and that you
may think that's pretty ridiculous
because i had absolutely nothing to do
with the design of the stream with
streamed api and in fact i wasn't even
really paying very much attention at the
time so you know but i'm going to do it
anyway the official documentation for
using the street for use
streams the the thing I'm really going
to be driven off more than anything it's
in the Javadoc for the java.util stream
you but as i said as i said before
although you could although there's a
lot of information in there it's quite
dry and it's not you don't you don't
kind of get you don't you don't going to
get the picture from it to at least i
don't anyway I think you'll understand
it a lot better when when you have some
background one other thing I'm sorry you
may have heard you may have heard me
expostulating earlier on yesterday when
I gave this talk this the the the screen
was about four feet lower down and
people at the back couldn't see the
bottom of it at all so I spent an entire
night cutting on my slides horizontally
in half and then they raised the street
so now they gotta look absolutely
ridiculous because you look like the
bottom half of the home to slice is
going to be empty hey that's life so the
the big ideas in the stream API or the
way that I want to present them anyway
is that is it first of all i'm going to
say they were they were inspired by the
ideas of pipes and filters so i want to
talk about i won't talk about that very
long because it's pretty well-known idea
and then then i'm going to say they
wanted to take pipes and filters and
they wanted to add parallel listen to
that because actually the kind of really
major driver of the of the lambdas in
java 8 and the streams api was a
particular use case in the particular
use case was how can we actually how can
we manage to break down certain kinds of
operations for execution in parallel on
multi-core architectures and although we
get very many other benefits from
streams api and in fact for most java
developers the other benefits will far
outweigh this parallel ism nonetheless
apparently the possibility of doing
automatic parallel ism was going to was
was really a major major factor and that
that falls into our managing the
parallel ISM falls primarily into two
parts because like the the hard parts of
managing multiple threads is starting
them off and allocating work to them and
then the really hard part is terminating
them and merging the emerging their work
together so that those are the two parts
I've talked about here recursive
decomposition
just the breaking of them down I'm not
going to talk much about that and
parallel merging because I'm kind of a
freak about that so i will talk too much
about that so the idea to let me let me
start off by talking about the idea of
pipes and filters before we have before
we talk about parallel ilysm at all so
is this this is a this is a very very
old idea at least 40 years old and
everyone who's ever worked with UNIX for
example knows it very well so I've got
an example there of how you might manage
a line which looks like it's the output
from the process table and where we're
looking for a particular log in and
we're catching and we're catching
particular field out of that and you
know this you know this kind of idea so
that so what the UNIX calls filters are
these are these processes here and the
pipes are the vertical bars between them
and basically we work stream of text
lines of text which of which are flowing
between these processes and each one is
doing something else to it and the same
kind of idea and in a rather different
forms has also appeared in an enterprise
integration patterns it's really quite
common and the notion behind it is the
is is that if you break tasks down if
other if you build large tasks up from
small ones you get a better engineering
results because the small tasks can be
engineered very precisely and then if
you have different ways of fitting them
together then and and the right ways of
fitting them together then you can build
larger tasks very easily and this is
good this is really well substantiated
by by command line tool building in UNIX
and and and programming shells and so
forth so the advantages of this pattern
from the from the from both from the
operating system point of view but
particularly from the Java point of view
is you don't have any intermediate
variables and a minute and in Java the
intermediate variables that you manage
to get rid of by doing this would
typically occupy a lot of a lot of
storage and occupying a lot of storage
well you might you may say well memory
is very cheap and and so it is but all
the same there's it will sell out up and
the most crucially if you are using a
lot of memory that you don't really want
because its intermediate like you're
storing something and then you would
then you're using it for the next
process and so forth that implies a lot
of garb
collection and garbage collection is
very expensive in terms are about
however cheap memory is garbage
collection is going to continue to be
expensive in terms of time for a long
time to come so so it's so getting rid
of intermediate variables is is is a
really good idea and in an intermediate
storage I was really talking about
intermediate storage there intermediate
variables are just cluttering your
program intermediate stories as a
physical thing that they do it gives you
the possibility of lazy evaluation so if
you generate a stream or further if
you're if you're using using a pipe in
UNIX but we'll see the same thing for
streams in Java then you don't need to
generate any more data than the your
program actually requires suppose for
example that you're looking for I mean
the kind of common examples of this but
supposing you're looking for the first
prime over over a hundred thousand
something like this then you can then
then what you can do is you can just
carry on generating data until you find
the thing you're looking for and then
you can stop and so that that I've given
an example they're actually generating
an infinite stream which of course lazy
evaluation is the only thing that makes
possible but lazy evaluation in general
is is an economical strategy for for not
generating data that you are not
actually going to need and the big deal
about it is flexible tool building so
there's the slogan of the the UNIX the
designs of eunuchs were the right
programs that do one thing well and
write programs to work together and
that's really what they're that
philosophy has been reflected in the in
the java stream api actually there was a
third slogan but since we don't pay in
it since we don't actually follow that
one I don't put it up that one was that
one was that we should always deal with
text because text is the is to compute
the universal medium of exchange between
UNIX processes but that one's not very
practical for us but these two are
proven engineering proven engineering
ideas ok so I'm going to show some
examples here and my example domain is
very simple one that's the same as
yesterday where we've got a
a person and i made it as simple as
possible we have a person we're going to
just going to have tea fields city name
and age of type the city is an inner
name is a string age is an int and and
i'm going to generate i'm going to
assume that i've generated some persons
and i'm going to have a list of
sometimes i'll assume I've got a list of
person called people which is just a
bunch of people so so really all we all
you need to know is that we've got
accesses on those fields that's all I'm
going to be using okay so pipes and
filters in Java look like well they look
they look pretty much like pipes and
filters so here we've got a I've got a
query which says it's everyone an adult
so I'm going to some some I'm taking
people i'm turning that i'm feeding that
into a into a stream I'm mapping that
mapping every element of the stream in
turn to an int and using using this
lambda here why it's a method reference
and it represents a lambda so this
syntax means for each piece of reach
person p that i get a map that into the
age of the person and then i want to
check that and then i'm going to check
do all of those match this condition
here and this is this is a real lambda
where for each a that's an age because
ages have been passed down the pipeline
the age is greater than or equal to 21
may ask how many people are immediately
recognize this because you've been
looking at streams and lambdas okay so
that's probably about half of the half
of the audience may be a bit more than
half so that gives me an idea of the
pace that I should take so and here's
another one and these these are actually
quite useful because up and because at
this point I'm looking at things which
were as we'll see in a moment don't
actually require to know anything about
concurrency these could have been
written these these conditions could
have been written by a version of the
stream API which didn't support parallel
ISM here I'm taking people and I'm and
I'm streaming and
putting that into a stream again I'm I'm
calling map and transforming each person
into into their corresponding city and
then I'm then I'm printing the I'm
printing the the city out so sorry I
should say now I'm now my action is for
each element in the stream I'm going to
perform this action on it and this again
is a method reference which is really
the same as a lambda and it says for
each p call system out print line on
that p so one of the reasons for putting
this up even if you're not familiar with
lambdas and streams is for you to get
its you to get a bit of a feel to
intermediate insight into the very
concise and expressive way in which the
in which operations are expressed so so
the claim is and and I support I support
this claim that this is clearer than
iteration it's better than iteration in
a number of ways we're going to see that
it's definitely better than iteration in
terms of efficiency but it's also better
than iteration in terms of style too and
in terms of readability and
maintainability and in terms of how easy
it is to to to change programs slightly
so the things that we've seen here map
and map to int these are called
intermediate operations because they
operate on every element of every
element of a stream and they just
transform that element into something
else well maybe they don't transform it
is that how I classified the different
kinds of intermediate operations in the
book I wrote them down at these six
kinds which are kind of fairly arbitrary
by just like grouping things and you'll
see that most that they some of them
actually do alter the the number of
elements in the stream and quite a lot
of them don't so filter for example
you've seen that I mean that allows you
to drop out elements that don't fit a
predicate mapping allows you to change
in each element into some into something
into a corresponding value possibly of a
different type by applying a function
flat map will take a single single
element and stream and actually
transform it into a number of elements
in the stream so it goes from one to
many we're going to
illustration that later on for debugging
you've got the the peak method the key
to the peak operation which allows you
to to for example to print the value of
each of each element in the stream but
maybe to do it maybe to do other things
as well you could place annotator
structure under certain circumstances
sorting and deep sorting sorting and D
duplicating while sorting it's kind of
obvious really d duplicating will give
you back one element of only a single
element of each value in the stream no
matter how many of us there are I'm
truncating will will will either skip
some elements of the stream or will
limit you to a certain number of
elements so I've got some little
animations of how these things work
which ad I know appear modern I don't
know if they do if you're not familiar
with this stuff maybe maybe they give
you a little bit of insight into what's
happening his filter we've got an
element coming down the coming down
stream this one set this one's a a
string and and that since the predicate
is that the the filter that we're using
here checks to see that the length is
less than for that one passed this one
doesn't pass so it disappears out of the
stream and here's one that another one
that passes so that's the kind of thing
that filter does map changes an element
to another one of a different kind so
here's his bill and here we the function
we're applying here is that we're
getting this we're getting a city from
for each person so that so that changes
that and the same kind of way and i
won't i won't pain you with the rest of
that and peek allows you to well in this
case what the consumer that have used
here system out print line because
that's kind of nice an illustrative peak
is intended for debugging modern and
rather than anything else so actually
system out print line is a reasonably
good one to choose and finally flat map
in this case I've chosen flat map to int
and the idea that the idea of flat map
is to take a single element and to map
it into many elements in the stream so
it actually changes the number of
elements in the stream so here comes a
string which is the string is made up of
three characters Amy and I'm flatmap to
int that this this
function here will so flat map to apply
to the Charles method of string which
which returns you that which returns you
a stream of characters corresponding to
the string that you put in you actually
get individual individual elements of of
the of this string are now sent down
sent down the stream as characters so
what's what you get so we get out well
the primitive car type so what your dad
is an int stream the stream the stream
to specialized you have reference we
have stream as a reference types and
we've also got streams of int double and
long as there's a primitive types so
flat map will break down not only this
is only an individual case but it'll
break down any any object and any value
and and send multiple elements down down
down the stream in place of it okay so
that's a kind of idea of the that's a
kind of idea of the intermediate
operations the ones i haven't shown here
because they're harder to show us are
the stateful operations now actually
don't make a great deal of difference to
you as a programmer but they're rather
harder to visualize possibly not on
sequential streams are quite easy to
visualize when it comes to parallel
streams are harder so these are
operations that depend on coordinating
values in different threads so the
sorting indeed indeed OOP locating
clearly you're not going to be able to
treat each value one at a time in the
way that we just did for the those those
stateless operations when you want to do
sorted you're going to have that you'll
have to form what they call a barrier
collect all the values in the stream
sort them and then pass them on down the
stream so they're big implications for
efficiency there and they're big
implications particularly for how it'll
execute in parallel but the that's the
that's the basic idea and and sorting
and sorting and truncating are typically
very very much more difficult for them
to program efficiently on parallel
streams so that's the idea that's the
idea of the intermediate operations for
the beginning and end of streams we've
got lost for stream sources well I'll
talk about those later because it hardly
makes any sense to talk
now since I'm only at this point talking
about sequential streams pipes and
filters then it seems pretty obvious
that's that the source of a stream
should just really be an iterator
effectively so there's really not a lot
more to say there's nothing much more
interesting to say about the source of a
stream that's going to be sequential
except it's just going to feed values
into the into the stream one by one
stream sinks are are a bit different
because I managed to show you examples
at the start where pipes and filters
worked even for sequential streams so
and and could be easily could be easily
understood just in those terms so find
first and these these are search
operations fine first we'll simply look
for an element in the stream find any
will non-deterministic alee look for any
element in the stream and the difference
between those doesn't really make much
sense when you're thinking about
sequential streams any match and all
match are easier because these these
these will take predicates and they'll
return that they'll return a boolean
value corresponding to the obviously the
truth and whether the whether the
predicate is matched by any element or
whether the predicate is matched by all
elements of the stream and these are
short-circuiting operations once they've
once they've discovered for example if
any match discovers an element that that
that satisfies the predicate then
processing of the stream stops because
you found what you wanted and all match
similarly will will will stop processing
the stream if it finds an element that
doesn't match it because it can then
return false there are so these are
these are the search operations the side
affecting operations are ones which as
you work by side effect which is kind of
seems that doesn't exactly run in line
with the with the the philosophy of this
of the stream API and of the idea of
parallel ready code so one of the one
thing that the one thing I would say is
let's look at these things with quite
carefully and with some caution because
they seem to be taking us back into a
non-functional style of processing they
seem to be saying well actually but you
can iterate over the values in the
stream and the alternative to doing that
is is reductions of various kinds and
those are the things that I really want
to talk about next because you
wouldn't although functional programs
have been using reductions since almost
forever it's not clear that reductions
would have been very important in Java
if it had not been for the next big idea
that I want to talk about which is
having para taking these streams which
I've talked about the basic idea of a
functional style on sequential code and
now moving that on to talk about
parallel ism or maybe not to talk about
parallel ism because the the inspiration
for the next few for the next few slides
is as a top my guys steal she's quite
famous now in which which is entitled
how to think about parallel ISM not and
his basic idea there is that that really
the what we should be thinking about
when we when we consider parallel ISM is
how basically it can be automated so
this is so in this in this talk which I
recommend you which I recommend you look
perfect thing is it's probably in
several versions on the on the internet
the one I found was a strange loop in
2011 and the one reason one reason for
looking at it is because in line with
what I've said at the beginning it was
influential on the Java designers they
they paid their paid attention to this
to this talk and the ideas in it so the
so you get some insight into what that
into what they were thinking so I steals
idea is that where is that as the
history of computing and I want to go
through this and a lot of detail the
history of computing has been a
continuous process of programmers
relaxing their grip as it were on the on
the physical aspects of the other
process and giving more and more control
over to the machine so so when you go
from writing machine code to writing
assemblers you're giving up the physical
address of the code and you're going to
allow the because now you're going to
say well just jump to this symbolic
location and now the the programmer no
longer knows exactly where the code is
just say I set location and you give it
a label you have the compiler a little
the assembler a label and similarly when
when you go to when you have register
allocation I mean it used to be
really a black artist was managing
register allocation when you were doing
assembler programming because you
obviously wanted as few unnecessary
registers transfers as you could as you
could manage and when compilers became
able to do register allocation again
programmers had to relax their grip on
the on the process heat management
involved the completely losing track of
whether where your data is you now no
longer have pointers to physical
addresses in memory you just have to now
rely on your memory management system to
handle all of that so it's so
increasingly it did not in return for
the benefits of automating process and
in return I guess for having less work
and operating into a more abstract level
we have to give up control and if I kind
of find control over the way that our
programs are executed so his his
proposition is that parallelization will
become another one of these another one
of these aspects and the and that
essentially it's going to become the
role of the system that's supporting the
execution of your program to to decide
whether to execute in parallel or how to
execute in parallel I should say well as
i'm going to as i'm going to explain
whistle some distance from that in java
with we've made some steps in that
direction but the parallel ism support
that is in java 8 is doesn't by any
means allow the programmer to step back
completely from the from from the from
the decision about parallelization it
does allow the programmer to step back
from the strategy but only because
essentially there is only a single
strategy for parallelization we know
that in the future or we believe that in
the future this situation will continue
to improve and that is a major reason
for talking about parallel ready code
now even though the actual the the
actual real gains in terms of
parallelization that you can make with
your codes proper are for many people
and most of the time probably fairly
small nonetheless if in the future and
when in the future i should say the
technology improves then your code will
be ready for it beforehand
so um I know what that is that's that's
me moving the slide up just in case
anybody at the back couldn't he couldn't
couldn't see so does don't say I'm not
responsive to his needs so so just to
continue for a moment longer and on guys
and guys talk his his idea was we're
gonna have to give up some old habits
and and most these old habits there are
two rather general ones we we've been in
a tradition for a long time people worry
a lot about performance and typically
they use operation counts you know the
amount of the number of operations in
your code as a proxy for efficiency and
that's not necessarily going to that's
that doesn't necessarily work any longer
you may you may have to be prepared to
waste operations to reduce communication
between different threads it doesn't
matter if you're performing the same
operation in different threads if the
elapsed time of those threads is
actually reduced by doing that even if
the even if the amount of work done by
any individual thread is greater this is
another side that's broken up by they I
would have loved to put all these on the
same one pan in mind minimizing space
usage in the same way by sharing data
between operations this is really this
is really really difficult with multiple
threads if you share data between
operations then you've got shared
mutable state you have to synchronize
access to it and that's going to
increase contention and destroy the
benefits you get from parallel ism and
here's an so these are kind of general
these are come general rules and they
won't you can hold them at the back of
your mind but here's one that's really
going to make a big difference to your
coding because oh sorry one more no this
one linear cut decomposition with
processing one thing at a time to
accumulate results but that's really
that's quite a big thing to give up
isn't it so really no more accumulators
so the idea is we're going to have to
give up accumulators we're going to have
to change from using accumulators
because accumulators imply that your
that you that your operations are
focused on a particular location and
therefore if you've got multiple threads
those multiple threads are going to have
to coordinate their access to that
particular location and we're going to
have to go over to
I didn't conquer strategy is symmetric
type merge operations seriously no more
accumulators I mean that's the arts
credit it's quite it quite a big thing I
keep on going on about it and this aside
some time I didn't realize quite how
many times I've written it mmm so this
is this is good this is good the big
impact on this is on terminal operations
because almost all terminal operations
or accumulators of some kind and that's
why I didn't carry on talking about
terminal operations when I was talking
about pipes of filters her i told you
about about intermediate operations
which are kind of okay to understand but
terminal operations are all of I mean
apart from find and find and match and
so forth which are returning a boolean
or a single element or for each which is
an iteration in fact then all the other
ones where for example you're getting
all the elements of a stream and putting
them into putting them into a container
which is actually absolutely typical
thing that you're doing a Java program
is uuuu process things and you put them
in a collection those things are all at
the moment written as accumulators of
some kind typically you've got a loop
and inside the loop you say things right
so we're really that really means that
we're going to have to be have to do
things quite differently so the idea is
that I mean here here the the the idea
about getting rid of accumulation is
shown on with just a simple simple
summation program on int just to show
because I just want to show that what
the execution pattern looks like so
basically what we've got here is a
linear pattern to you take your keeping
a running total yes I'm keeping a
running total of all the values in the
array nanbanin and first I'm going to
have to call this in a location the
location is called some and first of all
I add that one to it and add this one to
it than that this one to add that one to
it and so on so that one that's going to
be if if we're trying to think about
multi multiple threads executing this
and I said that was a really major
motivation at the start then you can see
that although the single thread can do
this quite efficiently multiple threads
are going to have to somehow manage the
concurrent access and without
synchronization your data will be
corrupt them with synchronization your
locks will get hot and you're good to
waste your threads will waste a lot of
time waiting for access to
so avoiding an accumulator hope avoiding
an accumulator involves using this this
this operation so in stream as an
example of a stream that had that has it
operational has a reduce operation I'm
going to look at I'm going to look at
this one which takes an identity and and
a binary operator the combined two int
and it returns an int so the execution
path here avoiding accumulator looks
like this well it can look like this so
um so what we've got here is we've got
we've gotta reduce opera we've gotta
reduce operation the one that I just
showed you and this one doesn't I'd not
use the one with the identity here I'm
afraid so she chosen the wrong one this
was the other one on the slide here's
the one without the identity and and so
the one without the identity takes two
numbers and adds them together and so
you could get a pattern like this
actually that's not the only pattern you
could get of course I mean you you'll
probably see immediately well why have
you taken these two numbers and these
two nums added those two together and
then added the result because that's
what we used that's what reduced us
supposing the threads the threads
actually work differently you might get
that pattern instead so you might get
these two numbers added together and
then these two numbers added together
and then these two numbers I mean sure
this isn't this might not be optimal for
multiple threads but it's certainly
something one thread might do so for
these these two different patterns of
these two pattern two different
execution paths have to produce the same
result because you don't know that it's
speed that which the different threads
are going to execute you don't know the
strategy that the the framework is going
to use for allocating data to the
different threads and therefore they
must produce the same result it doesn't
make sense otherwise and and the that
means that you're your operator must be
associative and associative means
grouping doesn't matter in other words
if the value of a plus B plus C has got
to be the same as a plus B plus C this
microphone coils likes me too much so so
this is a property that's got to be the
case for
it's got to hold for four binary
operators in reduce operations or for
operations and reduce for operators and
reduce operations generally so here's
the first idea about what parallel ready
code will look like it's going to look
like this and I haven't got to the
definition to my definition of what
parallel ready is yet but it's kind of
easier to say what are we going to be
the things that will make your PO make
your code non-parallel ready using
operators that aren't associative is one
of the things that will so now I can get
on to now I can get on to the thing I
wanted to talk about which is reduction
over an identity here it is my picture
of reduction over an identity this is a
different reduce operation and it starts
off with it with an identity and I debt
the identity for addition is zero
because zero added to anything is still
it still is anything there so the
identity for multiplication is one and
so forth and here now I've colored in
and now go and now really kind of built
up built this up in i'm imagining two
different threads that are working that
are working in on different regions of
the array each of them adding adding
adding up the their segment of the array
and then finally some other thread or
maybe one of those two threads adding
them adding them together so the and
what's important about this is the same
operations got to work for adding these
two numbers together as combining them
in the end so that's reduction over an
identity for for primitive values and
you may well think was what wasn't I
talking wasn't he talking a moment ago
about how we're going to accumulate
things into collections because that's
the problem i'm driving towards here
because yeah and not that not the
primitive values aren't important and
not the programs involving the amount
important but most of the time what we
do in Java or a lot of the time what
we're doing job is put things into
collections so you might think that if
we had a reduce operation over an
identity for collections then it would
look the same and in fact there is a
reduce operation over reference types
and it does look as though you could do
exactly this so it looks as though the
identity here we
be like an nth in this case I'm thinking
of an empty an empty list so an
arraylist and we've got an ad operation
it'll take an element from there and add
obviously adds adds a single element to
to rate this and some some some then
eventually you've got a combined
operation which in the case of of an
ArrayList is a doll so you take her so
you take an array call a doormat dumps
that that combines 222 array lists so
the different that so these obviously
have different types add takes it takes
and it takes a list and an element and
combine takes two lists so you might
think this was a good idea and I have to
say you would be wrong about that really
I was trying to I try to work out a way
which I could really tell you this is
not a good idea maybe maybe you remember
this reduction really doesn't work for
mutable types and the reason it doesn't
work is very straightforward it's
because the identity reduction assumes
that the identity will be immutable and
it will reuse it a different threads may
well reuse it so it's entirely likely
that one thread will start putting
things into it and another thread will
use that identity that will use that
so-called identity the same value as
though it were as though assuming that
it was going to be empty so the kind of
 an innovation in the in the in the
streams API was this idea of collectors
and it looks the next slide is going to
look quite like this one so you can spot
the difference and the difference is
here that in that is that that a collect
operation is unlike a reduce operation
since it doesn't assume it's going to
get an identity here it assumes that
it's going to get a function which will
produce an empty container all right so
each thread therefore can get its own
fresh empty container for the for the
for the purpose of for the purpose of
doing the collection and that's the
thing that makes collection
significantly different from from from
from reduction sorry yes
the API does not prevent you from doing
the previous one right sir so it's
really quite an important message to to
get home and i'll explain to you i mean
i can give you an illustration how
important it is I didn't realize this i
didn't understand this point and i spent
a lot of time developing programs for
the one program for my book in which
which this was exactly the mistake I
made and I know there is I know other
people have made the mistake as well
because you can actually find other you
can find at least one other book don't
know of that actually has that mistake
in it and we see it in labs and so it's
a there's definitely real possibility
the fact is that reduction over
reference types isn't very useful and
there are fact there are three overloads
of reductive reduce for reference types
and you can find a use for two of them
but they only work they're really only
effective for immutable types and one of
them I can't find a useful and I think
that and I think that basically what
happened was that they would they were
working through the the evolution of the
collection of the collector API and they
didn't have time to they didn't have
time to rationalize fully their
understanding of where they've got to
and I'm not just actually when I say
that I wasn't a witness to the design
processes that's true but what I just
told you is true for sure so you might
think I mean a kind of natural thing you
would think is looking at this is wait
wait if I want to make a collector do I
have to provide the supplier an
accumulator and a combiner that seems
like it's going to be a lot of work
unfortunately the answers this is no
they're they're very keen to tell you
that in fact it's quite an unusual thing
to want to write a collector of your own
so I've explained what's going on there
because I think it's really quite useful
to understand it but actually most of
the time you'll be using collectors that
are that are created by factory methods
in the collections class in the clip
collections class sorry they should say
collectors class I don't understand how
I got there so there's a collector's
class which is as you would imagine like
a full of static factory methods in the
same kind of way as the collections
classes for collection so kleptos create
create collector objects and
the collectors are will do things like
accumulate the contents of your list two
of your stream to a list to a set it
will take two functions and accumulate
them to a map it'll take a stream of
strings and join them together
concatenate them possibly with something
in between there's our and I can
actually I got something here so in this
case is the framework provides the
supplier so these will put in the
current implementation these will
accumulate to an ArrayList into a hash
set if you if you if you're not
satisfied of that you can choose your
own map map or collection implementation
and there's a third set which which
actually classify elements and we're
going to see those are really quite
interesting because it they actually
open the door to some 21 a very powerful
feature of the collector a p.i which I'm
keen on which is composition you can
actually fit collectors together they
can pose together very nicely so you can
do quite complicated operations with
them his is an animation of a simple
collector and again you'll be thinking
I'm insulting your intelligence with
with with it with a picture of how you
might collect in this case you want to
collect all the people into it into a
set so so the idea is that the framework
supplies the supplies a set here as an
intermediate value and here come here
come each of the elements they're going
to they go into the set and they are and
in the output from the whole thing is
that is the is it so that's kind of bit
trivial really let's choose something a
bit more complicated because to to
justify having all these elaborate
animations this one is this one is to
map what what the to map method it
expects is it's going to create a map
and the keys of the key to map will be
got by extracting keys the values from
this function and values will be found
by extracting values from that one so
this is what this will this produces
this is going to produce a map from city
to to name and his roughly the way it
will work i'll show you a bit of it so
here's that here's the to map and it's
going to basically we're going to call
get city to produce the the key value
and we're going to call get name
to produce the to produce the name and
so and then there's that there's an
entry in the map and so on but being
there'll be another one coming up and
then how will lose patience with this
and the obviously the output in the end
is a map from city to to string which is
the names okay so those those are like
the simple ones what about the what
about a more complex ones so here we've
got ones that actually take people a
little bit of time to understand when
they first see them grouping by uses a
classifier function to make a
classification mapping it's not like to
map except the values that are placed in
the map or are actually the elements
themselves are ratcheting they're not
the elements themselves but it put into
a list for example you might get a map
from city to list of person by streaming
by streaming people through the collect
operation which is what obviously is it
what makes use of a collector and we use
the grouping by operation simply on that
on the the get city method so again
we'll we'll just we'll just see how one
of these works here comes bill and Bill
is the lives in London so they get City
method on on bill gives you this and he
goes into a list there and I mean and
maybe I bet it on another another couple
of them so Amy lives in Athens so
there's a list is made up for Athens and
finally John also lives in London so
he's going to go into the list as well
and the output from this will be a map
from London to I let me I can show you
more quickly than i can tell you so so
that there's that's how grouping by
works and it's surprising it's
surprisingly useful we're going to see I
hope given time how just how useful that
can be you might say well what if I mean
there seems to be something hardwired
into this what's hardwired into it is
the fact that everything is that you you
just got a list here you don't have any
choice about what they went into so it's
kind of natural generalization to wonder
well could we maybe put them in
something else why does it have to be a
list and this is where composition comes
in very importantly because the the it
would be it would have been kind of
crass I think even even even I would
have noticed if they'd have actually had
a different over loads of grouping by
for each
different kinds of data structures you
wanted to put your you wanted to put the
the values into I mean I'm one for a
list and 141 / set and so forth that
would have been kind of stupid in fact
what the in fact the nice generalization
here is that there's that you can
compose this collector with another
collector and in fact you already are
doing in fact the collector here is the
two lists collector which I didn't show
you it's because what that's doing is in
practice in fact what was what was
happening there was that each one of
those elements was being collected by
that by by a downs of what we call a
downstream collector so supposing we
want to put these things into a set
instead of a set of a list than we can
we can supply a downstream collector and
and I know I'm going on about collectors
but I wanted to get to this point at
least because it's this idea of
composing collectors is so important in
the stream API so the red here is what's
different from the from the previous
slide here Mr saying that the grouping
bar is going to use the classifier
function to make classifying
classification mapping and it's going to
supply the elements that come out of the
classification mapping into a damn's
into a container defined by a downstream
collector so it's so it's like to map
except now we can choose what what kind
of container we wanted to go into and
the Miss overload will accept now
remember that this is this is a factory
call of a factory method of the of the
collectors class and therefore this is
this this is a collector itself so it's
like being passed on down to that so I
mean this is the point at which I really
kind of feel well maybe these animations
really do have some point here's here's
the dance here is the downstream
collector and and we've got again the
same same mapping we're going to group
by we're going to we're going to group
by by the by the city that people live
in but this time we're going into we're
going into a these these are like the to
set collector they showed you at the
beginning of these animations so that so
what's happening is that this is
actually been composed with this one and
in the end of course what's going to
come out it's going to be like the like
the default one with the with that we
have one slide back but instead it's
going to instead of being a map from
city to list a person it's going to be
that from city to to set a person so
gotta get rid of this yeah that's good
to the next slide did I I missed one
there didn't I okay so so last of all I
want to talk about last of all amongst
the most these collectors I want to talk
about specialized downstream collectors
because what we saw there was a
downstream collector which could have
been used as a nod like an ordinary
collector to set we saw to set is a
collector which can be used as an
upstream as an actually a standalone
collector as well but there's some there
are some things you want to do here for
which we have to have specialized
collectors like for example supposing we
want to serve as we want to counter the
number of elements well there's a
specialized reduction for doing that but
you can't but the reduction expects a
expects to get elements off a stream
it's a terminal operation you can't put
a terminal operation into a you can't
compose a collector with the terminal
operation but you can compose it with
the terminal operator with with another
collector which does the same thing
right so that so that so so also there's
a there are duels of the count operation
the some operation these are terminal
operations on streams kind of said this
wrong the dual of count is a class is a
collector that's produced by the
collectors counting method and the dual
of some is a collectible used by the
collectors not some method and the dual
of a map is quite interesting because
you can you can take the elements that
come from the classifier and before they
get further collected you can you can
pass them into a mapping collector and
that's produced by again by obviously a
static method of the collectors class
and what it does is it pre processes
elements that come from the classifier
before it passes them to answer yet
another downstream collector so now
we've got three collectors composed
together and it really fits very nicely
so I think this is kind of a significant
achievement I don't have time to show it
all to you you should come to my talk
yesterday and then you'd see this in
more
Peter okay so when we're definitely not
going to do that so now we're in a
position to start visualizing stream
operations very little time left what do
they look like well they this is what
they look like in the can in the simple
form so we've got with what we've got so
far we know how intermediate operations
would work so in parallel we're going to
see intermediate operations let's just
assume that we've got stateless
operations here like map or filter
because that's going to be much easier
to visualize we don't have an awful lot
of time to do fancy animations with
sorted or limit so I'm now and then they
go I'm assuming that was a map and it's
going to get passed into the into the
mutable reduction so we kind of we've
kind of got that got the idea there but
what's this showing this is interesting
I don't know what that was oh yeah maybe
maybe all this is showing is we don't
know yet how these parallel streams are
going to be generated so that's the last
part of the puzzle I said I was going to
leave that over because the ideas behind
the generation of data for parallel
streams don't really make a lot of sense
if you look at them sequentially so I
was able to find operators for sequin
terminal operations for sequential
streams but I wasn't able to find a
sensible source for Senator for stream
operations on sequential streams yes
uh-huh I'm saying it in this case I'm
not sure I'm not sure I get the question
I'm all right dot soup all right so I'm
saying I'm saying dot stream I'm saying
dot stream because there are two options
I mean thank you for the thank you for
the question when you are when you're
getting a stream from a from a from a
collection you've got two options you
can either call stream as I've been
doing or you can call dot parallel
stream in fact the word parallel doesn't
I don't think that doesn't appear
anywhere in this talk and there's
actually a reason for that
so the and the reason for it is that the
idea of parallel ready code means that
we should be thinking like this whatever
implementation we're actually going to
choose so here's my argument I know that
I've got four elements in this in the in
the in the collection that I'm streaming
here to write parallel stream would be
insane in terms of performance that's
there's absolutely there's no possible
benefit that I could get from that
because the overhead involved in setting
up the apparatus and I'm about to show
you for for generating parallel streams
it's far greater than any game you can
make by doing processing on forums
unless unless it would really unless you
were doing some massive cryptical
cryptographic operation so it's very
sensible me to a written dot stream you
right parallel stream or dot stream on
the basis of performance decisions which
are kind of quite complicated actually
and and I just could recommend you to a
good book that would tell you about them
but a bit mean that without with that
would that would be that would be wrong
so but but but just take it from me that
for these toy examples it's not sensible
to write parallel stream but the idea of
writing parallel ready code means we
should think as though we were we were
working with parallel streams and the
reason for that is because well I've got
you given the reasons for that I've
given you that that that the idea that
we're insensibly that we are both
future-proofing our code against
technical advantage that will make
parallelize automatic parallel ism
better more feasible in the future and
we also the claim is we're also going to
get better style now right yeah if I
don't if I don't write parallel stream
then then it will then it will execute
sequentially yeah well execute
sequentially but I'm going to tell you
something important about the sequential
execution compared to the parallel
execution in a minute
yeah yeah sorry the question what the
question was are we going to have to
adapt the code to the to the specific
performance requirements of individual
cases cases and the answer is yes we are
absolutely it's the put is it it is the
programmers decision whether to whether
to go parallel or not and that's quite a
serious decision and the answer is at
the moment in many cases and probably
your the default answer is don't write
you almost always you have to kind of
understand your problem quite well
there're that I'm not saying there are
no cases by any means but you'd really
need to understand your problem pretty
well so let me press on because time is
amazingly short visualize extreme
operations so I said that ok so I think
I've done this so I've said the one
thing that we don't know is about how
how these streams are being generated so
they're implemented by thing called a
splitter ater and the splitter ater is a
kind of cute combination of a splitter
and an iterator and it can do both so
it's actually provided with methods that
will allow it to either break a data
structure into into two and generate a
new split generate a new splitter ater
that covers the top half i think in it
and it covers the bottom half I and
these splitter aters can again split the
code down and they'll carry on doing
this until for one of a number of
reasons it's not worth doing it anymore
because I mean you wouldn't split it
down until you actually just had it had
a single element that wouldn't make any
that wouldn't make any sense and beside
you wouldn't have ever have enough
threads and practice to justify doing
that so in this case I'm in this case
I've stopped at four at four split or
four segments which actually corresponds
to the four core machine that I used for
my for the experiments in the book so
that his for splitter a turn each one of
them each one of them covers a section
of the data structure there and now now
they are going to send their there we
can now imagine these these are going to
be processed by different threads and
each one will send will send their
element
into the operations or will processor
their elements by the operations in the
pipeline sequentially so now they're
actually going to they're gonna they're
going to work sequentially through there
through their individual elements and so
that's the iteration part she's all
splitting part and now you've seen the
iteration part so now we have that so
now we have a sort of complete
visualization of stream operations
because we've got a splitter rating now
we've got intermediate operations and
we've got reduction or mutable reduction
actually this picture is still very very
far from complete a one problem about it
is it's far too neat I mean there are a
number of problems about it there's only
a single intermediate operation and
typically you'd have a chain of them
another problem about it is that the
intermediate operations are stateless
and you might well have stateful ones
which require to combine things but one
of the things that is that is worst
about it is that is that it seems to
show it shows all the elements moving at
the same time and that's not going to be
the case at all I mean it's never going
to be the case because you've got
different threads and those threads have
no not only them no way of coordinating
with one another but actually
coordinating with one another would be
extremely wasteful and pointless so
actually what's going to happen is these
elements are going to are going to
appear are going to be processed in
random order now you can say i want the
order of my I want the order of my data
to be preserved so so in this case it
looks like it would be preserved and it
can arrive then and we can say we say
that we say that we want to preserve
that this structure here has an
encounter order but but we're prepared
we're preferring the word spatial order
hit so a spatial order that is preserved
all the way there and that is different
and that I'm telling you this because
the document the Javadoc for the streams
API I just puts a lot of emphasis on on
the on the idea of encounter order and I
want you to show you that actually it's
really different from another order that
you might choose so if you imagine that
you've got a peak operation on on this
on the stream some peak here is going to
out is going to maybe produce into
system out it's going to print a system
out each element of the stream as it
gets it
right so you so what one order is the as
the output going to appear well of
course it's going to be it's going to
appear in the order in which they arrive
they're not it not the not the spatial
order of them in the in the in the
source but the temporal order in which
they're in which they're processed which
is I've been not not not random but
certainly not necessarily what you want
it may be best it may be what you want
you may be very happy with it because if
you don't care about the order of the
about the order of the elements if
you're supposing you're accumulating
them to a map or to a set it's something
that has no order then actually
relinquishing relinquishing this this
encounter order the spatial order may
actually get may actually get your
efficiency but you need to be aware of
that the that possibility and of the
difference between an ordered an
unordered stream and this is about
maintaining the kind of spatial
relationship of the of the data so I
think I'm pretty much out of time but I
haven't got to the really important
point well I have actually got to the
really important point so that this is
gonna get this is going to go literally
to the hour what does parallel ready
mean well here's some explanations
sequential execution is no longer the
default so we've been thinking in terms
of sequential execution right since
forever because that's been that's
that's the model that we were brought up
on but it's no longer the default peril
execution is now an alternative and it
will become an increasingly important
alternative in fact sequential execution
is as I've said often more efficient
you're probably not going to be using
parallel execution very often but that
will change over time and you need to be
aware of that and here's that is really
the punchline about that parallel ready
coach should be agnostic about how it's
going to be executed that's really the
point now I just couldn't find a word
for that apart from I don't know mo
diagnostic code or something like that
so Brian suggested parallel ready and
the idea is that your code should have
the same effect when it's jen when it's
executed in parallel that's when it's
executed in sequential mode that's
actually quite a big quite a big ask
because it's not something that we
normally
expect operations in the stream API all
have equivalent effect and they've gone
to a lot of trouble to impose to make
sure that's the case and in some cases
they've actually turned down operations
on streams which could have been very
easily executed in it could have been
very easily implemented in sequential
mode because they couldn't be
implemented in in parallel mode and
there's been howls of protest about this
so for example there's no take while
operation there's no you come put a
poison pill into a stream and the reason
you can't do that is because although it
would have been possible to do it in
parallel mode it wasn't a pretty way it
was difficult enough for it not to be
not to get onto the priority list and
they insisted you've got to be able to
do it in parallel mode as if it's going
to be there at all so that was a big
deal operations in the stream API have
equivalent effect sequential apparel and
let me finish this sentence sometimes
you'll find as in the case that I showed
you with the with the peak operation
there sometimes you'll find that are
executed in parallel operations are non
deterministic you don't know what their
result is going to be or you don't know
their for example the order in which in
which values arrive is non-deterministic
in that case you are supposed to assume
that the same is true also of this
corresponding sequential execution that
is a big thing to take in because we
don't think but we don't think about non
determinism in the normal way in in
sequential operations and so there may
be so if they're not if one of them is
non-deterministic they are going to be
equally non-deterministic so what does
parallel already mean and here's a
really is a really important point that
the execution mode is now your choice
between the sequential and parallel
execution mode is going to be depending
on whether you write parallel streams
sort of stream that's it that is very
much not the case with iteration if you
think about it eration that couples
together what you want to do with how
you want to do it is essentially
iterative is essentially sequential
sorry it's essentially sequential and
what we want now our operations which
are not necessarily at which which can
be executed in either mode so parallel
ready is not only about peril x.x
fusion and for now it's not even mainly
about parallel execution it's about is
about your code being agnostic about
about how it's executed so so finally I
get to the question with 58 minutes and
47 seconds according to my clock I get
to the question that the that the talk
was about is Yoko parallel ready and I
think the answer is it probably isn't I
mean I don't know your code so sure so I
maybe I may be wrong about this and that
if so I so I do apologize but the
chances are fairly high that you are
using iteration in your code but it can
be it can be but what you have to do
then is cooperate with the stream API
the stream API provides a framework for
writing parallel ready code you just
need to cooperate with it and it depends
on you behaving in an earth in the same
way so using extreme sorry I don't miss
Ainley I mean safely using streams
safely there are and you get this stuff
from the java.util stream javadoc
stateless behavior means avoiding a
stateless behavior of lambdas typically
means avoid stateful you want to avoid
stateful behavioral parameters lambdas
whose result depends on any state which
might change during the execution of the
stream pipeline I was going to show you
examples of all this stuff but it's now
I've got eight seconds to go maybe not
so basically basically this means don't
don't access things outside of outside
of the stream and don't try and get your
lambdas to talk to one another you know
the ones that are arguments to the map
to the map or filter operations
something like that non-interference
this onesie this one's really easy to
explain don't modify streams data source
during execution and from a stream
you're never allowed to do that from
stream operations other operations may
do it if it's if it's a thread-safe
class like concurrent like a concurrent
map or something of that kind but but
you can't do it from inside of a stream
don't rely on side effects so you like
peak for example don't try and use peak
or indeed don't try and use for each to
accumulate to her to a list that's not
what the stream API is designed for and
as I said at start you really get better
results from an API when you you may be
able to work
cases where you can just get it bend it
in your direction but that's not the
idea you won't get good results for that
so it's really a matter of cooperation
brian is really concerned that people
say are these stupid rules are imposed
on me and I'm just going to break them
but I don't think people will think that
I don't think you're going to think that
you're going to think that the framework
is designed to help you and obviously it
needs your cooperation and it with the
right motivation the cooperation looks I
think pretty sensible okay so conclusion
streams API offers a framework for
programming bulk data operations in
parallel ready style i hope i've got
over some of the idea while that is it
provides easy parallel ism some say too
easy with thread safe access to non
thread safe container so i didn't talk
about this but collectors will collect
to array lists and that kind of thing
using it in current code even though
that even though array lists are not
thread-safe so that's actually a big win
and that's something they say well you
should be able should be prepared to
cooperate in order to get such such a
big win so I say parallel ready code
starts today that's my conclusion</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>