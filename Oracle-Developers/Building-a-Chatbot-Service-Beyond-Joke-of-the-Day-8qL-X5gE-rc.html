<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building a Chatbot Service: Beyond Joke of the Day | Coder Coacher - Coaching Coders</title><meta content="Building a Chatbot Service: Beyond Joke of the Day - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building a Chatbot Service: Beyond Joke of the Day</b></h2><h5 class="post__date">2017-10-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8qL-X5gE-rc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good afternoon my name is Dan Nguyen
I am the Senior Director of Product
Management for artificial intelligence
and intelligent BOTS at Oracle I work
within the platform as a service
organization I'm joined this afternoon
by my esteemed colleague technical
colleague Nick mill hell off and I just
wanted to frame the discussion the guy
in the suit will not spend too many
minutes before I hand it over to the
meat of the discussion which is more
technical nature how many of you have
been in sessions about chat with chat
BOTS okay great so there's a lot of
attention on chat BOTS this year
according to Gartner karma
conversational AI first will supersede
cloud first mobile first as the most
important high-level imperative for the
next 10 years I obviously have a biased
view and agreeing with that but there's
an intuitive sense about that if you
look at the history of human-computer
interaction human technology interaction
the last for 40 or so years you started
out with no ascii-based command lines
and then you thanks to 1984 the
Macintosh you have Goofy's becoming mass
market and then 10 years ago
with the iPhone Touch became mass market
and so user interfaces have become more
usable more natural over the years I
believe there's been an inflection point
in the last five years or so an
inflection point in natural user
interfaces enabled by machine learning
specifically deep learning and so what
we're able to deliver for end-users are
more natural interfaces where the
technology adapts to the user rather
than the user having to adapt to the
frameworks and UI frameworks by the
technology and so obviously there are
examples of gesture recognition even
emotional recognition I spent
the last five years spent the last five
years prior to Oracle at a deep learning
technology company that determines how
you feel by analyzing your face and at
the end of that experience we were
required by Apple and we create a
technology similar to what they
announced about two weeks ago in the
iPhone 10 face ID in emojis so gesture
recognition emotion recognition
conversational recognition so
understanding what we say what we utter
in words as an invoice very naturally
and so that's why we believe that in the
next many years conversational
interfaces will become a key method for
accessing information and the key reason
is that it's just it just removes a lot
of friction you no longer have to
discover apps there are over five
million apps within the iOS and Android
stores combined there are many other
apps deployed by enterprises you just
have to text or speak and let the system
the chatbot system discover what are the
relevant back-end applications and
systems that provide you with either the
functionality or the information that
you're seeking and so it provides a more
direct way for you to access your your
desired information and functionality I
like to frame this discussion a bit so
this the topic of this discussion is
about how do you build BOTS just beyond
the joke of the day and what we've
discovered in building enterprise class
solution is that building a chatbot
service that it delivers real value
beyond a lookup table of jokes of the
day is non-trivial because of these
three areas of challenges one is
diversity of channels right if the
promise is to remove friction then your
end users should be able to access
information and functionality
independent of the screen or the medium
that they're using so across the
different devices and screens and
applications
so that's the challenge for chat pot
services to enable the livery of this
value through those multiple channels
second if you're too if you're to
deliver a real value for your end-users
you need to integrate deeply with
back-end systems that provide
information and functionality that is
specific to your domain and specific to
your firm and so backend integration and
making that very seamless with all the
scaling and availability and security
necessary to deliver an enterprise-class
service that has the trust of your
end-users is complex and then third
which is non-trivial is getting the
artificial intelligence right and so we
have spent a lot of effort in designing
our artificial intelligence and natural
language processing pipeline to make
that all happen seamlessly for our
enterprise customers so if they don't
have to be machine learning experts
natural language understanding and
processing experts to have an
out-of-the-box way to deploy chatbots
very quickly for them and so as a result
we're providing I think what is uniquely
a complete solution for our enterprise
customers one that allows them to
quickly deliver chat pod services across
multiple multiple interfaces voice text
web applications across platforms and
then also very importantly enterprise
ratings that means providing
out-of-the-box capabilities to quickly
and easily connect to their back-end
systems to deliver information that is
unique to their firm and industry as
well as the transactional capabilities
to do real things rather than just a
simple joke or fact of the day type chat
bot and then also very importantly we
vine embedded AI out of the box so you
don't have to know machine learning or -
floating or processing to make it all
happen for you and so it's I think it's
the industry's unique and the end
solution to quickly get up and running
chat bots deliver real value so with
that as the context I'll turn it over to
Ludmila to show you the innards of how
this happens
so so is all this lights about how we
create boats and very cool stuff so my
idea was actually for this presentation
and I hope that I will have enough time
to show this like try kind of cut the
slides because there is a lot
information I could show is how to
create a real boat what do I need this
is based on a solution we provide today
we have a very very aggressive schedule
so a lot of new feature is going to be
included in the next two to three months
I didn't include slide about that but I
can mention a few words and this is
basically in a real use case but I'm not
going to mention customer right now here
so the idea is to build a chat bot which
I we call held chat bot which actually
can deliver information based on support
wearable devices there are actually
amazing high numbers of wearable devices
sending information and you can imagine
you can get stuff like the steps
kilometres hair hard frequencies and a
lot of information inside so imagine
that you have that information every day
from your customers in a big data or
whatever system you use and you what we
would like to provide a chatbot
interface so that the customer can ask
for ask questions so what do you need to
do this is kind of a high-level gender
so these are actually the step by steps
you need to follow to be able to create
a plot so the first thing is you have to
recognize what the intent is when the
user is typing message typing questions
so you want to know what the user
actually really try to say or ask the
next one is entities this is really kind
of a very hard to do sometimes
probabilistic parsing is just to
understand different type of addresses
dates durations and so on and so on then
of course you need some type of dialog
to create for the customer so how you
want to response if actually is only one
response or there is a conversation flow
you want to have events and back
bakken's integration also very important
information all these data you're
storing somewhere you want to get that
information and be able to show to the
customer and of course channels which
channels would like to support facebook
Messenger slack or whatever client you
you look for so we start with the intent
resolution so remember the use case at
the beginning so the intent resolution
is basically the ability to understand
intent from human ambiguous language
whatever the user is asking to
understand wanted tennis is it asking
about how much calories I wanna burn or
whatsoever so you have to be aware of
kind of a different type of intense
you're going to have you have to
classify your questions what the
customer could potentially ask and I
actually especially choose the use case
because he is very kind of a unique to
show you the capabilities of the system
we have wine right now the user can ask
a lot of different types of questions so
the same question could be asked in a
different different ways like how I did
how I did today or just how I did or how
I was doing last week or how many
calories did I burn how many cars did in
porn yesterday or in a specific time
different goals but you can actually go
and make this even more advanced and you
can start asking question about when did
I burn most calories in a few months or
when was the you know where had a
highest step count depending on the data
you have and the services you creating a
back-end
you can actually also allow capabilities
to ask about projecting about based on a
data you were having in the last few
weeks how much calories I'm going to
burn tomorrow for example or stuff like
that so knowing all those intents what
you have to do right now is to get them
and to feed them into the system so this
is a screenshot from our system I want
you to show this for life but the
problem is so as with the network and
availabilities right now during the open
world everyone is trying to you know
play with with it so the user interface
well this is really extremely simple so
you define a
let's say for example walk and for that
in 10 you can specify your own
Terrance's the interesting here is one
mistake I've done is as you can see I
actually put three sentences there but
you don't have to specify all type of
sentences here inside if you actually
have only how far did I walk or how did
I walk Oh whatsoever it's just enough to
specify reduce a few of the sentences
and then for the machine learning will
be enough to understand the rest of the
questions so you don't have to specify
all type of questions by how far did I
walk two weeks ago ten you know last
month or something like that actually
you don't have to do that now one thing
you have to be aware here is that if you
have intents which are having too much
like how far or what or you know these
do words questions you have to make sure
that actually they're a little bit more
semantically rich to be able to identify
different type of intense so the next
one is the entity recognition the entity
recognition rule actually also called
North is the ability to automatically
recognize entity meaning from ambiguous
language that's something very hard and
most of the people actually
misunderstanding this with a search
search is a very different because in
the search you have a text where you can
build index and basically you search on
words which are providing in a search
field here is actually a completely
different way of approaching it is to
proactively without knowing the context
recognize if the user is talking about
specific entity or if it's he's
mentioning specific entity and one very
common example is like Wall Street or
Wall Street Journal right so for machine
learning to understand the difference
between two you know that one is a
newspaper and another one nah it's not
that easy and most of the solutions
actually provided based on algorithms
which kind of a try to detect position
of the words or specific sentence which
should look very smart at the beginning
but when you start playing more
difficult
you realize it's not working that good
so of course we provide here sorry I
Cecilia with you club we provide here
different different types of
capabilities which I'll show you one of
the next slides but first we need to
recognize first we need to understand of
course what type of entities are really
need and so this is actually the easiest
way to understand this or to look at
this is just to know about what your
back-end services are required because
whatever the user was asked if I ask how
much calories did they burn last week so
first you have to intend I'm asking
about the calories which are born and
then the next thing is as the entities
last week last week is going to be
entity so you need to know when was this
last week and if you see about which
parameters were back-end services is
requiring
to query this information so he requires
metrics start and end date so start and
end date could be only started because
if I ask today is going to be only today
we have different aggregation types I
couldn't ask what was the day I born
most calories last week for example and
of course user ID to be able to know for
which user you want to create that
information so if you look about their
entities you will recognize that metric
is going to be the intent so what i'm
what i was asking start and end date is
entity aggregation is entity so and you
wouldn't realize that i had this big
amount of different type of questions
but if you going to look about what
information i need to be able to execute
service request to return me any
information required by that question
it's actually it's always the same even
though I have so much different types of
questions so based on all on this three
to five entities actually I can solve
all of the questions to user was asking
so we have out of the book entries this
this on the right side is what we have
available right now so the date the
duration different between data duration
is that you can actually specify date
for example how much courage to die born
on 20
February or something but you can
specify also what we call duration which
is last week last month two days ago
whatsoever we have the capabilities also
to specify custom entities which is
sometimes extremely useful for example
in that case I want to make the body
actually capable to recognize different
types of aggregations so if I want to
ask for example what was the my total
calorie how much calories did I born
totally in the last two weeks for
example and I know that this is specific
aggregation so basically I can provide
additional synonyms to teach the bots
about that and you can provide this on
different languages also if you wish so
the next thing which we need to solve
that problem is of course probabilistic
entity parser the probabilistic parsing
is using the naming problem in the
programming languages to recognize stuff
like to be the first Tuesday of October
for example so now that's a Texas ok but
for me to be able to execute the
services I really need to know about you
know that date but if you ask the last
week or two weeks or whatsoever specify
all of this type of question this is
what it's called probabilistic entity
parser this could be used also for
addresses names numbers stuff like yes
or no because yes or no could be answer
it in a different ways right we can say
ok or I go for it or sure whatsoever
right is not just yes or no so different
that we support all this so what is
interesting so then in an existing
system right now the date and duration
actually support probabilistic parsing
already so it means that what you see on
the right side is a screenshot from the
testing interface when I specify my
entities and I show them also which
sorry intents and when I shows which
entities I'm interested on from the
questions the customer is asking then
here actually I can start playing I can
start and see I can put different type
of questions which actually are not in
the system
and I can see if the machine learn
is capable to recognize the intent and
is capable to recognize the entities for
example here I just asked how much
courage did urban las last friday and
the system recognized for me
automatically when was this last Friday
so I'm going to get that parameter and
be able to execute the query
next thing is here again example with a
different type of questions where you
can see that if you see the first one
was resolved by date but the next one is
by duration because I said last week for
example and so on and so on
however the mother is always the same
and what is interesting what is also
nice is that you have the start and end
date and you have actually what was the
actual test text the user was asking for
in our case this last week this is very
useful when you want to construct
dialogues later because when you answer
the user maybe you want to make it a
little bit more human-like so you don't
want to say you born son so carries from
September 23rd to September 30 but you
want to say you burned so and so
careless last week right so it's a
little bit more human-like
so dialogue I came over something which
you realized we doing when we create
dialogues it has to be friendly short to
the point and of course sometimes with a
job you can do really big answers here I
mean you have this small display it's
not really made to start having big big
discussions one issue we have over F IQs
for example where we have to do FAQ in
our bodies the FAQ usually have a very
long text you can just show that no text
there in in a message client right so
you have to figure out a smart way to do
that so you have to try to make it short
and maybe if there is more information
which the user has to read that have a
links or something something else here
is some example of dialogues which you
can make it a little bit more user
friendly so depending on for example how
much he walk you can actually make a
joke right
additionally what we actually did is
also to kind of an encouraging person
for example well you did great you burn
Sonne so careless which is I don't know
400 more than your goal or something
like that and we work actually Hughson
early on small talk-- ape abilities
which is not released but will basically
give you the capability to design even
higher dialogue trees
way bigger and based on a dialogue tree
you can decide depending on what is
happening what type of dialogues you
want to send to the user so it can make
it even more dynamic and looks more
human-like this is a one way to do the
dialogues this is we have a llamo
dialogue flow where you can specify the
dialogue the interesting part is to see
the components where currently you see
on the system components but you can
develop also your own component that's
very interesting we'll talk about that
in one of the next slides now this one
here of course is a one way to do it but
if you start doing it like this it's
going to take the list is gonna be very
long you can actually also have a
switches go here and there and so on so
one way to do this is also through a
custom component and later when we have
this motor capabilities you don't really
have to provide all this information
here inside another thing is that all
those dialogues they you can actually
load one another from a main di lock you
can load another dialog which allows you
kind of to fragment it fragmented so you
don't have to put everything in one file
back in integration that's probably one
of the most important points so of
course the very first thing is you know
you need to access the information
somehow so the boat and the capabilities
is everything it's fine but the boat has
to know where to query information and
show to the user in our case is just
getting information but of course
depending on your use case you probably
would like to put ticket or fine user
somewhere to search or whatsoever any
type of backends can be integrated
actually there is no limitation as long
as I have access to there we prefer rest
services because it's way easier to work
with and specifically if you have also
MCS environment
the integration is really very seamless
but the custom components are give you
the flexibility to develop whatever code
you want inside you will see in one of
the next slides how the custom
components are running on OGS container
so basically develop Java JavaScript to
do that but the backend can be any
technology so in our case was a Java and
we had a restful services implemented
getting information so back-end service
design so one service for all in our
case you if you remember all those
different types of questions that were
saving actually on the end I can resolve
and get the information only from one
service so even though I can have so
different types of questions this
service with those per parameters could
give me answer for everything why
because the metric could specify what I
was asking for if it's Carey's will step
down water intake or whatsoever start
and then it give me the the period I'm
interested on or you can actually use on
the start date if you wish and the
aggregation could give me different
types of if it's a minimum maximum
depending on what I was asking if I
asked for example what would be my what
was my maximum day with most calories
last week this is going to be calories
then start and end date for last week
aggregation gonna be max and then user
ID and I'm going to get that information
back in service response again you get
only what you need also very important
so from you have to specify off of
course what information you want to
response from the back end and using
your pot this is the JSON response from
the system so we have the name we have
the amount metrics again the start and
end date we have also a additional
property for if this calories or you
wanna call them something different
because there are different metrics
depending if you in Europe on us and
whatsoever and you can use that
information to generate dialogue it and
generate response to occurs to to your
customer our custom components
when when to use custom components
because sometimes you don't necessarily
have to we have also built in custom
components where you can pour any
information one of the things is of
course when you have a back-end system
we cannot just easily integrate but you
may be also what would like to aggregate
information or business logic in a
different way which we cannot provide
out of the boss out after the box of
course create a different client
specific parameters but of course also
different dialogues this is also very
interesting and another thing is of
course different channels require
different outputs
if you want to support Facebook message
of whatever output you generate there
this output it's not the same like for
example in slack this is a very big
problem and we're going to provide
solution very soon there as well and of
course the custom components can run on
a CCS MCS or any node GS basis
containers or there is no limitation
there bracket integration with custom
code how actually is look look like to
create a system such a custom component
so this is a very minimal example which
I want you to give you so you can
specify metadata if you remember so this
is the the very forces the name if we
remember the slide with the dialogue
flow where you were having component
this is the name you can specify for
that component the properties are
actually variables which you can give to
that component depending on what you
need you don't necessarily have to do it
because you can have also there is a
additional property which delivers you
actually all intents and entry to enter
this addition additionally in a custom
component as you can see in the
involvement inside this is your base
metal work which will be executed when
the dialogue flow goes to that level
where your component has to be executed
then your the the bot system will go
directly to that part here and here you
can get the channel types you can get
all those variables and what is it
inside and
but this is one of the slides where
actually can make five of this but I
want you to make it short to only one
slide save me some time basically shows
you a very simple way how how I can get
the information so all those entities
which actually was asking so for example
how much Carol is did I born last week
so I can get I can send the entry T's
which is aggregate aggregation date and
duration type to that custom component
then here I can see if this is the only
date or if it's duration there won't be
the same but there won't be available
the same of the above at the same time
so depending on if I was asking last
week then you'll have one iteration if I
was asking for specific date you will
have only the date so you can get that
period you can specify this in in
options and then you can execute this
restful service in behind and when you
execute the rest of for service you get
some specific information and just to
show though in a real system it's a way
more complicated because I want you to
generate different type of dialogues but
this is just to get the feeling how is
it how how is it working
so basically when I was a kid there
services and I get that information as
you remember in a payload I was saving a
mount and specific the texts and
specific mark if this is a calorie so
what so ever want to call them and last
week is actually from the entity itself
as I was asking the last week my entity
was saving that text so it allows me to
construct sentence with the last text
inside to make it a little bit more user
friendly and then you can think of about
taking this example of you can go very
very far encrypt way more complicated
stuff for example here we are having
logic for checking the calories with
this message example the colors which
the person born with his goals and see
if he actually is meeting the goals or
not and if you want
generate different type sentences if
this is going to be natural positive or
negative sentence and so on and so on so
you can create logic which can do this
here to register custom component it's
also very easy so as I mentioned this is
running on some no GS system somewhere
and is having some main file which you
securities having well so you just have
to specify this word or in our bot
environment and then you get access to
this custom component and you can use
this custom component in a system
already so very easy to do and the last
slide is a channels so as I mentioned
this is a very big problem because every
channel is having different type of
payloads I personally like the way how
Facebook Messenger is doing because it's
very very dynamic so you can support a
no easy way of different type of
responses and I don't know how much how
many of you are familiar with this but
in a facebook messaging we can have not
only text response but also different
type of horizontal vertical cars buttons
and so on and so on so basically if you
want to be able to support all those
capabilities you have to provide this in
your response and if you remember in a
previous way its light where it was
having just a tech response there you
can actually also have a response which
is a JSON response and depending on a
channel you can check the channel and do
that type of payload additionally here
we're in the next version and on one one
which is going to be available in
December we're going to provide you
actually a general way to support those
different type of channels which means
that you can generate output for all
support for different channels but it's
gonna be only one way to generate that
response you don't have to think about
okay how my JSON payload should look
like to be able to show that message in
a way I want you in a facebook messenger
channel and of course we have guidelines
capabilities which we've done already to
integrate to Alexa Siri and all other
channels which is actually way easy then
and probably works
of course also the capabilities to use
WebSockets this is in an enterprise as a
lot of customers using Cordova for
implementing in mobile applications and
often they would like to have the chat
pod capabilities in application itself
inside so WebSockets is a very good and
easy channel to do this integration all
right I was very quick you have any
questions yes
not right now it's only not GS based so
no Java but of course you can write most
of the logic actually in Java and
request that logic from the non GS
component yes yeah that's one won't be a
problem
all right yes
yeah yeah
I know what you mean yes yeah not right
now there is work around for that you
can do it because you can actually send
direct response using the Facebook tags
directly to the Facebook Messenger for
example and in the next version one one
we are heading to support this out of
the box sorry
Oracle Claudia is sorry I'm not sure if
you have a trial instance already isn't
it done there will be a trial which we
can explain yeah yeah or free credit
right well versus the easiness of use if
you try I work over I as well the entity
resolution is a little bit more powerful
and another thing is the integration
with a system so that's actually very
important because most of the customers
we have were Oracle customers having or
coexisting systems so to be able to
integrate them was way way easier than
having system someone outside
another thing is security capabilities
not allowing to go to somewhere in
Google or Facebook whatsoever but keep
the information in
yes yeah you can do this
yes yeah you're welcome all right very
good thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>