<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Developing Rich Interfaces in JavaFX for Ultrabooks | Coder Coacher - Coaching Coders</title><meta content="Developing Rich Interfaces in JavaFX for Ultrabooks - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Developing Rich Interfaces in JavaFX for Ultrabooks</b></h2><h5 class="post__date">2015-06-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/dm_0JF1bEhc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Bruno Borges I'm from Oracle
Latin America I'm product manager for
Java Midler but I'm also a job
evangelist or Java advocate as you
prefer philippi I am Felipe Pedroso I
work as a community manager at Intel
Brazil basically with what we do is to
promote the engagement of developers to
produce better software to have with
good experiences to their users ok so uh
thanks for having us and we'll
appreciate that so this section here is
about developing reach interfaces for
with javafx for ultrabooks this is just
something that Phillip and I have been
working for the last three months I
believe yeah and it's nothing official
between work and Intel we'll just
developers having fun with what he does
and what I do so this session I'm we're
going to cover the future of pcs it's
small talk about what we think that the
interest is going to and then how to
enable gel effects touch support and
play with sensors as well on ultrabooks
of Intel and how to use J&amp;amp;I the native
interface of Java to plug with the
sensors so basically we believe that the
laptops are becoming like smart tops we
see that smart phones have become a lot
of a lot smarter than ever and but
laptops they started to get sensors as
well and maybe this is an industry
opportunity to everyone not just more
forms we should work with laptops as
well I've got a few articles online so
the first gps-enabled laptop was into
drew introduced by hazards on 2007 so
while we've been having gps-enabled
laptops for quite a while actually
laptops are
as earthquake sensors in California
there's a group of students in MIT I
believe and this article talks about
using the laptops that are standing
still on desks but using the sensors
over there to actually identify in a
distributed Network if there is a
earthquake coming up so you don't
actually need to install the sensors you
just use the disputed network of laptops
connected to the Internet and they
already have the sensors right those
sensors that detect if a laptop is going
down so they can turn off the hard drive
you can use that to the fact an
earthquake so that's a pretty cool idea
these are very recent article the frost
&amp;amp; sullivan analyses company they sell
their sensors is going to be going to be
everywhere not just Mart phones laptops
computers planes whatever you work
wherever whatever you have hardware
device probably connected to the
Internet they're going to have sensors
somehow some kind of but they will have
sensors and yep Microsoft was right
touchscreen laptops they are true they
are right they are the future probably
the present already so if you look at
intel market they have a bunch of models
well see intel based models from dell
from asses from FG several laptop
vendors that use intel processors but
they booing is clearly a lot of them are
coming with touch screen cell screens
some of them are hybrids they become a
tablet as well so this is actually the
future and actually the present already
so flippy can you talk about more what
we are working on yeah as you can see
here we use it to have two types of
devices we had the types that you
consume content though you watch a movie
you read a book or you
actually have some fun in using that and
there are the creation and productivity
devices they are blurring themselves so
you are if you go right now into the
stores you will find a new form factors
that allows you to work in both forms so
when you need a tablet to have
entertainment you can use is that as a
tablet or you can produce your code read
your e-mails create documents and stuff
like that thank you well but how to
provide to your user this kind of how to
adapt to your app to have a good
experience to your user well users want
to want that your app have a kind of
context awareness so that the device can
understand where he is in what he's
doing so we imagine you we have a lot of
solutions like that that can that can
detect swear the user is and suggest
some restaurants even detecting if the
light on the ambient that he is inserted
is too strong is too too low and
adjusting the crunk the brightness of
the screen so the main idea is you sense
the environment that the user is
inserted and provides a context to him
according here according his environment
this make makes your user more happy
even he felt more confident to use their
apps and stuff like that so we have this
this is the idea of the platform that
ultrabook has we have much touch we have
a lot of sensors as you can see we have
a salido meter and the ambient light
sensor gyroscopes even some device that
helps the user to be connected
are easily well okay well how can I use
that on Java I know that if we pick the
Microsoft API you can use all those
features as in a weezy way because they
are promoting it they have a very clear
API and well at least for touch they
basically the same with rubber but for
sensors know well if I want you to
provide this kind of support touch
support what I need to use well actually
you can use a WT swing SWT but they are
they are and made for much touch usually
you can have touch enable apps using
this this api's that is the set of
graphical user interface but they they
aren't made for that they don't do not
support you can extend then use swing
acts or implement by yourself
implementing by yourself the mooch touch
support but is not easy you need to
adapt the size of the components you
need to create some more something more
attractive you need to create a way to
do these interfaces more touch friendly
that they aren't they are kind of all
they are kind of they are not so
beautiful to to show to the users oh but
how can we do it when i try started to
implement this i started to work with
ultrabooks i was trying to find a way to
implement touch and sensors in every
language that exists so the best
solution that I found in java was java
facts javafx has a lotta has a set of AP
is to provide this touch support and
also helps you to create reach
interfaces it already has much touch
support you can use how many fingers
as your hardware support so you do not
need to implement anything to have this
working so you just use the callbacks
and well it's working we have some
actions that are supported we have this
touch events that is the Simple Touch
that you just touch down or move and
touch up that you can create drag and
drop holding still and even at tap the
Bota app and we also have support to
some gestures that already have
recognized by Jove effects you can do
the swipe that is the short movement
that you do with your finger like a
flick for all the directions you have
zoom when you that that you can do with
spreading as a thing or pinching you can
rotate it can detect which is the angle
that you are doing with your to your
both fingers and also we have the distro
this crow is very common with the mouse
mouse but it's it also supports the
scroll that is by basically a longer
swipe so when you do a longer swipe you
have a scroll what I need to do to the
to manipulate my components first of all
you need to extend the node class or any
of any of its subclasses well it's not
possible all the components extends the
node class on javafx that our Eddie has
the support of the the callbacks to to
have the touch event but you can create
create one by yourself by extending one
of these components or you can apply
this event handlers in those one that
already exists so basically you need to
call a method that corresponds to the
the action that you want you to have a
call back
and then handle the event whatever you
want so in this case I'm showing the
disease has a yeah in this case I'm
showing how to implement the rotation
event so I add this event handler here
that has a generic type here that
receives the rotate event as a type of
even to handle and then I redirect the
information of the rotation event to
this method that I created and then I
consume to avoid getting the calls going
down to the components that are parents
from this component so basically one
component receives the touch then if you
do not handle it here it will redirect
to the next one that he is its parent so
after that when you handle you can use
some javafx magic to apply the changes
that you want in your company so here I
am applying the rotation that I got from
the rotation event in my app so I some
the current rotation with the event
rotation and the company's rotates in
the spring well let's talk a little bit
less and show some code I hope everyone
here likes to code like me here we have
the main component from my app from my
app I call it image image element and
here I handle almost every I think I
handle all the the touch touch even
supported by my component as i said the
component must you extends some class
subclass of nodal denote by itself
and if you want to put stuff inside it
if you want to have more nodes inside
your node you can do like I did here I
create an image evo and put inside this
tag pain and then when you want to
handle an event as you can see here wait
a minute just to close the console chew
when you want to do something like this
like zoom you just need to set the event
handler that will be responsible to
handle to handle your event so in this
case when I go to hand-roll zone how we
apply to the to Mike component to my
node and you scale so i get the
information of my event here we have the
zoom factor that is applied to the
object that I'm executing the action and
then I limited the the new scale to
avoid any problems of oversizing or the
component became invisible to the user
so all the events are easy like this is
not so difficult to add this this kind
of support on your app are we around and
now will show to you that with simple
code you can do something really cool
like this this photo gallery that I
created now it was open it tells nick
part of this is that you actually didn't
have to code any kind of integration
between that in the API or a book or
your laptop this is already included in
java SE runtime it comes bottle the
support for multi-touch so you don't
actually need to code anything on C++ or
windows whatever you need it's just
already supported so this is here so
Philippe's playing with only screen of
the left
up so it's also can play yeah I can also
play so one of the cool things is that
not just javafx but the screen also
supports really multi-touch I had three
fingers here's here and we actually have
more like four to five probably six yeah
and that's already that's ready to be
used from java c7 i believe right yeah
actually this hardware support stem
mucha touch points and you will see that
if we put 10 fingers there you will have
the 10 fingers detected by Jove effects
it's not something that you need to
spend a lot of time programming or
creating something new yeah it is ready
it's easy to use and the well it came
back so let me close this the problem
there are problems we again monitor
releases this is really a cool thing and
actually it is supported on mac OS as
well and also on linux the much
attention that's not difficult to use if
you want what else i think that's it but
it's easy but what about the sensors the
main problem using in sensors that is
that you need to access hardware and
java still don't have we we know that
there is a GLS are talking about sensors
in july me we don't know if it will be
included on Java Sea but it's possible
if you create a Java native interface I
skipped some slides but the idea is
simple you just create your jni layer
and then you use the sensors on Java
well what are the available sensors in
the Ultrabook platform as I say to you
we have this six months acelera meter
0-0 meet gyro meter magnet the magnet
this is
over as the sensor that measures the
magnetic field you can sense the ambient
the level of the ambient light you also
have GPS NFC that is something very
common in the modern smartphones to
establish communication and stuff like
that and Microsoft has provided a
software layer named sensor fusion the
idea of the sensor fusion is to create a
way to allow us developers to read the
sensor in the high-level way so we can
we do not need to worry about getting
the information from a salido meter from
gyro meter and creating the compass or
the device orientation sensor and the
day ID is basically you pass the
information that comes from these
sensors and create a class that
represents a high level sensor that give
you more sophisticated or more
high-level information as this device
orientation says that if your device is
in the landscape mode is in the portrait
mode is it with the screen attorney to
to to turn it down well so the idea is
basically passing the the information
from the sensors in the filters and
creating every time I try to follow this
these errands I get lost but you as you
can see here the accelerometer plus the
gyro meter create inside the orientation
filter and passing through the rotation
transform gives me information of the
device orientation so to avoid those
things that you need to create your own
algorithm to to process this information
then get this high-level information
they created the sensor fusion basically
in windows in the windows api
you have some packages namespaces are
the equivalent of packages in Java that
takes care of that has classes to handle
the sensors and the create this and
create this interface with the hardware
so we have basically treat main packages
that is windows that sensors windows
device geolocation windows network
proximity and here today I will show to
you guys how to access the sensors from
this package that well I don't know why
but they created these classes they have
the same methods they have the same
structure birth but there is no objected
oriented programming here they created
this stuff without having a base class
or something like that but they have the
same methods they have the same way to
operate and use the API I don't know I
really don't know why please
yeah the classes the day API is for
Windows but you can use I will explain
to you after how to detect if the the
computer or the PC or the laptop or
ultrabook has those sensors so you will
axis then check if the they are
available and then uses whatever you
want so it's it's microsoft public api
from sensors on windows so if a laptop
has the sensor installed the hardware
sensor this the vendor of that laptop
hardware they should implement the
connectivity between the the sensor in
the API on windows so it's a basically
OEM issue between the vendre in
microsoft
it can be it can be for example tablet
that comes with windows 8 installed and
if that has the implementation and used
the API then you get the data through
these api well well the idea is I was
trying to just have a proof-of-concept
you can implement it on Linux you can
implement it in other platforms but as
Java do not runs in Android not java SE
right and the this is possible to doing
whatever you want but you need to create
the oldest stack that you need to access
the sensors if you want to do it in
Linux how we'll talk about it later
linux don't have the clear support to it
to this kind of api you will need to
implement it by yourself if also Mac so
if the device has support of touch
javafx can handle it very well but with
the sensors I will talk about later we
don't have a clear support from other
operational systems and stuff like that
so what are you going to do here is
explain how to plug whatever data you
have through sensors using whatever
language you have through the Java
native interface to get that data into
your java application so we're going to
use the windows api example but you
could be using c language c c language
for linux to get the data using a linux
driver and connect that to the java
native interface so we're going to use
these exact as an example so basically
what we want to show you is how to
connect the hardware specific sensors
data through the specific operational
system API and provide that data through
J&amp;amp;I to your java application doesn't
matter which platform but if you know
how to create the jni to access these
sensors you can plug to java exactly
okay that so that is the idea but but
usually most of the ultrabooks being so
they are they are coming out with
windows and most of
in comes with sensors so that's why it's
easier today to develop some kind of
example using the windows API but you
can play with linux if you want yep yeah
they that they already have the direct
current api's to read sensors right they
don't but that comes the question if i
can run java applications on those
systems yeah which is another issue okay
so that's something we can we are not
covering as java from the android is
different for in java SE and yeah
something you should not be talked about
but that's one well but how to use this
API how microsoft created this api to
access the sensors well first you need
to get the full object from the sensor
all those sensors have the dis method it
it works like something like singleton
where you get the instance of the sensor
using the gap default if this method
returns no you know that this computer
or this device do not have the do not
have the sensor available so you can
know by that if you can provide some a
cellular material stuff to your user or
not then to read the value that the
value of the sensors you can you have
two ways the first one is to call the
method get get current reading to get
the net the name it says by itself that
reads what is the current reading of the
sensor or working with events to work
with event you need just to set the
timing that you want to read the sensor
you need to have a report interval you
need to respect the minimum time to do
that because you can have actually some
problems to read if you try to set
something lower than this value
and then you delegate a method to handle
this event it's something like listeners
that we are used in swinging it even in
Java facts so you need to say this
method we received the event and then
you handle they eat it even inside this
method something like pointers to
functions that we had on C++ okay as I
said this procedure is valid through to
the sensors on this package on this
namespace those other the others from
the other packages they are very simple
but they give a little bit more of work
it wouldn't be possible to present here
in just one session we need more than
one day too yep to show everything so
how can i access that so the basic idea
is to create my code in the c++ windows
api create a software layer using jni
it's broadly know that this is java
native interface it you use that to you
access some stuff that java cannot do as
is a brutal machine you must you take
care when you use it because it attaches
you to the the system that you created
this library so if you want to cover all
the platforms you need to create one
Jenny I layer for each for each see
saying that you want support in the case
of Linux that he asking me you need to
create the J'naii you can now you can
use the same interface the same methods
names and stuff like that to avoid this
problem but you will need to create one
to each platform and then I plug
everything in my java code so i have an
interface direct interface to my java
code to my c++ code
well how to and how I can create this
this layer and access the sensors
actually I have the full procedure here
but I prefer to show you the cold it's
easier it's more interesting but
basically the idea is to get the object
in Java keep a Heffernan's reference to
it in the c++ code and then what I
whenever the event with the sensor
occurs as I described it in the how to
use the sensor the region change it
event it redirects the event to the Java
object a method a method inside the Java
object so it must go ok ok so one of the
cool things about jni in this case this
example is that what we have two methods
actually one is the callback register so
we have a native method that will call
the library the C library giving a Java
object which we is the callback handler
so then we're going to keep a reference
to get java object inside the c library
runtime and then whatever data we get
from the sensor we call a method of that
java object from the sea layer so it's
basically we just actually use the jni
interface to provide a java object to
the c library and then the c library can
talk to the java application their way
so it's not it's not having a thread on
Java calling a native in method to read
the data we are actually doing the
opposite we provide a Java object to the
sea layer and then the sea application
is e layer provides data through this
Java object to the java application this
way we don't keep wishing the sensor
every time we just read data
automatically when the sensor has new
data to provide so which is a pretty
cool thing
to do and it's a it's a little bit kind
of dancing thing but you can find a lot
of articles we found these these we
actually found this explanation and how
to do this on IBM articles so if you
google for IBM GE and I call back see
you object you're going to find this
article pretty on you will find two in
at the interweb site in detail do not
forget that yeah yeah and here we have
the the first part of the code is how to
register the the Java object into the
C++ code so i get the i created this
method call it register object is very
difficult to not handle the cold having
tools to handle the cold from there so
here i registered this this acela
Demeter object that we have here we have
the class here that has all those native
methods so first of all I need to
register this object to keep a reference
choose to redirect the event after it
happened happening so here we get the
object class that call the debt register
method and then we start this restored
this this object this object Oh in the
in this in this attribute that we have
here it's a global attribute I'm not
proud in using that because it's not
recommended that you do stuff like this
and see but that's it was a hobby proof
of cool concept and then after I
registered this I in each a lie i
initialize the accelerometer as I
described it so I call the method get
the phone here and then when they called
the register reading change it and also
the the shaken method there is an API
to detect if you shake your device I
call this method and register the event
to whatever the user shakes it will fire
an event here we have the method to
register the shaken and when I call when
I add I tried to create something like
listeners that we have in swing because
i was at swing developer i created this
listener so when i add this listener i
will register the shaken method it will
comes here and then whatever the the
shaking even happens it will redirect to
java through this method to invoke shake
on java that as you can see here this is
a lot of complicated stuff but the idea
is just to get the environment of our
our java machine our JVM check if there
is some problem is attach it to my JVM
and stuff like that and then I called
the method on Java where it is it here
so I call the method on Java that is
shaking here I passed the reference to
my object here here i passed the ID of
my method and here the time stamp that
they even happen it so when I come to
Java you will see here that I have the
shaking method he's saying here the
NetBeans is saying that i'm not using
this method but as is a native call it
can detect it and if the shade it caused
the method he will head erect to my
listener so every time the user do a
shake here I will show who implemented
this interface
here is the the class that I implemented
this interface and then after I added
this shaking listener whatever the
device shakes I strongly recommend you
to do it on water books as they have
SSDs if you remember the classic hard
drives could damage if you shake them so
do not do it if you don't have an d
so also checks if the Ultrabook health
and a SSD and a classic hard drive
because there are this kind of mix it
mode so don't do that if you don't have
justin a SSD inside ok so whatever the
user shake the shake the check the
Ultrabook or tablet the disciplines to
also to our new platform that we
launched it that intel developer forum
last week you can call i will call the
get children to remove all the photos
that i added to to my photo gallery so
let me run to show you well Bruno will
be my tester you need to keep because
they need to see you break a posse ok no
no problems is quite you're a good cop
ok so i can add the photos using mytouch
well i don't know which what is this
picture doing here but here are some
photos from my facebook so i came on a
plate and when I do not want it anymore
I shake my device and it disappears so
it's not so complicated is kind of
tricky the way that you need to keep our
reference to your java object but in
fact is is simple you if you'd have the
reside you can create in whatever
language in whatever system that you
want so you shake the device and it is
appeared
so let me return to presentation you
asking me what about linux oh well as i
said touch will work fine we already
tested it ubuntu already has this kind
of touch support in the javafx works
actually very well with linux and mooch
touch but there aren't clear api's to
read the sensors maybe we can try
something really reading from the / dev
or creating some stuff that can read you
can read directly from the driver as
bruno suggests but if you know how to do
it please let work together because i
don't have a lot of time to develop this
as a broom said it was something that I
created in my free time and I would like
to i would i would love to have this
working on linux because i'm a kind of
linux fan too but i couldn't do it sorry
so that's it if you want to know more
about what Intel is doing own software
we call this this idea of Intel doing
software the most the top secret that
intel has i hope everyone here is
everyone hears everything about hardware
but nobody listing about intel doing
software i believe that we are the third
company in software in the world or
something like this i know i don't
remember the statistics but we have a
very nice website that we have a lot of
communities we have an html5 community
and android ultrabooks that's the
community that I am manager we also have
something for servers hpc high
performance computing and as I said to
you this is the best one they
are in Portuguese because i usually do
not promote Intel from the United States
because my speeches are in Brazil this
is my first one outside the the Brazil
but there is here is the community that
you can find more information how to
access sensors how to implement such we
will we will be releasing an article
about this this not the same stuff that
I made the photo gallery but I I saw an
article that a girl from the Intel here
United States created to describe how to
implement touch in Java you can find it
there Bruno have suggested the the
JavaFX community if you want to know
more about how to implement those things
in javafx you can grow there and the
take a lot of so I'm planning to write
something about that in stealing his
code is on his permission and published
on javafx community com not nothing
official yet but yeah maybe someday dick
the code to to to have the code as open
source I need to follow some guidelines
for detail and I'm still working on this
process to avoid any problems with
licensing and stuff like that but as
soon as i got this approval i will
publish the article window will have
this code at javafx community Bruno is
always asking me to do that but as he
says I are not brave enough to do that
without permissions oh yeah because you
don't know yet there's a website called
jf x jf extras actually which is a
project that provides you this
application here called ensamble and it
provides you a lot of gadgets widgets
what have you called tip use on your
java fedex applications there are out
there they are all free you can just
download and use them in your project
and some of them you can play with touch
so it's pretty cool you
can use some of those gadgets to provide
sensors data which is pretty cool as
well so it's pretty much about
developing the jni part of the code and
just reuse whatever it is already
provided online I studied use the
examples as you can also access the
source code from them yeah so the same
application provides you the source code
you know you can see how it works and it
has a box with the code showing you what
they did to create these examples yep
what are the takeaways of this
presentation the piss the PCX the PC
experience is being reshaped we are
creating new device we are creating new
forms of interaction we are giving users
more freedom we are giving users a very
nice experience so we need to be
prepared to provide this kind of
experience our apps must you to know how
to impress our use our users and to do
that javafx and touch it's a awesome
option it's really cool it's very cool
to use it to touch interface it's easy
it's simple you don't need to learn a
lot of stuff to create you don't need to
create gestured gestures by yourself it
has already a lot of Justices ready to
use and using Jane I I can be something
very very cool and from the keynote I'm
sure you heard that mark reign of the
director of Java development he said
come on Jay and I it shouldn't be there
hard to develop right so they are
working on improving J&amp;amp;I technology
probably java 9 and beyond so we hope
that one day it's going to be even
easier to do what we did here just
providing calls and methods and no not
working with J&amp;amp;I environment object on C
so while you are we are looking forward
to that and i think that's it questions
any questions
hodgkin easy party too here we have a
prototype with our new press processor
this is the the has a one second you can
you can go to I can show you later but
yes this is a prototype that we call a
white box it does do not have a brand a
specific a parent it is created to to
land tour our partners to try and test
and having their apps tested so it's
something that if you become a partner
from Intel we also have a partner's a
program for partners even to developers
we have stuff for lonely wolves that
want to subscribe by themselves not
using the company name we have this kind
of programs to land computers to lend
hardware to give the our our friends
access to our technology so this is an
ultrabook I can show you after I can
unplug it and you can manipulate or do
whatever but idea it has all the sensors
available it has NFC it has everything
that you can attach the ratline laptop
though the hardware is the same has the
same stuff that the latest macbook air
the higher the hardware is exactly the
same but it has multitouch so one of the
cool things about ultrabooks I'm not
telling ultrabooks but uh yeah you wish
it's basically it's a standard for
laptops that in tau is working on it's
like pro giving that's if someone wants
to build a laptop hardware they should
be this way with these kind of sensors
with this kind of torture support you
know and let's beauty standard for
laptops as we are working on stands for
smartphones as well right all of them
have the same sensors and same kind of
touchscreen so why not doing that for
laptops as well and Intel I think they
are
pioneering in this kind of thing and for
java is really good because doesn't
matter if it's linux mac OS x over intel
or windows running on the laptop intel
but it's the same java application
probably connecting to the sensors in a
standard way so we are looking forward
to see that happening in a new feature
and this is our way to do something now
but we wish this becomes a standard in
the next five years top yeah and also
this is one that this one that I brought
here is do not have the the touchable
feature so we have a lot of computers
that you can detach your screen and use
a steroid sturbridge yeah the end of
that hybrids yeah one of the ideas that
I had when I was thinking about this and
trying to motivate philippi to disk
these kind of things is that you know I
don't want to work on Raspberry Pi to
provide embedded sensors on my boat for
example I already have a tablet with so
many sensors can just actually that
already have the sensor oh my boat right
and if i want to write emails i just
take that and go to the car and i
connect the tablet to the car panel so i
can just reuse the tablet with all those
sensors wherever I go and if you want
you to take a drink and sit yeah exactly
the front of our boat in and watch a
movie I don't know I you buzzards
connected but that's fine you can
disconnect it in the users tablets yeah
the experience is being changed as we
need to adapt our self is because the
market is changed it likes much a smart
phones are becoming bigger laptops are
becoming smaller but every day all of
them are becoming smaller I believe so
thanks guys if you go guys want to
connect us to eat or its phila PA
pedroso and Bruno Borges we really
appreciate you coming here and thanks a
lot</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>