<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Multitenant Java for High-Density Cloud Deployments | Coder Coacher - Coaching Coders</title><meta content="Multitenant Java for High-Density Cloud Deployments - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Multitenant Java for High-Density Cloud Deployments</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bK8riOsKu2g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's a little bit about myself before I
get started as I said I'm with the IBM
genuine Java development team I've
worked with that team for about 10 years
now I've contributed to our shipments of
our micro edition jvms RSC jvms for java
6 7 &amp;amp; 8 I also was a major contributor
to our real-time vm and more recently
I've been acting as our cloud lead
overall I have about 23 years experience
I've worked for six different companies
ranging from small startups to large
companies like IBM my focus has been on
runtimes on delivering electronic data
interchange and e-commerce type
applications like credit card processing
any invoicing s services as well as
security product development and
security consulting so I'm going to
start out with a bit of a motivation as
to why we should be interested in multi
multi tenant JVM and then you go on to
explain some of the sharing
opportunities that we expect to get when
we move virtualization up into the
runtime layer I'm going to talk then
about the model that's used for the
multi-tenant jbm as well as some of the
key aspects that it has to deal with and
finally I'm going to finish up with some
demos that show resource control and
isolation in action with our
multi-tenant JVM and we should have
about 10-15 minutes at the end for
questions so first of all why should we
be interested in the multi-tenant JVM
well as always you know we always need
to do more with less one way to do that
is to reduce the amount of resources
that the JVM needs and we do work hard
in every release to make the JVM run
faster you use less memory and so forth
but the other way we can do that is to
share the resources that we have more
effectively we see that there's a trend
in doing that sharing as we move up the
stock and in a multi-tenant JVM we want
to apply a proven approach of
virtualization at the runtime layer to
be able to achieve that sharing so
you've probably seen a picture like this
really I just want to put this up to
show that you know there's a whole
spectrum of how we can share ranging
from the left hand side where we're
going to share nothing we shouldn't have
individual copies of the hardware
software middleware and application and
the right hand side where we try to
share everything we share our hardware
OS and even the application itself has
been modified to know about different
than tenants and support them and
there's many other
areas or many other points on the
spectrum and what I want to talk a
little bit about today is a couple of
other points which aren't on this
particular spectrum but give us other
options in terms of making the balance
between isolation costs and the amount
of work we have to do in developing our
application so if we step back and think
of the perfect world and trying to share
more we want to get better resource
usage to get lower costs but at the same
time I'd like to not have to make any
changes to my application I want to use
my familiar tools and I don't want to
have to have special skills and my
developers to be able to do that so when
you look at virtualization is this a
good fit well it gives you something
that looks like a dedicated operating
system you get your own file system
Network applications pretty much start
and run just like they did in your
regular environment in terms of
application development you know your
applications run without change for the
most part you can use your familiar
tools and environments and so there's no
real changes for your developers but at
the same time you've achieved better
resource usage and you can share the
resources that you do have across
multiple instances so are we done we
have we know that there's existing
virtualization technologies out there
like VMware and so forth well there's
evidence that no we have it there's
still the need to share more and we see
that through efforts like memory sharing
deduplication you know basically
technologies to try and say let's find
multiple pages virtual pages that have
the same content and use a single
physical page to back them things like
powervm virtualization systems like
powervm have active memory active memory
sharing active memory deduplication
clinics and kvm have Colonel same page
merging VMware transparent has
transparent page sharing so these are
all efforts to try and share your memory
transparently across virtual images the
unfortunate thing is Java often works
against these efforts for them to
succeed you have to have multiple pages
that are the same and even if javis you
know even if you started out loading
objects in the same orders and so forth
Java does its best to move them around
as gc's take place and so forth so the
reality is that if you move higher up
the stock and virtualize in the runtime
layer you're going to be a have better
control of those resources and better
opportunities to be able to share just
taking a quick look at the
virtualization over time you know they
were introduced a long time ago in the
1960s IBM's hardware had type 1
bare-metal hypervisor 'he's way back
then in the early 2000s we saw a real
uptake of hypervisors through the type
to ones i ran on top of your operating
systems things like VMware power of a vm
k vm and virtual box and more recently
we've seen a real interest in lighter
weight virtualization through containers
where you share more of your West the
kernel structures and so forth so things
like a ixw pars solaris zones linux
containers which became a 10 this year
and even in past type environments like
bluemix and cloud foundry we see them
using things like wardens to host each
of the instances which is again another
lightweight tape container and docker is
another technology that's making
containers very popular in the short
term and so that's very popular now and
the question is you know when will it
make sense to start applying
virtualization at the runtime layer so
why do people you know why do we see
this trend of virtualization moving up
well you end up with you know perhaps
having to make a trade-off in isolation
but you do get more sharing
opportunities and that's the interesting
part and what's interesting in addition
to the default sharing you get is that
you can share more than what you're just
going to get out of the box if you think
about the fact that you're now have you
no less isolation between you and the
other tenants in some ways you know
that's a negative but in other ways it
gives you more opportunities a really
good example of that is the shared class
cash technology in the IBM JVM what is
designed to do is when you have multiple
VMs running in the same operating system
it lets you share some of the class
metadata that's used by your
applications it ends up arranging the
read-only portion of your class metadata
and mapping it into a memory map file so
that you end up having a single copy of
that memory map file that shared across
all the VMS if you think about the
lighter-weight containers you are
actually running on the same operating
system so all although it's very
difficult to try and get the shared
class cast shared across traditional
hypervisors in this case you can
actually arrange it so that that shared
class cash maps to the same file
and in these environments that ends up
meaning that you share the exact same
memory and now you end up having a
single copy of that shared class cache
which can be a substantial size you know
30 60 megabytes and you have one copy
that across all the containers the same
thing you can do is if you actually
instead of installing the JVM
individually in each of the containers
you pre install one copy the JVM and use
that across the containers it will also
share things like the shared libraries
for you for free looking at that a
little bit more specifically we looked
at bluemix and cloud foundry which is a
platform as a service offering the
droplet execution execution agent which
is where your applications run there's
an instance of a warden started for each
of those applications and so what we did
is we pre installed on the droplet
execution agent a single JVM EE server
in our case Liberty and shared class
cash and we map that into all the
wardens with existing configuration
options are available and by doing that
we ended up with a single copy of that
shared class cash and you know the net
result was faster startup and lower
memory use across those containers we
also did the same thing for doctor if
you're familiar with dr. it uses layered
images and so what we did is we built
another base image where we pre
installed the JVM a copy of liberty and
our pre-populated shared class cash and
if you then start multiple containers
running your applications using that
base container provided you use the
right back end file system and for
example in Abu to you it uses aufs you
do end up sharing the exact same copy of
the file until you try and modify it in
this case we're using read-only
artifacts so you never try and do that
and so you end up sharing the exact same
copy of the shared class cash across all
those containers and you can see from
the informal measurements that I did
hear that you know some of your savings
can be pretty significant in the case of
just starting up Liberty you know we
used almost half as much memory as we
did is if we if we didn't share the
shared class cash and in terms of start
up because we were actually be able to
reuse the shared class cache which again
helps with startup you know our startup
times were pretty much half of what they
would have been without doing that
sharing the other interesting thing on
here is is the line in the middle in
terms of the speed up time is the
default where because of the new
approach that these could that are often
used with these lightweight container so
in darker and in bluemix typepad
environments most often it's a kind of a
stateless environment where you expect
to start from scratch run and then you
throw away the state at the end of the
run as opposed to the regular JV JVM
environment where you start up and then
you expect to start up many times so the
default here is actually going ahead and
trying to create a shared class cash
inside that container which will never
be reused so you're taking an overhead
that you're not going to get any benefit
from on the second start so this shows
that even if you don't take the effort
to try and arrange to get that the
proper sharing across the containers
maybe you want to look at the default
configuration options because being a
little bit different environment the
defaults may no longer be appropriate so
as we've seen going to a you know moving
up to lightweight containers from full
virtualization we had some opportunities
to share more through the container
through the shared class cash and you
know we'll continue to exploit those
because there's a lot of interest in
that kind of deployment today but at
some point we're going to exhaust the
opportunities to be able to share at
that level and at that point it's going
to make sense to move up to the runtime
layer and just like moving up to
containers we think that there's going
to be more sharing opportunities so for
the multi-tenant vm we want to take the
proven virtualization approach where we
know that hypervisors and containers can
run multiple applications safely side by
side they can share idle CPU cycles they
can meet our resources and shift them to
the tenants that need them you don't
need to change your applications which
is key and provided you have a number of
applications that don't need all of
their resources at the same time you can
end up sharing those resources pretty
effectively so we want to move up to the
case where you know the JVM can run
multiple applications safe safely side
by side it can shift resources and CPU
cycles to the tennis need it again we
want to maintain that you don't need to
change your applications and I'll talk a
little bit about that later on and so we
want the same net result where if you
have multiple applications that don't
need their resources at the same time
you can achieve better sharing and in
this case we have having moved up the
stock we should have better control of
some of those resources and more
opportunities to share
so in the next few slides were a little
going to be a little bit busy but the
idea is to show what kind of resource
what what do we think we can share we
always get the question okay if I move
up to the runtime level what is it that
I can actually share if you look at the
main areas where the memory is used by a
JVM you know you have the heap as a
significant contributor you have things
like threads where thread stocks and
Java staff can be non non trivial you
have your internal JVM structures so
class metadata class loaders can consume
a fair amount of memory as well as
things like internal jit caches traced
caches and so forth as well as the
actual components of the vm itself like
shared libraries so we looked at that we
also broke that down in terms of
artifacts that are related to the
bootstrap vm so the vm itself middleware
and applications because we thought
depending on the different options
you're going to have different
opportunities to be able to share those
or not be able to share them so we given
that break down we then looked at the
standard vm and said ok let's actually
measure how much memory each of those
things use and we use that / to predict
what the best cases of what we can share
at the different levels so we tried to
make predictions and we as we go to the
right we're getting more and more
aggressive about sharing so our first
option is well we'll just turn our set
on our on our standard JVM with shared
classes and that will give us a certain
amount of sharing and that's what you
know I've shown you could do with
containers if you try and if you set
them up correctly or if you have
multiple JVMs in the same operating
system next comes the multi-tenant JVM
where you run multiple tenants in the
same vm itself you get some sharing by
that just the fact that you're in the
same process and others by trying to
share things like class artifacts you
can then try and push that sharing up
and we have that option because by
default we only share at the bootstrap
so if your application code doesn't
share but you can actually push the
sharing up into the middle where in the
application code it does get a little
bit a little bit more complicated in
cases where you have more complex class
flurries those things like osgi but we
have done some proof of concepts to show
we can do that if you're interested
thomas watson presented a paper on
multi-tenancy and osgi sharing at the
last eclipse con so you can probably
find up through an easy web search
and we broke it down based on whether
you're running the same application or
different applications because if you're
running the same application you'll have
more opportunities to share than if
you're running different applications
and finally for completeness we included
the case where you pull the the
middleware server into the multi Tanner
framework and you isolate only at the
deployed application itself and that's
some work we're doing with the
university of new brunswick right now so
given these predictions we said okay
let's take our measurements and will
show what we could actually share in
this case the yellow red and green show
the total memory that was allocated for
the vm the green is what we predict we
can share based on our numbers red is
the portion that's non-shared yellow is
the portion of the unused heap so it's
not memory that's actually actively in
use but its memory that's been pulled
into your resource set at least
partially because it was needed at one
point in the past also important to
remember is this purple line the
resource set so that's what actually was
in memory for your application so it's
important to keep that in mind because
you may end up sharing things which
wouldn't have been in memory anyway so
looking at the resource that's always
important as well so if we look at if we
look at our different options and the
amount of sharing that we think we can
get to you end up with you know if you
have two VMs in a regular West you do
get a little bit of sharing because
things like shared libraries get shared
by the by the OS by default if you turn
on shared classes you know and in this
case we were running day trader which is
a standard application for measuring
performance for a JVM and we measured
after we driven some load on it so with
the shared class cash you got about 4 42
Meg that was shared if you move up to
the multi-tenant vm you know we predict
you can share about 144 meg the thing
you will notice here is that there's a
bit of a bump and that's because today
with our multi-tenant implementation we
have some extra overhead we have some of
our own threads we have to run some low
to some of our own classes and so you
know there's a bump that goes up at that
particular point and as we push the
sharing into the middleware and the
application you can see that you know
the prediction of our best case goes up
you know to find it to the point where
you know or about 250 Meg out of the
overall you know 420 megabytes they've
been loaded there
this is a little bit of a different view
where we said okay let's actually look
at it as percentages and we have three
different applications here at hello
world day traders startup and then day
trader after having driven some low and
we can see that you know even with just
this you know sharing at the
multi-tenant JVM saw levels of the
bootstrap level for hello world we get
really good sharing you know nineteen
ninety-five percent this matches really
well with our measurements where you
know we can start lots and lots of
multi-tenant JV f but multiple butts and
lots of hello world a lot more than if
you ran each individual hello world in
its own JVM normally for something like
a more substantial application like day
trader you know even with the
multi-tenant JVM you know the answers
say thirty five to forty three megabytes
which is still fairly significant and
you know as we push right you can get up
into the range and you know sixty to
seventy five percent we have the two
different numbers there because of the
unused heat portion so you can be
conservative and say well I want to
count that as something that's not
shared or you can say well if I have my
tennis running at different times then
that extra you know sort of overhead
that was needed to get things going is
likely to be not needed at the same time
so you can actually end up sharing that
so depending on how optimistic or
pessimistic you are the amount of
sharing we actually get will be between
those potatoes two particular numbers so
now that I've hopefully convinced you
that there is a good opportunity to
share more and get higher density with
multi-tenant jvm I'll talk a bit about
its you know the model that's used and
about some of the key issues that you
need to deal with so to start with you
I'm sure you're familiar with the
standard JVM when used every time you
start a new application you end up
having your own process with all the JVM
our data artifacts that includes threads
GC GC threads jit threads a heap and so
forth for the multi multi tenant JVM
instead what we do is we launch a very
small proxy process and that proxy
process will go out and find a java
demon and it's in that demon that your
actual your tenant code actually runs
when you first launch if it will go out
and look for a demon if there isn't a
demon automatically starts it for you
the default security models based on
users so
if unless you configure it differently
you'll only connect to demons that are
associated with your same user but of
course there are command-line options
they let you override that so you could
have multiple demons per user or share a
demon across users the standard in an
error now tis proxy back to from the
Java demon to that proxy so you know if
you're at the command line it still
looks like you're running from the same
process that you started even though
your tenants running in that Java demon
there are no changes required to your
application and I'll show you that
through some of the demos later on and
it's in that Java d that you can it you
can achieve that high density higher
density because you're sharing things in
that process so just to show starting it
you know the simplest thing you need to
do is just add in this xmt an extra
command line option now in reality it
doesn't always turn out to be quite that
straightforward because in the case of
tenants when you're watching tenants and
their tenants are going to run in that
single demon it no longer makes sense
for all command line options to be on
that tenant launch so for example you
know if I'm going to specify a jit
option well that's really going to apply
to the entire demon as opposed to India
individual tenants otherwise we wouldn't
be able to share as much stuff so there
are a few options that need to be taken
off the command line and put into what
we call java deed options that apply to
the overall demon but for the most part
things like system properties class pass
all the stuff which are really specific
to your application can stay on the
multi-tenant command line and you just
add on xmt so when I run that it'll go
out and look for an existing demon if it
can't find one it'll automatically start
the demon it connects to it and it
starts running your tenant in that
particular application next I can start
a second tenant again I have a different
class path effectively because i'm using
a jar file here i've just added xmt it
starts up running it connects to the
existing Java d and your tenant is now
running in the same process and that's
where most of our runtime structures end
up getting shared so now that I have two
tenants running in the same process the
same jvm effectively there are some key
issues that we have to worry about to
make sure that that's safe so first
thing is you need to worry about is
separating state I don't want the one
tenant making changes that affect
another ten so for example if I have a
default
locale and 110 it changes that default
locale I don't want that to affect the
other 10 so i'll talk about that we need
to make sure this data is separate
between the tenants the next thing I
need to worry about is resource control
it's a little bit less direct but I
don't want one tenant using all the CPU
and starving out the other tenant or for
example using all the memory and causing
it out of memory error on the other
tenant so we want resource control to
make sure our tenants can run safely and
cooperatively and finally we'd like name
spacing it would be nice if we could
have you know individual views as a file
system the network just like we had for
other in other virtualized environments
so that I don't have to reconfigure my
configuration files and stuff like that
so first looking at separating state I'm
sure you know if you've written Java
programs you know that static values are
pretty much usable across your
application if you can get access to the
class you can get access to the statics
system out is a classic case where you
know I'm saying I want to say system dot
out print line it uses a static behind
the scenes and given that you know I
have multiple proxy processes I want
that output to go back to the
appropriate one for your tenant not go
to all of them or anything like that so
I need to separate that that state thats
related to that system dot it if we take
that code and we look at the byte codes
to get generated for it well you'll see
that you know you'll see something like
this where it says get static system dot
out and it's basically saying give me
the static called out from the system
class and so what the multi-tenant JVM
does anytime there's an access like that
if you read or write to a static it
actually acts on a per tenant copy of
that static so if I'm in 10 at one I get
copy for 10 at one if I write to it i
get i use copy for 10 at one and to do
that we need dedicated storage for each
tenant behind the scenes the other thing
which isn't necessarily as obvious is
that there's a number of rules in the
JVM related to static initialization so
the first time a static variables read
written or say a static method is run on
a class there's a number of rules as to
when you run the static initializer for
those statics now since each ten it has
their own copy that the statics the
multi-tenant JVM needs to make sure that
we're actually going to initialize them
for each tenant to make sure that you
start out in the right state so that's
the other thing we do is we make sure
that when you access the statics
and it's the right time based on the
rules will run the static initialization
in the context of that particular tenant
the second main thing I mentioned was
resource control so we want to make sure
that we can control resources that are
used by the different tenants internally
we use what's called a token bucket
algorithm it's commonly used in network
traffic shaping and generally the way it
works is that you know you have buckets
for each tenant for a given resource and
as the tenant needs a resource it asks
for token out tokens out of that bucket
and as long as there are tokens it can
continue to consume the resource if you
get to the point where there's no more
tokens in the bucket the tenant
basically has then all the threads for
that tenant need to wait until the
resources become available and at some
interval the buckets get refilled and
anybody who's used all their resources
can continue in cases where there was a
natural command line option so something
like x MX we overloaded that for the
tenant case so you can say x MX 20 mag
and that limits of particular tenant
down to 20 meg for the other cases we
added this X limit option which has the
general form of X limit resource a
minimum reservation and the maximum that
you're allowed to use you're allowed to
say i want at least ten percent of the
cpu to be available for this tenant but
it can use up to thirty percent of that
cpu if you know nobody else needs to
what they've reserved and the resources
that can be throttled are includes CPU
threads heap memory on disk in network I
oh so a few concrete examples excellent
CPU ten to thirty says I'm going to
reserve ten percent for this particular
tenant and I'm going to let him use up
to thirty percent of the processor if
nobody else needs it excellent threads
five to twenty says this tenant should
be able to start at least five threads
concurrently but at most 20 and finally
XM x 20 is let's limit this particular
tenant down to 20 megabytes namespacing
so this is the third aspect I talked
about this actually if you think about
it would be useful even if you were just
running multiple JVMs in the same OS it
would help having to avoid
reconfiguration and stuff like that
status would be useful but aren't really
in place and this is one area we haven't
addressed yet most of the time it's
fairly easy to work around by
reconfiguring what ports or IP addresses
you use it's not a stretch to think
though that we could add name spacing to
the JVM it already has control over a
number of the namespaces so through file
api's Network api's you could control
what the vm CS or what the application
see by managing that in the vm and it
might also be at possible to leverage
some of the OS or container type
features to help us do that so just to
go over an overview of the multi-tenant
JVM so it gives you a hundred percent
pure sorry transparency from one hundred
percent pure java applications you can
easily opt in through the xmt command
line your applications run and shared
java demon and that's where the the
aggressive sharing takes place standard
in air and out is redirected to your
proxy process so from the command line
still looks like you're running from
that particular process you get JVM
enforced resource control over threads
heap sizes network i/o disk i/o CPU and
so really what you end up with is
something which behaves like a dedicated
JVM but is much smaller because they're
you know you're sharing the single
process there are a number of
limitations with how far we've gotten so
so to date one of them is didn't we
don't allow jaana application jni
natives once you get into the J&amp;amp;I layer
there's a lot less controls and so it
wouldn't be safe to have different
tenants running J&amp;amp;I and in those natives
generally there's a one-to-one
association between a process and a GUI
so it's not a good fit to try and run
multiple GUI Xin that single process so
we don't support GUI applications we
only support 64-bit because generally
you need larger heaps to rail to support
multiple tenants and some things like
JVM TI so far our process why so you can
debug but you have to connect to the
demon as opposed to an individual tenant
some things though like java agents you
can actually run per tenant you just may
have some limitations so for example you
can write your own java agent that's
going to transform classes but it can
only transform classes associated with
your tenant not the bootstrap classes
which makes sense if you think about in
terms of where you know the application
sweet spot well you really want cases
where the
issue between your class and JVM
metadata is larger compared to your heat
if you have a really really big heap
then the ratio of what you can share in
the JVM to the heap size isn't going to
be enough to make it worthwhile cases
where you have applications that start
run for a short amount of time stop so
things like batch type environments are
also good because you've already got the
JVM started and so you can connect to it
and run much more quickly and of course
you need cases where you have work loads
that need their resources at different
times of every app or tenant that you're
running needs all the resources that it
has at the same time there's not much of
an opportunity to share so those aren't
very good situations and then finally as
we said because of the jni limitation
one hundred percent pure Java code now
that's something that actually isn't
it's not something that you couldn't get
around we have done work in the past
where we've proxied jni invocation to a
separate process so you could imagine
it's actually running those natives in
the proxy processes instead of the
shared java demon we just haven't gotten
to that yet so hopefully now I've shown
you a little bit about the multi-tenant
JVM the model that it applies and how it
works I'm now going to go into some
demos to show it actually running and
doing different things the first
question we always get is well what
about system access I'm just going to
write some code let's go call system
exit it'll terminate the whole process
and so you know that's not gonna be
right of course those are the kind of
things we can deal with and so I have
just a simple example to show you that
in this case I have one application
which basically just says hello and it's
like hello hello I'm still here and I
have a second application that starts up
weights a short amount of time and then
call system exit i can start those two
applications concurrently just by adding
xmt to the command line and we'll see
that in a second here now I wasn't brave
enough to do these all live so that the
pre can them but they're short and it'll
make sure it keeps me on time as well so
in this case you can see I'm starting up
the first application saying yep I'm
still here I'm still here the other app
starts up and says hey I'm about to exit
does call system exit oh but wait a
second application one is still here and
it kept on running so this is a very
simple example of course with
system.exit but this does apply to other
things you know if you're familiar with
Java you can register shut down hook so
when your application finishes normally
you can run some shut down as well of
course those are the other kinds of
things we looked at and when you
register a shutdown hook it's in the
context of your particular tenant when
your tenant shuts down that's when
you're shut down hooks run all the other
tenants keep on running and they're shut
down hooks will run when they finish now
when I talked about the things we had to
worry about we talked about isolation so
things like system accident shut down
hooks those really aren't related to the
isolation that I talked about in the use
of statics so a more subtle example that
does show that is locales if I have
multiple locales one application changes
the default locale I don't want that to
affect another tenant so in this case I
have to application one which just
constantly gets the default locale and
prints out hello in the default language
I have another application which says
well I'm going to change the default
okay I'm from Canada we have two
official languages so French and English
so the second ones being québécois is
going to change the language to french
and print out Bonjour we have two simple
bundle files that you know control which
languages we print things out in the in
the previous example just like the
previous example we can start those
using the xmt command line I can also
they'll run them in a standard vm just
by running writing a simple wrapper that
says okay i'm going to start a thread
for each of those main lines and age
thread i'll call the main line and i did
that so now i can show you the behavior
in the standard vm and the behavior in
the multi-tenant via so in this case I
wrote a simple rapper called local
issues which is going to start these two
apps and run them in this in a regular
vm and we'll see that first ok weird
Mike
up there view okay well when I thought
this would help this would prevent me
from having problems with the demo but
we'll just give it a minute here I've
gone through this you know at least 10
times without any problem but you know
here we go okay so also going to start
yep so in this case come on oh you can
see we're running I think yep so the
first app starts up says hello hello the
second app is going to start up now and
he's going to say well I change the
locale and we see oops I think I want
one too far sorry yep okay so in this
case this is the case with the regular
vm you see the same thing we're going to
start up first app says hello hello the
second app is going to start up changes
the default locale to French now both of
them are saying Bonjour well that that
made sense in a regular vm because we
only have one default locale I could
work around this so I could still run my
to application safely but I'd have to
change the code from my application and
that's not something we want to make
force people to be able to do ok so this
case I'm going to actually start the
same same two applications without
changing the code in the multi ten of vm
and we'll see that you know again the
first one starts up start saying hello
we'll see the second tenant come up
it'll change the default locale so at
the French up but now we see we all we
keep alternating hello Bonjour hello
Bonjour so we've run the same
application without having to change it
and we see that in the multi-tenant vm
the isolation makes it so that it runs
safely and they don't affect each other
whereas having run them if i want to run
them in a regular vm might actually have
to go and change the code so the next
thing i'll show you an example of is
resource control and i'll look at memory
so the multi-tenant vm uses what we call
the balance GC policy and the balance GC
policy spreads the vm into a number of
regions and then each of those regions
is associated with a particular tenant
so the way we control the memory is we
can limit how many regions can be
associated with a particular tenant
every time you know a thread running in
the context of tenant needs to do an
allocation will allocate those objects
out of one of its regions and if there's
no more space in those regions will ask
for another region if we can't get that
region then that particular tenant will
get a tan out of memory air at the same
time there still may be lots of free
regions which other tenants can get and
they'll be able to keep on running so in
this case again I have a very simple
application that just says hey I'm still
here I'm still here and then I have
another application which just says
every two seconds I'm going to take
another bite of memory so chomp eat
bunch of memory and it's going to keep
doing that until you run out of memory
just like the other case I can run that
with a simple wrapper so I'll do that in
a regular vm to start with and know
where my mouse is going here but
oh it's like come on okay so I'll start
up in that the first app so you can see
the first apps I'm still here I'm still
here the other app Chomp taking by the
memory taking body memory now I did
configure this to disable options on the
command line up wait aside it did the
same thing to me get it let's go back to
the regular vm sorry about that so we'll
see the first app starts still here the
other apps taking a champa memory by two
memory I did do things like disabling
dump so that it doesn't cloud the output
so the first tenant when he runs out of
memory is actually going to run out of
memory silently the other tenant you see
here tenant nap number one it actually
gotten out of memory area even though it
was the other tenant that was eating all
the memories so with the regular vm you
basically end up one tenant allocated
until there was no more memory and the
other tenant ran out of memory died as
well with the multi-tenant vm again
starting the exact same two applications
we can see that you know the first ten
is still here I'm still here the other
ones taking the bytes of memory and
we'll see that when it gets to the point
where the first tenant runs out of
memory and silently dies the other
tenant just keeps on going until it ends
up terminating normally you can see
there is a little bit of GC activity
here as it tries to you know clean up
for that first tenant but then the
second tenant just keeps on going
because there's still plenty of memory
for it even though the other tenant ran
out ran out of memory
the next case is well what about CPU I
don't want one tenant eating up all the
CPU and basically starving out another
tenant so I have a very simple example
here in this case I'm just going to show
running under the multi-tenant us the
multi-tenant vm with and without CPU
control so I just have a simple
application it starts eight threads I
was running on a machine with four cores
and those eight threads all try and use
as much CPU as they can in the CPU
thread I just have a little bit of
randomness to defeat the JIT to make
sure that I don't need to start a whole
whack of threads to make it use all the
CPU so in this case we'll see that the
CPU used pretty rapidly gets to four
hundred percent I had four cpus as I
mentioned so as soon as I hit return and
it actually starts to run you'll see
that the CPU goes to four hundred
percent if I had multiple tenants
running it would now be up to the OS who
got you know they're both trying to
consume all the memory they might get
fifty percent each or they might get a
t20 it's really under our control not
under our control and we wouldn't be
able to predict that very easily how it
would end up so as you can see there we
got our four hundred percent being used
so now let's say this time I'm actually
going to run it with a limit and you'll
see up here I've added on the command
line there i've added x limit 50 50 so I
said let's reserve fifty percent of the
cpu for this tenant and let's cap it at
fifty percent as well so if you look at
the CPU against javidi you'll notice
that it's not four hundred percent so
it's not actually consuming all the
memory the other thing you might say is
wait a second though it's not exactly
two hundred percent well that's because
as I mentioned we use this token bucket
algorithm which limits you over a
particular period so you're not going to
always get exactly two hundred percent
sometimes you'll be able to get more
sometimes you'll be able get less and in
particular if nobody else needs the
resource in the early part of the
interval you can get you can use as much
as you as you as you can get but then
you'll be throttled back so that over an
average over the interval means you'll
get your two hundred percent and if we
took these numbers which are over and
above two hundred percent I'm pretty
confident they would average out to two
hundred percent next we're going to look
at network i/o control
so in this case we have an ftp server
and we're going to copy a large file to
that ftp server both with and without
network controls first of all we're
going to show that you know we're using
the apache FTB server it can actually
has some of its own rate limiting
control so we're going to show that
we're turning those off and basically
let the ftp server running at full speed
next we'll show the just a default
configuration we we don't actually have
any of the multi-tenant features turned
on for the first run you might notice
that I had some help from our team in
China to help you put this together when
we get to the next screen there's
Chinese and I'm speak Chinese but so in
this case we're going to start up now
we're going to bring our client and
we're going to connect and we're going
to drag the demo file a large file
across just to see you know how fast can
we transfer file if we have no no limit
in the first place the thing you'll
notice is kind of interesting is that
the number reported bounces around even
even without controls the number is
going you know from anywhere from 10 to
20 megabytes the the clients you know
the way they also try and estimate over
an interval causes you know some
variation in what you see reported as
well as there might be some effect but
you know we're running locally so there
really shouldn't be too much is probably
more related to the way that the client
reports that and we can see that over
time it trended to about 11 megabytes
per second so now we're going to modify
the configuration file and you can see
we're adding the x limit net i/o which
will limit the network I owed to half
the bandwidth we saw before so six six
men
once we've done that we'll start up the
the ftp server again and then we'll go
back and we'll actually transfer the
same file as well so just like with the
CPU you're probably going to say as well
wait a second it doesn't immediately say
six meg but it's you know both a
combination of the the client the way it
reports its speed as well as the fact
that you know we do average over an
interval so you can actually transfer
faster and then you'll get throttled
back and you see that pretty quickly you
know we're now say ten ten percent
through the transfer and we're already
trending towards the six meg limit that
we set so again we can quite effectively
limit the bandwidth that you can use in
terms of the network I oh and you'll see
the transfer speeds up but that's mostly
because we sped up the recording to make
the demo quicker herbs so those are the
demos that I had I mean they're fairly
simple but of course you can you know
apply them in different ways if you want
to learn more we have a multi-tenant
community this is the link to it it has
links to downloads you can download
copies of the vm if you want to try it
out for yourself it includes
documentation zit has links to white
papers it has links to pass presentation
so really it's your one-stop shop to
getting more information it also has a
form if you want to ask questions or
give us feedback so I you know I'd be
happy if you went there and you know
tried it out gave us some feedback so
just to summarize I started out with the
motivation you know why should we be
interested in the multi-tenant JVM
talked a little bit about the you know
the fact that we've seen the
opportunities to share as we move higher
virtualization higher up I explained
what we expect the base case best case
sharing opportunities to be in the JVM I
talked about the multi-tenant JVM the
model that it applies and some of the
key issues it has to deal with and
finally I ended up with some demos that
showed isolation and resource control in
action
i'll be at the booth today and tomorrow
so immediately after this i'm at our
booth at 5511 so if you have any more
questions or want to talk to me about it
feel free to come by and I think we
should have about 10 or 15 minutes for
questions sure to questions so let's see
first you call so like the api's like a
turtle keeps pace get available memory
you get what's just been allocated to
you or you get a whole picture of the
machine number one and then number two
is there do we have the capability of
modifying those X limits on the fly
right so we change it from say fifty
percent to say a hundred percent without
having to restart yeah those are two
good questions so in terms of whether
you get the overall view or your own
personal view it depends on which a pH
api's you call we haven't managed to get
through the exhaustive list so some will
give you a pertinent view and some may
give you the overall demon view in terms
of the modifying that the fly that's
something I've been asked several you
know many times we currently ecstatic
you set it up front but there's no
technical reason why it couldn't be
dynamic everything that's working behind
the scenes is used you know consulting a
number which could easily be changed
sure how would you identify a
misbehaving tenant so I'm used to using
top i know i can use top so rightly so
so things like jmx are a way where you
know we can provide pertinent
individualized pertinent information so
that's something we haven't completed
the work to fully make known to de jmx
api's show individual values but that's
the way that we plan to expose a lot of
that information triple any man should
the cpu time with this leaky bucket
great token bucket and why wouldn't you
just use the OS
facilities that are already there right
so the some of the advantages of well
the way we managed it is you know as as
tenants run we track the CPU that
they've used it in particular interval
we say has this group of threads used
more cpu than it should have for this
interval and at that point they're
forced to wait at the next interval when
we refill the bucket we release them and
they can try and get the CPU as well in
terms of why you wouldn't just use the
oos enforcement you know one of the
things this java is supposed to be
platform neutral right so this gives you
a way of providing controls which again
aren't specific to your particular
platform so yes you know if you run
multiple separate JVMs I can you know
under AIX I have a particular way to do
it under linux z/os and so forth but
this gives you one which would be you
know across platforms platform specific
is that the same reason you can't do GUI
yeah the GUI thing is that it's like
it's more the fact that like some of the
the libraries the underlying GUI
libraries really are expecting to be a
toast associated with their process and
they're just not set up to have multiple
GUI Xin that same process sure sorry I
said it again yeah so obviously there's
going to be some overhead in the RCM
controls as well as you know isolating
the statics the our target is about a
ten percent overhead we're not quite
there yet I think the last measurements
on daytrader were more like in the
sixteen percent range and it obviously
depends on your application in terms of
you know what it's stressing more than
others if you don't use very many
statics that portion the overhead won't
be a significant on the RCM consulta
side you can also control how often you
enforce the the control so you know your
interval if you make the interval really
small you can get very tight control if
you make it large but you're going to
have more overhead but if you stretch
out that that interval you can have you
know reduce the overhead that you get
through limiting so we've chosen to one
second interval now is a balance between
the two but you can sort of tune it
either way if you want to no sir yeah
android sigo closest just replicates
itself most of the memory shares right
yeah we've tried to apply that model to
Java in the past and and it's been
challenging enough that so I can't
necessarily say which one would be
better but you know I know our attempts
to do it in Java haven't been as
successful as our multi-tenant story so
far sorry it is GC tenant specific or
there's a GC of one tenant cause today
GC is shared across them and so would
you see in one tenant will call it will
affect the others the idea that we have
on that front is you know you can
obviously make it the GCE actually per
tenant so the balanced the way it spread
across regions we could say well we're
only going to collect reasons for a
particular tenant the other thing we
have in mind is that you could actually
if you build back the resources used to
a GC based on the region's you collect
you can end up using the cpu control so
that if you get billed for all the GCS
you cost eventually you're going to be
throttled back and you won't affect the
other tenants sure yep so you made like
how you tell like says that your
application is not using in the yeah we
don't have any tools to him we'd
certainly thought that a tool to help
doing that would would be useful you can
you can most often i think you know
because there's like extra libraries
like there's shared libraries that are
going to be that contain your J&amp;amp;I
natives so i think it's going to be
fairly obvious whether you have pure
java or something that has extra
libraries that go along with it okay
only if you only have jar files you
don't have extra ji natives sure
it's available as a tech preview right
now sorry ass not burn up not for
production yet we have a separate copy
per tenant yes yeah exactly every time
you go for a static variable you get the
tenant specific version of that static
and like I said you know your static
initialization is run per tenant at the
right time as well yes I mean and that
there's lots of cases in the actual JCL
itself and not you know the isolation
means that so for example the the
shutdown Hawks well they're done through
statics and so we almost get that for
free right so that's where you know I
mentioned that the ra's type features
may give you data based on the the Java
demon not pretended so you know Java
agents you can do some instrumentation
at that level but yeah today it's going
to be mostly processed wide and that's
another area we'd like to work on some
more sure
you just expand on that a little bit
right so by default the the multi-tenant
JVM actually only isolates at the
bootstrap class library so if you load
libraries for your application that's
going to end up having its own copies of
those anyway so you could have one
tenant running version one version and
you could have a different tenant using
a different version it you're right that
when you try and get more aggressive and
you want to actually share the
middleware and share the application
classes you're going to start to run
into that as well but by default today
you wouldn't necessarily have that
problem
okay I guess if there's no other no more
questions thanks for coming and if you
have other things you want to talk about
just coming down to the booth i'll be
there</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>