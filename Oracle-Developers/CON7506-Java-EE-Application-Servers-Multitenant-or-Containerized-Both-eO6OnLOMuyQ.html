<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CON7506   Java EE Application Servers: Multitenant or Containerized? Both! | Coder Coacher - Coaching Coders</title><meta content="CON7506   Java EE Application Servers: Multitenant or Containerized? Both! - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CON7506   Java EE Application Servers: Multitenant or Containerized? Both!</b></h2><h5 class="post__date">2015-12-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eO6OnLOMuyQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good afternoon everyone thank you for
coming to the last batch of sessions at
javaone my name is Bruno Borges I work
for oracle as product manager and just
waiting for these rights to come up I
work on the Oracle cloud team hey go
thanks organ Oracle cloud team on the
outbound outbound product management
team so my job is to make sure customers
developers operators add means they
understand what is oracle cloud platform
as a service and how you can use it but
i also work as my free time as an
evangelist as someone that engages with
the community and also the java ee
platform and other frameworks not just
java ee and for the past three years i
was working as regional regional
outbound p.m. in an America for weblogic
and at that time it was great to work
with weblogic directly are you David you
can you are welcome to join the stage
here and set up your laptop David
compiles is a will be speaking with me
he's a inbound product manager for
weblogic so David is the one who
actually talk to the engineers and make
sure the features of what logic that
customers are most interested about are
implemented hopefully the right way so
we're going to be talking here about
java ee application servers before that
of course safe harbor statement you're
going to be covering some features on
products that's why it's important you
understand this statement here so Java
EG application servers containerized and
multi-tenant
there's a huge hype on blocker and of
course last year I decided to work on
docker support for obliging and with
working with the rebound team Monica
Charlie deviated reliance the inbound
team we put together a support and
certification for weblogic unblocker and
then but logic decided to implement a
new feature called multi-tenancy on the
application server level and then you
ask yourself so should I put a logic on
docker or should I use multi-tenancy
should i use both should I just use what
logic the usual way and actually is
interesting because the multi-tenancy
idea is it is like darker but reversed
but its reaction to explain so what are
we going to deal here I'll go cover a
few slides and I'll show you a demo on
docker and then with the help of David
you can understand how the multi-tenancy
of what logic works on for application
server so of course as the traditional
java application server environment what
you have is usually when I use the
application server either as a stand
alone or with a domain model you can
have the stand alone you've got to see a
tomcat not exactly an application server
but you can add lots of stuff you can
use Tom IE you can use Wi-Fi on
standalone mode jboss the diversions be
before how stand alone but some
application servers offer at the main
model where you can organize lots of
resources on your application server and
deploy applications the way you want and
still resources can be shared among the
applications those applications so on a
standalone mode you're going to see one
application instance with applications
deployed JMS data sources of that
deployed on the application server of
course even on a standalone mode you can
create a cluster but with the main model
you can actually have different
clusters managed by that same domain by
that same application server and then
you can define a bunch of applications
JMS resources data for a secure area
bunch of stuff and you can say hey I
want to put this application on this
closer here and that other application
that other closure and you can spin off
different machines you can do a really
quite a topology domain model based on
your application server and this model
has been on weblogic since what 2002 the
main model the project how what is that
61 so that's like 99 yeah so it is a it
is a model very very stable everyone
knows people use it for many many years
but then we got darker we got containers
got isolation that we want to isolate
the memory want to isolate the CPU the
resources in this domain here in this
example in this picture usually the JMS
resources the data sources they will be
available on the gnd I 32 all the
applications so don't have a lot of
isolation so what customers the
administrators of these environments
they end up doing is they spin off near
domains and then you start to have
different domains and how to add me add
mr. dad and becomes a problem and then
you're going to see companies like GM
who has like ten thousand of weblogic
domains to manage and then that's why
some customers go to enterprise manager
making manage all that infrastructure
but then we see doctor and last year we
certified weblogic on docker between
last year and this year remember exactly
when we certified weblogic 12 13 on
docker so actually you can now run with
logic on dr. containers in production
and we certify some topologies on that
so how does a java application server
works on a container you may imagine a
sessions by arun gupta or by other java
evangelists running java ee servers on
docker containers but you don't see
clustering you don't see both balancing
without fail over of transactions ejb is
that kind of thing so what happens is
you're actually just using the Java EE
platform as an API that is ready to be
used but they're not taking advantage of
the phone java ee application server all
these features available h a clustering
replication distributed JMS all that so
that was the problem at the beginning
when you thought oh can I could a java
application server on a container yes
you can but its standalone so this is a
certification the new certification we
released now we also have 12 to 1 which
is java ee 7 certified and runs on
oracle jdk 8 and it's only eight because
eight is awesome i have lambda
expressions and stuff the darker version
is important 1.7 up we suggest you
always be on the latest version of
doctrine that project they released
something new every month or so so what
kind of topologies we have with weblogic
on docker in containers well you might
end up with two topologies at the moment
that we certify you might make it work
might be able to make work some other
topologies but you can also try those so
number one is the single host closed
read configuration you can actually have
a clustered environment on containers on
a single host machine or you can have
standalone instances of data main server
on inside a container and then spread
across multiple hosts the difference
between one and the other is that on a
single host environment when you have a
closer it is a real cluster so you are
ruining that the container is like a
lightweight vm fair saving resources on
that now you might think why should i do
that well for the development
development like environment on their
machines they would have to start at
least two virtual boxes to actually have
some idea of a prediction like
environment with the containers it's
much easier and you can share that among
developers instead of downloading a vm
with like 10 gigabytes of memory just
share a container
image with all the domain configured to
reply applications and it can create
servers and test some clustering on that
environment but if you want something
more like the darker way of doing stuff
you're going to use the multi host
configuration with a standalone Anatomy
servers so that that means you put all
the PR applications JMS stuff on a
domain you just find the enemy server
you target the ad applications all those
resources to the admin server and then
you run the admin server as your
platform runtime platform for your Java
EE applications and then you can of
course have a load balancer so how does
it looks like when you start java
application service on containers you're
going to have the admin server we're
going to start weblogic and then you're
going to call a script that you offer
that helps that it's called create
server they create server script that is
on github that way you can call weblogic
scripting tools and define your domain
the way you want in the case we push we
have on github it will create a machine
and you will create a managed server and
associate that automatically to the
domain running on the enemy server and
then you can fire that command multiple
times and then you have our containers
with no the manager and managed server
running inside each container and from
here you can go to the admin console and
say hey I want to create a closer now
with these servers but all the atoms
single host now I are on single host
because dr. does not offer networking
between containers on multiple hosts out
of the box there are many solutions out
there but none are stable none actually
work and broccoli still working on that
there is an experimental feature on one
dot eight but again we cannot certify an
experiment from the open source project
it has to be stable on an actual release
and then in front of that you can of
course use a load balancer now on the
continuous mode it's pretty cool because
you just have this image with all your
application other stuff deployed to this
domain and then you can fire many
containers for that application
so you're going to have one on your host
you're going to see one start with logic
and then you're going to say one started
logic and said run my application
startup logic you have three instances
of the same image that means you have
three jvms running enemy server the same
application all the Jane has resources
and that's why you can just put load
battles in front what you don't have
here failover because if I users
connected to the server and that
container pressures you're going to lose
that because there is no class ring but
if you want to certain or other
applications just go there and say my
weblogic app one and then you have a new
container running from a different image
since the containers don't have
communication between each other these
applications they can run on different
hosts because there's no failover
there's no communication between the
managed servers you cannot have
transaction being restored on the second
server it all what happens on in there
so you can have the same containers but
in different hosts and then you can go
to host one two and three and find the
containers and then can have load
balancing now it's odd because for many
years we've been documenting to weblogic
users do not put stuff on the admin
server and now we are saying well now
you can put stuff on the admin server as
long to run another on this way here on
a container and that should work fine
now how about data whether you store the
data now this is important the java
application server it has a bunch of
information binaries logs patches you're
going to patch stuff what are you going
to host that should i access the
container runtime and patch it know what
you're going to do is you're going to
either patch the image and shut down a
container the old one and start a new
one with the patch it with logic or
you're going to store the binaries on
somewhere else and then a patch that it
can maybe restart the container that
will grab the new binaries the Patrick
binaries so there are three ways that
you can save data from the logic running
containers you can have the container
zero here
with my domain your application weblogic
binaries everything inside the file
system off the container now this is our
color really you should really consider
these like stainless disposable
container whatever happens you just kill
it and you started you want you patch
the image and just use the new image but
if you want to if you want to have files
in some state you can use two approaches
one is the data volume on a container so
you have your one time on this container
here in a second container just holding
your data just holding your files for
example WebLogic domain files this means
that you can pick take these containers
and just shift them to a new physical
server it's more portable that way the
third way is the data volume on a host
environment that means all the files
will be hosted on the file system of the
host server you have a better
performance in terms of i/o if you do a
lot of I yo in this case but we don't
think that would impact much but still
the files will be hosted on the host
server and whenever you need to shift
stuff then you have to copy those files
to the physical server map the folder
again back to new container so if they
only have their pros and cons so what
about the issues yep
I'm sorry no you can you can have access
to the container the file system uses
that is there but when it's shut down
then you cannot you cannot get I think
there is a way to get access to it I
might be wrong now the data the data
stays on the container instance so they
do dr. PS you're going to see the
containers in there even the cute ones
so you're going to even experience to
have access this data volume and
container approach is actually designed
you're going to check that on the dr
cohn documentation that's a pattern that
they suggest so the issue that we found
during the certification process was one
the IP address changes when you restart
the container so that it's quite
problematic for a color straight
environment you have the servers
configured with our penises and we start
the admin server and the managed service
cannot find any more data mean server
because the IP has changed and that
happens my versa so the managed server
restarts the cluster doesn't know
anymore what the manager is so that's a
big problem for a cluster environment
because of the IP change thing there are
solutions for DNS you can run out dns
server but there might still have some
problems because sometimes the process
does a name resolution caches the IP
address and does not check the
resolution any more later it depends on
the whatever you're running inside and
the multicast support only in unicast so
you cannot do motok ass beat 20
containers now on the future like fuel
roadmap for darker and weblogic the
things that we want to take advantage
for running the application server on
this kind of environment is the multi
host board so it would be easier to have
a communication between the containers
between multi hosts and that's that
would we could be able for example to
create a virtual network to create a
virtual network with all those
containers from different hosts but they
think they are on the same network the
data volumes so there's a there's our
new feature to manage the data inside
containers so all those two those two
patterns there they they probably would
be still practical but it is better to
use the future they are working on data
model management and finally the
security so there are two reasons we
don't push the docker image of what
logic to get her to dr. hug one is
licensing and the second one is security
we cannot sign images yet there's no
feature for that so you can you don't
have you cannot have certainty if the
image your downloaded from dr. hub is
actually from Oracle so that would mean
you might end up without what logic with
some malicious code inside so the future
is of course as long as they become
available publish the images on docker
hub some integration in may then
optimize the size of the image and some
other products that the teams are
already working on so a suite enterprise
manager database all that and darker now
let me show you how does it work running
the application server on the docker
container so let's take a look at the
terminal here so I have some containers
running but they are all exited so what
I'm going to do is first moving talker
RM these containers here ok now I have a
clean environment I haven't some images
so i have my the weblogic image here i
have the installation image so this is
how you're going to use for budget on
docker you're going to create the image
of the weblogic installation environment
which means jdk in weblogic installed
but it's not a domain to create a domain
you have to define your image that
extends this image if you go to the
github project you can see then here you
go to samples and then you can check the
12 13 domain we already pushed the 12 to
one domain but I'm show you 12 13 you're
going to see the doctor file and the
doctor file extends from this image this
is the image that you should build
when you check out to get her project
and then there are settings like admin
password what's the port number for the
end mean what is the node manager port
what is your default manage to report
the jvm settings stuff like that and
then finally what is it default command
the difficult man will be start with
logic so what we can do here is dr. Ron
minus D my weblogic image start weblogic
and that gives me a container so now let
things back to this container and find
its IP address so this is the IP address
of this container now you can go to
Firefox and say hey give me the
container one and let's access weblogic
running and then you have the admin
server at least and it's the same same
weblogic as you know now we can come
here to servers and we can see that
there's no other server just the admin
server right so the for the
containerized a model what you do what
you can do here is deploy applications
on this weblogic environment and then
you can take a snapshot of this
container and say hey here's my
containerized application with your
blogger configure and the application
running we just spin off new containers
from that image or you can use web
project scripting tool and automate the
beauty process to deploy shared
libraries create data sources etc so
let's start new servers let's go to the
doctor run again and let's say rocky run
my weblogic image create server now
print server is a shell script that will
call a create machine server there's
another shell script that we published
on github as well you can check out the
code
but let's that let's do the cool stuff
server but SH and then you have a new
container running now this container
here as X axes it internally dash so
this container runs node manager and
it's not it hasn't started yet but it
will also run the managed server so
let's see how you are or better not
let's do with a su do
I've been experimenting using dr.
without root but it has been working
well
so let's remove the containers and start
at me again
so let's start the atom a server here
rocker 1 minus D my weblogic image start
weblogic ok that's got the IP address
that's a new container new add new
server
okay go to weblogic hostess and then
let's start dr. 1 minus TI I'm going to
do this one differently my logic image
creates river dart Sh let's want to see
what this script will do so there's a
lot of weblogic scripting tool behind
the scenes we connect Academy server oh
no host oh yes or about that so that was
our missing part here so the admin
server needs a name so let's do dr. 1
minus D my dash dash name louder that's
add me and then minus T for demon my lab
logic image and then start weblogic dot
sh ok now we are good and now I'm gonna
use my script or else I'm going to screw
up again the demonstration so let's go
to samples 12 13 can't read me and
here's a comment that I actually need to
fire this one so i'm going to link i'm
going to give a host inside the second
container with weblogic add me pointing
to the admin server running on the other
container now we have the right setup so
we have this one running
this is my project
and now we have the proper environment
so I'm sorry about that so this is the
machine that was added automatically
running the container so you see this
the same hash code of the container the
script weblogic script will use the host
name which by the four is the hash so I
can do in stock or inspect and get the
container that is running so this is a
create server so it's a machine one node
manager and managed server so what i can
do is i can fire a new command and
create a new container and then i can do
again and create new container it's a
one so what's going to happen I'm going
to have more machines add in here as
soon the script is called we have one
medicine already it's I've been running
on that container we have a second
machine now available from the second
container that I created it's reachable
and we have this second managed server
up and running and then from this point
you can create easily a cluster if you
want or you can actually go beyond and
with some weblogic scripting tool you
can actually do a dynamic closed room
you just find out more containers and
make more machines / managers available
as you want these topology where it's
fine we support on single host
environment because the DA current
limitation and if you want the single
host containerized application that's
pretty easy just go there and put
everything so if you want to check out
the script code for those those weblogic
scripts in 20 you're going to you can go
to 12 13 domain side samples and check
the container scripts and that gives you
an idea on worry what we do here but
again you can do all your own scripts so
it actually pretty neat they add servers
on using random code like just some
random name fridge add names get the
password from the environment connects
to the managed server yep set some
information from the minister
her stuff like that so this is this is
the approach for running weblogic on
containers and that's how we do it the
certification that's how you can run a
java application server as you would
expect with a domain model with
clustering on containers and hopefully
in the future we can do that on multi
host now to talk about hoes attend each
other's David to come up and cover the
new stuff that we have for kind of doing
the same thing in terms of isolation
because with dr. containers you can
isolate resources but with multi
Tennessee you don't need the containers
for coming from my pleasure everybody
it's three words portability density
isolation pretty similar to what what
you get out of using docker and that's
actually what we built into weblogic
server so the idea is it's very similar
we're solving the same problems we're
just solving them at a slightly higher
level so my name is Dave cabela's I'm a
product manager in the weblogic server
group we've spent about two years
working through this set of features i'm
going to talk about and i'm going to
talk about a month they're going to see
you're going to hear like wow they solve
a lot of the same problems they might
solve some additional problems they
might not solve some problems that
doctor was also that there's lots of
choices here right so we you know that's
part of what we're doing as a whole
group is we want to make it so you can
run you know our products the way you
the way they solve your problems in the
best way safe harbor statement so this
is you know this is kind of what I
started with right it's micro container
this thing it's a container within the
app server it gives me the ability to
move things around right so like a
container for portability density right
so I'm going to run multiple of these
things in a shared environment and a
shared and the shared WebLogic domain a
shared set of JVMs and then the last
thing is once I start putting these
things together I need isolation all
right
and we there's a lot going on there so
I'm going to I'm going to peel back the
onion just a little bit this slide I'm
showing just because I really like the
graphic more than anything it's it kind
of shows the general idea we're going to
take applications that had their
dedicated stack and let's take them take
the application some pieces of the
application that they need and capsulate
that into this pluggable partition or
micro container we're using some
terminology entertain interchangeably
there but the idea is let's you know
portability density isolation so this is
this is what it looks like when we start
to think about how does it look like
within a single JVM so the grey box on
the screen here is meant to you know
indicate a single managed server a
single JVM however you want to look at
it with in that single JVM I've got two
pluggable partitions running within each
of those plug aboard pluggable
partitions there's an application might
have multiple modules it's got you know
its own set of system resources set up
like a JMS configuration data source
configuration within that partition
there's also a dedicated naming service
so i think i've got a dedicated jndi
tree what happens within that partition
stays within that partition it's kind of
like Vegas right so when my application
is looking for a resource it's not going
to look across and see something else
it's only going to see what's within
this partition we think about the
dressing things we talked about IP
addresses changing and so forth with
with these micro containers in weblogic
server you actually define the
addressing how things are going to get
to this partition anything we call a
virtual target it's a lot like a virtual
host you can give it you know a hostname
you can give it a port you can give it a
URI prefix a bunch of other things you
can do there but the idea is how do I
get to this application where it's
running and that remains consistent
right so you know it's easy to keep this
addressing we've also built in
integration into Oracle traffic director
which is a software load balancer thank
layer 7 software load balancer so when
you add one of these partitions into
weblogic server we automatically update
the web tier to say this is how you get
to this thing if you unplug one of these
from one environment plug it into
another we also
update the the food web tier for you so
I think of it as a micro container
gateway already keeps track of where
things are with the with microservices
you think of an API gateway well this is
kind of same idea but it's my service is
a little bit bigger than just an API
it's a service and you know we just want
to make that very easy to get to things
don't change thinking about isolation
data isolation specifically natural
affinity with oracle 12c database
pluggable databases there's no need to
run a pluggable database but it just
kind of makes sense right try to get the
best efficiency at all the different
layers within this platform so but you
can run no SQL you can run mysql we
don't really care at all it all works
and then of course there's an
integration with coherence in this also
so if you need if your application needs
a coherence cash we actually share the
code coherence cluster but for each
partition we spin up a dedicated cash
service so that means you know ok I get
the best density but I get the isolated
data as well so it's a pretty nice
end-to-end story you can focus on the
middle tier that's where that's kind of
where I live but it's really it's a it's
a nice end to end story so what is what
are these micro containers give us right
supportability I kind of started with
this they are an encapsulation of that
application plus the system resources
that it needs so it's like it's not as
big of a container as you would think of
for docker right it doesn't go all the
way down to pieces of the operating
system does not include a JVM does not
include additional pieces of the app
server right it's just the application
and the stuff that the application needs
to run in a Java EE environment right
then you can so if you think you know
this this picture shows the model might
be my developer develops application in
the same type of environment but does it
in a partition then exports that
partition I get a zip file and a JSON
arc a JSON file that goes with it I then
want to move that to unit user
acceptance testing I import that during
that import it could be immutable right
I can just use the way it is and import
it that way and then or that JSON file
exposes all the different attributes
that can be changed right configuration
attributes for the port for the
partition itself as well as for the
stuff that's in the partition could be a
different deployment plan could be a
different URL for the data source which
kind of makes sense but so you get lots
of options there right and then this
becomes also a way to move to cloud
right so if you're running say you're
running weblogic and Amazon Web Services
maybe that's where you do your
development those were you do your
testing right it's easy to encapsulate
this move it to the cloud maybe from
testing you'll move it back on premise
for production lots of flexibility there
and lots of cloud enablement as part of
this so that's the portability factor
sure go ahead no so the question is each
partition will have its own admin
servers no so what we're doing is we're
actually sharing a WebLogic domain so
the domain has an admin server in the
domain you can set up one or more
managed servers you can set up one or
more clusters and then you would share
those clusters so you'd have multiples
of these partitions running in the same
set of JVMs so think you know what I had
before I might have had a two node
cluster dedicated to a single
application now I might have a two node
cluster and I'm going to run five
applications in that but within those
I've got isolation between them so they
don't stomp on each other and I'm going
to talk about the isolation factors next
but so it said we're going to sharing
the platform the platform is the admins
think of the domain as the shared a
WebLogic domain as the shared
infrastructure so isolation so there are
four flavors of isolation I've already
talked about the traffic and data
isolation already the next one the top
one is the runtime isolation so this is
where we actually partnered with the the
java jdk team as we were designing this
whole infrastructure it became really
clear from customer feedback more than
anything that there was no way we're
going to be able to put multiple
applications together without providing
some level of isolation for OS and JVM
resources so think he thinks CPU time
open file descriptors was another one
that came up as a really important piece
here so we partnered with the JVM team
the JVM keeps track of those three
resources
right retained heap CPU time and open
file descriptors for each of these
pluggable partitions while they're
running and then at the weblogic tier we
can set or you as an administrator can
set policies let's say ok when this
partition uses more than X amount of
heap take some action and there are a
couple of different actions we can take
one is we notify the administrators we
write to to the server log or we can
slow down a partition and the way we do
that is we actually deep prioritize all
of the requests so it's still a single
shared request pool single shared thread
pool for weblogic right it's all
asynchronously handled so for a
particular partition we actually slam on
the brakes right we say we're going to
deprioritize by ninety percent so we
really slow things down the idea is ok
let's stop this partition from harming
the other partitions running in the same
jvm the last action there would be a
stop action itself so within a JVM I can
stop one of these partitions so if I got
five of them I would just stop the one
partition would not affect anything else
right so that's runtime isolation the
next is security isolation so for each
of these pluggable partitions you can
have a separate security configuration
second separate security realm that
means a different authentication
provider different authorization
provider different credential map or
different set of users right so
different you know a completely
different security configuration users
also means administrators which is kind
of a nice segue to the administrative
isolation so I can have a different set
of people each you can have
administrators that are autonomously
administering this pluggable partition
so I can come in I can start it on its
own i can stop it on its own I can make
I can change the configuration I can
deploy applications in it it's all
independent of each other right so it's
so think administrative isolation why
would people have dedicated a you know a
set of VMs before for this while I need
to update at a certain time or I need to
start and stop independently so that's
all provided and I've already talked
about the traffic and data isolation so
I I wanted to dig down I actually kind
of gone through this a little bit
talking but i'll show you this sun on
the screen so this is
notion of the resource consumption
managers this is the partnership we had
with the we still have with the jvm team
this is where you can set up these
different triggers right so on this
example I'm showing a notify trigger at
one of the quarter gigabytes roughly
roughly one-and-a-half gigabytes we take
a slow action and the two gigabytes we'd
say okay that's enough you know we're
going to stop this one it will tell you
that this requires g1 garbage collection
and our internal benchmarking has been
phenomenal with g1 garbage collection
it's uh and I so a couple other sessions
I had this week I had other people come
up to me and say we're using it now and
really getting good results with it
seems to be really efficient in the way
that it handles especially young GC
stuff rights it's a it's able to stay
within its halls time goals and keep
things weren't running really well go
ahead question
right so the question was is this this
is only on memory or does it also CPU
and other resources right so there we
also do CPU time so heap seems to be the
one that everyone wants to know about so
that's what my slide talks about more
than anything but CPU time we also keep
track of / partition and then the next
one is open file descriptors so that was
one that you know was sort of a little
bit of a surprise to me but we heard
from administrators like hey this is you
know we see my apps run into this
problem frequently so if you can track
that one for me too we're looking at
other things we're looking at some
additional analysis tools building into
this we're also looking at providing
information in thread dumps and heap
dumps and also in flight recorder so
you're the events coming out of the JVM
into flight recorder would also include
right now right now it does include like
a consumer ID it's called but we want to
make it very clear what that is you can
map a consumer ID to a partition at the
weblogic layer we want to take away the
work there go ahead question
so the question is are each of these
micro containers completely isolated or
can they share some resources so the
short answer is they're completely
isolated we actually looked at providing
say a shared data source and then be
able to switch that data source to you
know depending on what the context was
who was asking for the connection we
could switch to a different pluggable
database we found the performance of
that which is really not working out so
well so it's not off the table we're
still looking at that but in general
it's these like these things are are
isolated I'll tell you one other thing
too that might be interesting related to
that is class loading so there's a
single class load some single system
class loader but then there's a branch
for each of these partitions it's fully
transparent to applications if you just
deploy them but if you have a situation
where you want to run the same
application multiple times and you know
you've got certain classes that are
shareable you can actually define them
in a deployment descriptor just as
shareable and then across your whole
environment you'd only load them one
time so there's there it's kind of
rocket science stuff built in to say yes
you can do some things that are pretty
advanced the easy stuff is easy though
it doesn't get it it's you know I'm
deploying an application there's nothing
else I need to do here that's great from
a density perspective so what we're
seeing is when we took when we start to
use this micro container stuff we start
to say now i'm going to put stuff
together what you know what's the
benefit so if i take a pretty standard
piece of hardware an HP dl380 16-core
box with 256 gigabytes of ram i think i
can run roughly 10 applications on that
and that's with over subscribing with
VMs on a three or four to one basis on
the cpu heap there's plenty of heat but
let's say two gigabyte heaps here I've
got four node I've got four node cluster
setup for each of these so I'm running
10 individual domains that's what's on
the left side right so big grey box is
meant to be a server right then on the
right I say let's let's put these into
micro containers so I put so I have 10
of these micro containers running in a
single in a single domain
and then when we actually run this to
see what happens we're actually able to
get three times the number of
applications running on the same piece
of hardware all right so even though I
put 10 applications together and so
sometimes people talk about like a 10x
consolidation you know the real ID the
real thing is under the covers it's
about a two-third savings and hardware
your mileage will vary I'm sure based on
what your application looks like what it
does and so forth but this is it's
pretty significant from from a numbers
perspective it's kind of I know it's a
little bit of an eye chart but the idea
is that when we ran this stuff together
we saw two and a half times less CPU
usage and then for a memory footprint we
saw three and a half times less memory
usage and so we were actually meant
measured the footprint of the JVM on the
operating system so we didn't just look
at heap we actually went down and said
what is the footprint of the JVM on the
operating system and we went from about
a gigabyte per each of those many server
VMS to almost three gigabytes for each
of the managed server VMs but I'm
running 10 apps in them so it's a it's a
pretty big difference we also did if you
can look here the the first row that has
any data and it tells you our JVM
settings so in our you know that in the
separate tests we set our max he back
two gigabytes in our combined test we
set our max gig at two gigabytes also
and we didn't see any reduction in
throughput we didn't see any reduction
in response times so as we as I push
this further when we got it to like 13
14 15 that's when we started to see you
know reduction in throughput time that
sort of thing question all right
it still runs for the whole JVM so the
question is is there an independent
garbage collection for each of these
micro containers no it's still a single
still a single JVM it's still a single
garbage collector that's a it's a very
commonly asked question and actually
we've been talking with the JVM team
saying is there something we could do
here is there some way we could actually
do this the problem is you know in the
regions where we r memory gets set up a
lot of times there's cross dependencies
between those things so for us to do a
real garbage collection / partition it's
pretty challenging so what we're seeing
though with with the g1 garbage
collection so we ran this for a couple
of days hitting it with constant load
and we didn't see a full garbage
collection during that whole time
because the young GC really really
behaves very well and g1 garbage
collection now like again your mileage
will vary right if you've got an
application that grabs the memory holds
it for a very long time then that's
going to end up in something you know
what I call the old generation and then
that would that might trigger a garbage
collection to get collected when you
when you close that so but I've been
like thrilled with this stuff it's been
really good how we doing timewise five
minutes okay okay so this is you know
I'm kind of at the end of the regular
content that i wanted to show so this is
a sort of a summary and again sort of
like this graphic and i will admit that
i stole it from the database team just
kind of modified it to make it work for
me but the idea is again portability so
you get this micro container to move
things around density I can put a lot of
them together and then of course you
need the isolation to make them work I
can show you a quick like export-import
if we want to do something like that
like I can move from one to another or
we just take questions
so the question is have you done any
enhancements to monitoring to make this
more monitor all with a in a more dense
environment we're going to have
different things and not just run an
enterprise manager so absolutely so
first of all there it is still a single
server so there's still a single server
log but in each of the those servers
each entry includes an identifier for
the partition so you know what you know
where all these things are coming from
and there's actually even a SS T command
to get you to generate a separate server
log so if you if you're autonomously
managing these things and I say here's
your partition and you're saying you're
seeing an issue call me up and I say
yeah I'll give you your server log and I
can email it to you right so I mean
it'sit's it comes out as a log file when
you're done at the end there are some
things that are naturally segregated
like JMS server has its own log because
you know you're isolated or ready to get
that web access its separate or ready
then we also changed the mbean
infrastructure so for each of these
pluggable partitions there there's a a
child mbean of the domain mbean for
configuration and then there's a child n
mean of each server where it's running
for the runtime mbean perspective and
then of that there a child and means
again right so your data source would
have a runtime mbean that's a child in
this your application runtime would be a
child of that partition so you get all
that access and it's separable right so
you can say you know admin one can only
see this I've been to can only see that
so you can also set debug flags /
partition lets one they kind of I forget
about frequently but it's the idea is it
needs to be manageable yep
right I don't think we've done the work
on that yet but
it's 50 so doctor the doctor more the
container model the tennis model they
all have their problem cause one is we
like hate is here's the image just
running right on the multi cabinets you
still need in traditional age our
projects son of the domain on your
progeny moment somebody to that and then
the development team will provide the
zip propecia because I hey import
institution on your environment the
doctor Margo it's like a pole for charts
theorize operating system with the water
installed already so they ops team
doesn't even know what's inside come
here they just fired up in it now the
multi can model it gives more control on
own resources for the ops team so it
really depends on what Koecher what what
what architecture what you need to have
I think we did a pretty good job in
providing more options here on how to
specifically but again it's more up to
you to decide which one to save
resources
alright what's your priority where what
are your cost structures right could be
that yep yep other questions yep go
ahead
which is running
I think it would depend on what on the
agent itself right i mean this isn't
this isn't coming from from us but wiley
enter scope what's so the neurotic agent
for example what it does when i put in
iran engagement of their the classpath
of the video and but still your
application needs to access the new one
of the API to get lead and then sent to
something relics early suppose that
information so you would probably end up
making the new relic agent available to
all partitions you would depend on which
application will be using the agent to
get information or what kind of
information wants to provide that you
would put right on everywhere but i
think it would be possible to put me on
an agent on on your application directly
I've seen people to find agent along
with the application my commodity so
that's also possible so when you just
need
make sure that two applications and that
doesn't it doesn't even matter if it's
all like that or not if the two agents
running st. DVM they have some sightings
of my scrubs we have to make sure they
are but I think it's possible it's more
up to demonic agent Markham impatient
now
yeah I think it's something to check out
there it's more like we find that what
options again discipline the doctor we
can also find all the models with
daughter I think the erotic on Mt we
checked how it can take it happen on
them cheaper we want we can go any
further already ran out of time no one
tries to that but if you guys want have
some person to get a conscience here so
I thank you very much that's right</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>