<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Three Key Concepts for Understanding JSR 352: Batch Applications for the Java Platform | Coder Coacher - Coaching Coders</title><meta content="Three Key Concepts for Understanding JSR 352: Batch Applications for the Java Platform - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Three Key Concepts for Understanding JSR 352: Batch Applications for the Java Platform</b></h2><h5 class="post__date">2015-06-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/XmcUN2SdYXE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so today what we're going to talk about
are you know essentially three concepts
around jsr 352 or batch applications for
the Java platform so Tim Fanelli was
about that right my schedule back up is
for 11:30 so Tim Fanelli was supposed to
give this presentation but unfortunately
yesterday he had problems with the air
traffic control missed his flight to San
Francisco so instead of Tim presenting
it's actually myself Brian Martin
so I'm chief architect of what's your
extreme scale which is our in memory
data grid product and previously was one
of the lead architects for the WebSphere
application server also had a product in
IBM called Webster XD which included a
batch the you know the batch components
which made it into websphere application
server after a bit of time while I was
leading the Webster XD product person
that worked for me Crispin OA was
leading the batch effort and was a
member of the jsr 352 expert group so
you know today I'm gonna be taking it to
Tim slides and I'm gonna also attempt to
run Tim's demo life so hopefully that
works out for me one thing I did notice
right before when I was looking at the
presentation it seems like Tim likes to
use lots of slide transitions and that
might trip me up a little bit but we'll
see how it goes
so you know essentially we want to talk
about the background of around java
batch the three concepts implementation
orchestration execution will go through
a sample application its illustrates the
basic concepts and then in the end we'll
talk about some of the advanced topics
so you know batch processing you know
this is you know one of the oldest
processing paradigms for computing
you know very historically associated
with mainframe computing you know Tim is
part of our Z team out of New York but
this is you know still wrote incredibly
relevant today you know businesses
operate and batch you know for example
if you know Amazon doesn't order a book
as one at a time from their suppliers
they order you know batches of books
they process a bunch of inventory as a
batch and then they start you know
shipping out batches of or individual
books to consumers you know that's this
one example you know telephone records
everything you know lots of different
types of data are processed in batches
so you know what about Java for batch
processing
so I guess traditionally we've seen you
know mainframe developers are shying
away from Java in the past on the other
hand we don't see a lot of new you know
COBOL developers coming out of college
so you know something needs to change
here because we're going to need to
continue to do batch processing it's not
going to be done in the traditional way
so you know we've kind of had this you
know skills get skill set gap between
people who are doing batch programming
in COBOL traditionally today or other
mainframe languages and then you know
the Java programmers so you know of
course Java and Java EE have dominated
the OLTP world but you know we need it's
time to bring the two together and so
you know there have been several
different efforts that have kind of led
to this jsr 352 one is you know within
web seer we we did a batch framework
spring batch also did you know a very
successful batch framework so what we're
talking about with this jsr is that you
know all these different communities
have come together standardize on a on a
batch programming framework both for
java SE and for java ee
so permits covered that you know the the
expert group was formed back in the late
part of 2011 had lots of participants
including uh you know IBM VMware Red Hat
Oracle Credit Suisse and some others and
essentially you know the final release
of the specification was back in May and
this is what I'm talking about with the
transitions it's now part of Java EE 7
so you know what three concepts are we
talking about essentially the three main
things defined by the jsr implementation
in other words a programming model for
actually implementing the artifacts that
you need as part of your batch
processing an orchestration layer and
this is essentially a job specification
language to JSL which can orchestrate
these various jobs job steps together to
perform your boss best job and then of
course an execution environment you know
an actual runtime environment to run the
artifacts and use the orchestration
language to bring it all together
so this slide starts to introduce some
of the key concepts so we see you know a
job repository a job operator jobs which
are composed of steps steps can have
either Bachelet sorr chunks chunks have
readers processors and writers and I'll
take you through these concepts in more
detail right now so essentially you know
chunks and bachelorettes provide the
programming model for implementing a
step within your batch job so the
context provide job at step level
runtime information and provide interim
data persistence that your chunk or
Bachelet may need as it's doing its
processing there's also a concept of
listeners within the framework so you
can plug listeners in to respond to
various lifecycle events as there
so that you can get kind of an external
view of how your your best job is
processing or proceeding and also
includes partitioning capabilities so
that we can partition up our batch job
and run it in parallel so let's now talk
about chunks versus batch words so the
trunk model is kind of the standard
encapsulation of a an ETL extract
transform load kind of pattern so you
have a reader you have a processor and
then you have a writer in the middle or
at the end so essentially what happens
is the reader processor loop is invoked
repeatedly until you build up a chunk of
data then the chunk of data is written
out to the writer atomically to you know
whatever output source that writer
defines the Bachelet step is kind of an
all-in-one step so the job the execution
one-time environment will invoke the
Bachelet and it essentially does all the
processing however it sees fit so you're
not forced into this reader processor
writer separation which has lots of
advantages in terms of composing your
job steps but if you want to implement
something kind of all self-contained you
can do that with the Bachelet the next
thing I want to talk about is
orchestration specifically the JSL so
the JSL is currently defined you know as
an XML document the XML document is
going to contain basically assembly of
all your job steps and how to group them
together and how to sequence them to
actually perform your but your best job
okay
so the job operator repository
essentially the job operator interface
is the one that you can use program met
programmatically to start job stop jobs
restart jobs you know find out about the
execution status of jobs and then the
job repository is in the database
essentially to store information about
the jobs and their execution so here
this picture puts it all together and as
I was really reviewing this picture
right before the presentation I realized
it's got an error in it this should be
there should be a star here because jobs
can have many steps but this kind of
shows the relationships between all the
the parts of the system so essentially
what you know once you submit a job you
you create a job instance within the job
repository and then once that job
executes it has job execution records
that are created so we can submit you
know one job create an instance of that
job within the job repository and then
we can continuously execute it over and
over again and we're generating new job
execution records additionally as the
steps execute within a job execution we
get step execution records also in the
database so now we're going to kind of
step through a sample application to see
you know how this all pulls together so
you know essentially this application is
you know your typical kind of batch
hello world app so a very simple app
that's going to read strings from an
input file perform some simple
operations on their strings and then
write this transformed output out to the
output file you know some of the key
capabilities that we want to be provided
by a batch train work you know if
something goes wrong we want to be able
to restart where we were before so the
the runtime container or the execution
environment for this batch job needs to
provide checkpointing capabilities and
so we'll see how that works
of course we want to control the
transactions copings so that we can you
know lessen the amount of commits that
we do to a back-end database and another
thing is you know we want to have
flexibility a plug-and-play where our
records are coming from and where
they're going to so this is how we can
use the composability of that reader
processor writer paradigm to you know
essentially change the input source or
the output source dynamically
particularly useful you know in your
testing environment so in this
particular sample was going to use the
programming model which i think is
probably the one that most people would
use as i mentioned before and it capsule
AIT's the the ETL pattern and we pick up
the checkpoint and capability from the
container itself and so let's see can we
actually see the code in the slide it
doesn't look like it so maybe I can show
the code coming up here in a little bit
but essentially what this is is the item
reader it's going to access the file
read in a given record and then make it
available for the item processor there's
really no restriction on the types of
item readers that you can create here so
you know this one is reading from a file
but it could be you know using JDBC it
could use a JPA hibernate spring data
whatever however you want to get data
into your Ida meter the checkpoint
restart data is actually provided as a
serializable argument to the open and
checkpoint info methods so essentially
when your reader gets invoked it can be
provided with this checkpoint object if
it if you are provided with the
checkpoint object then you need to kind
of you know scoot forward in your data
stream to where that checkpoint info
object is indicating the checkpoint info
method is a method that you provide to
essentially give back to the container
periodically is to indicate where you
are in the stream so that if it later
has to checkpoint it provides that same
object back to you
so that you know where to restart so
this is the item writer essentially you
know this is the companion to your
reader
it's basically and get a chunk of write
items as a list and then you're gonna
send those out to an output source
whether that's a database a file you
know whatever is going to be in your
particular job step then finally the
last part is the item price processor
itself pretty simple again here you know
you get invoked with a given record you
process it and then make it available in
the later stage to the writer there's
actually a sample main in here which I
don't think we can actually read on this
particular projector but it shows
actually using the job manager to start
a job so we can take a look at that
coming up here so then here is an
example of the actual job JSL so we can
see our given job let's see I'm not sure
how readable this is but you can see
here is the reader part of the the
specification is that you know a set of
properties can be passed into your
reader so that you can configure the
reader to have different characteristics
or different inputs so in this
particular case we're pointing out a
dictionary of words on a in the share
for the dictionary app and then we have
the processor in this particular case
our processor is not using any input
properties and then we have the writer
we say we want the output to go to this
temporary file
so you know you can you can patch it you
can package all these artifacts as a
standard jar or war file for deployment
and you know either a java SE e or ee
environment your batch xml would
typically go in your meta F or your web
of classes matter if directory your JSL
can go into your match jobs directory or
you can just kind of you can dynamically
submit that into the job operator
interface so let's go ahead and try out
the demo here and see what happens
so I think in this case we can actually
see the code a lot better so we can talk
about this so this is a simple processor
as you can see it's got the process item
method which takes the single argument
from the from the reader in this
particular case all it's doing is really
putting it in a string buffer and then
reversing it
so we're just taking the input you know
whatever input string that we're getting
in this particular case and we're
reversing it you know that reverse
string will be passed along to the
string writer so if we look at our
string reader also you know very simple
essentially it's using a you know a file
reader meaning through the file line at
a time and it's updating the line number
as it goes well in this case you can see
that you know if we got past a check
point information which a check point
info which would have been that case
that you know our batch job was stopped
now we need to restart at our last check
point we're checking you know that's not
null if it was not null it's actually
the line number and I'll show you above
here where we define that and then we
just read forward until we get to that
line up here you can see an under check
point info we actually return
the current line number that we're on
and then as we're doing reading items
we're simply you know incriminating our
our line number to maintain our current
place in the stream and we're reading a
line and returning it the final part of
this simple example is the writer itself
and you know essentially it also has the
same check pointing capability and we
see that it gets basically past a list
of objects which in our case as you know
our lines or strings and we write those
out to a file so if we try this out it
should hopefully work you see it
printing out all the the names from the
dictionary and we got to the end of our
batch job we're gonna put the new file
out in slash temp right there let me see
that you know we have all the words now
reversed so pretty simple example but
kind of shows you know the basic
interfaces are very simple in terms of
having a reader or process and writer
and then of course you implement the
complexity in terms of you know your
input data sources the processing that
you need to do within the processing
step and then you know where you're
going to output it in your writing step
if we take a look at the
let's take a look at the best job itself
so here's it probably a an easier to
read version of the batch job which
shows you know essentially the the
properties that were passing into the
reader it's simple in this case we're
just giving it a path to a given file
and the property from the writer which
is the outputs final location but you
see also this job is you know pretty
simple and that we've only got a single
step but we could have you know multiple
steps as well so for example here this
is a actually this is a partition job
it shows example of how we can apply
automatic partitioning and well we'll
get to that here in a second and then
here's a parallel job which has some
splits and flows with additional steps
as well
so let me continue on here
so you know had something gone wrong
what then so you know this was a pretty
simple example it really only started
the job and I think actually I didn't
show that so let me pull that up if we
go back to our main class you see that
essentially as the job operator we go to
the batch one time we get the job
operator singleton we're deciding which
type of batch job we want to start so we
used the sample batch job and then we
get a job execution record for that by
getting you know after we after we
started it then we can get the job
execution record and then we can wait
for it to be completed and that was it
so it was a very simple example of using
the job operator interface
so as I mentioned before the job
operator exposes you know api's for
simple tasks such as start/stop abandon
restart and to see the status of your
best jobs the door is kind of left open
within the specification for more
advanced batch job management systems to
be built so for example you know
integrate into your existing enterprise
schedulers perhaps in the future there
might be another standard around batch
scheduling where we have more advanced
back batch scheduling that's a standard
part of the platform but as state here
there's plenty of options but it's
currently left to the provider to kind
of implement a more advanced operations
interface and scheduling interface for
an end user the basic API is very simple
you know start stop restart abandon get
information about the execution status
you can certainly imagine that platform
vendors will have more advanced
scheduling capabilities and other
capabilities exposed as well so you know
jsr 352 is included in Java EE 7 so you
know once we're in the EE container we
now get advantage of clustering we get
advantage of the Java EE security
resource management and other things now
available to your to your Java batch
applications this is essentially stating
that you know of course there's a
performance benefit when you dispatch
into long-running containers because you
know you get your Java code jaded and
you know stage it it and run faster and
faster over time as the JIT optimizer
makes additional enhancements to the
jitter code so the next thing I want to
talk about is parallel job processing so
the specification within the JSL also
imput introduces a concept of what it
calls splits and flows for executing job
steps concurrently at the registration
later
so a flow is a sequence of one or more
steps which execute sequentially but as
a single unit
so everything within a flow you know
there's step step step that's all needs
to be executed sequentially one after
the other a split is a collection of
flows that may execute concurrently so
we can have you know two or three or
more splits each composed of one or more
steps and then these splits can execute
concurrently at the same time as it
states here a split may only contain
flows a step is not implicitly a flow on
its own and as it's pointed out here
that you know that you really are doing
this all within the context of the JSL
so it's nothing that you only had to
code from a coding perspective you just
simply focus on coding you know the
readers the processors the writers and
composing those into multiple steps or
you know the input from one step make or
the output from one step is typically
the input from the next step and so on
and then you can start composing them
together making them parallel as
possible using the JSL so that's one
type of parallelism the second type of
parallelism that you can achieve within
the JSL is of step level partitioning so
this is where you know we can partition
our input data source and then run that
in parallel across you know multiple
different instances of the of the steps
or the job the processors so essentially
a partition step runs with multiple
instances each having their own distinct
property sets so for example if we think
about our file case we can easily
partition a file into let's say we have
five files so we can run those five
files independently the partition mapper
is another interface within the system
that you can define to just to set the
number of partitions for a given job
execution and so that can either be
kind of a thick-set you defined within
the JSL or you can have a dynamic
implementation of the partition mapper
so this is once again an unreadable
version of the slides let me switch back
to eclipse where we can see this in
detail so if we look at this kind of
partition model here we can see that in
this particular case based on the
partition plan each chunk reader is
going to be essentially passed its own
file name to to execute and likewise
each chunk miner is going to be passed
its own output filename so these are
kind of dynamic inserts coming from the
partition mapper so we have down here
the partition mapper which is providing
or providing some input properties to
that so if we go look at our partition
mapper implementation
once again this is kind of a simple
example but what it's doing is creating
a partition plan based on looking at a
particular directory with state how many
files do we have in that directory and
creating essentially a partition for
each file so this way you know
dynamically we can see well we have
we'll say 20 files we can partition this
batch job up into 20 partitions and run
20 in parallel so this is kind of the
simple example of partitioning I think
you could also imagine depending on your
dataset might be possible to take you
know one input file and then use a
partition mapper to break that file up
into multiple sets or if we're talking
about databases you can have different
ranges of Records and stuff that you're
going to process so the flexibility is
growing here within the partition mapper
for you to define how you can break up
your input data source to run it in
parallel and then you know we talked
about the splits and flows as well
let me also point out another thing
which I think we hadn't talked about so
checkpoint policy there is essentially
you know two different types of
checkpointing policy that are built in
by the runtime there's an item based
checkpoint policy which is the default
and essentially this is about you know
how many items do we run through before
we checkpoint so in this particular case
you know we're going to do 10,000 reads
before we checkpoint these the other
option that you have for checkpoint
policy is a time-based checkpoint so you
can run for a certain amount of seconds
so in this case you know if we change
this to time we have configure a
checkpoint time period in seconds so we
see a split here we have a split called
a document split does this have it
doesn't seem like his example has a
second split so we only have one split
here we have two flows the first flow
which is step ID 1 and then the second
flow which has a second step so he's
just running this through a multiple
transformations of string processing
okay
okay so now we're mice to the end which
is a looks like we're gonna end early
but that's probably okay because we can
all go to lunch so this is kind of like
you know the oldest new thing in Java
you know batch processing has been
around for a long time as we talked
about jsr 352 now defines you know a
standard abstraction that you can use to
create these batch programs we can
efficiently execute these on distributed
platforms or all main mainframe
platforms you know whatever you choose
to run the execution in many cases I
think we'll still see a lot of batch
processing occurring on mainframe
systems where we have those systems of
record and you want to have very quick
fast access to that data resident right
on the system you know having a standard
programming model now provides
application developers with vendor
portability so if you're not happy with
IBM you can go to to Oracle or to spring
the other thing is that I think having a
common programming model like this
really you know allows us to build a
community around batch programmers so
you know as within your enterprises as
you're looking for people to do java
batch programs now that we have a
standard you know we'll actually start
building communities of developers who
are experts in building out batch
applications and you know that's going
to be good because there's COBOL
programmers are becoming harder and
harder to find and you know including it
in Java EE 7 of course is ensuring that
it will be available widely and any
questions apologize that that the
original speaker wasn't present for the
presentation hopefully I did an ok job
at presenting his content yes
question here
right so I don't know for sure but I
think we can look at the interface here
and you know this the reader interface
is actually read item returning a single
object so you know while technically you
could return an array as an object you
know an object an array is an object as
well I think the interface signature
pretty much indicates that it would have
to be one at a time yes so that would be
up to the the actual execution or the
batch runtime environment but
essentially what will happen is that you
know you can restart your job and let's
say we're in the reader here what will
happen is this checkpoint info object
which is a thing that you control so in
this particular reader you know we're
actually just using the line number as
the checkpoint in for information so
essentially you're your reader will be
invoked with that checkpoint information
and then that's where you need your
readers needs to recover back to that
point and then start processing again at
the last checkpoint checkpoint
information could be anything yeah it's
up to your reader in this particular
case we've returned an integer but that
could be you know whatever I did a
database key you know whatever you need
it to be in your particular application
and then the container is just
remembering that object so it knows like
where the last point was that we were
checkpointing so that if we have to stop
and restart every putt returns that same
old checkpoint yes
yeah so that's that's a good point I
don't know specifically the work that's
gone on recently with jsr 352 and
scheduling but I do know previously in
the work that we did with IBM's batch we
were integrating that with other
schedulers like the Tivoli workload
schedule so I'm assuming that there is a
lot of work underway to especially now
that we have a standard that makes it
even easier for people like control them
and others to implement to the standard
and provide an enhanced scheduler up on
top exactly yeah yeah I agree and I
think I think that's another benefit to
having the standard API there's that the
scheduling vendors now have a standard
that they can write to to build to come
to the next level level up of enterprise
scheduling keep it going like you're
talking about
sure
so there is some capability for
annotating your readers and writers as
well but I think essentially the JSL is
providing capability to composes various
pieces together in flexible ways which
you know if you use the annotations you
would be basically limited to a single
way to use that particular item because
you can't embed multiple yeah another
question using open-source tools so
that's a good question I don't know I
mean I've heard a lot about courts from
a scheduling perspective but I
personally haven't used it and know a
lot about its capabilities being with
IBM I would try to steer you towards one
of our scheduling solutions but courts
might be an answer there yeah
yeah so as I mentioned before because I
haven't been completely immersed in the
space I don't know all the the
integrations that are occurring I know
that in the past we were working with
Tivoli workload scheduler IBM also made
an acquisition about a year and a half
ago of a company called platform
computing which also has a scheduling
product so there may be some integration
going on with their scheduling product
as well but I haven't been tied into
this work in particular oh another
question yes so that you know the Java
SCE version of this or the reference
implementation does not but you know as
it's integrated into Java EE yes so the
clustered implementations within you
know WebSphere and in WebLogic and
others will spring batch will include
clustering yes
so the question is what about oh well to
OLTP and batch in the same container
certainly as possible I don't think I
would necessarily recommend it I think I
would probably keep a separate container
for running my batch jobs independent
from OLTP containers you know I can
reuse a lot of the same assets of course
but you know I like to not be called all
the weekends so I would keep things
separate myself yes okay yeah that that
would be the job operator or that yeah
yeah let's see if we can go back so in a
clustered environment you know this uh
I'm into this job repository is going to
have to be you know accessible from all
the members all the customers so that's
going to be and then you know the job
operator is going to be in charge of
actually dispatching the different in
case you have parallel parallel
execution they can dispatch those on the
various cluster members control they're
executing and where they are checkpoint
wise and then potentially restart them
for example if that customer fails that
can restart at the last checkpoint on
another cluster member yes
yes yes are they so this I think they're
for a chunk I think that's a that's a
good question I shouldn't apologize and
I have to get back to you right yeah
right yeah it's it if you think about it
it really will have to be the chunk
because you have the reader the
processor in the writer and the writer
is basically generating the output for
the next step
typically so that's someone gonna be at
a hunk level that is kind of it as an
input available for the next write the
holes the whole sequence you're saying
the whole set of steps
yeah I mean that that makes sense I
wasn't part of the expert group so I
can't comment in detail on that
okay okay essentially let's go here you
can kind of see it on the picture here
so if we use chunk the chunked interface
you're essentially get to use these
three parts the reader the processor in
the writer so it defines this kind of
programming model of composing the
extract transform load model ETL model
if you don't want to use that kind of
processing model you can just implement
a step as a Bachelet and that Bachelet
essentially says you know process the
whole step and give me the output so
it's like roll-your-own essentially so
you don't have to follow it maybe this
is the answer to your problem
essentially you know you could implement
your stuff as batch what's right
I'm assuming it will but if you come and
give me your email address afterwards
I'll forward your question on to the the
IBM expert who really knows the answer
to that rather than me speculate is that
all so like you once again sorry that
the original presenter didn't make it
that's you know how air traffic works
sometimes but thanks for everyone's
attention and have a good rest of the
day</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>