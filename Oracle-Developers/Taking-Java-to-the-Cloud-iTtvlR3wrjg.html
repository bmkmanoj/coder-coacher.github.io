<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Taking Java to the Cloud | Coder Coacher - Coaching Coders</title><meta content="Taking Java to the Cloud - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Taking Java to the Cloud</b></h2><h5 class="post__date">2015-06-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/iTtvlR3wrjg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">a little bit about myself first my
name's Nigel Daniels so thanks for
coming to listen to me I'm worked in the
tech industry for too many years in
various different capacities all sorts
of wide-ranging products quite a while
with IBM which led me into doing product
management so i went from development to
the dark side has everyone seen to say
at the time and now i'm consulting and a
disclosure i am working with water take
and i'm going to touch a bit on their
technologies because i think they're
really quite interesting especially in
this space so i'll talk about that as we
go through so what i am going to cover
is a bit about multi-tenancy quite a lot
Batman tintin see what does that mean I
will define it take a look at different
approaches to doing it there are various
different ways we can do multi-tenancy
and achieving the software developed
we're developing I'll touch on Java
virtualization and start looking at how
that helps in this space and then start
getting under the cover of that and
touch on how that works how do we make
that work well and then if the gods of
software are with me on to the demo if
they're not your watcher a road crash of
software is ever but we'll try and get
through that so some of the overview of
multi-tenancy and I thought I'd begin by
defining what that is and i found this
definition from garner who are saying
it's multiple tenants sharing a common
physical computing resource while
remaining remaining logically isolated
so that's our software running in
multiple times in the same place same
space and not interfering and I thought
there are some characteristics to do
with multi-tenancy we need to be aware
of and I think help the definition of it
it's about isolation and bio isolation I
meaning that it's not going to be your
software is not going to be affected by
what a neighboring process is doing if
it's using lots of memory of is using
lots of CPU resource or I up file i/o
you don't really want to affecting your
ability to operate and process security
I mean the data that is happening in
your tenant space is secure it can't be
accessed final seen by anyone else and
that's a characteristic that's
incredibly important especially in
finance they're very very hot on that
and
the elasticity you need to be able to
flex the resources you've got to
accommodate the demand and load you're
facing from people coming in utilizing
the software or the service and
horizontal scalability as demand
increases and your individual tenants
begin to reach the limitations you need
to be able to scale out rapidly so you
can keep responding to new tenants
coming in making new requests and you
can service all of those effectively so
hopefully that gives us a little bit of
a framework to start thinking about
multi-tenancy with when we start looking
at the stack just so essentially there's
hardware hardware's on the base we need
that long without that more things going
to work that's all of our resources
available and on top of that there's the
operating system well that's just
allowing is really to effectively access
it files access to the hardware and made
great use of the data storage and cpu
and things databases most applications
somewhere need to persist information so
there'll be a database layer we need to
be mindful often that can participate in
the stack and then we're looking at this
schema on the database and I'm calling
this out because it plays quite an
important role in some approaches to
multi-tenancy so once it's not a thing
of itself it's part of the database it's
important or aware it's there because
it's got a role to play and we're
talking about Java so of course there's
a JVM at playing that that's part of the
machinery in the stack we're going to be
using possibly some middleware not
always you could be running a jar file
directly but quite often this some kind
of application server or messaging layer
or something that's giving us a
container and providing other services
and resources we use to develop with and
finally eventually we get to our
business logic right up there on the top
which is the thing we really want to run
it's okay with this stack in mind or
stops or stepping through some of the
approaches people are taking we can look
at this sort of woman thinking all this
spectrum of approaches and we can start
with virtualization this seems to be
very very hot topic that lots of people
are trying to do it and there
successfully doing it no need for Java
but of course in all sorts of other
operating environments so you can make
best use of the services you've got and
it's a way of splitting things up by
taking a complete isolated stack you've
got your isolation and other service in
it so an approach to doing multi-tenancy
DB separation is another way having
completely separate databases for
different clients they call in like your
application then talks to that clients
database that can be another approach
and all look at these in a little bit
more detail here's where the schemer
comes into play people have the same
database but they're separating it by
schema so each client coming in or each
application until as their own schemer
to talk to you to serve as a client's
request or it could be that we're
sharing both of those and in fact we're
using the queries themselves or some
kind of identity coming in with every
request we make which helps us
understand who's making the request who
we need to get the data back to so
seeing as you're sharing both and doing
it in the queries we can go up to shared
middleware this is another approach
again bit like queries we're using some
kind of identity right this time
probably in a message request or in the
message body and we're looking at the
identity coming and then redirecting the
message to the appropriate place to get
the data for the client and then finally
there's the shared application where
everything is shared it's really down to
something like Salesforce looks very
like this you log in as one application
the whole thing's been designed from the
ground up around multi-tenancy and of
course these aren't mutually exclusive
they're all used together in different
elements in different parts but it's
useful just to think of them in these
different separate stages so we can see
what's going on as we look through
multi-tenancy soon yeah
oh yeah okay this so hopefully the
graphics clear but yeah this we're
trying to show with the blue part the
bits were focusing on so I'll set
throwing a little bit more detail and
think about each of these in terms of
the trauma to kill myself in terms of
the different attributes of
multi-tenancy and see where they fit in
how they play especially in terms of
Java software so with virtualization
your entire stack is separate you've got
a separate operating system and
everything from that level all the way
up to the top is separate so you've got
very great very strong isolation um it
is a large stack to manage however
there's a lot of moving parts in that
lots to go wrong lots of security
patching and an operational stuff you
need to keep that up and going and Java
tends not to virtualize particular well
in these environments we start Java up
we allocate a huge rate lump of heat so
we can manage our workload as it comes
and goes and the virtualization layer
can't really interact with that it's
kind of locked away so Joel is kind of
this larger moveable lump in these
spaces quite quantum I've seen lots of
large memory grids using this sort of
environment you gain the gain gain your
stacking up an instance and pulling them
out in your memory great and adding more
and more skylight horizontally which is
quite nice and as far as development
goes this very little you have to do in
this environment you are isolated you've
got some scalability going on you didn't
have to actually write any code to
achieve that so it's relatively simple
approach and you can do in terms of
people connecting to a server address in
a particular instance we've schema
separation birds yes we're scheming
separation getting rid of myself we've
got good days for isolation obvious
skipped one bear with me I think I've
gone I've missed DB separation so what's
getting ahead of myself we've got DB
separation of course you've got great
data isolation we've got separate
databases they're not talking to each
other in any way though so that gives is
that separation it's still quite a lot
to manage
we still need the whole stack though we
still got the operating system databases
and everything in the picture to play
with arm can be less responsive
depending on the implementation some
database systems large enterprise ones
tend to be designed Ryan clustering and
scaling out quite quickly in large
memory goods let you scale rapidly but
if you've just got something lighter
weight then it can be a bit of a hassle
to keep building a new instance and
adding one as you go can reel off script
work so and then finally you may need
some minor code changes to make sure
you're connecting into the right
database in the first place can often be
handled in configuration we scheme a
separation arm 30 similar good day to
isolation bit more workload for a single
database to be handling arm but not too
heavy a lot of them are designed to do
that some on some don't have schemers so
this won't applying um does scale pretty
well again many moving parts going on in
this picture still but there we go but
am as so you may need to redesign your
database if you've got an existing
system that you're wanting to scale up
you may not got scheme is in the picture
so there may be some work to do there
and then going to the query the world of
using the queries and identity that
siding a lot more stress to your
database each queries having this extra
process to go through there may be a
join involved looking up the customer
identity so there's a lot more work load
on the database and the other areas are
fairly similar to other database
solutions but in terms of the
development side you're going to have to
start redesigning your queries add more
data some of them and there's a fair bit
more work for the developer in taking
this approach and shared middleware okay
you need to sort of design this again
all we reinstall entry fact her to take
this approach because you're going to
have to add something to all of your
msgs you're going to need that identity
be passed around all the time so you can
pull it out of the message and utilize
it all pretty scalable most of these
messaging type environment middle
were really designed to be large-scale
installations so they from designed
around scaling which is pretty helpful
and it's a fairly well-known approach so
a sort of architectures have been around
for a while so it's a fairly well
trodden path and applying it to
multi-tenancy it's quite awful have got
that in place make it work with the
database layer make it work well with it
otherwise and finally the shared
application are not particularly great
if you've got a legacy application or
something you want to refactor this does
need the most amount of work you are
going to pretty much design everything
but if you've got a green field
situation then designing it all in a
each layer building the entire stack
around multi-tenancy is a good starting
point but it's greenfield development
it's locked designing a lot of work to
do so across all of these different
approaches we've kind of got this the
approach you take and how complex it is
versus the cost of doing it so we map
the different approaches with
virtualization it's quite expensive
you've got a large stack you've got a
lot of resources to stand each stack up
but actually it's pretty simple to do
and you just take your existing image of
what you're doing and pop it in another
box it is really not that much work
involved in that for the developer going
right across the spectrum until we get
to designing from the ground up and
there's an awful lot of work with the
developer but once you've got it up and
running then its low-cost operationally
it was designed to do this job from the
ground up so it's going to work which
kind of gives us an approach and cost
curve so you can say pretty much we're
going from very high cost solutions very
simple to very relatively low cost
rather rather low costs are rather high
complexity solutions so occasion but
what do we notice about this stack when
we've looked at the different levels and
the different elements this is kind of
something that's not come into play yet
so if we look at it we've got oh this
thing's firing off without me touching
it that's not good so sorry evening a
chance to answer that but it really is
the jvm low at no point if we use the
JVM there to do in your work for us in
this in any of all multi-tenancy
approaches it's kind of not been in the
picture so far so that leads into Java
virtualization as an approach to solving
the problem making this layer do some
work for is in the multi tendency space
and help us achieve a multi-tenant
application wouldn't touch anything then
okay I'm going to take that out as well
hopefully it's not going to keep running
off ahead of me so it is okay this could
be fun so all right that presentation
wants to get rid of things what if we
could do this what if we could do
everything and virtualized in the JVM
layer and inside the JVM self put
multiple versions spooky multiple
versions of our application he's
starting at that would help us get
multi-tenancy it would allow us to do
something that's looking a bit more like
the virtualization of the hardware but
further up the stack so maybe it's a bit
simpler maybe it's a bit lower cost and
what if we could go a little bit further
and do the similar sort of
virtualization with the middleware
itself and then we just had the
application stood up in the stack so
okay if we take those approaches what
does that mean for it well it means
pretty much like physical isolation and
physical virtualization of the hardware
we're getting great isolation of our
software from the ground up it's
separate we've got a fairly simple to
manage environment because there's a
stack of stuff that we're moving around
we've not had to do too much work in
security it's separate and it we're just
patching more level of each we're just
patching 1 OS we're just patching 1 wall
instance of that we're patching 1 J
um we're not having multiple copies to
manage a nap after the control of
resources should be the same there is a
regular virtualization so hopefully we
get some good control of resources and
hopefully we get the same scalability
but at this time it's at lower cost
because there's so much less in the each
container and of course no code changes
we much like with the hardware
virtualization stack we're just taking
what we've got already and putting it in
a separate box and if we did middleware
virtualization and somehow virtualized
the middle way so we could put
application in multiple times in
separate boxes then we have the same
effect but in fact we're getting even
lower costs so that means we can map
these down here somewhere very light
virtualization but much lower cost and
going further even less to do an even
lower cost still so okay but that's the
approach we go again that's the approach
I'm going to dwell on a bit and really
the history of virtualization starts way
way back virtualization itself kicked
off in the one experiment in the 60s
back in the 70s with our pals and
mainframes but as far as distributed
computing is concerned it's really sort
of hardware virtualization that kicked
off with VMware and folk introducing
their approaches recently operating
system virtualization with Lintz
containers and things like that are
coming into place so I've been to quite
a few companies where I've seen the
migrating from virtualization at the
hardware layer to virtualization in the
operating system there for various
reasons and what we'll have a look at
why people are doing that and then this
notion of Java virtualization no it
should have been working wore a sec and
I know the guys there have been working
on this for since seven years ago now
and it's interesting to see that fairly
recently IBM has been doing the same
thing for a couple of years they've
recently started talking about some
multi-tenant Java and then finally
middleware virtualization
top is something I know it's been worked
on really in the last year or so and we
can start looking at how that can take
place as well okay so why did why people
moving from hardware virtualization
which kind of looks like this and why
why missing will move across to
operating system virtualization what
okay I think it's the cost per tenant
and the footprint of each tenant their
large fairly common some things to
manage at the hardware but if we go to
the operating system layer we've taken
one element out of that stack so we've
got a much smaller container much
smaller element of computing to move
around or less moving parts less to go
wrong mr. patch so that's why people are
doing it they're making their
environments smaller more agile more
manageable and cheaper um even costs
come come across a few companies are
doing no virtualization at all and
they've gone you know what Weaver comes
to our Java workload there's no point
virtualizing it because it's got this
large lump of heat we couldn't manage
anyway so you we've got more efficiency
by not doing any virtualization
whatsoever and we're taking this
approach burn we're just standing things
up on separate JVMs to isolate them so
stepping into Java virtualization we can
get this kind of a picture where we're
taking our application server if we're
using on the applications stood on top
putting them in separate boxes on the
same jvm and we get that level of
isolation that we're looking for and
then we're quite clever about how we do
stuff we can actually get even better
density and better stuff with class
sharing and class sharing is about digit
compiler taking a role in all of this
it's about the JIT compiler saying you
know what you're standing up the same
application again and I think I've seen
this bytecode before so I'm not going to
omit the same permgen again or code
cache I might as well share that across
the applications and just let you keep
separate heap to your data space is
separate and safe so when we start
playing with the JVM and making it do
these sort of multi-tenant
virtualization tricks we can start
getting some quite interesting
efficiencies from it
and in fact if we went even further we
could go up to doing this so how do we
do this well if you've got a JVM and
you've got a hypervisor inside of it
that's letting you create these
containers and create these separate
isolated units of computing going on
it's written in Java so it should have
an API right so developers can come
along and do interesting and useful
things with it that's how we can do
something like this we can start using
an API to the hypervisor and watching
what the JVM is doing and change its
behavior so for the first time we can of
tck compliant Java they're doing things
javale's and designed to do and it's
still TCK compliant so that's quite a
really interesting space and I'm going
to be very very curious over the next
year or two to see what people really
start doing with it but one thing I have
seen done with it is the virtualization
of an app server so the code written
against the IPO API can sit there and
watch what's happening inside the
container and say oh you know what I can
now see that this app servers about to
load a war file see you all intercept
that are not pop it in a separate box so
that's how we can get to this level
where we've virtualized an app server
and we're just handling the application
itself as an isolated separate unit and
then you can do lots of lots of tricks
with the memory then at runtime because
it's virtual you're not having to
allocate a huge very heap every time you
start one of these aren't because you
can flick sit while the applications
running it needs a bit more demand so
you can say you know what I'm going to
add more memory and that's how we can
start really getting separate isolated
units of computing with very very
flexible behaviors so our services as
they want to scale can scale without us
having to sort of hold up and tire by a
whole machine which we did with other
kinds of hardware virtualization by
allocating this huge great lump of heat
does that make sense it was very quiet
today
so look at that in a little bit more
detail just in case that doesn't make
too much sense by looking at what
happens if we have a standard deployment
of separate java if somebody's using the
new virtualization solution we've seen
things like this where there's maybe a
production application running and
beside it there's some logging going on
this monitoring going on there's
compliance and security apps running in
the background of maybe less space so
overall in the picture we're using up
about four gig of heap these guys are
all doing their own thing but if our
third JVM goes to allocate more memory
more than the 204 he's got left he's
going to trouble which is crazy because
right next to it on another JVM there's
another application running or another
tenant running he's got plenty of space
so why why I have this problem so if you
move to a virtualized environment let's
share the memory whoever needs it can
use it we can make get far more
efficiency in fact we could be a bit
more aggressive of this picture we stole
the four gig of memory in this picture
but now everyone's got access to the
same pool of available memory sure
dynamic elasticity of it yeah it's the
elasticity of the heap and being able to
flex the memory at runtime in this
picture there's no constraint on the
containers each containers running the
application and has a the remaining JVMs
heat just to spread into so it's the JVM
you allocate yes that epsilon I was just
going to say it's the JVM that your are
cating a large lump of memory to to
start with but this time you're making
more efficient useful on each container
within that having flexible access to it
and if they aren't constrained then each
container can just go and take resources
as they need to that's what we're seeing
in this picture does that make sense in
terms of multi-tenancy of the same
application probably knock sure you tune
the whole JVM fee for the warren
application you're instantiating at
multiple separate times and getting your
separation through that if you are
running a heterogeneous set of
applications in this environment then
you need controls on this on separate
containers and in fact those are
available in the version I've seen how
this relates to say failover reliability
if everything is all running on the same
system under the same umbrella right and
something goes wrong you just took down
all of your clients you know first
yeah you're absolutely right side I just
something thought you guys might not be
hearing the question so the question is
about essentially there's a single point
of failure here there's one JVM and what
about failover and that kind of thing
and I knew right you would need to be
using a clustered environment arm across
the top of that and some patterns of
deployment I've seen in this kind of
opinion of an environment although
you've got a cluster an application
you're running to JVMs underneath one
half running one half of the plaster and
won JV and running the other half of the
cluster so that if there is a failure of
the JVM level yeah those guys go down
but you do your failover in the
application space does that help
otherwise you're right there is that
single point of failure but it's the
same as if you're kvm or any other
virtualization hypervisor failed under
you you you lose the law that's
absolutely true Oh saria's question
right back
so if I heard correctly it is the
elasticity across a single machine in
the implementation I've seen it is um
because you've got one JVM on the box
running the running underneath allocated
a chunk of physical memory in the box
but yes ah I as I say the implementation
I've seen doesn't span across multiple
machines now with Jericho I haven't no
I'd be very curious to play with that
and see ya if you could implement this
kind of an architectural on top of
something like that that would address
that issue absolutely ok cool Oh Jo Jo
Carter am I saying it correctly all
right so at energy goes heard the
question was about Derek hotter and
apparently that allows you to span jvm
heap across multiple machines so it
sounds like there is a solution to do
that and what you very curious to see
that working in this sort of environment
as well like V tell me more about
afterwards please
it's okay boy
it's a shared memory solution okay well
well well it's to chat about that
afterwards I I don't know anything about
Derek RT yet so terracotta terracotta
sorry okay and it seems this isn't oh
sorry one question but what you mean
virginal je viens yes yeah i mean the
diversion I've seen they just pop up as
you start loading another application
using a Java minus classpath blah blah
blah pop another one pops up okay and my
presentation isn't rushing ahead of me
either which is good so what is it going
to show is that um we start getting a
few more efficiencies out of this kind
of environment if we start actually
constraining the applications so the
normal behavior is allocate max allocate
for the biggest load of work later we're
going to get to make sure we've got
enough space and enough overhead but in
this environment we can start being a
bit smaller with things and start saying
you know what I'm just going to allocate
for my average amount of heat
visualization or my average workload and
then share a pool of memory between each
container which is what we're seeing at
the end there the free pool between
those at running applications so now
they want to allocate more heat and they
appear to have available they've got the
shared pool to you so we can get over
commitment and this is a technology in
the concept taken directly from existing
hardware virtualization you can over
commit resources so the containers so
why not do that in Java means we can
maybe squeeze some more work phone out
of the whole box as well and it helps
our scalability story so we can start
getting more work load out of the same
resource and then finally we could be
really really aggressive with the whole
picture and say you know what I'm not
even going to give them enough memory to
start with I'm going to make them force
them into using a shared pool and that
always get even more word out of the
machine but of course the trade-off is
at higher risk we've now got less pool
to share so if somebody who really does
get hit hard and need another gig of
memory there maybe not going to get
so that's kind of white trying to kill
myself of this that's kind of why we can
start using a virtualization technology
in our multi-tenant environment and
start getting quite a few advantages
around the isolation the scalability and
the amount of workload we can get
through but of course we were wondering
nosy neighbors before and I've really
sort of labored on the memory point and
how that works um I won't go through
these in huge detail with the same kind
of facilities and resources that we can
do with constraining memory are
available for constraining the cpu
utilization so we might take a container
and much like we would with VMware or
another solution like that say you know
I'm going to pin this to one of the
cause on my box because I know it's not
too heavy hitting it's not too
multi-threaded let's give it one core
and share the rest between the other
containers or half a quarter this
container or we can mix and match the
resources which stop people suddenly
getting CPU hungry and then taking it
all cause so all the other containers
run out of resource and the same thing
with network i/o and with file i/o so
it's a question that's a really great
point garbage collection so you're
running multiple applications on the
same jvm and you've allocated large
amounts of memory because you want to
run more applications than you were
before in the same jvm you don't want
garbage collection coming on stopping
the universe and everyone posing while
64 gig of memory of sweats absolutely
not great point the implementation I've
seen here is borrowed the g1 garbage
collector and that's region based so
it's constantly collecting tiny amounts
of memory which means everyone's
effectively paying on garbage collection
tax all the time but by doing that you
don't have this huge great 64 gig pauses
so hopefully that makes sense
when you've got multiple cores okay
okay for is over playing nicely of the
garbage collector I should have been at
that one then sure yeah I think we're
going to any details of that
presentation I not sure I we should seen
it but um yeah if g one has some
tweaking you need to do with the cause
that it's working with to make it really
efficient then yeah you could you'd have
to do that here as well okay so say the
implementations that we're looking at
its model very much on sort of
hypervisor environments we find of kvm
vmware on other solutions so we have the
same facilities to manage it essentially
and in fact you can go in at the command
line to the hypervisor and tell it how
to behave using jmx you can do the same
things get management information out
billing information out take control of
it reallocate memory reallocate CPUs and
I've even seen this sort of solution
running against the libvirt driver see
in a hypervisor e management environment
you get this weird situation where
you're looking at what looks like an OS
container and when it says operating
system you see this thing going value
blah blah path line all the way down to
a jar file you think okay that's my
operating system but so it's very much
taking all of those ideas and
transplanting them into the into the JVM
so ok that will sound very good right
but how does it work how does that how
does that look so if we take a look
inside inside the JVM itself how do we
provide a solution that's going to give
us the multi-tenant environment in the
isolation well we're going to have what
we call a domain 0 this is the
privileged main this is the domain that
has access to everything on the JVM
essentially it's running stuff directly
on the on the host JVM and above it we
will need to be able to create guests
these are the containers these are the
virtual containers that will hold our
separate application servers or
applications directly
and we could if we were talking about
our arm the virtualization of an entire
application server in that instance
we're going to have to run the
application server within this privilege
domain because it's going to be popping
up its own war files elsewhere in
separate containers so it'll need access
to all of them so okay and that means we
can run war files that will talk through
to the host in this case Tom cap and JVM
when they need to or we can just run
regular of jar files and they'll to talk
quite cheerfully to the JVM when they
need to so okay what's happening inside
the JVM well is that we've got a garbage
collection going legit now the jet needs
to be aware of containers the JIT needs
just somebody saying I need something I
need a resource the first question in
the jits now got to ask is who's asking
because there's more than one
application around and we also need
class libraries or in this case if we're
compliant we can just take hotspot
libraries partido jars drop those in so
it should be good and then we need a
hypervisor layer built on top of that
that's communicating and orchestrating
what's going on between the containers
and these core elements of the JVM it's
ok so it's doing some the virtualization
itself in the hypervisor what do we mean
by that virtualization well it turns out
in the world virtualization there are
two types of virtualization there is
type one and there is type 2 not the
most imaginative names people ever came
up with but those are the types of
virtualization and one is really about
having a hypervisor directly on the
hardware which is a bit like operating
system virtualization approach and the
other is having a host operating system
and then creating images or containers
on top of that which is kind of your vm
while hypervisor if you're running
fusion on a laptop that's the sort we're
doing so in terms of a JVM which type
we're going to do well if let's look at
tight one in a bit more detail what
happens in type 1 virtualization we have
our guest operating system running
around in the container I'm already
going along and it needs to make a call
down to the
we're so the hypervisor needs to get a
hold of that call and it needs to ask
the question is this sensitive and what
do you mean by that what you mean by
that is this a call that's going to
somehow affect another container breach
the security of the system or is it is
it sensitive or can we just allow it to
pass through if the answer's no it's not
going to compromise security it's not
going to do anything on toward to
another container we can just let it
pass on to break through and we can let
the host environment respond if however
we do need to do something we need to
track the instruction we need to emulate
the response and treat it make it behave
correctly and then pass that back to the
host environment so this model of
trapping and emulating instructions
we've got a machine underneath the
virtual machine arm and we were running
java on top what if we could do
something like that well there's a
problem because the JVM itself is an
application running in user space rather
than anywhere else so all the calls that
Java makes our non-sensitive as far as
their hardware and the CPU is concerned
but what about an instruction like this
what if one of our containers cause the
system exit that's going to shut the JVM
down so we're going to need to somehow
get a hold of these make sure they do
the right thing we can go a bit further
we can say we've got another problem
that in je were sort of got this court
written multi-tenancy environment or or
application framework and what we mean
by that is we've got all these
application sharing the same underlying
framework and a bit like Windows
workgroups remember that one application
went down the whole system came down je
is behaving a bit like that if one
application goes down the whole stack
comes down so this is where the
middleweight virtualization starts
coming into play in giving us some
protection against that but how do we
really fully isolate all of this well
guest applications running on the JVM an
exit transition occurs it's making Hall
down to the underlying JVM for something
and we need to make sure that have we
virtualized this type it's a type called
it's trying to instantiate an object
have reverted eyes this for any reason
did we need to was an unsafe instruction
so in terms of system we need to have
virtualized that in terms of saying of
an ex it's called we need to convert
that to a shutdown that container alone
instruction if it's safe fine just like
with type 1 hardware virtualization talk
to the JVM get the resource you need
however if it isn't then we need to
emulate that in the hypervisor layer and
pass that back so
hopefully that will make sense so far so
we've got a containers they're all
running on top of domain 0 and they're
running on top of our application and
they all say great I need a hashmap so
they all get a hashmap so how do we tell
who's hashmap is whose how do we know
that container number two when it says
well give me content of index five
doesn't end up with the content for my
index five of container three how do
identify these all at the bottom and
when I hold Java environment started up
there was a base class loader which
booted the whole environment kicked
everything off so what we could do is
give each container a virtual base class
loader that means that each of these
containers now thinks it's got the real
base class loader thinks it's the only
JVM in town and this is how they'll not
start interfering with one another if I
do a get all threads on my virtual base
class loader I'm not going to get the
threads for the container next to me I'm
just going to get my own threads and if
we start defining objects and start
making the underlying vm emit bytecode
then it will emit the hash map and if we
happen to call it from the domain will
get the real hashmap when we do a
defining our container we're essentially
getting our own copy of hash map which
is actually referring back through the
virtual race class loader to the
original emitted bytecode or we've
called this for the first time in our
container when we've limited that in the
drain zero but it's got a virtual copy
of that which can call hashmap prime so
container to gets hashmap prime prime
and three would get point prime prime so
they've got their own heap contained
with the content of hash map but the
bytecode underneath is shared across all
of the domains and it's through the
virtual basic last load is that the
isolation is being managed
hopefully that will make sense very
quiet room again so I'm going to risk
life and limb and try oh sorry question
yeah i mean the the first versions of
this i saw that was absolutely correct
it's complete night mex you go to do a
thread dump where he dumped and you've
got this huge great pile of stuff and
you're like oh well whose is what um
we've actually ended up having to build
facilities in around that for own
engineers sanity when it comes to
debugging so part of when the by codes
emitted we will go back to that picture
part of what's being armed emitted is an
ID as well as so there's a an extension
to give an ID to think so you know which
contain what belongs to walk container
and by doing that you can actually just
get heat and thread dumps per container
so if you're trying to debug a single
application you know which which of
these containers it's running in you
just you just see its own heap dump
sorry I didn't hear
um for reproducing issues yeah i mean
that that that makes me think really of
what's in with vmware coil from your
running software and you go to the
company that wrote the software for
support and they say oh is it running on
vmware and they're like running on bare
metal first to prove it was a natural
problem of ours not VMS arm I've so far
not seen too many instances where the
underlying VMs caused the problem apart
from during test phases and getting TCK
compliance as generally flushed a lot of
that kind of situation out but you know
I would quite understand you some
companies said yeah run all software of
hotspot first before you log the defect
but
okay so I'll try demo yes sorry the
these are yet in yeah there are there
instances of the arm hashmap that each
contain is defined said yeah they then
it with reference to the heap and
they're actually sharing the perm gen
underneath but they think they've got
their own absolutely yep
disgusting
we've clustering here clustering is
definitely the approach I've seen before
this to achieving one way of achieving
this and that's really looking at the
middleware virtualization or talking
about when I was looking at the
different types of virtualized
multi-tenancy wanting to get clustering
and using middleware applications to do
that and deliver that is an approach I
don't think they give you the same level
of isolation in in terms of the data if
you've got multiple different customers
coming in you're going to need something
else to help identify you who's asking
for their own data and so you don't mix
and match that in a clustered
environment so you you need to add add
something to the clustered environment
to achieve multi-tenancy that makes
sense
yeah yeah it's definitely an approach to
multi-tenancy you undoubtedly
okay see without any other questions
before i get into the demo okay all
right let's try that okay can I get this
to pause exit this okay why isn't that
explain
not
and try again doesn't look like it a lot
of it
what's very frustrating is I did check
all this before he started now it's not
working software demos got all of them
let's mirror my display with my desktop
ok now let's go here let's go hear you
right always good in the world we can
see ok so um this is virtualization
squared so I'm going to virtualize
inside a virtual contain i'm running a
linux platform on my Mac here so a batch
form and if I start up this JVM I'm
starting using the core java d because
it's going to need to run in the
background as a process so it runs in
the background as a demon process and
when you start java the command line
Jarlath that you normally call is still
there in this instance if that becomes a
lawn chose a Python script that just
launches applications into the
background process but I'm going to go
straight into it directly and then we
can start taking a look at running
different things so boom boom ok so we
started the JVM and we're now inside the
JVM or inside the hypervisor within the
JVM that's what this command line is and
it's called Josh arm that's if anybody's
got a vm background they might go hang
on that sounds a bit familiar it's very
much modeled on versh so it's sort of
height wise your environment and I will
run a script just to save me miss typing
a dozen times which has got a demo ok
bang so the first thing is kicking off
there you go and we've just run tomm cap
so we've got one thing running on a JVM
but when we run tomcat there was some
extra output at the top arm so here this
was the I was saying that you can go in
and start modifying the containers in
their behavior with would an API that's
been published that's what the first
thing that we're starting so that's this
block of output here is the driver
getting loaded then there's this very
uninteresting empty line
that's where the call to start tomcat
took place and then the following output
was the driver starting going all hang
on Catalina door bootstrap I recognize
that I need to set a few things upset an
environment up around this so i could
start monitoring this application and
load it into domain 0 and then all the
rest of it is Tomcats output with no no
code changes to tomcat that's standard
tonk output tonk out at this stage has
no idea what's going on it just thinks
it's running on a JVM so we talked about
running multiple things in
virtualization hello world fairly simple
it's just a tick tock it's going to
count for us or what lets us do is see
now we've got Tom count running in this
domain 0 and we've got hello world
running in another container on the same
jvm and it's still alive so if we go
back to the arm output we can reattach
the output of that of a container and
see what's going on inside of it so if I
have a look at console one which is
hello world is still alive and ticking
and going on in there
so
let's run this come on this is the
dominant folk come on this goose is just
a high level snapshot of what's
happening in a container just so we can
start having a look at what we're
running and how we're running it so that
tells us we're looking at the hello
world container it's been running 49
seconds and this is a strange output
here gigahertz hours so because it's
been running in a container we can
monitor the application on the
individual basis and check just how many
cycles it's had on the cpu and what
we've done in this case is then we treat
it a bit like electricity apply the same
formula and say well how much time is it
spent how much CPU resource has been
consumed and will report that in
gigahertz hours so if people wanted to
run an application then build a client
who is using the cpu heavily more than
another client if you're setting up
multi-tenant environment you can do that
check how much CPU utilization they've
done or indeed how much heat they're
requiring for their application so
currently this is a maximum heat memory
it hasn't been set to anything in this
case so this is that picture of one big
green bar of shared memory with four
applications running inside it's the
same sort of a picture but hello world
only is taken I'll just just shy of a
megabyte to run in and for some reason
has access to all of the CPUs which is
may be overkill for hello world so we
maybe should have constrained that one
hmm we can yeah yeah we can monitor
exactly how many classes got loaded for
us to get armed that's just for hello
world 239 classes get get loaded from
starting at the nothing just this jvc
yeah it's just looking at this
individual container and looking at the
resources it's taken to run this
individual application sorry it's a
question over
yes yeah you can attach arm the jmx so
if you're using on the j console or any
other jmx monitoring tool you can attach
to either the entire thing at the
hypervisor level and see what
everybody's doing or you can attach to
an individual container and see what the
individual containers doing how can you
choose that oh yeah you could run
anything in there and the way to do that
you'd have to arm use the API because it
walks happened when that driver started
up and I said there was some output from
a driver loading it's not that was
responsible for saying how long that
this bootstrap classes tom cat beginning
I've ever watched some behavior i need
to do and i will run that in directly on
the JVM rather than in a container and
it's doing that because one of the next
things will do is load a war file and
just see that go into a separate
container and I think that's
particularly interesting but it could
have been weblogic it could have been
jboss websphere any other app server the
tomcat was free every similar bit
simpler for us to do the implementation
on so in fact that's the next thing that
my script does we're just going to use
this command deploy which is just going
to copy example stop war into the web
app web classes folder on tomcat which
makes Tomcat load web apps so if we take
a look now we can see we're running
hello world running examples dot war in
its own container and in that platform
layer we've still got a tomcat running
but if we look at the web app we can see
that it now identified it as a servlet
container so it's aware the drive is now
aware we just loaded a web application
it's really not taken very much see for
you to get there it's used 643 kilobytes
to get at that now that measure of
memory is just the war file it's not
measuring any of tomcat at play here
because as far as this contain container
is concerned there isn't
any tomcat it's a JVM it's just got this
one thing running inside it but actually
it hasn't done any i/o if we look at the
network I owe on that thing it's a war
file but it's not really done anything
so we're just 550 requests in what we
can see where we can track the file i/o
so again if if you're using an empty
environment and want to build people by
utilization of file i/o network I or
anything else you can track all of this
information sorry sort of question again
yeah yeah good question so the question
is about is there a hit on performance
and the answer is yes it's
virtualization so we are doing extra
work you're right it is it is having to
monitor what's happening inside the
containers in duelist rapping emulate
I've been doing some measures fairly
recently of that cuz i was thinkin the
same things like how much slower wait is
this all going to go and if you run it
on a lan on or on the same box next to
hotspot you notice it you do see that
there is this overhead in terms of
response and process time but as soon as
you start running applications and
measuring things like transactions per
second over a regular network or across
the internet in particular the latency
is so high in those environments that
the difference just disappears so you
get exactly the South runco no current
application fairly recently the
e-commerce app and we're fine requests
into that and we were getting the same
response from the JVM with three kona
console running and answering requests
versus horse bought running one and it
got the same requests per second but
that was over a network
you
I'm sure so you mean policies for the
class loaders I believe we can apply
policies I'll have to i'll have to check
that and get a non stitute cuz i don't
want to say yeah sure we have cleaner or
things like java agents we can load on
per container basis but i'm not sure
about um plus later policies but I'll if
you want to grab me afterwards I'll get
an answer on that okay so there we go
got so we've seen what we just done
we're done example stop war we find some
requests at it we've seen that it took
some more resources to service those
requests that use the IO by Network I oh
it's also used a bit more heat memory to
do that a little bit more CPU so you can
see it's all fairly live it's tracking
all of the stuff you're doing finally we
can enter the bean she'll just to show
we can run something else in a container
I'm not going to dwell on that cuz I'll
make a bit of time for people to ask a
few last questions because I think now
is nearly done okay so you can see we're
running for four different things in
this case but in an empty environment
you you could run the same application
again and again and really you could
create you would then create virtual
network interfaces in the environment
and just point those at the different
containers and you really would for no
code changes have an empty environments
stood up pretty much out of the box so I
think this is going to be a fairly
interesting technology an approach it's
creating UNT environments um then I was
almost up I'll just try and step back to
my run away my god I'll run away
presentation it's not rushed on ahead
without me so what next we're nearly up
so if this does sound interesting and
it's something you'd wanted to a bit
furthers quite a bit of information on
vortex website they're the guys who've
written the jvm and created it
there's also a version that uses the
middleware virtualization that we've
just looked out for tomcat so if you're
a tomcat user and that's of interest
grab on and as for writing and changing
the behavior of containers that API has
been published that's open source API
and drivers have been published as well
so the Tomcat drive has been published
as open source so people can really
start understanding how does that work
how do you how'd you create this kind of
environment so if you're interested in
taking weblogic and virtualizing that
there's a kind of a framework you can
study and see and of course it always
give me a pain as well so are there any
other questions we've got almost out of
time which version is so it's a 1.6 jdk
and i believe 17 is in the point point i
don't i don't know when that's coming
out but there is a 16 is a 16 version
again Oh update your gloria dates all
the time um I know the team working on
this have got Paul writes because they
teach they've got a license from Oracle
support code so that goes straight into
the JVM as well so fixing matches on 0
or a constant if there's a constant turn
on those and it's normally around 24
hours of the team pull them in
regression test and then get them out of
the door so cool
okay in that case I think we're up thank
you very very much for spending time
listen to me and if you want to do have
questions that we didn't get through
today then grab my email address please
and just let me just ping me</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>