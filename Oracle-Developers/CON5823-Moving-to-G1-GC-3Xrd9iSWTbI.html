<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CON5823   Moving to G1 GC | Coder Coacher - Coaching Coders</title><meta content="CON5823   Moving to G1 GC - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CON5823   Moving to G1 GC</b></h2><h5 class="post__date">2015-12-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3Xrd9iSWTbI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yet another garbage collection session
right so have some questions here before
we start here how many people here have
been trying to use the g one g see today
how many people have been having good
luck using the g one g see pretty good
so the question is if you're having good
luck why are you here I guess for those
of you haven't had good luck what seems
to be the main concern that you're
having just showed it out no concerns
too many sorry too many configuration
options options for the g one oh ok I've
not really heard that complaint before
but that's an interesting one will take
that under advisement I guess ok the
other question I have before you before
really getting into this in earnest is
how many you realize here now that the g
one g c garbage collector will be a
little redundant the g one g c will be
the default collector in java nine oh
wow that's pretty good that's about the
this group is very aware then i would
say because most of the places haven't i
go to when you say that they're looking
at like what okay what's going on here
so um does anyone know what the default
collector is today parallel wow ok well
is the crowd is it really really
educated ok so i'm here to basically
talk about what the g how the g one is
functioning and hopefully can get
through that part quick because the more
interesting part is that I've been just
I've been doing a lot of benchmarking
with the g one over lost while trying to
sort out you know what did what it is
that we can actually do to this thing to
to keep it out of the way of our mutator
threats or keep it out of the way of our
application threads and it's been quite
an interesting experiment and it's and
quite revealing in
and well I have to say honestly if we
were going to you know as a spoiler
alert is saying that the I would say
that the jvm hotspot engineers have done
a remarkable job in this particular
collector and in that it works fairly
well from my point of view and it
doesn't seem to be much that you do have
to do to it but anyways let's see what
the numbers tell us right so that's a
slide about me which I assume you can
read and everything like that so here's
some questions that we like to answer
day so you know how does the GC g one g
one g c algorithm work then we look at
you know what does the g one g c memory
pools look like and you know what are
the tools that we can use to help us
understand what's going on so in this
case i'll use the term here
evidence-based tuning as opposed to what
we generally see in the past is people
will just have discussions about what
they think is happening and then start
picking options or configurations in
order to tune the collector right and i
guess the other question is like how
does it really tuned compared to the
other collectors in other words do you
really want to leave the g one g c as
your default collector in nine or or
move to it in eight well you know it
really depends on your workload and some
of the characteristics your workload but
you know let's take a look at and see
how it fares and in that regard ok so
the standard introduction here is that
we're going to when you when the JVM
starts up it's going to allocate one
error reserve one large contiguous space
piece of ram and out of that it's going
to carve out to the the area need it for
for java heap we're going to split this
into four or five memory pools it
depends on the type of collector we're
using but generally this is considered a
generational scheme in that we're going
to have a nursery where objects are
created and we're going to have a place
where we can put the objects or the data
that's been around for a long time and
we're going to segregate that you know
in between a couple of spaces so in
hotspot terms we have an Eden we have a
survivor space generally a from
two alone the g1 only the two space will
ever exist outside of when we're moving
from the from space to to space and we
have an old space and prior to Java 8 we
have a perm I guess everyone here is
post you know post Java 7 anybody using
Java 7 6 okay well I'm not really going
to talk about perms face and meta space
here in this particular talk that's
another discussion but you know come
Java 8 you know basically perm has been
replaced with this other area called
meta space and they there's some
fundamental differences in how they work
ok with a generational garbage collector
the workhorse algorithm that everyone
uses is known as a mark sweep copy and
in the case of the of the g1 and the CMS
character well sorry the power new
collectors these are what are what's
known as evacuating collectors so in CMS
we're going to have evacuation for young
ng1 we're going to have evacuation for
all of the all of the spaces now with
the mark sweep copy we have a number of
different implementations we have cereal
we have parrot that we have these
implementations that have been paralyzed
and in some cases we've actually well
these that have been deprecated in hot
spot but we do have what are known as
incremental collectors in this case it's
the incremental mostly concurrent mark
sweet collector of course I I think
everyone's may be fairly aware of the
concurrent mark sweep collector okay so
why do we need all of these collectors
well if you look at the serial collector
it's very efficient but it uses a single
four core and there's a lot of work that
it can actually be benefit you can
benefit by having that workload
parallelized so we move to the parallel
collector right the parallel collector
works fairly well but it can inflict
long pause times on your application
because it can just take a long time to
get the job done
and so we introduced the concurrent
mostly concurrent mark sleep collector
to say okay let's interleave the garbage
collection threads with your mutator
threads sometimes we need to stop your
garbage collection threads about another
other time so you can just let them all
work together and the g1 is actually
going to be you know using a concurrent
mark sweep collector and it's going to
be parallel and it's going to be also
there's something current phases to it
from the scalability point of view if
your application is pause time sensitive
what we're saying is that you can only
keep a certain amount of data in heat
before your paws times are going to
start affecting your end user experience
so parallel tends to scale reasonably
well CMS will scale maybe better from a
pause time perspective but generally
when you get to about 4 or 8 gigabyte
heaps you're mostly done with these
collectors you know the pause times even
in the mostly concurrent phases are
going to start increasing to the point
where you're going to start seeing
problems in latency sensitive
applications so in comes the g1 and what
we're trying to do here is build a
collector that is one predictable and
its paws time characteristics and two
has hopefully shorter pause time
characteristics now unfortunately to
achieve that it also means that there
are higher overhead so the mostly
concurrent mark sleep collector comes
with higher overhead than a parallel
collector and it comes with higher the
parallel comes with higher overhead than
cereal collector and the g1 is going to
come with higher overheads than with
these other collectors right so we're
going to say that out-of-the-box g1 has
been do really designed to scale so we
want to try in this case to break the
pause time heap size dependency that
exists and the other collectors it
should be easier to tune at least that
was one of the goals of the engineers to
say look we don't want people playing
with all of these very esoteric command
switches right with it with CMS to get
it to pour perform well you sometimes
you have to dig really really deep and
you have to go hunting around and find
the switch that's going to affect the
configuration parameter that's going to
you know allow things to to go better
but we don't want to do that with the g1
basically what we want to do is give it
a pause time goal and we want to give it
a max-heap size and I'd like it to
figure out everything else from that
point right so you know so the question
is does it work well surprisingly I
think it works well most of the time ok
so how are we going to achieve this well
in the generational spaces we we just
had this idea of Eden survivor and
tenured spaces and they were just all
contiguous spaces with the g1 what we're
going to do is we're going to break heap
up into a number of reasons regents
approximately 2048 regions sorry there's
a typo there the reach each of the
region size is are going to be 1 2 4 8
16 32 or just recently 64 megabytes in
size and you know there's a small
calculation you can see approximately
how the JVM is going to sort out what
the region size is going to be and it's
approximately a thousand and 48 regions
so there's obviously going to be slopped
depending upon what your heap size
actually is you can also specify that so
I'm not really going to list the flags
here I think there's some listed around
but but you can fix a region sighs and
there's some reasons why you might want
to do this we can look at that in a
minute okay so we're going to place all
the regions in a free list and then what
we're going to do is when we start
allocating from this into heap we're
going to grab a region from the free
list we're going to tag it it's either
being an old or sorry as well we're in
this case we're allocating into it
initially we're going to tag it as being
Eden but regions in general can be
tagged as being Eden survivor old or
human
Gus right and after we've cleaned out a
region we're just gonna put this region
back onto the free list so that means
that any region in Java heap could be
one of these four tagged as one of these
four spaces they're pretty much all
homogeneous okay so what will happen
maybe after time is that you'll see
these regions being allocated or being
allocated into and there'll be tagged as
Eden and you'll keep taking regions off
the free list and keep allocating into
them until finally what will happen is
that you don't have any more any more
regions allocated to you right so at the
beginning of the cycle they're going to
say you get ten regions now we're just
going to consume all the ten regions and
when we finish consuming all ten regions
then that's going to be a trigger to
start a collection cycle now we also
have this other case is like you know if
we have a one magritte Meg region what
happens if we create an array that's
like to Meg in size in that case we have
what's known as a humongous allocation
as a matter of fact a humongous
allocation is any allocation that's
larger than half of a region sighs so
what we're going to do in that case is
we're going to find a number of
contiguous regions we're going to string
them together tag that as being a
humongous region and then we're going to
do the allocation into the humongous
region now you might want to note here
that the definition of a humongous
allocation is affected by the region
size so if we have a one Meg allocation
and we have a for Meg region size then
of course that's not going to be
humongous however for smaller region
sizes that will be humongous allocation
ok now this gets a little tricky because
I mean this picture is trying to show
that the heap is not contiguous it's
slightly fragmented I'll admit that I'm
not doing a very good job of that here
but it can be sometimes difficult to get
enough contiguous regions to satisfy
I a humongous allocation and if you
can't get enough regions together to do
a humongous allocation then of course
you're going to have to do a garbage
collection now before that was a full GC
now through refinement over the
different versions what you know they
try to manage this using young
generational collections but you know
they'll try and try and try and if they
fail they're all of a sudden just going
to have to do a full GC generally a full
GC in with the g1 is going to be an
exceptionally expensive event and
generally we're going to want to try to
avoid it now you might say well why
don't we just make the region's really
really big and then we can avoid this
problem all together well you know no
free lunch here there's other things
that are happening that really would
prevent you from wanting to do that so
we really want to make the region's as
small as we can make them but no smaller
right we want to make them as big as we
can make them but no bigger right so
here's our collection triggers you
allocate and you don't have another
region so you can allocation failure
you're unable to satisfy humongous
allocation heap is full that can happen
I'll trigger full GC or meta space
thresholds have been reached and that
will also trigger a garbage collection
again I'm not really going to talk about
meta space here so for garbage
collection we're going to have what's
known as a mark sweep mark garbage
crushing combination so we have a mark
sweep in young generational space and we
have a mostly concurrent mark for old
space notice there's no sweep for old
space that's going to be handled
differently so the sweep is going to
evacuate live objects from the region
they're sweeping to another target
region right so this sort of gives you
an automatic compaction things are going
to be automatically compacted when
when this happens and there's also a lot
of mechanism under the hood here that
I'm not really into explain today but
what it means is it when we use this
evacuation technique right we don't have
to maintain free lists we basically have
well I'll naively say a bump and run on
a pointer a top of the top of the region
space okay obviously the mechanisms
under there a lot more complex to avoid
having a hot pointer but you know we can
just leave it at that for the moment
right so when we run a concurrent mark
what we're going to do is we're going to
go through all of the old regions and
we're going to calculate an occupancy
right of for that particular region and
we're going to have thresholds that
basically say if I have a certain level
of occupancy in a region that's a region
I don't want to touch I'm just going to
ignore that region right and I'm going
to find all the regions where you know
like if it's an empty region fantastic
really easy to collect put it back on
the free list we're done okay full
region very expensive to collect don't
want to go there let's just set that one
aside for later ok so I'll sort them in
this order and then when the young
generational collector starts what I'm
going to do is I'm going to do what's
known as a mixed collection and in the
mix collection I'm going to take all of
the young generational regions and I'm
going to add in a few of the eligible
old generation regions and what I'm
going to do is I'm going to sweep them
okay now these are the ways you can
affect how all of that behaves if you
really want to most of the phases here
require your mutator threads to be at
what's known as a safe point and this is
where we get our stop the world pauses
right a safe point is a place where your
mutator threads your application threads
can't stop and when they've stopped
right the maintenance inside the JVM can
occur garbage collection is one of those
maintenance steps that can happen here
and sometimes what will happen
often what will happen with the garbage
collection pause is that other
maintenance will get piled into this
particular safe point so we're going to
stop the threads we're going to just do
a lot of work you know maybe it's like
lock deflation or something like that so
the jvm signals is going to perform some
maintenance mutator threads stop when
they finally reach this point where it's
safe for them to stop the maintenance
kit gets carried out and then the
mutator threads are allowed to restart
so you have to imagine with frequent
mute safe pointing you have a lot of
context switching going on here right
because I got to stop the contacts with
mutator threads contacts in the mutator
threads get the scheduler to schedule
mall also it's a cooperative effort the
mutator threads well you know if they
have never reached a safe point they
just don't reach a safe point and yes
there are conditions in the JVM where
threads may not reach a safe point and
at that point the maintenance step will
never happen right so we tend to measure
a ttf p or time to save point as an
important measure right so if there's
anything interfering with the threads
getting to a safe point we'll look at
how long did the maintenance take in
terms of pause and we'll compare it to
TT SP and we'll see if there's a gap
there and then I'll be looking in the
system to say okay what's going on why
is it taking my thread so long to stop
and it's a sort of a side topic here but
that's something okay so we have heap
after mark sweep right notice all the
eden regions are gone they've been
basically compacted into a survivor
region and you know we'll just now keep
allocating and compacting allocating
compacting and eventually the data is
going to survive enough collections that
is we're going to start promoting it
into these old regions okay so that's
really the really fast basic idea behind
the collector okay so what we're going
to do here is to tune it so what we need
to tune it our while we need to get some
data we need observability we need this
thing to tell us what's going on and in
order to do that we need to be looking
at these things here yes don't squint
too hard it's fonte small don't worry
we'll fix that in a moment okay so how
do we get this well today in Java 8 we
have and in the early release versions
of Java 8 we're going to use these types
of flags in Java 9 we're going to
unified logging framework so a lot of
these details are going to change okay
so so this is the data I'm going to get
when I capture in minus X log GC now of
course that's very terse data I'd like
more details so it's going to start
giving me a breakdown on what's going on
I'd like to know how the data is moving
search through survivors faces i'll do
that reference GC so my phantom week
soft final J&amp;amp;I final all of these type
of reference types they all get
processed here it's nice to know what
you know what their effect on collection
is I'll put that in there and you know
the garbage collector okay so one of the
things I said is right at the beginning
of the collection young generational
spaces is been allotted a certain number
of regions well how does it know how
many regions to give it well adapt a
sizing will come in and say I think
based on how this application is burning
through memory that I should give it x
regions and when I hit when I consumed X
regions that's going to be my trigger
for a garbage collection right so
adaptive sizing here what it does is it
looks at what's going on in the runtime
and it makes decisions as to how to size
each of the memory pools so that it can
so each collection can run as often lee
as it possibly can sometimes we want to
see the decisions or how the decisions
are being made so we can print the
adaptive size policy and that will give
us that information also so you know
what do we get here well initial state
of Java heap what our application did to
the heap final state of Java heap after
the collection and basically what the
garbage collector did to the heat how
long did the process take right and
we'll get and all those extra flags will
give us a breakdown of all of the
internal phases so we can see what's
going on right
so generally unless i have what i call a
Black Swan event which is based
something completely unpredictable
happening in that case I'll look at one
record but I'm going to look at
thousands upon thousands of these
records and I can make tuning decisions
based on generally I like to start with
a minimum of like 24 hours of data okay
which means I'm not going to go through
24 hours of GC logs we need some tooling
to help us visualize all of this so that
we can make some digital decisions or
better yet it'd be nice if we could have
some some smart algorithms that would
run over these things and help us to
understand them okay so some of the
phases that we run into this one is a
very important one with the marks we've
collective is we know this is a precise
collection we're going to find a route
object or what's the other one is known
as an external pointer into a memory
pool and what we're going to do is we're
going to trace the pointers and every
time we you know reach a piece of data
at the end of the pointer we're going to
mark it as being live so I'm going to
basically run this wave through memory
marking all the reachable data are all
of the live data okay now potentially
this is a scan through all of Java heat
to find all of these things remember we
said we wanted to avoid that we want to
break that relationship so one of the
think techniques are going to use to
break this relationship is used to use
these things called our sets or what are
known as remembered sets so for any
region in heap if I have an external
pointer pointing into it I'm going to
record that fact in this thing called an
hour set now there's a whole bunch of
graph theory behind all of this that I
don't want to get into but essentially
what we had in CMS were cards and and
were you going to use cards here also
but the cards are generally the
equivalent of like sparse arrays and so
scanning through sparse arrays is kind
of like
inefficient so what our sets do is they
go through this like refinement process
and with the refinement process what
they do is they I guess create the
equivalent of super knows where you can
get a lot of information or you can
compact things so that you can get to
the information in a more efficient way
okay so that means that every time we
have an object form one region pointing
to an object in another region we're
going to record that piece of
information into cards and then we're
going to have these refinement threads
come through these cards and they're
going to refine this data in the our
sets now these things happen when your
application is running if they don't
finish before collection starts then it
will be the garbage collectors job to
finish the refinement step before it can
move forward okay so refinement sort of
works like this we never find mchugh
broken into four regions and as it fills
up you're going to go into these zones
and as you go into each of the zones and
there's going to be more and more effort
applied to maintaining the our sets okay
now one of the other structures that are
going to be used through these things
called see sets okay this is how we get
predictability I have a pause time goal
I want to meet the pause time goal I'm
going to use the pause time goal to tell
me how big I need to make the collection
set how much data can I collect or how
much how many regions can I collect and
try to meet my pals time goal now it is
a goal it's not a strict limit okay so
first step all of the young generational
regions go into the sea set right now if
that's too many regions for me to meet
my paws time goal as I say too bad so
sad we're not going to meet the pause
time goal during a mix collection what
I'm going to do is I'm going to divide
all of the eligible regions up into a
number of different chunks and I'm going
to have a number of back-to-back mixed
collections which are going to take a
chunk now right now the default way of
breaking it up is divided into a maximum
of eight chunks okay quite often what we
see is that you don't need eight mix
collections in a row to get rid of the
chunks it'll clear them in a couple or
maybe just one mix collection okay so
you know reclaiming memory memories is
like to mark sleep copy capture all the
mutator threads a safe point scan for GC
roots trace all references from GC roots
right and we're going to mark all the
data reach during the trace copy all the
mark data into the two space reset the
supporting data structures replace all
the mutator threads so the parallel
phases in here or external root scanning
right updating the remembered sets
scanning the remembered sets code root
scanning all right so that's a GC roots
that might be actually in our in our
code object copy right so if we're
moving from one region to another the
obviously that's going to be a lot of
coffee costs in there and in nine we
have string D duping I don't know they
had a session on it yesterday evening
Charlie hunt did that where the
explaining like compact strings and what
they're doing to reduce the amount to
string consumption in heap the serial
phase is really going to be the code
root fix up a code root migration
clearing the the card tables choose so
it's preparing for the next collection
well the next next cycle choosing the
collection set reference processing read
during the cars and like at the end of
it will have to free all the sea sets
right so those are pretty much the
phases that we're going to look at some
of them are sort of always seem to be
inconsequential the other ones seem to
be somewhat expensive so this is a young
generational collection again we can see
on the end we have a pause time right
and this one is a wells a g1 evacuation
pauses the known as the GC cause these
are what the parallel phases will
actually look like slightly bigger so
you can just see the ones that I've
mentioned here
and they're going to have a duration and
then a summary so you can take a look at
what's going on as I said before really
you know with these types of things you
you're not going to generally look at
individual log records unless there's
something some real compelling reason to
go down and take a look what we were
really want to do is visualize and
visualize them okay this is starting a
mostly concurrent cycle okay we're going
to start a mostly concurrent mark when
heat occupancy reaches 45-percent this
is different than CMS if you used to CMS
there was a heap there was a occupancy
fraction and and when you reach that
occupancy fraction then you would start
a CMS cycle that occupancy fraction was
just of tenured space this one is of
total heap that's slightly different as
I mentioned before we're going to run a
number of different phases here some of
them are concurrent some of them are
stopped the world the first phase is
going to be an initial mark that's going
to be piggy back into the young
generational collection and then we have
phases that look fairly similar to what
CMS is doing although they're not so
similar but we have a concurrent mark
right so our mutator threads can run
during this concurrent mark the reason
why we can do a concurrent mark here is
because well there's a couple of things
right first from a bookkeeping point of
view we're going to start by taking a
snapshot of what our world looks like
okay now we can mark from there all the
live objects now during that mark this
concurrent mark of course our mutator
threads can make some things dad they
can disconnect them but we're not going
to worry about that too much is the two
ways that these are managed where are
they going to manage that during a
remark phase or we're just going to
leave them there and this was going to
be considered floating garbage the
floating garbage will be picked up in
the next collection so we're not going
to really be concerned about that right
now
and oops some messy messy slides here
but anyways will do see set construction
this is from actually from the ergonomic
setting so you can take a look and see
what's going on here in terms of C set
construction I'm not going to focus too
much on that today right so you
basically hear the the phases the red
ones are stopped the world and the green
ones are concurrent so there's a mark
there's a remark and then there's a
couple of different cleaning stuffs so
stop the world clean and then a
concurrent clean common failure
conditions right so these are things
that are basically indicators that your
collector couldn't keep up collection
ran out of reserve queue right so
there's a reserved spaces in built in so
that so the as buffers are being
consumed during the collection cycles
that you know there's just space there
in case they start to overflowing right
we want to try to avoid or flows because
generally the most common reaction to an
overflow is going to be a full GC and as
I mentioned before these are things that
we want to avoid and there's a few
others here like we can have like again
more buffers that have been overflowed
so whenever you get to these overflow
conditions it generally means your heap
sort heap has been too small okay so
let's look at some tuning stuff now
right for GC logs really what we want is
some tool that's going to help us look
at it right so there's a couple of tools
around here there's HPG a meter which is
a free tool from jmeter it's a fairly
basic tool that will give you some
information it won't manage all the
flags that I've told you to use right
it'll just choke on them there's GC
viewer which is you can get that in
github again it'll manage a number fly
x more than HP viewer but well really my
frustration with these tools cause meat
or motivated me to find the right sense
him and was sent some they've done a lot
of work on the par setters and being
able to deke and manage corruption in
the in the in the in the log files and
just a bunch of other features and
certainly able to manage a good fraction
of the approximately sixty flags that
will alter the format of the GC logs
okay right so flags dozens of them most
of them you don't want to touch right so
generally here's the flags that you
might want to use or should use well the
ones you want to use is like use g one g
see obviously max at the max-heap size
and set the the pause time goal those
are the ones you want to use there's the
a general set of GC logging tools
logging configurations that I would use
as I mentioned before here are some
things that you might have to use but
you probably want to use it so you can
set the region size the initiating
occupancy for action and there's there's
some other things like when adaptive
sizing is deciding and you know how big
or small to make things it has some
limits and one of the limits is how
small can I make it so by default it's
five percent of total heap or max-heap
sighs I found it useful in the past two
to make that smaller and sometimes I
found it useful to make it bigger it
just depends on what you you know what
your particular goals are and there's
also some other information here like I
setting survivor ratios and setting the
ten uring thresholds those will control
the size of the survivor spaces in
general tuning these and CMS was
essential there's no way you could get
the collector to run efficiently without
tuning the survivor ratio and the
tendering threshold with the g1 it's a
slightly different story
flags you should think twice about using
alright which around here is the g one g
see account mixed sorry g one mix GC
count target so that's the number of
consecutive mixed collections that I
would use in order to clear out all the
tenured regions that would end up in the
in the collection set and there's a g1
GC live threshold percentage and what
that does is it sets the threshold at
which a region would be considered ripe
enough to collect so I think the the
values of in flipping now between 85 and
sixty-five percent so you need to go and
check whichever version of the JVM
you're using to know if it's either
eighty-five percent of sixty-five
percent generally you should be always
using the latest build there's still so
many bug fixes and changes going into
the g one that you really really do not
want to be using older versions as a
matter of fact anybody using seven not
on a support contract don't even
consider using g one yet ok and here's
some flags you should never use so i
won't talk about them because you should
ever use them yeah I'll just put them
there because if someone says hey we
should use that you can go flicking
through the slides we'll get them off
the slot you know speaker deck or
whatever like that and you can look at
it oh hold on they said never use this
one of course never is a long time so
there might be some reasons why you want
you have times when you might want to
use it ok so what it was running was the
Cassandra a benchmark stress test does
anyone run this particular benchmark
yeah it's it's a fun one I just sort of
randomly picked one bit because I was
trying to get something that I thought
might work right so these guys spend a
lot of time tuning it to run with the
CMS collector so I went in there and
just as a matter of fact it's kind of
fun to look at that exactly what they
did but they used I don't know how many
flags were in there
there was a probably there's a at least
20 I didn't really count them there's at
least 20 different flags used in there
and I and sometimes I think it actually
might be closer to 30 but anyways so
just just a general overview of some of
the results we got before we start
looking at the answer is why right so I
you know I ran the benchmark the one on
the left is the actually what are we
looking at here because that's too small
to see even for me make it a bit bigger
okay yeah that's the so what I do is I
picked a workload that I said okay it's
a fixed benchmark fixed workload I
should be able to clear this bench this
workload in approximately 15 minutes
okay so the guy on the left on the far
corner there that's a CMS collector and
you can see that with this particular
run you know it was able to clear all of
the workload in the smallest amount of
time all the other guys are different g1
configurations right and we can look at
a select few of them for the remaining
time here right so again if I look at
this particular view here you know what
we can see is that in terms of
operations the number of operations per
second the rate CMS did much much better
than g1 and I could do you know it was
really easy for me to make the g1 really
bad there's some runs up here that I
didn't include that ran for like 30
minutes or longer but there isn't really
much I could do in this particular case
to make the g one approach the you know
approach what I was seeing with CMS and
there's a number of reasons here this'n
this isn't necessarily a bad story for
the g one ok there's a number of reasons
why what's happening but first off this
was a stress test in other words my
machine was able to cook my lunch when I
was running it it was running very hot
and and it was running at about
20 I mean it was running really colonel
hot so he started looking at what's
going on here I found that it was really
bottlenecked on few Texas so if you've
actually looked at Cassandra you would
know that it just burns through locks
like crazy and it's a real problem in
the Cassandra implementation but anyway
so it's burning through luck so so
really what we're measuring here are the
relative efficiencies of each of the
collectors right I didn't actually run
one with a parallel collector but my
guess is with a reasonably well tuned
parallel collector that that would be
the most efficient thing here right
because this is like running a batch job
so and there's no spare cpu so really
what I'm doing is I'm always stealing
from the application okay so it really
says what I said at the beginning right
CMS is more efficient than g one less
overhead in that case right ok so but
it's but it's interesting to see if
there's things that we can do to
minimize the overhead in this case to
try to improve the throughput and as you
can see you know we could get close but
not really you know we're not going to
get there all the way ok so let's take a
look at some stuff here any questions so
far I saw some we put their hand up
which I ignored oh there's just number
of operations per second so basically hi
good low bad right that's about it the
AB the absolute numbers I would not
worry about because it's a the way I ran
the benchmark I could say that the noise
and there is probably enough that you
know the relative rankings are okay but
the absolute value bussche
yeah no sorry you're right so the one on
the left is CMS everything else is gone'
with different configurations I'll take
a look we'll take a look at some of the
configurations now so that you can get
an idea about mm you know some of the
thoughts that went into trying to do you
know when we're trying to figure out
okay like you know what are we going to
do okay so since we have a baseline here
with CMS I figured let's take a look at
that probably what I should do is mere
this in order for need to deal with my
exceptionally bad eyesight okay so i'm
using sense i'm here obviously um sorry
and there's a couple of things that
would want to look at it first off you
want to make sure that ok heap is stable
and this is a really indication this is
hiep utilization after the collection
and you can see that it remains fairly
stable so that's that's a good sign
that's probably something we expected
our allocation rates are generally
reasonably okay they're running around
500 megabytes per second that which is
relatively it's a good rate it's a
healthy rate but you know it's okay
really what we're looking at here is
like what does the pause time picture
look like and the blue dots are the
parallel new pause time so you can see
they're all pretty much banded in here
somewhere between like 75 and like maybe
like 90 milliseconds the others outliers
on our edge but that's pretty much what
we're talking about it's the remarks
that are quite interesting and they
remarks can go up to like 160
milliseconds time right so but if we
look at the summary data over here we
can see that pretty much out of the run
how what was the run time let's just
look at at the results from one the run
time here i think was about 14 minutes
yeah okay this is just using CMS in that
case but oh I was using a much larger
heap to your right in this case um
um actually should do this one here
giving the idea yeah it's 13 minocin say
40 seconds 1339 right so it's just 20
seconds I 14 minutes so and really what
we're saying is i'm spending 56 seconds
total in garbage collection over that
particular duration okay so yeah it's
what's the throughput 93.3 percent so we
generally like that number up over there
to be about above ninety five percent
but you know we'll we'll live with it
given what we're doing here okay so so
when I look at this particular thing you
know with the positon picture you know
pretty much we can see that yeah there's
some fairly long pause times in here so
you know the question is you know what
we can do what can we do in terms of
throughput in efficiency well let's take
a look at are we running out of time
what are we supposed to finish 12 okay
let's take a look at this let's go
actually go back to the slides and
really the the best one is this one here
so this is like the second run so that'd
be like run three let's go over here and
take a look and see what we did in this
thing here right so again like a look at
heap after GC hmm we can see that
there's the blue dots down here like
your mix GC the sort of blackish like
triangles are the young generational
collections and again it seems
relatively stable for the you know so we
don't really have any problem here let's
let's go take a look at the pause time
picture okay and the pause time picture
here is again really really kind of like
really messy but again it's these young
generational collections that are really
messing things up so we're still getting
like some really significantly bad pause
times anyway
anywhere up to like 180 milliseconds
actually I have other runs that are less
efficient that the positive integers
completely brilliant if I look at a
summary here we're spending about 63
seconds in garbage collection time it's
the ninety-four percent throughput okay
so now we should be like going like okay
wait a second the runtime here is fort
is more than what's the difference in
times like four seconds more difference
in GC pause time and we have you know
much about 40 seconds of difference in
runtime to clear the workload okay so
that's not that's not actually the
garbage collector interfering per se
that seems to be to me and this requires
a lot more investigation to figure out
what's going on here because quite
honestly I don't yet have the answer but
it says that there is something else
that's interfering with the with the
application to cause it to run much
longer okay so well maybe it's something
like well you can start thinking about
the implementation at this point in time
say okay okay so what could be
interfering there well it might be the
concurrent refinement threads because
they're taking time away from the
application okay and in actuality what
happens if we run this benchmark with
the concurrent refinement threads turned
off it looks worse so that doesn't seem
to be the problem right and and so we
went through this so you went again went
through this thought process well you
know the first thing I did start
freaking out so I phoned Charlie hunt
and we had some conversations on the
phone Charlie hunt is one of the
performance engineers within Oracle and
he's saying well did you try this or did
you try that and I say well okay I don't
really have any evidence for trying
these things or the other things but any
non is really like looking for what I
say evidence-based tuning certainly in
this particular case here if we look
down to the other phases
the parallel phases you can see that in
here these blue dots here object copy
and as a matter of fact look look at
this guy over here right that is more
than 100 mil 60 milliseconds if i look
at my total pause time for that
particular point that's like 100 80
milliseconds so so that's like more than
ninety percent of the pause time there
is just basically an object coffee okay
so if you want to deal with the positon
problem somehow we have to deal with the
object copy problem if you want to deal
with the throughput problem well in this
at this point in time I really don't
know what to say except for that it
appears to be some sort of interference
in or how hot spot is integrated into
the garbage collector itself that might
be causing some some difficulties which
means we need to go into a different
type of profiling in order to figure out
what that is right I'm sorry I don't
have a good answer for that now let's
say i would say stay tuned right okay so
what can we do with the getting maybe
trying to minimize the object copy costs
well there's something you might be able
to do okay so if you think of this we
have a stable heap that means that rate
in equals rate out right over time which
means that there's going to be some
there is going to be a minimal amount of
data that's live in eden at any point in
time and that probably will remain
constant well there'll be some momentary
localized fluctuations but it should
remain constant over time which means
that if we want to reduce the object
copy time don't copy them as much so
let's reduce the frequency of collection
and see what that does to the whole
picture okay because if I'm if I go
always have constantly of 50 megabytes
live in Eden or a young generational
space right if I'm copying 50 megabytes
once a second or coffee make copying it
once every five seconds by controlling
the frequency of the young generational
collections you know obviously that
should help me reduce my overall
copy costs and we tried that the way we
did that we just said don't let young
Gen or Eden shrink as much so it from
five percent I moved up to twenty
percent what we did was like we
basically reduce the frequency of the
collection right so here's a frequency
collection right now there is a
collection event about excuse me once it
once a second so let's see if I can
quickly find what's going on here that
was run to I'll take a look or is it
pause time picture here no that's not
that one that's we're sorry the run to
as a baseline so all I did was set the
max heap size in this particular case
and run for going to the pause time
picture there's some other things that
we said in here that basically made it
worse i'm just going to run through a
bunch of these here until we get to the
nice one again not a very nice post I'm
picture
um
I'm going to ignore that one right now
it might be right okay so this one looks
peak wise where is so it basically what
you things like we ran through all these
thought experiments and we're looking at
the data and we're like trying to sort
out okay what can we actually do to make
it okay so make the pause time picture
bidders so this one actually you know
we're starting to say ah ok now we got
now we're getting someplace here let's
just keep going through them now yeah
okay now this one is starting to look
really good right no so our maximum
pause time here is like 100 10
milliseconds but the vast majority the
pause times are now below 70
milliseconds okay so let's see what we
actually did to to get this one here so
that was run number nine
okay so let me make this a bit bigger so
we can see and and so so basically the
options here what okay so i set the one
of the things he did as i said okay
let's set the g1 mix GC count target 200
and then let's make the GC pause time
not 200 milliseconds which is the
default let's make it a hundred okay so
so in this case what i was trying to say
is like okay let's not let so many mixed
Regents be added to the cset let's try
to always try to keep the cset as small
as possible i'll allow for a lot more
mixed collections but i want each of the
mixed collections to be as small as they
possibly can be so that's one of the
things that you know these things say in
here and if i go down here what I also
said was like you know what if I want to
reduce copy costs why my copying from
yeadon t survivor spaces are bouncing
data around in Survivor spaces for a
while and then and then pushing the data
up into a tenured space so let's just
tune the tanyard space collector hits or
the the tenured spaces so that I get
essentially no prob I get everything
promoted from Eden to old space bypass
survivors face all together right and
and this is the thing that seemed to
have had the best effect on copy cost
unfortunately as you can see it almost
it also gave us almost a 15 minute
runtime
okay so it seemed with the collector
like it is incredibly tricky to tune in
the sense that when you start looking at
affecting one set of parameters you're
always going to seem to be seemingly
running into something else right that
that comes along and bites you so you
know really you know I guess it's one of
the reasons why we suggest that you know
you don't really want to spend a lot of
time tuning us in the sense that if you
have to start using a lot of switches a
chances are you're not going to get
really really good results okay in terms
of reducing the overheads but you know
but you know the only conclusion I can
say is that you really want to try to
just really setbacks heap size and set
the pause time Golan and not do much
more now this is for this type of
benchmark for different types of
workloads where you do have a lot of
extra cpu there are other things I think
you can do for instance you know I
didn't actually show you the run here
where we're turning off the concurrent
refinement threads but that's something
that we would sometimes do okay
sometimes we turn them back on and make
them work more aggressively especially
we have a lot of CPU okay so you know if
you have a lot of cpu and you can
offload work on to those cpus that
you're not using that seems to be a good
thing that seems to always get us win
that's how we got wins with CMS and that
will work here also okay but if you
don't have a lot of cpus then really
there yeah it gets quite tricky there's
a generally a lot of experimentation
that you're going to have to do in order
to get this thing to run as efficiently
as it will in your environment okay so
maybe not a satisfying answer to the
whole problem but as I mentioned to
people before and we're really just in
the beginning phases of learning how to
cope with the g one g c collector it
took us quite some time about two years
to figure out how to deal with the CMS
collector this one is
much more complicated collector and the
implementation it still is where I would
say it's mostly stable but it still is
evolving which means that which means
that we're still learning how to cope
with this collector and hopefully this
time next year we'll have better answers
that will say really just set max heap
size and go away and then you don't need
to come to g one g c talks anymore be
fantastic we talk about more useful
things but in the meanwhile i guess you
know what i'm going to be doing and
others will just be continuing
benchmarking try to sort of sort of
what's going on and as we get results be
telling you and that's about all i have
to say for today</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>