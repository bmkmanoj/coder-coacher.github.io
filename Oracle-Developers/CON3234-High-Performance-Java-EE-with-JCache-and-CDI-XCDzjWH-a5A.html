<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CON3234   High Performance Java EE with JCache and CDI | Coder Coacher - Coaching Coders</title><meta content="CON3234   High Performance Java EE with JCache and CDI - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CON3234   High Performance Java EE with JCache and CDI</b></h2><h5 class="post__date">2015-12-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/XCDzjWH-a5A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay thanks for coming and we know it's
late and there's beer outside so you
came in preference to that so this talk
is a high-performance jabri with Jay
cash and CDI I'm Steve millage I'm a
founder of pyara I was also a member of
jess i 107 expert group a small member
but i did what did a few comments so I I
know a bit about Jay cash I've talked to
John one before and Jay cash my name is
Jeremy himala and I'm a developer one
move developer's of hazel cast
okay so what we're going to talk about
today so what we're going to talk about
today is pizza delivery so we all know
pizza delivery we're going to basically
show an application that isn't really a
pizza delivery application but that's
the sort of mean that we're going
through so imagine okay you work for
small pizza shop they have an ERP system
that manages pizza order management or
Peter manufacturer my pizza
manufacturing or something of that order
and your boss comes to you and says I
know what we need to compete with those
major pizza conglomerates what we need
to do is we need to create a mobile
interface to our pizza at pizza back-end
that integrates seamlessly with point of
sale in the store via the website so
that you set it so anybody can order a
pizza see their real time status from
the website and get it delivered within
35 minutes and your challenge as a
developer is to build that obviously in
a couple of days probably because it's
just web just bit web interface bit of
html5 fantastic so this is our
architecture that we've been given so as
a Java developer what we have is we have
a pizza store back-end some probably
some ELP system and their provider that
ERP system has nicely given us a nice
java jar file as an api which talks to
the backend pizza system does all the
pizza manufacturer &amp;amp; Order Management
unfortunately from you as a developer
front end or so near the front end is
that talks back head to the pizza store
back in using some proprietary protocol
called the wet string protocol okay so
the problem you have with this protocols
it's not very fast to say the least
so what we're going to do is we're going
to look through a bit of code and show
you the performance of this pizza store
back end now it's not graphical because
it's all html5 so therefore you just
create a JSON service because we're back
end people and that's what we need to do
nowadays which is fantastic my design
skills are poor as you can see so so our
pizza erp system has a sort of fairly
standard standard model we have a
customer entity and the customer has
many addresses and he can place many
orders and he can place them at many
different stores and each store has
potentially dresses more than one maybe
I don't know why and each order has my
lord r items and each order item creates
a pizza so an order item of like
pepperoni madre jack whatever the base
is who knows and that that's the model
that we've been given from the erp
system so i'm going to jump over to the
computer and basically show some of this
code as you would build it in java ee
i'm not going to build this code i'm
just going to walk through what what a
standard sort of jax-rs application
version of this would look like this one
work nope
this one work this one sorry okay okay
hear that
okay so we got NetBeans and we've got a
standard maven project so this this
project you can get from from a github
which the URL will be later at the end
of the presentation but we split into
four maven modules from from our
purposes we have a top level one which
is just three modules very interesting
but we have the pizza connector which is
from our third party okay so that what
that consists of is a an interface which
gives us all our fantastic api methods
that we need to use unfortunately like
many of these interfaces it's been
designed by someone who thinks in a sort
of low-level granular way to find all
the customers brought all the orders and
pizzas for a customer you have to first
find the customer by ID then you need to
get the order IDs for that customer and
then you need to find the orders
associate with those IDs so there's
multiple round trips potentially if you
just want to display one JSON feed of
all the cold orders for a specific
customer and our implementation of that
that they've given us has some latency
problems okay it's as I say it goes over
wet string so our latency problems are
in that it takes over two seconds to
respond so i er p developers managed to
get some sleeps in there ok we just
obviously generate in dummy data
and so what we've done is as Joffrey
developers is we need to create a
restful interface everybody needs to
create a restful interface restful api
onto their erp system so this is our
restful interface so we have a basic
application config we add three
different resources and we've wrapped
the third-party api in a application
scoped cgi beam so we have get orders
for customers so we basically just
completely wrapped the erp systems
interface with a CDI bean and then we've
got some various resources for example a
customer orders resource that resource
standard jax-rs injects the connector be
and basically takes customer ID generate
some json data for that ok fairly
standard sort of jax-rs cgi code so
let's build that code and just build our
wall file
okay so that builds a standard wall and
what we're going to do the do in this
case is because i'm i'm from pyara we're
going to use something called pyara
micro which will mention a bit later but
what it is is a version it embeds
glassfish 4.1 and it creates a
embeddable version or a standalone
version that you can run from the
command line run a while file so this is
basically the code that is going to
bootstrap pyara micro and run that while
file as a jax-rs you can actually do it
from the command line but so we're
basically create an instance add a while
file and then boot the server so this
this double method here is going to make
it find any available HTTP port starting
from 8080 onwards and we'll see why at
the end so if i run that
okay this is going to boot start
bootstrapping in a embedded glassfish
server or pie or a server it will also
bootstrap hazel cast and it's going to
deploy war file so we see we've deployed
a while so let's test the performance of
our newly created rest service so we're
going to access it from / web resources
/ customer orders so web resources is
defined in the application config
basically there and customer orders is
defined by that annotation there okay so
if you run that and it's done it on the
one port you can see their performance
of our web service is pretty poor okay
because we help even though the ERP only
had two second latency on each call it
requires multiple multiple calls to
actually generate the JSON data to the
backend so we have a problem now what do
you do in that situation because you've
got serious problem now you've got
probably a day left to get this
implementation out there you've spent a
day on this swearing at your third-party
developers for the probably about an
hour coded of the jax-rs and so what we
do now is
so just to summarize our problem ok we
have em so we have high latency typical
for any for some api's that you get you
have multiple API round trips over some
wet string we have the wrong data model
and basically our system Collins scale
so in this too costly to obviously
rewrite whole your people reconnect her
in it in a day so anyone experienced
that sort of problem no one like that
except a few mutterings so you said in a
way of Steve considered we have one day
left but according to my experience that
overly you know this overly optimistic
should be our one day after the deadline
that's that's my experience so how do
you speed it up so what we're going to
show is j cash okay Trey caches the Java
temporary caching API and we're going to
use that to to speed this code up so
back to the code
just
yeah never use alt tab to switch JB a
switch virtual machines okay so this is
our this is our code and what we need to
do now is remove the latency so we're
going to just show you some magic first
and then we'll explain how the magic
works so the first thing I'm going to do
is I'm going to find my resource again
just find the right bit code okay so
this is our CD I be and we're going to
add some CGI annotations from je cache
to speed this up so we're going to do is
add cash result okay so we've now added
12 characters to the code and we rebuild
it all
almost remember to
stop are over otherwise I'll get
confused ok so we've rebuilt the whole
project we've added the 12 characters so
we've added cash result and now we are
going to rerun that on pi r microbe so
if I we run that file again
okay so that that's rebooted and deploy
down you are now because it's a caching
API our first calls still going to be
very slow so if you run this again we
get the same initial latency because we
have to go and talk to the back end okay
however the second time we run it it is
now very fast so we can now run the same
rest webservice in sub well I'd on the
timing a few milliseconds let's say okay
not you so that's it you've solved the
problem you can go home everybody gets a
beer we have solved a latency problem in
je cache using je cache and obviously
you don't tell your boss that you put
added 12 characters to the code you tell
them you agonized over it for all those
two days didn't really spend the time
having some beer so actually now now the
question is what the heck happened so
one thing is clear our boss is happy it
makes unhappy probably right so and
Steve said we just could go home and
enjoy our pizza and I enjoy it boss is
happy that's always great I know this
for sure because Steve used to be my
boss but if you are you always told me
two weeks
yeah it was close characters but if you
are like me you know you would like to
know what what's actually going on with
this this black magic because well black
magic is great as soon as it's working
but you know for sake of troubleshooting
it is it's always good to know what is
going on behind the scene so Steve
already mentioned this magic word je
cache which is the main team of this
topic so what is je cache I will
continue with my survey actually I will
ask you can you please raise your hand
if you have ever heard what Jay cage
before this talk cool great so for the
rest of you what is Jake cash is that
you can you can see that as a standard
for cashing in the sense as a jdbc as a
standard to access our database right so
you have jdbc you have this well-known
classes like results at statement etc as
a trunk and you use this regardless of
your actual database you know engines
which we can use it for oracle my sequel
postgres you name it je cache is an
attempt to achieve the same results for
cash shake so is that the API to access
our cases there is one fun fact this API
is what one of the longest-running jsr
107 it started I believe in 2001 and the
final release was just I believe last
spring yeah so I'm not sure about what
did what this says about JCP or maybe I
will not I will not do any speculation
at this point so it gives us API to
access to access our cash it also
defines a standard set of annotation
which one of them is this cash result
connotations to just use so this
notation is from the JK JK Shin stack
and as it has many providers what does
it mean so provider you can see the
provider as you see driver in jdbc work
so one of the providers happens to be
little cast but there are more varies or
a coherence there is an infinite span
from red hat and all they all implement
this JK CPI in there are others as well
and one of the thing is that it happens
to be built into pyara Steve just
demonstrated so really you can just use
this one rotation and it will do this
magic it's still the magic at this point
behind the scene so in order to make ya
to to understand what what is going on
behind the scene ability to understand a
few concepts so Steve prepared is nice
nice picture and I to make it a little
bit complicated for you I will start
from the middle and so one of the term
you you should understand is a cache
which is the thing which you can use to
put something to store something and to
get get to get it back you can see it as
a sort of like a map you know like
java.util.map except it is not so it
does not the interface does not extend
java.util.map for performance reasons
mainly but it tastes somewhat similar so
you have key you have value you can put
stuff in you can remove stuff you can
you know that that's basically like a
map the second concept is a cache
manager it sounds very fancy cache
manager actually you can see there's a
cache factory so when you want to use a
cache where you ask this cache manager
AKA cash factory to provide you one so
this this seems quite clear but the
third concept the caching provider is
perhaps less clear what this discussion
provider well you can see it as a as a
factory for cache manager and
the question is that seems maybe a bit
over engineering factorial factory
sounds very enterprising the reason for
this abstraction is that you can have
multiple multiplication providers in
ciety of JVM so I'm from hazel castle I
don't really understand why anyone would
use more than one caching provider but
I'm obviously and biased so it will you
know caching provide this concept allows
you to have multiple multiple different
implementation inside your application
now finally what was this test result
magic so as Steve shows the few the
quote so he annotated a CDI been with
discussion result annotation it means
that the container which in his case
happens to be para but you could use
other container which supports this
annotation well when he called the bean
para they are entire subject Nicole it
obtained the cache manager from the
caching provider it creates a cache name
based on the method Andy in the class
name so now we have no cash because in
that it did look up from the Arab cache
manager / fish factory so we'll work at
this point we now have our cash then
then it takes the method parameters and
I mean the actual values obviously
because you would want to store you know
you don't want to mixture orders for
different customers so you need to take
the arguments / you know argument values
into consideration and it is a look up
into the cache if if there is it's empty
it means in other than the they are just
started the application it's empty so it
invoked the actual method that that's
the reason why the first run was slow
and well it did put it means the second
run was quick because valid again the
GDI container or para intercepted
intercept riddle method and this
for a second time you get about the
stuff was stored in the cache I can show
you this into the code of pair can you
can you read it this is the actual
source code para PRI uses from directly
from github so this is the important
part so well we have our cache which was
generated it's not actually important so
we try to get it from a crash if the
result is not now that is great we can
directly a regular internet instead of
calling the actual method this part is
not that important now and in the bad
case it means that if stuff is not
stored in the cache then we need here to
call the actual method and then we can
store the result so it's pretty clear
it's basically a standard interception
or pretty easy maybe not clear but easy
the concept is easy this is more or less
the same thing para is is doing or the
way how to how to how to write it you
know by her by hand so first we get our
caching provider so this call caching
caching provider is a part of the Jacobs
pack once we have the provider we will
get the manager then we create some some
cash configuration we can set up type so
we will have a type check you can enable
management je cache specification yeah
and force that every every compatible
provider has to have some management
capabilities basically it means that you
can check your things like cache hits
admits over jmx and also we want to have
some statistics and once we have the
configuration we can create the cash we
create our key and then we store it easy
peasy
now as I said don't pack itself defines
a bunch of annotation so Steve use the
casual result which well it's pretty
self-explanatory but we there are more
so for example you know you know the
saying that there are only two hard
things in the computer science do have
you ever heard this is sentence because
that's true there are in computer
science they are really just too hard
things so the one is how to name things
you know go to how to create good good
identifiers and the second hard thing is
how to invalidate our caches so this you
know annotation cash remove is target
think this this second hard problem or
the computer science so if I have
annotated my metal by the cash removed
then when i call them at all it will
remove the stuff from my cash basic
green validations and I mentioned hazel
cast it's used it's used it's used
behind the scene inside pyara just a few
words I will not talk too much about it
but it's you can see it basically as a
distributed implementation of July you
to collection that's very a simplistic
view but every everyone knows let's say
July little map and inside inside the
Java standard library you have a hashmap
as the implementation of digital map
it'll cast can provide you the same but
it just is distributed it means that you
have to jvm running they form a cluster
you store something inside the map in
one jvm and it will be visible in the
other one but for the sake of this talk
or this presentation just the last point
is important not be much more but DJ
cash implementation so hazel cos happens
to implement je cache and it's as the
first class citizen so yes I said I
other implementation but but now
oh no the bearer does use hazel cast
okay so so the question is really what
is PI R micro so what we've done with
pyara micro is create we taking glass
with 4.1 and we take it embedded glasses
4.1 and we've wrapped that in an API to
allow you to run war deployments from
the command line or embed them in your
co-workers we saw just they're all so
what we've done is we put in full je
cache support so it's for its jess r107
it embeds hazel cast and using the power
of hazel cast it auto clusters as we
will see in a minute so it has a fully
embeddable api and you can run you can
basically run the same way as we did
before without the API just by doing
essentially that so it's designed to be
that's okay it's designed to run just
from the command line okay and it's also
designed for the way the author
clustering is designed for cloud elastic
sort of deployments and basically adding
in hazel cast like its uses that for
session persistence so we can add full
hazel cast session persistence but for
this talk we have 107 out of the box for
hazel cast so we have all the CGI
annotations and we can also as we maybe
see later we can use the full hazel cast
API as well so we do also the problem of
days i 107 is it's a spec and it goes a
certain level and it took many years to
actually thrush out that spec so we've
got a couple of extra annotations which
make it a little bit more useful because
at the moment it's no CDI annotation to
it actually inject a cash in your code
and use that directly through the API so
we've added that into pi RS so it has an
extension for that it hasn't CDI
extension to actually inject the cash
manager as well and we also for hazel
cast people can actually inject hazel
cast directly into your code into your
CD I beans so what does that sort of
mean for our pizza store so we're going
to show now I'm going to jump across to
the computer again is just show these
autocross drinks so let's show how you
would scale now scale your api out okay
that on Sunday okay so
if we go back to a higher micro it
actually killed it off so if we run it
again so go back to our bootstrap code
it's like said pay our micro as a full
it embeds glass efficient as a as an API
that you can use directly from your coat
so if we run first one of these it will
boot with a restful web service and what
you'll see as it boots you'll see some
log messages coming out of hazel cast so
we have basically at some point when the
boot it'll spit out how many members of
the cluster there are currently there's
one because we've run 11 server if you
run it again
we will see it it'll spit out the fact
that it has two members of the clusters
so we can see it flash past there now
we've got two members so just by running
to them together we've got now got
distributed je cache and just for sake
of argument I will run a third one okay
so you can imagine on a sort of cloud or
daca sort of implementation you could be
able to start a new containers as your
as people come online and start ordering
more more pizzas from your brand new
pizza store then you'll be able to auto
scale by just adding additional pyara
microservers let's say we're not
changing only the code it automatically
clusters and it automatically works at
what HTTP address to listen on so we'll
see in in the log that I find it so now
we've got essentially got three members
of the cluster so if we go back to our
API again our restful interface I shall
run that again the first time is going
to be very slow because that cluster has
no data within it
so again it's going to take a number of
seconds and give back the data okay but
now if we go to the second member of the
cluster h81 see that comes back really
quick that's because what's happened is
it's automatically created a distributed
je cache cache and all that data is now
spread between the different and
accessible from all the different trade
cash notes that we've got running so if
we run 88 ajt two not three can see that
comes by fast as well so now you can
once a date is in one of the nodes it's
on all of the nodes that'll do so that
date is also resilient so if we take say
we take down take down the first one
that we run with the first one we hit
you just stop that so if we just kill
that essentially you'll see the other
servers will work that out and
understand that they only have two
members now and they do magic things
that Jeremy knows about to make sure you
don't lose any data so if we go back to
H 82 that still obviously got the data
and if we restart number one again
we'll find out that you know it hasn't
lost any day to do during its brief
disappearance so its up its deploy to
our and we go back to age 80 there it's
got the data straight away so it is no
latency so what so what we've done with
those back to those 12 characters we've
added 12 characters of the code we now
got fully distributed highly resilient
restful interface for our pizza
connector so that's definitely worth a
couple of beers yep there is one primary
copy and one backup by default this is
obviously configurable pardon it depends
on your key so the cash or the
Interceptor is genetic a key and then
he'll cars will distribute the data
among the members according to the key
as a developer you don't care you can
just spray a load balance across all of
them it won't make any difference you
know you don't need to root it based on
key or anything like that
nope well this this demo it ignored the
database totally but Jay cash in the
spec it provides a way how you can
connect your cash and your database so
there's a concept of over loaders and
and and if a good deals right right
writer yeah it's one when there's naming
api's one's loaded one writer otherwise
not reader and writer and loader and
story which is horrible put
you'd have to use probably coherence and
weblogic its key here into the day cash
implementation yeah j groups hazel cast
does not use j groups it has owned on Io
or you know own way how to distribute or
stuff and how to communicate but if you
use for example the infinite span data
use J groups but it's not really related
to the d JK Shin this pack this is
implementation detail of your provider
is configurable as all these things
independence you can have a sink right
behind you can have right through you
can have read through it depends on the
provider what what capabilities they
give you for the cash writer in the cash
loader based on a single
not actually you know I run 33 j3j BMS
yeah yeah sorry my not weak lyrics
Oliver Lee netbeans yeah so there were
three JVM running and each horse running
its own copy of PR so in theory you
could run this load steve was running
this one on one one one vm but you could
run it in no on different boxes it
should make more sense of chili is it
possible to mix there's nothing in the
spec around scopes is just speculate
provides you with the four interceptor
annotations now what whether those beans
are scoped and use different cache name
no probably not no you'd need to create
something separately for that obviously
if you the name generate the generated
name when you just use cash result
without actually you can actually
specify with in cash result annotation
what the name of the cash is that's
obviously set in the code so by default
though it just creates a name that is
some sort of concatenation of the class
name plus the method name plus all the
parameters so it'd be difficult even if
you put that on different scope beans
it'd still be the same cash
sounds like on social engagement to me I
mean there's many ways I mean we're
going to show something called a
listener i'll be using this now no we're
not doing listener okay I mean there are
things called cash listeners where
potentially you can get an event if
something occurs in the cash and that
event could be in a different JVM
process so he could invalidate them that
way so potentially your European update
the cache and that could invalidate if
you want to invalidate or I could update
everything for you so there are so a
sink hooks in that tweet quickly lost
this one more question yeah so it's
possible ne ne you can do a cash pot
from any obviously any other JVM and it
would update and keep the cash in in in
sync in sort coherent state if you had a
it would be due to the configuration of
any database loaders or store or writers
sorry whether that would you know how
that would keep the database in sync but
it'll be possible for the distributed
cache to be in synchronized even though
updates going through in different nodes
that they'll handle all that that's not
problem and the database synchronization
will depend on the provider and how you
would configure that writing and storing
of that data to the database already the
easy way would be just to use some you
know TTL or expiration so you can say
okay I'm I'm I'm fine if if my you know
and trace somewhat also you can
configure your caching provider to well
evict the entry if it's not for example
touched by in last I don't know 10
seconds or something like this so that
would be the easy easy way but there is
a reason why why the cache invalidation
is one of the
two hardest problem okay we're not quite
finished yet so we'll carry on and we
get get to you at the ends that okay
good yeah okay so that things we have
seen so far are pretty much from the
spec but the J cash there is you know
it's the first release of the spec and
if you remember the first 30 s of
example jba people would use you know a
mixture of say GPA annotations and then
some say hibernate specific stuff well
because in the first theories that is
never everything you could possibly need
one first good news is that the expert
group of the j cash was aware of this so
Jay cash itself provides a way how to
unwrap your standard cash from the
Jacobs back and to to use the
capabilities of your underling provider
so you have a way to to access the euro
thing the implement the provider
specific API obviously it means that the
note to be portable between providers
and I could show you this but i will
show you something slightly different
because if you even if you unwrap the
cash and you will you will get the
provider specific capabilities they
still be limited to do to cash in
basically and i want to show you how you
can use against standard in check
annotation to get an arrow access to the
hazel cast instance and use OD all the
structures provided by hello class so
can you can you please read it is
readable ok brilliant so
I will open my resource which is called
custom order resource and basically what
i want to do is I want to monitor the
customers ID so if customer is a
customer is calling get orders I won't
be able to you know to to put the
customer ID into the queue distributed
queue and do stuff to do some analytics
and things like this so how I can do
that so into my custom oil resource I
will let my container to inject hello
cast
this is all standard inject notation
nothing proprietary except of course the
esocast instance itself a link to this
place I can use this as a class instance
get Q and I will call it a customer q
once I have the key
custom cool offer custom ID so every
time a customer call let's get orders I
will get an instance of my distributed Q
and i will put the customer for a
customer ID to link to that cube and now
i will do even more live coding which is
trolling for me so let's try i will
create a brand new project let's say
calm jello one demo je cache
21
i will add to the pendants ease
so one of the dependency is like all the
other one is Jay cash and will create a
new class it's called main
I will create new instance instance get
Q was my cue name I close my ability
customer q yes
customer q and use this great construct
I can
ok so do figured the gods of them like
me let's try it so first of all I will
rebuild this a web application
ok
so starting
okay is deployed so i can try to access
it
it's low because I haven't used this
cached page to result think eventually I
should I should cut the adjacent it's
there and now we can start a new JVM
with just the application i am just
wrote
and
both applications are running hazel cast
member so they will find each other so I
can see that now I have two members and
I have consumed 11 item from the queue
which is in customer one so now i can
change the URL to customer to again it
will take some time but eventually i
should see a new item being consumed by
my consumer services is the way how you
can you know you can access or how can
you use the full capabilities of your
provider together with DJ Kurs from the
spec so you could see it was very easy
mainly thanks to the ability of PR to
inject you directly you're very hazel
cast instance
so yeah customer to was consumed the
item to was consumed from Mike you and I
was very very little coding involved as
you could see
okay so just to summarize basically if
you add 12 characters to your code at
cash result you will remove latency from
all your your all your latency problems
will disappear possibly but to summarize
basically using je cache is pretty
simple is once you have a provider like
say it's Biddle it's built into pyara
but if we get built into all the others
as well and you can actually use the
annotations basically the way pyara
works is you don't need to put this CJ
on a CD I extension into your while file
whereas in other providers at the moment
you will need to put the CGI extension
into your war file well that's the only
thing you'd need to do another another
containers with other providers so using
most of these technologies for example
in Finnish burn or hazel cast or
coherent you can build very rapid
extensible elastic microservices
implementations but and they all have
some auto distributed caching so if you
want more information we put all the
obviously the slides will get sent out
somewhere but we put how to get pyara
where all the codes built open source on
github where to get hazel cast but also
all this code is on my personal get
there and there's a whole bunch of je
cache examples as well on it we're gonna
pay our examples repository ok and now
also if you are even more interested in
je cache just a plug for not my talk but
somebody else's actually in this room in
half an hour after we finish seven seven
o'clock suppose if you're really
dedicated the je cache to Boff is here
which is i think is entitled where do we
go from here ok and that is basically
the expert group je cache to looking at
what do we need to pull in the in the
day cash to API
and I suspect it will also be how we get
Jay cash into java ee 8 so if we race to
if we erased your interest and you would
like to know more both para and hazel
cast and the booth in the exhibition
hall also so just stop by and can have a
chat and you know dive a bit deeper any
question any questions then at the end
yep
it's a bit tricky question or certainly
more tricular it seems so in the jkb
just pack it defines expiration so it's
something very time-based so you can
specify okay I do not want to have any
entry older than X you can do that but
the j cash type it does not specify
eviction so you can't use purely je
cache standard construct to let's say
constant to concentrate your cash to
certain sites but up to my knowledge
every single texting provider offers a
proprietary very how to configure your
eviction so you can you can do that but
you will have to use some you know some
proprietary code which might happen be
just some XML so you will say okay this
cash can't be larger than I don't know
500 megabytes for example so there are
ways but they are not always specified I
believe this will be or should be yeah
the part of debuff which is starting
soon it's a very good question it this
is not specified again in the spec
because the spec really provides you
just API and then it's up to every
provider to you know storage so for
example hazel cars will use just a
memory by default but there might be
another provider which will be added on
disk based so so this is something again
specific to to to the plea provider
um
yeah you mean be honest i can remember
the code i think is cashing the actual
return object I can't remember like I
gotta look but it can just as easily
could return long as I serializable you
could cash the result and pass the back
a complex object
you would have to do that yet yeah
that's that's something you have to
manage yourself and you know how you
build your api's around je cache
in the index pack as I said there is
this management access so you can use
jmx and I believe this is a mandatory
part of this pack so every provider as
to offer some management capabilities
and again there are providers specific
ways so in hit alas there is a web UI
and other others have something similar
as well but there is always DJ Max and I
think they i believe it was quite
controversial to include it as a
mandatory part because you know there
are some simple simple libraries and the
management is not related no important
or needed there but it is it is a
mandatory part of DJ gets back so it's
always there at least the chair max
step 3
yeah absolutely at that first day they
remove the invalidation annotations yeah
so yeah so by default hazel cast will
will always owned by did not always by
default it will have one backup copy so
if you kill pyara which happens to have
the data you are interested in there
will be another PR which has a backup
copy off of your data this backup copy
will be promoted to be a new owner and
see at this point it is the
responsibility of the new owner to
create a new backups but this this is a
configurable behavior and again this is
not you know something in the spec this
is a this depends on the implementation
it's configurable and by default is out
risk or so at least in the case of hazel
cast by default it will use UDP
multicast so so members will discover
each other if they are if they are
running in the network multicast is
enabled alternatively you can use some
well-known members so you can just
configure the IP addresses or you can
use you can use AWS specific discovery
or you can write your own discovery
mechanism so you can use zookeeper move
for the refunds
I would say yes yeah yeah I think so
because I in application server again
it's specific to every application
server how they you know form the
cluster so
okay again this answer has how the
question was how this works if you have
multiple data centers it has two parts
one is Jay cash what is in the spec spec
doesn't know anything about about data
centers it will just give you the API
and it's up to every provider to to do
the magic right so in case of hazel cars
you can use one replication so we can
have two clusters every request running
in one day to no data center and they
will replicate the data don't think it
you could answer this better than me to
declare a scale yes ya mean we have a
Don Paul pie Oracle pie our scales which
is use hey Lucas enterprise which will
give you one replication so you can set
up you can use multiple micros in one
day centre and multiple in micros
another data center and they will copy
data across between but it's all using
hazel cast capabilities under the covers
it's all possible
after no it's not it doesn't stretch the
cluster it'll basically two copies yeah
okay you think we're at a time thank you
thanks having feel good and remember to
press the green button on the way</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>