<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Multi-Region API Design and Challenges | Coder Coacher - Coaching Coders</title><meta content="Multi-Region API Design and Challenges - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Multi-Region API Design and Challenges</b></h2><h5 class="post__date">2018-02-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pZIOPBMxd-I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so we're going to start with a quick
introduction about ourselves we'll go
over what our company does we'll give
you a quick overview of the product and
a basic overview of some of the
architecture for services that were
using we'll dig deeper into some of the
problems we've been facing as well as go
over some of the solutions and
resolutions to finish the talk with a
couple of results limitations and future
directions so I'm sorry
so I'm Reza q-sphere and the principal
architect at hot flow I do a couple of
things I manage the overall architecture
of the product as well as a few
engineering teams including the backend
team the team is responsible for
distributed computing in the cloud as
well as web services I have previous
experience working on modeling and
visualization workstations as well as
large-scale distributed systems for
machine translations
hi I'm Kunal I'm a software engineer in
the backend team with resi care so what
I do is I develop and maintain our
service or micro service architecture
and the associated libraries with that
so my previous experience is that some
Lean Six Sigma with our proprietary case
processing workflow and also a
computational work when I was in grad
school just a quick second something is
it off with the slides
okay good okay so what's hot flow so hot
flue is a software company in the
medical space so we've been founded in
2007 where all of the research lab in
Stanford we're mostly located in the Bay
Area Silicon Valley we have offices in
Austin and Portland and the UK we are
about 250 people and we're still growing
and we have a very very deep expertise
in machine learning and deep learning
medical image analysis biophysical
simulation as well as computational
fluid dynamics but we also have
expertise in large-scale distributed
computing as well as serving customers
in various area of the of the world so
hard flu focuses on cardiovascular
disease so coronary artery disease is
the leading cause of death in the world
and it's still on the rise just to give
you a few numbers the US cost of care
for coronary artery disease is expected
to go over 300 billion dollars by 2030
so that's a very big market and there
are a couple of reasons for out the main
reason is that more than half of the
people who undergo an invasive procedure
to detect coronary artery disease do not
even have disease to begin with so they
didn't even need the test so at hot flow
were focusing on providing non-invasive
tests to understand a bit deeper what's
going on to for a doctor to be able to
assess coronary artery disease they need
two pieces of information the anatomical
information and the functional
physiologic information the way they do
that is by computing a number that we
call the fractional flow reserve that's
basically a different ratio of pressure
upstream and downstream of a blockage in
the Canaries with that number that can
assess if the disease is significant or
not and what's the right thing to do for
the patient the way to do that today for
the patient is to go and get surgery in
a cath lab and I have to follow that
procedure that's the only way heartful
focuses on providing the same
information but they write directly from
CT images we call that FFR CT as of
today more than 18,000
Asians have received the heart flow
analysis in the world our customers are
mostly located in North America in
Europe and in Japan we've been able to
demonstrate that there is already a
reduction in unnecessary invasive
testing by 60% significant improvement
for the quality of life for patients and
a 26% reduction in cost of care for
patients with coronary artery disease so
let's quickly go over what the product
looks like and dig into some of the
architecture for services so as I
mentioned earlier hard floor focuses on
both anatomy and function physiology so
the anatomy is composed of the after the
coronary tree and the myocardium and we
extract that information in order to be
able to identify the regions on the
model where you see a narrowing so where
the vessel gets smaller so that we can
do a blood flow estimation accurately on
that 3d model so the way we actually
achieve that is by retrieving CT images
directly from the hospital and then we
use our proprietary machine learning and
deep learning algorithm to extract a
high fidelity patient specific model of
the heart and coronaries we apply the
laws of computational fluid dynamics to
be able to do an assessment of the blood
flow at each point of the of the 3d
model we deliver back a color-coded 3d
model that can be used by the physicians
to get the right values for FFR CT
dynamically on that 3d model with that
3d model they can choose the right
course of treatment for the patient
whether it's medication a planning a
stent or sending the patient to surgery
to get a bypass
so we're basically a software as a
service company that gets it images from
the from the hospital and into the cloud
we run machine learning and deep
learning algorithms to extract the high
fidelity 3d model we have a team of
people at heart flow that we call the
hot flow analysts
they're basically trained to review the
results of the automation and correct
the algorithms in case of any any
mistake and really get really get to
very detailed and precise 3d model for
that specific patient
we then send that 3d model to a
computational fluid dynamics engine also
in the cloud and we generate our results
of our different mediums and platforms
so we give back to the customer a PDF
report that's helping him with the
diagnosis we have a WebGL application
that 3d model basically that people can
interact with in the web as well as
lately we launched a mobile application
where you have all the same
functionality attempt ok
so let's dig a bit deeper into some of
the service architecture that we have
today so that's a very simplified
diagram of our architecture - for all
the services supporting that platform
currently in the United States so there
are a couple of things you can notice
right
we basically articulated or everything
around that API so we designed the
restful api for the typical reasons you
would do that so there are management
segregations of concerns between all the
different applications using the data
appropriate granularity mechanisms and
permissions and the API is used from the
hospital to be able to push the DICOM
data the city images that we need to to
run our pipeline it's used by our
computing and processing pipeline to
generate our 3d models it's used by all
the different web interfaces that we
have either externally for the customers
or internally for all of the different
hot flow employees whether either a
customer support or team of analysts
DevOps and so forth
one particularity around the services is
that we keep the patient information in
a completely separate database and the
reason we do that is because we are
operating under strict regulations you
guys might have heard about HIPAA for
example and we cannot get that patient
information anywhere else so every case
that comes in we have to take the
patient information out keep it in the
region where the case came from our API
today is written in Python using the
Django retinol framework when it comes
to additional geographies so we're
currently available in Japan Europe the
design is very similar so we have a
central API in that region ok and the
one specificity here is although we keep
the patient information in that region
we actually always send
back the rest of the metadata to the
United States we're gonna get into the
reasons why we're doing that but
basically our original api's are
designed to keep the patient information
in the regions yet provide all the rest
of the information to the US we applied
the same design for the United Kingdom
and for the rest of Europe the reason
why United Kingdom is not part of Europe
is because of break it that's pretty
much the only reason so what problem are
we trying to resolve why are we here
today if you go back at the architecture
diagram we're really focusing on the red
arrow that's that's now being displayed
the the connectivity between all these
different regional API is and the
database has been to us a major
bottleneck and that has been true for a
long time and we've been working at
trying to get a solution for this the
reality is that just to give you a few
numbers the latency between all those
different region is at best over 100
milliseconds and for example trying to
retrieve for us a hundred cases metadata
to serve of different websites takes
more than five seconds so that just
provides a very unusable web interface
it's not acceptable for our customers to
have to wait five seconds to just have a
list of patients to pop up the reality
is that the physical distance between UK
and Europe sorry you can the US or Japan
and the u.s. is a real there is nothing
we can do about that we'll have our
customers there is we cannot bring these
regions closer to one another and we
don't have any obvious way of
redistributing around the globe of data
centers remaining HIPAA compliant
humanely compliant with the regulations
in Japan remaining combined with the
regulations in Europe and be able to
redesign on their product easily and
we're not the first one to really have
that problem
you guys might heard you have heard
about the consistency availability and
partition tolerance or cap theorem has
been introduced about 20 years ago now
try to rationalize the the behavior of
distributed database systems and the
reality is that often cap has been a bit
misunderstood or misapplied it has
always been assumed that you pick two of
those three properties and you design a
system to fulfill these properties
but when you're designing systems to
work globally you obviously have to have
networks you have to handle wide
networks and one should ask himself what
do you really what do you really do in
case of a failure right when you have a
network partition how do you trade off
appropriately between consistency and
availability and if you remember the
architecture diagram everything has been
designed today and build for a
consistency in other words if we severed
the connection between the US and the
rest of the and the rest of the
different regions those origins just
become an a variable hence were ensuring
that we were consistent but our
customers cannot use the websites
anymore cap is however limited all right
what if there is no network partition or
even better yet what about the latency
Khepri doesn't address everything that's
about the consistency latency trade-off
so pasul has been introduced more
recently as an extension or a rewrite of
the cap theorem and I'm just going to
read that here but it's about the
behavior without without partitions so
if you have a partition how does your
system will trade-off availability and
consistency but when the system is
running normally so in the absence of
any network partition how does your
system will try to flatten see and
consistency so basalt really helps you
have a better understanding and picture
around consistency in all situations and
that unifies cap with the consistency
and lattin's it right off you go back to
what we do today what we can tell you is
we're always consistent so when there is
a network partition hot flow remains
consistent and expense is that no our
region's become unavailable but what we
can also say is when there is no network
when there is no network partition had
flow remains also consistent so all the
services need to communicate back with
the database in the United States that's
our master record that's the only way
that you can get the letters us to this
information
but if you do that you have a very poor
latency and this is what we're hearing
today so why did we choose Latins why
did we choose consistency of our latency
the obvious reason like many companies
is that we've been founded in the US and
when you operate in only one country you
can have very good consistency and you
can achieve a good latency and nobody is
already asking that solves that question
however as we grew organically and we
started having customers in Europe
customers in Japan customers in other
regional graph is we just we didn't
redesign our system we just plugged in
these new regions and we assumed that
everything is gonna go fine and now is
the time to rethink that the other thing
is we have as I mentioned a team of
trained analysts so those analysts are
basically processing cases in the United
States and for them specifically we
wanted to minimize the latency so that I
can process cases with the necessary
quality so that we deliver quality
results to our customers the other thing
is just to simplify the workflow we
wanted them to have a unified case list
so wherever the case come from they have
a unique list of cases they need to
process and the easiest way to do that
is by having all the information in one
single location the last piece is that
HUD flows product and business model can
tolerate latency so the image data that
we get is retrieved asynchronously so
there is no you don't need any direct
connection to get like those hundred
megabytes of data sets back into the
cloud so that you can process it the
other thing is the turnaround time for
processing each of those cases so the
time between which will receive the data
we run all the algorithms we will review
manually those algorithms and we send
the results back is ours
so when that is ours it's okay to have a
few seconds or even a minute of latency
nobody really cares they don't zero
information that's pretty much it but
what are we doing today to improve the
latency while preserving some of the
consistency that we have in our product
so I'm going to let me now go over some
of the different solutions and
resolutions yeah so I'm gonna talks
about some of the resolutions that we
did or some of the solutions that we
took to try to decrease the latency in
our regional in our regions excuse me
so the three things that we looked at
application performance and
optimizations application routing and
the last was database replication so one
of the things was query optimizations as
Rosie had pointed out we have a restful
api we have a variety of getting post
endpoints and the issue is that we're
making too many calls to the database
and specifically we're making too many
calls of a database over a large
geographic distance so since we're
making these like n number of calls to
the database all this information needs
to be aggregated at some point so we do
the aggregation right now in Python and
then we serve that information back to
the user so again the goal here is to
decrease the latency on those endpoints
so just to give like a kind of a simple
example you make a call to the API an
API is resource you make three calls
resource of zero one and two and then
you return that information back but
again all of that is happening within
the API itself so since we're using
django django does provide something
like a query set optimization and so if
we look at foreign keys for instance
Django has this really nice method
called select related in which you can
tell the base resource that hey you have
foreign key constraints I have foreign
key constraints on this base resource
make sure you retrieve those when you
get that base resource so when we do
this we only have to make one query to
the database so we can decrease the
number of calls and then we can offset
the joins that we're doing right now in
Python 2 the database itself which is
already highly optimized to do such
operations the second thing is
many-to-many so let's say for instance
we have that base resource and we have
keywords 5 keywords that are associated
with that one resource now in the
previous or the way we would do this
before which is we would make one
separate call for each of those many too
many keywords so that'd be five calls to
the database and one for the base
resource now using Django's prefetch
related we can just make one for the
base resource and then one for all those
many-to-many or in this case our keyword
examples and so we do only two queries
but we do the join in the application
itself so this is kind of like what it
looks like you know feel writing this
out in Python you can get a bunch of
resources filtered on name specifically
example this would be three
bass calls and then using the select
related and pre fresh related will bring
that down to calls so the next thing we
looked at was persistent connections now
our old application would for every
request the API it would open one
connection in database it would retrieve
the information that it needed and then
would shut their the connection down now
we actually just keep the connections
open indefinitely
we never shut them down we always keep
them live so obviously the benefit here
is that we're using pre-allocated for
resources and it decreases our latency
so yeah we make a call to the API that
one call already establishes the initial
set of connections again we never shut
those down but then what happens if in
an instance that one of these
connections you know terminates we get
network glitch or the database decided
to shut one down for whatever reason
some timeout something like that then
what we do is on the next call to the
database or sorry the next call to the
API on API resource will re-establish
all those connections again so the one
thing that we wanted to do here for
these failed state connections was make
sure that in the same request cycle we
reopen the connections again the latency
for that one user for that one call will
increase but at least subsequent calls
after that will already use those
connections so to give you an idea of
like kind of like the number of calls so
these are like the number of calls to
the database from like a regional API
for instance the red being kind of the
network latency the green being the
application plus the database so we
again we're making three calls to the
database with this being the again the
application and the database time and
then after we decrease the number of
calls to so there's an overall decrease
here and we've also optimized for the
query so we've decreased the time in our
application plus our database but the
network latency is still constant right
we're doing it across a region so that's
still a big component for us and so the
limitation again is that geographical
distance so the question we asked was
like what can we do I mean we obviously
cannot decrease the distance between our
regional API is plus our master database
we cannot like we can spend more time
optimizing for this but as you can see
it's such a small component like
what's the point in spending that kind
of time using the 80/20 rule this is
good enough for us so the next thing
that we looked at was application
routing so we're gonna focus
specifically on our post endpoints here
so so when an application or when a user
makes a request to the API specifically
a post endpoint again we have the exact
same issue we're routing these calls
over large geographies here and so we
want to decrease that but also it's
really important for us to maintain acid
and strict consistency as rosie had
pointed out our entire framework is
built around consistency so we still
wanted to maintain that so this is kind
of what it would look like we have Japan
here our master database a call to the
API again we have squashed a few
resources into one database call but we
still have too many database calls we
want to decrease that down to one so we
have to in this case and yeah we want to
squash that down so we have yeah again
the geography here that's the problem so
just to give you a simplistic view of
what the architecture looks like right
right now we have read and writes to the
master database in the US now with our
new architecture we post query the calls
from a regional API to a master API so
we have this now concept of a regional
and a master API here and in doing so we
co-locate the API with the master
database so we're making one call over
the over the distance over from one
region to the to the master and but
we're doing it to it at a co-located API
in master database so even though that
that API make may make like two three or
n number of calls to the database it's
such a small distance that it isn't like
a huge deal for us so we have kind of
decreased these down to here and so
we're again minimizing the number of
calls and since we are post routing
these queries we can still maintain acid
and strict consistency since we're
reading and writing from the same master
database in this case so the next
question you might be asking yourself is
why don't we just do a simple nginx
reverse proxy on this so we have like
nginx on each of our API is why don't we
just put it in a reverse proxy the one
big issue is our pH I database or our
patient information so as you can see we
have always a patient in
in each of the regions and then we have
the master database now the application
and sorry and also that has to stay
within the region and cannot we cannot
move information from the pH I from one
region into another again as Rosie had
pointed out due to regulations of all
sorts of varieties so what we have done
here is we let the application then
decide what it needs to do so it has the
complete understanding of which
databases it needs to extract
information from when to dynamically
aggregate that data back and send it
back to the user
so since this is all like since the
application is completely or
holistically aware of the information it
makes sense to keep a logic within the
application itself and if we were to
actually register endpoints with nginx
and use it as a reverse proxy you would
have to duplicate logic across both of
those components there's no way to get
around just the application handling it
and there's no sorry there is no way of
getting around just nginx handling it it
would have to be split across two
components so this way we just let the
application do what it's supposed to do
so after we have done all of these
optimizations we took in the query or
set optimizations we did the persistent
connections and then lastly the post
query set rerouting this is two regions
so the light is Japan and this is UK the
bigger bars here as you can see are our
regions before we apply to all these
optimizations and then after we applied
them we saw a 30% decrease in the
overall latency and another big
component is that you can see that 95%
quartile there it's been squashed down
to this really small region so now we're
getting more consistent performance from
our overall optimizations of our
application and this is due to again by
decreasing those number of calls over
the over the large geography which you
know if you have like a line that is
super busy it can really increase the
latency times now that since it's a lot
closer this is a lot more consistent
with our what the results were saying so
what about some of the limitations here
so the one big thing that you can see is
that we still
have an address that gets we haven't
done the reeds and that's a big problem
for us obviously and it's still again
plagued by the exact same problem we're
doing again across large distances and
it'll still have the same latency issues
so now we do database replication we
have an API that has a get request on
API resources we still have the same
problem of the large distances between
Japan and the US it's making multiple
calls so let's just squash that down and
co-locate a data source directly in the
region and this is when we introduce our
read replicas so this was the original
design of the API and its overall
architecture and now we co-locate that
data source directly in the region by
doing replication so we have a read
replica now directly in the region this
allows us to co-locate the information
so the API its user the API and the data
source are not co-located and now we
don't have to worry about this large
distance problem that we have and we let
the application again decide how it's
supposed to aggregate that information
so what we did was we built simple
routing mechanisms within the
application to understand all its
different data sources and how to
aggregate the information correctly and
then serve that back to our users so
what does database replication approach
we now have two consistency models with
our overall architecture we have strict
consistency for a post again we're doing
post processing so we can read and write
from the same master database and we
have eventual consistency with our get
operations now I know Rosie had pointed
out that we are always strictly
consistent like consistency is our
biggest problem but with our get
operations we're not producing real-time
data back to the user we have a business
needs that are in the SLA czar in ours
they're not in minutes or seconds so we
can be eventually consistent and the
last thing is that we're using a semi
synchronous replication approach so just
to kind of give you what that is it's
like the slave and the master
communicate with each other to guarantee
the correct transfer of the transaction
the master only populates the
log and it continues a session if one of
the slaves provides confirmation that
the transaction was properly placed in
one of the slaves relay log and the last
thing is that we ship the bin logs over
a dedicated bus so now with the new
replication this is specifically for EU
it has to get operation so these are to
get operations that we do on the API and
pre database replication we were seeing
about six and about three seconds on
these two very particular end points and
now we're under a second after the
replication which is to be expected
since again the data sources co-located
within the region thank you okay so this
is the last part of the the discussion
here we're gonna go over some of the
overall results a little bit of the
limitations of all the different
solutions who have chosen and some of
the future directions so let's summarize
what Kunar described so the first thing
is optimizing the performance of your
services is good it's very good but most
of the time it needs to be done on a per
query basis so it's it's time consuming
you have to go and analyze exactly
what's going on at your application
level you can decrease the the time it
takes for one single resource to process
and go back but the reality is that it's
really hard for multi region api designs
to make a significant improvement and
just leave it there second big thing is
routing of the post queries so this is
definitely a better option as you're
basically minimizing the number of
connections that you're opening to the
database you open those connections only
in the region where there is a variable
you basically reduce your other head to
just one communication instead of
multiple ones but you're still not
really addressing the physical distance
between your original api's and your
main database combined with routing the
database replication is our best option
because you minimize the latency for
pretty much all the different get
operations and you still preserve with
the routing some consistency so we don't
write in the region we don't have to
wait for those changes to be variable
somewhere else
they are always written to the US so if
you go back to the overall architecture
for the services what we basically done
is two different changes
the first one is each of the original ap
is is now routing the queries for write
operations back into the united states
by focusing the cause to our us api
always the second big thing we've done
here is replicating all of the regions
were available in the master database so
that the get operations can happen
within the region and you can reduce the
latency and you can improve the user
experience for your websites because
know this is pretty much regional and
local so where do we end up so what
we've done here is we've taken some
scenarios what somebody would do in our
UI and go through all the different
steps and we measured the response times
in the United States and in Europe so in
the US we are basically seeing here that
the mean response time is pretty much
equivalent right so with or without all
the different optimizations we pretty
much have the same performance what we
can see though is that the standard
deviation has been dramatically reduced
and the number of outliers as well in
Europe though it's a completely
different story
so we've achieved basically a 10x
improvement which is expected since that
there is a variable locally and we're
the more important thing here is that we
have an equivalent performance in Europe
than we have in the US and that's pretty
good for our customers because whether
they are in the u.s. in Japan or in in
UK they can basically expect the same
user experience they can use your
product exactly the same way and some
same small thing as the u.s. your
smaller standard deviation reduced
automatically the number of outliers
okay so now let's go into some of the
limitations and future directions so
we've achieved reading operations at a
much faster pace and that's really good
but the replicated data that that
database instance has become less
consistent the other thing is we need to
handle the replication strategy so what
happens when you have a lag between your
master and your replicas or worst yet
what happens if your replica goes down
or that the replication lag is just not
acceptable well in that case we've
chosen consistency so we're falling back
to our model where we go from that
we'll read from a master API and again
going back to pass all what we've
obtained at the end of the day is a
system where if you have a network
partition and we are consistent but
otherwise we are going back here and
we'll reduce dramatically the latency
for our customers by improving them in
response time on all of the different
operations
the second big takeaway here is that
we've decided to route the right queries
but the master remains physically far
away and that comes at a cost of having
a high latency for all the right
operations but again it's not that big
of a deal for us because all the data
that we write in the region can be done
asynchronously so it's completely
transparent to the user or scanner in
the hospitals or pushing the data and
whether it takes them a couple of
additional seconds or even up to a
minute that's not really a big'un video
however we're implementing a radio right
strategy so what we're doing here is
working on caching all of the different
updates that we make in the region so we
can serve them back directly for
original API so that what you write you
can actually get right away before even
waiting for those changes to be
committed back to the master and get
replicated in all of the different
regions the last piece here is that
we're scaling as a company so we're
having more and more patients we're
getting more and more customers we're
expanding to new geographies we also are
getting into the emergency department
market where you actually need your
results really faster than what we can
deliver today all of those things are
pushing us to decouple origins to end up
having a very highly available system
low latency but more importantly they
are pushing us to understand how we can
manage all these consistencies issues
and how we can build a system where we
can reconcile the data from the US and
each of the different regions
appropriately we said it multiple times
now consistency has been paramount for
us like we just cannot get results wrong
we just cannot deliver things that are
not up-to-date and we have to really
focus our effort into building that
reconciliation strategy we're pretty
much done
so thanks
listening will be around for a question
suggestions just chitchat otherwise
we'll be here for the rest of the day
too
you can reach out to us directly if you
have any questions and thank you yeah
we're not using any Oracle replication
so we're yeah it's it's really the my
sequel replication using bin log so
going back to what Kunal should we use
being log and the real a log and we
that's pretty much how we get the data
into the regions okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>