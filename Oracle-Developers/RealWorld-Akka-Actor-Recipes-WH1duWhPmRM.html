<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Real-World Akka Actor Recipes | Coder Coacher - Coaching Coders</title><meta content="Real-World Akka Actor Recipes - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Real-World Akka Actor Recipes</b></h2><h5 class="post__date">2015-06-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WH1duWhPmRM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is beyond antonsen and i'm a
senior developer typesafe do we have an
echo
I keep hearing an echo here okay so I'm
a senior developer typesafe for those of
you who don't know what type II
cepheid's we're a company that basically
driving the development of the plate web
framework the akka actor toolkit and
Scala language and a number of other
different projects and components and
you don't have to be afraid we're not
I'm not going to show you a nice color
code all the things I'm talking about
it's available as a template or a
project impurity on bar coding actually
so it's everything I'm talking about
it's equally usable from both Scala and
Java and we're trying very hard to make
sure that Java is a first-class language
when it comes to our products so a
little bit about me before I joined
typesafe I I did some work in the
finance and in the gaming industry
they're not that different really and
before that I worked on the j-rok JVM
for about ten years so I was one of the
cofounders of the gyro hmm and so I have
a strong background in concurrency and
low level optimizations but this is
going to be more high-level so these are
the points I'm gonna go through today
what is akka basically just a quick
question here has it have people used
actors and akka okay so there are folks
here who has hasn't read up anything
about actors right could you raise your
hand oh yeah that's that's nice okay so
I'm gonna go through what akka and
actors are in few slides but the
the the session really is about how you
use actors usually a couple of common
patterns for using actors so yeah but
I'm gonna go through what it is and
hopefully you'll I won't you won't get
lost if you sort of think that I'm way
way out there or you're not getting it
just raise your hand and ask questions
in the middle of the talk it's better
than served just to wait to the end and
then there might be not be time so it's
there just raise your hand so I'm gonna
go through what is akka what are actors
and a part about getting into the flow
it's basically there are things that are
different when you're when you're
working with actors since it's a
different paradigm so how do you make
sure that your system behaves you know
in a nice way and getting your messages
across as as well discuss shortly it's
since its message passing you have to
serve think differently again about what
does it mean I sent him a message did he
get it how do I know and then there's a
complete example of how you take these
patterns and integrate them into a
working application it's sort of a toy
application but it has has all the
components of a real application and
it's available as a standalone template
with the tutorial where you can serve
just play with it yourself and read the
description about the different
components and and just walk through it
very easily so what is akka it's a
toolkit and runtime for active
applications on the JVM and its main
purpose is served for you to easily be
able to write applications that are
concurrent distributed fault tolerant
and event-driven this is sort of the way
we think that people should be writing
applications going forward
it has multiple tools for doing this
it has actors futures it's the futures
that are now part of the scholar
language but akka has some nice features
allowing you to easily use these futures
from Java code it has data flow remoting
and clustering but I'm gonna focus
mostly on actors and a bit about the
using the clustering which of course is
built on top of remoting but yeah so
what are actors actors are serve a
different language construct there are
isolated lightweight event based
processes they share nothing they
communicate as synchronously and user
send messages to an actor and it ends up
in the actors mailbox he processes it
every message one time from that mailbox
so their location transparent because
they don't share anything everything the
actor knows about is inside the actor or
if you serve give give it reference to
something in the outside world and you
can't really look inside the actor
unless you do weird stuff yourself and
write bad code so that makes them long
location transparent you can easily move
an actor to another system the rest of
your system doesn't need to know because
they're just sending messages and
getting messages from him and they're
also super vision based failure
management in all of this so when an
actor crashes because it did something
bad
it is the supervisor or the sort of the
parent actor of that actor that takes
care of deciding should this actor be
restarted
should it be shut down or should it just
yeah
continue working as if nothing happened
with the next message so it's it's
you sort of separate the the code that
you normally write around bad or
dangerous calls where you do try catch
to try catch around everything they sort
of separate that logic up into the
supervisor so your actor can basically
just do whatever it's supposed to be the
the code flow is very easily traceable
there's no fault handling in there and
if it crashes it's the supervisors job
to say yeah we'll have to skip that
message and try it with the next one or
whatever so what is an actor good for I
would like to say that it's an island of
sanity in a sea of concurrency some
people say an island of consistency but
if you have done any serious debugging
of concurrency issues where you have
multiple threads reading and writing in
same memory you would probably say
sanity everything inside the actor is
sequential there are no races inside
actor it takes one message from the
message queue called mailbox processes
it and then it either emits messages to
other guys or not and then it takes the
next message processes it it's just very
sequential taking one message at a time
there are no races and nobody else can
look at data inside your actor unless
you hand it out to them preferably
through a message they're very
lightweight it's not a thread it doesn't
have any OS context with it it is
minimal actor object basically that
encapsulate is the data and it's a
message queue and then it's it costs
almost nothing you can create millions
of them or you can create one of actors
say I'm gonna do something dangerous I
create a sub actor that basically just
does the dangerous thing is that if
everything went well it just returns the
result will buy a message and then dies
if it crashes the supervisor basically
you created it will be notified so and
this property of share nothing makes
them inherently concurrent concurrent
that means that you can basically just
run them in parallel because they can't
look at the state of each other they can
only send messages and receive messages
so if I compare actors to objects
they're basically not that different you
can think of an actor as an object it
encapsulates some some data but the big
big difference is you cannot peek inside
it it's closed it has its own state and
you can touch it
you don't call methods on an actor you
only send messages to it you do not get
return values from calls you only
receive messages from an actor so the
internal thread is that the internal
state of an actor is always thread safe
because one message at the time
sequentially so why is this important
then why should I care
the world is multi-core and this slide
serve shows why it is important this is
an Bell's law the expected speed-up of
your program based on the number of
cores you add so if your program is 50
percent parallel no matter how many
cores you add you will never get more
than a two time performance increase so
if we write our code so it's inherently
concurrent easily parallelizable then
adding course will make your system run
faster so what's the catch
well the reel is no catch it's just a
different programming paradigm it's like
when people started out with object
orientations like oh it's very different
yeah it's a slightly different way of
thinking
active programming is a slightly
different way of thinking it's all about
trade-offs some things that are easy
with with normal object orientation are
hard some things that are hard like
parallelizing are easy so you just have
to think a bit different and that's what
we're gonna try to do now getting into
the flow so I do need flow control and
how do you control the flow and then
there's the question if I have a system
sending messages all over do I always
need all of the messages do you have to
serve for every message I received send
a message to someone else the big
question of why do you need flow control
serve comes from the fact that function
calls are blocking in a normal system
you serve I call a function I know that
I will not return until I get the return
value I sort of just hang there until
something comes back that's what it's
seen your in your program flow the fact
that that function call might call
several other functions eventually go
into a database somewhere that that's
irrelevant but in your code flow yes see
I call a function and when I come back
yeah I have a return value but message
sends there a synchronous as soon as you
have sent a message to an actor you're
free to send another message do the same
actor maybe to another guy you don't
know just send him a message it might be
in his mailbox it might have gone out
over the network but you are free to do
whatever you want and some of the
possible problems that come from this is
that you just produce jobs to fast it's
easy to create the jobs maybe you're
doing em I don't know prime factorial
calculations they're taking a long time
but you create the number of the jobs to
do these computations and queue them up
in somebody's mailbox some of the jobs
might need large amounts of CPU
some of them might need large amount of
memory and you're creating multiple jobs
maybe spawning them out on several
actors and they're all running in
parallel you can also have a system
where you're calling out to an external
resource like an Amazon Web service of
some sorts they have limitations you
can't do that too often you have to sort
of slow down your rate to be within the
limit of the external resource or you
can have a serve unpredictable job
patterns where you have storms or
requests maybe your slash started I
don't know you're the most famous site
on the internet for a few seconds and
you have a massive amount of incoming
requests it's easy to just create the
jobs just spawn the spawn the create a
small messages spawn off the actors and
all of a sudden your system isn't that
healthy so the free flow of messages
usually leads to that you're either
blocked from external resources you have
message backup in in the mailboxes of
the actors you're creating stuff so fast
and they can come and keep up and
eventually you'll have a slow system and
possibly even an out of memory error on
the JVM because you've filled up the
heap with jobs waiting to happen
so there are a few different ways of
controlling this you serve have a rate
limiting where you serve push jobs with
but only a fixed amount of jobs per time
unit you can also have acknowledgment
parents where you serve push jobs and
but you don't push more than X of them
until you get acknowledgments that I
have finished a job from some worker and
then you can start pushing more jobs or
you turn the whole thing around and have
the workers basically pull the master
for jobs saying yeah do you have a job
for me and he handsome one so I'm gonna
go through all these three examples
you'll see they're basically very
similar in in the structure but but
there are some differences and they have
a strengths and weaknesses so push with
rate limiting you basically have a timer
that sir periodically sends a tick event
to the master who's controlling the jobs
and once you received the tick he gets a
number of tokens basically the number of
jobs I can produce during this time
period so and if there are no tokens
when he receives a job from the outside
he will queue it in something a
persistent store in memory it all
depends on your your requirements if if
your system is important you should end
the jobs not getting lost is important
to you you should probably persist it in
something durable but otherwise you can
just put it in a queue in in memory and
as soon as there are tokens the the
master will start pulling jobs off the
queue and sending them to the workers so
here we have a master zero tokens and an
empty queue he gets some work puts it
into the queue he gets a tick from the
timer fills up the token count
yeah we're allowed to do five jobs per
time unit whatever that is starts to
dequeue a job and sends it out to work
here
so and the next pattern is push with
acknowledgement it's very similar you
but you create a fixed number of jobs
basically you sort of have a you can say
you have a token camp but you don't have
a repeating job sending you new tokens
instead you as soon as you getting an
acknowledgment from from a worker that
the job has been finished you increased
token count again and if you get jobs
coming in while there are no tokens just
as before you queue them somewhere
because the thing with actors I sort of
forgot to say is the there's what this
one thing you can't really do is block
you should never block there is no
reason you serve just send messages or
receive messages and you store away
stuff if you want to do it later
sometimes you can set up a set up a
timer to sort of send the message to
myself in in a minute I'm not doing it
right now I want to get this message
again in one minute so that's just fine
but you do not serve oh I'm not sure
what I'm gonna do with this right now so
I just block or I call a call a service
that will block because that will sort
of halt all the other because these are
not threads there is nothing in the
operating system that will sort of
preemptively switch between them if you
block all your actors all the other guys
or all your threads running your actors
all the other actors will basically just
sit there do nothing even though they
could be doing useful work yeah yeah
we're coming to that yeah that's the
yeah no problem it's it's it's four
layers or you have to design it around
that because we're gonna talk about
guarantees as well so it looks very
similar you get work you have no tokens
you view the work from one of the older
workers or previous jobs there is an act
that I'm done with with
work right now so the master gets a new
token the accused and sentenced to
worker oh yeah and he acts when he's
done and then there's this or inverted
version of the pattern where you
basically pull jobs from the master so
he the master just accused all incoming
jobs until a worker asks for a job then
it's pulled off the queue sent to that
worker and both would both with the pull
pattern and push with acknowledgement is
that if you if the time for sending the
acknowledgement or the time for
requesting the work is relatively large
to the amount of time it takes to do the
work you can serve introduced lag in new
systems and then you can start using
batching instead or maybe sending out
more jobs than there are workers but
just a few more jobs so you keep their
mailboxes busy so it's or a full so they
keep this instead of just waiting for
the complete round-trip every time so
there's a piece of work coming in it
gets queued and a worker asks the master
is there any work to be done yes there
is work to be done and he gets to work
yep if there is no work yeah then he
won't get in a work right now but this
is also an important thing excellent
question
this is not active polling the worker
basically says I'm a worker I'm
available to do work yeah and that's
registered with the master he will keep
track of the workers system data
structure on the side and as soon as he
gets a piece of work he sort of picks
one of the workers and says here it's
for you
so he doesn't the worker doesn't need to
serve give me work if we work in an
abyss Apollo or anything it's just he
registers for being able to get work we
will also see that in the example later
you can use this mechanism for fault
tolerance as well by by periodically
asking for I'm available for work but it
doesn't need to be often and it doesn't
need to be actively this is pinning so
then their server comes the question of
do you really need all the messages to
be sent to someone else
do you read really really need sort of
everything to happen in these small
chunks and there are basically two
things you can do either you can group
the messages together called batching it
all depends on your use case maybe it
serve the thing that network traffic is
very costly for you you have a slow
Network big latencies then you need to
sort of batch up a number of messages
and send them in bulk or you can do
scrubbing where you basically discard
some of the messages or aggregate the
data before sending them on so batching
as I said you collect number of message
before sending or processing them and
you can either do this by time or a
number of messages or a combination so
it's if I have five messages I send them
forward or if I haven't received five
within a second I basically say oh yeah
I'm gonna forward them anyway but that
basically limits your rate to something
smaller than than the incoming rate and
it's useful for things like right behind
or data base bulk inserts or updates or
rendering gooeys where the action you're
taking based on these messages has a
really big cost so you don't want to do
it one message at the time because serve
rendering a GUI yeah maybe you're
rendering several small lines so you
don't want to redraw the whole screen
for every line maybe you want to say oh
yeah draw ten lines and then I'm gonna
refresh because the user is never gonna
see this anyway or stuff like that and
then they're scrubbing where you
basically discard messages and or
aggravate them and it's very useful for
things like financial data because you
might have a guy with the terminal doing
trades on the other end he really
doesn't need to see all the updates he
really may be as cares about the price
for the last second because that's what
what his human brain is able to process
anyway so you don't have to serve force
all the messages through you can easily
sort of scrub out the data and just take
the last one or you maybe you're
interested in a time series of the the
average over a period of time you don't
have to send out every message but one
every once every second you send out an
average so things like that and then
we're coming to the other thing that
sort of different from from what people
are used to it's getting your message
across and it's split up in a number of
parts when is a message delivered
because this is different
it's asynchronous so when is a message
really delivered to the other guy and
what can you serve expect and then I'm
gonna talk about the fallacy of a
guaranteed delivery what does it really
mean guarantee what what kind of
guarantees do you have and I'm also
going to talk about what akka guarantees
and a thing called the reliable
messaging so when is a message delivered
function calls they basically block
until they're done and you get some kind
of false sense of guarantee that when I
return from this function call whatever
I asked him to do is actually done and I
can proceed knowing that it's safe
message sends they return immediately
so you basically say I'm gonna send this
message to that actor but what does it
mean when is the right point to server
say the message has been delivered is it
when I send it out over the network is
it when I get it on the other machine
from the network is it when I put it
into the guy's mailbox
the actor has served a number of
messages in front of him it's it when he
pulls out that exact message from the
mailbox is it delivered then or is it
when he has processed that message so
the thing here is basically to do your
aking on the business level there are no
guarantees when sending messages you
have to basically know when I send this
message I'm expecting from somewhere
along the line and acknowledgement that
what I asked you to do has been done on
a business level it doesn't have to be
for every message hop it's just serve up
data inventory
yeah it might do several things but in
the end somewhere the update to the
inventory has happened and
want to know about it so for doing
things like that people usually say that
we need guarantee delivery
it's from the enterprise integrated
integration patterns and it's a
messaging system that uses a built-in
persistent store to persist the messages
on the sender's side and on the receiver
side and to acting on all and every
message hop basically so you act from
the producer to the sender to the sender
to the receiver the receiver to the
consumer that's a lot of Acts there is a
thing in a cackle durable mail boxes
where you basically serve persist the
message received by an actor into
durable storage so what if I just use
durable mail boxes I I know that when I
receive a message it will be persisted
but you really don't know if the message
was lost on the wire before it got to
the mail box when is it in the mail box
there are no guarantees that ever got
there there are no guarantees that the
guy is going to pull it out of the
mailbox so you still have to act to be
certain at some level if you use an
external durable message queue they have
lots of nice guarantees but maybe that's
a single point of failure a bottleneck
to your system and when it's the message
in the message queue from the nectar
perspective you really don't know if
you're if you want to make sure that
you're doing this reactively and
concurrently you serve your send the
message you wrap your message queue in
in some kind of an actor and this
message send it is synchronous so you
basically don't know that you have put
the message in the message queue and
even if you block and say I know that I
put the message in the message queue
there are no guarantees just anybody's
gonna pull the message out of there so
you still have some leverage some some
higher-level have to act that the guy
has actually done the work I asked him
to do so
guaranteed delivery doesn't really exist
there are no guarantees that things get
delivered because things break
persistence doors crashes networks fail
servers go down even if it's a very
slight probability that they will
someday they will it's just to serve the
sheer amount of data and the volume of
data and transactions of people are
handling today make sure that things
will fail so you have to design for
failure and resilience and that
basically means that you do your acting
at the business level where it's
important to know that I sent this
message somewhere someone did the very
important thing and has persisted that
to a certain degree of security and then
he says to me it's done so what does
akka guaranty you could argue that akka
has taken the easy way out
we guarantee at most once delivery that
means that your message is only
delivered once if it is delivered you
don't know you have to make sure
yourself this is usually not a problem
in a single in a single JVM set up all
your actors are local all messages will
get delivered but as soon as you do
remoting or distributed computing in any
setting you have no guarantees you have
to build this on top of whatever it is
by yourself we also guarantee that if
you send messages
from this is true of remoting and and
all the different set up if you send
messages from actor a to actual be a
number of message say one two three they
are received by actor be in that order
if they are received you can receive two
three you can receive three you're gonna
see one three but always in that order
or you can receive none at all
you really don't know that's sort of the
the problem with at most once delivery
but the thing with at most once delivery
is that it is really really fast and
most of the time it just works so
instead of trying to build a toolkit
that sort of gives you guarantees that
you can't depend on and being really
slow we build one that er doesn't give
you a lot of guarantees you still have
to implement the same things you have to
do anyway and it's really fast so there
are other delivery guarantees at least
once they will eventually be delivered
but it can happen multiple times
basically you try until you succeed and
exactly once messages will be delivered
but it will only happens once and you
have to build stuff around this you have
to add this yourself and of course they
include aking in some form so this is
reliable messaging with at least one
semantics you send with an acknowledge
and you keep sending until you're
getting acknowledged from the receiving
system once again it doesn't have to be
acknowledged on the first the last
sender and the first receiver it doesn't
have to be on every message hop it can
be at whichever end you like at the
business level it doesn't need to be the
lowest lowest level or there's a receive
with re-request you basically keep track
of the messages and if you miss one you
say hey wait a minute
shouldn't I be getting
this one instead and you will re receive
the messages that you have missed both
of them requires message stores at the
sender to keep track of the messages he
needs to repeat or the messages he needs
to resend and availability redundancy
guarantees that's up to you and your
application for you to decide so this is
send with acknowledge I guess ya might
be missing a slide there this is and we
would acknowledge you have a sender
receiver and your persistent store on
the sender side and basically you
persist two messages you send them over
wait for the acknowledge and then you
write the economic knowledge to the
store this can serve easily be done with
a append only log and you don't have to
sort of do do have it in a normal
database just to serve say that I sent
it I get an acknowledgement and this is
at least once with what I was talking
about you really don't need to
acknowledge at all points you can use a
pipe of actors as long as the pipe is
free of bad side effects it can have
side effects but it isn't something that
should be served affecting your system
in a big way
so the message might come several times
but maybe that's okay to the rest of the
pipeline it's the only the last guy the
the ultimate receiver who serve needs to
acknowledge so we have some kind of
message we persisted we send it over and
get it authenticated it contains you
through information as well
where does some inventory shaking
because yeah and we augmented the
message and a half and we send that
augmented message after inventory check
to the receiver and he
doesn't work and when he's certain and
maybe have persisted some result in some
store I don't know he sends the act back
to the sender and the ACK is written to
persistent store receive would we
request basically you keep track of the
messages you have received on the
receiver side and you need an uniquely
identifiable sequence so you can know
that I have a number X and he's sending
me X plus 2 what happened to X plus 1 I
don't know so same setup we persist the
message we try to send it but it's all
get swallowed in the internet cloud and
then we get another message and
persisted we send that over to the
receiver and he says hey I need
something from you you sent me the wrong
message and was expecting something else
we'll pick up the old message send it
over pick up the new message send it
over
so yeah what yeah and then yeah if the
sender loses one of the messages yeah
then you serve have to decide what does
that mean to your application at one
system we basically serve if if we got a
request for something that was so old
that it was kind of lost because we had
notes that could go down and be offline
for ages we basically just send an empty
sequence of empty messages so it came up
to speed until it got back to serve the
certain point because we couldn't it
we couldn't recreate those and the state
wasn't dependent on those because it it
had snapshots later on so it's you have
to think about these things when you
design your system because things will
get lost and things will be served
crashing and that's basically serve
because the same thing could happen to
your to your message queue and it has
guarantees yes but
yeah no no it isn't that's what I was
saying so if if you're doing if you're
doing all this in process in the same
JVM they don't get lost that's how easy
it is but if you want to distribute your
application the this is sort of one of
the strengths but also kind of a
weakness with akka is it's really easy
to serve take your actors put them on
another node in
all of a sudden you're doing remoting
over the network yeah
tcp/ip is not a guaranteed protocol it's
a reliable protocol but there are no
guarantees somebody cuts the cord things
go down another guy is there and plug in
the cable yeah
messages start flowing but in the middle
you lost messages if you do not design a
protocol on top of it that is serve
guaranteeing that you buffer things on
both ends until you're certain and keep
track of sequence numbers and stuff like
that there are no guarantees in TCP it's
just making sure that the stream I'm
standing now it contains the data it's
it's it's reliable in the sense that it
will know that it failed it will know
that it has dropped packets and stuff
like that but you cannot be certain
special for the last message I'm sending
a message to the other system are you
expecting a reply will it ever come you
don't know if the last message ever got
there because if that guy replies to you
how does he know that his reply got
through to you basically you're throwing
back and forth I got this from you okay
so I need to say and tell you that I got
this from you
there is no the very last message is
never it's serve you you can't decide
yeah so tying it all together this is
basically an example application it's
available as a template that you can
download from the web that uses these
concepts to build a system
it's a example with distributed workers
and have front and nodes getting
requests yeah yeah no no so basically
okay so basically you can do can do this
in different ways either you start
stashing your messages serve it's it's a
it's a pattern where you sort of put
your messages on the side but I would
actually go with this being a corner
case or an edge case I would actually
say oh I missed I have up to message X
please resend everything from X and
onward and then I would just throw away
everything until I read receives X plus
1 and then continuous normal because
it's usually it works so if if this
fails and and and then you might be okay
with it giving you some extra latency or
network traffic
yeah no no no so so I I wouldn't I would
basically serve switch modes of the
actor and and so this is this is where
you sort of change the actors behavior
during this phase where you say I'm I
have only when you receive the first
faulty message and then you say I have
only message X and then you go into this
mode where you basically empty your
mailbox until you get X you don't care
what's in there so you just empty all
the messages until you get the first X
or X plus 1 in this case that you were
asking for and then you go back to
normal
so you won't serve pick up a new message
and say this is a faulty one as well
before you get back to normal no no so
and then you can serve empty your
mailbox until you know it's empty and
then you try to send it again yes I know
this there is a glitch and it is a
problem but you sort of have to design
for for these kind of corner cases and
it's it's might be multiple access but
yeah so there is a there is a corner
case and the thing that will serve
happiness maybe you say I'm we got X and
he starts to resending and say I only
got X again and he resents once more but
then you serve have to deal with this is
at least once delivery it is not only
once delivery if your system can handle
that the same message come
twice then you have to do sequence
number filtering on the receiving end
you sort of persist all the messages
that you have processed and if the same
one comes again you just ignore it
yes yeah yeah yeah yeah yeah that could
definitely be the case that's the thing
I'm saying saying is it's all up to you
it could be that you start just stashing
your messages on the side inside the
actor until you receive the message that
you lost you have to sort of beside when
you write the protocol this is not
something that we provide it's something
you have to build yourself so you can
just ask for exactly that message that
you lost or you can ask for all message
from that and and to now so if you ask
for only that message and the sequence
order is important to you you have to
serve stash away messages until you
receive that and then unstack them and
process them afterwards
if it's possible to simulate in in our
car yeah so yes they're testing
facilities for simulating it's not like
we have a facility for you to sort of
drop certain messages but you can easily
write that yourself by putting an actor
in between your even though you're
sending after in your receiving actor
and say yeah when I'm a dropped message
number three that actually used wedge
him in there is nothing special nobody
else will notice what no no you can do
whatever you want
if this actor is only forwarding stuff
nobody else needs to know they know only
know that I should send to some guy and
he knows I should receive from some guy
they don't need to know about each
other's logical names or anything so you
can basically test it and and we also
have a testing facility for multi JVM
testing where you can basically filter
out messages and slow down the network
and and but that's not a network level
not on the and and basically black hole
the connection so it's it's you the
system will think that the other guy
just dropped out so I think I need to
speed this up a little bit if we're
gonna go through the example as well as
I said it's an example in Java using
using akka to do distributed workers and
we have some kind of front and nodes
that basically receive requests from I
don't know rest service you decide in
this example it's basically just an
actor driving them because we want to
keep it small the master who sees the
works from the front and nodes and this
routes it out to workers and the workers
they pull for work though yeah
and this is available as a typesafe
activator template it's a server
configuration thing where you download
the activator as it's called it's it's
really neat because you can download
templates and it has the build files it
has dependency resolution it if you
don't have to set up this project for
your IDE itself you can serve from the
template open up the code in your IDE or
generate out the project so it's code
and tutorial browser-based
and the template is called distributed
workers with akka and Java there's also
a scholar template for the exact same
thing so depending on your your taste is
you can pick and choose so this is how
it looks like basic overview front-end
notes a master new worker but we have
want to have some more more
requirements or goals here we want to be
able to elastically add removal add or
remove front-end nodes we want to add
remove workers we want this to scale so
we could have thousands of workers and
we don't want our jobs to be lost and of
course it's a tutorial so there are some
corner cases where where it's not
complete like the persistent store isn't
that persistent we didn't want to pull
in extra dependency so it's just in
memory persistence the best kind and
this is how it looks basically the
message flow for for the application
starting up we have worker he registers
the mat with the master saying he's
available for work some kind of work
comes into the front end node and he
forwards it to the master who persists
it an technologists that yeah this work
will be taken care of
eventually the front-end nodes has to
the producer yeah uncle we're gonna deal
with this and then then after the
fronton node has signaled or
simultaneously basically the masters
asks all the workers and by saying there
is work work is ready what sorry about
that
yeah work is ready and then the workers
will basically say I want to work and
one of them wins and the master will
hand off the work that guy and he will
send this work to the work executors and
this guy is sort of living on the side
because I don't know the work might be
might be dangerous you might be serve
doing expensive computations that take a
long time so the worker needs to be able
to talk to the master and maybe give
update progress like yeah the work
execute seems to be running he seems to
be alive so you just don't serve block
the system and the flow when the work is
finally done is sort of the reverse the
work executor sets were complete the
worker sets to the master the work is
done and he gets an acknowledgement back
so to be able to serve scale this and
make it more tolerant we're using a
number of clustered technologies or
patterns they are all built on top of
the clustering their contributions
they're in a package called country so
this is nothing inside of the clustering
itself they only just use the clustering
mechanisms that are available right now
and that is basically a gossip based no
single point of failure membership
mechanism where you serve keep track of
who's a member of the cluster are they
healthy and and in are they joining are
they leaving are they exiting so we have
the distributed pub/sub mediator and
that is a publishable scribed mechanism
that's also you
gossip mechanism where you where you
serve register knowns under different
names and they get properly the meteor
data gets propagated through the cluster
no single point of failure we have the
cluster singleton where you serve keep
one actor instance as a singleton within
the cluster and because you might have
something like the master that you want
only one one guy to be doing but if he
goes down you want somebody else take
his place
and since we have all these workers or
the work executors that are kind of
flaky might be on JVMs or other machines
that go up and down you might want to
add them we have something called the
cluster client where you have machines
or actor systems that are not part of
the cluster being able to communicate
into the cluster so that they can easily
participate but not change the structure
of the cluster membership because that
would serve lead to a lot of traffic if
you want to scale to thousands of nodes
so this is what mediator looks like we
have a meteor actor and all nodes the
master registers himself under some name
in the mediator the front and says I
want to send the message the work
message to the to the master guy I don't
know exactly on which node he lives but
I want to send it to the master guy and
the meteors are forwards the message to
the master as I said completely
distributed gossip based no single point
of failure eventually consistent all the
buzzwords we have a cluster singleton
where you basically have the same actor
on several nodes but only one is active
and as soon as the cluster failure
detector notices that this node has gone
down and it has been removed the standby
guy
B or the the guy running on the the
least oldest system were now the oldest
system because other system when a way
will become the new master who we
promoted to the new master and the thing
here is if you have stayed inside the
master of course you have to persist it
somewhere and that is not something that
akka provides its by itself so you have
to have a persistent store on the side
so this is the cluster client together
with the cluster singleton basically the
guys in the in the in the gray nodes
here they are not part of the cluster so
the worker nodes do not need to
participate in cluster gossip and stuff
like that they just want to register say
hey I'm available I can do work so
they're using the cluster client that
sort of talks to a receptionist that
basically ensures that all messages flow
through the receptionist so nobody
inside the cluster will ever start
talking directly to the to the cluster
nodes or the non cluster nodes they will
all go through the receptionist and this
is sort of the whole picture you have
the front ends talking to the master
through the distributed pub/sub mediator
it should be there and you have the
failover master and and cluster clients
so resources if you want to read up on
this we have some excellent blog posts
pushing rate limiting by Casper Fisher
and pull patterns by both Derrick Wyatt
and Michael Paul mile Paul Meier the
derrick white post is basically the
inspiration for the for the derrick
quite directly and they're quite post is
basically inspiration for the the
pattern in the example we also have the
typesafe activator we just released 1.0
of this it
fully open source as well so it's it's a
I really like it I usually don't like
when people package up stuff and and do
do these kind of things but I really
like the fact that it's taking a lot of
hassle out of configuring your own
project or downloading a project and
getting it to run it's a prepackaged and
it's in the browser and user get these
tutorials together weed with the
examples and there are a lot of samples
but this one is called distributed
workers with akka and Java so go and try
it out and there's also if you want to
learn more about reactive programming
like that's sort of what we like to call
this there's a Coursera course that's
sort of starting this fall and
principles of reactive programming and
it's by Martin darsky Eric Meyer and
Roland Kuhn and yeah I would recommend
it I think it's gonna be really
interesting and that's it for me any
more questions if we have time no we're
over time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>