<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Do Your GC Logs Speak to You? The G1GC Edition | Coder Coacher - Coaching Coders</title><meta content="Do Your GC Logs Speak to You? The G1GC Edition - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Do Your GC Logs Speak to You? The G1GC Edition</b></h2><h5 class="post__date">2015-06-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Miwga8-dx0A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay it's 4:30 so time to get beer right
alright excellent so you enjoying the
conference so far good talks and do we
were you guys at Gil's talk this morning
at the GC collection Scott yeah it's
awesome right it's really fun way of
categorizing collectors um usually like
to start by asking a couple of questions
you know because mostly people are
interested in g1 GC well other than that
it seems to be the future of collectors
not discounting the shenna does anyone
seen the shenandoah talk today oh what a
few yeah that was a rough crowd actually
I think they were being very polite
there was a number of questions that
this magically didn't come up but
anyways we'll just leave it at that
was Pierre was the only one asking the
nasty questions so okay so yeah so it's
the future collections you know you know
what problem is it trying to solve and
you know what problems you have but so
the problems trying to solve is big
heaps yeah whose whose and so the
question is who's using big heaps so
let's start this way who's using a 512
Meg heap or larger you're not you're not
you're not now okay keep your hands up
that's a little that should be just
about everybody so I'm just exercising
your arms right ok so then in that case
who's actually let's get to something
more reasonable who's bigger than 4 gigs
ok well that's good because 4 gigs is
really considered to be a limit for like
a CMS collector yeah anything bigger
than that then you start having to do
things to deal with things right
anybody bigger than let's pick another
arbitrary number like 16 gigs does that
you can leave now it's ok
don't try yeah okay yeah so bigger than
16 gigs just ignore that no it doesn't
include off heap storage you're talking
about you know abnormal spaces where
people normally put things bigger than
32 gigs I'm just gonna binary search
this up 2-0 64 gigs oh these little guys
in the back just put your hands down now
128 gigs whoa okay you three I want to
talk to afterwards all right 256 gigs I
definitely want to talk to you after is
this is really fun it's like how did you
do that right oh you did i awesome
okay since we probably haven't met face
to face before you'll have four you'll
definitely have to come and remind me
I'll take a look I like looking yes I
mean I have a hobby it's not kind of an
odd one but I collect garbage collection
logs that's my hobby and and I have a
lot of them and if you have any that
you'd like to share with me I'm always
very happy to get them mostly because we
write for the tooling company you know
we started in tooling company with
Martin where's disease in the back there
he's got presents for you on the way out
and and one of the things we that we ate
commercialized is really garbage
collection logging blog analysis tools
take a quick look at it a little later
on but mostly here did the other thing
we did was we wrote this other tool
called illuminate which is what I'd like
to call a intelligent diagnostic engine
so it's not really a profiler it's
certainly not a p.m. but it's something
completely different so we're having a
version release very shortly so when is
it you don't know
okay the CEO doesn't know so we're well
organized okay fantastic so you can go
and check it out if you want anyway so
so much for the commercial what
do I do
consultant performance tuning co-author
Java forum Singh Kham with dr. Ozzie
he's now doing wonderful staying a
wonderful job with that
a bunch of other stuff you can use
Google for Madhu training there's my
wife at near our training location in
Crete so it's quite fun we do that with
Heinz kibbutz and write standard
disclaimer the resemblance of any
opinion recommendation or comment made
during this presentation to performance
tuning advices merely coincidental so
I'm going to tell you a lot of stuff
here to know if it's going to work for
you right take it home
test it kick the tires on it because you
know performance tuning is a response to
a highly localized condition like my
local locality may be different than
yours so you really need to test and see
what's going on here okay first question
probably don't have to answer it but you
know why collect you see logs any idea
mm-hmm why not perfect that's yeah I was
thinking of wearing my chicken shirt
with the question why on it for this one
but anyways and because this this is
really what I call one of those key
performance indicators if you want to
know how your application is really
behaving you're the one way of figuring
it out is to see how it's irritating the
garbage collector jaw or Javas memory
management right and there's a couple of
different directions you can go to fix
things one is like you finally fix your
application or or you might be lucky and
you might be able to tune it up by
setting a few parameters in in the JVM
right so the next question people ask is
what is the performance impact of
logging GC and production and the answer
always was none there is absolutely no
performance implication of logging GC
and production but then we hit these
wonderful virtualized environments that
turn disk calls into Network calls for
applications that are already bot elect
on the network and of course turning on
the GC log is again you know your
mileage may vary on this right but
generally you can leave them on in
production and they tend to leave them
on because they really are a key
indicator you can tell all kinds of
things by looking at your applicator
looks especially if you look at enough
of them across the number of different
platforms how do I get a juicy log well
you're probably all familiar with some
of these flags here I won't get into too
many details you can read them on the
slides right now a long time ago in a
JVM far away we used to have this
actually still have it's like a
generational collector and really you
know there's a lot of assumptions that
were made and to come up with this
particular structure one is about the
lifespan of objects most objects live
for a few microseconds or maybe even
less right or you know certainly not for
a very long time most don't make it out
of the CPU life right they still all
have to be written back into into the
heap memory but when they get written
back they'll we will put it into Eden
right so you know everyone I think is
familiar with this thing called
mark-sweep right yeah no you're just
saying you are familiar with mark-sweep
excellent okay I'll give you can do this
part then that's good so you know I want
to try to go through this part fast but
if anyone really wants a slower
explanation we can do that also but
anyways to get to the interesting part
with them but the point is is like you
know the power of this thing is that you
know when I do a young generational
collection so that's like everything
from the green line to the left right
the only thing I'm touching over there
are our live objects and since most
objects die young then we get a huge win
by segregating all the young guys on
young objects in that particular section
and then only dealing with the the young
objects right and we'll just do not a
mark sweep in the sense will do a mark
copy
so we'll just either you know find the
live guys evacuate them out to someplace
else and that's pretty much how it works
yeah you leave the that you leave all
the rubbish behind you reset a pointer
you know life is good there's all kinds
of other optimizations that fall out of
that yeah and then you know so that's a
simple structure underneath there
there's some more complex structures to
deal with concurrency and all that other
stuff okay a little bit beyond the scope
of this talk right
you know so when you start a garbage
collection well you meet some condition
that's going to trigger a collection
cycle the most common thing is you've
run out of memory every well sorry you
have an allocation failure one condition
meaning that you've run out of memory
completely the most common I think way
to trigger a garbage collection is you
get an allocation failure due to
fragmentation right and that'll cause
that'll start a collection cycle so the
first thing we need to do is we need to
find all these things called well sorry
before that sorry the first thing we
need to do is we need to bring all your
meat mutator threads to a grinding halt
and we'll do that with a safe point so
there's some discrete point in your
threads life that I can safely stop that
muck around with something underneath
all the data underneath it right and
then let it continue on and it's going
to work with a you know being corrupted
or anything like that so I need to find
all the GC roots and then I need to mark
all the live objects by tracing I start
from the GC roots and go forward and
then every claim and you evict all those
survivors places into something else
right then the hard part right I need to
find everything that was pointing to
this thing since I moved it I need to
fix those things so they're pointing to
the right thing so I don't have any
dangling pointers anymore right so if
I've a pointing to B and I move B then a
is pointing to find it and then fix it
right that's what Shannon Doe is
supposed to look after and look after by
having this double referencing Brooks
pointer arrangement where basically they
would leave a forwarding reference okay
and then you know that at some point in
time they'd read recognize though the
data is not really there it's like over
there yeah and here we're actually going
to search for it okay so I started to
describe what a safe point is it's
basically like I said point when thread
execution can be safely halted
interrupted and the threads are gonna
remain in this state until the garbage
collector says okay you can go forward
right now it's not only garbage
collection that calls for save points
there's all kinds of other things a call
for save points that's a bit
than aside if you want to learn more
about them then I think John Carson is
giving a great talk on what makes your
JVM halt tomorrow
it's obviously not the right title but
something along that lines things about
11:30 anyway so you can learn more about
that there but the point is this is a
cooperative process in other words the
garbage collector is gonna say you guys
need to save point and some point in
time there's you know there's this like
your teenage kids yeah I'll clean up my
room sometime right or wherever I'll get
to it and you know so they eventually
have to arrive at a safe point and when
they get is everybody is at a safe point
then the garbage collector can go all
right and there's all kinds of problems
with frequent safe pointing these are
problems that you may not be facing
today but I'm sure you'll be facing them
in the future we've already had
discussions with the hotspot team about
the the damage that frequent safe
pointing can cause okay next question
okay so what's a GC root well there's
two types of pointers its external
pointer is an internal pointers and the
external difference between the two is
you know who's holding on to the pointer
are you inside the pool that were
interested in or are you outside of the
pool that we're interested in if you're
inside or internal if you're outside
we're external so we want to find all
the external pointers now in some of the
collectors we're going to do what's
known as a snapshot at the beginning
right so we're gonna capture all the
pointers and then what we're gonna do is
we're going to move one step forward so
we're going to internalize all our
external pointers and then we don't care
what happens to the outside world well
you know we don't really we're not
interested in any more we just care
about what's happening inside the box
inside the memory pool that we're
collecting and and that allows us to
become partially concurrent there's some
techniques like that right it's so we've
there's bookkeeping that goes on to
allow collectors to become concurrent
anyways so you know you know the
question is okay so so where where the
where do we gotta go to find these
things oh there's a whole bunch of
different places you can lurk stack
frames locks data structures registers
perm
any other memory pool and and you know
this this is really the collector that
we've been playing with for for for
quite some time you know so what's in a
pause safe pointing that's 2x context
switching scan for routes mark
everything reachable sweep which is a
copy and implied compaction right and
then basically Swizzle all the dangling
pointers right so you know and this
works well until you get up to four gigs
right as soon as you start getting
bigger and bigger and bigger and bigger
heaps you start having to scan more and
more space to find all of these GC roots
so they don't really want that so they
come up with other structures too to
cope with that and that's called a card
system so we're gonna record pointers
from one pool to another pool like
incoming pointers into into this card
system so that we can just look at the
cards instead of scanning all of heap
for these things but we still have to
scan all the cards and all these other
things and and the more memory you get
the longer this takes so we get a longer
longer pause times and all sudden the
pause times that we're seeing becomes
unacceptable you know for Fourier
application it becomes disruptive to
your applications ability to serve your
customers okay so that's one thing the
other thing is some people question the
validity of what's known as the weak
generational hypothesis and the weak
generational hypothesis is what I stated
before you know objects don't live for a
long time they tend to about to die very
quickly if you cache a lot of data and
you retain all of this data in cache
then basically you're creating a lot
more work for the collectors you're
adding to the life cycle of the odd the
lifetime of the object so you're adding
to the life cycle cost of maintaining
that object in memory so in this case
caching is not a very good thing for
garbage collectors they don't like
caches right if you get into medium
sized objects things that live just for
long enough to get promoted from young
into tender and then die then that's
really really bad also because that puts
pressure on the tenured space and that
means that we get the full garbage
collection happening and when we get
into a full garbage
election go back to this little diagram
here just show you what's going on that
one over here tenure right
we don't have an evacuation strategy
here anymore right so now I got to do in
place compaction I got to do free list
maintenance alright I got a more
expensive allocation over here and I got
a whole bunch of different problems that
I over here that I simply just don't
have over here right here I you know
here I can do all kinds of tricks to
make allocations very very very cheap
and over here you know that all of those
tricks all of a sudden they're taken
away from me
right so you know we end up with this
you know Oh with a whole bunch of
problems and things that said okay we're
not going more than four gigs right so
so you know what are we gonna do well we
you see this idea we have these
evacuating generational collectors seem
to be very good at ignoring dead objects
not so good at ignoring live objects and
that's a problem because as we our live
objects that size grows our scan times
and our the work that it has to do sis
keeps going up and up and up right so
the question how can we maximize our
minimum mutator utilization that is how
can you give our application threads the
maximum amount of time we were gonna
guarantee they get the maximum amount of
time right we want to basically minimize
the time that the garbage collectors are
getting as opposed to what our
applications start to getting sorry so
and we want to do this so that you guys
can use like 200 or what did you say
three you put your hand down at 256
right it's a massive heap it's a massive
heap but you know we already have people
who are in 512 and planning on one
terabyte it just seems stupid but you
know that's what they want to do right
so we want to disentangle pause times
from heat size ignore long-lived objects
so we want something that said you know
what this thing's been around for a long
time I don't want to bother with it I
don't want to interfering with my
collection time for so so in comes this
idea of regional collectors not really
new idea but you know we finally get
some implementations of it
and the regional collectors are Oracle's
g1g see in the garbage first garbage
collector IBM did a implementation based
on balance we have Azul c4 which is a
regional collector and we have the red
hatch shannon TOA now I said regional
collectors sort of because the Oracle
g1g see the are fairly early on the
development said you know what the
optimizations we can get from being
generational are so powerful we just
believe that we are going to that we
can't ignore them right so we're gonna
make the gene ones you see it like
hybrid regional generational collector
okay so you know what so what do these
things look like well the first thing I
need to do is I'm gonna take all of heap
and I'm going to divide it into
approximately 2,000 uniform sized
regions the regions can be any one of
those particular numbers in terms of
megabytes by default it's one megabyte
okay
and you know I can configure with that
particular command-line switch there you
guys all know where to find command-line
switches yeah yes sir good question I
don't know it's it's not it really is an
arbitrary value and I guess I guess they
didn't feel there was any reason to have
a 64 make region at the time but you
know I guess we didn't need more than
640 K of RAM either so you know who
knows right that's sort of an old joke
ok ok so so we got this thing that looks
like this greedy thing right so we're
gonna take all these regions put them on
a free region list and then when we
start allocating what we're gonna do is
we're gonna say okay I can allocate into
an Eden region so I'm going to go to the
free list crop region tag it as being an
Eden region and then start allocating
away in it and as you can see there you
know unlike the generational heap
structure you know the Eden region
doesn't have to be contiguous so you can
just be scattered all over the place
right so we have you know the familiar
things here we've eaten
survivor and old and then we got this
new thing called humongous and for the
non English speaking people I had to
come up with the definition so I just
came up with like really really really
big because he among this isn't a common
a common word in non-english speaking
places right so anyways yeah so we're
just gonna grab whatever we need and
take it so what do you mean what do we
mean by humongous well it means that
anything is like 50% the size of a
region or up to like over 50% of size of
the region what we're going to do is
we're going to take a number of regions
and we're going to put string them
together and we're going to do the
allocation in that humongous region this
does present some problems yes yes as I
said this presents some problems the
humongous regions must be contiguous
sorry
yeah it's okay no ask questions where
whenever you want to and help me out
very happily answer them sorry for a
single for a single allocation yes and
if you can get more than one allocation
any humongous region apparently that's
that's good also yes sir
no humongous is humongous it's not eaten
it's not old it's not survivor okay
yes sir I yeah I think about 2,000 no
yes it's a rather arbitrary limit yeah
it's I don't there might be a limit I
don't know of one personally and I don't
think you can allocate something that
big I mean realistically what you're
allocating here are large arrays right
and we're limited by max int unless Zul
what
no that's net maxint oh yes right of
course yeah perfect yeah minus 2
yeah to be completely correct yet yeah
it's all arrays are always - - because
you need they have to they throw away -
for the keeping the length right okay
say yeah this Weaver yes you're right
times eight good good point and it's
times eight only if your alignment is
eight and you can reset the alignment so
it could be x 16 or time so easy I know
when they're talking about compressed
oops right and heap size and stuff like
that right it's like you're 200 gigs
right you're there's no way you use your
not using compressed oops this is like
it's off the table I mean as soon as you
get to 28 gigs you're not using
compressed oops unless you start doing
play games with the word alignments I
can tell you I talked to the Oracle
engineers in st. Petersburg they're
doing all the performance testing is
that they can't cannot get a benchmark
to pass when they start making the word
alignments much bigger than 16 or 32
they tried with 256 the benchmark fell
over almost immediately right so if you
start playing with word alignments in
your application I assume there's gonna
be some interesting performance
degradation that means that you're
probably not going to want to use
compressed oops at all just take the hit
yeah for those of you who don't know
what compressed dupes are I mean that's
just a way of encoding addresses so that
you can use you know 32 bits instead of
64 bits and this so they do some tricks
to to make all that happen okay right
where was I okay now the thing with the
g1 collectors what they wanted to do is
they wanted to make it easy to tune like
very easy to do they wanted to make it
somewhat predictable as much as you can
make a collector to be predictable it's
surprisingly enough you can make it
predictable under certain conditions
like we also I'll show you something at
the end or closer to the end that that
that that was interesting
in order to make it predictable you know
that there's there's a whole bunch of
different things there are structures
that they put into here to help the
collectors decide how much work they
have to be doing or how much work they
can do in order to meet some of these
performance targets okay well we got
oh yeah reagent sets did it cover that
yes unused Eden survived or old monks
okay we're done there do I cover enough
fund everybody understand humongous
right big allocation typically erase
sighs okay no problem okay next thing to
do is look at these things called
remembered sets okay so you know we had
that scan for route problem right
because we had to go find like all the
GC roots well I mean so if you're in a
200 or 400 gig heap that could take some
time so instead what we're going to do
mm you know this this is sort of the
trick that the shenandoah guys are doing
what they're working on right is to get
rid of these things and do something
else but here what we're gonna do is
we're gonna have a set of cards so we're
gonna have one card for each region and
we're going to put all cards into an R
set so that if anybody is pointing to
something in my set then they're going
to record that fact in the other
remembrance set so there's an overhead
for doing this it's approximately a 5%
of memory and there's a write barrier
and we can have all kinds of arguments
as to what the right barrier cost but
you know you know there's a cost that
and there's also an indirection costs to
doing all this okay when it comes to
collecting right we're gonna do or
basically and do the same mark sweep
type things that we do in the other
collectors but we're not going to do it
on the entire heap space what we're
gonna do is we're gonna build this thing
called what's called a collection set
right and in this case what we're going
to do is we're gonna find all of the
regions that are quote unquote right for
collection right they're going to be
easy to collect we want to collect the
easy stuff
first yeah empty is trivial yeah
it goes back home free list almost empty
is cheap full is expensive so you don't
want the full guys we want the almost
empty guys and the empty guys alright
those are the guys we want to deal with
deal with so we want to build a sea set
that goes like that hello
so we want to build a cset oh the
projector went off ah awesome thought it
was my fault okay
oh I've been breaking things today yeah
so this is now your time to either ask
questions or escape whatever suits your
fancy
okay yes well then you get larger
regions yeah
one way doing it or you have more
regions is the other way of doing it so
no no no they're just all of this stuff
is highly configurable as I asked the
question before does anyone know where
all of the how to get it the the jvm
flags one two oh yeah okay Pierre tell
us I know you've been dying to say
something talk to them nothing here yeah
so translating that to English its
global to HPP and they JDK yeah down
just go to the download the JDK source
or use what's up does tool they have
like a source tree or source phone
there's the you know not make euro sorry
that you can just find them online by
just searching and the all the source
code comes up in what page isn't it
source view or something like that oh
yeah it's very pretty
it's very nice yet you get one line of
gibberish so yeah no no the explanations
are actually not too bad you're they're
not overly verbose but you can sort of
sort things out from that most of the
flags you don't want to touch anyways
right because there's as I like to say
there's I don't I don't even think God
knows what will happen if you touch them
and certainly not when you put them in
combinations with other things okay
yeah so keep your mitts off the flags
don't that's
they say okay so infuser okay so where
were you oh yeah okay
so what we're gonna do is build this
thing called a collection set so since I
can get an estimate as to how long it's
gonna collect each region I can give it
a pause time goal I can say you get 100
milliseconds no more so I can build my C
set out to 100 milliseconds now this is
a goal it's not a it's it's a guideline
it's not a strict rule okay so what goes
into a C set the first thing that goes
into a C set there are all of the young
generational regions and then maybe
you'll get other stuff okay except for
humongous humongous is a problem you
guys are probably suffering from you
humongous problems yeah no yes yeah I
figured as much everybody is everybody
does anything serious like that suffers
from humongous problems well we'll get
into that in a minute yeah let's go okay
so so if you're if the work you need to
do to clear out Eden is more than 100
milliseconds well you know that's life
it'll pause is more than 100
milliseconds that's all you're gonna do
okay so let's go through what happens
here right so what we have is we have a
young generational collector which is a
mark-and-sweep
so we're going to take all the young
generational regions and we're going to
mark them and then no this one's not me
let's go to something else mice must be
overheating or something like that
anyway so I can hand wave this and we
will go on from there that the the so
what happens with the mark-and-sweep in
this case I'm going to build my
collection set and I'm basically going
to do a mark and sweep and it's not
really sweep in this case it's a mark
evacuation so I'm going to evacuate into
survivor regions or into tenured regions
depending upon you know what the target
is yeah and then there's gonna be these
things like what we call like per region
evacuation pause so if I go into a
region mutator threats cannot get into
the region yes sir
the point on the slide which was yes yes
good question
and I will get to it in a couple slides
in terms of there's some flags that you
can do to set the threshold so either up
or down and some default settings saying
like you know what they what they like
in terms of occupancy so okay so you
know so like I said we're getting a
mark-and-sweep in a young generational
space right we only get a mark in in
tenured space part of the process of
marking is we're going to calculate a
liveliness factor right so I'm gonna see
what the liveliness is in each of the
regions then I'm gonna sort by
liveliness okay if you're not at a
certain percentage of liveliness
we're just you're not in the list okay
you get done later so the you know the
idea is that you know if you have lots
of cash things in this case and they end
up in the same region right then you
don't really want to do anything with
that region anyways so we're just we're
just so all we're gonna do is like go
through it say okay not a candidate
throw it away we don't want to look at
it and no one's gonna bother with it so
that's really the theory behind there
right oh we're back excellent okay so no
much just safe say about that what if I
missed here so the mostly self tune you
give it a max-heap size specified the
pause time over an interval and then
everything else should adapt that's the
theory yeah
right and we get this one one half
collector type thing we get a mark sweep
and young and a mark only in in tenured
space fully evacuating so there's no
need for compaction okay so this is our
ug c large speaking to you so let's look
at a GC log right so this is a what I
would call sorry don't worry if you
can't see it in the back don't strain
your eyes too much we'll go through a
bit by bit but the but the point is is
that this is what I call a reasonably
detailed GC log entry for a young
generational collection okay and there's
a whole bunch of bits of data there
so let's start at the top line and the
bottom line and just go through it right
so this is saying the the life of the
JVM there are the age of the JVM when
this record was take it was produced was
thirty point six oh five seconds right
we can add a date there if we want but
let's not worry about that so this is a
g1 evacuation pause and it's caused by
well it's a young generational
collection right and we have like three
something-something milliseconds of
pause time okay then there's a bunch of
little records in the middle you can
talk about them next and that's just
that's giving information about what
half what's happening in the survivor
spaces right so the life cycle is we go
young survivor tenured yeah with a
little bit of bouncing around and
survivor until we get to tenure now so
this is a desired survivor space sighs
it's really actually we probably should
a patch in here and actually say what
this really is this is a desired
survivor occupancy after the collection
if if the number of bytes that you want
to fit in there exceeds that threshold
then we're gonna take the excess bytes
and we're gonna push them into tenured
directly okay hopefully we do that by
age but there's some doubts on that but
anyways here's here's some totals here
that basically said at age one we have
this many bytes so it's a yeah what do
we mean by age well age is the number of
collection attempts you survived okay
so at age one we have this many bytes at
age two we have that many bytes at an
aggregate we have that many bytes that's
less than this so life is good on the
command line I said my tenuring
threshold was 15 actually that's a
default value after years of arguing we
finally got them to set a reasonable
tenuring threshold at least for this
collector for the other ones that still
six or eight or depending on which
version you want
generally this is one thing you want to
set rate at the beginning just set it to
15 it opens things up when things are
opened up you get a clear signal about
what's going on in your JVM
and afterwards you can make some really
informed decisions as to how to shut it
back down okay but if you shut it back
down then do your data is going to be
disturbed by the by the size of the
space and you really can't make any good
evaluations after that right okay
anyways so max 15 it's hot spot here's
calculated the threshold should be 15
everything is good you know with CMS
when we roll this back so that's less
than 15 and we prematurely promote data
into tenure space that's generally a
problem because premature promotion
causes extra pressure on tenured and
that means that we need to collect that
space far more often than we should
that's a sign that we need to do
something in their survivor spaces in
order to keep retain that data down in
survivor spaces longer okay now yeah
I'll talk about the rest later
the goofy bits right okay we go to the
bottom and really what we're getting
seeing here is we get occupancy heap
you know region size afterwards right so
in this case we're saying that the
occupancy was full right and then after
the collection of course Eden should be
completely evacuated so zero should be
the N number there and what it did was
it actually shrunk eaten in this case
and isn't here it has four regions and
over here it left it with two regions
okay which is really cool yeah that's
what we that's what we wanted to do we
want it to be able to adapt and this
this collector is very highly adaptable
to different conditions and you can see
we do it for Eden we do its first
survivors this is occupancy before
occupancy afterwards and it shouldn't be
surprised that it's the same yeah in
this case and this is for total heap so
you can see in here we're working with
the 14 you know should be 14 big heap
not sure what's going on there my name
is uh you get the idea this is occupancy
before after you know with these numbers
I can start doing some calculations that
we can actually start doing some
interesting analysis on fright so if I
look at you know if I look at these
numbers here I can see what start
getting an idea of what the churn is if
I compare the
record to the previous record right then
I can see what my allocation rates are
and now I can start doing all these
calculations that are giving me good
information about how my application is
you know what the what's the memory
pressure picture yeah and that that's
that's interesting because I can tell me
if I can tune the JVM to get rid of my
problems or if I have to actually go and
tune the application to get rid of my
problems so I can start making informed
decisions here you know I can also make
better and dishes and as to what's how
big my heap should be okay so there's a
blue bit and then there's some
alternating green orange green orange
and other blue bits and stuff like that
let's take a look at the big blue bit
there okay oops missed on some stuff but
anyways this is the parallel time so
this is where you know basically most of
the work is happening and if you start
from top to bottom you can see there's
rgc workers have started and you know
min average max so I don't know why
they're publishing this type of detail
for when the worker starts the only
thing I'm interested is when did the
first guy get stopped it gets started
when did the last guy end that's my you
know that that's the how long this thing
took right so I can start doing some
calculations here and see what's you
know what's what's what's happening in
that regard then I'm gonna do my
external route scanning so this is tell
me how long that took this is
multi-threaded
right in this case there were eight
worker threads one for each core right
so now that's basically my scan for
routes when I mean external route
scanning not things that are in the
remembered set these are things on
stacks registers coming from the class
loading activity you know things that
are outside of the g1g wants to mate
j'ni things like that then this is how
long it takes me to update the
remembrance set so as I'm moving things
around and of course I have to make some
adjustments there and I'm going to stop
threads from updating the rumored sets
and the the you know instead they're
going to basically
and cue the work and so after it's what
I have to do is have to clean out the
buffers right
so these are these are all just the
individual steps here that the give you
an idea exactly what the collector is
doing you can actually get much more
detailed than this but then it B gets it
gets Harry to reach I always say you
know scanning the result of the
remembered sets code route scanning so
again all steps that are into individual
internal steps here you know
object copy just exactly what it says
and then terminate termination so the
termination step here is really easy it
used to be what they did was they showed
the termination attempts and when
showing the termination attempts that he
actually showed how successful
work-stealing was going on inside the
collector so the threads will go to
their neighbor and start stealing work
from it if they're finished quickly and
then they do some you know this other
activity that we get here and and the
sum total so here we can get an idea of
what you know where they're spending
their time and what they're doing and
and again we can take a look at some of
the values here and then start doing
other calculations again we take these
calculations over a series of Records
and we plot them and we can see some
interesting behaviors than in the
collector that will tell us if we need
to change our application or if we can
tune things out by side setting command
line switches oops
didn't go back and edit that one
properly okay I'll just do this what
should be there and when I post some
output what should be there right so
there's a code route my creation so what
we're doing is cut and paste error code
route so basically here in these
particular steps like what we're doing
is again we're we're just dealing with
dealing with cleaning up routes and
stuff like that and here we're dealing
with like cleaning up the the card
tables other activities we get involved
with our collection sets oh sorry yeah
using the collection set reference
processing that's all your weak
reference final reference phantom
reference finalization
all of that particular activity gets
caught up in their reference and cueing
reader tea cards so it's a concurrent
collector so as you're working things
are happening which means that we got to
deal with the change right so the first
time through we'll try to catch things
and then the second time through well
you see it in the in in the when the
concurrent collector kicks off that what
we want to do is we want to catch what
has what the delta is between the first
time during the second temperatures in
other words what has died right we won't
catch everything but it doesn't matter
the stuff that's left behind will be cut
yet well we'll catch it on the next
collection and then that was the old
termination record that we don't
actually get anymore
that's what work stealing okay so
there's a couple so that was a young
collection this is a mixed collection
and what we mean by mixed collection is
that this collection is not only going
to collect young generational regions
it's going to collect a number of the
tenured space regions in addition right
so I'm going to build my C set from both
sets of Regents that need to be
considered here right
that's called mixed and this one here
actually triggers the mark of tenured
space so this is actually going to feed
back into mix because the regions that
it marks here it's kind of fini it's
going to calculate the after collection
occupancy and then use that value to
determine if it should be included in
the collection set from a young
generational them while evacuation phase
right okay so that's a couple of
different types of collections so after
we do the initial mark we're gonna go to
the initials of what the imagination
mark does is it internalizes the
pointers so we take one step forward so
we're not dealing with the external
pointers anymore we have internal
pointers and then we're going to start a
concurrent Ruby region scan so our scan
for routes we can do that concurrently
right
with our application threads running so
that gives the concurrent time how long
run you can get it by subtracting these
two values but the granularity over here
obviously doesn't allow us to get this
particular value then concurrent mark
then we get a remark remark is a pause
the world time right so this is where
I'm only going to consider the cards
that were dirtied all right you know by
the mutator threads between the time the
initial mark was run and the remark is
run and you can get some calculations on
that and this is also does the reference
processing it starts the rest reference
processing here and we do a cleanup
right which is also stop the world event
and there's a secondary cleanup phase
here which gets rid of empty regions so
if after a collection and a region is
empty that we can return that region to
the free list and so what this that's
what this phase does okay
all of this concurrent stuff has to
finish before the heap fills up so
you're gonna raise conditioner your
allocators are allocating this thing is
cleaning when it finishes it it releases
all the memory back to the application
so the allocators can keep on going if
at some point in time during this whole
phase the allocators outrace the you
know the you know the collector then
you're gonna get it with you then you're
gonna get a failure when you when you
get a failure with the g1 it hurts
it's a single-threaded . the world GC
you know that's how you spell ouch okay
so you don't want to do that the way to
avoid doing that is to make sure you get
your thresholds okay so the question is
like when do you trigger when when do
you trigger one of these questions to
start well that's dependent of what's
known as an initiating heap occupancy
percentage and the value is jumping
around right now I think it's fifty five
percent do you remember it's fifty five
it's I get confused by the versions to
these sometimes it's four
five percent or fifty five percent it's
forty five and seven I think it's fifty
five and eight they've been upping the
thresholds but it doesn't matter if you
if you're getting if you're getting
these collections - if you're getting
these these failures it means your heap
is either your heap is too small or
you're starting your concurrent cycle -
you know you're waiting too long just to
start your concurrent cycle yeah you
need this is a not that expensive a
failure but it still causes it still
causes the jave at the the garbage
collector to reset data structures and
start again and that's also potentially
another well not quite as an expensive
failures as a as dropping out to a full
GC okay so yeah so that's the IHOP that
I mentioned before
right so eight is think is 55 normally
it's 45 you know some of these values
they just pick them out of their hat
they just said okay we don't know what
it's supposed to be we're just gonna
pick a value now that they've actually
gone back and you know have a better
field experience and understand done
some benching and stuff like that
they've actually gone back to adjust
some of these values to what is more
central settings right now
so you remember CMS has has initiating
occupancy fraction that initiating
occupancy fraction is just for tenured
for g1 its total heap okay so it's it's
a different type of measurement right
live occupancy threshold after which a
region will not be considered for
inclusion in the collection set right
now it was 65% in they just checked in
the code today or yesterday that resets
that to 85 percent right so they did
some benching it says this seems to be a
better value there's a g1 heap waist
percent right so the amount of heat v1
is willing to
not collect to avoid an expensive
expensive so if I'm not going to get a
recovery from a region a good recover
from the region that's something that
I'm going to abort and say look you know
this isn't working out so let's just
move on right so it was currently at 10%
there's thinking that's not aggressive
enough so they move it to 5% however
your collection cycles are too long it's
possible that you want to basically flip
this back to like 10% and make it less
aggressive it's just like with with this
one here right if you find how you say
it if you find your collections are that
you don't see be collecting enough see
set as your see set isn't like large
enough not collect enough regions then
what you want to do is like maybe adjust
this value to to fix that particular
problem
there's also another weird one here it's
called g1 mix GC target so if anyone
ever experienced the annoying RMI
problem you know like once an hour they
call make a call to system DC yeah okay
so how all that works is that by default
the garbage collector is designed to run
once every max long milliseconds and RMI
actually adjusts that value okay so you
know the first thing I do is I just make
the call back into the code to set it
back to max long to just throw them off
there's no there's really no one in it
from the RMI team has been able to give
me a good reason as to why they need to
do that and you know and so it's just
like calling is a speculative call to
juicing in our experience speculative
calls to GC give you a lot of cost a lot
of overhead and very little return and
this is seems like one of these the
things like if a mix GC is needed to run
then it'll be naturally triggered by all
of the other heuristics in the engine
this one is basically saying yeah you
know what doesn't seem to have run off
enough to let's just exercise and see
what happens yeah so it's a speculative
call
used to be four it's gone to eight and I
can imagine as they do more testing that
this thing will get blown out to bigger
numbers or maybe just disappeared or
something like that okay so in terms of
getting into tuning this we'll just try
a couple couple of slides here on like a
case study or two this was a fun one
I think if it works it's working yeah
okay fantastic okay so this is a first
FX program I wrote for a curve for
commercial purposes it turned the screen
white then black then white then black
at 60 Hertz it's really fantastic
application and you know so we put a
light sensor on the monitor and you can
see how good the monitor is by the shape
of the square wave there right and every
once in a while it sort of flickers and
stuff like that right every time it
flickers they missed the vsync I have a
sixteen point seven millisecond time
budget in order to hit each vsync which
means I got to get the capture of the
video do the annotation and that in this
case it was like running through a GPU
and then and then basically getting all
of that data into the frame buffer right
and and yet it basically hit it sixteen
point seven milliseconds that's your
sixty Hertz and this was done and not
this channel year ago January this is
actually on a submarine see US military
so that's kind of fun you know they have
nice icons so that we put in there like
friendly torpedo I'm not sure what a
friendly torpedo is but you know it's
quite there and and and maybe I can just
play the video game and everything like
that and you could see that when we
tried to get g1 to basically run and hit
this target all the time so the the
processing took about five milliseconds
means we had about ten milliseconds for
the collector to run after that and in
in this case you could see we missed it
on occasion we missed it because we
couldn't get the young generational
space to shrink we needed to get to a
certain size 40 Meg's at 40 Meg's we
knew we could collect it consistently in
well under 10 milliseconds
okay now as it turns out there was a
hidden source which that was hidden at
that point in time that that basically
says don't let eat and shrink a certain
percentage below total heap-allocated so
so we had to take that down from 10% to
5% we could go to 40 Meg's and we're
good yeah so I have a heap here like I
mean I could see I could I tuned this in
CMS it was absolutely fine because we
could get the heap down to 40 max but it
meant that you had to keep tenth the
whole heap small enough that we were
worried that we were worried that you
might under certain conditions get an
out of memory error and we didn't really
want an out of memory error you know
when you're trying to render an icon
like friendly torpedo or something like
that so we figured like you know giving
it you know a larger heaps meant that we
were safe for for for the out of memory
our conditions it would just like grow
and which shrink back down and maybe the
video wouldn't be as quality would be as
good but it would still be usable unders
under high load conditions yeah yeah so
we never hit it during those testing but
today I'm absolutely confident that we
could looky we get to hit this target
that client is quite hot using CMS right
now though so let's just try another
example here what I did was I took one
of our standard benchmarks and said okay
let's go and just see how we can tune
this one all right we tuned it with CMS
and if that's in a different
presentation but you know let's let's
see what happens here right so those are
the goals so that's essentially the
things that we want to do right reduce
the hardware use less CPU have better
response times you know all this
wonderful stuff yeah so this is my
visual vm plug-in for memory pool view
and and what it does is it just well
shows you what's going on in the heap
now I for other reasons I have a memory
leak in here that I forgot to took it to
take out and or I thought it taken out
but somehow I ran the not taken doubt
version and and you can see that you
know here we go this is tenured space or
old gen and then by the
you get up to here we're you know we're
basically in in trouble and and the the
fun thing about about this is a you know
there's my CPU utilization that goes
along with it
so you see that the CPU utilization is
really proportional to the occupancy in
the heap you know which is to be just
which is to be expected but it's linear
it's really kind of it was kind of fun
okay so in this case took the you know I
took the problem out and we started
running again and you can see some
values there right across the top here
so these are response times for four
different things that were happening it
doesn't really matter what it was doing
it's just in this case it's consuming
churning through heap and consuming a
lot of heap and and you can see here you
got a couple of queries here so that's
my average response time that's my max
response time you'd really like the
spread here to be much less yeah and I
figured okay and we can look at some of
the data here yeah look at this
particular piece of data you can see how
it's running and you see its sawtooth up
being in here and and you know even
though he peers set to give you like 14
gigs is it no I actually know max is at
8 cakes right so the you know in this
particular case it looks like I'm the
you know the heap is constraining the
workload in other words the heap needs
to be bigger
yeah in order to get better performance
and will hopefully better performance in
this application right so I give a
bigger heap right ran worse figured out
why it ran worse tried to correct those
things by tuning it it ran worse right
I figure ok you know I'm a clever guy I
can I can do this right and so we just
go into doing battle with the collector
here trying to get it to actually just
run better and you know after a numerous
tries and stuff like that solving all
the problems that I thought were there
by giving like sensible values in order
to try to get this collector to actually
work better at the end of the day
the best performance that could get out
of the this application was just going
you know there's some you know some of
the failures and stuff like that is is
really just going back to not setting
anything I'm just setting a proper
max-heap size and letting the collector
do the rest so it was it was really you
know one of these things that you know
he where it was the moment he's saying
like you know now even people had tuned
collectors on a fairly regular basis
really need to step back from the
switches and not not touch what's going
on and and really what we see is that
only under a number of special
conditions are we are we ever able to
successfully tune the g1 and so it's
really working I would say fairly well I
mean there's still some bugs and things
like that that they're that they're
trying to get out of the system and
everything but you know but really it
seems like it's a lot more
production-ready than it was and it
seems with every release it's
continuously getting better and and it's
now to the point like if you're using
like an 8 underscore 20 that you know
this is a collector that you know that
we can be happy with like 8 underscore 6
to 7 under score 65 something like that
then these are collectors that are
working very well I mean is it is a
collector that you that you want to be
in a position where you can keep
updating your JVM so you can keep
getting like all of the fixes and
improvements that are coming in each of
the collectors yeah there's a question
back there
ah right I didn't pay him to ask that
question right have we ever met before
no okay so not supposed to say that part
okay um oh yeah
glasses sorry good question
flags and stuff oh let me finish that
right does not respond too well to
aggressive posture I'm goals don't say
you're allowed to pause one millisecond
every 10 milliseconds or this is not
going to work out so well for you right
cut it some slack it'll do what you want
right more commercialization here right
okay
so let's go to tooling here yeah yeah
I'm gonna I'm gonna actually run how is
the latest build sorry if not checked
into code reviewed or anything
note to seat note to CEO and backer
if it crashes it's his fault Jennifer
maybe do it okay um so yeah so what am I
looking at here yeah let's actually turn
on mirroring so we can see what's going
on here so I started up here one of what
I consider to be well I started building
this tool a number years ago because
quite frankly I got frustrated either
with the inability of the tools to show
me what I wanted to see or you know they
just weren't extensible you know there
wasn't anything to or there was other
problems with some of the we tried with
our son to to come up with something but
it you know in that it wasn't really a
priority with them and and anyway so I
wrote this thing called sense them so
here's the let's look at some of the log
files that come from that particular
demo and so we have a whole bunch of
analytics here since this is a brand new
build and stuff like that I'm not going
to close your ears for a second I'm not
going to trust the analyze
let's tell Martin he keeps telling me
not to say things like that but anyways
the some of the analytics are really
good so they were giving details and
saying like okay these are the flags you
use to run this thing so part of the
process is I'm if you look at enough GC
logs I can actually tell you which
versions of JVM you you're using just by
looking at GC log because of you know
the silly things they do but it gives
you an idea okay so it says here that
there's a premature promotion problem
this is an interesting thing right
because in a CMS collector this would
really be a problem when I went to
collect it in the g1 collector it made
the performance worse I was like and and
so when I talked to the you know the g1
guys about this they're going okay well
that's odd we don't know why that is in
and as you know saying that you know it
doesn't really feel like you need a
survivor space here it seems like just
having young is good enough you know
that's what it feels like break today I
might change my mind tomorrow but today
that's that's what it feels like anyways
oh yeah if somebody was doing something
nasty those are the developers you don't
want on your team wait a second who
developed that it was so weak so we get
some summaries here that basically tell
us what's going on so oh yeah the
application throughput here is 62.2%
that really sucks and that's really an
indication that the heap is like really
under sized in this case right and the
full GC 2 GC ratio I don't know why
we're getting so many folds you see
pauses here or what's actually oh yeah
because of this big system GC down here
that took quite a bit of the percentage
at the time but it was the we're getting
a breakdown is like it each of the
different things that he talked about
region scanner e marks yung
oh there was 78 foals in here ok again
getting full full GCS here's a real
clear indication that this the heap is
very badly under sized mix so you can
see all of the different types of things
that are going to cause pauses listed
here and then you get into some
interesting views here this so this is
my heap after
after collection they occupancy after
collection and and really look at the
the line going up here we're just
extending a heat the expanding heat
until we basically max out in this case
we're maxing out for ya just about four
gigs okay so you can tell that this in
this case here just using default
settings right default settings is like
urgh anomic says 1/64 of ram is is your
max heap size and anyway so you can
start looking through this stuff through
these things and start seeing what the
problems are this is our allocation
rates and our allocation rates are kind
of nice actually these are like way too
high until we get down into here and you
can see ok somebody just kicked the
chair Oh from underneath our allocation
race knocked us on the floor right so it
means that something is interfering with
our GC threads as they're allocating so
the question is now of what's finding
the what's what's the interference in
this case right what's slowing down our
application threads so they can't
allocate as fast as they were apparently
able to in this part of the our of our
applications life right so that's go
change your code type problem yeah so
yeah this is this is really and I'm
highly biased oops
there's a book don't look at this one or
as the the zeros at the bottom right
there's no X's below the zero so so yet
so this is this is actually my favorite
tool that I use for for analyzing GC log
files and and doing some analysis yeah
and yeah if you want any more
information about that you can have sent
I was hoping for more time for questions
so yeah if you have any questions you
know please fire them out as we go along
here yes sir
we have a crazy Serbian that suggested
that in a tower unconference in jaikrit
and now he's off on the first stages of
trying to see if he can actually do
something like that
Zoran his is offering that he's actually
part of the netbeans dream team but he's
I know he believes he can do something
like that um I'm not gonna say the I'm
not going to suggest he's wrong I'm just
gonna suggest that it might be in a very
expensive thing to do you know and
hopefully I'm wrong
yeah you need other questions okay yes
what threshold do you think I was
referring to at the time
oh right max Henry yeah the next so
there's four bits in the header for
keeping track of age that's all you get
that means you can have a maximum age of
an object in young generational spaces
being 15 then the reason why I said up
to 15 when I'm starting to tune is that
I want to get a view hold on and this
one here I probably do I have a view
yeah okay fantastic
see that that's my tenuring distribution
that's the number amount of data I have
at age 1 2 3 4 5 so you can see this
application here everything dies very
quickly and so what I want to do is I
can with when it's at age 15 I can see
this and they're very naturally and I
know that I want to set my tenuring
threshold now to 4 right because I'm
getting good recovery up to here and
then a everything after 4 is copy costs
so now I can by setting the tenuring
threshold before I cut out all the
coffee costs okay I can do that now by
calculation instead of guessing back and
forth right that's exactly right and
that's the view you need to nip that one
in the right but okay and then you
there's some other views here that are
actually kinda useful like this one here
can actually help me sighs oops that's
megabytes over there I think yeah
certainly not a 285 gigabytes so I
finally found it okay
the anyways this this view here can help
me actually tell me how big the survivor
spaces spaces have to be okay so you
know so it basically it's a stacked on
view it's like I got all the bytes at
age one two three all added up so at the
top of the peak is you know so and
really what we're saying is that you
know this heap could really support
maybe like a 60 megabytes survivor space
right I'll incur some premature
promotion with that size but for me
that's good enough okay and that and
from there that gives me a reasonable
sized survivor space tenuring threshold
is set nicely I might have to do an
adjustment on tenuring threshold after
doing this but then really that's how
I'm gonna start sizing my heap then I
don't know it's sort of I did I think
it's sort of a folklore thing it sort of
comes with generational spaces I mean it
certainly IBM doesn't use survivor
spaces the but they use a another
technique known as hemispheric spaces so
they do the same flip-flop but they
don't have a nursery like a specialized
nursery in that case you can turn it off
if you want
and the documentation for that says one
thing and this something that someone
from the g1 team was in a presentation
in a slideshow yeah the to space
overflow well that's just premature
promotion I mean you have to protect the
buffer right you can't overflow the
buffer so that means this is what it
tried to do is they tried to do an
estimate as to how much live was going
to be left after the collection and it
got it wrong right so then it overflowed
and so instead of like premature it's
going to prematurely promote but it's
going to do it not as a I know I need to
promote these guys it's going to do it
as oh I made a mistake now I need
to promote these guys and we need to get
the oh moment it means that now I
can't selectively promote that means I
have to just promote everything no
matter if they're aged 1 2 3 4 5 or 6 or
whatever right so again just make your
survivor spaces bigger I think that
should be the problem yeah who is the
Charlie Hunt yeah that well that's
that's the old moment right that's
yeah so that means that basically you
need to make your heap bigger to then
right yeah if you run out of regions
then you're like in some in many cases
like the default behaviors full GC yeah
so if you can't find a region you're
screwed right you've lost yeah
yeah I mean the humungous region which
we unfortunately didn't have time to
talk about is another problem because
again because of fragmentation it's
sometimes very unlikely you're gonna get
contiguous regions and my phone I'm not
gonna complain about inviting the
audience leaving the phone on now and
and you know it's just statistics are
working against you I guess soon it's a
probabilistic event am I gonna get three
four or five whatever reasons are right
and you know the answer is okay well
just make the regions bigger but that's
not free either that comes with the cost
because that means you have bigger hour
sets and more dense hour sets bigger are
sets take longer to process right so you
sort of have this thing I want the
reasons to be small but then if I run
into humongous allocation problems then
I get a problem where I want the regions
to be bigger and you know that right now
is it's just they haven't really
properly
I think humongous regions is sort of
high on the list of things that they
need to deal with properly and it just
hasn't been it just hasn't really been
looked after properly I mean they they'd
like the problem to go away actually I
mean the way to do one way to do it is
to fragment to your allocation so if you
have an array that's like I know like 20
20 Meg's or something like that then
just say okay I can put it in Meg
regions but it's going to be in 20
different Meg regions and link them
together yeah that's what you've done
yeah yeah of course yeah and that seems
to be about the only reasonable way
around the problem right now yeah sorry
yeah well running our regencies is one
reason a humongous allocation failure is
another reason and I'm sure there's
others that I for some reason am not
thinking of rate at the moment they're
not coming to mind but no there's not
there's really not that many reasons but
that's fragmentation is fragmentation is
always an issue I mean I was working on
a bench based on what some of these
little guys told me about how to break
the g1 and you can break the g1
basically by fragmenting the heap by
allocating small big small big small big
big big small something like that and
then and what happens is when the and
when the objects are free then the space
that gets freed actually gets put back
on the free list as its that size so you
don't get free list Cola being coalesced
and you know and and so eventually what
happens is that you have enough free
space but it's all fragmented so you go
big and it says can't compaction right
and then free less compaction goes on
top of that yeah yeah these guys over
there yeah yeah we're happy to talk to
you I'm excited I'm not paying attention
to the time because we're the last talk
of the day are we not anyways well keep
quiet
asking answering questions as long as
you're or you can just leave</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>