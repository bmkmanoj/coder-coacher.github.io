<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Big Data on Big Maps:  Displaying Vast Amounts of Geospatial Data | Coder Coacher - Coaching Coders</title><meta content="Big Data on Big Maps:  Displaying Vast Amounts of Geospatial Data - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Big Data on Big Maps:  Displaying Vast Amounts of Geospatial Data</b></h2><h5 class="post__date">2017-10-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/uSlQ3Fsyhn4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody thanks for coming
today's session
big Maps I am Roberto McHale
I work for Oracle spatial and graph I'm
a software developer the other guys that
contributed to the project couldn't be
here but I am here representing them so
today I want to talk about big this is
missus the contents of the session so
first I will talk about the big Maps big
data on big maps what is our target with
that then what is the data set that we
are using for that how we are preparing
the data then how we render that into
the actual map and at the end I will
provide some of the numbers summary and
extra links that you may look into so I
will start about telling that goal we
have so we wanted to represent all of
the streets and roads all of the
highways into a map a really big map for
that we want to use as input the Open
Street Map Planet file and the output
will be a huge PNG image so it's 57600
by 2808 well the pixels that is
translated to 4 by 8 feet that's us
printable resolution that we want to if
we wanted to put it on on a wall let's
say we are defining the bounding box to
be just United States continued
contiguous region and for that win we
need to divide that region into smaller
tiles so that's easier to
to work with and of course all of this
needs to be configurable for the user if
they want a larger or smaller region and
also the output if they want it to be
larger or smaller than than that so in
other words that's our target area and
this grid we see it's divided by four by
four degrees but we can have less than
that if we wanted to two by two one by
one zone that's something we can
configure in in this example so before
rendering we need to start with
something so for that we are using our
OpenStreetMaps on the planet data set
that is a PDF file protocol buffer
binary file that is 36 gigabytes so it's
a compressed format that if we wanted to
use their regular OpenStreetMaps
will be double so this PDF file is
easier to read it's faster and it
supports random access to sections of
the file so it's arranged in a in a way
that all of the components in in the
file are well the different elements in
the file are notes that are basically
longitude latitude points then ways that
are a way to represent Lin linear
features polygons maybe and relations so
for more complex polygons we need to
create some sort of relation for them so
what we are aiming here is to represent
just the ways information within the
file this is an example of where are
those osm file XML looks like basically
it starts with all of the node
than all of the ways that are referring
to to a list of notes and in the end
it's the relation so if we had this huge
file in the readable XML format this
will be what it looks like
so before rendering anything we need to
prepare the data so since it's a huge
file what we are using for this is to
create that information from the PDF
file using osmosis so that's an open
project that OpenStreetMap has and it
allow us to read that information into a
smaller file blocks and then we are
using HDFS and had to to load that into
our file system our HDFS file system
then using some MapReduce jobs we join
all that information into the waste that
is what we are interested in and after
that we create je geometries so if you
are familiar with the Java the Oracle
Java object that we have for
representing geometries is a geometry so
it we can start working with that
directly so this is a code example of
that so in the first part we start
reading the sequence of of the PDF file
into small chunks of it and then we
separate the different elements so
so we keep appending all of the same
datatypes into the into this into the
same category so all of the notes will
go together and then all of the ways in
I love there are relations once we have
everything in HDFS we apply an
operatives job for them to just separate
the ways that we are interested in and
we write that into a different file
directory in HDFS and a third step we
are following is to build all of the JG
Amma trees from that data structure we
have now so we create je geometries with
all of the coordinates basically each
way refers to different notes their
longitude latitude so we keep appending
that into the je geometry we create the
geometry and also for rendering purposes
we need the tags that are attached to
each of the ways that exist so that way
we know what kind of way we have so it
could be the highway or just to do to
decide if we want to render that or not
so that was preparing that part using
Hadoop then we need to partition the
data into useable tiles so we want to
make that partition dataset using spark
and in a way that each of the tiles will
refer to a partition meaning a cell in
like information in which I just show
before and from that
so this is the code for spark so this is
the how we have we partition that data
so we start with creating the Hadoop
file from spark we access the
information we wrote before and then we
start creating the region that we are
interested in so all of this is
configurable and after that we have a
grid partitioning for our information so
we can decide from all of the all of
those features which once belonged to
each of the of the tiles we are
interested in and in the end which we
save all of the each of the grid that
make all of the data set into a
different partitioned data set that we
will access later for the rendering
purposes so rendering is just
translating the what we just created and
partition before in two different PNG
files or tiles so later we can just
aggregate them all into a single image
and for that we start the this is
another spark job so we create the the
we read the partitions we created we
start rendering them and for each of
those partitions we call the renderer
class that will receive a collection and
an iterator of all of the ways instances
those will go into the render and the
render will know what is the the MBR or
the bounding box that that tile
represents once all of these parts of
the image or tiles are retrieved we need
to create the whole image so for that we
have this aggregation in the
so we start with the zero image that is
just the empty carcass word for that and
we start appending all of them so we
first aggregate into this zero image and
later we just combined them all to get
the final big image and then it is just
a matter of fact a multitude to write
that to the file system so this is the
render class we received as I said the
records those are ways so basically they
have a jjomi tree attached an MBR so
having that information we decide what
is the tile context of it the size and
how to translate those coordinates
longitude latitude of lines to
particular points or in other words the
pixels that will go into our PNG file so
that's why I am calling my world
Mercator util there to translate they
launched it to Larry to 2 meters and
written finally rendering the line
string so let's say maybe a away lengths
a hundred meters but finally in the
image will be just a pixel stencil so
that's why we run that and the object we
are using just saves the bikes portion
of it so we are not actually sending the
the bytes in there and yeah well this is
how it looks like very roughly all of
the straights in the US and maybe a
little more if you if you see part of
Mexico too if we wanted to access a
single tile that's how it looks like and
as I said all together
barbar language so maybe I can show you
okay so this is how the image looks like
weakened to me on the different areas of
the world so basically there is no
background map it's just the straights
drawn in the map and the empty areas
well our lake so there are no streets
yeah it's up so this is the simple
render we used of course we can always
come up with a better stylish render but
that's the the idea behind this project
okay so now in the numbers so that
they're rendering part after we have
everything in loaded into HDFS it takes
roughly 30 minutes to partition the
information the the area we want and
render that and just the rendering part
takes around 10 10 minutes for that area
we just so the full planet file contains
4.5 billion records among just notes and
ways and their relations and as I said
right now wait we don't care about
relations or single notes but just the
ways and for this exercise we used
cluster with three machines one is was
the driver in two executors and that's
the RAM that they had for for this there
are some links in case you're interested
in in making something similar some of
the Java classes that we use for
partition and all of the some of the
spatial information are part of the
Oracle big maps spatial and graph and so
that's the telling link also for osmosis
it's part of OpenStreetMaps
and well if you have questions for me I
can't answer yep I wait to verify that
we covered all the points now we don't
currently verify that because well we
use the input as our OpenStreetMaps
so we don't verify that they impact our
current but we're using the latest
version although it changes everyday I
think so yes
right so we just have a count of all of
the records so we know whether we parts
at the beginning reading the PDF file so
we do count that and then when we render
we also from each of the different
grades we also count all of the records
that we got to to render so those
matches yes
yeah well I think it was just the title
for the session and so it's because they
they are big maps right yeah well maybe
even make it a trend that I know so it's
not part of the product right now I
don't know it's maybe Shiva
so we just wanted to show that it
typically when you talk about Maps
people only talk about generating each
each individual tile if you look at
Google Maps for example they're not
individual tile inside if you take that
and then if you try to print a
wall-sized map then you can do it right
you don't have enough resolution and so
this is basically to say if you really
want to put up a display for example
argue a big screen and you want to show
like the type of map that they show on
the TV screens when something happens
and those are very high resolution maps
and it's a like a single image so if you
want to generate something like that we
wanted to show that you can use the big
data technology for that and then be
able to produce a very high resolution
mass map in a very short amount of time
so this is a very small cluster views
which support only about three notes but
if you want to process the whole planet
and create a straight cap for the whole
world you can probably do it under an
hour for the whole dataset so the idea
is to show that its release chemical and
then it's very easy to produce very high
high resolution maps that's like a
single large image so that was the idea
yeah so basically we like we were
fishing around to see what will be about
the mapping application that is suitable
for big data technology this is one
thing that's really useful and you know
some meaning behind it
so we are we do have a lot of this
technology as part of relation database
and and we want you to show that Big
Data technology can also be applied in
this type of applications so the whole
point is to show how to apply Big Data
technology for a mapping application so
that said we chose how to render
MapReduce and then also spark so the
idea is to show like Hadoop and spark
those are the two biggest technologies
in Big Data right so and then we wanted
to see how we can apply those kind of
technologies for a mapping application
the whole idea we can do something
similar with relational database also
again you have mentioned Porsha is
similar to know similarly in Oracle
database we have a lot of spatial
technology which is much better than for
she is if I may say so but so we could
have used all the database to do the
same thing for that but this is more
about how to use how to apply Big Data
technology for this type of things
right now to the format of a file or
yeah yeah we can do something very
similar with Oracle's patient very
easily so if you look at the first part
where we process the data and then
created times on HDFS we can eliminate
that part and then read the data
directly from Oracle spaceship and then
use this part to do the rendering part
of it no not to this scale but we have
done experiments where we can read
thank you
so yeah we have done similar stuff so
basically you can do the processing and
then typically the result of this potato
crossing is a summary of results and
then that somebody can be persisted
aided in the database or in the shape
finer any of those things but we have
done we have persisted reserves back in
the database we haven't done
specifically for shape file murder I
don't see any reason why that cannot be
done so it is very similar concept
and then
all of that
they done in heroin system and then
general questions
okay well thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>