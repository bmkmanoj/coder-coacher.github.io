<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CON6627 Proactive Optimization of Java Workloads in Production Environments | Coder Coacher - Coaching Coders</title><meta content="CON6627 Proactive Optimization of Java Workloads in Production Environments - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CON6627 Proactive Optimization of Java Workloads in Production Environments</b></h2><h5 class="post__date">2015-12-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4kML10xVpQs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good afternoon everybody happy to see
such a crowd here it's a late Thursday
I'm hoping everybody had fun last night
with the elton john and everything so
I'm Michael a form of the senior
director of development for java
Diagnostics it Oracle then with me I
have Abby Huber was the senior director
product management for several items but
one of them is jvm diagnostics and then
may is the architect for the product for
the most part and she's going to fix
things when I break them so so we're
here today to talk about you know what
happens really after you finished and
you were successful you manage to get
your code running in production and then
things really start to be more
interesting you do whatever you can do
in development and obviously in testing
and production but before production but
things really show up in production
differently it's a safe harbor statement
as you seen so much you want to read it
but it's okay so what is what is the
workload that we talked about here so um
in terms of dictionary com workload is a
something that is defined based on mmm
something that a machine employee a
group of employees can do expected to do
in a reasonable way when we come to Java
and to our world really we're talking
more about application that needs to run
well with the resources the machine that
it has and the different types of things
that you throw at it and you expect it
to really do well but the two things
that its skin kind of hard to define
ahead of time what the work look is
going to look like you know what you
implement some things get invoked in
testing some things get invoked in
production but for a very long time you
don't see them at all and then at some
point they start shooting up because
somebody started using a module you
didn't see them
doing so really the workload is very
diverse and it's it's going sometimes it
is throwing some curve balls at us and
and it's kind of hard to just say okay
let me try to reproduce something that
you complained about that happened last
night let me try to reproduce it in my
own testing and getting and get to
understand what's what's going on in my
own darkroom so there's a lot of stuff
that we're seeing in production our
customers are telling us that they have
issues with so on the ones that we are
usually the kind of conflict that we
usually see between developers and and
the folks in operations is there's
really very little patience in opes for
a developer to go and meddle with with
things I mean they they need to really
keep things up running they have their
own requirements for compliance for
everything is audited allegedly of
course the things that they do sometimes
are not audited they don't know make
changes and things fall apart but then
you know you cannot track these things
but they are very careful about who can
get where and the true thing is what the
world that you know in development where
you can actually hook a debugger or you
even go on on a host and play around
with it that world is just doesn't exist
in production you some customers would
have forms that you have to feel some
some production managers we want you to
feel some form when they get approval
that you get a down time to play with
something it's kind of difficult and of
course we really want to deal with
you're going to get to two things that's
not the slightest
ok
you may see things a little bit out of
order sorry okay so why proactive so
what are we talking about proactive here
for proactive is is really it's a little
bit different of an approach then what
we sometimes see the ops doing in ops
you see typically what you see is there
more reactive the more driven by
problems somebody something doesn't meet
some KPI some service level that they
are response contracted to deliver on
and and that's what they do in many
times that's what they monitor and
that's what they deal with but we've
seen in the past that they still have in
production you still do things that are
more proactive DBA is for example the
database administrators they don't just
wait for somebody to complain that
sequel is or page is executing a slow or
things like that they have the tools to
look at their system as a whole to look
at what it's processing the workload
they look at what it's really spending
its time not necessarily that they know
that somebody is going to complain about
this but if they look at a sequel
statement that is executing for too long
or consuming too many resources this is
going to chase down the person who wrote
it and i'm going to say you got to fix
this I don't know who's going to
complain about it but not in my database
we want to get in a similar way fashion
to do the same thing in in Java we don't
want to wait till somebody calls at
night that something is broken we need
to make sure that we understand how
application behaves all the time monitor
it all the time and and see if things
are doing egregious things low
contentious that shouldn't be there you
know they might not be a big issue in a
small scale but if you have a higher
load all of a sudden that thing becomes
completely responsive so we want to be
able to do all of these things to reduce
outages and to be more really more
efficient about our resources because
you can't just waste these things it's
not just about the money of the hard
where you throw more harder at some but
something what comes with it is also
a data center capacity ventilation power
you can't just hard with everything so
that's another thing that to bear in
mind so really so so what is the mission
in production that is kind of we need to
pay attention to is their role is
basically keep the system running
running that's it it's always service
availability and service availability is
not just up down it's whatever you
define service and they measure it by I
mean this is a simplified formula you
can get and see a sigma formula that
talks about and breaks it to multiple
other things but at the end it's about
how much time the system is operating
between failures divided by the time
including failures and the time that it
takes to recover from a failure
basically so that way that that's so
what developers really what developers
want to make sure is that the code is
operating it quality so you know what we
want to do is to make sure that we don't
have failures so that it requires really
investigating sometimes things and maybe
we are willing to pay some price of
looking at the system that it's hurting
you know III don't mind if somebody is
telling me I have a huge GC overhead
right now and they you know the JVM is
at full capacity and GC is acting up I
would want to get a heap dump and
analyze it because I don't want it to
get to the same state again in the
future what the ops would want to do is
they would want to just bounce the JVM
as soon as they can they're not going to
wait for minutes to get the hip dumb
that you want that's an example or even
just any any stuck threads or anything
that you see they're not gonna wait for
it yes they don't have the budget for it
because if you look at 59 I don't know
if anybody here do you know what it
means 59 how many minutes can you be in
a year how many minutes hours you could
be down if you want to support five
nines anybody want to guess five minutes
five minutes in a year in total that's
the thing so if I need to dump a heap
and it takes a minute
you took five you took a minute out of
my downtime I'm already in trouble
because that's how you want me to give
you the heap dump so that's really the
sorry so so that's what we want to be
proactive but to be proactive you really
still need to be asked to have access
you're stealing oh yeah yes correct yeah
so I'm actually before that I was kind
of it's a mixed crowd I don't know if
people would volunteer and raise their
hands and tell us a little bit about
what kind of things they do and
especially as it pertains to production
the type of issues that they deal with
I'd be interested to hear any first
volunteer yeah I know yeah because we
talked about this and I think one of my
slides was a bit off of what I thought I
don't know what happened with it anyway
but anybody volunteering some oh good
hip exhaustion huh yeah and then usually
what it's an inhabitable out of memory
or worse yeah look is actually yeah so
the gentleman in the back was talking
about hip exhaustion the truth is it's
not the worst you can have if the if the
JVM actually crushes it's not that
usually because usually it would bounce
again most of the servers that you have
would have some facility some watchdog
some node manager something that would
bounce it again but sometimes that's not
what happens really it just gets in two
minutes possibly even hours where the GC
is just rushing and then that's really
bad maybe I see people you know nothing
about that so that's so anything else
I'm not I mean they imagine some of you
do web services web applications any
applications are not web applications in
production
yeah that's the other thing that you
reminded me basically we see these
things is on on web web containers as
well what do you happen what happens is
the same thing that we talked about
before like a long pass that happened
usually most developers don't really
plan for that and what happens is you
get things queued up you come back from
this long GC pause but all the requests
that you were supposed to be processing
are backlogged those requests fire in to
the thread pool and they bring up all
the threads and you're already stressed
for memory so that's you know things get
compounded and if you locate crashes
that's your best case scenario so the
five minutes that you have to work with
you might be able to work with that okay
we'll move on so really what we want is
when we are in production and we want to
do the diagnostics and proactive be
partyi we really need to have access but
access like as we decided I know III I
wonder if anybody else has a better
experience with getting access to
machines to host in production anybody
here usually gets on hosting production
oh you do how do you get how do you get
that what oh ok ok so i should be
careful about what I say about this
admins huh yeah yeah anybody
yeah so you also sometimes you can you
fight with yourself sometimes yeah
deployment yes of course to grant access
tool yeah so in Oracle we deal with the
Oracle plow orca public cloud assets and
they're really I mean we we don't get
access to if we get any access its
supervised access and and of course you
need to have to schedule a meeting and
it's not with something really bad
happened so you know you just you can't
really do anything and you need to know
again for the scale that we talked about
here the gentleman here I mean obviously
you know exactly where everything is
running when you look about on a bigger
scale you need to know where the
services are running it's not that easy
also so that those are the challenges
that we're seeing so what what we are
looking for when we when we Oracle when
we implemented our own solution which is
not the only thing that we think is is
possible to do but we're looking is
really to get access superb not
supervised but controlled access and
audited access to the systems so you can
get to the application understand the
mapping the service director and it's
telling being able to do things on line
when that something happens right now
but also historically go back and see
things and be able to look at things
when they have if they happen in the
past or just analyze data if nothing
happened just be able to look at data
and figure out if this is how you want
the application to to execute the other
thing that we do is we listen to
critical events in the in the JVM and I
think even if you don't use Oracle if
you have your own your small shop you do
your own things you really have to
sometimes you need to factor into your
code some means
to deal with production issues you have
to at least instrumental in a way that
you know I took this work this is where
I'm taking the workload that I'm
supposed to be processing let me
instrument it some way these were
finished things you got to do some of
these things otherwise you'll be left
with in production you would not have a
debugger and logs will not do u dot
great for performance usually they would
be good for for logic issues sometimes
but you'll need data and you need to
enrich it to be able to get the data
that you need you could do we will talk
later about Jay stock you can look at j
stack but Jay stock is not gonna be good
enough if you don't enrich it with some
some context okay moving going so what
are you doing in pre-production okay
actually this is maybe good question for
for the crowd what do you do before
production of course in production you
can't really do stuff but you do run
some load in production you have
performance scalability what do you do
there what are you using to profile
optimize your your applications
Jane here okay just to run the load into
profile Oh j-roc admission control okay
that's good your relic how do you
profile with that it shows you what
well you know your response times when
you get that also from jmeter if you're
running jmeter you know your you know
your timing jmeter gives you a beast at
it doesn't give you the breakdown in in
terms of yeah I know I know um yeah okay
so you can selectively decide to get the
stack traces for so it does sampling
similar to JP JP umm like h prof oh yeah
okay
oh you still busy
netbeans
okay yeah so so actually many people use
profilers to some extent of course they
have some limitation but you have to do
this in sampling you have to do simply
because if you if you enable the
profilers to really cool feature said
you would be messing with the with the
test as well you can't load the JVM if
you're not sampling you have to do
sampling and be careful about what you
instrument so but the problem with that
is again you need to really understand
the context of what you're sampling and
if you look at any profilers they don't
really know they know the JVM they don't
understand the context of the
application and I think some of you even
even Mission Control is not always it
doesn't always figure out the context if
you have if you're running in weblogic
you have good context of what's going on
but if you run on a JVM with some other
application container Mission Control
won't necessarily know that you're
running requests even on what the
requests are in your in your code so
you're gonna be missing some of this you
know that your hot methods are going to
be you know a y ax ABC or whatever but
you won't really know truly if those are
methods that matter so what what people
do and this is something that if you're
using these things what they do is
sometimes again is is be there filtering
out they develop some others some to
some configuration files they develop
some means to filter out threads that
are really not executing a lot of any
any workload we actually call them idle
threat threads that are waiting for for
work load instead of threads that are
processing workload okj stock somebody
mentioned here JMC as well these are the
things that we've seen GC logs and J
mapping some of these things you can do
not necessarily in production even even
JMC in a small site you can get with JMC
I think
in a bigger side where things are
control you suffer from the same
situation GC logs you can collect if you
enable them but you have to enable them
either all the time or hope that the
problem will happen again okay I wanted
to just show a little bit what it looks
like how it looks like when you do jtag
and I mean in a real situation everybody
here yeah yeah so if we look at
oh yeah I see that way yeah if you are
complaining about I can imagine what
others would say but fortunately I don't
think I can scale this this is a Mac but
let me open another screen oh this is
all so small
oh you know what that'll do something
else
oh good for me o0 sorry
bigger but probably people at the end
won't see it but I don't think we need
to look at the all of it but i just
wanted to show what what's important to
show is how many threads you actually
have when you do you know Jay stack is
it not read about right okay maybe we
should skip this yeah any time that I
can but ok i'm able to move mouse
zooming
mouse is flaky
no good
now it's visible sort of
okay let's do this for a second
oh sorry yeah sorry this is si si stuff
yeah I know anybody knows what these
tuck is used it ah good yeah so let's do
I'll do more because there's no sense in
doing so okay so this is this is a
server weblogic server a similar things
you've seen many frameworks it's going
to be very shocking if you know if you
haven't seen it but ok I'll do something
that will see how many threads we have
this is way too many but so we have
think it's of ni d equals something how
many people are familiar with Jace ok
yeah and then we'll do WC fish ok so
this is this one actually right now
doesn't have done many threads usually
you would see hundreds and hundreds of
ball of thread this is just 137 but the
important thing is most of them are
doing nothing so that's probably issue
the other thing that you have is
sometimes is that you would want to know
you know I'll do a grip ok
so if you look at j stuck what it
provides you it actually looks at the
threads and tells you some threads our
blog some threads are time or other
things and then some are random asleep
some of them sleep sounder than runnable
the problem with that is even that is
kind of a bit flaky runnable in anybody
knows what runnable means in java when
you do to Adam you it means that it's in
the run queue what does it mean that it
has to potential do the main thing is
actually based on what the java
implementation does runnable means that
really java is almost like a catch-all
basically in Java we just don't know
what it's going to do we know it's not
sleeping we know it's not it's not
locked we just it could be native and
then obviously we don't know even if
it's do it does the pole or select or
something from our standpoint it's
runnable it could be really runnable it
could be in there in the run queue so so
these these are the challenges you do j
stock you don't know that you would we
would see there the threads you won't
know how they threads are associated
with requests that you are executing but
you have to use it sometimes if your
introduction you have to get thread
dumps from the customer right i mean
we've anytime find that we have to ask
the symptom bearing individual to give
us either j map or j stock or things
like that because we don't have access
to it so an email back and forth between
the developer and the victim and we ask
the victim to help us by giving us j
stein anyway so I won't spend too much
time on this specific thing because I
think we'll be it's going to be
challenging with the my skills with the
with the screen here
okay so these are the things that is
this okay good okay so what really what
do we really want to have papa Proactive
we talked about resources we talked
about workload the important thing is
really to understand the relationship
between those two two things we need to
really understand how the resources are
affecting us how much how much time we
spend on each resource and resources and
this is similar to what we're doing in
the database so there's a lot of history
behind this we want to know how much
time we are spending on cpu runnable or
or in 1q memory i/o what is blocking us
external resources like database rmi
other cause and we need to look at these
and and what we do in the model that we
look at we look at each thread and we
say what is that thread executing on
what resource is it is it you relying on
right now and we categorize the thread
dumps that you saw first of the first
thing that we want to do is to throw
away all the threads are not doing
workload so we need to identify that
they are actually doing work load second
thing that we do is we just break it by
these categories these types of
resources now these the second section
here is talking about okay so now i know
that i'm doing i'm waiting on cpu or I'm
waiting on I or network that's all cool
but who is actually consuming these
resources so for the same type of work
what you really want to know how much I
look how much our memory allocations
it's doing because that affects
everybody when you allocate memory
necessarily retaining but at least
allocating you know how much CPU you're
consuming if you if you track this over
time between versions of applications
you same like in the database you can
figure out that you know the same
request a version ago was doing you know
100 milliseconds of CPU and now it's
doing
500 milliseconds that is not right to do
5x all of a sudden in CPU something
might be going going bed here so these
are the things that yeah yeah so based
on what we call so we look at these
things even even people that don't do
necessarily web requests we model things
in terms of requests we just normalize
on 11 name for this workload so were
Clarissa is comprised of many types of
requests we call the different things
that you can actually observe recall
those things requests so it's a web
request but it could also be a job that
is request so as long as you know what
is the start and end of this thing
that's to us is a request so some things
that we I think I would recommend here
for people that just want to use their
own home you know just wanna reach their
thread dumps I would recommend to do a
few few things if you instrument your
code so that you could actually be more
effective with thread dumps one of the
things you can do is you can rename the
threads to define what the thread is
doing we're doing it in in our code when
we rename the threads the weblogic does
that as well so when if you take a
workload you're executing a job you can
give the name of the job to the thread
and when you finish the job you can
remove the name you can bring it back to
pull thread number one you can also
decorate the name of the thread with the
thread ID you don't have to because you
already have it with the j start but it
was going to make things a little bit
easier especially if you add to it the
current time because current time and
threadid would give you uniqueness of
the execution of the thread it's almost
like an execution ID of the workload
that you are executing when you have
those and you get thread Dom's the 20
ohms would look all of a sudden a lot
better too
you you know which threads are actually
executed you can actually clap by these
things and you can start also putting
them in database that you make on your
own or in Excel and mess with these
things and figure out what things are
it's not easy still but and you can
still be missing some things but I think
that's an easy thing to do to get better
thread dumps otherwise you'll see the
thread um did I just showed you and
that's not going to be extremely useful
what we do at Oracle is we do things
that are go beyond that because what we
do is is is a whole interaction with
which is what I want a demo is how we
look at things from our standpoint okay
maybe I'll go back to better resolution
I think we can do better resolution for
this actually you know what it's fine
you can do with this
Oh
yeah no no okay so so what you're seeing
here is what I talked about before we
mark every thread first of all in this
what you see here we look we do
essentially a few things we instrument
code that wasn't instrumented before we
instrumented with the events that relate
to taking workload and processing it and
going to other systems or other
important things to to use to obtain
some resources that are meaningful
enough let's say if you go to database
or you go outside to http we track those
things so we we kind of figure out what
events are going on but we are not
collecting these all the time because
that's going to be expensive under heavy
load for production we're just tracking
it but we the way we actually get access
to the data is by sampling so we
constantly sample simple and simple and
separately what you see here is our
sampling the height of this is the
number of threads for this application
and the colors you can read kept it a
big some of you could read the Blue Nile
the red is CPU when cpu is usually good
actually but what we can't read database
is threads that are doing stuff in
database and we just aggregated across
as many gb aims as you may want to
monitor it's a cluster or multiple
cluster or the whole data center you
aggregate things and you can see a good
feel of what your workload looks like in
terms of resources and you can detect or
even here I think people could see that
there's a shift in the behavior in this
in this specific thing we see that there
was a period in time that there was a
contention bluish contention we don't
know yet from this because it's multiple
je viens the table at the bottom we
don't know yet which of the gbms has a
positive but we know that there is
contention yes sorry oh this one's a vm
here yeah because
okay let me add the other one also I all
be filtered out a JDM that
so okay may corrected me so actually
this this is specific site only has two
JVMs and you would see here the
cumulative count of the processing
threads based on what type of resource
they are spending their time at the
moment of the sampling that gives you a
good feel for what is your bottom like
what is your resources that are being
slowing your application because that's
what the threads are spending the time
so around here we see a lot of database
also but we also see IO we see a period
of time that is locks now nobody has to
complain about anything here we're
saying proactive it's not about somebody
saying that something is slow but me
looking at chalk like this usually what
we'd catch my eye is why am I looking a
lot and what would happen if i'll see
you know monstrous load load what would
happen then if i have this looks so how
do i figure out who's responsible for
those logs so if I have multiple jvms
this is not many though but if i go and
zoom into the area where this log
happened i can actually see the jvm that
is the culprit there's one JVM that is
doing a lot of database that's actually
the JVM that we are interacting with
right now the JVM below it is a JVM of
the sample that actually you can see
that it's spending some time in in lock
sometimes in I or sometimes in CPU and
if and there's a little bit of database
what we can do is also look at what you
know if you if you look at the while we
show in there is how much jva how much
time the journey is really active what
we call is JVM time it could be more
than the wall clock time because you are
running multi-threaded multi-core it's
more than the world clock time but this
gives you a good understanding of how
much the JVM is really active because
these are only active threads so for
this these GBM is active about 20
minutes I think about 20 minutes
out of the time selected in the selected
time is seven minutes so that's pretty
active you can see high level stuff
immediately and that's why you need to
aggregate things and you get me to get
to em beans sometimes and things like
that and we also show the GC overhead GC
overhead I don't know if people hear
anybody familiar with the notion of GC
overhead okay oh just okay so okay so um
GC overhead is really more of a
calculated metric the way we do it is we
look at the GC processing time and we
divide it by the local time at the wall
clock time and because you know that the
GC at that time that we're measuring is
GC that is actually pausing then you
know that this is the overhead based on
what you're supposed to be processing
this is stuff that you couldn't do on
the in that time because GC was was
giving you that overhead so that the DC
overhead and those numbers ideally you
don't want to see them about 5% about 5%
you will see already some some impact we
put treasures usually around five and
then I think ten or maybe seven and
twelve or something like that but it's
really needs to be really low what we
can do here as I'll go back and again
this is the data data process on without
yeah it's the number of threads that are
active so every time that we sample the
thread that is active we counted as one
sample and we simple in this thing we
are doing sampling every two seconds we
can do it in various you know it's it's
it's something that people could choose
how often out of the box we do every two
seconds and we count every two seconds
like that that we see a thread we count
it as JVM time so the thread is active
let's say you said you count we were
running we got you know a ten ten
samples
we saw 10 threads it would be a hundred
seconds now it could be that we had
these ten ten samples and later there
was no active threat we still simple
there are no active threats it will be
for an hour you didn't have any active
threads so it's still going to be those
100 seconds for that hour but then you
know that it's idle for the other time
and the height is really also something
you can look at in terms of thread
samples 20 seconds so I'm going to go
and do some okay actually one thing that
we can do is also even at this at this
level we can look at what requests are
executing at the time so even from this
standpoint even at the level of multiple
JVMs I think I don't have to even say
but you would see that you can see which
request is really doing the locking the
contention it's not everything that is
having a contention right so you can see
here because it's decorated because we
know what the workload is it's not just
JJ stack we we know which request is
doing what and here we see also that's
the thing that it's kind of not going to
be that easy to do but still doable is
even if you build your own thing you
still want to know how much CPU the
request was taking which is things that
we're showing here and you can also
count the allocations there are counters
in the JVM in the platform being that
allow you to know how much you are
located so you can in any given point
each thread tracks how much allocation
how much memory is allocated so this is
really cool to be able to know look at
the allocation because it's not always
that the allocation is a big deal the
location sometimes it's just a good
measure of activity same like you look
at CPU if you're doing a network read
it's not very easy to know if the reed
is just blocking for traffic waiting for
traffic or really you are reading you
look you do a JTAG you'll see something
in socket read it could be just idle
waiting for something but it could be
actually reading if you have if you
actually can track how much memory was
allocated you would know that it's
actually reading they're not just
waiting to read right so you can use it
that way yeah no no not open source no I
James see that open source also you can
calculate it actually from GC logs also
you can calculate the GC overhead from
GC lobes that's probably the best you
could do but some of so the thing is
okay so it depends on the crowd the tool
that you're seeing here is tool is a
tool that usually is available in
productions in big productions they're
using this it's all a matter that
sometimes they don't know that they can
that the developers can can take
advantage of it so it's not that this is
I mean obviously you would prefer to do
things in even some of these things you
want to do even in your own environment
so not just relying on admins in
production I think there are ways to
deal with that also yeah we can talk
about that later but I just want to just
the concept let's go over the concepts
first and then figure out what is the
other yeah
okay the name the thread is a notion
that I kind of suggested that you would
do if you want to do it you know in your
own you want to do some things we don't
name the threads really what we do is we
catch the the actual invocations of for
example of a servlet or any similar
things that are executing in the in the
JVM and we know how to catch me
basically it's some of it is based on
some bytecode but even without bytecode
we know how to find the object that
defines the workload and then we use
that as the name of the request so even
in spring or or in other types of
infrastructures we we grab the whatever
defines the workload and in situations
where we don't have that what we do
sometimes is just based on the stack of
the execution we define what is what is
the user last method before it's not the
last the first method that out of the
framework became a method that actually
is executing the workload so we may not
in those situations we may not have the
exact request name that you expect to
see but for example if you if you were
doing this if we didn't know anything
about JSP but we would do with this
method we would get to at least the name
of the compiled java class that executed
JSP we wouldn't notice a JSP but you
would know that this is the method that
executed the JSP we would also what we
would also be missing is we wouldn't
know when it started exactly but I for
example the top chart you would know
without needing anything you would know
what where are you spending in terms of
specific request full underscore JSP
blah whatever you would know that it's
consuming mostly I oh because we would
know that every sample that we took is
categorized by that artifact in the
stack any other questions
okay so um how we doing on time okay
what other things that we do is so let's
look at what we do in terms of other
resources okay actually no not this so
we went to requests but request is not
the only thing we talked before about
instances of requests it's not just that
you want to look at requests as one
cloud of things sometimes some of the
requests so we show of urges you can see
here that we show the averages we show
the max duration but it's never going to
tell you enough to deal with one
sporadic slowness you really want to go
a little bit better into the instances
which is what I told you before why I
would recommend that you do sometimes
what you would want to do is to decorate
the threads with the current time that
you started taking the workload so here
you go at Oracle we call these instances
ecid execution context IDs I don't know
if you heard of those things and they go
at Oracle all the way to the database in
the Oracle stack if using most of our
Oracle stack would have that and and you
could tell even what sequel was
executing in the database based on that
execution ID and what it was doing at
the time so here we see the instances
and you can see per instance the same
thing that we saw showed in aggregate I
can show per instance that the instance
took point the top the top one for
example is to a hundreds of milliseconds
of seconds or it's 200 me 20
milliseconds right in terms of of CPU in
terms of allocation it took it allocated
6.4 two megabytes for that instance
obviously it didn't do that much because
it was mostly locked and you even see
that the i/o wasn't that dramatic here
for the duration because this request
took 14 seconds and it really didn't do
that much we can see the other thing is
let's look at how the
to what level we can go on this we can
actually go to the level of we can go to
the other thing is because this is an
the grated system you can even go to the
logs on this on this specific instance
you can see the log files that this
instance emitted if you want to I
wouldn't I wouldn't really focus on that
but I'm going to show the coal tree for
example look what happen here
it's part of the fusion middleware
fusion middleware is the Oracle stack
for I would say j2ee they j2ee stuck at
Oracle and and it's instrumented is part
of it so if you get weblogic and you
enable that feature it tracks everything
for you and if you have saw osb the all
that framework is instrument some of
oracle applications are that are built
on those that infrastructure are also
instruments so if you end up using them
and even in turn integrating with them
in your solutions you can take advantage
of that okay so this is the cool thing
about this is not now that we can
actually do this is ok this is always
right we could we should look at this
request this specific request and look
at it and see the stack traces of
execution but actually the stack trace
is how we connect we always collect them
and for all the requests so the notion
of looking at the stock risk it's all
good to see with one instance but you
can also pick multiple instances and
look at the start race the aggregated
start race it's basically puffs
contextual profiling you're not just
looking at a cloud of of everything that
happened in the JVM you can pick
specific requests out of the stream
because they are the slowest for example
you can pick them and look at them in
the is is an aggregate stock as a
profiling stack and you can see the coal
tree and you can go and you know open it
like any profiler in developers I'm sure
you've seen these things you've seen a
profiler you can open it more zooming
and the heavy stuff and you know and and
on and on and and you see the line of
code you see the methods you see the
line of code you the file name you see
all of that and and this comes from
production and it doesn't use only
to be there when it happens yeah
questions because we're doing sampling
it's kinda even how to give a number
because it's it's not integer you know
basically you can notice then the time
it's and it's controlled even you know
if you have any concerns you can I mean
the cool thing about doing sampling is
that you can play around with the
frequency if you want to have if you say
okay you know what I don't mind I don't
see any any impact maybe I want to have
a higher frequency of sampling I don't I
don't like the two seconds out of the
box i want to do every half a second i
want to simple gotcha about this is that
this is really for high production
environment so what you'll find yourself
at some point is if you increase your
frequencies that you need a huge
database to store the data where we're
bringing the data we're not keeping it
in the JVM my god i think it's useful to
end here at the point of the other heads
because of the same plane is the
overhead doesn't depend on that shallow
to the system if you are monitoring
anywhere that note that we have now you
suddenly have high load and
many tools once you hi lo this is when
your applications in problem this is
when you want to bring up your
monitoring but you wanna Turing now have
over increasing overhead because there's
more all of the system but because we
assembling it's the same sample all the
time the overhead the minimum of what we
have is the middle of it is exactly the
same regardless if we have the tenters
out to the second or thousands of
section per second so it doesn't affect
the actual what you want or Y actually
emphasize on this a little bit more
because they did think the one important
thing is to notice is to understand here
when you do things like executing based
on on event tracing like bytecode
injections somebody people here
mentioned like New Relic they're not
alone there other people who do that
they actually execute their work on the
execution thread they have no choice
they have their bytecode it's as if you
wrote the code to do the instrumentation
they just do it in byte code which is a
cool thing that you could do this we
also use this here as well to get some
things but we were very conscious about
still keeping our sampling as the main
means to get their richness of the data
because really as hobby was saying and
one of the things that we did is we did
introduce some bytecode because we can't
track the resources if we know if we
don't know exactly when something
started when something ended if we just
simple we won't know so what we did is
we introduce some bytecode for example a
servlet start we have some small code
that runs in there and when a simple
ends we have a little bit of code that
measures what we want at the end but
we're not aggregating any of this we are
not even getting the name of the request
at that point we're not doing almost
anything at that point beyond the
absolute necessary that we have to do in
the context of the thread we respect the
context and the integrity of the thread
so we don't screw up anything that's a
funny story though because we hand our
PSR even with all of that that are
talking about we had our PS are doing
testing and they you know it's not PS
sorry it's actually its quality
insurance and and
they were lacking on methodology but
they kind of blew up with some concerns
about performance they were saying oh
it's like forty percent impact and we
know what we are doing so obviously they
were wrong and it was very easy to prove
it but at the same time I had the person
that was doing this code he was not
trusting then he said okay I'm going to
write my own application and I'll see
what the impact is and we measured
everything so he had his own application
that goes all the way to the database
des does a select from do all which is
less than a whole request that is
traversing only code that we are
instrumenting took less than a
millisecond back and forth to the
browser and he was running it under load
hundreds in a second the same request
and then he's telling me Michael I don't
know I have overhead of twenty percent
said what twenty percent what are you
running so he explained I ran a request
that is one millisecond and high load
and you know obviously so I saw okay
let's measure how much time you take in
them minut code that you execute how
much time you take in terms of of really
wall clock so he ended up finding that
he was taking about 200 microseconds to
process his stuff how he was doing
nothing I'm not kidding he's doing you
can't do less than that we found that
actually I'm lying you could do a little
less than that which is he was creating
a unique identifier for each of these
requests the thing that you see here the
ecid that was taking 50 microseconds
that's not nothing if you care about 200
microseconds so we optimize that yeah by
the way found these issues with this
tool it's funny even though it's such a
small thing he ran it and we checked it
in jail this is called JD &amp;amp; D we rented
in this and the same thing that you see
here with the you know where you're
spending the time and and and the
distribution based on sampling he found
these issues themselves they eat tried
Mission Control by Mission Control again
it's it's a pretty big tool and takes a
lot of events and it's kind of some
times difficult you really need to
understand how to throw away the noise
out of the tool the tool is amazing and
we use it here and this by the way
allows you to get jf ours from remote
JVMs you don't need to be on the host if
you have a side that is using enterprise
manager you can go as a user you can get
your own user on that you can go from
that your browser you can go and say ok
I want to dump this GFR I want to start
a new recording you can do all of it
from here you can download it and you if
you have Mission Control on your on your
PC it would open the file and show it
yeah we have that's ok i think in terms
of demos yeah we were running out of
time down in terms of that but we can
definitely answer questions yeah we are
using java flight recorder in the sense
that we we do a few things with it first
of all we enable it we enable access to
it in production you will find that in
big deployments it's very hard to get
access to cello flight recorder this
allows us all the JV games that we know
about you know the domains the pores the
data centers all of that that is managed
like this we have because we have an
agent on those jvms we allow you to
start recordings and dump JFR we're not
using the GFR in this UI well what we do
do with JFR besides just dumping it and
getting access to it is we create
reports out of it and may is probably
trying to navigate there no ok good yeah
so we create we have reports that we
parse the JSON files and we can we have
right now to reports but we would enrich
them one of them is a report that says
that talks about GC if you have a GC
pressure like you know you may have we
can tell you what was affected by GC and
also um what was allocating memory
because the cool thing about what JFR
can do
that we can do it nobody can do without
impact is even they have impact on this
story i'll correct myself but it's not a
material impact they can catch the stack
traces of the allocations when they
happen so if if you have if you have
something that goes out of whack and
allocating memory and causing the GC to
to trash this is extremely useful to do
to dump the GFR file and look at the
allocations actions like dumping GFR
snapshots as well as keep snapshots I
think many people are interested in
memory Diagnostics of a memory exception
or you know the JDM runs out of memory
and you can proactively take some heap
snapshot and now we can compare and give
you the cause of video memory issue so
you know this is another usage of
foreign a proactive optimization I think
we got signal that we have excuse me um
are we the last door there's somebody
waiting okay okay thank you much okay
thank you thank you guys</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>