<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Modernize Your Database Development Process with Open Source Tools | Coder Coacher - Coaching Coders</title><meta content="Modernize Your Database Development Process with Open Source Tools - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Modernize Your Database Development Process with Open Source Tools</b></h2><h5 class="post__date">2018-04-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vI-FA3eLxKA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so howdy I'm Blaine Carter I'm Oracle's
database I'm Oracle's open advocate for
boy and I messed that up
I'm Oracle's open-source advocate for
database development basically what that
means is I work the intersection between
open source and the Oracle database so
on the one hand I promote open source
tools and software for database
development and on the other hand if
there's an open source project that
might need a little bit of help with the
database I can assist with anything from
introduction to database development all
the way up to the more advanced features
of the Oracle database now of course I
work with lots and lots of different
things so it doesn't necessarily mean
that I'm an expert with everything that
I talk about there's still a couple
things in this talk that I'm not fully
into yet but I'm working on it so if you
have a question on something then I
don't know the answer
there's my modes of contact get with me
and I do work with the experts in these
areas so I can help you get to the
correct person so today we're here to
talk about modern database development
processes and what does that mean I kind
of a simple explanation is just the way
that we develop software you should be
working from some sort of a written
specification so if you're still using
the waterfall method that would be your
big requirements document if you're
doing a more agile process it might be
Kanban cards or storyboards depending on
your process pretty much this just means
that you should be working from
something that everybody agreed on what
you're building and write it down
hopefully we're all using version
control so this one's kinda redone
but we should be using version control
for all of our development how many
pills sequel developers do we have so
hopefully you're all working from files
develop your file or your coding your
files saving and your version control
compiling into your database if you're
working live in the database you're
probably familiar with the problems that
that will lead to you should have good
tests this doesn't necessarily mean you
have to have fully automated tests
hopefully you do that's the the end goal
but if you're not able to do automated
tests at this point you should at least
have standard consistent repeatable
tests and have somebody testing your
software that's not the person that
developed the software that they will
find more bugs that way speaking to bugs
working out of some sort of a bug
tracking system preferably something
backed by a database that will give you
the ability to do searches and
preferably something that has some sort
of a commenting system built into the
bug tracker so if you have an issue you
can have a discussion
individually-wrapped with each issue
using some sort of a build tool this
could be as low down as just a shell
script that so with the build tool
that's the thing that goes and grabs all
the different pieces of your application
does what it needs to do packages it up
ready for deployment so this might be a
big fancy shell script or maybe you're
using a tool like mate or ant there's
lots and lots of build tools out there
some way to package up your application
that doesn't involve you personally
having to go out and do that every time
because we should be aiming to automate
as much of this as we can because most
of this stuff it's kind of fun the first
time you do it they all hate cold in a
tool that 20,000 at the time you do it
it gets to be real old if you have to do
something more than a couple of times
you should try and automate it and of
course we're all leaning towards trying
to get into DevOps and so speaking of
DevOps
usually new people coming into a DevOps
type of environment think devups is cool
tools
it's automating this automating that in
this cool tool and the tools are really
fun but DevOps is really more about
culture it's the way that you interact
with the other people on your team's
notice that's plural because it's not
just developers versus operations
anymore
there's also the QA testing team
there's the documentation team there's
the database team database gets left out
of DevOps far too often it needs to be
part of your product and as well as
security security especially if you're
getting into IOT I've been playing
around a lot of IOT things
it's like security as that thing that
nobody wants to talk about when you're
developing an application you should
have representation from all of these
groups in every stage of the product you
shouldn't be having a design meeting
that doesn't include the security people
and people will overlap in these teams
but DevOps is really the culture of
everybody getting along and developing
the product together there's lots and
lots of stuff out there on the web on
how to do a DevOps culture far more than
I'm going to do in this talk so of
course I'm going to talk about the fun
fancy tools one of the tools about be
using is this little application that we
put together in the developer advocates
team called dyno date this is kind of a
little slowly application it's a dating
service for dinosaurs it is an
open-source application and it's up on
the oracle github account if you want to
check it out but the purpose of this
is to demonstrate different ways to do
certain things so right now this is the
node version of the application so we
have some PL sequel we have a middle
tier that's either node or Python so if
you're into one of those two you can you
can load that and then there's a front
end that's jet there's also an angular
front end but I haven't updated that in
over a year so the jet application is
current but the kind of the cool thing
about this is you can see here I just
did a search for dinosaurs to find for a
date this isn't this is using Oracle
text so eat is going to find things that
are with an Oracle text relationship
using eat if I were to do that with a
like statement we're like percent eat
percent I'm going to get a whole lot
more because this is going to find
things like beat or beat those types of
things and if you want to see and so
there's a spatial there so eat within a
thousand kilometers but this is kind of
the cool thing when you see a little
gear there this is actually showing the
live node code on how to make this call
so that's about as much as I want to go
into Dino date it's not the point of
this as I'm building out the application
for the remaining steps this is the
application that I'll be deploying and
I'm going to be deploying it to Oracle's
application container cloud service so
what a CCS is it's a system that allows
you to easily deploy your apps to a
pre-built
everything type of environment so
normally you have an application that
you build and you want to deploy it you
could go get a server install an OS for
doing the node version install node
install
drivers do all of that and you know
we've all probably done that many many
times that gets old after a while you
can step up and get maybe some sort of
pre-existing vm that already comes with
the operating system and node and
whatnot so there's another layer you can
step up to or you can step on all the
way up to something like a CCS where
everything is all installed configured
and maintained for you and all you have
to do is focus on your code package up
your application throw it on the server
and it spins it up for you so I'll so
this is what the interface looks like so
you can see here that I'm I've loaded
the node.js version of Dino date and
once it's loaded up it gives you the the
URL directly to the product and so
there's there's Dino date and a CCS I
mean I'm gonna go any more deep into a
CCS just know that at the end of this
process that I'm going to show you
that's where everything's gonna wind up
alright so you're probably thinking well
that's all well and cool for all the
other languages that are outside of the
database but database development is
different specifically when we start
talking about version control and we
start thinking about your database
schema objects your database schema
objects should be version controlled
just like everything else your database
schema is as much a part of your
application if not more so than most
other things but how do you how do you
version control your schema objects
we're probably creating a bunch of our
tables and whatnot with scripts yeah so
you can write a script that will trade
your tables
maybe next version updates the tables
how do you keep track of who ran the
script who wrote the script wasn't run
it when there's a problem can it easily
be rolled back and the answer to all of
those are yeah that's doable
you just write more strips or we use a
fancy tool so liquid base is what's
called a schema
my tool there are several of these out
there another one is Flyway DB if you're
in the Ruby there's ruby app active
record migration Python has one into
Django but basically it's version
control for your database so liquid base
is an open-source product it's
maintained by a company called data Cole
so this is not an Oracle product but it
does work really well with Oracle it
works with many many other databases of
course and I'm going to focus on the
Oracle aspect what it does is instead of
writing a sequel script you write a
change set so fancy talk for nearly the
same thing these change sets are going
to auto generate the sequel for your
database so you if you are writing an
application need to be portable between
multiple types of databases this comes
in really handy it tracks the changes so
if I write a change set and it gets run
it's going to record that I wrote it
it's gonna record when it was run it's
gonna do a hash on the actual chain set
to make sure that nobody monkeys with it
after I've run it it keeps track of a
whole bunch of stuff and it keeps track
of this in your database in tables so
you can go in and query to this
information later when there's a problem
it gives you the ability to
automatically roll back a majority of
the changes you make so what I mean by
that are the standard things like create
a table at a column drop a table if I
make thirty changes like that and I say
roll back twelve of them as long as
there are the standard type changes
liquid base will automatically generate
the sequel and roll those back for you
things like changing data are not auto
ruled back liquid waste does not keep a
backup of all of your data so if you
make a change set that updates some
records and it's in the middle of that
rollback
back till it hits that and then it'll
stop and throw on air say you I don't
know what to do I don't roll that back
I'll talk I'll show you how to handle
that and a little bit it gives you the
ability to include conditionals
conditions in your in your change sets
so if you're gonna run this and stand up
a development database a test database
in the production database you can throw
a condition in there that says run this
for tests and so maybe it loads in all
of your test data you don't want to do
that production so you wouldn't use that
condition but you can write one change
set that handles the different
environments based on the conditionals
instead of having separate scripts to
maintain so it's a nice handy feature
and once again when things go bad so
I've got my known good over here and
I've got my I don't know what the heck I
did over here I can run a diff between
those two schemas and liquid-based will
generate the change set for the I don't
know what I did to get it back in order
or in matching your you're not good or
if you're just starting out and you have
a database it does have the ability to
reverse engineer your existing stuff out
into change sets so you can get started
without having to start from scratch one
of my favorite features on liquid base
is the ability to auto generate
documentation for your database which
looks like this so when you run the
command to generate the documentation it
generates a Java dot style doctorate so
it looks like this and you can go in and
click on the current tables drill down
into a table maybe look at a column you
can see the authors that are out there
for different change sets you can see
which ones I've written which ones I
automatically generated you go in and
look at the actual change logs
themselves so they look like that lots
of different stuff pre-built in and this
is just a command you run it goes
through your liquid base history looks
at your database and makes a nice little
document for your database alright the
way we run a liquid base is I mentioned
we use change sets so here's a sample
change
that creates a table so if you're
familiar with writing scripts to create
a table if you read through this so by
the way when you're looking at examples
for liquid base most of the examples
you'll find are going to be written in
XML
I think xml's a little too pointy you're
gonna cut your fingers on that stuff so
I like to use Jason you can use Jason
you can use XML yamo you can even use
groovy there's all kinds of different
ways you can write your chain sense but
I like Jason because to me it kind of
reads a little easier so I'm just start
at the top and walk through at the top
are making the changelog and we have
some preconditions here I don't know
about you but I've way too many times
I've ran my scripts when I'm still
logged in as sis or system or something
this precondition makes sure that before
this runs I'm logged in as my dynamo
user there are a whole bunch of other
preconditions you can put in I put this
one in almost every time and you can put
more than one this is an array of
preconditions down here we start our
change set we give it an ID
this one was auto generated by the
reverse-engineer tool so it has my name
with generated next to it we're creating
a table called DD members the underscore
T's because I use EBR so I'd have to
separate my tables in my views here
we're going to start an array of columns
the first column up is member ID it's a
number it's going to be an identity
column
true it's going to be the primary key
and here's the name of the primary key
next columns dinosaur ID it's a number
location is a number down of a name is
mark r2 it's not null so if you add the
constraint their email is also not null
and unique down here is a club there's a
default value set to P you can also use
a default computed value if you want to
call a function to populate your value
something like this function rather than
just a static value scroll down here by
the way if you go to get
when you look at the dine of a
repository all of the examples I'm going
through this is all part of the diamond
a repository so you can download this
and run it yourself it's all it's all a
bit there's a timestamp down here we're
adding a couple foreign keys to go off
to our other tables so this change set
pretty much just creates a table now the
change sets are run similar to how you
would do when you have a bunch of
scripts to run you write one master
script that runs all your scripts in
order liquid-based works in a similar
fashion you write one change log master
that runs all of your change logs or you
change sets in the particular order and
so this file here's what that looks like
it's just a bunch of includes you can
see that I have some run one tsa's these
create tables and the naming convention
you can name however you want this just
makes sense to me so this is how I did
we get down to here you can see that
when I start getting to my PL sequel
type objects so my triggers my
procedures packages and my views as well
too anything pretty much that I can do
it ready to replace I switch over from
writing a change set in liquid base to
keeping that in a file and in my git
repository and then I tell liqui base to
monitor that file and if it changes
it'll rerun it next time and so that's
why I've separated these out into
directories where on once run on change
you can set this up however you'd like
and you'll notice that for example in my
packages it's calling a sub change log
master so you can tree this out and make
this as complicated as you want and this
is all set up like I said in the github
repository so let's take a look at one
of these run on changes so here same
precondition make sure I'm running this
is the proper user ID this is one that I
were up directly
I put the tag in say run on changes true
great procedure
like I said liquid base works with a
bunch of different databases so that's
just generic term for any type of code
so
anything you want to execute not so much
a table change so create table will
create procedure will execute all of
those I'm telling it it's Oracle and
here's the path to get to the actual
package body that I'm going to execute
I put relative chain to change log
equals true that's why we have the back
out of the directories and then go back
in because I keep it all in a relative
directory and then of course the schema
name now here this is probably not the
best role backed use for a for a package
but I had mentioned before that some
things cannot be auto rolled back so if
you're going to do something that can't
be Auto rolled back you need to include
this statement or liquid base will roll
back to here and stop so I could have
ice cream it should have for a package I
should have a roll back that's just
empty so it just tells local base ignore
the roll back to move on because if I'm
gonna roll back code I'm gonna change it
and get I'm gonna recommit or I'm gonna
change it back on liquid base will
notice that it changed and rerun it for
me but I wanted to put a little more in
the example so here I have a roll back
that is executing sequel that sequel is
drop the package like I said not the
best type of a rollback for a package
but it will serve for the example all
right so that handles how to do a nice
tool for doing version control for your
schema objects but database development
is still a little bit different when it
comes to testing specifically unit
testing or PL sequel it's a little bit
different when you're talking about unit
testing there are a couple features that
you want in a unit testing application
you need to be able to do some sort of
setup to where before you run your tests
boy that thing just picks up before you
run your tests you might need to modify
your environment a little bit to get
everything set up
right matter so that could be set up
before you run any tests it could be a
setup that runs before every test or it
could be a setup for an individual test
obviously they need to be able to
execute your code and validating that
the code did what you wanted to do some
sort of a results chanting done you need
to be able to clean up in the reverse
order so it might be clean up for an
individual test clean up for every test
or clean up after they're all down so
most languages out there that are
outside of the database there are a
bunch of tools out there to make testing
really easy the database developments
have been different so it's a little
more difficult so what about PLC there
is an application out there called UT
PLC home this is another open source
product that was originally started by
Steven Feuerstein years and years ago
since then it's been improved a lot and
it's currently being maintained and I'm
going to say this wrong shock kick the
ball I've only communicated with them
typing so I have to have somebody tell
me how to say that correctly but this is
a very active project I found a couple
little bugs and they jump right in and
get it going and get it fixed really
quick if you're a PL sequel developer
and you're interested in getting out and
doing some open source stuff and you
don't want to pick up another language
this is a great project to get involved
with the team is very helpful they have
a slack channel you can learn the
standard way to interface with open
source and still be in a language you're
comfortable so the way that this works
is I mentioned the admin package
when I did the other example in Donald 8
I have the admin package and in there a
single function called call generate
members and so for when you're writing
your tests it's a unit test and so the
unit is the function even though my
package has a bunch of functions or
procedures the unit that I'm testing is
that function to generate reverse
function so on the UT field single side
I have a package of tests that test a
single unit or a single function or
procedure so for each one I have a
package and so this is what the package
looks like I want to test my admin
package and I want to test the generate
members function so the way we would
find a test for you details sample as
you use these annotations that are
commented out here it says this test
belongs to the dining suite that lets it
know that this is a test you can't
include this suite if you're familiar
with Java it's kind of a way to package
your taxes so here I say it belongs to
the database EEMA it's in the admin
package and it's the function generator
that works later on when you see the
output this is a way to group your tests
and you want to run a specific a suburb
instead of just running everything now
et PL sequel will go through and notice
that this particular function has
committed so it will not run because it
will go I'm not changing your database
now unless you put in this rollback the
manual
which is me telling them to feel sequel
that yeah I'll deal with the commits on
my own I mentioned the setup and cleanup
so here is a before ball so before I
read any tests I'm gonna run this
procedure after I've run all my tests
I'm gonna run this procedure after each
individual test I'm gonna run this
procedure I don't have one before a pair
for this exact same thing before each I
could have been a senator before each
and my individual tests are defined like
this this is a test and it should
generate 10 members so the reason we
have this generate members function in
dyno date is because by default there
are 41 members that are defined in there
and they have nice little BIOS but when
I'm trying to show you how a difference
between speed between a couple different
functions and 41 members there's not a
whole lot I'm gonna do that's going to
be none of that they are no second
things so I wrote this function so you
can throw in 10,000 members or however
many you want however I didn't want to
as a safety check I put a limit
I typically for my system I typically
keep it at 10,000 because I don't want
someone to go and say generate 200
billion members of whatever I'm doing so
this test is to make sure that that
limit works so we hit the are these
tests are and are testing those limits
so when I call this function it's going
to generate however many members it can
and return the number of how many were
generator so when I call this I should
get 10 back when I call this as you get
19 here as you get 0 let's go look at
those
pieces down here don't make more sense
at this part first up is a little helper
function so that limit this is a
function I have in here to change the
limit because for testing purposes if
I'm testing banking up it's that limit
there's no real difference between
banging up against limited ten thousand
and banging up against it at sixty other
than it makes my test run longer to
generate the extra members
so this drops the limit for me there's
my before all function so this procedure
that's defined just a little bit lower
will delete any randomly generated
members after the forty one would come
with the proper and it will set the max
limit to sixty when everything's done it
will also delete those members and set
the max on the back to ten thousand this
is the delete call to get rid of the
extra members and now here's our first
test the generate ten the way you call a
test and as you say you t expect so I'm
going to expect that when I run this
function into passive ten that it's
going to return me ten so this one
expect this to Eagleton down here
generate over the limit I know that I've
just said that a limit the sixty so if I
ask for ten thousand it should return
nineteen down here I do a little pre
setup in this individual test where I
send it to ten knowing I already have 41
so I'm already over mine so when I run
this test thanks
to return zero and so that's basically
my tests for this particular function
the way you run it is in sequence e all
your signal plus or whatever your
favorite tool is and you can set the
server output on set the feedback off
and just execute Beauty run and that
will go out and run all of the tests
that you have defined so right now I
only have this desk appliance so the
alcohol look like this
remember the packaging thing I talked
about it will treat down shine this is
the package the schema the package and
the function and then they all belong to
the diamond each suite this shows a big
time for each test and down here you can
see the results three rounds you know
failed zero errors or warnings alright
so now that we have some tools in place
to take care of getting our schema
objects version control and being able
to unit test our peel sequel it's time
to start wrapping some of that into a
continuous integration continuous
deployment type of an environment so on
you may have heard about the CI CD it's
pretty common term now CI stands for
continuous integration so the way to
think about continuous integration is
let's say you are working in a git
repository and as a local developer I do
my change I commit local and I push to
the shared repository when that push
comes into the repository the CI
pipeline the pipeline to the term for
the flow the CI pipeline will make sure
that when that code gets into the
central repository whatever a branch is
I
going on we'll all be merged back into
mainline so it automatically makes sure
that shared repository is all merged
into me the next step up from that is
continuous development which starts at
that point and then it does whatever
else it needs to do to package up your
application so that the end product is
always ready for deployment so you'll
have their deployment objects that maybe
you have a release management tool where
it drops those over there and then your
users could come in and get those or if
you make it private it's a good place
that you can get it ready when you want
to send it up to users so you have a
package it's ready for deployment and
the final step this is the scary one for
most people is continuous deployment
which means it takes that package that's
ready for deployment it drops it into
product so in that environment as a
developer I make my change I commit I
push pipeline kicks off it does
everything it needs to do it runs its
tests and package everything up
assuming everything passes it deploys to
production if you're going to go that
route make sure your tests are really
really really really good they'll never
be good enough but it's kind of it's
kind of fun to push the button hope
nothing burns down so I'm gonna walk
through a very simple pipeline that's
just a straight through these pipelines
can get as complicated as you want you
can hit certain steps and say if this
happens that run these off do concurrent
processing all kinds of stuff I'm just
going to run through a very simple
pipeline that starts out with the first
step of the pipeline I check the code
out of get it will build whatever it
needs to build and then it will package
up some artifacts and that step will
hold on to those artifacts the next step
assuming that and so each one of these
steps is assuming that everything else
is passed up to this point if at any
point it fails then the pipeline stops
so the next step is it will
those artifacts that the first-step
created and we're liquid-based to deploy
all of my changes to the database so
that works it will kick off you TPL
sequel and run all my tests if my tests
work then I'm going to go back to liquid
base and generate the documentation for
the database and when that works and I'm
going to take the documents that were
generated in the previous step and mix
them with some of the articles or
artifacts that were created in the first
step and create a deployment object that
is ready to drop into a CCS so when you
deploy things in a CCS it's typically a
zip file with a manifest and the
deployment object so this will create
that zip file before deployment for a
CCS so that's what I'm about to do and
to do that I'm going to use a tool
called Oracle developer cloud service so
I'm going to if you if you already have
a cloud account you're already started
with dev CS that's the example I'm going
to show you there was a release the one
out last week that changes some of this
gives you a more advanced pipeline view
and a couple features I don't have
access to that yet but everything I'm
going to show you is still works in
either version so Oracle developer cloud
service is not just the CI CD pipeline
it's a complete environment of most of
the tools you're going to need to
develop your software and most of these
are going to be open
so rather than go through and read out
all of these icons are let's just switch
over and look it apart so this is the
developer cloud service do see us you
can see here I have a ton of a project
if we go into the project you can see
some recent activity these are the
current activities over here are some
items that I'm gonna go through most of
them I've used some of them are still
learning but of course there's a code
repository so you can use github you can
use bitbucket
you can use git lab whatever you want to
use or if you want to keep all your code
internally at Dempsey us has a git
repository and later on into the build
if you want to use stuff each and every
different repositories you can mix and
match you don't have to you don't have
to use just one thing next up is a maven
artifact repository so this is the maven
artifact repository not the maven build
tool the maven build tool is available
down lower build section what this is
for is when I build I'm a big I need a
few things I'm gonna be running liquid
base so I need liquids so I've stored
the version of liquor base that I need
in my repository my friends Oracle jet
so when I distribute dynamic I do not
distribute the files for Dinah big party
for her Oracle jet but when I build it I
needed so I keep the files here
separately if I'm gonna have to put the
Python version there's a couple things
that I need to do differently
but those things require some extra
files so that's there and then of course
UT PL sequel requires a file system I
keep all of my dependencies in my
artifact repository I had mentioned
continuous development where you had
releases ready to go this would be a
good place to have those releases stored
so that you can keep them internal get
them yourself where you can make them
public release management built-in I'm
sure we all have those little back
pocket pieces of code that we use over
and over and over again I know I've got
a big directory on several different
file systems snippets is a great place
to put those and then of course there's
a way to share those snippets with Russ
to your team it's nice to sharing means
carrying one of the steps I didn't
mention this before one of the steps
that we should be doing in a good
development process is code reviews and
this is a great tool for doing code
reviews
it says merger classic but this is just
basically saying before this is merged
in please somebody else will look at my
code it's okay to point laughs for my
code I do it's a nice tool for handling
code reviews there's a bug tracking
system built into here if you're using
an agile process you can have scrum and
or Kanban board I'll come back to these
two doctors one of those things where I
really need to get into it learn it
keeps getting bumped from the top of my
list for some reason if you're using
docker there's a place to put links to
some external repositories and of course
every project needs some kind of weight
going back up to the deploy tab this is
a piece of glue basically so what the
deploy tab does is it watches one of my
that we'll get into next and when it
works if it works then it will take that
deployable object that I mentioned in my
pipeline and auto deploy it into a CCS
for me so you said this at once what you
do it looks like this so this is the job
that it's watching I'm automatically
watching so it always watches for the
latest success so you said this F once
and then forget about it you're Bill
little trigger tips all right fun stuff
onto the bills so I'm going to normally
I would make a change push it up to
github this particular job is that first
box and would want to get home and it
would start itself off I'm just gonna
have manually hit the button here if you
up the process I'm gonna try to talk
quick enough to meet it as you're no sir
because this is going to go through
those boxes step by step so first up
source change let's look and the
configuration the the main thing is just
the name a couple of other features here
if you have a particular build job that
requires some sort of an external input
that's what the build parameters are for
of course if there's an external input
that's the opposite of automation so you
don't require that the middle of the
Builder and stop-and-wait source control
I can use one or more occasion none or
more source control repository so here
you can see I'm actually pointing to the
oracle github for diamond rather the
eternal one also because I keep that
code updated
using a demo system so I always blow
this away at the end it's just easier to
point my demo to the live person one
thing I want to point out with this
particular step of my pipeline I'm a big
believer and when I kick up a pipeline
my first step is the only one that goes
and gets cut from github or from any
given positron I go get all of the code
I package up all the pieces that I need
and then I keep them in my pipeline so
for example I run my tests against those
artifacts if I were pulling from get on
every step I might run my tests some
other developer makes a change and then
I go to deploy if I pull down that
change they're not tested there are ways
to work around that you can use tagging
and branch and all kinds of different
things with this method I know that I'm
only working off the things that I
pulled there's no way anybody else can
mess me up
they might not did their tags right or
whatever it is so this is just one of my
my ways I do it so this is the only step
that pulse Armageddon
this is triggered on a schedule every
five minutes it checks again if
anybody's checked anything in it'll kick
off the build automatically I like to
have timestamps on my console output and
I like to have time stamps on my console
output and my version that I'm using is
is a dud whatever by the way the reason
that's wrong I'm just because you're
paranoid does not mean they're not out
to get you
I have three different pad blockers
spirit blockers privacy badger my come
at me so that does mess up some some
webpages every now so when you see these
things that's my fault but I'm using the
card version I'll come back to the build
steps post build once this is done you
can see here it's going to kick off the
next step in the pipeline okay and here
these are those artifacts that I was
talking about that first step in it
collects up and saves so the belt step
looks like this is just a simple shell
script I could use Gradle or maven or
some other type of a build oh you're
phrasing I should use Gradle uh maven or
some other type of a build tool but
since this is so simple I just wrote
some shell scripts first up I pull stuff
out of the Mayman repo I make some zip
file zip files for my artifacts I did my
note subsistent in the numbers when I
wear my NPM install I unpacked legit
libraries include those of my product I
run the Bower install that's not the
current way to do this
they've updated gent there's a better
way to do this I just haven't created my
demonstration yet and then I finished
off with some more artifacts at the end
so you can see here these are all the
artifacts of this makes so all the
subsequent steps in my pipeline from
here are going to be pulling from these
artifacts rather than the length of the
tip let's see where we're at in the
running all right so it's two steps
ahead of me already
so once I kicked that off the next thing
that we do is we run our liberal base of
update so all of this stuff is pretty
much the same here we go
in the bill step you can see this is
where I copy some of those artifacts
from that first step so you can see this
throughout the rest of the steps down
here I kick off the liquid base twice
because making my tests in liquid base
and I keep my code changes in the liquid
phase so I go and I install my tests I
just don't like code in the next step I
run those tests okay so this is the UT
peel single section we jump into build
steps you can see here I'm using C plus
C L is equal sales built-in and by the
way all of these tools in dev seus
they're all really well integrated with
each other so if you wanted to build
this same thing yourself you could go
get all of these different open-source
tools put them together make your own
version of this and that's just fine but
here Orbital's already tied all of that
together make sure all of the the
securities handle keeps everything up to
date one of those tools being cocl
here.i modulus equals CL and execute you
notice that this is
different than what I showed before this
is called a formatter so basically what
I'm doing here is when i run UT PL
sequel i'm having input the output out
in a j-unit style document post build
might take that jadianna style document
and i publish it to believe that i
publish that to the pipeline there do
this step come back to here when you do
that that's where you get this little
button here for your texas so we can go
directly into here and the tool that
makes it nice and neat you can see that
we ran three tests it took this long
they all passed should one of your tests
fail and I did this on curves just point
out that I'm not always here looking at
this particular bill one of the test
failed you can drill down in and see
what happened right here's the line that
it failed on and we expected zero
so we expected to generate zero and it
generated 60 so that was wrong all right
so that's how you integrate the testing
if you hit a build like this where the
tests fail it will stop your pipeline
now you can set up notification so stop
your pipeline then sends emails to
everybody and make fun of whoever it is
the Peralta builder so after testing
after tense testing we go and generate
the the dots with liqui basic and I
wanted to catch up so I can show you if
you click the console up but you can
actually run watch the console as it
runs with these tests and so here you
can see that I just barely caught up
with a brand right there's the same
little base like we looked at before but
this time it gives the command DB Docs
to generate the docs and work with the
documents and then zips those documents
opening to an artifact
looks like otherwise that's the same as
the previously basic step assuming at
this point that everything has kicked
off and worked properly now we go into
here where I'm packaging up my release
to deploy into the node version into a
CCS I could have a parallel step that
also deploys the Python version but I'm
just doing no DCs there's a funky thing
I have to do with Python that makes it
more complicated you can see that it
just kicked off so the build steps here
I copied the artifacts from the original
pipeline step the source has changed I
also go copy it from the DB dog step to
get those documents down here I heads if
all that stuff I put everything where it
needs to go and then I make one new
single zip file one little note here if
you're gonna deploy own applications a
CCS if you're no driver for your Oracle
no driver doesn't match the what they're
using in the e CCS
you may get a weird error but the
drivers already pre-installed in a CCS
you don't need it so it's just safer to
do this right here where am I taking the
driver out of my deployment before I
said it
so that's success so you can see that we
started out with source change we
updated the database or in our tests we
generated our dogs kicked off no an ACC
has to repackage everything you see here
how this is spinning you can see that
yes this deployment tab was watching the
build process and it automatically said
you're done I'm gonna deploy and if we
go over to this time
come on it's coming there here you can
see right here these little tiny words
it's actually deploying the current
release someone that's all automated
start to finish so to kick that off all
I really had to do was go in and make a
change in it and push it to the repo and
then all that stuff happens
automatically every time so that is
pretty a very simplified example of how
to build a pipeline with your database
development so that's doing all the
stuff on the PL sequel side is handling
that node middle tier is handling the
oracle jet side and packaging everything
up nice and neat putting everything
where it needs to go and running my
tests and deploying it to production so
true database development is a little
different than some other types of
development we need to learn how to
version control our database objects you
can do that with liqui besar like I said
there's flyweight a few others you can
try to do need to write a unit test for
your PLC start starting out it's going
to be a writing test but after a little
while what you get in the flow writing
test can become really addictive you'll
start writing way more tests than you
thought you would more tests you have
the better chance your products been
around at the end of the pipeline and of
course we want to automate everything we
can you don't want to focus on the busy
stuff you want to automate away the busy
stuff so that you can focus on writing
possibly code are there any questions
yes
Oh like so Java or known or whatnot you
can just add another step in the
pipeline that kicks off your like let's
say you're using j-unit for Java you can
kick off j-unit in fact you notice it
was defaulting to the j-unit format by
the way the build pipeline tool is just
Hudson it's an open source pipeline tool
out there there's also if you're doing
knowledge there's Travis CI there's also
Jenkins there's a bunch of different
tools that you could use hudson is the
one that oracle maintains but it's also
an open source project but yeah you can
you can get as complicated as you want
in that pipeline so what I normally type
line for Dino date is I would collect
all my artifacts like I do in the first
step then I would kick off my my
database changes while I start deploying
or kick over my database changes and
then when I get to the testing phase I
would have I would deploy I got to think
through this now deploy my node objects
to a test
ACS environment first make sure my
database changes are up to date at that
point I would kick off parallel tests
one that tests my node one to test my
jet one that tests my database assuming
all of those fail or fail
assuming none of those fail then the
pipeline merges back in and goes on with
the other steps so yeah you can you can
test all of your stuff it's not DIF CS
handles whatever language you want to
throw at it and we should be able to do
with them see us but the kind of the
reason I focus the way I do is a lot of
times database developers and feel left
out because there's not a lot but for
some of these other languages they got
some really cool tools but there are
tools available for database developers
and Boston are open source any other
questions is it
I missed the last I so when you're
creating the order of your pipeline
especially with the new tool yeah all
right so contact information I will shut
down anyone wants to ask questions come
up and I'll shut it down
but if you think of other questions send
it to me there thank you for spending
your time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>