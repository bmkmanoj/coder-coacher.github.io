<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Distributed Caching for Your Next Node js Project | Coder Coacher - Coaching Coders</title><meta content="Distributed Caching for Your Next Node js Project - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Distributed Caching for Your Next Node js Project</b></h2><h5 class="post__date">2017-07-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/VRCAUeaSKd4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay good afternoon
San Francisco thank you okay so the
quick test how many of you guys here
using OGS
okay this is going to be interesting
it's going to be interesting all right
so this is talked about distributed
caching for your nodejs applications and
we're going to talk about obviously sub
caching
we're going to talk about some of the
implementations that I think will be
suitable for certain projects and yeah
so let's start so Who am I so I work as
a Solutions Architect with company
called hazel can see who cast is the
company that were developing supporting
to all kind of things with the fiddle
cast and here to get to memory data grid
and one of the very popular use cases
that they encountered my in my work when
I work with customers when I work with
the developers is that distributed
caching and and the I'm going to talk
about why it is important for us and
this kind of this presentation what I'm
trying to do I'm doing while speaking
with the customers and in in a
real-world project also I developer
advocate of Scheduled Caste so I'm on
Twitter
I'm my Twitter is over here I'm in
Twitter if you have some questions about
hazel cast distributed caching this
presentation whatever you can follow me
on Twitter also a post very weird
pictures in Twitter actually there is a
kind of cool background about this
picture is that in this picture the Dolf
longer and which he is playing Russian
guy I'm originally from Russia and I
kind of I used this picture a couple
weeks ago when I was a snow globe
it was even cooler because the Dolph
Lundgren was born in Stockholm and he
was playing Russian and I was Russian
who was in Stockholm showing this
picture with Doerflinger
anyway yeah so you should follow me on
Twitter I'm very interesting
alright so caching so why do we cache
and what we cache so and let's start
with sort of the problem what kind of
problem we're trying to solve of caching
usually the problem my arise is that we
need to make things faster we need to
make things faster without producing so
much in the downtime for some reason my
slides just
rolling themselves so I will I will
check if it's if it's think you still on
so the problem is that we don't have a
time to work on performance we don't
have a time to to work on things like
profiling or finding the bug so we want
to make things faster without much of
much of the time so I think the caching
is the simplest possible way how we can
apply and improve performance of many
applications and this why it's kind of
very alright so let's go let's go yeah
and I think this is kind of stuff that
it's very easy to apply and very easy to
implement and very easy to understand
now why caching is important so
basically many applications these days
have a many layers the layers of data
access layer presentation layer business
logic layer and you have a data store
layer have a middleware layer and the
the bottlenecks my arrive in the
different places and using the
sophisticated tools you're using
profiling tools you can find these
bottlenecks eliminate them but at some
times you cannot simply do anything
right so for example you really tried
everything with your database you have
to my two indexes you optimize
everything nothing so in this case you
can okay so let's trying to cache some
of the components some of the data from
some of the components that would be
much easier to access from the cache
then you know get from original source
the typical application typical business
application contains multiple layers as
I already said and multiple servers they
might react with different the back-end
components it can be database it can be
mainframe no secure database etc now and
how to solve the problem in you know
slow slow slow interaction on these
layers we can apply cache but applying
the cache will you know we need to set
what is what is good for and as I said
the performance is the is the simplest
possible explanation why you need to
apply cache in your application so there
is some come some components or there's
some element of your application that
require a data immediately it may be
okay if data would be stay a little bit
but your response time needs to be
lightning-fast
so this why performance and the pure
education for performance would be very
good good choice another another use
case your application is working with
Intel huge amount of data or worse under
intensive load so some of the pieces of
this computation can be done offline for
example some of the data that you can
collect from the previous day you can
collect it in the cache and store it in
in accessing it from the cache because
well you don't need to have this like
real-time data you okay with storing
this from from yesterday so scaling up
data scaling up your cache so how you
can get most of your machine so you have
some logic and you have some some some
code running on your machine plus you
want to maximum use these resources of
this machine so usually people asking me
how I can not they asking so I'm trying
to explain them what's the scale up I
think this is guy this is the best
explanation of the scaling up so you
have a small small Bruce Banner guy and
you can grow it into the Hulk same thing
is that you have some some hardware by
bringing more hardware into into the
computer you growing the beef of this
machine you can have a large amount of
data stored in one machine very big
machines like Oracle Exadata
or even in cloud when you have the
memory optimized machines with terabytes
of RAM when we're talking about scale
you also talking about scaling up so ok
now we already exhausted all the
resources we put every possible hardware
now we stuck in one machine how we can
distribute this in this case a
distributed caching or scaling out you
case it is another choice for solving
this problem so by adding more machine
to the to the cluster performing this
shared memory shared network storing the
data inside inside the network we can
have almost indefinitely we just bring
in more machines bringing more data we
bring in more machine and especially it
works very well in cloud where you can
have elastic environment where you can
have auto scaling capabilities and this
picture I think very good explanation of
scaling out capabilities you have
multiple commodity machines in this
commodity machines they create shared
space shared memory to storing data and
obviously the caching it is very easy
use case to implement there is no
presentation without this slide or this
slide so why have distributed cache so I
already touched about this one a little
bit when I talk about scaling out use
case sometimes is that simply enough put
everything in one machine there is no
capacity to store everything or data is
too important to store in one machine in
case of failure you will lose your data
so this why distributed caching but
having the cache this theory that across
multiple machines it's also very cool
stuff now when we talk about a
distributed cache we want to talk about
data distribution so this why I want to
spend so much time a lot of time to
explain data distribution patterns that
usually are typical in distributed
caching or distributed data world so
question to you what kind of stuff I
have on these pictures so reminder we're
talking about data distribution and I
will explain you so in one picture we
see like the same terminators in the in
the in the pictures of this totally the
same in another picture we have like
sliced version of one Terminator so how
you will apply this like picture
metaphor for data distribution anyone
anyone any any any wild guess okay so it
is a replication so replications the
simple splatter of data distribution you
simply have a cooperate of the data
across multiple machines absolutely the
same copy once the data change in one
machine it will be replicated or quoted
across all these nodes so replication so
now you have a hint so what's the what's
the second one who knows and what
register alright - charlie
ok we have replication sharding so
replication we have a same copy of the
data across multiple nodes with sharding
we have data that sort of sliced across
multiple nodes now in real world
usually this patterns in the pure sense
like when you have a copy of just
replication use very very very often
usually it's some sort of combination
you can so the problem with replication
obviously you cannot scale it
indefinitely because you will be limited
by size of one of the machines with
sharding you basically will be limited
by your charging sharing key or sharding
algorithm that you will implement but
right now theoretically there is no
limit for sharding you can scale up to
physical limitations like a network
sockets etc but in general
algorithmically the charting is much
better to scale as I mentioned that this
algorithms do not exist in any pure
sense so sometimes in real-world systems
they used the sharding with some some
sort of replication applied as well so
for example we have some data that sort
and one node and we have a backup copy
of this data but it's not actual data
but we have just a short of the of the
date and one node and we have a backup
of the scharton another node I will show
in some examples in a couple more
minutes so I guess this picture is
better
explains for engineers because engineers
they love drawing squares and drawing a
whiteboard stuff on whiteboards close
the whiteboards who write the code who
likes to write the code and whiteboard
your interview you're the man you've
probably very successful interviews if
you like doing the stuff anyways so the
way how explain sharding we have a 10 or
you have a hundred of entries from zero
to two to fifty you storing or 4 from 0
to 49 you storing in OneNote from keys
starting from 50 to 100 you storing is
another note so your data set is charted
across two notes and as you can see here
this is example where I have a data
Charlotte for partition data that's
stored on a and B and as a developer you
look at this data as a whole so you
don't think about how the data is
limited so the system that that data
distribution for you already solving the
problem of how to how to chart it and
with replication we have a same copy
across a course to note now now you have
a basic understanding about about how
the things done I'm going to talk about
about how we doing this with shadow cast
and how you can apply it with with no GS
application so because it is talked
about not just right so in a in a very
simple in a very simple use case I'm
going to start hazin cast in the two two
nodes mode that will demonstrate you how
the data will be distributed so first of
all I will go ahead and you stop this so
the way how it looks like I just have
this distribution that I downloaded from
the website today and can you see this
well on the screen
is it phone big enough okay so let me do
like this so I will switch to demo
folder I origin demo folder and I will
start this application Conn console so
it will start instance of overheating
cast member so helicase works as either
as a simple library so now it found one
member that was before that was running
on my on my laptop earlier it joined
this cluster and now if I will take a
look what how this cluster looked like I
will take a look on this one passwords
okay password and we can see what's
happening so we connect into this
cluster now I see there's a two nodes
cluster that have some some default data
have something there and now let's
connect to this cluster from from my
node.js application okay so a little bit
of explanation so here you'll cast is
the Java library and Hittle cast is
written in Java however nothing prevents
Hisle case were exposing API that
available from Java C++ C sharp Python
no GS someone is writing go client right
now so this happened bye-bye us
developing the open client protocol so
the client protocol is his published
version of explain like how the bytes
going around and that's why the people
were able to to develop their own client
so the basic data structure that many
Java developers or not only Java tables
just the developers in general know it's
a map it's a key value it's a I would
say like a simplest no sequel database
it's a map you have a key you have a
value you need to put something you have
a key and it would something into the
by the well you so now so in my where's
my my class let's start with this simple
a data structure that called map let me
switch to the the white screen I think
it would be much easier for you to see
is it better
can you see a call it was kind of funny
story so the one guy showed the code on
the screen and she asked the same
question to audience like can you see
the code people said no he tried to make
it bigger and someone's shout from the
audience I still can can read this code
it's color so it's going to find job
anyways so now in this case it's a
JavaScript JavaScript file that written
using the echo script 6 construct I
think the actual script 6 brought lots
of new cool construction that allow you
to write more concise code on the first
two lines I'm basically using hazel cast
hazel Cal client and to install hazel
cash client I just need to go and
execute command NPM install hidden cache
client simple as that so to connect to
cluster we need to pass the
configuration in this case it's
localhost and the port there are also
different ways how to configure we can
configure different data structures say
we're going to use map that will be
configured eviction for the map but this
stuff needs to be done on the on the
server side on the client side it's
pretty simple like this another
interesting thing here is that because
no GS doesn't have threads it's a single
threaded and event loop based system so
in this case there were two choices of
designing this API using callbacks or
using promises so and the library that
we designed for node.js client uses
promises so that's why you see things
like this like when we're trying to
create instance of the client connect to
connect to the cluster we not blocking
here we're just using this
the notion new hazel cast client will
will create will create a promise and
when this promise will be resolved the
object of the client will be passed
inside this the callback as well and
after that client fool is initiated and
I can use this client to interact with
grid so what about you if I will run
this so what it will does it will
connect to the cluster right now show
some of the information so first of all
important thing here is that client once
it connected it doesn't require to
restart if you're changing topology so
for example if I will go here and so let
me for example kill it I will kill it if
I will kill here it so client will react
on it and the members list will be
updated however data still will be
available and if you see here I have
this map my distributed map I do put
something by key value so let me see if
data is still there so let me I need to
switch to to this distributed map so in
this case I can see the map content and
data still there indeed even though this
data was may be stored on the on the
note that I just killed so same thing is
that when I will start another member
this member will join this cluster and
the client also react on it so now
client will update a list of off members
you see the previously the member was
removed now member was added to the
cluster so with this approach you can
scale your data stores scale your server
side part independently from the client
so for example if you used in the past
things like memcache or Redis you might
find that ok so if you changing topology
of the cluster you need to update
configuration the client so client will
be connected to this to this cluster
members so in
get it different so hazel caste is it
has this approach of providing
information for the client that client
needed reactively so if the apology
changed client will be notified if a new
new member will join client will be
notified plus if something was changed
on the server-side client also can be
notified I will show you some of the
code examples how it can be done now
this is a very simple simple very simple
use case and the map is a very easy data
structure to to understand another very
interesting very interesting so let me
move this guy it's not from here left
over so another very interesting data
structure is called multi man so the
difference how many of you heard about
multi map before anyone so the map you
understand key value so let's think it
like what multi map should look like so
we have a key and multiple values so
this is multi map so ideals of multi map
explained in this use case so I have a
New York and The Last Vegas as my keys
for my map and I'm storing different
restaurants in the different cities by
this key so when I will when I will
apply this and I will run this multi map
example it also will connect to my
cluster and will execute stuff okay and
after that it prints out the result
interesting thing is that as the value
of the multi map it's some sort of
collection in this case in the case of
multi map it can be list which is
ordered collection of elements when you
push something into multi map it will be
stored in the same order that you push
it there if it's set set is another
storage that can be used to set this
data structure that not allow you to
store duplicates so you will put
something we've duplicated the
duplicates will not be added there and
this wife it will be very useful so
let's take a look on the cluster side if
data is actually there
so now I have my same name same name I
use multi mark old restaurants so now
here are doin an error s okay and I'll
do and I see I have a size five for
multi map and four for this multi map I
will do this is how my multi map is
looks like right now
so the there's multiple entries here but
if I will do multi map yet yes like this
how we need to pass this one as a simple
string yep I guess something is with
with this maybe like this I don't know
anyway but it's there so I can I can
read it through the API but maybe I
cannot read it from from Castle Syrian
no I don't think so so the by default I
guess for shrink it uses string
serialization and I need to check how
this the this place how the space is
actually represent internally but it's
not it's not the point in most cases you
interact with hazel cast through the
through the API not through the console
now ok multi map okay so what else we
have so we since we'll talk about the
data structures like lists that can be
used as a storage of values on the multi
map how about having a distributed
version of the list so by distributed I
want emphasize over over again that
distributed version meaning that it's
available from multiple client so if one
client will write something another
client can read this so in this case
it's a distributed plus it doesn't
really matter where clients will connect
so let's take a look on the permutation
of the list very straightforward very
easy to wear it
to you to use so remember when I
mentioned about this list and set
differences in general this is doesn't
matter if it distributed Li sort of its
local list or whatever it's just a data
structure that we know from computer
science so in this case in this code
example I have I have code snippet that
will actually try to add multiple same
elements into the list and we see that
order of this element is preserved of
this element is preserved so also I can
I can run
API that will check the data is in the
list or data is not in the list similar
idea so in this case it contains one
element and contains all elements that I
pushed in in this in this in this
variable similar stuff we've we've set I
have multiple duplicates here so I will
run this I pushed three similar elements
here and voila
so the set not accepted those elements
here also you can see here in some of
the information about so the one client
joins the cluster it's actually print
information about members by default it
will print to the console but there's a
different login configuration also can
be used to you know if you don't like to
see it on your console but sometimes
it's useful because you know what client
what what cluster you connected and what
kind of members you connected to etc now
so now you learn about map multi map
list and set so distributed available
through the multiple API now okay in
sometimes sometimes you want to have a
distributed execution of some sort of
tasks and but you want to execute this
task one at the time you will to have
some sort of critical section across
your task in that is said okay only one
client or only one process can execute
this at the
time so it would be neat to have
distributed locks that allow you to to
grab this critical section so he loukas
provides distributed log that available
out of the box and this lock is also a
cluster wide so if you're trying to
acquire this lock from another
application so you can do something here
anything alright you can do some
modification of some some shared state
and the other process that will try to
acquire this lock will be his execution
will be blocked until until this data
will be executed now this is distributed
synchronization when we talk about when
we talk about different tasks we usually
also talking about how you can you know
distribute this test how you can tell
other process that there is some task
for you and usually the message oriented
middleware it's a good good choice for
this like you have a q1 process will
write to the Q another process will read
from the Q and executed so in hazel
caste and in not GS we do have ability
to send send this data through the Q so
the method offer will post into the Q
method pool we'll listen to the queue to
get this result
we can listen the Q for certain period
of time for example here is a 5 seconds
and we put this item on to view another
item a and another item as well now it's
cool but Q is only one to one
communication we have one producer one
consumer so what about you want to do
subscription or like a broadcast type of
operation so here one node.js process
that will broadcast something you have
multiple other components for example
you doing micro service right and you
need to somehow
by other services without explicitly or
directly communicating with them through
their API right so in this case using
messaging system and they can catch this
message with their own pace so for
example if they busy doing something
they can take it after certain time so
this wide topic it is data data
structure that suitable for doing this
kind of stuff and the way how it looks
like pretty much as you know we in the
JavaScript world know how to deal with
events because everything is interacting
through event in in this API we have
this message listener and the message
listener this is the callback that will
be invoked from the so I can I can run
this topic thing and if I run this topic
once again
why it wants me to run it so I'm for
some reason they want me to run in a
single process indeed configuration and
we will tell that we want to run it
multiple times to do okay single
instance only and I want to run this
topic multiple times so you will see
right now that my application this
application published here I have a
listener already started in this
application so first time it started
that pushed the message to to itself
second time I started another process
pushed another message and my previous
instance of vacation just received this
message automatically so if I run this
month once again you will see the three
times on the first client and two times
on the second one see so data here two
times here so they will able to consume
so this is very powerful concept that
you can use to interact between your
know GS microservices now and I guess
the final thing that we didn't talk
about is actual like how how we can use
the caching in our application right so
I do have like very simple
a very simple Express application that
will demonstrate how caching can be used
in your Express application so let me
show you a premise for this one my where
is it
it might works so idea of this
application is very simple so I do have
my Express application that registered a
repose the handler for get requests and
once I will hit them this application it
will do another call to another service
it's very easy to simulate something
with public API so in this case I'm
heating the github API to get public
repositories for organization right so
in this case I will get this list of
public repositories and I will write it
into the cache so the next time I'm not
going to go and to read it from from
internet now so the way how it looks
like I use the library called super
agent that will allow me to execute the
rest calls against this API here I use
I'm checking if body contains data if it
contains data I am storing a number of
repositories in my map so there is a
method called put of absent I will
writing this stuff into the hazel cast
put if absent allows me to do you know
if data is already there
so next time I will not write this so it
will start another process and that will
require the data I'm not going to I'm
not going to use I'm not going to write
this
the data for the ski because it's
already there and it's another another
example how we can listen for listen for
for this callback for this promise
so result will the method put the flaps
on return promise and after that after I
receive the confirmation for my promise
I returning response into the web so
basically the way how it would look you
I will show you in a second so I will
run my orgs app okay so my application
is running on port 3000 so I will open
my browser all quick here so and to
demonstrate to demonstrate you let me do
it bigger I don't know if I can make
this this panel bigger now I can okay
cool so this is Mike the Google Chrome
and developer tools so with developer
tools I will measure measure performance
I just want to make sure that I don't
have anything in my cache so if I will
go to if I will go to an S github words
this is a storage that I use I'll do
size some nothing is there github
orgs okay cool so the first call will
actually be executed where is my chrome
yep
the first call will be actually execute
the rest call it will collect data and
foot inside the cache so we like click
here
oh I hopefully internet will will work
here okay now so I see it will it took
me roughly around one second to get the
data now if I will go to my to console
and see sighs I have one entry and I
have n so in this case it writes J frog
dev as organisation and writes it to the
5555 the private repository compositor
is that available on the github now so
when I will do it next time so first
time it was like almost one second
now the second call took just 14
milliseconds because data was scared it
not required to go anywhere so let's try
with something else for example we have
hello gasps so hazel cast has 261
repository
it'll case has more open repository
because hazel cast is open source
company we like everything what would
you would put in the github now it's a
similar one second call to to Internet 8
milliseconds now if we will see my cache
so you see now I have a 61 repositories
written as a value of this map and so
the next time will I try to okay let's
try something else
let's try Oracle right Oracle does open
source
51 Wow so cool so in this case we have
similar time so Oracle does open source
also does a lot of things in the things
are on the github as well now let's see
entries so we have Oracle G frog and
Hagel cast written into the cache so
yeah I think it was very very cool stuff
in terms of how it can be done and how
the application performance can be
proved just simply applying this simple
concept plus as I mentioned your server
side component is scalable independently
like if your your cache is growing you
have like tools like a management center
that allows you to see how how big is
your data for example where is my github
orgs right now I shows me how the data
is distributed so remember when I talked
about the sharding versus versus
replication so in this case he look at
automatically distributed this data
across nodes so it happened to you so
let's let's have something something
like at an organization named github
ending something
ok took even more so the way how it
works right now so github API returns
only results in pages and in my code I
actually have this explicitly mentioned
that the per page is 100 by default to
30 repositories but obviously to github
they have more than hundreds of
repositories of private public
repositories on on on their side now if
you can see here so what happens I have
a 4 entries I have a to note this data
is distributed equally distributed
across this cluster so what's going to
happen if I will kill if I will kill the
one of the one of the nodes so I will
kill this game so I kill this guy
and what happens on my application
I still have this four entries it let me
check if my cash still works
let let me do give up mmm-hmm something
went wrong it happened to live demo
everything this happens on live demo if
something better will happen it will
happen now let's take a look on on
actual ID okay so so the client was
trying to reconnect but for some reason
it couldn't which is which is kind of
weird because clients supposed to
recover successfully without any
problems I assume it might be some
problems with multicast that I usually
encounter in conference Wi-Fi but I need
to check and I don't want to spend much
time on it right now well it's still
it's still stuck hmm
okay let me try another thing so in this
case I can okay it's it's a it's a it's
a micro service right it's running on
the cloud it may be ephemeral I would
just simply restart it and let's see how
my application continued to work so data
was returned from the cache right now so
even though client was not able to
recover I don't know why but data is
still there and this is important for
you know for safety of your data that
you stolen care see the hazel cat will
return was returned from from the cache
and after failure where is it where is
my guy I don't see where is another one
so many so many windows will console I
don't see it Hey ok I lost track of my
my console windows anyways now so I will
switch back to my to my presentation if
I have some something else to add here
yeah so what you just saw it was very
successful conference live demo so you
learned that we've distributed caching
it is it's cool stuff that you can scale
your data independently from from actual
storage not necessarily need to have a
cache built in and your application
which is good but in this case you need
to deal with how this data will be
synchronized across the node and the
solutions like he has already providing
the way how this data can be
synchronized which is which is cool
which is out of the box thing now so
this is website where you can grab
information about his request no J's
client so the some of the some of the
insights if you like like strong type
languages he has not just written and
typescript but it compiles down to
JavaScript and it is like a geometric
JavaScript so there's no it's JavaScript
is still readable and when we publish
this into NPM it's actual JavaScript
this is JavaScript that you write but
for developer productivity we decide to
use typescript because basically you
know we came from Java we came from
dotnet this kind of languages and the
types typescript has similar thing so if
you haven't haven't seen the typescript
before check this out that's pretty cool
and it's like I said generates a
geometric code which doesn't require you
know some weird deification or something
like that now you can grab the as I
mentioned hidden cast is open source
Apache 2 license library can use it
absolutely for free without any extra
charge and I think you guys still
engaged they don't see people sleeping
in my session which is already a huge
success
I will take some questions right now so
and I'm here to answer them and I will
be still secure on if you have some
questions in we have another speaker so
yeah
yes
could you repeat please so everything is
free everything I just accept ID I use
IntelliJ IDEA ultimate it's cost money
but everything else plus PowerPoint also
cost money but everything that I showed
it is free you can use it for free
so it ok so question was like if it's
for for rapper how we stay in business
if we're given away for free so
professional services training and
enterprise integration - price plugins
we have a set of enterprise plugins that
we develop for example multi data center
replication of hisoka's cluster with
built-in security kind of stuff that
people if the people can afford having
multiple data centers to support having
the this replication feature the for for
small small fee yes
technical questions please not money
questions
I'm a technical guy and sometimes people
ask you know how much it cost and no I
usually work with sales people they they
know exactly I'm here for technology so
yes my favorite question so what's the
difference between hazel cast and
Reddy's okay I can actually start have
another topic and for 45 minutes just
talking about this but simple thing to
remember actually three simple things to
remember so first of all the hazel
Caston ready to devolve in memory based
technologies but Redis is in memory
database it allows you to store the data
it has limited capabilities for
computation you can write Lua scripts
that will be running on the server side
they recently added modules that allow
you to do something on the server side
as well Hetal cast is memory data grid
meaning that the the storing date is one
of the use cases that hideous works out
of the box I didn't talk about a
computation capability so I'm just
talking specifically about this limited
cash so he Lucas has a distributed
computation engine that allows you to
run
mutation next to your data instead of
moving data around to another
computation engine we can run
computation inside this and you can
submit computational job from not just
client as well second thing
third thing so reddit provides you some
data structure that can be used for
messaging for example the in hazel caste
we provide more I would say we are
developer the weird out a developer
facing so we're providing the interfaces
that people can use without inventing
their own things so this why we
providing messaging capability to queue
topics out of the box not that you just
reuse the some data structures that you
can write this plus for know GS
specifically in other clients so hazel
Cassie has the ability to have a new
cache so new cache is the cool stuff I
didn't show you but it is there so it
allows you to on the client once the
data you request it once you can cache
it on the client so the next time you
read this data you don't need to even go
to the cluster so Redis client don't
have this disk apologies right now blast
I said I didn't say this but hazel cast
we're providing like full experience
right we're providing your server side
we test our clients of compatibility so
we delivering clients and servers
comparing two registers community who
develop this driver this driver this
driver and we kind of think that it is
good to have community we have a closure
client that was developed not for his
wife is okay guys we have gold client
who developed by other people but in
general we as a company would provide
like a full experience for different
clients and I don't have much time so
more I can I can talk about it we
actually have posted benchmark on our
website so if you go to he look at that
chrome and try to find the benchmark we
have a redish benchmark while we're
showing how we can beat them
same thing with memcache it's even
easier with memcache
any other questions all right so if you
have some questions
you can send me on Twitter or you can
send me email how many we have Twitter
how many of you just tweeted this
session today
no no sad okay send me email if you get
some questions thank you for your time
guys and it was real pleasure to talk to
you today enjoy a rest of the country</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>