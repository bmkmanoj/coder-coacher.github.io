<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CON1521 The Java Memory Model for Practitioners | Coder Coacher - Coaching Coders</title><meta content="CON1521 The Java Memory Model for Practitioners - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CON1521 The Java Memory Model for Practitioners</b></h2><h5 class="post__date">2015-12-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/XgiXKPEILoc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello yeah we're starting first of all
thank you all for coming
I know it's the last session of Chora
one as an attendee in not for the first
time I've been to two last sessions job
and I was always thinking like wow I'm
glad that's not me and this year for the
first time it's me and it's actually not
so bad look how many shown up all right
brilliant today I'm gonna talk my last
talk about Java memory model and I guess
most of you have a basic idea of what
the Java memory model is and but today
I'll try to walk through it and make it
a bit more accessible because I'll be
honest with you the Java memory model
isn't easy I think it's actually the for
me at least I think it's the hardest
part of Java the programming language to
understand the memory model took me
years and I still have moments where I
feel like ok am i 100% sure about that
and the thing is jar memory model if you
read through it it reads like a PhD
thesis and it's not coincidentally the
Java memory model was developed as a
Jade PhD thesis and if you read the
original thesis you can actually tell
that it's basically a copy pasted to the
to the JLS so so it's very formal it's
it's defining the Java memory model in
forms of ordering all rings and today
I'll try to avoid that I don't want to
go through formalisms I want to look at
the practical side of what the Java
memory model does for us and how we can
basically apply this knowledge because
understanding the memory model is
important I can tell you so much already
and I also show you why I think it's
very important despite we have like
actors and everything else today which
basically makes a concurrency more
accessible all right but first of all
let's look into why we need a memory
model or what the memory model what
problem it solves and if you've been to
my talk yesterday not at Elton John you
could have done both but it was a small
time conflict the reason that we have a
Java memory model is that a java virtual
machine optimizes our code heavily and
in the context of concurrency that is
very difficult the java virtual machine
tries to understand what i call
doing but in in the context of multiple
threats that is sometimes very difficult
how can you basically analyze and
predict a program if potentially
hundreds of threats access the same
codebase simultaneously right and what
happens when we write a Java program is
that we express our intent of what our
program is supposed to be doing we
express that as Java source code right
and then we hand over the source code to
Java C which compiles to bytecode and
this Pyatt code is then handed over to
the java virtual machine where code
starts to be optimized and in depth
context code is transformed a lot and
basically the memory model sets
boundaries to how this code is allowed
to be transformed so if you for example
use a lot of volatile fields on your
code what this does effectively is that
it prevents the java virtual machine of
optimizing fractions of the code so if
you use volatile fields or synchronized
blocks in the wrong way this can really
severely slow down your programs and
even if you don't use concurrency at all
simply because you basically forbid the
just-in-time compiler to do things
because the machine code that is
basically produced by via Java Virtual
Machine can be very very different to
the program D that we have written the
program that we write is supposed to be
focused on readability on clarity while
the machine code focuses on performance
of basically running a program as
quickly and as efficiently as possible
so let's look at a first slide that we
like to think about when we run a
program and this slider
we all have basically except when we
write programs is the lie of sequential
consistency and what I want to do now
quickly is I want to run this program as
if it wouldn't be optimized so I want to
explain to you why it is important that
the JVM optimizes our code and what we
want to do is that we run this program
on a fake hardware so this fake hardware
has a main memory where we have this
instance stored in form of two fields
foo and bar which start out with an
initial value of 0 right this is how
yeah this this reordering class is
defined right so now we want to run
method
and how do you run a method or any code
on your computer we do that by sending
instructions to a processor and the
processor will then manipulate the data
that we have and every program in every
language on every computer breaks down
to this we have values stored which we
manipulate using a processor the most
simplest computers even my calculator
they more or less work like that right
so in order to add the well you want to
the field foo we have to send this
instruction to a processor the processor
has a cache processors never operate
directly on values that are saved in
main memory so in order to manipulate
foo we first have to lower the value
into the cache and there we can it
increase and incremented the number and
then we have to write it back to main
memory this is how all data basically
traverses a computer and now we go
further to the power value and now we do
the same thing be increment and we write
it back and now of course the last
instruction foo we have to read foo
again and write it back and you can
already think how you can optimize a
program like that of course cache is a
bigger than just one slot this is just a
very simple machine to to make a point
right but in in a bigger dimension this
is true if we have to swap out values
from memory all the time this is fairly
inefficient so how can we optimize this
program well it's it's fairly simple
we can swap around these instructions we
can take care of foo first before we
take care of Baro and that is where the
problem comes in this is a
single-threaded program the java virtual
machine can read the code of this method
and say ok this switching here is safe
because we don't really expect any other
outcome we don't expect the value
through to be transformed after the
value bar right but in a multi-threaded
environment this changes state because
if you look at the past that we can
observe for the first program we
recognize that this third value wouldn't
be possible if we observed from another
threat that is this object that we are
writing you would suddenly see that foo
is 3 and bar is 0 and if you write and
look at our source code here we don't
expect that to ever happen right we
would
never think that that would be possible
but this is a transformation that the
java virtual machine is allowed to do
and it will absolutely do it this is a
very simple straightforward optimization
that we can do in a room like just like
that right the java virtual machine
applies much more complex
transformations to a code than that
and that is why sometimes in concurrent
programs you observe states that you
cannot explain to yourself why they can
even exist right okay so of course the
java virtual machine can even optimize
this further but it doesn't make our our
strange state of the object go away this
will still be allowed to to create an
object where food set to three-mile bar
set to theorem and that's a problem when
we write multiple multi-threaded code
and why is this important let's look at
some numbers processes have become very
very fast in the recent years especially
and it's slowing a bit down but again we
got a lot of free lunch and that was
important for processing speed but the
caches of processes didn't become
exponentially bigger such that this
processing power is actually used by
many programs so if we look at the
colored instructions here if we can read
a value from l1 cache it takes
approximately half a nanosecond before
this instruction reaches the processor
and we can also read from this table
that it takes on an average a nanosecond
to execute an instruction that means
that if we have all the values that we
need to run a program if all these
values exist in the level one cache
level one caches the cache that is the
closest to the processor then we can
actually feed the processor with enough
instructions to constantly execute
something however if we go all the way
down and we go to how long it takes to
read one megabyte sequentially from a
disk then we can see that this takes 20
million mil and nano seconds right
so that means 20 million instructions
cannot be run while the processor is
waiting for this data to arrive people
who also like to to speak about process
of stalling that's happening a lot and
you have to write cache efficient
programs in order to fulfill this
premise and the great thing about Java
is that we don't have to
as much about these things as other
programmers in other languages because
the java virtual machine is smart it
analyzes our programs and it rearranges
our code in a way that processor caches
are used much more efficiently and that
actually adding a lot of performance to
travel programs without such reorderings
yeah we are have to wait a lot processor
alone to as much as they could another
lie that we like to think about when we
when we reach our programs or java
source code is the lie of eventual
consistency and eventual consistency is
a concept that you might have heard of
databases like cassandra uses eventual
consistency concepts but eventual
consistency in a java program doesn't
exist if you look at this program it's
it's a very simple program it iterates
over a flag and as long as this flag
isn't basically set to false the program
will increment the counter and there's
another method which is run by another
threat which sets this flag to false so
we expect this program if we have two
threads running both methods we expect
this program to eventually stop with a
fixed value for the count
however the caching has an effect here
as well again the process of one will
just treat the count value and the
process I can say or the just-in-time
compiler can say okay this flag is
actually never modified by the thread so
we can optimize a program we'll just see
in a second how and also process a cache
to recognizes that it doesn't need to
care about the count right so how can we
optimize this program well the
just-in-time compiler can say ok this
flag is always true so I'll just replace
the value with true then I don't have to
read it every time and I can use my
cache more efficiently again of course
this is an acceleration listen that
doesn't necessarily need to happen but
the Java language specification allows
for it meaning that I can write a
drawable to a machine that is valid
which will pass all compatibility kits
and we'll do this optimization and in
some cases the JVM does this sort of
optimization also the same thing goes
for thread to the thread too might be
required to write false but since the
there's no requirement to ever write
this value back to my memory this
I never happen so even if like thread
one didn't do the optimization this
other optimization might prevent this
program from ever stopping and of course
that surprises us because if we look at
the source code here
we were wondering what's going on here
right okay so and one last lie that we
like to live which is not so important
and that's probably one you heard of
before it's the lie of atomicity
atomicity means that we consider all
values in a Java program to be atomic if
I write to a field that is 64 bit long
like long and double values then we
expect these values to always be
modified atomically however let's run
this program quickly on a 32-bit
architecture it doesn't exist that much
anymore that's why I already said this
is not much of a problem anymore but
this can happen so we have main memory
where all values are stored as 32-bit
values that's the smallest entity that
the Java Virtual Machine or the rather
the hardware beneath running our process
can read then we have the field law the
long field through saved into slots
because of 64-bit and we start out with
zeros and then process a cache one
writes back its value which is the the
hexadecimal for the first 32-bit set to
zero and the last 32 bits set to once
and this processor 2 does the opposite
with those values switched and now since
this is not atomic anymore which can
happen is that first process of 1 gets
to the chance to to write the first part
of the field then processor 2 gets to
write the second part of its field and
then both processes get to write the the
missing parts back so the value that we
will observe all of a sudden will be the
value for long set to all ones which is
minus 1 but we don't expect minus 1 to
ever happen here right that's it's minus
1 because we have to complement notation
and Java where all 1 bits equal to the
value minus 1 all right so this is also
a problem and these three problems are
relevant to us writing concurrent
programs and the travel memory model
basically gives us a way to communicate
to the Java Virtual Machine that
we intended this to not happen we
intended this program to run in a
concurrent environment where certain
optimizations are not long allowed such
that our program doesn't get
inconsistent with what we expressed in
our source code one problem when writing
concurrent programs and that's why
things get more relevant and that's why
I observe a lot of failures and
concurrency when I'm digging around a
bit is this like it's hidden by this
table in a way most computers like my
computer run x86 hot architecture x86
doesn't profit from reorderings of
loadings like if we read two fields
there's no point on x86 to read the
first field after the second field so
generally despite you cannot guarantee
it
generally x86 doesn't try to prefetch
memory and the only reordering of
instructions that pays off on x86 is the
reordering of writing a value with a
later a subsequent reading of value
however on a or m more power pcs on
different hardware architectures
reorderings are way more aggressively
applied so while this computer might
never expose a bug to me when writing a
incorrectly synchronized program if
someone else runs it they will be able
to observe it and what's happening and
in the hardware world is that mobile
devices like to run AR m architectures
traditionally in pull and x86 we're
focusing much on power on running code
fast and even my laptop
I mean it's plugged in most of the time
right so if we run code fast it doesn't
matter so much how much how much
electricity how much power it consumes
on a mobile device and we all know how
annoying it is if your phone if your
Apple watch doesn't last a half a day
right so power consumption is way more
important all of a sudden
and that's why hardware's shifting more
so your program that might or your
library that we write might work
perfectly fine on most computers while
when someone uses the same library on an
android architecture it
isn't happening anymore because there's
another hardware it's not a problem that
Android isn't basically compiling your
program in a correct way it is basically
and I don't think to have a certificate
certificate because there and then order
standard VM but let's say that Android
doesn't have any box it doesn't have any
compiler box they might apply
transformations to accommodate a or M
architecture better then my computer
does for x86 right and that's that's why
we're shifting in the world where this
gets more important because just a study
and I guess this is not a secret to you
that their mobile devices get
increasingly important this is how it
looks like 87 percent of all people have
a computer and 64 percent of all people
have a mobile device and 40 and that's
Americans in this case and 42 percent
have a tablet so there's already more
people owning mobile devices if you take
tablets and mobile phones together
compared to computers and Internet of
Things we have all these can never tell
what's happening of course but we're
shifting in a more disconnected
environment where electricity is a more
crucial issue than it was before
that's why I think it's it's more than
ever it's important today to understand
which our memory model and what it does
just so what is the memory model the
memory model is basically this is a
rather formal definition it answers the
question what values can be observed
when I read a field right so I want to
know what values are valid when I read
for example foo in the example before
can it be three in the context of bar
being zero which is the price that's
right or is that not allowed at the
memory model regulates that and that's
where the academics come in right the
Java memory model formally is defined as
a set of orderings and if you take all
these orderings together you get
basically a transitive closure if you
studied mathematics oh that's that's not
so complex it sounds is basically the
combination of all orderings right but
but it's difficult to reason about it so
what I want to do is that I want to
thunderstorm or I guess tearing down jar
1 already right so what I want to do is
I want to look at examples and then we
can look a small bit at the orderings
right so and one thing about the memory
model is that it's not concerned with
concurrency necessarily the Java memory
model is really just answering this
question what values can I read on a
right and if we read this program right
through with zero then we set food to 1
and then we assert food to be 1
this program will always assert true it
will never throw an assertion error
right and why is it the case well first
of all probably we don't have assertions
enabled so it doesn't matter but the
memory model dictates that in a
single-threaded method that all reads of
the value have to observe the values
that were written before so even in a
single-threaded environment the tower
memory model has an implication and it's
basically to just to get you familiar
with this terminology if you ever want
to read it up we have two actions
actions are all readings and writings in
a way we have one right action and one
read action and then we have an order
which is the program order which defines
that with inside a threat the read
action must always observe the previous
right action that doesn't mean of course
that the Java Virtual Machine really has
to set the field foo to one already but
that read of foo must always be one so
the Java the machine is allowed here to
basically simply remove the assertion
all together because program order
already
dictates that that's a possibility right
and that's why it's important to think
about the Java memory model more as a
way of communicating with the Java
Virtual Machine rather than a way of
influencing hardware decisions or
optimization decisions right there are
two ways or three ways rather to
communicate your intent according to the
Java memory model and you can either
communicate intends on a field scope and
there we have to to instructions you
probably have you probably all know that
volatile is a way of expressing
something in a current context but many
people don't know is that final the
final modifier also have implications on
the optimization and that the driver to
machine is allowed to do and of course
synchronized both it's a method modifier
and the method block allow besides of
course they do synchronization right
they they to mutual exclusion but they
also decide upon reordering instructions
that are allowed to be performed and
implicitly many of the classes within
the java.util concurrent like the lock
for example have implications with the
memory model in with respect to the two
reordering constraints because
internally many of these classes and
they are like like concurrent hash map
use volatile fields and final fields so
what I want to do now is basically I
want to walk through an example of all
of these ways of communicating intent
and then I want to look at some some
frameworks that you probably all use I
want to quickly look at spring and
Attica how these frameworks solve
concurrency issues so that's that's the
rest of the talk it's now 40 minutes so
40 minutes I said again it's not super
trivial but I hope it's very valuable
and then we can all have a beer
brilliant okay so this the text to what
it just said by the way if you want to
have two slides they're all on
SlideShare that's why they're sometimes
texts that I don't really expose I
always get a lot of questions on my
presentations and it reduces the noise
for me to have some explanatory words on
the slide so they should be readable and
not like a book of course but they
should give all the hints if you want to
read up something afterwards so let's
look at a program which fails on many
other hardware architectures not on x86
and and I will explain quickly why but
let's just look at what's wrong with
this program so what's this program
doing well we have a threat one and
threat one basically we implemented a
very bad lock a spin lock where we
basically wait
and until our thread is ready so we
check the field ready and then once we
are ready we assert that the answer is
42 and in threat - we set the answer to
the 42 which is the expected outcome
right and after we do that we set ready
to true so that the other thread can run
the assertion and hopefully succeed well
what we just read is that the Java
Virtual Machine can reorder these
instructions and on x86 we don't reorder
normally store stores and store stores
means to read to writings to have to -
fields are not normally reordered but on
other processor architectures this can
be an important optimization in in real
terms the field for ready might be in a
different cache line and maybe the
sketch line must be flushed to main
memory before the cache line that answer
belongs to has - and then this assertion
will run false right so it is a legal
outcome according to the Java language
specification that this assertion failed
right so how can we solve this problem
well you might have guessed it because
the title of the the slides has volatile
field semantics that we have to do some
volatile magic here and you might maybe
you know that already but we don't have
to make both fields volatile it's enough
to make one feel volatile in this case
ready and if we put this modifier here
this program is not allowed to fail on
any hardware architecture so what does
volatile imply in this case what a tile
implies that when one thread writes to a
value and another thread reads the same
value and that value volatile that the
certain reorderings
are not allowed to be applied any more
in terms of and ears come here we go
back to again academics in terms of
reorderings
and orderings we have a synchronization
order we have synchronization order
which is not only applied within a
threat but also across threats where if
we write to a field and read through a
field these two actions and that's again
a right action a read action
have to be committed in a certain order
and then if we have such a yellow
synchronization order we have to remain
the program order around this fields
practically this means that when you
write to a volatile field that all the
rights that you have previously made in
the order of your program have to be
visible to any program code that comes
after a volatile read of the same field
so as long as both threads right and
read to ready it is not allowed to
basically do the answer it's 42 after
setting the field ready or do the
assertions before the spinning has ended
right so this is basically called a
happens before order and if you ever
have read any article on the Java memory
model these terms pop out a lot pop up a
lot synchronization order that's between
two volatile I'll write on the read and
D happens before order is basically an
implication that everything in these are
colored boxes here have to basically
remain in that order nothing can be
pushed up above the ready and nothing
can be pushed down below the ready so
that's the first thing also volatile
means that both threat so that's
basically fixing the problem of non
sequential consistency we have
sequential inconsistency with volatile
we fall back right again both threats
must align their value now with my
memory so that solves the problem of
eventual consistency the threats that
right or volatile field have to flush
all the values both the ready value but
also all the rights before they're ready
value back to main memory once they do
that and all threats that read a
volatile value have to refresh all their
values from my memory after discovering
reading a volatile value right
so this basically fixes the problem that
we had before in the first example where
when the one action would never become
visible to another threat and thirdly if
a volatile value is a type long a child
of type double then these writes on
reads have to be atomic so we we solve
the third problem
before before the problem of
automaticity atomicity right so these
three problems are encapsulated by the
volatile modifier and of course now you
can also see the downside these are
potential optimizations that could have
sped up our program so if you go around
and you just spread volatile everywhere
on your program you might fall back to a
program that it's run in the order you
actually defined it and that might be
magnitudes of slower that might be 200
times slower 300 times thousands of
times slower if you just do it
everywhere right because this and the
end forces the Java to the Machine to
say okay I cannot turn these things
around I cannot put things together
which might then basically forbid other
optimizations that would have been based
on these previous optimizations so don't
don't abuse volatile you should always
know what you're doing when you use
these keywords because they they seem
harmless it's just a modifier but they
might have huge impacts right so and
it's important these actions have to be
on the same field if you just read any
volatile we have field from one thread
and just right through any other
volatile field from another thread these
ordering guarantees are not there for
you okay so let's look at this problem
and let's solve it in another way this
is the same code as before right we we
spin and then be assert and the other
thread we just set the answer first and
we be set ready another way of doing
this would be to do synchronized and I'm
very much aware to just program my
deadlock because the third thread
doesn't give up the monitor any more
before they're ready is modifier set
right but let's just assume that thread
through always acquires the lock first
if this will be the case like it was
before we still don't have to guarantees
that for example this reordering is not
applied and we don't have the guarantees
that rarely so actually flushed back to
memory to become visible to thread 1
however synchronization has the same
effect more or less as volatile it also
instructs a Java Virtual Machine to
preserve a certain ordering a
synchronization in Java is basically
broken off into two different
instructions and if you look at Java
bytecode basically the
step of compilation of any Java program
you already see that actions are broken
into two different instructions and one
is entering and one is exiting a lock
and you can actually if you do by cop
manipulation and it's a terrible idea
because the Java Virtual Machine won't
recognize this pattern if you you can
break up to have basically the
synchronization entering in another
method then the synchronization exiting
and and that forbids a lot of
optimizations that the Java 2 machine
expects to be doing and there was a
there was actually an entire talk ajar
one just about this problem or less
so it's something severe but you can't
do it if you just use plain Java again
we have a synchronization ordering here
because every time you exit a
synchronization block and you enter the
same synchronization block from another
threat the same restrictions apply that
applied before both threats that the
first threat on the left has to flush
all of its writings to my memory and the
second threat has to get all values back
from my memory we don't really have the
reordering problem anymore because of
course the synchronized blocks are a
mutually exclusive so even if it was
reordered with inside a block then we
would only gain control from the another
threat once both actions were already
committed and flushed back to main
memory so again yes
yeah
basically all actions all actions must
be committed that either like if it has
you could have a side effect there right
so you might have to you basically the
easiest thought you can have is it is
it's forbidden that you are surprised so
once you exit the monitor everything
needs to be flushed and once you enter
them on it all you have to fetch
everything from my memory what the java
virtual machine is allowed to do is that
it basically it's called a roach motel
it can put instructions inside the block
but it is not allowed to put
instructions out of the block so
basically it might it might do more
before it flushes or it might basically
pull before prematurely right but it's
not allowed to yeah for example flush
everything flush to 42 but without
flushing they're ready yeah
and no it's not allowed yeah I mean
depends on if it's on the same cache
line its implicit right but as far as I
know no oh no yes it is allowed yeah
that's sorry no it's allowed within the
synchronization block that's basically
an entity in this case you don't have
any ordering guarantees anymore but you
have guarantees of mutual exclusion with
spatially it solves the first problem of
reorderings but it's not allowed to get
anything out it's basically just these
barriers you can see them as borders
that you cannot cross we can go in and
but not out and the question was if it
can basically flush the answer before it
flushes to ready or the other way around
if we can flush ready in this case
without so if you basically have one
threat to synchronizes and another
threat it doesn't synchronize you don't
have to guarantee then you can again
observe in the wrong order okay so in
this again it's based in the formulism
it's based on synchronization order in
combination with program order and and
basically what the transitive closure
means is that we can connect errors
that's really what transitive closed my
mathematics professor wouldn't be happy
with this explanation but but for now
it's good enough connect the aerostats
transitive closure all right and from
that we derive what is the happens
before relationship which we desire in
order to make this program correct right
okay LUMS so there's more actions than
that that's the main actions but let's
let's look at that one we start a new
threat and then the first and only
action of the threat is to assert that
to the value through is set to 42 we
don't use volatile here important for
this example are we guaranteed that this
assertion never fails well we are this
test color the reason that this is
guaranteed is that every threat in the
terminology of the Java memory model
starts with the first synthetic action
with its the start threat action and we
have a synchronization order between the
action that starts the threat and to
start action so any threat that we start
from a threat basically copies all the
well you
into its cash which are already observed
from the other threat in this case this
is fool so again we have program order
synchronization order we connect dots
and we end up with the happens before
relationship right so also here we don't
have to access the synchronized because
of course because maybe not never read
42 again but we can start a new thread
and it's guaranteed to see the world as
we see it from the starting thread okay
let's look at final field semantics and
we're solving another pre problem here
which often occurs in the context of
double check locking we're actually
going to look into double check locking
as an example of application of the gel
memory model in a short while let's look
at this example what we do here is that
we create an instance of unsafe
publication and already spoiling the
outcome of course and the question is
can this assertion ever fail right and
the answers of course yes it can fail
and important here is that we only a
certain cases the instance isn't null
right otherwise we could get in an null
pointer here because thread one might
run after threat too but it might be
that we observed the instance in a state
where it's uninitialized and the reason
for that is that initializing an object
is broken off into two actions or two
multiple actions actually first actually
is the the pure object allocation
basically writing an object to the heap
but without having executed the
constructor yet so the constructor and
this I refer to it here as in it which
is also the the bytecode representation
of a constructor but construct an array
it's just a method nothing else it might
run after the instance was already
allocated but before that the assertion
might run after allocating the instance
such that the if instance is null
returns false right err true then we run
the assertion but in it wasn't run yet
so assertion yeah asserts to to false
and throws an exception and arrow in
this case right so how can we prevent
this and again the title of the slide
says in a way what the problem so what
solves the problem and it's
setting this field final right the thing
about final fields is that we have a so
called freeze action at the end of a
constructor once we set a field final
the Java Virtual Machine basically is
not allowed to publish an instance to
another threat before setting this field
to the value it receives in its
constructor so once a field is as marked
as final you can rely on the object
being fully initialized in all other
threats when it is observed right yeah
yeah no I mean practically the
implementation if you look at the source
code of hotspot that's what it's doing
and sometimes you see people wanting
that behavior so they just have a field
dummy final field dummy is object right
that's terrible because I can implement
a JVM which just wants to annoy people
that do that which legally yeah
publishes instances very badly right
delays every initialization action and
just sits there for a minute and waits
other threats to fail so this is only
true for final fields so if you have two
fields right one is final and what is
not final and you assign the same object
to both fields the one object might be
there already and the other one might
not be there yeah and a hypothetical
yeah yeah I mean that's the thing about
I'll have one slide on that matter
you should always code against the
specification never against the
implementation of hotspot unless you do
like high performance work and I know
people that do that they run around
implementations but what it basically
requires you is that whenever you
upgrade Java even if it's a just a
security check a security update you
have to look at the implementation again
run all tests see if everything works
again because you did something that is
technically not allowed right so the
freeze action is only true for the field
instance foo here so and that introduced
is not a synchronization order if you
again look up the Java language
specification and read the formalism
this is referred to
the dereference or the no
desynchronization order but this
basically says this constructor has to
be executed as a whole so it is allowed
to see the field as null even though it
technically already happened but it
wasn't flushed yet but once you flush
the instance allocation to the heap you
also have to flush the information about
setting this field through 242 so then
again by setting this field final the
assertion will never fail again and if
you if you pay close attention this
happens before or during doesn't cover
the entire code this time it only covers
the constructor right so once you
allocate it the freeze action which is
basically the the freeze it on the heap
make it accessible to everything
everybody else this has to happen before
another another thread can observe this
object yeah yes yeah there's there's
another watering that I didn't fit on
the slide basically it's not once you
walk through a final field all
references that you make through that
final field are visible so in that way
in in theory you might observe an object
in two states once fully initialized
because you dereference the object by a
final field and once partly initialized
and that sounds like it's impossible but
it's possible if you look at C 2
compiler what it does it's it's crazy
it's really 20 years of of crazy
performance work right there's a lot of
things you might not expect to ever
happen but that's it I spend a lot of
time on trying to understand what
hotspot does and I'm still apprentice
level despite I'm I'm doing this for
years now right yes yes of course if you
basically read the field from another
threat which isn't in a synchronized
block if it wasn't a synchronized block
with the same monitor if the code
couldn't run yet right and once you
access the monitor then you have to see
the field fully initialized but if you
and that's the problem of double check
locking we look in this in a second all
right so here's text again so there's
more actions than that one sex
Colonel actions and that really refers
to Jay and I so Jay and I basically
let's say we implemented a native method
which asserts that foo is set to 42
could the just-in-time compiler reorder
foo and the Jane I call here the answers
of course no and that's what makes Jay
and I so dangerous and that's why Jane
is considered to be slow this simply
because everything that Jay and I does
is not known to the just-in-time
compiler the just compound compiler
cannot read native code right so
basically it has to assume the worst as
to say okay this J&amp;amp;I method expects the
world in a state how it was basically
described here so external actions
basically say you can never Ryo do these
things this has to remain in program
order and train is more than you think
Jane I might be system.out.print Allah
right that's that's native interaction
because you don't want anything on the
console e that describes a state that
wasn't supposed to be there right so
that's why I like logging frameworks day
they basically write everything to a
buffer and then they pulled from the
buffer to read it from the console ER
from another thread because that's
better
for optimization otherwise you have
these native blocks everywhere that's
really important if you have any like
they're random system.out.print ulm that
you have maybe just with an if something
is enabled right if the JVM cannot proof
that this code can be deleted anyway in
the production environment that might
refrain from from optimizations that you
could otherwise to write sames for IO
it's if you have to form and relevant
algorithms for example it's always good
to make these yeah blocking actions from
another thread and to pull something
from a buffer it helps the just-in-time
compiler sometimes right but that's
that's micro optimization work sometimes
so be careful with what you optimize but
it's good to know this stuff right okay
and there's another rule this last rule
that the threat to version actions again
is this program allowed to assert false
and throw an arrow and of course the
answer's no threat to versions actions
basically means if the JVM says okay
this action will probably never be
reached then I cannot execute it because
we would be confit
used if who would be set to zero despite
the field not being volatile because we
effectively prevented this action to
ever happen right
that's basically what but threat
aversion actually means I name it with
the academic expression because if you
read through articles through the java
language specification you will see this
right okay ramps so in practice double
check locking if you don't know double
check locking basically it's lazy in
this realization right so what we want
to do is that we have a singleton object
and we want to initialize it lazily
right because the constructor has some
some expensive opera's age or expensive
initialization procedure maybe goes to a
database is something and of course we
do shouldn't do that but we don't know
in general right and what we want to do
then is we want to check if an instance
is null and then we synchronize on on
this instance right because all
instances are received we are the get
instance method and then we check again
if the field is still null because maybe
another thread did the same routine and
already initialize the instance before
we even reach the synchronization block
and then we set the instance and then we
return it right and if you paid
attention yet
you know while this can fail by this
assertion in method can be zero and it
is because allocating an instance is not
implicit implying that all fields and
the constructor is already run right so
we might have written the field from one
thread and then basically be at a
context switch that thread was delayed
before even executing the constructor
then another threat came in it checked
okay instance is not null anymore so I
just return it and then I basically
expect food to be 42
despite that the other thread didn't run
the constructor yet right and then we
have an assertion error so basically we
haven't gained anything if we would have
always entered the synchronized block
and we didn't in this case because the
the instance already was allocated then
this problem wouldn't a cure
so yeah probe and have color yeah right
so what we have to do basically is that
we have to make this feel volatile right
and only then we have an ordering
guarantee that implies that the
constructor has completely run because
at one thread we right through right to
the field writing from another thread we
read from the field implies the
synchronization order implies that all
the rights from the one thread are
visible to all the reads of the other
thread so this is the only relative a of
doing double check locking yes sir yeah
you're right it should be on the class
so it should be a double checked yeah
you're right
good point I'll fix it later right so
then this has really bad reputation
right in some Club in some cases yes
if you have there's there's different
patterns to making this safe and one
pattern is final filled rapper so what
they do is basically they instead of
assigning the value directly they have
like a generic object called holder and
then that has a parameter T right so you
basically create a constructor which has
a final field of parameter T you assign
the instance to that field and then you
only read the field via the instance by
going through that final variable you
again guaranteed to see all fields
initialized there's an overview that's a
great I hate to always quote Alex a
triple F and all of my talks but he has
great resources and one is about a safe
initialization where he compares the
performance implications the problem
with that approach is that it runs often
faster but not on all hardware
architectures so you can again micro
optimize for certain processes but you
don't want to go there that's one of the
reasons we use Java all right we don't
want to think about these things
the fastest way actually is always to do
something in an enum so a field of an
enum is implicitly available whenever
you read you know if the enum class is
read lazily then we basically have the
same effect we initialize the single
instance lazily but what the cost that
we have is an additional class right but
the same goes for holder and that's why
I personally prefer double check locking
because today on modern hardware
architectures wallet I reads are more or
less free wallet I rights have a like a
minimal performance overhead but Walter
Reed stones on at least on x86 it's not
true and arm but you have to get it
somewhere right so but the cheapest way
is enum initialization actually Scala
this is what Scala compiles to in in
bytecode when use the lazy keyword in
Scala it's double check locking in
exactly this form if you do this
yourself just never forget volatile you
will be able to observe the strangest
things right okay
another common problem that I I see in
practices that's the practice LM a
partner of the talk is that people make
arrays volatile the problem here is that
we have the array volatile right and
then we read we have the same problem as
before
we read a value from the array and then
we basically have another threat that
again sets the answer and sets the flag
in the array the problem this time is
that the the volatility really only
concerns the array itself here we want
read array for forgetting ready and then
we read it began to set it because we
read the array but we set the value on
the array and that's different thing
right and this time we have two reads of
a volatile fields and two reads other
than a right and a reads they don't have
an ordering implication so here again
the Java Virtual Machine is allowed to
optimize code and to flip things around
so once and people like to use like they
they have a distributed job right and
they write results of a thread through
an error element and they think think
that by making that array volatile the
results of other thread gets visible
right that's not true because the
elements of an array
there's no way in Java to declare array
elements to be volatile only the pealed
references right and you cannot go into
an array and make make fields in an
arrow so what the Java the machine has
instead it has a so-called atomic
integer array in an atomic integer
arrays you can make volatile reads of
elements you basically give the array
thun thun an object instance of optimal
integer array and then under the covers
the java 2 machine at least hotspot uses
the unsafe class but in a safe way right
so you are allowed through access field
values and I think in Java 10 we will
have more handles and all these fancy
things hopefully then we can do that but
right now we don't have a way other than
having a wrapper class ok I have 10
minutes left
we almost through as well let's look at
some practical implications do you think
that is safe we have a spring beam right
and spring typically is in a
multi-threaded environment right
we have controllers somewhere we have a
web application and the web application
accesses repositories and all the like
right however many people in spring like
to do certain and instantiate a setter
initialization and have like post
construct annotated methods which are
then run after the the spring context
was set up so we wonder can
assertion if it's triggered from another
threat or any at any time before Slyke
and these values be not set and the
truth let's know it's not possible for
spring everything you do in the
initialization phase in spring or any
well-written dependency injection
framework is guaranteed to be visible to
all threats later of course internally
spring doesn't have a magic trick that
it can use to do that but what spring
does is that it writes all beans to a
volatile through a volatile value and
then whenever it hands a pinned over to
another instance from another threat it
will read the beans over this volatile
field and that way the travel memory
model guarantees in a way that foo and
bar are fully initialized once you have
reached your actual application after
the initialization phase right and this
is only true for initialization if you
have a spring beam and you mutate the
values then a multi-threaded
applications again is allowed to do
reorderings and 2c values in a certain
way because just in time compilation
doesn't work like it's happening at some
point and then it never changes its
dynamic it's it's basically adapt if it
looks at how your program is like right
now and it might do rearrangements even
after the initialization so don't rely
on it if you have initialized something
spring gives you extended guarantees
similar to final fields or to volatile
their values you don't have to make foo
and bar volatile here but it only works
for the initialization phase afterwards
you own your own in a way and then you
don't even have to remind of a final
field which is even allowed to disallow
to be changed right ok same goes for
actors acha actors I take this as an
example now are not guaranteed to be
executed from the same thread for all
messages right so how does eka do it in
this case we right through to be 242 and
then we send a new message to ourselves
to trigger the assert akka does the same
trick akka basically writes all actors
to a volatile field once a methods is
dispatched and if another threat has to
execute the same message that this
thread reads the same actor back from
this volatile field and then under the
covers of course we have again an
ordering readwrite you can argue that
it's
easier to just accept that eka does
everything for you but there's no
basically no trick akka isn't isn't
faster because does something magically
right occurs just using the primitives
given to you by the Java Virtual Machine
and by the Java language specification
rather it's by the way a nice nice thing
to know most Java VM that the memory
model is a model specified for Java the
programming languages most most
programming languages that compile to
Java code don't have a memory model
well-defined one so basically you just
have to accept how does this map to
bytecode and then you can use the Java
memory model in a way right okay so yeah
one thing that I see sometimes right how
the Java Virtual Machine implements the
memory model is by using so-called
fences fences means that whenever it
does count it encounters a volatile
right it will just flush everything and
once it encounters a volatile read it
will just pull everything from my memory
and I do that before that we have to
read and write the same field in order
to have these guarantees in hardman
practical applications this is way too
complicated to check so in most cases
like here we can just say okay we
synchronize on a new object that means
or else we enter a monitor by accident
monitor this is like flushing memory
instruction right and you see that I've
seen this way too many times in library
code and and libraries that everybody
uses partly because this worked out
however the JVM becomes smarter every
day so that's why I'm telling you code
against the specification not the
implementation because the JVM this is
we can say that right so the JVM can say
that to say like this is nonsense
I removed this and then you lose your
guarantees right so don't rely on these
things okay we almost through and just
quickly if you want to prove correctness
of a program what you do we take all
these orderings I've shown you you
basically lay upon them and you have two
small intersection where you say ok this
is the only value that's allowed to be
observed at that point so I have a
correct program I just proved it and
again my mathematics professor would
love this this is how you do academics
but for us as practitioners that's not
free
it's really hard to prove as well and
real programs so what I can recommend
you is a framework called JC stress
again I am mentioning way too much so
probably huge equipped assault but he
doesn't so I just can refer to him Alex
ACP laughs has written a framework that
basically runs a lot of load on your
program and it basically tries to
trigger scenarios where reorderings cost
v8 states so basically what it does it
runs his code millions and millions of
times and then it checks all the
outcomes that you write to in result and
then will tell you ok you know what this
r1 this result that we have written it
was 99.9 percent of the cases it was
actually 40 to what you expected but
these four or five times I have
encountered the value zero and that's
because yeah optimizations aren't
deterministic sometimes things are
triggered in a certain way the framework
basically tries to push your JVM to do
optimizations as much as it can and this
is of course not a unit test but it can
discover problems in your code and the
problem is that it only tells you you
have a problem that sometimes not enough
but that's why the memory model is hard
right
proms just like just a quick look before
we're done in the future the Java memory
model is currently under revision the
atomicity guarantee doesn't make much
sense anymore for 64-bit machines and
everything today is a 64-bit machine
almost so there's considered because you
can't do like you can't just get the
volatile part at the atomicity part of a
volatile field you have all the
guarantees which is of course much
costlier than only applying atomicity so
probably in the future we will see the
memory model to be revised to
encapsulate that there's also another
funny thing is that you cannot make a
field post final and volatile right you
cannot guarantee that it's a certain
state after running the constructor but
still have it mutable in a concurrent
context that's a problem too many people
so also there there's revisions over how
the memory model will be revised it was
already rice in the past once JMM 133
was that and before before the primary
model was broken so if you run old java
Bertold machines before 1-3
you have to be super careful how you
write your code in a concurrent
environment for various reasons right
okay
data races we stopped over that
basically it says the java virtual
machine if you have data races at least
a java virtual machine has to give you a
well you that makes sense it cannot make
up stuff right so just that slide I know
I want to leave you want to leave that's
it for me thank you so much for coming
my name is Rafael
I'll be here five minutes more ten or
however you want basically I'm flying
home tomorrow so if you have questions
just come forward you find me on Twitter
I have two open source frameworks that I
try to promote one is fight buddy which
I talked about on Monday just won a Dux
choice about on Tuesday it's a lot of
work and it's really cool applications
are check it out documents which I as
well thank you so much bye-bye</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>