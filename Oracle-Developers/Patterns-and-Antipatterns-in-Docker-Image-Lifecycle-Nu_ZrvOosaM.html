<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Patterns and Antipatterns in Docker Image Lifecycle | Coder Coacher - Coaching Coders</title><meta content="Patterns and Antipatterns in Docker Image Lifecycle - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Patterns and Antipatterns in Docker Image Lifecycle</b></h2><h5 class="post__date">2017-07-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Nu_ZrvOosaM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so welcome to my talk and today we are
going to talk about patterns and anti
patterns in docker image lifecycle and
my name is barb so degorski I'm the
developer advocate with with Jeff frog I
usually describe myself in this way
drink and know things so today at least
during the day I will tell you these
things that I know and in evening San
Francisco after all we'll see then Jabar
from Twitter and everywhere on the
internet so feel free to find me and
connect and shown out in the video the
slides the the video ok the slides and
the links the feedback form and small
raffle are already there you go to Jeff
of the calm slash show notes find
today's event find this talk you'll find
a lot of content everything that we are
going to talk about is there is the
video and thanks to those gentlemen on
the back I hope I will have the video
right after the talk I will upload it
and it will be there by tomorrow so you
will be able to see the video by
tomorrow and not wait until the official
channels will publish it and I hope
you'll find that useful
AJ frog we do a set of product around
managing binaries you might heard about
our factories being are the most popular
product bin trade distribution platform
an x-ray in recursive component analysis
we have a table in the expo zone with
those cool t-shirts if you still didn't
get one right after the talk I know
where you are going right and come talk
to us and we'll see you we will show you
a couple of cool demos as well this talk
is not about the factory and I will use
it maybe a couple of times as an example
but it's definitely not about that and
it's not doctor and we will start with
with a small poll show of hands and you
raise your hand you keep it up until
what I ask is not relevant to you
anymore all right so let's try it
who heard about docker okay hands up and
for the sake of the recording I will
summarize everybody know about docker
who can do the tutorial okay one couple
of hands went down the majority are
still up good how many of you peep you
know playing with it
doing stuff evaluating how good it is
for your work okay still decent I would
say like what 30 percent and now the
magic amps how many of you use docker in
production well hand down your wires
okay
and let's just count the remainings like
four and that would be like what like a
less than 10% of the audience we started
with everybody ended up with less than
10% it's actually getting better because
when I did this talk even in a couple of
months ago it was like everybody heard
about Doctor Who is in doctor in
production no one and the question is
why and there are a lot of theories of
what's so cool about docker that get
people really excited and what's wrong
with docker that people giving up before
they reach this goal of taking docker
and production and one of the answers my
talk is trying to find them of course a
deal with and and I would say that one
of the reasons we don't take doctor to
production in a lot of cases is the lack
of trust doc here is a pretty scary
layer of indirection right it's it's
this black obscure box that stuff is
running inside and we are not really
sure what we are not really sure is if
the inductor is it the same thing that
we wanted it to run we have a problem
with integrity of what we put there to
what it runs and we're going to talk
today about how we can actually fix it
by implementing a continuous pipeline
for
or what Doki runs for lager images so
that's that's my what my tongue is about
and the reason why I think I can be the
one speaking about that is because I
work for Jeff rock and as you can see we
have a very long and love relationship
with Daka and that's if you are not sure
frog
hugging the whale right and and in that
because we we do binaries for for very
long time actually we had something that
it's called docker registry today before
dr. D Tucker registry and and the reason
why we feel our products are more
interesting for the industry as being
universal and not only docker is because
of that so that Solon hikes standing in
this room actually dr. Khan 2015 that
was took place here it was all this huge
ballroom and the stage where was I think
somewhere over there thousands of people
sitting right here and he was asking
this question who is using doctor and
nothing else and and the question is
okay so you have a company that the only
technology that they care about is
docker
whose is endogenous and nothing else
well no one and that's an answer from
you guys and there was the same answer
for thousands of people now because it
doesn't make any sense to only do docker
docker is a container technology this
analogy works very well in multiple
levels including this one no company in
the physical world will make their
business from shipping empty containers
back and forth right there is always
something in it and something in it can
be Java can be a NPM can be Python can
be a dotnet applications whatever there
is there is something in it and having a
tool that takes care not only about the
binaries of docker but about binaries of
everything else you build makes a lot of
sense and that a what what we do so
let's get back to the topic we gathered
today and this is the patterns for
implementing continuous life cycles for
daughter
and as usual with patterns where
software engineers will love patterns
and that because someone else already
solved our problem so all we need to do
is come to a conference talk or read a
book and boom we have a solution
and when we have a new technology like
docker so very new but the adoption of
course is still pending is to ask
whether we have an existing program and
if you have an existing pattern we would
apply directly to this new technology so
continuous integration delivery
pipelines this is something we do for
years and we would say ok we can just do
whatever we always did that's a pattern
that should work with docker so let's
see what this pattern is and we will
evaluate whether it applies to bloggers
as well so this is something that we
call the promotion pyramid it's only
complicated graph just because there's
too many dimensions on it but the idea
is that it have a lot of bills in the
beginning of your pipeline and those
bills are very short but there is tons
of banners that we built right and I'm
talking about thinking about unitest
all the code you write parts or fails at
unit tests some can survive and it goes
to the next fifth the next steps might
be integration test integration tests
are longer but the amount of binaries
that you run through the integration
test is smaller and then you go to this
permit with less and less builds we set
the take more and more time and
eventually you end up with a small
amount of production ready artifacts
that went through all those settings and
the ended up rated product just taking
this and putting it on the side you will
get this picture and that's great
illustration I like to use it a lot from
agile I am book by Michael Futterman I
am it's a relatively old book specially
by you know continued software
engineering measures I think it's been
around for 10 years or something if not
more but this picture still stands for
every technology that you take this
those are the binaries that you build
you pass them through it it's called the
quality gate and those want to get our
dead
that we spoke about previously and you
pass them through those repositories
through those isolated spaces in which
only the next quality gate can access
and then eventually you stage them one
to other to another all the way to
production if the quality requirements
are met right this is not new by any by
any you do it for years right that I
hope I didn't explain something new here
to anyone now let's see how it fits with
docker now one of the most fascinating
things in docker is the docker build
command and and and the daughter
beautifu it's an extremely simple and
extremely powerful concept you just take
a text file and you throw commands
inside and eventually you'll end up with
a contact with an image that has
everything you wanted right that's
that's a super powerful bill pool much
easier and much more appealing than
other builds that we know about compare
that to an auto to ant omegan right this
is way more powerful and easy and the
problem with powerful and easy tools is
that we naturally want to use them more
and I want to do that when you bring
that to a slightly changed version of
the same pipeline you only saw that the
only difference here that instead of
promoting the binary file the docker
image we promote the docker build file
promoting the document file promoting
the text file is something very very
easy all you need to do is drag it
differently in your version control
right you can pass it through branches
you can tag it differently hell you can
just name it differently and then or put
it in different directory and move it
from directory to directory there are so
many ways how
even managed one text well it's
definitely much easier than managed a
binary file which you need you know
specially docker image when you need
different facilities to to work with
text file is very easy so it this is
what we attempt to do and then we just
run daughter build on every environment
and we end up with image in every
environment right we just reproduce it
in every environment this sounds like a
very good idea
but it's not I think that Shanghai China
that's like if it's kind of hard to see
that's a house that was built and then
just felt after it was already built so
why it's not why it's not a very good
idea that's why here you can see docker
file that every line in it and I mean
everyone except of creating the
directory and running their application
is the dependency management relying on
a latest version of the dependency now
when I build this talk I was like okay
I'm going to create a ridiculously
fragile docker file like no one in the
world will do that but I just want to
make a point so I will do something like
to the extreme and then I just went to
the internet this is true stuff in the
show notes page you'll find a link to
github very popular one of the node.js
application that this is there docker
file I don't need to invent everything
the barielle it is much work that I can
imagine now where and there are couple
folks there I think we count for that
take docker to production and this is
their time to send up and shout
because this is know how you manage it
you can fix it right guys let's fix it
let's start with the prompt file how we
can fix this guy with the firm statement
very easy how we can figure that thank
you we just added version here you go
done is it better now the prom did we
fit the firm statement well as you might
ask i if you may imagine if i ask the
answer is no right now let's let's talk
about why not well one of them in a bun
to 1404 when it was released on a guide
naturally April 14 that's why it's 1404
right okay so it was like what almost
three years now for the no.4 is a very
good version and it's very popular it's
stable everything's good with it so a
lot of docker built files even today
rely on 1404 at the base image exactly
like we have here but something's
happened
between April 14 and today
something really bad security wise some
other members affected tons of linux's
what happened as a cell or as we know it
hopefully thank you very much horribly
right that's a name hard wood happened
and of course fortune for was affected
by our bleed and now here is the dilemma
that canonical the company behind 0.0
distribution is facing from one side
this is the released version 1404 it's
not like kind of integration version or
or a snapshot or better this is the
release version release version means
immutable every time I ask for 1404 I
should get the same results that what we
know about release versions on the other
side we know people especially the ops
people what ops people hate is change
right upgrading Linux that's a horrible
idea because so much can go wrong and
also you don't screw up my app time
right upgrading is a very bad idea
so you fortune on for works
there is no way without applying brute
and then brute force and like beating
this guy to force him to update to a new
version of Linux there is no no way so
here is afraid of 4:04 is vulnerable
with our ability there is no simple way
to make people upgrade so we're going to
did the right thing they incorporated
security up updates like the updated
version of OpenSSL into the already
released version what you download now
as 1404 is not at all what you download
it 3 years ago is 1404 and this of
course can happen every day right so new
vulnerability discovered you'll get a
new security update into 1404 it won't
be called 1404 o1 it won't be called
1704 it will be still 1404 that means
that running this file multiple times
running the same docker build on a same
daughter dual file might end up in
different results so that won't fix it
any other ideas how we can fix it now we
can use what it's called fingerprints or
or or checksum or shut to or all other
cool names this is a checksum of a
docker image right it relates to some
version and every time we ask a boon to
with this checksum we'll guaranteed to
get the same version right bulletproof
do you have any idea what version it is
by I think I just said uh no on the
keyboard when this game came out I don't
know a real checksum at all right this
can be anything so this is very solid
but it's absolutely useless
and how about those by the way can we
fill those they up get commands
how to fix those come on guys you know
version thank you very much this is up
get right this is this this tool we know
that accepts versions after big exams so
we can go like now yes and then
semicolon whatever version of nodejs we
want will it fix it yes that will fix it
but we rely here
on the fact that we know how up get
works now I assume most of you here I
have juggled around I didn't have Java
background yeah most of you so let's say
I run here run MVM install is it good is
it solid will I have reproducible
results every time on the Ramseys
daughter file well it depends it depends
on the form palm file in place do I have
a latest versions there do I have ranges
in this palm file and all the transitive
dependencies of this point file maybe I
have ranges or latest versions in any of
those but that's again you know we can
fight why because we know Megan we know
Java I can force me them to not to
accept any version ranges or latest
versions by using the maven enforcer
plugin right now I know how to fight
those because I'm good with men this is
what I did for the last 10 years but if
I have your run download random
from the internet dot sh how about that
is it like is it solid will it work we
have no idea so my point is there is no
way in the world you can rely on docker
to run the same docker file twice and be
absolutely sure you will get the same
results no way and this what will
eventually happen you run docker build
on the same file and you get different
results because
dependency in your doctor bill process
changed without you real and another
pattern that I want to throw in here is
the immutable server pattern who heard
about the mutable server pattern alright
good I can tell you something new this
why we are here
so immutable cheran pattern that's
another great pattern from Martin Fowler
talks about servers
you remember how servers were 10 years
ago they were tangible hardware and if
we want to change something in the
server we logged in into this server and
made the configuration change right and
that was the reasonable thing to do but
it was very complicated to manage judge
because state is bad and hard to manage
and we might ended up and we eventually
ended up with different servers that
supposed to have the same configuration
but have almost the same configuration
and that always was the source for
troubles in operations always managing
state is bad now servers are virtual
they are software we can throw them away
we that they don't cost anything to us
and then brings us to idea that instead
of changing and managing change we can
just kill them and fire a change the
configuration and produce a new one from
this blueprint we have one blueprint we
can create endless numbers of servers
out of it and if anything change we can
kill all those it won't cost us anything
change the blueprint and get a fresh set
of other servers with exactly the same
configuration it only makes sense and
the only thing that Martin Fowler did it
took in the name of the pattern and
that's the immutable server pattern and
now you know
what I'm talking here is the extension
of the mutable server pattern and the
importance of immutability to the CI
process as well so when you build and
when you promote when you build a
promotion pipeline and you need to
promote a binary you always do it in the
mutable stable binaries and if you want
to change something you will create a
new binary and pass it through the whole
process right now again all I did by now
is configure is trying to convince you
that you shouldn't rebuild in every
stage right and and this is something
that you'd never did with any other
technology than docker you didn't do it
in Java you had your build running maven
and Gradle would ever produce your war
file and then you took your war file
through those gates and I hope and
convince you now that you need to do the
same with docker and now let's see that
yeah so that does the picture right you
create docker build and then you promote
this file this is not new this is
exactly what we did with Java and other
languages and I keep talking about the
quality gates and you might think like
what's up what is this guy with the
gates why so upset upset with the gate I
have a good reason as opposite to and my
reason is it's very important to keep
the binaries with the right within the
round boundaries of the visibility the
creation will waste their time testing
something that is not ready for testing
the staging environment should be
shouldn't be loaded with artifacts which
are not ready to be staged and of course
only production ready images should go
to production and the stronger quality
gates you have the bigger the chances
that you will have only right binaries
in the right stages so the problem with
all that and as I mentioned all I did
now is
telling you do with doctor what you did
with Java this is all this part was
about and now you want to do it in Java
you say okay this guy probably have a
point let's do that but no not so fast
we have some limitations imposed us by
the docker itself that will fight us
when we try to do the right thing and
this limitation is the anatomy of docker
tag a tag is the name of a docker image
right it consists of different parts and
the interesting part here is this guy
this is like this is the name this is
the only mandatory part of the tag but
it also have some optional parts and the
interesting part is that what we see
here that inside the docker tag we
specify where this image comes from if
we do a pool if we dream it or where it
goes to if we do a push if we upload it
that's an interesting decision
that's an interesting design decision
that have pros and cons the benefit of
having the registry host inside the tag
is then it's always very clear what do
we have in god we have against so let's
say we have this Ubuntu image it can be
the official Ubuntu image from canonical
and then it will one have any registry
host or it can be my copy or my flavor
of this bundle image and then it will
host it will have my registry host in
front right so that's very clear what we
have in hand and that's of course the
benefit the downside is that they use
slashes to separate between different
parts of the tag shrink and the problem
with slashes is that this separator is
already taken it's already taken by the
URLs right
and this structure means that my
registry host can only be a host name
and the port but for example I cannot
use a context string inside my URL
because inside it will be the username I
cannot use a repository name in my URL
because instead it will always be our
username or already a name right so the
URLs will sorry about it the URLs that
I'm used to work with having multiple
repositories inside my repository
manager cannot be achieved how can I do
that this is what I do for years with my
Java right so I have my repository
manager host reporter management port
and then I have some context to RL or
even resolve the context URL doesn't
really matter and then I have the
repository name there create staging
production those are the environments
separated by quality gate and only then
I have the tag name how can you support
that how my tag will look if I use the
host and port and then slash I need to
provide the image name right there but I
also have additional at least one token
which is the repository name then have
to be separated by slashes but flashers
are overloaded with another meaning in
the docker tag so how can I do that
that's a very strange limitation that
bites not only us as you know external
providers of docker registry but also
docker themselves when they went to this
stage of realizing that you know what we
probably need more than one registering
a single host because we want to
separate those environments even they
didn't have the solution so what we do
as a workaround is what actually
suggested by docker themselves as a
workaround and that's a pretty dirty
work out not that this
and what we can do is using the ability
of different HTTP servers like Apache
nginx H a proxy to rewrite URLs using
virtual ports and hosts so when the
request comes to this URL and that's
exactly if I now do daughter pool and
then host port and beauty box this is
what will come as a request to my server
and then I can say you know what this
was import are not the real ones based
on those I will determine whether it
should be dr. Deb or dr. staging or
daughter probe right so I introduced
another rewrite that get this single URL
and by using virtual host and virtual
port or virtual port actually make a
real URL out of it that we know how to
do so this is an example of this an
example of nginx working with
artifactory it pretty much the same with
apache and nature proxy and it's pretty
much the same with other registries at
all as well so we can see here if the
request comes to 5001 then go to
daughter death and that's the whole URL
into action we need right and we can add
more here and say 502 we'll go to the
restrain chip wife five thousand three
will go to dr. prade so by using those
mutual ports
I have those simple host port pair again
and actually I can be flexible in having
as much local registers in one host as I
like and as I mentioned this is not ours
this is the only way at the moment it
can be solved right so both we all our
competitors docker themselves this is
what they all recommend and then do
because there is no other way until the
structure of docker attack changes which
I which is so
this change is so breaking I don't know
if that will ever happen now there is
another problem here if there my is my
registry a host and port are embedded in
my tag how do I promote I need to change
them obviously if 5001 goes to death and
5002 goes to cue a moving image from dev
QA requires changing the tag and we
tagging is done on the client does it
mean that I need to download the image
retake it and then upload it to another
repository that's painful especially
considering how huge docker images are
and they are usually big and here we did
another trick which is called the
virtual repository and again this is not
only exists in our solution I will talk
about ours because that's what I know
best right so what we have here is a
repository or docker registry that it's
called docker virtual it's not an actual
storage instead this is kind of another
layer of indirection it will have its
own virtual host virtual port let's say
it goes to localhost 5000 and then it
backed up by different physical
repositories themselves or registries it
proxies mMmmm caches docker hub and it
has all those different repositories
hidden after this URL so when we do
another pool here the request will come
to 5,000 as I mentioned and the images
will push will eventually be deployed to
dr. devlog now dr. dem local is a fully
placed docker registry it has its own
virtual port 5001 right and it can be
used directly as a docker registry
I can pull stuff from here directly but
I also can promote those artifacts or
those documents inside from one
repository from one registry to another
by using REST API I can call this REST
API from my pipeline it can be for
example Jenkins that promotes the
artifacts after some automatic testing
or I can promote it or I can promote it
through the UI so let's say I have a QA
team manual QA that verifies that this
document is good and they decide to
promote it now from testing to staging
right they can do that and eventually
when we have this image in the
production repository some other client
can still retrieve it from this virtual
repository using the same URL of port
5000 without need to download retag and
upload again all right so we kind of
minimize the number of repositories
daughter need to interact with so we
won't have to change this version every
this host and port every time and when
you use the REST API to promote if we
take care of free tagging ourselves the
images will have the correct tag when
they are in the corrector positives so
if you need to instantiate this image
and create a container out of it
directly from one of those intermediate
stages you will use those as a fully
placed daughter registries and they will
have their own unique host and ports and
this is what guarantees that you won't
end up mixing production ready with no
production ready artifacts or staging
with technical artifacts just because
they will reside in their own registries
with their own Hooft from one time and
this is also grant is that you can build
this promotional timeline in a very
efficient way because you are not
actually dragging the images around you
just issue rest api's to retouch them
from one repository to a
right so let's talk about a simple
example of a pipeline that uses that and
there are a lot of ways to create an
image the one that we really suggest is
having at least two layers and this
example with used three and I will talk
about them in a second right so we have
some base image and this example like to
Center is just for the fun of it not one
to on that we have something I call the
framework which includes all the system
dependencies and this up here I use an
application actually Java EE application
server a well fly from j-bot and and
then I have a war file which is my
application
this one does something with couch base
apparently based on the logo right so
those are my layers I have to build that
build those three layers one is the
framework build primer build taken care
of taking the base image and applying
all the system level dependencies Java
and a1 fly in my case and the most
important is that this primer build uses
a verified base image the base image you
can trust and it won't change over time
as we saw earlier it adds system
dependencies for Mars Factory obviously
in our example JDK and Tomcat and this
is the most important part you own it it
is in your repository and there is no
way it will change without you
initiating the change and this is how
you can guarantee that it won't change
under your fingers when you don't need
it to change and the minimal framework
build can be as simple as take center at
7 and don't do anything with it but now
you have another image which is yours
and won't change until you want it to
change this is how you protect from
unexpected changes in our example it
will also apply Java and and invoke line
application build that when you
framework with your base you run your
Java build or whatever build you get
your artifacts which you need to add to
this image and then you add one file to
your base file that's the deployment of
your application and in our example here
we go from this is my framework and then
I add one file the app file I added to
wherever deployment of wildfly days and
I use here a little posit ory of my Java
build and here you can ask why don't you
release why do you take it from release
don't you want to take it from death but
here what I want to do is taking the
test at war file the one that been
already tested and approved to go to
production and this is where I take it
from now if my test is always going
together
I only test this war file with docker
image then of course I will take it from
there and I will pass both the artifact
the docket image and the war file
through all the quality gates but if I
first test all my Java stuff then I can
take it from release right those are two
options now you need to go and ask come
on don't you think not to rely on the
latest version why don't do that why do
you take the latest release and my
question will be this is mine this is
tested I know that every Java file every
war file that I can find in my release
repository is good because I changed it
so I'm afraid to take it from here but
what about those didn't you tell us not
to rely on the latest a base image I
need but again this is mine I am the
only one who changes those versions so
I'm for sure no the
this is good regardless was it today's
four-wheeled or yesterday's final build
it feel good right and now let's talk
about sandwich sandwich testing anyone
knows the term sandwich I think now
that's okay so much testing is a kind of
integration testing the does top bottom
and bottoms up in the same in the same
test right there is it is an actual term
I didn't invent it and the links are in
the show notes semi setting world like
that when I want to test my application
pipeline I will use my latest known good
production ready framework and if it
works on that it's good the other way
around when I now build the framework
and it's here in my system test I will
test it with the latest known
application that was good and if it
works that is good right so I use the
framework to test the application I use
the application to test the framework
and then you should ask but what about
that and the answer is that won't happen
that will happen just because of how and
when you trigger your bills you trigger
your application build every time source
code changes by the time it's finished
there is a good known framework that you
didn't touch for some time now because
there is nothing to change in framework
the other way around you only through
your framework build when you have an
application and when you have a frame
change and there is latest good known
application by the time so it will be
good as well well I can think about
scenario when they are both dependent on
change let's say in general version and
then the application requires it and you
provided there
very slim chances that regional happen I
would say it won't so this is a good way
to do it right and and the conclusion is
all this we do for a very simple reason
we want to take what we built to
production as far as as fast as possible
and building those very rigid ironclad
continuous integration in delivery
pipelines this is what gives you the
trust that you have in production
exactly what you meant when you built
the source and when you have this trust
you can move without fear and that means
you can move faster right
so with that we have two minutes for
questions
that's me working code hashtag go ahead
and tweet show notes don't forget it
will have the video by tomorrow the
slides are there other links sandwich
testing everything is there in fitted
form to tell me how great this talk was
of course and ruffle if you come early
if you go to this link now you can
double your chances or even triple your
chances when you enter the raffle
something nice just to say thank you for
being there
so with that questions thank you very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>