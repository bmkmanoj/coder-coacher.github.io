<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>You Deserve Great Tools: Commit to Production Automation at LinkedIn | Coder Coacher - Coaching Coders</title><meta content="You Deserve Great Tools: Commit to Production Automation at LinkedIn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>You Deserve Great Tools: Commit to Production Automation at LinkedIn</b></h2><h5 class="post__date">2017-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qqbLOIVJp9U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yes working thank you very much for
coming today we will discuss and talk
about continuous delivery and how it
changes their culture in your team or at
least it can so let's get started
this is my agenda today and we will
start with open source and continuous
delivery in the open source because it
gives me a very nice segue to talk about
the use cases from enterprise from
linkedin.com which are like amazing so
let's bring it on so I created mockito
between 2007 and 2008 early 2008 version
1.0 was released and it was very easy
the releases were manual like we didn't
think about continuous delivery at all
at the time and then there was this
problem of popularity which is an
awesome problem to have I you know I
wish all your endeavors and projects
have that problem of popularity mojito
could be like the number three Java
library in the world
according to some of the objective data
that we have so it's pretty interesting
it's an interesting scale and when we
introduce continuous delivery in mojito
we learned about certain use cases that
we couldn't have learned if mojito was
not that popular so it's a it's an
interesting project and let's zoom in to
what we did in 2014 so in 2014 we
enabled this model where every merged
pool request goes creates a version that
goes out to the maven central and how do
you like that did you guys like it too
many versions so it helped us a lot
resolve the problem of stale releases
and sometimes we had like two months of
two years period where there was no
mojito release and in 2004 in 2014 we
have resolved that problem and what was
amazing about it is that I no longer had
to tell to myself step on you have to
release mojito come on come on push
yourself you got a release mojito
because we automated everything so it's
really impossible not to release mojito
so long we merge pull requests
Makita versions get released which is
awesome and we've learned things so let
me share with you what we have learned
it gives nice productivity boost
implementing countries continuously
deliver it for a Java library such as
mojito there's no release overhead I
don't have to master myself - okay I got
it right those release nodes I have to
tidy up my tcats and all that stuff
because it's all happening it's all
automatic then we're supposed to have
happier users I hope we have I thought
that users of mojito were always happy
they they get features faster you get
features faster because us there is a
pull request we review it we merge it
immediately you can take advantage of
that next thing is that it's easier to
debug problems usually in order to find
problem you have to identify the comet
that introduced the problem and if the
versions contain little comets every
version has a very little change it's
easier to identify which version
introduces a problem and then which
comet is the problematic one I have to
tell you though that in mojito we didn't
have traditional regressions where like
something worked and then something
stops working we didn't have that for
many many years
so it's not really so like we have a
problem with progressions only for like
incubating features like final marks and
some of the bite body tests that we have
done but not for like a core
functionality of mojito which is nice
nonetheless if you have many versions
with little Delta changes it's easier to
identify problems oh this is a nice one
so in open source sometimes projects die
typical reason why project dies is that
there are no releases now with
continuous delivery model where every
code is released it's less likely that
the project will be abandoned and will
die oh another one of my favorites so
you minimize the problem of unreleased
code like every code change that you
push to your main development
a change that is not released to
production that nobody uses is waste is
essentially we don't know if this code
works we don't know if it adds value but
it's there it's checked in right so this
kind of waste needs to be like
eliminated you want to have as as little
of that waste as possible and we've
continuous delivery model you have far
less unreleased code like most of the
code is always released the quality no
no this is my favorite quality when your
comment gets released to production
within hours or within minutes you have
to really make sure this is high quality
right so there's no you can't defer
quality checks like hey you know I'm
gonna push that code today and maybe
I'll do some testing tomorrow that's not
possible the pull request has to be
complete documentation testing
everything because we when we merge it
we released a new version finally you
have thriving and engaged community
because pull requests are merged really
quickly this means that there is no
situation where some eager contributor
he submits a nice pull request and it's
merged to the branch and it's awesome
but then the next version is released a
year from now and that contributor loses
interest in like contributing to that
project so we avoid that by doing lots
of lots of releases so all those
benefits with open source I definitely
recommend we also got some feedback from
community maybe from some of you that
not everything works we've continued
delivery model one problem was this
quality anxiety where you are shipping
so many versions so you're probably
shipping so many bugs as well to address
that problem we decided in mojito that
we will never do any bugs and hopefully
it's working but it's only half-joking
we really care for quality like code
review we never push code directly to
master it's always reviewed by someone
so even core developers go through the
pull request and code review cycle not
to mention that we have really high
quality tests
this is like we have to do it in mojito
like I couldn't give you a mojito
library not ensuring first that we have
like state-of-the-art tests there in
mojito we are mojito is the test tool
right so it's gotta have the best
possible unit test and that's what it is
if you look at github our github
community also reported that they don't
know what versions to use come on
there's 200 versions in maven central
which one to use and traditionally we
are kind of afraid of latest versions
right who's going to be using Java 9 in
production like soon probably some of
you will wait a little bit so and it's
sometimes it's just like we remember all
those tools over the years of our
experience that the new version didn't
quite work and we had to wait for a more
stable release that's not the case for
material like every pull request that we
merge is high-quality and passes all the
validation all the tests it's sort of
easy for mojito because we are a library
which means it's easy to like unit test
it inside out all use cases when you
have really large scale applications
it's kind of harder so for mojito it's
easier to have really high quality
automated tests that give us like really
hyper like we know that we don't break
things so use the latest version because
it works it really does not regress
anything and like I hope that you'll not
have questions at the end of
presentation about why things are not
working ok so another problem is
dependency management cost when there
are a lot of versions you have to update
them more frequently and I'm not sure if
you like updating versions with you know
in Java ecosystem like usually our
version completes the graphs the
dependency graphs in like real life
projects are super complicated nested so
it exists and we can't really solve that
problem the way we address it in mojito
is we we make sure that we we don't have
unnecessary dependencies that will bring
in like extra dependencies that will
bring in pain to you when you upgrade we
make sure that we are compatible it's
like we really honor this principle that
we ship a library which means that every
dependency of our library of lockira is
a liability to you because you have to
consider its comparability its versions
because when you put maketo in your
project in your dependency set there
it's we don't want your dependency graph
to explode or to introduce an
unnecessary conflicts so we take good
care to minimize the dependency graph
that that comes with mojito they have
limited amount of dependencies we will
never depend for example in guava that's
not gonna happen so this is how we
address it we acknowledge that this
could be a problem I'm moving on what we
have done also we extracted the
automation engine that implements
continuous delivery for mojito and there
is a standalone project called ship gate
so check it out finally the enterprise
which you've been waiting for so we've
learned that the benefits from open
source like also apply to the enterprise
you also have productivity happy users
you also have this pressure on quality
because like this is this is it's
somewhat somewhat as a culture shift for
engineers where wow the code that I'm
like writing right now and then if it's
reviewed and the reviewer approves my
code
it goes to production within a couple of
hours and we were talking about the
serious application like that scales the
planet-scale application so it really
changes the game when it comes to like
hollering quality and making sure that
the stuff that I write is works and it
doesn't break stuff we've learned also
other things so it because you can
release so quickly to production you can
test your business theories really fast
this is fundamental this allows you to
innovate rapidly and this gives you the
competitive advantage and because what
you can do there is a business theory
someone can implement it and then we can
ship it to production we can see the
business metrics whether they are
helping us or not
and then we learn and then we learn how
to build great products so this also
helps a lot with with continuous
delivery so now I'm shifting back from
open source to LinkedIn linking there
are many open source projects from
LinkedIn as I'm sure you know Kafka and
some of the famous ones mojito is
something that I have been working on
long before I started working for
LinkedIn so but LinkedIn was I think yes
LinkedIn was founded before mopida like
two years before mojito but now let's
focus exclusively on linkedin.com which
is which is the use case that is very
interesting add link linking com we try
to release 3 times per day and maximum
time from comet to production is 3 hours
which is pretty impressive when it comes
to you know application of that scale
that's now and previously in 2050 for
2015 and even even further in the past
things were not so nice and even now
we've continuous delivery like we still
have a lot of challenges so I'll get to
that but I want to highlight a little
bit what was before we had monthly
releases we have a couple of problems
with the way we released software one of
them was this problem of a feature rush
where like shortly before the release we
like few weeks or days before the
release there was way more code checked
in because everyone was rushing to get
these changes in because like if he
doesn't if I don't make it for this
release you know my change needs to wait
another month nobody wanted that this
cost like a lot of code to be checked in
before the release and that cost of
course this code was you know if you're
rushing it's not gonna be super quality
right so then and then that code was not
super quality this led to having a lot
of branches and also like we found that
engineers especially like top engineers
on the team they spend a lot of time
like cherry picking cold and like
working with those branches and managing
that the stability of the main branch
during that shortly before the release
or shortly after the release and that is
not a good use of engineering time and
if in your organization you find
yourself that we have this phase in our
workflow that we always spend a lot of
time on doing cherry-picking from brand
do a lot of like branch development that
that indicates that something is not
working well this is not the best use of
engineering time the best use of their
time is really working on products like
deliver like building product creating
code not cherry-picking we also
historically we used manual verification
and I want to indicate here that I'm
talking about the manual verification
that is a part of the release process
like someone needs to check and approve
whether the release goes out or not I'm
talking about that kind of manual
verification manual verification in
general even in continuous delivery is
still present we still manually verify
that of course you you send Canara
versions to production and your users
will manually verify code for you manual
verification is present like an it will
always be present in software but we
want to avoid manual verification that
is a part of workflow that blocks the
release right we want to have this
concept of really strain that the
release goes no matter what and I'll
talk about it in a second so in 2015 we
started working on three by three more
oh it's three hours from commit to
production and why three and not five
and not 15 we wanted this time window to
be really short really small because if
it's really small it's really pushing as
hard to make sure that we can figure out
how to test our application within three
hours that it works that it's not going
to break stuff and it's super hard think
about very complicated applicator
application that that is that is scaling
at the planet level and with 500 million
members and you you have to test it
within three hours right that's that's
hard but that the fact that it's hard
really pushed us to like to identify how
we want to test our
application like what do we test with
our our unit tests right like the
testing parameters right a lot of unit
tests and not so many UI tests also what
test and what we don't test like all
those things we have to figure out not
to mention making our test super fast
and super reliable we also wanted to
release three we want to ship three
releases per day the key the key thing
is that we didn't want to have just the
capability to write to release multiple
times a day we really release multiple
times a day
no matter what the release goes out no
matter what and that that is key for for
continuous delivery and in like in the
model that we wanted to adopt that those
releases go no matter what and it was
super hard it's still very hard so like
I can tell you this like it's you know
get it working and then maintaining that
even that we still develop the product
it's hard now continuous delivery is
hard so what do we do if something is
hard somebody knows yes do it more often
exactly this is something that I learned
first from just humble one of the
co-authors of continuous delivery in one
who one of his interviews and let's see
what are there those hard things that we
have identified flaky tests were killing
us like flaky test is so like developers
on the team were saying flaky test is
worse than no test which is I guess for
smaller teams is like what like flaky
test is okay it's just once a year it's
fine you know it provides value now in
really large application when you have
hundreds of developers you can't have
flaky tests and you are ambitious about
delivering to production multiple times
a day you can't have flaky test they
will kill you basically they will just
they frustrate engineers like this like
engineers were asking are we do we want
to have the features or we or do we want
to have tests because we can't have both
it's just so hard to write those tests
in a way they are stable fast and
reliable
now one of the systems that worked well
for us was running our tests like 1000
times without any code change over in
this was working very well to identify
the flaky tests and then the flaky test
was always taken off the test suite and
somebody had to work on it later there
was a jarate cat open but that allowed
us to manage flaky tests and solve the
problem well not solve the problem
completely because they still exist and
they still need to be worked on but now
the problem is manageable now one of the
one of the things you have to be
cautious about is that some teams
believe that they can fix the problem of
flaky tests by just applying
craftsmanship and code quality and code
review and you should totally do it we
should totally apply high levels of
craftsmanship and code review now that's
not going to resolve flaky tests because
flaky tests at certain scale at certain
complexity of your application there
will always be present no matter how
much time you put in crafting those
tests and code reviews and whatnot you
still need to come up with a system to
manage to manage your flaky tests it's
best to identify them take him
quarantine them and work on them or
delete them maybe right I'm moving on
also we found that so like traditionally
in software and maybe this is my
subjective opinion like production code
is most important so it's the highest
quality and then there is test code
which is you know maybe doesn't have to
be super quality it's just test code and
then there is like build code all your
infrastructure code which is like even
worse like that's just like like the
build the build file it just works it
builds it's okay don't touch it there's
one person on my team that knows how to
touch this file nobody else touches it
of course you don't want to be in that
position and I exaggerated that a bit
but there is something in it that
various types of code was not
necessarily treated as the same with the
same distinction as production code and
you can't have that if you do continuous
delivery at scale in our scale
Enterprise test production code test and
infrastructure called all top notch it
has to be
high-quality we have we found out that
we need to improve various open source
frameworks so when we took those open
source various frameworks usually for
testing
they didn't ideal they were too slow
unreliable so we had to fix all bunch of
stuff now the situation is changing but
in 2015 basically everything we have
taken from most of the things we've
taken from open source we had to like
fixed and tweak this is something to be
like cautious about when you go into
continuous delivery you suddenly
discover that the tools that you've been
using successfully suddenly they you
know they have some instabilities or
they are kind of slow because your your
demand your requirements are like very
much bigger wave continues deliver we
are going heavily parallel and
distributed to gain maximum speed to
meet that three hour from commit to
production and oh one more thing we
found that the master branch has to be
always green which for small teams you
know you might have a situation that oh
I broke the build and I go for lunch and
then I fix it and it's okay because
there's not the comment volume is not
that high in big teams in large scale
like your master brush have to be always
green we have found that we need to run
like we run entire test suite before the
code gets checked in if we if we up
throw with if we do all testing up front
it's pretty much working for us and the
the try the master branches is green
which is what we want we want that
stability in master if you're interested
more in that like to in tune to read
some articles I encourage you to check
out the search for 3x3 on our LinkedIn
engineering blog they're like very
interesting articles if you want to if
you're interested how we do it for
mobile and and how we do it for like
both mobiles like Android and iOS it's
very interesting we found that the
continuous delivery for like Java
back-end is easier because this is a
technology that is known for 15 years
like you know that's but like doing like
large like really big apps mobile apps
in that model where you release very
frequently it's really hard to get the
testing down to get the quality there so
check out those articles also 3x3
introducing the introduces this culture
shift it's very interesting that it's
like the way you engineers have to
consider quality the fact that there is
no QA team there are no there's no
manual verification releases go no
matter what it just changes the game how
we have to engineer code and like we had
to figure out how to do it like
traditionally on this slide like with
the historical times per linked team we
had engineering team that was working on
code and at some point they would just
basically take that code and drop it to
QA s who would be validating that code
that we're they're like all the times
and then of course gradually we've been
moving more and more of that to
automation and finally 3x3 means like
full automation there's no this at
LinkedIn there's no a human that
approves releases there's no such thing
like the releases go no matter what and
how they go I'm going to explain now so
commit to production pipeline which is
slightly different topic then 3x3 and
continuous delivery I want to tell you
about the workflow that we have at
LinkedIn like what engineers do on a
daily basis how they ship their changes
to production because that workflow at
LinkedIn is is standardized across all
technology starts and all teams honor
that workflow so let's get started I
want to start with some background on
the on the tools that we have been using
and how it all evolved so several years
ago we used to be on the monolithic code
base and we did try to scale it and we
know that there are companies that
successfully scale the monolith Google
Facebook they have the mono repo and it
works very well for them we tried it and
whenever we tried really hard we ended
up putting a workaround on top of worker
and those we're not really like
solutions like it seemed that it's going
to get harder and hard
so we we basically decided to rethink
all that and eventually we split into
separate code bases now I want to tell
you one example of that scalability
problem so in our monolithic code base
where all our micro services were what
well they were not micro service all our
services were there in that monolithic
girl code base at some point this code
base was so big that we couldn't use
IntelliJ anymore so what was the
workaround let's use eclipse because it
and it was a little bit better for like
very big projects which does not make
sense from the standpoint of like
maximizing developer productivity right
you want to offer the best possible
tools and not the tools that just work
because you know in our context we can't
use anything else so that was that is
one example and like you can fast
forward that trend what if we stayed
with monolithic codebase happily
developing in Eclipse and at some point
if the scale is too big too subjective
does not support it so what we do we go
to notepad because you know that you
know that's you know we still can you
can still write a Java code in notebook
so that that like it and that's just an
example like if things did not scale we
put effort and sweat and it didn't seem
that there was the light at the end of
the tunnel so we broke free we went into
you could think that we went into multi
repo now we we are LinkedIn we don't
like this distinction mono repo versus
multi repo we don't think that it's
important like how you keep your code we
think it's important how you version
your code how you ship your code that's
that's important and and therefore I
personally like to think about it as a
Federation so you can have a monolithic
code base we're all code in the same
place but you can also have Federation
and that's what we have at linking
Federation means that code bases are
separate and they have certain they are
they have certain autonomy they do have
to conform to certain rules within that
ecosystem so let me like tell you a few
difference
here so we've monolith and I'm talking
about typical monolithic code base of
course monolith is something very
specific for given use case for given
organization which means that it grows
and it it's highly specialized and
various organizations have various
implement various use cases in internal
special ways so this is like generic
generic description of the monolith and
what's key here is that all software
components are released like at the same
time with the same version right that's
that's the key date everything is built
from like from triangle from master from
head there is no concept of versioning
between like internal components usually
usually in monolith you also have a
unified version of external dependencies
this means that usually this one version
of j-unit that you use in your entire
monolith let that's usually that's that
those are the traits of the monolith and
with Federation and this autonomy with
an ecosystem every software component
that is in separate code base it owns
its release cadence right it can it has
those components they have SEP they are
versioned individually okay you have you
depend on certain version of that
component also there is more freedom in
choosing the dependency version that you
use for that
for that component and today I will not
dive into comparison but it's it's
coming it's coming that presentation
like monolith versus Federation is
coming but on the high level I can tell
you that both approaches have pros and
cons like we are linking we discovered
that we are not Google we will not be
able to to scale scale our monolith we
don't we count allocate 500 engineers to
develop like entire tool set of
engineering tools on top of our monolith
we don't have also like like Google who
is super successful with them with their
mono repo they started working on tools
for engineers and supporting that mono
repo like ten years before LinkedIn like
many many years so so we couldn't do it
we decided to go a different approach
and but regardless of the investment
that you need to make because you have
to make investment in both approaches
either you go Federation of monolith
you'll have problems if you go mono leti
will trade one problems with other
problems so like each approach has pros
and cons I want to share like just
handful of them for you to to know
so we've monolith it's what's awesome
about my life is that you don't have
version conflicts within your internal
components like you build everything
from had it's super nice that's not an
example with Federation you have many
versions in use of your components so
you have to deal with version companies
and you have engineers that are not very
productive because yesterday I haven't
written any code
I've been troubleshooting you know the
dependency tree right you know things
like that can happen on the other hand
you can flip it in monolith your problem
is that you can't roll out a change like
in your one of your core components
easily because you have to update
everybody in your model it right at the
same time right and that and you have to
build tooling around that and how to do
it safely you can't easily do like
incremental breaking you cannot you
cannot roll out a breaking change
incompatible change because sometimes we
do want to release incompatible change
and then gradually onboard your
consumers on that change it's kind of
hard and maoli in Monali do you have to
you know it's your code change you have
to update everything whether whereas in
Federation it's easier right in in
Federation is easier because I can I can
do a major version change I can update
those customers that need that
Meucci version and then and then maybe
some other customers I don't have to
update maybe there is some customer that
is not used at all it's used once in a
year in production there's no reason to
update a version there it's fine it's
using all the version all the version
works so but you know and then you can
you can flip it again and say that we're
Federation and with that with this
freedom of versions then you have too
many versions in use and you have stable
version or like multiple major version
and yes it's a problem so none of the
solutions is perfect in this a silver
bullet
we at LinkedIn we developed a whole
bunch of tools around the federated
approach and that's something for the
next present day for some future
presentation maybe I'll general and
we'll see each other again so in our
model we have a concept of multi product
and no tie product is abstraction on top
of a code base and like commit to
production within that multi product
framework is standardized across all
technology stacks what's beautiful about
that multi product concept is that it
helps us keep a cohesive engineering
culture where you avoid the situation
that one team for similar use cases is
doing something completely different
than another team and this introduces
this kind of they have kind of separate
cultures and you start having
conversations like me and them they are
doing this and we are doing that and
this there's no no no longer like a
concept of we are we are the same
organization we are we we are not me and
them right so how how it works with
multi product at LinkedIn is that you
know as an engineer at LinkedIn how to
contribute to any other multi product in
the organization because the workflow is
standardized you know where to find that
new tie product you know how to build
that multi product you know how to
submit code for review and if you get
approval of that code review you know
how to ship that change and it's and
it's the same that workflow is the same
regardless if you develop JavaScript C++
Java Scala
whatnot we do we are at the Java
conference so we are about I think 55%
of engineers at LinkedIn our Java
developers so we were a bigger than Java
it's like a big part of that but
multi-product is an abstraction on top
of a technology stack okay coming to
production what happens we start with
code change this is the most fun part
right for us which is you know happily
called hopefully the releases and
everything just happens that next is a
code review and
I don't know how many of you have called
review in your organization but like
formal code review that every code is
reviewed this is like also like I think
60% of you like raise your hands like
fantastic so I don't have to preach it I
think you know I think code review is
like amazing it's also a culture changer
in an organization if you have it and
like the key things in code review are
when developer the like works in code
and he there are two key things that
echoed the coder who introduces one is
that my code will be reviewed by
somebody else like it will be reviewed
for sure because I'm not allowed to ship
that code before until someone reviews
it and number two is like that person
who reviews my code will basically write
some problems with my code and I will be
expected to fix those problems or to
address them that's like like that
that's game-changing for like
organizations from like freedom of code
reviews or not jump into like a formal
code review system or like every chord
changes reviewed at Lincoln we also have
a strong code ownership which means that
code bases are owned and you need to
have an approval from the owners of a
specific code base or a part of the code
base it's different from weak code
ownership there are also organizations
successful with we called ownership with
everybody can shape wherever he wants
like it's really it's a part of your
culture it's kind of hard to contrast
each has pros and cons now there is some
research there was some research done I
should have a link for that actually
I don't wear like strong called
ownership is helping organizations to
have higher quality code what I mean is
that if you have code commits that are
either approved or done by a small set
of like core owners that according to
research helps with the quality of the
project and what doesn't help is like a
lot of random people are committing to
the same codebase so that's likely
lowers their quality that's not some
research that we have found okay then
when the code is reviewed and approved
you can ship that code and like CI jobs
can
and I wrote in my slides pre post
validation because you can configure it
LinkedIn what happens before the code is
merged and after it's merged but think
about it as like your CI job that when
it runs it violates things and finally
this is this step is pretty awesome
the pender testing so at LinkedIn we
have this Federation of those software
components and we have a service that
understands and keeps that dependency
graph of all our code and because we
have that dependency graph what we can
do on the CI machines is that when you
have a code change in your library or
your software component we will
automatically rebuild the software
components that depend on your code even
though those software components they
are in separate code bases there are
separate teams no somebody completely
different team maintains that will
rebuild their code with your change to
make sure that you don't break
compatibility you don't do some stuff
like that so this is very powerful and
at LinkedIn it's a very strong signal so
if you write code in your software
component that breaks some other
component that depends on you that your
change is not going through the pipeline
you'd like your build stops like you
have to fix that problem you have to
resolve that problem and like depend
their testing as we have it at LinkedIn
at scale also poses a lot of challenges
because now what's happening is that if
some team that depends on your code have
flaky tests then those flaky tests are
impacting you and you don't have like a
clear path they're like it's it's
somebody else's code a low-quality code
that impacts your core your ability to
push changes which is which is a problem
but again we we found ways of resolving
that problem too and and they'll be of
course more challenges I just want to
mention that okay I've got seven minutes
then new version is released this is
also very interesting because for every
code change we release new version and
it's different from traditional ways of
how software was developed where you
know like the team was happily coding
and developing and at some point let's
say hopefully
frequently but you never know and
sometimes sometimes their releases every
week or or after sometime so you have
multiple code changes that form a
version that's not how we do it at
LinkedIn if you remember from the
beginning on that presentation it's also
not something what the Mojito team is
doing with low key to open source
library right every pull request
produces new version so it's sort of
similar to how we do it in the
enterprise scale at LinkedIn where every
code change is a new version and this is
very powerful for us this is how we how
our like ecosystem of federated software
components works there is a new version
and we are releasing that new version
for those those reasons mentioned before
we want to be you want to make it easy
to identify bad version you want to have
we have ways to end of live versions
deprecated versions and basically manage
the lifecycle of the version and then
I'm gonna go next so the next step is
for library usually what's what you need
to do you need to update your consumers
and we also have automated ways to do it
at LinkedIn where we ship that new
version to the customers and we also can
manage the lifecycle of the previous
versions we can end-of-life them which
means that if somebody tries to build
and it's using an end-of-life versions
his build will fail so that's for
libraries and for libraries sort of
their workflow is kind of easy but it's
way more interesting for applications so
we have a staging environment where we
can do more testing and finally there is
a counter release which I believe how
many of you do camera releases with your
production about when the person died I
think more some of you don't want to
raise your hands but you do it I know so
so some of you do it already let's say
20% of you or 30% it means that we ship
our new version to one host not to
10,000 hosts with just one host and
monitor the traffic automatically
identify problems and mark the camera as
unhealthy or mark mark color as healthy
and if Connor is healthy by healthy
means there are no new exceptions like
there are no CPU spikes the business
matrix looks good those kind of things
so if camera is healthy we can roll it
out to all our production notes that
take production traffic so question to
you when we when the camera is healthy
and we roll it out to all production
notes do our customers already see the
code change that we have shipped do they
see the code change what do you think
depends sometimes if they use that
feature right so we ramp up features
slowly so in theory almost all features
are wrapped within the layer of the
conditional complexity to some degree
but generally like it's it's hidden and
then we like can slowly ramp it up we
can we can ramp up that feature to let's
say all the LinkedIn employees who use
our products and then to California and
then somewhere else so that's how we
increase the population and that's how
we manage risk and we manage that we
ensure that the quality is high we can
also quickly toggle off any feature and
we need to remove the experiment as soon
as we ramp it up to 100% of our
customers or of our population and this
is something that you know it's extra
cost
that we need to do by now we already
have systems to identify you know dead
experiments like code that already been
pushed to everybody but like we still
have those two code paths in the source
code so but it's definitely something we
need to do just checking time quickly oh
cool I'll have some time for questions
also and that is I think the end of that
slide oh cool we we also have a couple
of other slides they are framed under
this you deserve great tools so there's
this talk I hope you like it please give
feedback when you when you leave the
room I want to know whether it was
useful for you tomorrow there's also
play on Gradle talk it zooms into like
specific part of of our application
suite you that use play framework
and we've gradle but it's interesting
because it's not about Gradle or play
framework from this project we learned a
lot how to drive a big change in a
large-scale organization I also do a
monkey to talk tomorrow on clean tests
so if you want to have clean tests come
join me and I have like ten two and a
half minutes for you to take some
questions
oh okay so we are not going to finish
all questions I'm gonna hang out at the
Gradle booth so you can find me there
and I can take more questions but okay
maybe you reporters
excuse me
so the question about I lost my voice
next question maybe I don't have a good
answer so the question was about
repositories and how how repositories
we're working like in the past and also
in the context of micro-services okay so
micro-services are they have their own
special style of doing so at LinkedIn we
have a standardized way of doing a micro
service right so you conform to certain
you create that kind of product multi
product that is the type of micro
service and then when you depend on
other like service like there is a
protocol between them we call it rest
Lee and it's open source so you could
use that we manage that compatibility
you know during build time we identify
incompatibilities we have test
frameworks also to manage that and we
have all kinds of like machinery and
tooling to manage our micro services yes
we do micro services we have a lot of
them and we have like a special like
layer like special tooling around them
so I'm gonna take another question
okay yes so the question was how does
3x3 and like three releases per day
against correlated a number of comets or
like so we don't release the production
every comment like every comment would
I'm gonna go back really quickly to this
every comment well every code changed it
could be multiple comments but it could
be one comment every code change really
produces a new version and that new
version can be pushed to production or
not it kind of depends on you and on the
levels of automation and the team so
think about it that in our like in
linkedin.com in in the web front-end
part and I might be wrong because that
that data changes we have I think around
sixty comments per day I think right now
so this means that you have roughly
about twenty commits per release to
production for that front-end part I
don't know if that answers your question
but that's how we do it yes it's
absolutely so it's released by schedule
it's like you released train train train
goes no matter what you don't you know
you don't get to choose that we release
when somebody finishes or when somebody
tests or all that kind of stuff but
releases go on schedule and I have time
for one last question maybe from you in
the back yes you yeah
okay so I will share few words about the
defender testing it's so dependent
esting in the way we have implemented it
it only runs your first level
dependencies it's not like recursive
like it doesn't like test the entire
graph we also our dependent depend our
testing mechanism understands like
semantic versioning and versions so for
example if you are shipping zero point
star version like zero point one you are
indicating with that version number that
hey like don't think I'm compatible
right I just started working on this
right so then the signal from dependency
testing will be ignored during the CI
because okay you are you you told us by
using that version number that you're
incompatible but when you are at one
point Oh Virgin like and you're broke
some customer that depends on like one
point X version of you like we're gonna
give you strong signal like that changed
is not going through the pipeline now
but again if you do a major version bomb
you go to 2.0 and you have some customer
that is left on 1.0 then then we reduce
that signal to be like a warning right
because they are still not on me they
are no longer own they are not using
your current major version which means
we can like ignore that signal I hope
that shed some light on defender testing
how we do it and thank you guys very
much for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>