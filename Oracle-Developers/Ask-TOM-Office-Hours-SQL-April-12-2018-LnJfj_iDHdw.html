<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Ask TOM Office Hours: SQL April 12 2018 | Coder Coacher - Coaching Coders</title><meta content="Ask TOM Office Hours: SQL April 12 2018 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Ask TOM Office Hours: SQL April 12 2018</b></h2><h5 class="post__date">2018-04-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LnJfj_iDHdw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright then so we'll start off with a
question that came in and advanced and
someone wanted to know about being able
to add an auto increment primary key to
a CSV file load so there's a couple of
parts of this one is auto incrementing
primary keys and the second is CSV file
loading and both of which have several
techniques so we'll start off with what
they introduced and they have a
situation a bit like this so we're
looking to do a sequel loader control
file we've got some data here that we're
loading and it's all in the file and you
can see this data doesn't include the
any kind of surrogate key in that we
just got some text so they wanted to add
some numeric value to that and they're
like well how can we do this
well good thing about sequel loader is
it actually there's a lot of power in it
a lot more power than people realize and
one of the things you can do there is
assigned default values to columns and
one of those defaults you can assign is
a sequence so you can do something like
this if these primary keys aren't
actually in your data set you can just
assign it as a sequence like that one
note of caution on this one thing to be
aware of if you're loading really large
files through sequel loader you might be
doing it using direct path loads with so
setting the direct option equal to true
this won't work if you're trying to do
that so you've got to ensure you've got
the direct set to false that's the
default so that's probably what you're
doing anyway if you haven't otherwise
fiddled with this but if you've got you
know hundreds of thousands millions of
rows that you're loading by a sequel
loader and you might have been looking
into that so bear that in mind so this
is all very well good but
what this means is that you have to go
through and edit all your control files
to include this and some of you they
probably think yeah well I don't really
want to have to do that I want to don't
wanna have to go through and change all
my control files you know you've got
loads them scattered everywhere that's a
lot of effort I want it to happen in the
database automatically now of course at
this point a lot of people point out you
can do this using triggers and you can
do it using triggers I don't really want
to talk about that
partly because it's been around for a
while and there's you know formants
overheads with doing that and so on what
I want to discuss instead is something
that came in in 12c so we introduced
some options and we kind of caught up a
bit with a lot of other database vendors
at this point by introducing something
called an identity column so you can
create a table and have this generated
as identity field so we got our ID and
we put this identity calls on it what
that means is the database creates a
sequence for you in the background so
you'll get us if you start hunting
around in new sequences and user
sequences and things like that you'll
see these strange and I dollar dollar
sequence sequences appear that's because
they've come from these identity columns
so that's how the database assigns it
it's just really doing some magic behind
the covers to assign that sequence value
for you but there's something to watch
for if you do this so when we're doing
it generated we are the database is
always going to assign this value even
if you try and provide your own so if
you do an insert kind of like this we're
saying we want them to set the value to
1 we know this is the primary key value
for this row put it in but unfortunately
you're gonna probably see something like
this you get a lovely Ora arrow with
this generated always or cannot insert
into it generated always identity column
and that's because they say it's a
database is taken control this column in
effect for you and it will
there is no way to kind of bypass this
once you've defined it like like that
but you can change it there is a way
around it there is an extra option to
this cause this by default option so
this will now only supply the sequence
value if you do not specify one yourself
so if you go down that route you've got
to be careful of course and you know
it's intended for situations like
somebody deletes a row and you need to
reinsert it with exactly the same
primary key value it just had it's the
kind of oops moment that does occur if
you stop putting primary key values and
you know really high in the millions or
billions or whatever you've got to be
aware of where your identity sequences
up to because at some point they'll they
could hit so you've got to be watch out
for things like that so that's a way
where you can assign these and primary
key values like that but a lot of you at
this point are kind of going well we got
this table we've got our existing tables
we've upgraded our application from 11g
to 12c we we've already got a bunch of
sequences on our tables you know we've
used triggers or it's in our code or
whatever we've done I don't have to go
through you know we've got these
redundant sequences well the good news
is you can also assign those to be the
default value for a column now from 12:1
well know I'm getting ahead of myself
one of the things you could do is
remember that identity is just a
sequence so with all the options that
exist for sequences such as the cash the
increment by values also exists on the
identity column clause so you can set a
start with and put in whatever the
current value of your sequence is you
know or set it to something much bigger
than that or as I was saying go ahead
getting ahead of myself and you can also
assign the sequence to be the default
value for the column so that
allows you to and hello there whoever
spot with your eye see we can see
they're switching you video off no
worries and that's all very well and
good so that kind of covers various
options for auto having an auto
increment primary key value if you've
got any questions or comments on that or
anyone got any thoughts on how they do
it differently then let us know in the
chat
otherwise I will move on a bit and
talk more about the kind of the CSV
loading aspect of it so we saw there we
used a sequel loader control file so we
were loading the data in but I much much
prefer to try and you to load files in
using external tables so this is where
you've got a table and the data comes
from a CSV and there's a number of
reasons I prefer this over a sequel
loader one is that you want primarily
it's that you are in the sequel engine
so you can do things like join the data
to other existing tables use all the
lovely syntax we have in sequel case
expressions apply functions do whatever
it is you want so you've got a lot more
power to do things and with an external
table than you do its sequel loader
particular if you want to do things like
load half of the data or load half the
data in this table and the other half
into that table it's much easier to do
that using external tables and you can
do this by creating a table like this so
we have the organization external which
tells us that it points to one of these
CSV files and we tell it where that file
is a data dot CSV do note this file must
exist or be accessible from the database
server so if you're trying to load a CSV
file that's on your desktop you can't
use external external tables you have to
be able to transfer it to the database
server and do it that way if you have
got a CSV file on your desktop then you
can you seek a loader
other things like sequel developers got
their import option fine if you're doing
like a one-off load you trying to get
some test data in and so on but if this
is a repeated load you're kind of doing
a daily import of stuff then really you
want to systematize it and actually have
a process transfer those files to the
database and then you can use sequel to
load them in so we've got our external
table and then of course if we used our
and we could just insert our data like
that nice and easy if we had our
identity column or default C
grunts default column everything would
go in and we have those incrementing
values or of course you can specify the
sequence like that so external tables
really like them and someone's got
question coming in does it load home
line feed characters yeah I'll come back
to line feed characters in a little bit
so bear that in mind an odd spot eatery
I'm not sure I'll come back to that
shortly
so where was I
yes so we're loading file names in a lot
of loading files in and this is all very
well and good but if you've got a daily
load process the the external table
points to a specific file now you can
actually point it to multiple files but
you still potentially have a problem if
you are got a daily import let's say
you've got external system send you a
file you got to load it into your system
and of course what happens is when you
receive that file it is stamped with the
date so you end up with a situation bit
like this each day you've got standard
file name followed by the date this is a
bit of a fiddle to work with because you
need to change your external table to
point in a different file every single
day and that's just a bit fiddly in a
faff and it gets even more tricky if
let's say they haven't just stamped it
with a date but they put the full date
and time down to the seconds that the
file was created so you know not just
the first of January 2018 but also it
was at midnight and one minute and 10
seconds or something like that and this
just makes it more fiddly because you
can't really predict in an advance
precisely what time the file is going to
be stamped with now you can go through
kind of like a process where you receive
the file move it to a standard file name
such as sales dot CSV and when you
finish loading archive it off with the
date on it that's a bit of a pain in a
faff or we can go through and repoint
the external time a external table like
I've just done again a bit of a pain and
a faff easy to make mistakes on luckily
in twelve two we introduced a new
feature which makes this a whole lot
easier this is something I really like
it's called external table parameter
override and what this allows you to do
is that the individual query level point
an external table to a new location so
we can do it doing with something a bit
like this we've got this external modify
clause that says we are specifying new
parameters so you can change the
location
the directory the location as in the
actual file the directory the reject
limit and you can change where the log
files and bad files go in like this so
now it doesn't matter what I've
specified the you know I could have said
that this external table points at sales
dot CSV by passing an external modify it
now points this particular file here so
the one data on the first of April next
day we want to load in the next day's
file we get a second and so on so this
makes it a lot easier to deal with so
you can get different if you've got
changing file names you've no longer got
to go through that dilemma do we rename
the file or do we repoint an external
table well you can just change your code
and point it get it so it receives the
file name and points it to the
appropriate location really cool I
really like that but then people quite
often have and run into another problem
and so we've talked about reasons people
use sequel oh that one is it they're
using local files on them you know on my
desktop or for whatever reason they're
not on the database server another
reason and something that people quite
often come up with on questions when
this written sending text questions to
ask tom is you know I can't create
tables you know the DVA has not given me
permissions to create tables or create
any objects in fact you know what do I
do
I would love to use external tables but
I'm simply not allowed to and of course
you know I got to go to beg to the DBAs
and put it in their queue and wait a
week for them to actually deploy that to
the system I don't want to have to do
that well luckily in 18c there is a new
option in line external tables so these
are external tables that only exist in
your query so what you do is you have
your career like this use a keyword
external specify your column names and
then you can literally paste in the DEF
Nishan of your external table so the
minimum you need is the directory in the
file location but you can do all sorts
of things like change the access
parameters and fill it round and so on
so like I say this is this literally
it's not table that exists anywhere in
your database it's just for your query
and then reads the data and does
whatever it is you want to do with it so
this can get around that problem where
you're not allowed to create tables and
so on and and the thing is it's really
easy to change so let's say we want to
we find there's not just one column in
this external tables actually - we want
to load that in as well well we just
update the definition like so like so so
it makes it much easier to kind of
figure out what's going on so useful if
you've got some constraints you've got a
workaround
if Youth's your real production code and
i would thoroughly recommend you create
real table but it's very useful
potentially if you meet a prototype your
table so you've got to try and figure
out how to define the clauses so I'm
kind of coming back to the line feed
characters question when you if you've
got a straightforward CSV and it's just
common area separated values nice and
easy you can just do something like this
here but things get tricky when it comes
to things like row records that span
multiple lines or non-standard
terminators you got something other than
a comma as a separator or you got
different separators between different
fields and all other sorts of weirdness
going on in files which can get this
make this in line external tables makes
it much easier to kind of prototype and
rapidly develop you say okay what's
going to be in there and what am i doing
and so on to try and figure out the
correct definition of the file then when
you've got it nailed down you can create
the real table so that saves you having
to go through the process of drop and
recreate your table every single time
essentially I think this is potentially
very nice feature and those if any of
you do donate a trial analysis or work
on data warehouses may find this very
useful so
that was the kind of things that I had
to discuss if we talk a bit about half
date all right felt like I have data
deep data in my table and when I load
data in like it gives me invalid month
error okay we got our table with the
date in it and we've got this date in a
day month year format and we find mmm
okay we're getting a you met our error
but we can put the data in like this
that's to do with the session NLS
session parameters as we set as I was
saying I've got my date format set to YY
mmdd now you can change this by setting
the NS date format for your session so I
set that today day yyy like so and we
will find that the second one fails and
the first one that works so you might go
fantastic we've got a way around this
and this is a really really dangerous
thing to rely on because as you can see
I just set that in my session any client
can change their own NLF date format and
this is it particularly becomes a
problem when you start having some
servers which are configured for us
settings and some servers servers which
are configured for non-us settings as
the u.s. typically has the mm you know
month month day day format whereas
almost everywhere else in the world goes
day day month month and this can if
you're unlucky or not careful you can
have some clients ear with your us
settings and some with the you know any
pretty much any other country settings
and if it's this half of the year so
well if it's this off for the month I
should say so any day before the 12th
you could be loading data in and the
dates could be in the wrong order and
you just wouldn't know until you get to
the 13th and whichever format is
incorrect or for the source data you can
suddenly find things start loading
getting errors so well you can do this
and it it is kind of handy if you're
working in an individual session you
should absolutely not rely on this in
your code you should to date your your
things like this and say what the format
you're looking for is an otherwise
you're just opening up yourself the
chance for all sorts of weird bugs and
so on okay can we dynamic this format
the user able to enter any format he
want well I mean they say this is a
client setting so essentially you can
have something where you ask the user
what format they wants and they get it
out like this but they say it's much
better to do the to date and then you
can still ask past this as format as a
variable as a fine variable format like
this much more reliable much less likely
that something unexpected is going to
happen so you know this is kind of handy
if you're just doing a quick demo real
codes do a to date
yeah yeah as Pete says sequel developer
is great for loading CSV data actually
I'll just I'll bring sequel developer up
cuz that that has a lot of options for
sherek working with CSV data know back
in the Fortran days Wow
so we've got a lot of all people working
with cobol soil data fantastic so um
yeah as Pete says it's actually sequel
developer has a lot of good options for
reading see working with CSV data so one
of the cool things is this little import
data option so if we right click and we
go to the table here and it's going off
the top of the screen a little bit but
yeah I've lost my buttons somehow yeah
come on let me just move that over there
and resize it then I'll drag it back up
and is now not playing ball so we can
pick a file and load it in there and you
can actually do this so it will create a
table for you on the fly and hopefully
I've got export file so we can see
what's in it there we can fiddle around
with the terminators change between
Windows Mac and so on and if I can get
it to do next I can't get it to resize
for some strange reason but that is yeah
and we can now create the table so we
have a new table and move along
hopefully always doing that and we do
bolt in there we go yep I'll go back a
second and you can see we've got all
sorts of things to map the data types
and so on so if you're doing one-off
exports and imports of CSV data I would
absolutely recommend looking at the
import and export options here in Seigle
developer there is also get data out
there is a date export option so you can
get all the DDL but you can also just
get the data in the whole bunch of
format so let's get CSV we can load in
two separate files all the things we're
looking for and I need to say which
database I'm using and so on so we can
get home loads of stuff out so for
one-off exports would really look into
that if you're doing if this is going to
be a ongoing process like a daily import
or export bill the system you sequel
loader external tables and so on and
that so you've got some CSV stored in
your database and you want to convert it
into columns is that kind of what you're
saying there Steve yes
so let me just share my screen again
briefly so that the short answer is
there is no way built-in way to do this
in you know there isn't like a convert
to see it CSV two columns feature
however um there is something in new in
eighteen C which kind of lousy to
emulate this functionality and I
actually have a nice little demo of it
arm live sequel so let's just log in and
get in so we in eighteen see we came up
with this fantastic new feature called
polymorphic table functions which it's a
crazy sounding name and sounds
impressive right this is like wow we're
using polymorphic table functions and
what it allows you to do is manipulate
the your data set
so manipulate the columns in your output
so you can change dynamically which
columns appear or don't appear in your
output and one of the things you can do
with this is use it to make do a CSV to
column converter
yes PTF does is if you fear sessions in
the future as you're right very truth i
you this it's it is a complicated
feature but you see there's a fair bit
of going on here but now what enabled us
to do we passed in these comma separated
values and say there's two columns with
data in here and they actually come out
as separate columns as for four columns
they come out as four columns and so on
so you're able to now dynamically pass
in some data and say if the PTF can kind
of manage it all extract the information
out and convert that into individual
columns as you've asked for basically
the acts exact details of how this works
is way beyond that if there's too much
cover for us and then in the next five
or ten minutes but if you're interested
head over to live sequel and look for
the dynamic CSV two columns converter
for a demo they say this is an eighteen
seat feature so it's going to be a while
before any of you and have to play with
this I'm sure but it's generally very
useful if in the meantime until you get
to eighteen say you're gonna have to
build your own kind of and work around
some kind of either dynamic sequel or
you know build your own custom functions
to you know deal with e all the
substring and in string passing you know
all the good fun that the link brings
but so watch for pts on eighteen see in
the meantime you'll have to build
something over your own
wasn't that even possible before 18c
with any data in any type you may be
right Neels to be honest any data and
any type are not things that I've
fiddled with extensively free you may be
able to do it oh good I'll challenge
challenge someone see I'm watching to
see if they can come up with their own
version that does it
3:18 see I've there's been some good
discussions thanks for all of you for
joining me I hope you enjoy this more
importantly we hope you've learned
something we want this is an ongoing
program office hours so please let us
know if there's anything we can do
better if you've got questions that you
want us to cover you can submit them in
advance and if you go to the office
hours pages give us your feedback let us
know what worked what didn't work how
can we be better you know we're here to
help you be more successful at oracle
database and build better faster more
reliable applications so what I just
want to thank you all for joining me and
and say goodbye</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>