<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building Applications with a Graph Database | Coder Coacher - Coaching Coders</title><meta content="Building Applications with a Graph Database - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building Applications with a Graph Database</b></h2><h5 class="post__date">2015-06-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/SuF3KdY5hm4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Tobias I'm here to toss with
the incredible incredible task of trying
to deliver a presentation while not
drinking so much water that I'll have to
run out the room I'm going to be talking
about how you build applications with
graph databases and why am I a good
person for giving this talk while I work
for a company called neo technology what
we do is we build a graph database
called neo4j I've been with this company
for six years now which is Xavier after
we started I was actually the first guy
to to be employed by this company so I
think I know graph databases at least I
think I do and but there's a flip side
that right um there's also a reason why
I'm not a good person for talking about
this and that for the same reason
because i work for a vendor so i'm not
really going to be biased so this talk
is going to be strongly focused on neo4j
i'm just gonna say that there are other
graph databases out there and I'm gonna
mention them but this talk is going to
be somewhat focused on here for J it is
the biggest graph database I hope so I
hope you have some some understanding
for that and also being at a Java
conference that's run by one java vendor
I think you guys got the whole idea of
bender Baez I think you're comfortable
with out already so the the premise for
this talk or where I'm starting from is
I'm going to base this off of an actual
application that we built in-house that
we call the test lab it's an application
that we use for testing the database so
it's built on top of our database and we
use it for testing our database for
testing future versions of it and one of
the reasons why we built it was of
course that we needed some way of
getting a clear overview were all our
tests
but we also wanted to actually build an
application on top of our own products
that we have an in-house feel for for
what it's like to run and operate an
application that's critical to our
business on top of our products and
that's the aspect that I'm going to be
talking about so when building an
application any application using any
database these are the things that you
will face you'll have to model your
domain I have to choose how to deploy
your application and you have to have to
maintain the application when it's
deployed you also have to eventually
you'll have to know how to evolve your
model or in your domain as your
application needs of and what I'm hoping
is that this will be surprisingly
familiar to all of you I build
applications using interactive is the
same way I build applications using any
database pretty much the main difference
is in how I model my data model my data
for a graph rather than for a document
database or for a relational database
the actual act of building an
application same thing and although I
personally might have some differencing
views on on how to build application
from from many developers I find that
the approaches i usually take work just
as fine for any database just to get a
feel for for what I mean that um I'm one
of the things I don't like is like so
this is a web application and one of the
things I don't like is these large
frameworks for like jax-rs frameworks
and stuff like that I think they get in
the way of understanding the code but
that's my personal opinion I built
application using those frameworks as
well and it works just as fine
um let me start by introducing this
application that I'm talking about so it
it's not pretty that's not the goal of
it it's essentially made the main part
of it is one web long long web page
where we list from the bottom up data
sets that we can start off a running a
database from so we can bootstrap it
with some data clusters of databases
that's the main thing that we put load
on and that we have an under test
there's also clusters of load generators
that put load onto a cluster or
databases then there's tests tests those
are things that currently run or have
recently run against a cluster and then
there's on top of that there's test
series and a series is the same test
running over time the multiple times and
from the test series we generate I
should have had a pointer I want to
fight point your she will show here if I
do know oh that's the laser pointer
perfect start which button do I that one
these that that's these charts it's what
comes out of those series so this is
each of these bars is one test in a
series of test runs and we the statistic
statistics we gather for this we use the
excellent HDR histogram by guilt any he
wanted me to plug that so we use it we
love it and we also have integrated log
analysis in this application so there's
a page when you get down to a particular
run you can get to analyzing the garbage
collection logs and analyzing the actual
application log so the application logs
are request specific to us it's our
database log will be mainly analyzing
that is commune
vacation between the instances in a
cluster so that if something goes wrong
we'll know we can try to trace the
messages and see where they go wrong the
main benefit that we got all of this
first we started was a click and go
clustered deployment because prior to
that it have been a bit of a few steps
that you had to go through to to set up
a cluster and once you've set it up it's
fine it's just restarting you and
everything run smoothly but that that
initial setup that's a bit tedious and
doing this exercise and getting just a
click and run most lovely it me it it
took us from running real world tests
mmm occasionally maybe once a month to
running them continuously in terms of
architecture we've got to perpetual
things running one database server that
it stores the data of this application
and one server that we call the manager
and the manager is what serves up this
web UI it's a pure pure HTML and
JavaScript and interface all static
files and then data API is over HTTP I
will not say that it's a restful api
because i know rest and i know that this
isn't rest and I designed the API and I
I've gotten a lot of for it not
being restful but it was carefully
designed so that we could evolve it and
therefore we decided to not do it
restful initially and just do something
that solve our use case and not think
too much about what we did so this
manager is the server that does all of
the work but it doesn't keep any state
all this data store in the database and
in work use
so if their workflows they're stored in
work use and we use Amazon's simple
queuing service for that as well get to
later that has a nice benefit let this
man manager being completely stateless
is super easy to to restart it's just
kill the kill the machine that runs it
and start a new one and we do that every
time we change the code for this
application that's what we do our
continuous build system what it does at
the end of the build is start up a new
machine with a manager running out and
then we have two of them running run a
few tests on it to make sure that it
works as its supposed to and then rebind
the elastic IP to the new new manager
kill the old manager and we're done zero
downtime which is really sweet actually
I was I was happy that was so easy to do
an application with zero downtime even
though we have sometimes redeploys every
20 minutes supplication also cute but
useful feature that I thought I'd
mention because I'm I'm proud of it is
that if if something goes wrong right
here i have a screenshot of a server in
a cluster where the application install
failed in order to diagnose that what i
can do is just click that button that
says ssh and it opens up a web page with
a built in terminal into it that's it
has an ssh connection to that machine
the way that this works is to have a
vt100 terminal emulator written in
javascript that connects over WebSocket
to to the server which runs yay jaeschke
yesh unpronounceable library that does
there's a ssh client implementation in
in java we're surprisingly simple it's
just take existing library for VT
hundreds
existing safe lines wire them together
with a WebSocket it's just bites going
over a socket done I'm thinking I might
open source that at some point not
because because I think it's something
that is hard to build but because I
think it's something an easy to build so
like a showcase I look how easy it is to
build a ssh over https tunnel right so
that's the application what were the
requirements for this application I
pretty much talked about this already
I'll just skip that so in terms of data
storage and retrieval requirements what
we store in the database is the metadata
about the tests and like what to do in
the test and the parameters for the
tests and so on and then we store and I
a summary of their outcome with with
references to full log files about the
entire run these full log files we just
store in s3 case we have the aggregate
and that's what we show that's what you
serve up from the database and when you
want to look at more details you just
want to look at the raw data anyhow and
mangle that in a custom way for the
particular thing you're looking for we
see right we also the way that we model
state is of a database for example is a
other cluster is not by storing the
database is running but rather storing
all the events that has happened to that
cluster so we have an event that says I
requested the cluster to be created i
added a server to the cluster I the
server notified that it had started
and I requested that the cluster gets
destroyed and the cluster was destroyed
those kind of events and from that so
that's what we store in the database and
what we forgetting to the actual state
of the clusters and servers and whatnot
that's the job of the application so it
reads up the events and processes that
and computes the state another
requirement was that we wanted to
minimize the number of round trips to
the database that's always a good thing
with any database if you can do
everything in one query or a happy
camper speaking of queries let's look at
those so for neeraj a we have a query
language called cipher you might start
noticing a matrix theme here that's not
accidental our founder what is it as a
great fan of that movie so these are the
basic things of the cipher query
language we have a what you do is you
define patterns that you match you with
a graph a match the match Clause is the
main part of other query that's where
you say what type of pattern to match
then you have where which filters down
those matches to using predicates to
only those that match the predicates get
returned and then returned what you want
to return from your query in versions
the current released versions of neo4j
there's also something called start
which defines where in the graph that
you start matching in version 2 0 which
is I'm so comfortable with tutored oh no
because that's what I'm working on that
I'm just thinking in terms of vert of
nephew jtro but it's not actually
released yet but it will soon be I'm
thinking at all i promise anything but
soon the start loss is not needed in 20
because it recognizes from
what you have in your match pattern
which indexes it can use to find those
star points on its own and patterns are
described using an ASCII art like syntax
you draw nodes they're like circles
parentheses around an identifier and
then relationships using just arrows
with the type of the relationship in
brackets then there are a few more
classes for creating and updating great
creates relationships and nodes based on
a pattern as well so this thing with
ascii art patterns comes over and over
again in this language set assigns a
property to a note orale a relationship
delete delete a node or relationship
remove isn't in here but remove removes
a property from a node or relationship
then we have create unique which is like
create but doesn't do anything if
something that matches the pattern
already exists this is being superseded
by merge so we're changing the name of
it in 20 crazy unique will still work
but you will get a warning saying that
please use merchants ID and then for
each when you is when you have a
collection of things you can collect and
aggregate things in cipher and we have a
collection of nodes for example you can
do something to each of them typically
an update so more advanced things with
is super useful and that's what we use
for creating a sub-query so it's
essentially we say width and it has the
same syntax as return so you define the
things that you want to carry with you
to the next query and then those things
are starting points for your next query
so it's like you can imagine it as being
a query that returns and then you
sending the result of that query back in
this parameters order by can be used
with both within return and it sorts
your result and skip and limit is for
paging typically only used with order by
because if you don't have a sword and
set paging is nonsensical and then of
course as I said we have aggregation you
can collect things it's similar to c
equals group I you can do sums and min
max and counts and whatnot same as you
can in sequel so let's get down to it
modeling your domain I have a min on a
short thing for remembering things for
how to model your domain so I started
with I i wrote this down as you should
do your right model you remain for your
queries so queries first do it on a
white board so white board first and use
examples because humans are really good
at reasoning around examples rather than
reasoning around abstract concepts so
you should do examples before you do
abstract concepts so there was a lot of
first I was like this is cute I wonder
if I can extract a pattern from this
query first part wood first examples
first and I happen to look at my
keyboard and so on that's the top left
corner of my keyboard I wonder if I can
turn that into korte and then I realized
yeah you should avoid redundancy when
you when you model your domain so you
shouldn't you should try to not be
normalize your data and then i just
added thank you and got Cordy and a very
handy way to remember how to model your
data so query first what i mean by that
is that you should create your model for
satisfying your queries and not the
other way around not
I to model reality and then try to
shoehorn your queries on to that no your
your model is therefore the need of your
application it's a model it's not
reality it is a model so model to
satisfy your queries and then draw it
perfectly using examples this is one
example that I I took a picture of one
of the whiteboards in the office after I
had modeled one of the things for this
application this is the model for or an
example of the model for benchmark
series our test series they were when we
designed them work what they were called
benchmark series later we were named in
test series so here they're called pinch
marks so we see that we have a series
the ties to an implementation of a an
implementation is a particular
benchmarks on it it's an implementation
of being a benchmark and then we have
versions of this and a version is a
version of the database with that
benchmark is supposed to run for the
version is associated with a jar file
that's how we deliver code to it and the
jar file is associated with a branch of
the code so we can track back to to the
source curtains so if we got if we get
regressions we can immediately find the
this source code where we have the where
those changes were made and as I said
example first you draw on a whiteboard
and what you draw is an example so even
if you ml is nice and cute and powerful
I think you should start with an example
and then when you understand your domain
in terms of examples you can move on to
uml
and finally avoid redundancy so
relationships in a graph database are
traversable in both directions if if I
oh if I have a relationship this ice on
this computer you can also find out who
are who the owner or owners of this
computer is by traversing the
relationship in the reverse direction
from from the node representing this
computer so you don't need to model dual
directions if you have undirected
relationships in your domain you can
just model them in any direction then
when you actually query for it you just
ask for i don't care about the direction
i just give it give to me in any
direction so if I if if you're modeling
a social networking you have friends
relationships something that is a a
reflexive relationship then the fact
that you and I are friends you wouldn't
model that as a relationship saying that
you are my friend and I am your friend
with two different initiatives you would
just have a friends relationship between
the two of us and it doesn't matter
which direction you store you created in
because when you query it you're not
going to care about the direction and
also a second redundancy you should
avoid is adding inferred relationship so
if you and I are friends and to viewer
friends I should not add a friends and
friends relationship to you but rather I
should find that by traversing the graph
and that speak that gets right to the
sweet spot of crafts databases joins are
there are no joints it's just reversals
and they're super sheep you can do four
or five six eight levels deep traversals
and it's going to be fine
yeah there's a method to modeling with a
graph database and that is first you
identify your application user goals
then you figure out what questions you
want to ask of this domain so query
first you identify the entities in this
in these questions and the relationships
between them that you convert this to to
a path pattern and you express that as a
graph pattern and this becomes the base
of your query and the paths and the
pattern also become the base of your
model so let's start with a simple
example as an employee I want to know
who in the in the same company as me as
i work for has a similar skill set to me
so that we can exchange knowledge this
being based on the premise that you can
all only learn the things that you
almost already know so the question to
ask of this domain is which people who
work for the same companies we have this
game same skills as me and identifying
the entities in this we have people
that's a person we have company and we
have skills those are the entities those
are the nouns in this sentence and the
relationships here you sort of derive
them from the verbs and in the sentence
so work for which people who worked for
the same company as me so people work
for companies person works for company
and have similar skill set to me or has
similar skills to me so person has
skills and then what you do is you
convert that to a cipher path you do
that by saying that these are the nodes
the entities are the notes and the
relationships are the relationships the
the verbs are the relationships now you
just write that down in this ascii art
syntax person works for a company her
soon ha skill skill and we call these
things here labels and these we call
relationship types and you take that you
can consolidate it to a single single
path pattern and sort of draw a model
for what that look like all right so you
have a model but I said example first so
what we do then is we we sketched out an
example we have our first mental idea
for how we think it should look like we
sketched out an example of what this
would look like so we have a company we
have some people who work for this
company and they have skills and given
this I can start looking at okay who do
I think I would have the same I would
have skills in common with I can start
with me and I can see we will all these
people work with same company I can see
that I have this skill in this skill and
so does my colleague en and with my
colleague Jake i only share this skill
so I better fit with with ian because we
got more skills in common so i could
probably learn c sharp from him whereas
with jacob i don't know i don't have as
many common grounds with him so learning
python from him might be harder than
learning c sharp from ian again we go
back to our definition and use that to
define the pattern that we're looking
for so we have companies we have people
and we have skills and we want to find
given a person we want to find the
people who work for the same company and
it has the same skills so it's like a
two-sided triangle with a missing
relationship in the middle and that's
pretty much the basic for all
recommendation algorithms all
recommendation algorithms look like this
at least the basic ones
and then i can write a query from that
so i got the person i'm starting with me
i see i think i got ya got the pattern
so it's one person who works for a
company another person who works for the
same company and first person also has
skills and the other person should have
the same skill to find this pattern i
also define a predicate like the name of
the first person here the me should be
parametrized by name and this will so
conceptually this isn't a filtering of
the of the total graph but if an index
is available in defined in your schema
it will filter based on that or use that
for look up rather than filtering around
the entire data set and then finally i
carry that create a projection of the
result and what I do is I return the
name of the colleague I count the number
of skills that we had in common and I
also collect the names of those skills
in a list that I call skills and my
associates then i order all of these so
I this is grouping by colleague named
counting the skills we have in common
and also collecting the scales that we
haven't come in and then I ordered this
by score so the number of skills that we
have in comments are the people the
colleagues that I have the most skills
in common with will come first let's
look at an example of this we here we
have the power and again here we have
our example graph I've used colors to
match them up it should be a
semi-transparent it looks like it on my
screen it doesn't look like it from this
angle um but the first match is from me
to the company I work for two en and to
the skills Scala the second match still
the same people but two new skill third
my
much new person and a skill that we have
in common so the result i get is en I've
got two skills and come with him there
Scala in there for Jay and Jacob one
skill in common with him it's named for
Jay weird that we would have a new
fridge is in our skills that everyone
who works at at my company right let's
look at a few patterns that I've
identified for when you model your data
in in a graph a few design patterns if
you want if you want to call it that for
how to model your data the first one is
a simple ordered list really common
really useful really easy to to model
and gives you a whole lot of benefit and
such as pagination without being I'm
having to sort because you can have
things stored ordered so that you can
get them back in a paged fashion without
having to sort it's awesome examples of
this is event streams for example like
things happening in an order that's what
we use in in the test lab application we
also could have like episodes in the TV
series i use that as an example in the
next slide or a job history where a
person has worked in the past so let's
look at this example so the way you
would store laying store ordered data
and a graph database is by just
materializing the order ass
relationships in the graph the nice
thing about relationships having a type
is you can overload your domain with
different aspects so even if I have in
the Doctor Who example here I love
Doctor Who
I can have information about what the
production order of the episodes are but
I can also have information about the
sort of fictional universe in the same
graph can have which characters were in
this episode and what are the
interpersonal relationships in this in
the series between the people and Doctor
Who now for now we're focusing on the
just the ordering of episodes but you
can mix this with production or because
they're not produced in the same order
side here I have two different orderings
of the same data and for grouping these
orderings I sort of add a tree-like
structure on top of this with the
seasons so these all belong to the same
season I have the first episode in the
season and the last episode in the
season and the seasons are linked as
well so I get an order of seasons and
right so I can interleave multiple
different and organized into groups I
think this is powerful useful what we
the main use case we have four for this
ordered or linked list pattern in the
test lab is for recent events for
example when tests complete we store
them in a I recently completed test list
and it's an it's an infinite list so we
have some reference node that's like
these are the reasons you could
represent the conceptual notion of the
recently completed tests and that links
to the most recent one and then they all
link to to the one prior to it so let's
look at a query for updating such a list
here is how you add the cipher query for
adding or removing an entity into this
list
break that down we start by defining
this structure sort of the initial
structure or the item potent structure
that we want for each to be the end
result so we find the tests that we're
interested in adding to the list we find
the recent reference so it's a has the
label recent of type tests and that's a
unique unique note I've defined a
constraint saying that recent nodes are
unique on the type of property so i know
that i get the only the only node the
represent recent tests and merge gives
me that gate or create semantics and
then i create a relationship from the
reefs from the reference node to the
tests and for the first if this is the
first time ever i would be done but this
same query runs every time i add a test
to the recency list so but this is still
the fun basic foundational structure of
it this is what i want to my data to
look like afterwards and i have to take
care of okay what was there before and
what I need to do with this so I start a
new sub query carrying through the
reasons and the test and then I match
out the relationship that we just
created between reasons and tests and
the reason I rash this out is that so
the next met match when I find another
relationship of because remember since
we created one and the the idea is that
there should be only one if there was
one before there will be two now if
there was none before there will be one
and we're done so if there was one
before we'll match that out and call it
previous so the way that we this works
is that if you've already matched
something
in the same match class if it was some
relationship that will not be matched
twice so since I've matched recent to
test though with those two no nodes I
know that the relationship that are
called previous here will be a different
relationship if it exists and then
finally what I do is I remove the
previous relationship that was there
before and I had a relationship from the
test that i just added to the list to
the previous tests done that's the full
cream slides will be online on
SlideShare if you want to read this in
detail I hope the comments are
self-explanatory enough that you will be
able to understand them once i'm not
there to talk them through with you all
right so fine we can add things to the
list how do we get things from the less
than so this is the query for getting
the five most recently complete tests
again I'm a shout the recent tests note
the reference node for the recent tests
I get the last completed one and then I
get a path of length 0 to 5 or all paths
from length 0 to 5 i miss something
here no yeah i missed something here
sorry i'll talk that through so i get
the paths of length 0 to 5 from this
most recently completed tests like a
lost to any old node I don't care about
what that note is because it's going to
be in the path and then what I should
have done is have a width that sorts
these paths by length and get the
longest one so the reason I'm doing that
I'm not just saying I want one of length
5 is that I'm not sure that there are
five tests
and sorting five elements is quick
enough as I sword for the sword five
paths and I get the longest one and then
I do this iterate through each of the
nodes in the test path and get the ID of
it and return that the nice thing about
this is that it's pretty much the same
for forgetting the next five elements
given a certain test so if I have the
idea of a test like say it's the last
one of the list then I can get the next
five in the next five and the next five
by just jumping straight into the list
and doing the same thing so this
actually has the same bug in it sorry
about that should have a with Satan here
that says sort and sort by length and
filter out just like the longest so it
would be sort by length descending limit
one and that's it notice how similar
these are from here and down it's the
same it's just the top initial part of
how to enter the graph that differs
alright so ordered data through linked
lists easy useful next pattern that we
have in the test lab is what i call the
active set pattern so this is what we
use for storing which clusters are
currently live so we can display those
nice and quick and easy on the UI
without having to write a query that
goes through all clusters that have ever
existed and looked at and computes the
state of them similar pattern I have a
reference node for the active tests yeah
so these this example is for the tests
that are currently running on the
cluster and then I just have direct
links to each of the active ones so you
can imagine this being linked
here and then I have shortcuts into it
again a query for adding and removing
from an active set it's really quite
this is for clusters quite simple I get
the reference node for active set same
same deal as before I also what I do in
in here is I store the the event of
creating a cluster and I store who did
it so I store the user with the user ID
and I just create the cluster reference
it from the clusters add the properties
for it and the event that for the fact
that it was created at a certain time by
a certain user similarly for destroying
a cluster which removes it from the
active set I find the cluster I find the
user that fired off the destroyed
cluster event and then i create a
relationship from the that let's see
yeah i also find the relationship to the
clusters node and then i create a
relationship saying that the cluster was
destroyed and i delete the relationship
to the to the clusters reference node so
this is even easier it's super useful
for the for the for building a UI that
has a list of active things because
typically the list of active is short so
it doesn't matter that this is a just an
arbitrary list just an arbitrary group
of things because sorting them is easy
if I want them sorted by any any
property booster it's going to be a
small set right so we mentioned events
there so how do I model those so events
and actions there's a pattern to
modeling that as well and the thing to
realize here they involve multiple
parties it could be more than more than
to the the trivial or the sort of naive
way to model this would just be to say
that there's a single relationship
between the the entity that triggered
the action or the trigger the event and
the entity that was affected by the
event so to say for example saying that
Patrick worked for some company as a
relationship or sorry sent an email to
Lucy so from from the previous from
previous lives of how to identify
entities we would sort of think that
yeah this is these are Patrick and acne
are the entities here Sarah and Lucy are
the entities here these are the verb so
these would be the relationships but for
entities it turns out that that's
actually not the way that you want to
model it because look at this one it
might be that Sarah when she sent the
email to Lucy she copied in dating
Claire so actually here what we have is
email as a separate entity so that's the
way you should model it because even if
even if in your domain now it is just an
event the act of sending an email since
it can involve multiple parties and
events frequently can you should model
events as nodes so here for example we
have Patrick unemployment at a company
and we can store the role they had at
this company as a separate entity and by
storing roles as separate entities we
can find all software developers
globally or at the company or whatever
similarly for email we've now we can
store the subject and content but we
could have store that on the
relationship as well but if it was a
relationship would only be between two
parties and we wouldn't be able to store
the fact that someone was copied in
I mentioned that we use events in this
application for computing state and
here's some Java code that exemplifies
roughly how we do that I'd simplified a
bit but this gets the gist of it so we
it iterate through all of the events for
a cluster and we get the implied this
implied state over the state that this
event would imply so if that had been
the only event what would the state be
and then we keep a track these states
are ordered so there's always an ordered
progression through the list of states
and that's true in most cases if you
have a more complicated state machine
you can model that as well but then you
might have to sort your events and we
update if the candidate state is greater
than the state that we knew from before
and then we return the state that's how
we compute state final pattern and this
is more of a pattern for how to
structure your code with queries and I
think this applies to using any database
and not just a graph database it's what
I call the repository pattern and I've
always use this when i worked with
sequel databases as well I've never been
a fan of hibernate because I actually
think that it hides the power of sequel
and similarly with with a graph database
you have power in being able to write
your crease so instead of using a
framework that hides that from you just
encapsulate your queries in a central
place that's the repository and you'll
gain all the benefits of both worlds so
having all of your queries in one place
also simplifies testing because all your
queries are known and then make sure
that you use query parameters rather
than a string building or string
concatenation so that you're not sending
22 injection same thing as you would
with any database so but usually what I
what these repositories do is is finding
an entity see so it kind of has a an
underlying structure implied in the
graph as well those are the indexes so
for finding the finding all active
clusters for example this is what that
query would look like to remember we had
this active set pattern so this is what
the code in the pasta Tory would look
like for finding all active clusters
let's walk through that so this match is
not that active set reference node again
and matches each of the cluster related
to it fine that's pretty much all we
needed if all we wanted was the IDS of
the active clusters we would be done but
we actually want all of the data that we
need for building up the information
about these clusters so let's continue
so we match zero or more servers this ?
means optional so if there are no
relationships of type member of that
comes into this cluster that would be
okay and then we from each server we
match out the events that happened with
to that server so this is also optional
by implication a key server is is
optional here by by being through an
optional relationship and then for each
event we find the details of that event
that's also optional because not all
events have details then we start a new
sub query where we group by a cluster
server and event and we collect the
details for the event and then we do a
second one where we collect all the
events up so we do this but for
forgetting a collective collective
so that this gives us a list of event
details becomes a list of zero or more
detail nodes so we get rid of the
optionality here that we have it there
and then we collect each then we collect
up the events as well so we get a list
of all the events that happen to the
server so these are the server events so
now what we have going into the next
query is the cluster the server and the
list of events for the server then the
next thing we're going to do is collect
up the servers for each cluster same
thing again and then what we do is find
all events for the cluster so we find
the cluster events same pattern as we
had up here and the same pattern we saw
in the previous queries where we have an
actor as well and then finally we return
all this where we again collect all
collect up all of the events for the
cluster so we get a list of of clusters
and this should have said servers this
is a copy paste error so I returned the
cluster the list of servers for the
cluster which has aggregated up all of
the events with all the details for the
server and then the parameters for the
cluster and the events for the cluster
analyst so get one row for each cluster
which is a which contains all of their
all of the servers and events I sort of
nested documents in in that row and it's
a single query for getting just one
cluster by ID all i need to change is
this first line
so all of the rest is absolutely the
same all the only thing that changes so
here we have find the active set and
then each cluster hanging off of that
active set here it's just finding the
cluster with the idea that one this is
also a good point for why you would want
to use a repository pattern in your code
because that means that well at load
time you could do some string
concatenation and concatenate up the all
of the queries that you know that you
want so you can have this as a query
fragment and you have these two
different initial parts for it and then
you have your code for the query in just
a single place and refactoring becomes
smoother and easier right so I would
that's what you would do many queries
you'll find will have similar fragments
so composing queries from fragment is a
good idea storing them together in one
class helps with that and what you would
do is concatenate on load time and then
use parameters for query parameters for
the parameterization at runtime and
another side effect that this is of
course that you is that the query
optimizer will love you because if the
query text is the same every time you
just use parameters we can use the
cached career plan and we won't have to
recompile the query every time so it's
another great point for not building
query strings dynamically I think the
same is true for pretty much all
databases and I am pretty much out of
time but I have managed to get through
all the things I really wanted to get
through so let's see if I can jump to a
nice place near the end of this
so much good content
I think this is fun
it's near the end so one pitfall is that
you should try to avoid is modeling
entities as relationships it's what we
saw with what I mentioned when talking
about the events that actually turned
out to be um entities in disguise and
what you notice is that for finding
things where you have inadvertently
modeled entities as relationship what
you'll see is typically that you have
lots of attributes on a relationship
lots of properties and that you somehow
wish that you could use a relationship
as a starting point for a query you will
want and you sort of find yourself
asking us to implement relationship
indexes where you can just look up a
relationship by random so here's an
example where someone has done that
where you modeled reviews of of movies
movie reviews as relationships bad thing
here is that it doesn't so say that we
gotta change business requirement for
this where someone says that well
actually now I want to be able to
comment on reviews and that's not
possible in this model because I can't
have relationships on relationships I
can't add things to the center tease
what I should have had is something like
that like this or each review is as a
note and someone wrote the review and
the review is of a certain movie this
leads us to refactoring your domain and
there are two main refactorings one is
converting property to a node and the
other is converting relationship to a
node and here's an example for how you
would convert a the emailed relationship
the emailed thing that I mentioned
before if you had a system that modeled
email communication
you have one user the email another user
this is what you would do for
refactoring that to having something
that represents an email as a node so
hope is not lost if you if you happen to
have I've made a mistake you can always
refractor and yeah that's about it so
remember model your data for your
queries draw on a whiteboard using
examples and avoid redundancy and you
cipher it's a great query language it's
still young though we haven't done a lot
of work on performance optimization for
it so you might in some occasions want
to drop down to our native embedded Java
API either by writing a custom extension
to our server in Java or if your
deployment model is such that you can
support it actually embedding the
database within your application and if
you are interested in more information
about graph databases we have our own
conference here in San Francisco next
Friday so you're very welcome to attend
that I'm even going to give you a
discount code that gets you in for only
ninety nine dollars so if you use Java
one as discount code should be easy
enough to remember you can send our
graph connect conference for cheaper
than the regular price if that's too
long a wait for you you can come and
hear me speak more tonight at the meetup
at the engine yard offices and undress
Taylor my colleague and the main
implementer of the cipher query language
is going to be there as well thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>