<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Don’t Code It!! Unicode It!! | Coder Coacher - Coaching Coders</title><meta content="Don’t Code It!! Unicode It!! - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Developers/">Oracle Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Don’t Code It!! Unicode It!!</b></h2><h5 class="post__date">2015-06-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/TBSmnTvombs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome all to San Francisco jar 1 and
you know I feel privileged to open a job
on with you know one of the first lots
we got so I will come all to the session
called don't call it unicode it so I'm
going to discuss a lot about unicode
translation and best practices and stuff
like that so I request everyone to put
him a while so on silent form please so
that can have a good session over here
yeah so Who am I I think of Japanese
users can identify the text over there
it's written as like Who am I so am I
scenes of my engineer with verisign I
working there for the past three years
and you know you can reach me at mail me
at my official ID or my gmail ID you can
treat me at 192 satheesh and you know
what do i do I loves adventure you know
I like to travel norwich code so before
starting into the presentation I'm going
to discuss about a few stats or the
internet like you know which are like
pretty relevant you know pretty much
overlooked stats so on the stats is this
so this stat says the English so it says
about web content language so what is
the content language web content
language is like language in in which
your websites are there over the
Internet predominantly it's still
English fifty-four percent and the
Russian is six percent German is five
percent Spanish five Chinese for and you
know French focus and so they did data
and the websites is this much and pretty
much the content in other languages are
moving strong and English is
predominantly reducing and so let's look
at some of the stats so from 2001-2011
the online content in English increased
by 281 percent so can anyone gas like
the next entry is Arabic so can you know
anyone gas like how much person it
murder it might have increased any
guesses please sorry
that's way too far so it's 2,000 finite
% the next comes I shared by eighteen
hundred percent the next comes Chinese
bite for hundred percent and then
Spanish by 80 son percent and then the
Portuguese by nine ninety percent and
the rest other languages are like in
other category of you know your online
content and after that the study by Lisa
so I think Lisa is currently not
operational so what it says is like if
you if you are investing like one dollar
and the localization business you're
going to get $25 written on that this
stat was in 2008 2007 so after that Lisa
got closed in 2011 simpang and some most
ads so in EU like ninety percent of the
internet surface the prefer to access
websites in their own language and
fifty-five percent then at least
occasionally use a language other than
their own and like 45 person they use
like the feel like you know something is
still missing if the content is not
present in their own language and only
eighteen percent surface you know they
buy products online in a foreign
language like you know some a Spanish
guy purchasing something from a are away
cause Hebdo website is eighteen percent
and all this it signifies any one thing
it signifies the growth of Internet I
cross and it also signifies you know
your applications that should support in
translation going ahead so this is the
agenda for today I'm going to discuss
about the basic character sets unicode
encoding and i'm going to go deep into
in translation the best practices of
that and then i'm going to touch base on
localization i'm going to summarize and
leave the house for questions so so
let's go to the first topic the
character sets and Unicode and encoding
so initially the characters are like you
know we have something called as ascii
which was there from the beginning so
the way you need to represent characters
was like using ASCII so it stands for
American Standard Code for information
exchange and you know each character is
encoded a single white we have studied
this in our colleges and schools some
and the extinction for ask you is iso
8859 where it supports no language
support for Greek sorella can't have
boobs ebru languages and even in iso
8859 each language or each character is
encoded a single bite and it uses eight
bits on like a ski to seven bits in the
eighth bit is unused so let us go to the
next thing in a ski so you have a ski
works great for English text so internet
is predominantly not just English text
just more than English text so it has
like Chinese Japanese Hebrew Arabic and
other language text too so so then in
this case is like how to support the
millions of characters that you have a
cross so that is one concern another
concern is like what about so ASCII
supports only 0 to ask it defines the
antique code for each character from 0
to 1 27 but what about 128 to 255 what
do you do with that it's like lying free
around so what happened was like the
computer manufacturers they define
something or less code pages where like
they've defined the characters for this
range of 128 to 255 so very in like for
example i have i purchased a computer in
india so my manufacturer defined the
code page in in my own language it's
called telugu and you know i have a
friend from japan he purchased the
computer from his own manufacturer there
so his code pages for defined in
japanese that means like the text from
18 to 2 55 or defined in japanese and
when he is trying to reach me out let's
say hi how are you and i'm going to i'm
going to reach it or the text come reach
me in a different text or different way
because my computer is going to read it
as a different way because my code page
is different to us code page so this is
a ideal example of that for example the
characters 169 in hebrew is not the same
as the character 169 and Cyrillic it's
completely different so what happens of
this like you know it all results in
only one thing only confusion so what
are due to avoid this confusion we have
like unicode encoding to the rescue to
our dis confusion so let's see what is
unicode so unicode is like international
standard for representing almost all
written languages that exists in the
world and it it can accommodate
of characters and what it does it labels
each character as a something or less
code point so when this Unicode
consortium has sit down to define all
the or sit down a code point for each
character that is a long and discussion
because people from all the countries
sit together at the Unicode consortium
and you know they said like this
character the disk or point should
belong to my character and you know this
code point should belong to my character
and after all the confusion we came up
with a proper code points for all the
Unicode or all the text or all the
symbols you can see and for example
Unicode unicode points written in hex
you can take an example of character a
which is mapped to you plus 0041 that
sadden ocean you pluses the Unicode
innovation for that and they mapped as I
said they mapped every language every
character in every language to a code
point and the code point 0 2 127 are
same as a ski and Unicode supports
multiple n codings just like utf-8 utf-8
utf-16 you tf7 etc and the Unicode
version 6 20 is the latest and this
supported by Java and let's go ahead so
we have a new term here call n coatings
let's go and see what and coatings are
ya so what is an encoding a character
encoding is a way to represent a code
point in a sequence of bytes or we call
it as raw data so apart from unicode
they are like various encoding slick
which are supported by java to like the
CP series the IBM series the dost latin
the selic and many more so all this
encoding zar are like the present and
they separated by java to and unicode
has specific and coatings so let's have
a look at what encoding is unicode have
so UTF unicord has utf-8 utf-16 and you
dip 32 n coatings and what does UT of
stanford it's an for unicode
transformation format and its algorithm
mapping for every Unicode for every
unicode code to work corresponding
sequence of bytes sequence or raw data
bytes and yeah there is an example of
that character a and you know AE and the
euro symbol it's mapped to code points
and correspondingly utf-8 transforms to
that so UDF 841 and you know UDF
16 it's too white so it's 0041 and 32 is
like four byte 0 0 0 0 0 0 for 1 so let
us have a look at a brief look at this
and coatings how this in coatings are so
which encoding should we choose so you
have utf-8 which encodes each character
to one from one to four bytes and then
additional cases to six bytes and this
is best suited for a ski or Latin
characters because it just takes this
one bites to encode and you know this is
most common on the web but when using
utf-8 there's a time-space trade-off so
it needs to convert each character so
it's going to it's going to consume some
memory and it's going to consume some
time so which is actually pretty much
good for us because even though it takes
time it is very easy to represent a very
very easy to use utf-8 in our no web
language or when you're doing your
applications the next is utf-16 so
utf-16 encodes each character 22 24
bytes so so this is better wear a ski is
not predominant because it has a bite
way stage and this is used by java and
windows so the utf-16 on the typical
situations of you d 16 is like it
encodes each character into two bytes so
when you are encoding into two bytes so
when it if it is not if it is a ski one
of the white is wasted it's going to
become null and the other problem that
you're going to face with your 16 is the
Indian problem so when you when you
using when you are encoding text to
youtube 16 so they are two types of
indians one is a big indian and the
little Indian so the little endian all
comes first in the big Indian all comes
last so you never know which Indian the
text is encoded to so the solution for
that was the bike by Tata marker which
needs to be defined on the header of the
text which sees like this particular
text is encoded to big Indian or little
endian so that when you read the text or
when your reader reads the text it knows
that this is big Indian or little Indian
so that can be cut back to the same text
the original text so next comes you
utf-32 which encodes each character 24
bytes and this is used when your string
operations after dominant or like when
you string operations a prominent use
lot of link operations and the user due
to helps a lot there isn't early used by
lenox and various unix systems
so now we have seen like waters
character set we have seen what is
encoding what is unicode we have seen
what is encoding like how encoding is
slick important so i have explained
about utf-8 16 and 32 but you know we
will see couple of cases why you know to
sympathize or to emphasize on why you
have to use utf-8 as i know it's 16 and
32 so these are the considerations that
you have to see the storage space utf-8
is usually smaller text then you have 16
and 32 so let us have an example of this
so this is an ASCII string with a
japanese or chinese character embedded
so utf-8 usually takes 50 4 bytes 16 is
going to take 10 6 bytes and 32 is going
to take 20 8 bytes so these are the
considerations why you have to go over
utf-8 and the next one is error recovery
so this is pretty much important because
your applications when you use
international code and transfer text
your stream is going to get character at
some point of time out when it gets
corrupted it's very difficult to recover
it if you're if it is encoded in other
other strings like utf-16 the best
example for that is considered a Unicode
string like ABC and three Chinese or
Japanese I'm not sure Chinese characters
may be and then what happens after that
is when the stream is corrupted utf-8
just corrupts the single character and
it leaves other two characters a cities
but utf-16 what it does is it transforms
the corrected text sorry the culprit
takes to some other new character and it
transforms the meaning of the entire
input so this is one of the reasons why
you should go for utf-8 but not rather
than utf-16 so having said that let me
sit there is enough for today and let's
have done the first part of it let's go
to the second part just a important part
of it like internationalisation the best
practices so orders in translation so
this is a textbook definition which i
suspect it it means a lot more than this
like it is a design and development of a
product application or document that
enables easy localization for target
audience that vary in culture religion
or language it's a very big definition
but in short what it means is like you
have an application and let's say you
have an application you want to enable
data or you want to support text of
different languages and converting that
applique
to support text from multiple look of
multiple locales and regions is called
as in translation or making your
application ready to support that is
called translation it's often written as
I 89 i18n and and one more thing is like
your product needs to be entranced lies
before you need to localize it and why
in translation increased accessibility
to people of different cultures and
languages your brand awareness so as you
have seen the internet is growing a lot
in other languages as well so that you
can you have more opportunities for
growth and expansion for your particular
product or application so in translation
so let's see how it begins the typical
way in translation or a request often
translation begins with the customer and
this guy comes up and says application
should support Arabic Japanese Spanish
everyone Russian by now amber so this is
when like you know typical requests ads
from and it comes to the management and
the management chase yeah we already we
are good to go we can do anytime so this
guy says yeah it will be done and the
toughest part comes to engineering and
they think about like nicely be designed
your dynamic schema selection your
framework changes email character
encoding your downloading files
localization changes your mind data from
multiple formats and how to test so
after thinking about all this that's a
typical engineer no that's how it's
going to become so yeah so let's see
what and translation is and let's go
into the best practices so in
translation can be on the top can be
barely classified as two types one is
static and other is dynamic so let's
take an example of a simple website
where you know you're giving information
of your company and you know you hang
address and other stuff so this is like
when someone comes and ask you like
international ice or convert this
content for me to the language it's like
simple how do you call your labels or
resource bundles yes need to translate
the text add a new resource bundle and
switch other sauce bundles whenever the
language is switched or another locale
is switched which is very static which
is pretty straightforward it's not so
much effort than that so next comes a
dynamic part so consider an example
where you have a application or you have
a report capturing application way you
capture reports in various languages so
when this comes
the actual data is to be handled in
different languages but not just the
labels it always it it involves
redesigning your application so let's
have a look at what dynamic and
translation contains so these are the
typical components that you have an
application minus the end users the
safest guy and the webui the decks that
he sees on and your business layer which
includes you apart and JV impart the
database and your search engine and your
third-party products that you have in
your application so let's go into each
and everything individually so first
let's dye into web UI so when when you
displaying text on your screen always
make sure the web server sends the
character encoding information using the
content-type header and the content type
errors is always increased to use the
car set utf8 and also includes to be
equivalent in your websites which says
meta content its text HTML and cats at
utf-8 and for GSP's you can use a page
encoding and which says like you define
the page encoding and say page encoding
call you th of that whenever your text
comes up it will not be displayed as
junk agaves but it will be displayed in
proper text property Japanese or Chinese
text for XML then coding this utf-8 is
the default encoding so it should be
specified on the top of the header it
says xml version 1 and encoding utf-8
yeah so next comes a tomcat so watching
so a tomcat is on the up app servers
that we use so far apart i said the
following directive and has to be
confined which says which defines the
default care set utf8 and the next part
comes the request encoding so request
encoding is one thing which is very
tricky so what exactly why exactly you
need to encode your request in utf-8 of
the typical examples to you know
understand this is your on your
application has multiple data content
and we when you are giving out a
download and the download file name
contains your Unicode text so what do
you do in such situations if you don't
handle lot properly what's going to
happen is the download file name you're
going to receive it as a junk text and
finally when you're going to give the
download back it's going to be junk
again or you not your application cannot
find the file which you need to download
back so for
that you can just put request cap
encoding like you know the default
encoding of non cat is like iso 8859 so
you can just put you can either you are
encoding equal utf-8 this converts every
request utf-8 or else you can have a
different configuration like this so
what you can do here is you can create a
filter here so this filter what it does
is it adds it takes a parameter called
encoding and takes the para- as utf-8 so
you have a filter knee built a class so
let's say you have a very big
application very huge application where
only specific requests are to be encoded
to utf-8 so in such scenarios what you
do is you define a filter and then the
way you use it is like this either you
map the filter for all the URL patterns
that you have any application or you map
the filter for only specific URL pattern
where you are saying okay this URL
downloads me unicode artifacts or this
you all know not being specific
artifacts which contains non-unicode
text this is one way you can do it so
you have seen the URL encoding let's go
ahead and see what you have in Java and
yogi impart so Java default encoding
Java supports unicode encoding and the
default encoding is determined to the
property called file lot encoding so if
you don't specify this it's going to
take the system encoding property
whatever the system is having so if you
want to specify this you have to specify
this week by using be file encoding
which is the property into a set to
utf-8 and Java supports unicode 6 its
toes characters internal yes utf-16 and
all the outboard characters you can
convert that or different cats that if
you want to in case if not it's going to
go it's going to be utf-16 and this is
about like how Java supports let's see
something interesting an email subject
so email subject is a tricky apart if
subject line is not encoded properly
this is what is going to happen so when
you receive an email subject is going to
be junk speed reverse ? or a proper ? so
the problem is the email is the email
body is like a response so typically you
can just set the according to that and
you know it's going to work fine but the
email header is not email
is an ASCII encoded so when you have
special characters like this it is very
tough to do that so if you do not do it
yeah John characters would welcome you
new in box should properly encode the
subject so the way you should do it is I
should encode the subject into base64
encoder and you have the encoded subject
equal to utf-8 be so what the second
price is like you are defining the
castle first the utf-8 is the cat suit
in which you want to encode and then you
want you are defining something or less
be so we can see in some places it's
called as Q so Q is the quotable and the
B is the base 64 encoding so what it's
going to do is like it's going to take
the car set the encoding and it's going
to take the final values and it's going
to send it across so this is in this way
using this you can encode your email
subjects properly and you know you can
make sure that email subjects will now
be junk yeah so this is a similar
scenario which have discussed previously
out of your file has a unicode text name
in that this is the best example for
that there's a PDF file which has a text
name called japanese named or PDF if you
do not if you do not actually come sorry
yeah if you do not handle properly this
what is going to happen when you can do
your console back you're going to see as
a text call opening junk dot PDF and
then it says from your local host or
whatever it is so the problem with this
is like the browser's they do not
recognize this properly so different
browsers working different way IE
supports your landlord filings the five
Fox of words Bay 64 encoded file names
so the solution is encode the file name
basing on the browser so how do you how
you do that is like litter mine I'm
sorry it's going fast determine the get
the user agent object first and
determine which browser it is effort is
like msie or internet explorer or if it
is opera and for that you encode using
URL encoder or encode and if it is
Mozilla Firefox UN code using seem as
the base64 encoded so that and said that
encoding it your response so that when
you get a header
this it is going to be proper it will
not be like you know junk text that you
have seen previously so let us jump onto
validations part so string validations
are no pretty much important when you
are handling your text or when you are
having an application which accepts
reports of which accepts data on the
trickiest part here is like when we have
an application we have length validation
fields or length validation set for each
of us field so let's say you set us
length validation let's like 10 so and
you're going to store that corresponding
your database into 10 bytes or 20 bytes
each so let us assume you've stored in
20 bytes so if you see the example here
the length of this string if you if you
say dot length it is going to tell you
as eight so can even guess how many
bytes this might occupy that's a correct
answer so so what happened is like each
character is committed to three bytes
here so it's going to occupy 24 bytes in
your database if you want to store so
ideally when you are validating your
lens you should never do it on length
actual length but should always convert
that to your bites and then you should
validate the length of your bites so
that you'll never get an exception or
are saying that database is not
sufficient to slow your text even though
an actual you length is 10 and your
database is 20 it's double than that so
always do it in this way so that you can
have better storage and better
capabilities for you know unicode text
yeah so next is this what would you do
what you browser do it encounters this
below URL so when you click on it couple
applause like safari and like chrome it
automatically converts this to app
unicode URL and you know it's going to
navigate to the corresponding link but
mozilla couple optic nothing for the
past couple of months they fix this but
previous to that they had did they
didn't have the support to support
Unicode text or Unicode URLs what's
going to happen when you click on that
is like it doesn't know way to navigate
to so for that what you do is like you
have the puny code for your rescue what
does pineco dash what is pretty good
it's a Unicode syntax encoding syntax
you know
and for a Unicode string of characters
which translates them to the basic ASCII
car set so this is useful translates
domain names or people carless ID ends
and you know this is designed to a cross
walk across all the scripts it has
various capabilities to optimize your
your what you've all your Unicode of
Unicode text for the corresponding input
that you give so this is what Unicode is
so this is a small example of that how
it works so you take the idea and you
convert that to a string using idea not
to ascii and you give the URL the host
name of that and then when you form the
Unicode URL again saying putting all the
ascii text that you have received so the
if the input unicode URL as this it's
going to get translated to a Unicode URL
like this ascii text which resembles the
same as the previous URL so you have
seen in Java let's go to database and
see what you have in database so Oracle
supports storing unicode characters in
two ways this first one would be either
you convert your entire database to a
unique utf-8 or utf-16 encoding or you
have something or last national
characters where you use only specific
columns where you convert them like mcat
and Klopp you convert these columns into
an mark are you convert these columns
and only use these columns you need not
convert an entire database you know it
depends on the way you use if you have
all the applications in your database
using Unicode text yeah you can go ahead
convert them to database if you do not
have like that then you can convert on
the specific characters that you can
that you want to use so the way you
intercept is like you need to set the
car set and to define either 16 32 or
utf-8 so the only difference would be
like if you go for 16 s 8 is like fat16
your columns your column lengths is
going to be double like in the previous
example we have seen text of 20 it is
going to become 40 bytes and your DB
cassette yeah it is just the
illustration of water explained so let
us go ahead and see how you design a DB
and you know when you haven't ran
supplies
patience so the ideal design scenario is
like having a separate column to
identify data for each language and for
example the same example which have
referred previously considered an
application that captures reports so
each report would be an english russian
and chinese languages so the ideal
scenario is like create a report stable
and have a column which sees which
language report is the particular row so
all police on this table to obtain data
for reports is like you're going to get
to the table you're going to query for
like the particular language you going
to get the results back for that
language so this this is considered the
ideal design scenario but you know we
have it has pros and cons so what
happens in this is like one table or one
database table is going to be hit every
time and where ever you want data and
also this decision of going for a single
database way or single table which can
which should store all the language as a
column should be taken it the initial
design but not you know when you have
when you have application ready and when
you want on translation on the existing
application it is not at that stage but
the initial stage and the you know the
concept it is like it adds a lot of
float on the report it should contain
which contains like you know to maintain
parallel transactions multiple
transactions and the changing the
database once it is designed is if it is
a big task so what we have done so we
work an agile based model where you have
faster delivery we'd faster product to
market and stuff like that so what we
have done in a scenario is like we've
created a separate table for each
language or separate schema for each
language and we have retained the
existing structure as it is so that all
the queries are a sities except for the
fact that we are adding a query or
schema identifier for each table to the
starting of it so what the schema
identifier does is like it says or it
identifies which schema for this
language and you know it queries for the
corresponding schema of data for that
butler scheme or language so we also
have advantage in responders of this
like the advantages like better
identification of schemas and it's
better accessibility easy to maintain
and we promote reuse so what we have
done is like we've left the double layer
or data access layer as it is we have
all the queries in place
which we didn't change at all only thing
we change is like we added a schema
headed to it like identifier to identify
skew which schema basing on your
language change and the cons is like it
is not ideal design principle people
call it as and you know additional
language support yes it needs additional
schema but not on the code just me on
the back end and you know the dog should
be injected automatically so you will
see like what how do you take jobs in
the next slides so having a database or
having a database internalized is just
not enough what happens is like your
connection properties which are like
overlooked if you do not have a proper
connection settings in the properties
you do not be able to query or receive
text or receive Unicode text so how to
enable this the way you can enable this
like it's java d Oracle jdbc default and
care equal to true for your application
so this is one way to enable it there is
a movie that you can enable this just
like this so you define a data source
for your basically you for jdbc and you
give your jdbc URL username password and
connection properties and here you can
define a property which says default and
care equal to true so if you can
carefully see there are two properties
here one is defined for a small c and
the other says it's a big c and can you
anyone identify why it is too ok so the
default n small c care it works fine
session and the default and capital c
care it works for retrieval this is a
trivial but you know it is very
important because the reason being we
have like burned the hands like we have
just put either the small c or the
capital c and you know either the
retrieval works or the insertion works
so it is lot after lot of effort that
you know we've identified that the small
t works fine session the big c for
retrieval yeah the issues with default
and care is like if you convert your
data to an care what happens is like it
is like a significant perform impact on
performance the reason for that is like
whenever you do this conversion what is
going to happen is your oracle is going
to convert all your normal takes to n
text or your national character text
it's going to take time for example
there is one scenario which we faced so
what we are doing is we have two tables
which one which we are not worried on
outer join on these two tables so the
what do you call the unique entity of
table 1 is latin-based car set and the
unique entity of table 2 was utf-8 based
Cassatt so when Oracle was currying or
when you query for data from or auto
join from these two tables initially the
simple query performance time was like
four seconds or 0.4 seconds and you know
when the cat sets were different Oracle
converted all the output results or the
data results to utf-8 the higher cassatt
and it took like five second the six
seconds to get the output back and also
with default on card is on most
situation that you can face it says
unimplemented or unreasonable conversion
requested so this is going to happen
when you set castrum and search string
when you're passing a string which is a
ski or Unicode encoded and length
between 2k + 16 16 k as national
language parameters and that to a stored
procedure this is a very big lindy
scenario which we occurred but still
it's no it's 42 actually have a look so
this occurred only for jdbc 10x against
annex and 9x databases this didn't occur
for jdbc 92 against 92 database yeah so
we have discussed and previously like
you know we had different schemas so how
how did we switch between schemas we use
spring to dynamically inject dao objects
basing on the language preference and
the advantage was like we separated the
concerns and you know we had least
amount of code changes for existing code
because we just reuse the same code we
had we have added a something to the
table to some identifiers to the table
which changes / language and also the
conscious like initial initially yeah it
was stuff for us to do because for each
table that you have in your application
or that you have in add object you have
to add identifier which says lo que get
scheme out by language in your language
changes you'll schema changes that was
only tough which we feed so we've seen
the anime schema selections let's go and
see what you have in store for search
engine
so linguistic search architecture how it
works so when you have data Alec which
maps across multiple tables and which
which has like when you publish daily
like twenty thousand records 30,000
records in that scenario it's like huge
data when you have data in that numbers
it is always advisable to use search
which is on the text search not on the
actual database search so this initial
let's say this is the content that you
have and this herb it's going to it's
going to be actually indexed and
searched upon so you take a data source
index the content you see leucine you
tokenize it you filter it and you know
you use stop words use synonyms and you
finally you normalize the text so excuse
me so this configuration is unique
foreign or it can be unique for all the
different language texts that you have
only Japanese specifically has it was
separate tokenizer which can be used but
even that tokenizer is not valid against
so you use a standard tokenizer to you
know tokenize your text and finally this
how salon works but how actually use a
lot of course behave or search
architecture is let's see so salar is
like is open to enterprise platform from
apache Lucene project and as major
features like powerful tex engine
highlighting faceted search you're in
google when you say type something he
says is this what do you mean so even
all these features are available in
solar so solaris let's see how you can
configure salar as a architecture level
than at solar configuration level so the
ideal way to configure solares I single
field monte indexing and single core so
you'll have a single core where you have
you index all your data in a single
field when you retrieve UNIX from the
same thing or written the same thing so
advantage like one field where he is
indexing attack straight forward and you
know one schema one co for multiple
languages it supports all the language
and the problems with this is like it
has you need to custom tokenize it and
also the language you have to have a
language or interfere or standard
analyzer to end which text which
language text it is basing on that we
have to switch your tokens or the way
you are tokenizing the language and they
should have explicit tf-idf values
and also the biggest problem of
multilingual searches the relevance so
when you give a text in japanese and
menu search for a text when you have
like 10 records found you never know why
the 10 records are there because it's
not that everyone understands japanese
takes in japanese language so the
relevance is a very important factor
when you when you're doing actual
searches so this is how we have done we
had a single core where we stored all
the reports so what we have done so the
we've seen what ideal configuration is
but same constraint that we have like a
gel on remand you have faster product to
market and stuff like that so instead of
multi instead of single core indexing
what we have done is multi core indexing
so each code for each language so in
that case the most beautiful weight
helpless is like it helped us to retain
the single same configuration and you
know it we were not required to reindex
the entire text in the production and
also and we didn't have any query time
overhead because the same corista there
we just like ran them for different
schemas or different course it also
allowed us to reuse the code and it
enabled us to deliver the product faster
to the market rather than you know
instead of going to a ideal approach
yeah I agree that application complexing
peers because you have to manage
multiple quotes and also moving towards
single core approach is always ideal but
this design nation should be at the
initial level but not in events your
application is in prod and you know it's
running happened yeah so this is all we
have done different course for different
reports have seen what search engine
does let's see or third-party tools that
we have does so the typical third-party
tool first one is like so let's say you
have your applications displaying graphs
so so can you identify the text on the
x-axis and y-axis is dummy boxes so the
reason why is boxers what's wrong as
junk boxes the reason is like the font
support when you are building the graphs
for x-axis and y-axis is not enabled so
what are you in the font support the
font support like oh do you no phone
support is like whatever font you are
displaying the text here in so here it
is japanese text
so for japanese text for it to display
it does not have the supported font when
it is building the graph so the solution
is installed phone to the server site
that supports the corresponding line or
the conspiring language for x axis y
axis and use that font when you are
defining the axis labels for example
here you can say access properties to
sell title character font and you set a
new font so here as Texas Japanese so
the VL gothic font support chef nice
text so we have used that phone to
support the text on the x-axis and
y-axis so next comes the specialist tml
characters always the specialist America
does need special treatment so if you
are if you want to see what the facility
male characters are like it is a double
dagger it is a MLA or unlistenable send
sign and other characters so if you do
not handle this characters properly it
is going to be very tough so what it's
going to happen as you can see the text
here they have being displayed as like
actual symbols you can see I acute and s
care and stuff like that so a solution
is what happen is like the characters
got escaped so you have to unescape the
characters before displaying them on
your actual you I so next comes the
ckeditor part so see character has a
very popular history man text editor at
say what you see or what you get edited
so it rises specialist EML characters
and it converts them to character code
so for example you have input called
internet TM what is going to do is it's
going to go and convert that internet
and trade dot and it if you do not
handle this properly it is going to see
if in the same way in your database as
internet and trade colon so so how do
you do it like if you having XLT
processing and you know if you want to
handle the specialist email text the way
in to do is does like you need to have
this configuration signore fckeditor dot
J's file which says is to process team
and it is false and it is false basic
and it is false and your Greek and Latin
and it is false so if you put this it is
going to escape all this characters and
it's going to save this character cities
in your database yeah next comes a tidy
tide is a small utility where it helps
you and you know completing your HTML
statements or your correcting a
stainless treatment for example you have
something always heading where the
ending tag is not closed
tri-d is going to give an input like
this output like this so so in tidy the
problem is when you have text with
international characters or unicode
characters and you sent that text as an
input to tidy it encodes it to its
default encoding which is a Latin or
input as Latin output us-ascii so your
text get scrambled so the best way to do
that is lik you set the default encoding
so you set the input and output output
encoding set ID which is I created set
input end currently you do fine
opportunity a fight so that when it
handles this text it's going to handle
it properly and it's going to turn back
it's going to turn back your tricks
properly yeah so we have seen what if
the PDF name contains junk characters so
what if the PDF itself contains unicode
text and if you do not handle us
properly this word is going to happen so
the whatever PDF you are going to get is
going to get scramble with all hashes
the reason for this is like the font
support for this fonts for the PDF is
not installed so you should always
install your supporting fonts for your
for the languages that your support and
for your PDF free download the
corresponding text so the way the main
challenges that you get in this is like
one font will not support all languages
and if that supports a paid font and
Arabic and Hebrew need separate font
same cases japanese and chinese and if
these not available that's what are
going to see you going to see Jeong
characters on your PDF so what you do
what you do is like use helvetica font
for English and Latin language support
so all these fans are like analyzing
like hundreds of fonts and you know
getting out all the free fonts out but
not the paid ones so use free sorry for
Russian Arabic and Hebrew language
support and then use IPA go thick for
japanese japanese language support and
use chinese font for simplified chinese
and traditional chinese language support
and then as i explained all the phones
are like free fonts and which can be
used to display unicode characters in
PDF and apartment that you also have
something called as arial unicode ms
which can be used but the licensing of
this or or the purchasing of this is a
bit it's a bit problem so you know we
went for the free fonts which you know
which are they available or internet so
we just used them
so this is a more thing called a spy
where you know which can be used to
generate Excel files so when you have
cells with unicode data it shows up a
done it shows up as John character
Shapiro and handled improperly so the
way you introduce like you need to
encode each cell after you create it the
way you have to do it is like yes end or
set the cell type a string and by
default the java string a CD of 16 so it
encodes it to that and returns back the
text properly yeah so we've seen in
translation the best practices and you
know we've seen character sets Unicode
encoding and let's go and see what do
you have in store for localization so
what is localization so localization is
nothing but adaptation of your product
or your application or document or
content to meet the language or cultural
requirements I'm sorry when back yeah so
it is written as i 10 n and it contains
or it entails customization to all the
following like date formats currency
keyboard usage alkylation and sorting
symbols icons you know colors and
minimal things so a product must be
internationalized first for you to
localize it the reason is like if you
don't have it's supporting different
languages you cannot support a specific
language so let's see couple of best
practices of localization that you have
a date and time format so date and time
format is not constant across across the
world like each region supports or each
region sees the date as differently or
the format differently so let us take a
typical example so my birthday party is
on three four five so this date three
four five can anyone guess what s is in
US or Japan
yeah so it's a belter to then fine
Europe it's much further than fine us
and it's april fifth to the three in
Japan so what my birthday is going to be
three different ways in three different
places so you should always handle your
dates properly so the best way to handle
your dates is like have your application
that supports you know have your tables
that you have in your database to
support these formats and have one
column you know to support all these
streets or you want to add specific
dates to specific regions and have a
single column which is like out of your
eye which doesn't handle anything but it
just has a UTF UTC date format so what
you do is lay whenever you get a date
convert that to UTC and stow that in
that particular column so what utility
does is like it removes a ambiguities of
seasonal time changes or it removes the
expertise of local time zones like gmt
or or you know the pacific time and
stuff like that and it can be converted
easily to a local aware display which
you have so the options to consider is
like use long format dates the word
possible misinterpretation also have a
new column to store UTC date and you
know application services populates it
with UTC basically you populate your
rates with UTC whiskey and yeah text
display or layout so when you displaying
text elements on on your UI so you need
to take specific here for different
language text let's say you're
displaying Arabic text so what happens
with arabic text so it's a single by
text and they expand horizontally so
when you have a fixed space that for you
to display text it's you're displaying a
character called string and you define
less like six or six inches of display
on the screen it doesn't always help
because the string in Arabic is going to
expand to more than six let's say it's
going to go to eight or nine and
sometimes more than developing this text
to that's for single bite and for the
double byte characters like Japanese and
Chinese Chinese Korean they expand
horizontally but not vertically so even
the horizontal space also should be
properly considered for each language
when you're displaying them
and the options to consider use dynamic
length protects fields where multiple
language might be displayed and do not
use fixed length as it truncates the
text when you displaying them so that is
one thing and next is yeah handling
numbers so when you're passing your
numbers should take very good care
because for example see the string 9 8 7
6 5 4 this can be passed in different
ways in US UK Japan it is equivalent to
the entity of nine eight seven six five
four in Europe it is equal to nine eight
seven six five four thousand which is
nothing but the decimal so always use
local specific formatting for numbers as
the very basing on locale for example a
simple example here where you define a
local called Germany and when you have a
number what you do is you get the number
format for that Butler instance or get
an instance of the patellar locale for
that number and then use that which you
know for this for example for Germany
displays as nine eight seven comma 6 55
DM yeah so we've okay we've done with
numbers and let's go see what have in
currency so even see similar to your
numbers your currency is also different
for different countries where in u.s.
you displayed as dollars nine eight
seven six point five four and in French
of Rancho de freitas like nine eight
seven six five four so use always use
local specific settings for currencies
as they are like the very basing on
locale for example define a local for
Canada and use the currency here like
you know format it define a new instance
for that particular locale and formatted
using that so the main reason why
currency is out there here is because
when you're handling monte transactions
across your application let us say you
you're converting or you have
application which converts your money
from one language or from one region to
other region so one dollar is equal to
six sixty rupees or 62 rupees if you
don't get the currency text properly
from that what's going to happen is one
dollar is going to be equal to six
rupees or one dollar is going to equal
to six hundred rupees so it should
carefully handle that so next comes the
collision collision is general term
that's used to describe or determine you
know how the sorting works so
the way you have to use collation is
like let us say you have two characters
like Z and 0 with Emily so in Swedish z
is less than over them lay and in German
Oh with emulous lyst answered so when
you are sorting text or when you're
sorting text in your application it's
very tough to determine the sorting
order if you have multiple languages so
the best way or or the typical way to do
that is like there is a collision
algorithm provided by unicode so use
that collation algorithm you can
actually customize this collision
algorithm for your specific languages so
once you use this it's going to
determine which language text should
come first when you have multiple texts
of different languages so this is
coalition which is very important also
please even explain like and you're
having multiple multi-language
multilingual search it's always good to
have a correlation on top of it so that
when you get the text out it's going to
be in a proper sorted way than a jumble
way yeah next comes first let us format
yeah this is a typical example which you
see on websites where you know India and
now people ask you to fill like four or
five address fields for your single
address and you know all the fields are
mandatory and you know it's very tough
to feel like one character each in each
field and like in u.s. you have like
three fields of two fields to fill your
address and in Japan you have two fields
to fill a dress so when you have all
these things for consideration always
use a free text for you know updating
the address don't you know make the user
enter more things in different fields
instead of having and said just give a
single field and ask them to enter in
that field so that will be easier for
you to format and as well it will be
easier for you the user to enter text as
well so that is one thing and yeah so
one more thing which I want to discuss
and this is like when you're handling
the Arabic and Hebrew text the way the
Arabic and Hebrew text words is like it
goes from right to left instead of the
left to right so and anyone can guess
there's one synonym in this like the
numbers in Arabic the Gotham left to
right or right to left any guesses peace
so the numbers from in Arabic or Hebrew
it goes from left to right instead of I
to left so it's like
the text goes from right to left the
numbers were similar to right so this is
a very big confusion when you're
handling text when you're editing text
on your editor what happens is when you
delete a number across when you use a
backspace instead of the previous
character the next characters will be
deleted if user delete the previous
character the forward Carter will be
defeated deleted so in situations like
that should your text editor should
handle this properly if you do not
handle this properly your text will get
like the user will get confuse like why
am deleting am using a backspace but why
the front cat has big deal attention of
the back character so that is one thing
and once you have done with that you
have something or less pseudo
localization which is like which allows
you to test what you have done so far so
pseudo vocalization is a testing
procedure that you can use in order to
test aspects of international aspects of
your software so for example you have
something or less account settings so
you replace your actual text whether
it's different dicks Corleone settings
and you know when you run your
application with this text if it doesn't
display this new takes that means like
your application is still not supporting
your proper text or you have to see
something which is wrong also when you
are testing performed X 4 string length
expansion so previously explained like
when you have strings with small lens or
specific lengths you Arabic and Hebrew
text or your Japanese takes get expanded
horizontally or vertically so in such
cases you should always ask you a
validation team to perform stingwell
with expansion issues and also the
extended character display or corruption
issues like and you have a different
character sets or specific character
sets like your special HTML characters
and you are trying to update or use
those in your application it's going to
be very difficult if you do not handle
this properly so you should always
validate for those characters as well
and also everyone is not a language
expert you know we are developers via
coded s we don't you know we do not
sympathize more on the language so
always have it's better to have a
specific language translator or language
known person to validate your searches
or to validate your text in your
application specifically searches
because you cannot now come to a
conclusion based on the diluents so the
relevance orders are very important when
you have multi lingual search so yeah so
we've come to the last part so I want to
summarize this for today
so you have to plan ahead to reduce the
costs or to reduce costs and engineering
effort and it is a mass for all the
modern modernized applications because
you have lot of growth in the internet
and also understanding the basic
language constraints which helps you to
internationalize your applications
better because like basic language
considered like Arabic takes most on
right to left and you know the numbers
motion electrolyte all these things so
also it provides a global reach to
application it gives it gives a much
better value to your product also I'm
sorry take good care of relevance
factors while implementing your
multilingual search you know as
explained like have a dedicated
translator with you always so that for
each language you can validate your
searches and your text and data and
finally don't just score it understand
the concepts of Unicode and you know
Cody applications using Unicode so these
are the couple of searches which have
used in the the Indus ppt and now is
open to questions yeah please yeah
expensive you just want to expand into
the ankles you wanna go to the UK
Australia New Zealand right how do you
adapt the strategy so so the base the
base for localization would be when you
design your application or when you
strategize your application so always
consider all the aspects which are
mentioned in the localization when you
design your applications like putting
more spin more length us all the string
spaces or you know when you have special
things like your currencies in place so
when you when you design your framework
you have to have all these things in
aspect so if you don't have what happens
like typical example what we have done
like you know it was like we just given
like 20 30 days to get the fruit out of
market it was very tough to identify all
this thing's first after identification
you know you have to convert all the
things into your specific locale
specific link currencies or like you
know the address for my hat or anything
everything else so once you have your
application ready we get it off so use
it from the design stage that we have to
do all the things you have to use all
those things so that when suddenly a
request comes like this like you want to
localize to us or America it will be
very easier to localize it so that
answers your question thank you any more
questions please
so one of four I want to explain his
case energy which of explained
previously so we had a deployment of a
product into applicant Amun to your
production so after the deployment was
done you know the quarries for like
taking 30 seconds 40 seconds 50 seconds
to run so the reason was that like
explained less energy previously like
when you when we are querying the two
primary keys of two different tables
were in different character sets so when
it's it's converting an Oracle
internally converted it converted to
everything to the higher character set
so that entirely took a lot of time and
effort so this is a very tricky it is
very tricky to identify why it's
happening like that but you know should
always make sure when you're querying on
two tables both the tables have same
character sets or what the tables are in
similar character sets so any more
questions please yep yes yeah yes so the
way we used is like all the interest
partisan single field and we have
something called as the pin number or
pin code so which we put it separately
out and we have something called as the
recall the address locator you tell that
we have written so a part in the pin
number whatever you have it identifies
based on a comma or a space or as a
delimiter so we determine it is a
generic utility of written so you can
determine or you can give the input as
like space or comma or Colin where you
can put on the top of a dress or that
address field saying colin is a
delimiter so whenever the user hits a
colon that means he is going to go to
the next line is going to continue for
the next next like street name or city
name like stuff like that so our digital
it it's going to pass that on Colin and
it's gone identifier and it's going to
put it in the database so basically
that's what it is we don't want to use
to get confused or like writing multiple
fields surrounding data into multiple
fields
no no this is just to identify text
instead of having a multiple text so
that we'll have better when you index
this into salah you will have better
searching capabilities so in that way we
will have better searching capabilities
validation for for what whatever
foundations using blunt validations you
cannot do that yeah it's all up to the
user like order I enters his Audion does
any more questions please yeah I'm sorry
here yes so we have an marker and as
well vodka yes I made you say yes yes so
it's like each character is going to
store so are the way we you know we
think of or we assume that is like each
character is going to store in one bite
is that what you are asking yeah so each
character by default is going to be in
one bite so if it is if your DB is so I
can cut utf-16 it will be in two bites
so when you have English characters it's
going to map to your bites parallel your
10 bytes 10 characters is going to
matter 10 bytes it's going to easily fit
into 10 bytes but when you have your
Japanese characters each Carter is going
to map two three or four bites so one
traditional Chinese character which we
used map to six bytes so what we have
done is like we have in your database
you have like four thousand bytes and
you know are you I supported only like
16 of it six hundred characters from you
I so 600 characters of Unicode or
international text was equal in to two
thousand or 4,000 bytes which you have
stored in database also we translate so
all this mappings are critically very
important is that the question that you
asked
okay thank you any more questions please
yep if it's a key seein ya thank you
thank you all thank you and lick</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>